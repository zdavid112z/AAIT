{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "{'epoch': 86,\n 'arch': 'resnet50',\n 'state_dict': OrderedDict([('conv1.weight',\n               tensor([[[[ 0.0170, -0.0061, -0.0434,  ..., -0.0258, -0.0037,  0.0245],\n                         [ 0.0020,  0.0256,  0.0646,  ..., -0.0058,  0.0337, -0.0156],\n                         [ 0.0174,  0.0205,  0.0694,  ..., -0.0023,  0.0101,  0.0109],\n                         ...,\n                         [-0.0099,  0.0191,  0.0401,  ...,  0.0240, -0.0557, -0.0412],\n                         [-0.0166, -0.0345,  0.0606,  ...,  0.0030, -0.0187, -0.0362],\n                         [ 0.0061, -0.0541,  0.0253,  ...,  0.0001,  0.0160, -0.0042]],\n               \n                        [[ 0.0085, -0.0118,  0.0107,  ...,  0.0185, -0.0017, -0.0038],\n                         [ 0.0076,  0.0154, -0.0033,  ...,  0.0134, -0.0225,  0.0095],\n                         [ 0.0043, -0.0131, -0.0186,  ...,  0.0135, -0.0143, -0.0183],\n                         ...,\n                         [ 0.0136, -0.0583, -0.0079,  ..., -0.0351, -0.0093, -0.0424],\n                         [ 0.0211, -0.0632, -0.0201,  ..., -0.0451, -0.0287,  0.0231],\n                         [-0.0091, -0.0317, -0.0107,  ..., -0.0135,  0.0040, -0.0329]],\n               \n                        [[-0.0002,  0.0054, -0.0156,  ..., -0.0283,  0.0171,  0.0031],\n                         [-0.0305, -0.0514,  0.0114,  ..., -0.0183, -0.0050, -0.0099],\n                         [-0.0162,  0.0043,  0.0137,  ..., -0.0297,  0.0105,  0.0227],\n                         ...,\n                         [-0.0512,  0.0187, -0.0072,  ...,  0.0086, -0.0224,  0.0116],\n                         [-0.0014,  0.0106,  0.0140,  ...,  0.0297,  0.0071, -0.0238],\n                         [-0.0020,  0.0140, -0.0015,  ...,  0.0006, -0.0135,  0.0119]]],\n               \n               \n                       [[[-0.0113, -0.0259,  0.0586,  ..., -0.0046,  0.0209, -0.0095],\n                         [-0.0123, -0.0089,  0.0020,  ..., -0.0046,  0.0012,  0.0053],\n                         [ 0.0173,  0.0209,  0.0469,  ...,  0.0070,  0.0050,  0.0292],\n                         ...,\n                         [-0.0651, -0.0818, -0.0198,  ..., -0.0013, -0.0251,  0.0151],\n                         [ 0.0520, -0.0673, -0.0020,  ...,  0.0205, -0.0010,  0.0143],\n                         [ 0.0378, -0.0617,  0.0051,  ..., -0.0297,  0.0224, -0.0051]],\n               \n                        [[ 0.0144,  0.0027,  0.0014,  ...,  0.0149, -0.0247,  0.0010],\n                         [ 0.0202, -0.0008,  0.0343,  ...,  0.0335,  0.0073, -0.0520],\n                         [-0.0150, -0.0118,  0.0627,  ..., -0.0150,  0.0054,  0.0261],\n                         ...,\n                         [-0.0550, -0.0660,  0.0036,  ...,  0.0169,  0.0084,  0.0145],\n                         [-0.0002, -0.0674, -0.0041,  ..., -0.0070, -0.0019, -0.0238],\n                         [ 0.0384, -0.0500, -0.0392,  ..., -0.0179, -0.0161, -0.0090]],\n               \n                        [[-0.0129,  0.0277, -0.0109,  ...,  0.0241, -0.0269, -0.0121],\n                         [ 0.0106, -0.0444, -0.0030,  ..., -0.0149,  0.0007,  0.0232],\n                         [ 0.0007,  0.0064,  0.0160,  ...,  0.0257, -0.0051,  0.0123],\n                         ...,\n                         [-0.0697,  0.0114, -0.0002,  ...,  0.0364, -0.0020,  0.0050],\n                         [ 0.0081, -0.0297,  0.0138,  ...,  0.0160,  0.0158,  0.0025],\n                         [ 0.0072, -0.0760, -0.0242,  ..., -0.0058, -0.0101,  0.0104]]],\n               \n               \n                       [[[ 0.0289,  0.0286,  0.0287,  ..., -0.0098,  0.0021, -0.0083],\n                         [ 0.0079, -0.0406, -0.0899,  ..., -0.0100,  0.0039, -0.0070],\n                         [-0.0250, -0.0466, -0.0929,  ...,  0.0234,  0.0174,  0.0350],\n                         ...,\n                         [ 0.0093,  0.0150,  0.0234,  ...,  0.0472,  0.0191, -0.0377],\n                         [ 0.0129,  0.0142, -0.0021,  ..., -0.0159,  0.0290, -0.0025],\n                         [-0.0415,  0.0166,  0.0237,  ...,  0.0098, -0.0257, -0.0049]],\n               \n                        [[-0.0102,  0.0062, -0.0361,  ..., -0.0008, -0.0050,  0.0052],\n                         [ 0.0085,  0.0031, -0.0335,  ..., -0.0241,  0.0092,  0.0079],\n                         [-0.0211, -0.0291, -0.0240,  ...,  0.0220,  0.0108,  0.0159],\n                         ...,\n                         [ 0.0252, -0.0270,  0.0246,  ..., -0.0293, -0.0274,  0.0128],\n                         [-0.0194, -0.0190,  0.0052,  ...,  0.0023, -0.0217, -0.0119],\n                         [ 0.0365,  0.0068, -0.0401,  ..., -0.0054, -0.0015,  0.0051]],\n               \n                        [[-0.0004,  0.0048,  0.0343,  ...,  0.0007, -0.0123,  0.0018],\n                         [ 0.0001, -0.0192, -0.0606,  ...,  0.0094,  0.0184,  0.0012],\n                         [-0.0179, -0.0762, -0.0234,  ...,  0.0109, -0.0063,  0.0025],\n                         ...,\n                         [-0.0099,  0.0415,  0.0439,  ...,  0.0522,  0.0302,  0.0035],\n                         [ 0.0223,  0.0121,  0.0085,  ...,  0.0360, -0.0302, -0.0025],\n                         [-0.0082, -0.0255,  0.0241,  ...,  0.0226, -0.0168, -0.0018]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0151, -0.0072, -0.0109,  ...,  0.0129, -0.0357, -0.0229],\n                         [-0.0225, -0.0313, -0.0020,  ..., -0.0377, -0.0206, -0.0250],\n                         [-0.0193, -0.0195, -0.0451,  ..., -0.0118,  0.0004,  0.0341],\n                         ...,\n                         [ 0.0259,  0.0357,  0.0369,  ...,  0.0150, -0.0541,  0.0321],\n                         [-0.0066, -0.0013, -0.0189,  ..., -0.0169, -0.0002,  0.0127],\n                         [-0.0011, -0.0093, -0.0013,  ...,  0.0074, -0.0232,  0.0197]],\n               \n                        [[ 0.0350,  0.0055,  0.0220,  ...,  0.0286,  0.0154,  0.0224],\n                         [ 0.0036,  0.0574,  0.0058,  ...,  0.0016, -0.0026,  0.0118],\n                         [-0.0090, -0.0703, -0.0485,  ..., -0.0342, -0.0167, -0.0286],\n                         ...,\n                         [-0.0031,  0.0213,  0.0431,  ...,  0.0347, -0.0046, -0.0604],\n                         [-0.0099, -0.0312, -0.0685,  ..., -0.0584, -0.0278,  0.0148],\n                         [ 0.0084,  0.0306,  0.0034,  ...,  0.0488,  0.0043,  0.0038]],\n               \n                        [[-0.0394, -0.0171,  0.0009,  ...,  0.0024,  0.0318, -0.0326],\n                         [ 0.0375,  0.0397,  0.0202,  ...,  0.0090, -0.0229,  0.0081],\n                         [ 0.0041, -0.0198, -0.0397,  ..., -0.0183, -0.0192,  0.0158],\n                         ...,\n                         [-0.0008,  0.0150,  0.0236,  ..., -0.0015, -0.0161, -0.0187],\n                         [ 0.0061, -0.0156, -0.0277,  ..., -0.0319,  0.0134,  0.0096],\n                         [-0.0156, -0.0174,  0.0240,  ...,  0.0203, -0.0157, -0.0247]]],\n               \n               \n                       [[[ 0.0153,  0.0292,  0.0281,  ..., -0.0473, -0.0139, -0.0030],\n                         [ 0.0022,  0.0107,  0.0230,  ..., -0.0588, -0.0468,  0.0382],\n                         [ 0.0038, -0.0723,  0.0339,  ...,  0.0648, -0.0416, -0.0217],\n                         ...,\n                         [-0.0048,  0.0003, -0.0560,  ...,  0.0788,  0.0665, -0.0277],\n                         [-0.0042,  0.0220,  0.0270,  ..., -0.0562, -0.0126,  0.0129],\n                         [ 0.0073,  0.0205,  0.0200,  ..., -0.0304, -0.0119,  0.0238]],\n               \n                        [[-0.0087, -0.0206,  0.0186,  ...,  0.0020,  0.0408,  0.0003],\n                         [-0.0105,  0.0175,  0.0029,  ..., -0.0291, -0.0090,  0.0028],\n                         [-0.0099,  0.0208, -0.0188,  ...,  0.0074, -0.0297,  0.0161],\n                         ...,\n                         [ 0.0086,  0.0326,  0.0081,  ..., -0.0223, -0.0084, -0.0136],\n                         [ 0.0139, -0.0149, -0.0088,  ..., -0.0321,  0.0239,  0.0114],\n                         [-0.0113, -0.0045,  0.0066,  ..., -0.0122,  0.0250, -0.0004]],\n               \n                        [[-0.0021, -0.0195, -0.0087,  ...,  0.0178,  0.0152, -0.0162],\n                         [ 0.0089, -0.0185, -0.0034,  ...,  0.0028,  0.0325,  0.0056],\n                         [ 0.0062,  0.0148, -0.0205,  ..., -0.0280, -0.0068,  0.0196],\n                         ...,\n                         [-0.0340,  0.0146,  0.0138,  ..., -0.0167, -0.0322,  0.0347],\n                         [ 0.0007, -0.0094,  0.0192,  ...,  0.0273,  0.0042, -0.0100],\n                         [ 0.0059, -0.0331,  0.0015,  ...,  0.0189,  0.0033, -0.0247]]],\n               \n               \n                       [[[ 0.0029, -0.0016,  0.0200,  ...,  0.0114,  0.0072, -0.0179],\n                         [-0.0253,  0.0130, -0.0096,  ...,  0.0325, -0.0149,  0.0081],\n                         [-0.0057,  0.0521,  0.0444,  ...,  0.0504,  0.0382, -0.0117],\n                         ...,\n                         [-0.0096, -0.0044, -0.0693,  ..., -0.0310, -0.0172,  0.0253],\n                         [-0.0353, -0.0058, -0.0069,  ...,  0.0237,  0.0497,  0.0066],\n                         [ 0.0233,  0.0067, -0.0003,  ...,  0.0198,  0.0022, -0.0227]],\n               \n                        [[ 0.0028,  0.0092, -0.0087,  ..., -0.0198,  0.0211,  0.0016],\n                         [ 0.0093, -0.0048, -0.0211,  ...,  0.0181,  0.0112,  0.0175],\n                         [ 0.0063, -0.0068,  0.0536,  ...,  0.0399,  0.0337, -0.0014],\n                         ...,\n                         [ 0.0153,  0.0048, -0.0399,  ..., -0.0608, -0.0076, -0.0065],\n                         [ 0.0018, -0.0191,  0.0058,  ...,  0.0191, -0.0297,  0.0292],\n                         [-0.0204, -0.0133,  0.0322,  ...,  0.0001,  0.0126,  0.0101]],\n               \n                        [[ 0.0221, -0.0024, -0.0057,  ...,  0.0115, -0.0060,  0.0105],\n                         [-0.0289, -0.0367,  0.0236,  ...,  0.0099,  0.0164, -0.0014],\n                         [ 0.0245,  0.0304,  0.0872,  ...,  0.0853,  0.0139,  0.0161],\n                         ...,\n                         [-0.0018, -0.0497, -0.0210,  ..., -0.0344, -0.0084,  0.0033],\n                         [ 0.0266, -0.0039, -0.0103,  ..., -0.0379,  0.0264, -0.0397],\n                         [-0.0151,  0.0037, -0.0056,  ...,  0.0060, -0.0106, -0.0150]]]])),\n              ('bn1.weight',\n               tensor([0.7847, 0.9172, 1.0542, 0.8899, 0.7934, 1.0288, 0.8917, 0.8543, 0.7572,\n                       0.9163, 0.8919, 0.9928, 0.8467, 0.8459, 1.1230, 1.2172, 0.9849, 0.8914,\n                       1.0316, 1.0690, 0.9608, 0.9386, 1.2706, 1.0624, 1.0948, 1.1437, 0.9014,\n                       0.9944, 0.8584, 1.1555, 1.0830, 0.9887, 0.8928, 0.9334, 0.8312, 0.8045,\n                       0.9408, 0.8436, 0.8460, 1.0910, 0.9874, 1.0324, 1.1500, 1.1806, 1.0805,\n                       1.0112, 0.8924, 0.8326, 0.8099, 0.7781, 0.9498, 0.9083, 1.0825, 0.7956,\n                       1.1021, 1.0434, 1.0486, 0.9006, 1.0348, 0.8248, 1.0111, 0.8741, 0.8993,\n                       1.1301])),\n              ('bn1.bias',\n               tensor([ 0.2805,  0.0893,  0.4276,  0.3565,  0.1798,  0.3280,  0.3141,  0.5996,\n                        0.3203,  0.1718,  0.1446,  0.7326,  0.3491,  0.1838,  0.0126,  0.4341,\n                        0.2965,  0.0978,  0.7293,  0.5894,  0.6202,  0.1814,  0.8993,  0.1664,\n                        0.4113,  0.7769,  0.1369,  0.2740,  0.3730,  0.0099,  0.9701,  0.3263,\n                        0.1113, -0.0020,  0.1707,  0.5150,  0.3344,  0.2802,  0.4526,  0.0099,\n                        0.7368,  0.1444,  0.0054,  0.4990,  0.0332,  0.3439,  0.0884,  0.2401,\n                        0.1982,  0.3936,  0.5092,  0.0967,  0.2067,  0.2573,  0.0751,  0.0485,\n                        0.3565,  0.1985,  0.1709,  0.2179,  0.4451,  0.3026,  0.3654,  0.1628])),\n              ('bn1.running_mean',\n               tensor([ 1.4135e-03,  3.1521e-03, -3.1321e-03, -3.4468e-03, -1.7758e-04,\n                       -6.2092e-03,  1.7688e-04, -8.7361e-04, -2.9407e-04, -1.4239e-02,\n                       -6.5435e-03, -5.1693e-04,  2.3054e-04,  2.2185e-03, -5.3485e-04,\n                        1.4671e-02,  7.1111e-05, -7.8620e-04,  1.0034e-05, -6.7187e-03,\n                        5.0433e-04,  4.1384e-04, -6.8329e-04,  2.0778e-05, -9.1007e-03,\n                        8.0838e-04,  3.3700e-05,  2.1336e-03,  1.2009e-04,  1.3641e-04,\n                        4.5290e-03,  4.6712e-04, -1.3441e-03, -3.3862e-04, -5.5203e-03,\n                        9.6873e-04,  1.4836e-03, -3.9035e-04,  6.0818e-04, -2.1074e-04,\n                        1.0253e-03,  8.3378e-05, -9.2978e-04,  1.1587e-02,  2.0655e-03,\n                       -3.1783e-04, -3.4977e-03,  3.9785e-05,  5.0409e-04, -1.2554e-04,\n                        1.5199e-03,  6.8413e-05,  5.6445e-04, -6.6357e-04, -1.6852e-03,\n                        2.7362e-04,  3.6007e-03, -3.9105e-03, -5.1574e-03, -5.6557e-03,\n                       -1.8058e-03,  1.4866e-03, -2.8267e-04,  1.7813e-03])),\n              ('bn1.running_var',\n               tensor([0.1206, 0.1235, 0.1288, 0.0767, 0.0021, 0.1457, 0.0110, 0.0321, 0.0184,\n                       0.8191, 0.1922, 0.0774, 0.0084, 0.1414, 0.0092, 0.8285, 0.0085, 0.0185,\n                       0.0271, 0.4300, 0.0138, 0.0275, 0.0189, 0.0089, 0.2706, 0.0390, 0.0110,\n                       0.0750, 0.0375, 0.0230, 0.1315, 0.0191, 0.1197, 0.0202, 0.1763, 0.0410,\n                       0.0237, 0.0256, 0.0095, 0.0480, 0.0110, 0.0393, 0.1855, 0.2262, 0.0326,\n                       0.0080, 0.0600, 0.0044, 0.0395, 0.0054, 0.0774, 0.0357, 0.1333, 0.0183,\n                       0.1919, 0.0246, 0.2648, 0.1871, 0.2592, 0.1585, 0.0260, 0.0355, 0.0069,\n                       0.1236])),\n              ('bn1.num_batches_tracked', tensor(13572)),\n              ('layer1.0.conv1.weight',\n               tensor([[[[-0.1040]],\n               \n                        [[ 0.1076]],\n               \n                        [[ 0.1878]],\n               \n                        ...,\n               \n                        [[ 0.2816]],\n               \n                        [[-0.1266]],\n               \n                        [[-0.0499]]],\n               \n               \n                       [[[-0.0848]],\n               \n                        [[-0.0687]],\n               \n                        [[ 0.2110]],\n               \n                        ...,\n               \n                        [[-0.0044]],\n               \n                        [[ 0.0394]],\n               \n                        [[ 0.1440]]],\n               \n               \n                       [[[-0.1130]],\n               \n                        [[ 0.0020]],\n               \n                        [[ 0.0927]],\n               \n                        ...,\n               \n                        [[-0.2364]],\n               \n                        [[ 0.2376]],\n               \n                        [[-0.0163]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0921]],\n               \n                        [[ 0.0300]],\n               \n                        [[ 0.0113]],\n               \n                        ...,\n               \n                        [[-0.0384]],\n               \n                        [[ 0.0414]],\n               \n                        [[-0.0945]]],\n               \n               \n                       [[[-0.0333]],\n               \n                        [[ 0.0488]],\n               \n                        [[-0.0011]],\n               \n                        ...,\n               \n                        [[-0.0405]],\n               \n                        [[ 0.0818]],\n               \n                        [[-0.2250]]],\n               \n               \n                       [[[-0.2092]],\n               \n                        [[ 0.2600]],\n               \n                        [[-0.0595]],\n               \n                        ...,\n               \n                        [[-0.0746]],\n               \n                        [[-0.1187]],\n               \n                        [[ 0.1222]]]])),\n              ('layer1.0.bn1.weight',\n               tensor([0.9974, 0.9254, 0.7893, 0.8638, 0.9034, 1.0236, 1.0102, 0.9884, 0.8885,\n                       0.9882, 0.8711, 1.0936, 1.0253, 1.0593, 1.1488, 1.0510, 0.9069, 0.8770,\n                       1.2689, 0.9931, 1.0092, 1.0116, 0.9747, 0.9479, 1.2032, 1.0281, 0.9216,\n                       0.9053, 0.8652, 0.9433, 0.8702, 0.9840, 0.8994, 0.9961, 0.8860, 0.9472,\n                       1.0447, 0.8415, 1.0868, 0.9172, 1.0137, 0.8470, 0.9178, 0.9738, 0.8192,\n                       0.9080, 0.8746, 1.1281, 0.9962, 0.9403, 0.9791, 0.9947, 0.8720, 0.9732,\n                       0.9712, 0.9567, 1.1085, 0.9441, 0.9427, 1.0570, 0.9782, 0.9122, 1.0065,\n                       0.8998])),\n              ('layer1.0.bn1.bias',\n               tensor([ 0.0442,  0.0276,  0.1272,  0.2088,  0.2730,  0.2185, -0.3439,  0.0253,\n                        0.2599, -0.2098,  0.1853, -0.2603, -0.0411,  0.0880, -0.1011, -0.1027,\n                       -0.0164,  0.0857, -0.4525,  0.0706,  0.0576,  0.1437,  0.4029,  0.1277,\n                       -0.5729,  0.0799,  0.0744,  0.2754,  0.0253,  0.2643,  0.0380, -0.0298,\n                        0.2346,  0.1446,  0.3168,  0.0913, -0.2886,  0.2474, -0.3303,  0.0822,\n                       -0.1723,  0.0059,  0.0205,  0.1720,  0.2643,  0.2070,  0.1778, -0.2158,\n                        0.2757, -0.1086, -0.0219, -0.0249,  0.3901, -0.0026,  0.4688,  0.1615,\n                       -0.1723,  0.0232,  0.1609, -0.0044, -0.0345,  0.1519, -0.0023,  0.2074])),\n              ('layer1.0.bn1.running_mean',\n               tensor([-0.4115, -0.5391, -1.0338, -0.6578, -0.1825, -0.2391, -0.2659, -2.1304,\n                        1.2379, -0.6359, -0.2571, -1.6311, -0.2645, -0.7809, -0.1282, -0.7265,\n                       -0.5130,  1.9629, -0.8690, -1.3059,  0.7061,  0.0355, -0.6224, -1.3627,\n                       -0.9470, -2.5844, -0.7188, -0.2397, -0.0506,  2.3526,  0.6200, -1.5888,\n                       -0.2250, -1.5494, -0.3562,  0.4151, -0.8454, -0.0534, -0.7135, -1.0542,\n                       -1.9133, -0.6455, -1.1464, -1.7436,  0.1840, -0.9725,  0.4476, -0.6087,\n                        0.7588, -0.2860, -1.4031, -1.9707,  0.0823, -0.8805,  4.1617, -0.3469,\n                       -2.0003, -1.4606, -0.3887, -0.7709, -0.9855, -1.7758, -1.3508, -0.5626])),\n              ('layer1.0.bn1.running_var',\n               tensor([1.0522, 1.0866, 0.9864, 0.7256, 1.1028, 0.7369, 1.3073, 1.3723, 1.3995,\n                       1.1115, 0.6830, 1.4364, 1.1990, 0.9057, 1.2008, 1.0543, 1.0055, 2.0257,\n                       1.4342, 0.9483, 1.7890, 1.1214, 0.9145, 1.0826, 1.3526, 1.7488, 1.0834,\n                       0.5211, 0.6443, 2.6065, 0.6629, 1.8474, 0.8458, 0.9413, 0.7906, 1.2831,\n                       0.9637, 1.1515, 1.2244, 0.5550, 2.0210, 0.7121, 0.6506, 1.8922, 0.7019,\n                       1.3895, 0.9327, 1.3761, 1.2647, 0.5606, 1.0044, 1.1253, 1.3220, 1.1447,\n                       2.2913, 0.8762, 1.9721, 0.7848, 1.1804, 0.9318, 0.9404, 1.0409, 1.2899,\n                       1.4830])),\n              ('layer1.0.bn1.num_batches_tracked', tensor(13572)),\n              ('layer1.0.conv2.weight',\n               tensor([[[[-6.8985e-02,  6.0525e-02,  4.2665e-02],\n                         [ 1.1267e-03,  1.6834e-02,  8.9273e-02],\n                         [ 9.3678e-02, -1.7385e-02, -3.0511e-02]],\n               \n                        [[-4.3926e-02,  3.7349e-03,  3.1802e-02],\n                         [-3.6462e-02,  2.2471e-02,  3.6111e-02],\n                         [-6.1035e-03, -5.1611e-02, -5.7321e-02]],\n               \n                        [[ 6.5360e-02,  9.2248e-03, -4.9294e-03],\n                         [ 1.7023e-02, -4.4859e-02, -1.7471e-02],\n                         [-1.3168e-02, -1.2969e-02,  8.8108e-03]],\n               \n                        ...,\n               \n                        [[-8.4368e-02,  6.3524e-02, -4.1309e-03],\n                         [ 1.0656e-01,  8.3941e-02,  3.4034e-02],\n                         [-2.9691e-03,  1.8798e-01,  8.7840e-02]],\n               \n                        [[ 1.1670e-02,  2.2962e-02, -5.2622e-03],\n                         [ 7.1297e-02, -5.5259e-02,  2.2508e-02],\n                         [-2.7976e-02, -1.9220e-02,  4.6576e-02]],\n               \n                        [[-8.7549e-02, -8.9710e-02, -8.5386e-02],\n                         [-5.4946e-02, -1.9309e-03, -7.5506e-02],\n                         [-4.5702e-04, -8.0812e-02, -5.7422e-02]]],\n               \n               \n                       [[[ 1.3653e-02,  8.5893e-02, -1.0546e-02],\n                         [-6.3350e-02,  6.1188e-02,  1.3896e-01],\n                         [-4.1004e-02,  7.4908e-02, -5.8110e-02]],\n               \n                        [[-5.0814e-03,  9.6992e-03, -1.0643e-02],\n                         [ 1.0489e-01,  1.3972e-02,  3.6944e-03],\n                         [-1.1575e-02,  1.2352e-01,  1.2715e-02]],\n               \n                        [[-2.4491e-02, -4.5555e-02,  3.9671e-02],\n                         [ 1.7964e-02,  5.5599e-02,  4.5546e-02],\n                         [-1.1647e-02,  6.9790e-02, -1.2168e-02]],\n               \n                        ...,\n               \n                        [[-2.3227e-02, -8.2797e-03,  6.0156e-02],\n                         [-6.1794e-02, -7.2372e-03, -6.5643e-02],\n                         [-5.8790e-02,  1.8587e-02, -8.2581e-02]],\n               \n                        [[ 3.2046e-02, -6.8821e-04, -1.9629e-02],\n                         [-3.1592e-02,  1.5593e-02,  4.5861e-03],\n                         [-6.4362e-02,  4.3045e-02,  9.3459e-02]],\n               \n                        [[-2.1123e-02,  3.8345e-02, -1.4451e-02],\n                         [ 2.4907e-02, -2.6294e-02, -6.3839e-02],\n                         [ 1.9465e-03,  1.8776e-02,  4.7586e-02]]],\n               \n               \n                       [[[ 1.4083e-02, -3.2184e-02,  5.0524e-02],\n                         [-3.6235e-02, -5.1812e-03,  8.9978e-03],\n                         [ 3.4249e-02,  1.6430e-02, -7.0788e-02]],\n               \n                        [[-5.4859e-02, -3.9116e-02, -6.1946e-02],\n                         [-7.7447e-02, -5.0125e-02, -2.6851e-02],\n                         [-2.7032e-02, -1.5036e-02, -4.3593e-02]],\n               \n                        [[ 6.5215e-02, -1.6538e-03, -9.6018e-03],\n                         [ 5.8783e-02,  5.1676e-02,  8.8859e-02],\n                         [ 4.4319e-02, -7.3405e-03,  1.0646e-03]],\n               \n                        ...,\n               \n                        [[ 2.0129e-02,  9.9641e-02,  5.7396e-02],\n                         [ 7.7510e-03,  3.2031e-04,  1.4886e-01],\n                         [-4.2682e-02,  4.6037e-02,  7.8062e-02]],\n               \n                        [[-6.1255e-02,  1.8302e-03, -1.0378e-02],\n                         [-3.2084e-02, -9.0398e-02, -2.1692e-02],\n                         [-2.2120e-02, -1.1105e-02, -3.9777e-04]],\n               \n                        [[ 1.5636e-02, -8.2772e-02,  3.0889e-02],\n                         [-2.7496e-02, -3.7462e-02, -5.0625e-02],\n                         [-2.1368e-02,  4.8106e-03, -6.9386e-03]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-1.8008e-02, -2.9003e-02, -9.3771e-02],\n                         [ 9.8595e-03,  5.9009e-02,  2.5965e-02],\n                         [-2.6635e-02,  9.4710e-02,  5.4834e-02]],\n               \n                        [[ 1.5571e-02,  4.0003e-03,  2.2403e-02],\n                         [ 6.7347e-02, -3.0990e-02, -6.7141e-02],\n                         [ 2.9593e-02, -4.7997e-02, -2.3853e-02]],\n               \n                        [[-5.2191e-02,  6.1289e-02, -7.4815e-03],\n                         [ 6.0693e-05,  5.8768e-02,  6.8937e-02],\n                         [ 3.9343e-02, -3.5784e-03, -3.8864e-02]],\n               \n                        ...,\n               \n                        [[ 9.9055e-02, -2.0947e-02, -3.2426e-02],\n                         [-6.3006e-03, -9.5709e-02,  4.9128e-02],\n                         [ 3.0588e-02,  3.3419e-02,  2.2620e-02]],\n               \n                        [[-3.1640e-02, -5.4183e-02,  4.4070e-02],\n                         [ 2.9839e-02, -5.4218e-02, -1.6681e-02],\n                         [ 5.9626e-02, -3.1374e-02, -4.5373e-02]],\n               \n                        [[ 2.1521e-02, -5.7802e-02, -1.7567e-02],\n                         [ 9.9431e-03,  5.0307e-02, -1.7494e-02],\n                         [ 2.8829e-02,  5.2508e-02, -8.2268e-02]]],\n               \n               \n                       [[[-6.9244e-02,  6.9929e-02, -1.2583e-02],\n                         [ 3.1900e-02,  3.4148e-02, -3.0557e-02],\n                         [-1.0882e-02,  5.6076e-02,  2.7812e-02]],\n               \n                        [[ 5.8430e-02,  5.1993e-02,  3.1899e-02],\n                         [-4.9248e-02, -6.1044e-02,  3.3651e-02],\n                         [ 5.1565e-02, -3.1715e-04,  3.0498e-02]],\n               \n                        [[-1.5327e-01, -6.3202e-02, -5.1203e-02],\n                         [-2.2543e-02,  2.6922e-02, -7.6930e-02],\n                         [-1.5567e-02, -4.4139e-02,  4.2291e-02]],\n               \n                        ...,\n               \n                        [[ 2.8223e-02, -6.5154e-03, -3.7528e-02],\n                         [ 6.0936e-03,  9.5283e-02, -5.3841e-03],\n                         [-1.9342e-02, -4.2805e-02,  4.5551e-02]],\n               \n                        [[-4.5758e-02, -8.0173e-02, -7.3527e-03],\n                         [-1.5349e-02,  1.1445e-02,  1.2460e-02],\n                         [ 5.6414e-02,  7.3240e-02,  6.5362e-04]],\n               \n                        [[ 2.2908e-02,  2.5413e-02,  5.0993e-02],\n                         [ 6.5693e-03,  9.5176e-04, -1.2886e-03],\n                         [ 8.7336e-03,  4.1149e-02,  7.8622e-02]]],\n               \n               \n                       [[[-2.3007e-02, -1.0607e-01, -7.3492e-02],\n                         [-6.2256e-02,  1.7043e-02,  3.0552e-02],\n                         [-8.2600e-02, -2.5777e-02, -1.6335e-02]],\n               \n                        [[ 2.7446e-02,  2.7121e-02, -7.3236e-02],\n                         [-5.4284e-02, -7.9651e-03, -4.2206e-02],\n                         [-2.8820e-02, -5.3331e-02, -1.2894e-02]],\n               \n                        [[ 2.4186e-02, -8.7668e-02, -5.1040e-02],\n                         [ 1.8015e-02,  1.7997e-02,  6.5816e-02],\n                         [-1.1975e-02,  4.0704e-02, -9.6848e-02]],\n               \n                        ...,\n               \n                        [[-8.7081e-03, -2.4150e-02,  4.0132e-02],\n                         [ 6.9258e-05,  7.1835e-03, -7.3516e-02],\n                         [-1.0407e-02,  2.1834e-02,  4.4193e-02]],\n               \n                        [[ 3.9616e-02, -2.4295e-02, -6.6894e-03],\n                         [ 2.3870e-02, -1.8274e-02,  8.6332e-03],\n                         [ 7.5868e-02, -1.2174e-02,  1.6488e-02]],\n               \n                        [[ 4.5521e-02,  1.5292e-01,  1.6849e-02],\n                         [-1.2726e-02,  7.4780e-02, -2.8069e-02],\n                         [ 1.3525e-02, -1.3020e-01, -3.4164e-02]]]])),\n              ('layer1.0.bn2.weight',\n               tensor([1.0329, 1.0469, 0.8829, 0.9530, 1.0379, 0.9802, 0.8514, 0.9426, 0.8548,\n                       0.9277, 1.0269, 1.0101, 1.0180, 0.9339, 1.1951, 0.9723, 1.0181, 1.0033,\n                       1.2251, 0.9413, 1.0029, 0.8753, 0.9404, 1.1305, 0.9255, 0.9394, 0.9229,\n                       0.9154, 1.0721, 0.9477, 1.0465, 1.0491, 0.8933, 0.8988, 1.0363, 1.0431,\n                       1.0401, 0.9643, 1.1134, 0.9740, 1.0297, 0.9828, 0.9494, 0.9926, 0.8803,\n                       1.1051, 1.0875, 0.9403, 0.8906, 0.9688, 0.9615, 0.9070, 0.8858, 0.9910,\n                       1.0534, 0.9616, 0.9809, 0.9348, 1.0920, 1.0004, 1.0204, 1.1065, 1.0077,\n                       1.0200])),\n              ('layer1.0.bn2.bias',\n               tensor([ 7.2480e-02, -1.6256e-01,  9.6667e-02, -8.0512e-02, -7.6179e-02,\n                        8.5832e-02,  1.5246e-01,  6.9069e-02,  1.4426e-02, -9.8412e-04,\n                       -3.4551e-02,  3.4018e-02,  1.2903e-02,  2.2159e-02,  2.8432e-01,\n                        4.7604e-01,  9.5317e-02,  5.0077e-02, -5.2066e-02,  3.0647e-02,\n                        2.0068e-01, -4.0782e-02,  4.9647e-02,  2.8910e-01,  4.8305e-02,\n                       -2.1699e-02, -4.9102e-02, -3.8622e-02, -1.2832e-01, -4.0796e-02,\n                        1.9722e-02,  2.3600e-01, -1.8230e-01,  4.3013e-02,  1.5555e-01,\n                        1.5034e-01,  7.6240e-02,  3.9277e-02,  1.5913e-01,  1.7603e-01,\n                       -2.7110e-01,  1.3282e-01,  3.0192e-01,  9.4528e-02,  1.8800e-01,\n                        1.8298e-01,  2.0632e-01,  9.5288e-02,  2.2175e-01, -6.0445e-02,\n                        2.0891e-01,  1.3733e-01, -9.1199e-02,  3.4583e-04,  2.3850e-01,\n                        7.7017e-02,  1.8530e-01,  2.8268e-01,  1.8180e-01,  5.3043e-02,\n                       -1.4034e-01, -6.3799e-02,  1.4902e-01,  3.1360e-01])),\n              ('layer1.0.bn2.running_mean',\n               tensor([-2.9218e-01,  7.9252e-01,  6.6384e-01, -1.1515e+00, -3.7150e-01,\n                       -5.7596e-01,  4.6701e-01, -9.0547e-01,  8.3171e-02, -3.7481e-01,\n                       -1.2598e+00, -1.5199e+00,  3.9170e-01, -4.8792e-01, -3.7939e-01,\n                       -1.2530e+00,  2.5057e-01, -1.3679e+00,  1.6435e-02,  7.9055e-01,\n                       -9.6309e-01, -4.5233e-01,  3.2027e-01, -1.3690e+00,  2.2201e-01,\n                       -2.2422e+00, -1.5613e-01,  5.0241e-01,  1.3743e-03,  3.3745e-01,\n                       -6.6553e-01, -4.4132e-01,  8.5559e-03, -5.3279e-01, -4.5253e-01,\n                       -2.2993e+00, -4.4983e-02,  1.5014e-01, -3.1101e-01, -7.9519e-01,\n                        1.1162e+00, -6.7140e-01, -9.1859e-01, -2.6132e-02, -3.1467e-01,\n                       -5.3073e-01, -8.2303e-01,  2.7039e-01, -1.4661e-01,  1.0024e-01,\n                        4.4082e-01, -1.6329e-01, -2.3893e-01, -8.4448e-01,  1.5639e-01,\n                       -2.3044e-01, -6.8413e-02, -1.2252e-01, -7.4310e-01, -5.4070e-01,\n                        2.7482e-02, -1.1938e+00,  9.6198e-01, -2.9175e-02])),\n              ('layer1.0.bn2.running_var',\n               tensor([0.8770, 0.9124, 0.8689, 0.6580, 0.6453, 0.6412, 0.8069, 0.5850, 0.5509,\n                       0.5021, 1.4285, 0.9635, 1.0128, 0.9590, 1.2972, 1.4919, 0.7395, 0.9674,\n                       1.7152, 1.2440, 0.8697, 0.7772, 0.5702, 1.8467, 0.7488, 1.4802, 0.5476,\n                       0.7639, 1.3277, 0.6157, 0.8558, 0.9993, 0.9068, 0.7653, 0.9843, 1.1178,\n                       0.9585, 0.5605, 1.2060, 0.9718, 0.8255, 2.8168, 1.2622, 1.0261, 0.9532,\n                       0.7728, 0.7948, 0.5990, 0.5371, 0.9161, 0.7288, 1.1060, 0.9796, 0.9844,\n                       0.8125, 0.8637, 0.7194, 0.5910, 0.5288, 0.8071, 0.5347, 0.4653, 0.8727,\n                       0.6960])),\n              ('layer1.0.bn2.num_batches_tracked', tensor(13572)),\n              ('layer1.0.conv3.weight',\n               tensor([[[[ 0.0657]],\n               \n                        [[-0.0597]],\n               \n                        [[-0.0107]],\n               \n                        ...,\n               \n                        [[ 0.0175]],\n               \n                        [[-0.0101]],\n               \n                        [[-0.0414]]],\n               \n               \n                       [[[-0.0289]],\n               \n                        [[ 0.0626]],\n               \n                        [[ 0.0656]],\n               \n                        ...,\n               \n                        [[ 0.0356]],\n               \n                        [[ 0.0808]],\n               \n                        [[-0.1045]]],\n               \n               \n                       [[[ 0.1031]],\n               \n                        [[ 0.0416]],\n               \n                        [[ 0.0158]],\n               \n                        ...,\n               \n                        [[-0.0263]],\n               \n                        [[-0.0461]],\n               \n                        [[-0.0540]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.1138]],\n               \n                        [[-0.0380]],\n               \n                        [[-0.0239]],\n               \n                        ...,\n               \n                        [[-0.0841]],\n               \n                        [[-0.0306]],\n               \n                        [[-0.0229]]],\n               \n               \n                       [[[ 0.0978]],\n               \n                        [[-0.0892]],\n               \n                        [[ 0.0149]],\n               \n                        ...,\n               \n                        [[ 0.0493]],\n               \n                        [[ 0.0177]],\n               \n                        [[-0.0843]]],\n               \n               \n                       [[[ 0.0620]],\n               \n                        [[-0.0475]],\n               \n                        [[ 0.0463]],\n               \n                        ...,\n               \n                        [[-0.0163]],\n               \n                        [[-0.0534]],\n               \n                        [[-0.0166]]]])),\n              ('layer1.0.bn3.weight',\n               tensor([-0.1684,  0.4139,  0.1582, -0.1951,  0.2781, -0.2103,  0.0976, -0.1319,\n                       -0.1349, -0.2679, -0.2363,  0.3653,  0.2495,  0.2544,  0.1665,  0.3129,\n                        0.2380,  0.0814, -0.0650, -0.0013,  0.3433, -0.3925, -0.3038,  0.0835,\n                       -0.1791,  0.2376, -0.1756, -0.0317,  0.1797, -0.1270, -0.2473,  0.2256,\n                        0.3745,  0.2170,  0.2198, -0.2765,  0.2332, -0.2787,  0.3725, -0.3021,\n                       -0.1839, -0.2587, -0.0598,  0.2777,  0.1096,  0.3984,  0.2177,  0.2287,\n                       -0.2401, -0.2277,  0.2307, -0.3077,  0.1971,  0.2106, -0.4287,  0.3490,\n                       -0.3912,  0.2945, -0.0518, -0.2523,  0.4815, -0.0910, -0.3084, -0.3891,\n                        0.0845,  0.2695, -0.1767, -0.2251,  0.0866,  0.3684, -0.1500, -0.2644,\n                       -0.2193, -0.2716,  0.1035,  0.2306,  0.2070, -0.2225, -0.2605, -0.1145,\n                       -0.1679, -0.3680,  0.2073, -0.1849, -0.1955,  0.1141, -0.2463, -0.1292,\n                       -0.1366, -0.3309,  0.0194,  0.3610, -0.1953,  0.2770, -0.1633, -0.2469,\n                       -0.1190, -0.3031, -0.1725,  0.3364,  0.3411,  0.1460,  0.2897, -0.2982,\n                       -0.1901,  0.1707,  0.1776, -0.1505, -0.2356, -0.0308,  0.0813, -0.3026,\n                        0.1621, -0.1439,  0.1109,  0.0878, -0.0353, -0.2544,  0.2981,  0.2211,\n                       -0.2838, -0.1161, -0.0896, -0.3476,  0.1701,  0.1375,  0.1696,  0.1183,\n                        0.2966,  0.1149,  0.1745,  0.1874, -0.2839,  0.3534,  0.2206, -0.2362,\n                       -0.0444, -0.2295,  0.2335, -0.1637,  0.1684, -0.3976,  0.0151, -0.2338,\n                       -0.1459, -0.4047,  0.2276, -0.3187, -0.2635,  0.3358,  0.0518,  0.0045,\n                       -0.1110,  0.2609,  0.2216, -0.2741,  0.3870,  0.2233, -0.2301,  0.2093,\n                       -0.2805,  0.4134, -0.2706,  0.2427,  0.2897,  0.1719,  0.1209,  0.0067,\n                        0.3831,  0.2316, -0.3159,  0.1163, -0.3455,  0.3901,  0.4556,  0.2308,\n                        0.3028, -0.4014, -0.2733, -0.1742, -0.0950, -0.3163,  0.2893, -0.2414,\n                       -0.2344,  0.2775,  0.3239,  0.1882,  0.2729, -0.3050,  0.1372, -0.1183,\n                        0.3111,  0.3381,  0.3881, -0.2534, -0.2446, -0.1858, -0.2896,  0.1047,\n                        0.2246, -0.2186,  0.3546, -0.0739,  0.4051,  0.2545,  0.2527, -0.2609,\n                       -0.3216, -0.3609, -0.3594,  0.2059,  0.2241,  0.2834,  0.3013,  0.2456,\n                        0.2841,  0.4578, -0.0881, -0.3844, -0.2039,  0.2015,  0.1883,  0.3175,\n                       -0.2242,  0.2833, -0.3124,  0.1397,  0.2009, -0.2750, -0.3616, -0.2309,\n                        0.3747,  0.0465, -0.2951, -0.0013,  0.2775, -0.1677,  0.2867, -0.0784,\n                       -0.3409,  0.0789,  0.4784,  0.3074,  0.4023, -0.2951,  0.2832,  0.1991,\n                        0.2868,  0.2734, -0.2915, -0.2354, -0.1857,  0.3529,  0.0273,  0.1527])),\n              ('layer1.0.bn3.bias',\n               tensor([-0.0547,  0.2247, -0.0820,  0.0247,  0.0599, -0.0888, -0.0738, -0.2598,\n                       -0.0714, -0.1786,  0.1100,  0.0315,  0.0145, -0.0913, -0.0803,  0.1462,\n                        0.0873, -0.3055, -0.0958, -0.1034,  0.1234,  0.0695,  0.0283,  0.1093,\n                       -0.1198, -0.0033, -0.2116, -0.0707,  0.0021,  0.0146,  0.1284, -0.0758,\n                        0.1364, -0.0808,  0.0865, -0.1145,  0.1002,  0.1150,  0.2115,  0.0708,\n                       -0.0680,  0.0219, -0.0579, -0.0983, -0.0878,  0.1308, -0.0308, -0.3151,\n                       -0.0258,  0.0157, -0.0797,  0.2186, -0.1656,  0.0153,  0.0126,  0.1677,\n                        0.3054, -0.0606,  0.0616,  0.0213,  0.0670,  0.1235,  0.2240,  0.2040,\n                       -0.0176, -0.0117,  0.2288, -0.0114, -0.0847,  0.0877, -0.0620,  0.1022,\n                       -0.0627, -0.1276, -0.0525,  0.0788, -0.1611,  0.0302,  0.0893,  0.0401,\n                        0.0975, -0.0193,  0.0618, -0.0784, -0.0694, -0.0673, -0.2077, -0.0148,\n                       -0.0920,  0.0793, -0.0105,  0.0383, -0.0532,  0.0410,  0.0269, -0.0788,\n                       -0.1788,  0.1456, -0.0491, -0.0068,  0.0597,  0.0375, -0.0176,  0.1282,\n                       -0.0679, -0.1404,  0.1015,  0.1312, -0.0956,  0.0322,  0.2176,  0.1287,\n                       -0.1884,  0.0380,  0.0387,  0.0091,  0.1108,  0.0862, -0.1421,  0.0819,\n                        0.1175, -0.0257,  0.0242,  0.2372, -0.0772, -0.0173, -0.0642,  0.0553,\n                        0.2233, -0.0673, -0.2099,  0.2682, -0.0036,  0.0060,  0.1665,  0.0967,\n                       -0.0416, -0.0078, -0.1970, -0.0175,  0.0618,  0.2020,  0.0637,  0.0053,\n                        0.0095,  0.2210, -0.1298,  0.1118,  0.0517,  0.2656, -0.0708, -0.2395,\n                       -0.0779,  0.0509,  0.1857,  0.0766,  0.2029, -0.1773,  0.0063,  0.0366,\n                        0.1206,  0.1605, -0.0016,  0.0246, -0.0524,  0.0030, -0.1466, -0.2174,\n                        0.3603,  0.1058,  0.0744, -0.0453,  0.1013,  0.0996,  0.1398,  0.0351,\n                        0.1038,  0.0956, -0.0083, -0.0295,  0.1695, -0.0384, -0.0132, -0.0841,\n                        0.0636, -0.0892,  0.0018, -0.0005,  0.1461, -0.0919, -0.1403,  0.1352,\n                        0.1529,  0.0220,  0.0754, -0.0366, -0.0582, -0.0550,  0.0692,  0.0344,\n                       -0.1387, -0.0745,  0.0881, -0.0046,  0.0558, -0.1127,  0.1501, -0.0012,\n                        0.1278,  0.2281,  0.0278, -0.1291,  0.0068, -0.0580, -0.0214, -0.0174,\n                        0.0675,  0.0908, -0.2050,  0.1360,  0.0275, -0.0135, -0.0509,  0.0590,\n                        0.1072, -0.0065,  0.1286, -0.0063, -0.0394,  0.0874,  0.0321,  0.0062,\n                       -0.1131,  0.0454, -0.0245,  0.0892,  0.1382, -0.0177, -0.0122, -0.2008,\n                       -0.0824, -0.1471,  0.0204,  0.0886,  0.3063, -0.0487,  0.0791, -0.3038,\n                        0.0335,  0.1381,  0.0635, -0.0258,  0.0327,  0.2151, -0.0067, -0.0015])),\n              ('layer1.0.bn3.running_mean',\n               tensor([-0.1225, -0.1606, -0.2430, -0.0530, -0.1708,  0.2533,  0.0173, -0.2540,\n                       -0.2053, -0.0204, -0.0137, -0.0306, -0.1856,  0.2896, -0.0491,  0.2220,\n                       -0.4830,  0.2717,  0.0321,  0.1346, -0.1703, -0.4044,  0.2247, -0.1694,\n                       -0.1828, -0.1972, -0.4573,  0.1028,  0.1749, -0.1436,  0.3125, -0.1889,\n                        0.0023, -0.0066, -0.0190,  0.0158,  0.2838,  0.0476,  0.0469, -0.0355,\n                       -0.0476, -0.4227, -0.1375,  0.1648, -0.2196,  0.6846, -0.1619, -0.2264,\n                        0.0925, -0.1499, -0.1473,  0.1765, -0.0750,  0.3188, -0.4351,  0.2670,\n                       -0.1198,  0.1403,  0.1120,  0.2646,  0.4531, -0.5429,  0.0262, -0.3762,\n                        0.0326, -0.5829,  0.0245,  0.0909, -0.0084,  0.2189, -0.1263,  0.0924,\n                       -0.2618, -0.1857, -0.2291,  0.5123, -0.1071, -0.1311, -0.3217, -0.5085,\n                       -0.2870, -0.0188, -0.0769,  0.0359,  0.0582, -0.0307, -0.0138,  0.3037,\n                        0.3078, -0.2810,  0.2515, -0.0591,  0.3185, -0.1262, -0.4117,  0.0853,\n                       -0.0958,  0.0429, -0.2666,  0.3329,  0.5947,  0.1180,  0.1012,  0.5028,\n                       -0.2721, -0.1238,  0.0025, -0.3013,  0.3009,  0.0318, -0.0747, -0.2404,\n                       -0.1137, -0.2803, -0.2238, -0.1497,  0.3415, -0.2639,  0.1708, -0.1061,\n                       -0.2892, -0.2309, -0.2229,  0.0161,  0.5311, -0.6257, -0.1697,  0.0152,\n                        0.0032, -0.2044,  0.0873, -0.4244, -0.0970, -0.0246, -0.2355,  0.2600,\n                        0.1183,  0.3333, -0.1053,  0.3322, -0.1309, -0.4140,  0.1947,  0.0315,\n                        0.0701,  0.3814, -0.2098, -0.0027, -0.0136,  0.0751,  0.0683,  0.0368,\n                        0.0667,  0.0117,  0.2347, -0.0114, -0.2099,  0.2948, -0.0256,  0.0308,\n                       -0.1155, -0.2458, -0.4028, -0.1511,  0.1630, -0.0626,  0.1946, -0.0220,\n                        0.1816, -0.2443,  0.1646,  0.0208, -0.0542, -0.0782, -0.0343,  0.2286,\n                       -0.2792, -0.1485,  0.2472, -0.6058, -0.1656, -0.4602,  0.4186, -0.2756,\n                       -0.1347,  0.3685, -0.3839,  0.1377, -0.2265,  0.1140, -0.2082, -0.5983,\n                        0.2332, -0.1088,  0.2566, -0.0783, -0.3619, -0.1080,  0.2114,  0.0482,\n                        0.1789,  0.2008, -0.2118,  0.5016,  0.1197,  0.1968,  0.0746,  0.3102,\n                        0.1684,  0.3414, -0.4595, -0.1683,  0.4729, -0.1034, -0.3408,  0.2932,\n                        0.1038, -0.7503, -0.1485, -0.6562, -0.1156, -0.1109, -0.1978,  0.2140,\n                       -0.1383,  0.0415,  0.2378,  0.2435,  0.0081, -0.1092, -0.2945,  0.4043,\n                       -0.3072, -0.0323,  0.1467, -0.2128,  0.0550, -0.0328,  0.3483, -0.2663,\n                       -0.2671,  0.2463,  0.0883,  0.0946, -0.2136,  0.1179,  0.0727, -0.2378,\n                        0.1549,  0.0030, -0.1112, -0.4096, -0.5624, -0.1398, -0.2813, -0.1216])),\n              ('layer1.0.bn3.running_var',\n               tensor([0.1532, 0.2183, 0.1130, 0.1776, 0.1190, 0.1300, 0.0827, 0.2390, 0.1002,\n                       0.2344, 0.2230, 0.1706, 0.1652, 0.2597, 0.1479, 0.2770, 0.1726, 0.0946,\n                       0.1328, 0.0587, 0.1908, 0.1849, 0.1930, 0.1069, 0.1692, 0.0888, 0.1890,\n                       0.0609, 0.2615, 0.0906, 0.1590, 0.2387, 0.3693, 0.1719, 0.2414, 0.2140,\n                       0.1513, 0.2481, 0.1945, 0.2387, 0.0629, 0.2849, 0.0688, 0.1411, 0.0832,\n                       0.3129, 0.1990, 0.1628, 0.2045, 0.1917, 0.1075, 0.2263, 0.0905, 0.2931,\n                       0.2191, 0.2627, 0.3428, 0.1122, 0.0947, 0.1401, 0.4049, 0.1551, 0.2775,\n                       0.2884, 0.1249, 0.1908, 0.1499, 0.1504, 0.0492, 0.1988, 0.1436, 0.2543,\n                       0.1490, 0.1805, 0.0811, 0.2009, 0.2263, 0.2133, 0.2023, 0.1181, 0.1195,\n                       0.1482, 0.1190, 0.2131, 0.0967, 0.1083, 0.2654, 0.1016, 0.1107, 0.2567,\n                       0.0665, 0.3971, 0.1330, 0.1837, 0.1876, 0.1453, 0.1274, 0.1886, 0.1688,\n                       0.1727, 0.3101, 0.1256, 0.2159, 0.1837, 0.1717, 0.1384, 0.2598, 0.1187,\n                       0.1705, 0.0657, 0.1067, 0.3461, 0.1350, 0.1498, 0.1357, 0.0730, 0.0521,\n                       0.1625, 0.2228, 0.1217, 0.1463, 0.1202, 0.1470, 0.2079, 0.1234, 0.1663,\n                       0.0970, 0.1205, 0.3366, 0.1448, 0.1688, 0.1629, 0.0987, 0.2092, 0.1816,\n                       0.1530, 0.0677, 0.1771, 0.2774, 0.1518, 0.1848, 0.5678, 0.0655, 0.2312,\n                       0.0687, 0.3200, 0.1909, 0.2905, 0.1695, 0.3942, 0.0686, 0.0781, 0.1439,\n                       0.1526, 0.1978, 0.1970, 0.3458, 0.2527, 0.1110, 0.0865, 0.2827, 0.2599,\n                       0.2099, 0.1787, 0.1384, 0.2006, 0.0843, 0.0479, 0.4096, 0.1735, 0.1489,\n                       0.0706, 0.3105, 0.3307, 0.2867, 0.1757, 0.1767, 0.2899, 0.1270, 0.1116,\n                       0.1290, 0.3068, 0.2504, 0.2899, 0.2585, 0.1416, 0.1542, 0.1789, 0.3369,\n                       0.1414, 0.0994, 0.1401, 0.2596, 0.1760, 0.2930, 0.3349, 0.1692, 0.1684,\n                       0.2383, 0.0924, 0.1635, 0.1594, 0.4465, 0.1008, 0.2470, 0.1837, 0.1307,\n                       0.2261, 0.2019, 0.3308, 0.2368, 0.1315, 0.1488, 0.1674, 0.1601, 0.2983,\n                       0.1454, 0.2093, 0.0881, 0.2097, 0.0952, 0.2390, 0.2025, 0.1520, 0.1413,\n                       0.1665, 0.2231, 0.1035, 0.2418, 0.2073, 0.3534, 0.1844, 0.1551, 0.0601,\n                       0.3239, 0.0484, 0.1560, 0.1010, 0.1676, 0.0651, 0.2689, 0.0718, 0.3160,\n                       0.2136, 0.4115, 0.1267, 0.3049, 0.2711, 0.1317, 0.1865, 0.1295, 0.1985,\n                       0.1919, 0.2155, 0.0833, 0.1806])),\n              ('layer1.0.bn3.num_batches_tracked', tensor(13572)),\n              ('layer1.0.downsample.0.weight',\n               tensor([[[[-0.0033]],\n               \n                        [[-0.0229]],\n               \n                        [[ 0.0051]],\n               \n                        ...,\n               \n                        [[ 0.0651]],\n               \n                        [[-0.0425]],\n               \n                        [[ 0.0121]]],\n               \n               \n                       [[[-0.1060]],\n               \n                        [[ 0.0593]],\n               \n                        [[ 0.1445]],\n               \n                        ...,\n               \n                        [[-0.0503]],\n               \n                        [[ 0.1044]],\n               \n                        [[ 0.0393]]],\n               \n               \n                       [[[-0.0760]],\n               \n                        [[-0.1774]],\n               \n                        [[ 0.1093]],\n               \n                        ...,\n               \n                        [[-0.0216]],\n               \n                        [[ 0.0603]],\n               \n                        [[-0.1320]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0288]],\n               \n                        [[ 0.0019]],\n               \n                        [[ 0.0161]],\n               \n                        ...,\n               \n                        [[ 0.0208]],\n               \n                        [[-0.0380]],\n               \n                        [[ 0.1156]]],\n               \n               \n                       [[[ 0.1093]],\n               \n                        [[-0.0949]],\n               \n                        [[ 0.0972]],\n               \n                        ...,\n               \n                        [[-0.0673]],\n               \n                        [[-0.1088]],\n               \n                        [[ 0.0140]]],\n               \n               \n                       [[[ 0.0281]],\n               \n                        [[-0.0661]],\n               \n                        [[ 0.0638]],\n               \n                        ...,\n               \n                        [[-0.0726]],\n               \n                        [[ 0.0579]],\n               \n                        [[ 0.0005]]]])),\n              ('layer1.0.downsample.1.weight',\n               tensor([0.7832, 0.7788, 0.7557, 0.9886, 0.6976, 0.9329, 0.8660, 1.0146, 0.8373,\n                       1.0806, 0.7644, 0.7562, 0.8455, 0.9254, 0.9673, 0.9087, 0.8435, 0.9813,\n                       0.9555, 0.9627, 0.8253, 0.7415, 0.8591, 0.8194, 0.8834, 0.7725, 1.0352,\n                       0.9172, 0.8404, 0.9274, 0.7567, 1.1062, 0.8386, 1.1274, 0.8043, 0.9839,\n                       0.8247, 0.7873, 0.9054, 0.8674, 0.7862, 0.8877, 0.9218, 0.8200, 1.2058,\n                       0.7641, 0.8195, 1.0920, 0.8466, 0.9644, 0.9910, 0.7906, 1.0122, 0.9802,\n                       0.7933, 0.9242, 0.7080, 0.8181, 0.9649, 0.7728, 0.8852, 0.7999, 0.8998,\n                       0.7497, 0.9661, 0.7994, 0.7840, 0.7172, 0.8563, 0.8421, 1.0862, 0.7959,\n                       0.9610, 0.8327, 0.8627, 0.9182, 0.9477, 0.8440, 0.8402, 0.8138, 0.8189,\n                       0.7438, 0.8295, 1.1050, 0.8864, 0.8310, 1.0188, 0.8999, 0.8309, 0.8987,\n                       0.8351, 1.0212, 0.8164, 0.8817, 0.8048, 0.8748, 0.8554, 0.7655, 1.0256,\n                       0.8389, 0.9981, 0.9792, 0.9535, 0.8641, 0.9236, 0.9739, 0.7938, 0.7819,\n                       0.8453, 0.9010, 1.0742, 0.8692, 1.0875, 0.8210, 0.6843, 0.7106, 0.8713,\n                       0.8277, 0.8891, 0.8491, 0.8921, 0.9186, 1.0245, 0.8094, 0.8335, 0.9987,\n                       0.8662, 0.8235, 0.7027, 0.9013, 1.0816, 0.8261, 0.7742, 0.9369, 0.8668,\n                       0.8943, 0.7325, 0.9795, 1.0758, 0.8388, 1.0146, 0.8694, 0.9375, 0.8657,\n                       0.8152, 0.8743, 0.9985, 0.8534, 0.8515, 0.8098, 0.7988, 1.0607, 0.9996,\n                       0.8239, 0.8360, 0.8145, 0.8792, 0.9485, 0.7687, 0.7860, 0.7727, 0.9179,\n                       0.8812, 0.8567, 0.8131, 0.9167, 0.8940, 1.0278, 0.7296, 0.9649, 0.7462,\n                       0.8231, 0.9107, 0.9292, 0.7489, 0.9244, 0.8642, 0.8804, 0.8794, 0.8680,\n                       0.9298, 0.9345, 0.8970, 0.9695, 0.8873, 0.8174, 0.8271, 0.8148, 0.9797,\n                       0.7507, 0.8344, 0.8818, 0.8741, 0.7672, 0.8270, 0.9005, 0.7947, 0.7921,\n                       0.9620, 0.7959, 0.9193, 0.8672, 0.9343, 0.8633, 0.8743, 0.8402, 0.8543,\n                       0.8129, 0.9008, 0.8159, 0.9535, 0.9850, 0.8995, 0.9310, 0.8636, 0.8614,\n                       0.8685, 0.8181, 0.9300, 0.9256, 0.7199, 0.8896, 0.9069, 0.8977, 0.7720,\n                       0.9811, 0.8260, 0.8934, 0.8254, 0.8178, 0.9977, 0.9908, 0.9686, 0.9153,\n                       0.8226, 0.8537, 0.8381, 0.8775, 0.7798, 0.8544, 1.0653, 0.7491, 0.9076,\n                       0.9270, 0.9268, 0.7860, 0.9145, 1.1081, 0.7406, 0.8221, 0.7840, 0.9844,\n                       0.9622, 0.7855, 1.0191, 0.8889])),\n              ('layer1.0.downsample.1.bias',\n               tensor([-0.0547,  0.2247, -0.0820,  0.0247,  0.0599, -0.0888, -0.0738, -0.2598,\n                       -0.0714, -0.1786,  0.1100,  0.0315,  0.0145, -0.0913, -0.0803,  0.1462,\n                        0.0873, -0.3055, -0.0958, -0.1034,  0.1234,  0.0695,  0.0283,  0.1093,\n                       -0.1198, -0.0033, -0.2116, -0.0707,  0.0021,  0.0146,  0.1284, -0.0758,\n                        0.1364, -0.0808,  0.0865, -0.1145,  0.1002,  0.1150,  0.2115,  0.0708,\n                       -0.0680,  0.0219, -0.0579, -0.0983, -0.0878,  0.1308, -0.0308, -0.3151,\n                       -0.0258,  0.0157, -0.0797,  0.2186, -0.1656,  0.0153,  0.0126,  0.1677,\n                        0.3054, -0.0606,  0.0616,  0.0213,  0.0670,  0.1235,  0.2240,  0.2040,\n                       -0.0176, -0.0117,  0.2288, -0.0114, -0.0847,  0.0877, -0.0620,  0.1022,\n                       -0.0627, -0.1276, -0.0525,  0.0788, -0.1611,  0.0302,  0.0893,  0.0401,\n                        0.0975, -0.0193,  0.0618, -0.0784, -0.0694, -0.0673, -0.2077, -0.0148,\n                       -0.0920,  0.0793, -0.0105,  0.0383, -0.0532,  0.0410,  0.0269, -0.0788,\n                       -0.1788,  0.1456, -0.0491, -0.0068,  0.0597,  0.0375, -0.0176,  0.1282,\n                       -0.0679, -0.1404,  0.1015,  0.1312, -0.0956,  0.0322,  0.2176,  0.1287,\n                       -0.1884,  0.0380,  0.0387,  0.0091,  0.1108,  0.0862, -0.1421,  0.0819,\n                        0.1175, -0.0257,  0.0242,  0.2372, -0.0772, -0.0173, -0.0642,  0.0553,\n                        0.2233, -0.0673, -0.2099,  0.2682, -0.0036,  0.0060,  0.1665,  0.0967,\n                       -0.0416, -0.0078, -0.1970, -0.0175,  0.0618,  0.2020,  0.0637,  0.0053,\n                        0.0095,  0.2210, -0.1298,  0.1118,  0.0517,  0.2656, -0.0708, -0.2395,\n                       -0.0779,  0.0509,  0.1857,  0.0766,  0.2029, -0.1773,  0.0063,  0.0366,\n                        0.1206,  0.1605, -0.0016,  0.0246, -0.0524,  0.0030, -0.1466, -0.2174,\n                        0.3603,  0.1058,  0.0744, -0.0453,  0.1013,  0.0996,  0.1398,  0.0351,\n                        0.1038,  0.0956, -0.0083, -0.0295,  0.1695, -0.0384, -0.0132, -0.0841,\n                        0.0636, -0.0892,  0.0018, -0.0005,  0.1461, -0.0919, -0.1403,  0.1352,\n                        0.1529,  0.0220,  0.0754, -0.0366, -0.0582, -0.0550,  0.0692,  0.0344,\n                       -0.1387, -0.0745,  0.0881, -0.0046,  0.0558, -0.1127,  0.1501, -0.0012,\n                        0.1278,  0.2281,  0.0278, -0.1291,  0.0068, -0.0580, -0.0214, -0.0174,\n                        0.0675,  0.0908, -0.2050,  0.1360,  0.0275, -0.0135, -0.0509,  0.0590,\n                        0.1072, -0.0065,  0.1286, -0.0063, -0.0394,  0.0874,  0.0321,  0.0062,\n                       -0.1131,  0.0454, -0.0245,  0.0892,  0.1382, -0.0177, -0.0122, -0.2008,\n                       -0.0824, -0.1471,  0.0204,  0.0886,  0.3063, -0.0487,  0.0791, -0.3038,\n                        0.0335,  0.1381,  0.0635, -0.0258,  0.0327,  0.2151, -0.0067, -0.0015])),\n              ('layer1.0.downsample.1.running_mean',\n               tensor([-0.5959, -0.0458, -0.0843, -0.8052,  0.9888, -1.1036, -1.5632, -0.9838,\n                       -0.3226, -1.0848, -1.2207, -0.1492, -0.0594, -1.2540, -0.5904, -0.5613,\n                       -0.3485, -0.7262, -0.3934, -1.0863, -0.1630,  0.6928, -1.2603, -0.3707,\n                       -0.6924, -0.1006, -0.9511, -0.6629, -0.8275,  0.2021, -0.3839, -0.5254,\n                       -0.3940, -0.8928,  0.2103, -0.7089,  0.4878,  0.6921, -0.1572, -0.3110,\n                        0.2259, -0.9065, -0.0730, -0.7798, -0.3682,  0.3096, -0.6186, -0.6346,\n                       -0.8042, -1.1423, -0.4096,  0.9593, -0.4302, -0.8323,  0.2502, -0.4159,\n                        0.2434, -0.7191, -0.5016,  1.1636, -2.4317,  1.2274,  0.5094, -0.6403,\n                       -0.6606,  0.7503,  0.2067,  0.2597, -0.7712,  0.0262, -0.8341, -0.0940,\n                       -0.6682, -0.2977, -0.3099,  0.2333, -0.8042,  0.0604, -0.9037, -0.7049,\n                        2.0876,  0.6780,  1.3340, -0.3191, -0.5459, -1.0830, -0.4610, -0.6551,\n                       -0.5365, -0.8828, -0.5116, -0.3578, -1.1899, -0.8461, -0.4522,  1.4609,\n                       -0.5975,  1.7270, -0.4658, -0.7562, -0.7958, -0.3351, -1.4799,  0.5509,\n                       -0.5775, -0.6837, -0.1848, -0.2510, -0.5651, -0.7063, -0.7673,  0.0531,\n                       -0.9997, -0.2707, -0.2393, -0.1475,  0.6660, -0.4300, -0.8805,  0.0187,\n                       -0.0777,  0.0431, -0.3573,  0.8587, -0.8925, -0.1973, -0.3329, -0.7708,\n                        0.0332, -0.9693, -0.6496,  0.5798,  0.7467, -1.4600,  0.2434, -0.3976,\n                       -0.2802, -0.4779, -0.3843, -0.7965, -0.0218, -0.5248, -1.5318, -1.2173,\n                       -0.8204,  0.6485, -0.8418, -0.3935,  1.7661, -0.6638,  0.6059, -0.3404,\n                       -0.6804, -0.9711,  0.4092, -0.3342, -0.2698, -0.5801, -0.1796, -0.0517,\n                       -0.2119,  1.2212, -1.3859, -0.3401, -0.8558, -1.5610, -1.4978, -0.5191,\n                        0.0393, -0.9405,  0.0851,  0.5580, -0.9432, -0.5225,  1.1866, -0.9520,\n                       -0.0170, -0.3714, -0.6121, -0.6807,  0.9074, -0.7822, -0.7843, -0.9261,\n                       -1.1614, -0.4608,  0.5630,  0.0310, -0.4659, -0.0883, -0.9705, -0.3377,\n                       -1.4282, -0.1325, -1.3896, -0.9538, -0.0097, -1.6262, -0.6182, -0.5028,\n                       -0.6930, -0.7777, -1.2500, -0.9408, -0.7042, -1.4803, -0.0141, -0.5397,\n                       -1.0213,  1.1751, -1.4994, -0.4887, -1.8570, -0.7560,  0.5900, -0.7961,\n                       -1.1075,  0.3895, -1.1535,  0.6732,  0.5580, -0.8234, -0.5817, -1.1770,\n                        0.0676, -0.7120,  1.3233, -1.2472, -1.0423, -0.3008, -0.0746,  0.6936,\n                        0.4653, -0.5264,  1.3501,  0.6976,  1.7546, -1.3448, -0.3845,  0.4809,\n                       -1.6682,  0.2013,  0.3683, -0.2698,  2.5947, -0.5998, -0.5833, -0.8799,\n                        1.5040,  0.4684, -0.6553, -0.5200,  0.1312,  0.9638, -1.4571, -0.2235])),\n              ('layer1.0.downsample.1.running_var',\n               tensor([0.3705, 0.3600, 0.7417, 0.8622, 0.2317, 0.7320, 0.6395, 0.7274, 0.3807,\n                       1.1325, 0.6524, 0.5230, 0.4903, 0.7088, 0.5759, 0.4982, 0.2884, 0.6959,\n                       0.2464, 0.8769, 0.3815, 0.4798, 0.6603, 0.2387, 0.4751, 0.3288, 0.8329,\n                       0.4429, 0.4076, 0.6256, 0.6828, 0.5195, 0.2694, 0.6730, 0.4324, 0.5951,\n                       1.1139, 0.7993, 0.4583, 0.8359, 0.6452, 0.8111, 0.2404, 0.3245, 0.4241,\n                       0.8096, 0.3704, 0.4554, 0.3977, 0.5737, 0.4435, 0.4567, 0.4042, 0.6382,\n                       0.7237, 0.7285, 0.6105, 0.4753, 0.3963, 0.6518, 1.2663, 0.8668, 1.2692,\n                       0.3176, 0.6889, 0.6749, 0.4885, 0.6013, 0.6534, 0.4602, 0.4150, 0.5365,\n                       0.9267, 0.6404, 0.2893, 0.6274, 0.6649, 0.5051, 0.5845, 0.4923, 0.7593,\n                       0.5242, 0.5713, 0.3388, 0.5121, 0.6949, 0.5054, 0.2515, 0.3990, 0.7269,\n                       0.3619, 0.5827, 0.5072, 0.6290, 0.6880, 1.0537, 0.6005, 0.5901, 0.4072,\n                       0.3906, 0.7464, 0.5397, 0.9605, 0.3534, 0.4446, 0.4245, 0.6673, 0.5851,\n                       0.2887, 0.4769, 0.5369, 0.6281, 0.8182, 0.2507, 0.1385, 0.3188, 0.7481,\n                       0.3916, 0.8898, 0.3965, 0.2296, 0.9770, 0.4852, 0.6172, 0.4073, 0.3796,\n                       0.4582, 0.4539, 0.3388, 0.6483, 0.3993, 0.6661, 0.7502, 0.8489, 0.6867,\n                       0.4176, 0.2207, 0.5282, 0.6761, 0.6132, 0.9849, 0.7675, 0.9243, 0.7902,\n                       0.3106, 0.5084, 0.6339, 0.5836, 1.1419, 0.5279, 0.4464, 0.5108, 0.6191,\n                       0.5640, 0.6277, 0.4089, 0.6106, 0.4116, 0.3590, 0.5286, 0.6591, 0.6296,\n                       0.8219, 0.5551, 0.4149, 0.7755, 0.5525, 0.4100, 0.5809, 0.5198, 0.6071,\n                       0.4781, 0.8631, 0.9323, 0.5118, 0.8061, 0.3504, 0.6357, 0.5471, 0.4842,\n                       1.0313, 0.4354, 0.2542, 0.5110, 0.6767, 0.7586, 0.3248, 0.5726, 0.5157,\n                       0.2345, 0.3285, 0.4314, 0.7803, 0.3637, 0.8984, 0.5581, 0.4892, 0.5437,\n                       0.3901, 0.4135, 0.5658, 0.7004, 1.0202, 0.4788, 0.4624, 0.6905, 0.4170,\n                       0.3753, 0.4434, 0.8809, 0.7209, 0.5036, 0.9370, 0.5804, 0.4740, 0.5467,\n                       0.7364, 0.3076, 0.5912, 1.0120, 0.7148, 0.7520, 0.4134, 0.5331, 0.4050,\n                       0.5132, 0.9219, 1.0440, 0.7030, 0.5325, 0.6326, 0.8550, 0.4542, 0.7135,\n                       0.5262, 0.7026, 0.8438, 0.7676, 0.6233, 0.6812, 0.7216, 0.5740, 0.6260,\n                       0.6340, 1.3576, 0.3225, 0.5324, 0.8348, 0.4466, 0.2700, 0.6285, 0.6915,\n                       0.7456, 0.6332, 0.7896, 0.6390])),\n              ('layer1.0.downsample.1.num_batches_tracked', tensor(13572)),\n              ('layer1.1.conv1.weight',\n               tensor([[[[-0.0758]],\n               \n                        [[-0.0518]],\n               \n                        [[ 0.0788]],\n               \n                        ...,\n               \n                        [[-0.4280]],\n               \n                        [[-0.0601]],\n               \n                        [[ 0.0197]]],\n               \n               \n                       [[[-0.1357]],\n               \n                        [[ 0.0301]],\n               \n                        [[-0.0170]],\n               \n                        ...,\n               \n                        [[-0.2251]],\n               \n                        [[ 0.1086]],\n               \n                        [[ 0.0136]]],\n               \n               \n                       [[[-0.0218]],\n               \n                        [[-0.0731]],\n               \n                        [[-0.1225]],\n               \n                        ...,\n               \n                        [[-0.0997]],\n               \n                        [[-0.0029]],\n               \n                        [[-0.1347]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0522]],\n               \n                        [[ 0.1585]],\n               \n                        [[ 0.0105]],\n               \n                        ...,\n               \n                        [[-0.1750]],\n               \n                        [[ 0.0728]],\n               \n                        [[-0.0354]]],\n               \n               \n                       [[[-0.0604]],\n               \n                        [[-0.0068]],\n               \n                        [[-0.0357]],\n               \n                        ...,\n               \n                        [[ 0.0095]],\n               \n                        [[-0.0960]],\n               \n                        [[ 0.0243]]],\n               \n               \n                       [[[ 0.1129]],\n               \n                        [[ 0.2580]],\n               \n                        [[-0.0552]],\n               \n                        ...,\n               \n                        [[ 0.0601]],\n               \n                        [[-0.0965]],\n               \n                        [[ 0.0608]]]])),\n              ('layer1.1.bn1.weight',\n               tensor([0.9035, 0.9898, 0.9939, 0.9699, 0.9559, 1.1295, 0.9543, 0.8289, 0.9035,\n                       1.0315, 1.1527, 0.9435, 1.0194, 1.0268, 0.9616, 1.0273, 1.0339, 0.8870,\n                       0.9622, 1.0316, 0.9979, 0.8718, 0.9349, 0.9261, 0.9503, 1.0218, 0.9495,\n                       1.0554, 0.8362, 1.0390, 1.1221, 0.9774, 1.0175, 0.9254, 0.8816, 1.1521,\n                       1.1444, 1.1557, 0.9527, 0.8768, 0.9673, 0.9213, 0.9772, 0.9687, 0.9760,\n                       0.9215, 0.9631, 1.1404, 0.9080, 1.0062, 0.9513, 0.9782, 0.9419, 1.1033,\n                       0.9054, 0.9740, 0.9083, 0.9656, 0.8385, 0.9680, 0.9981, 0.9295, 1.0345,\n                       0.8929])),\n              ('layer1.1.bn1.bias',\n               tensor([ 0.1861,  0.0491, -0.0375, -0.0327, -0.1784,  0.2298,  0.1739, -0.1055,\n                        0.1582,  0.0109, -0.0186, -0.0403,  0.2819,  0.1833,  0.0199, -0.2468,\n                        0.1337, -0.1777,  0.0813, -0.0560,  0.3056, -0.1349,  0.0093,  0.1845,\n                       -0.1524,  0.2039,  0.0744, -0.1444,  0.0597,  0.2056,  0.3003,  0.2442,\n                        0.0834,  0.1623, -0.1874, -0.3874,  0.2852, -0.2157,  0.2187,  0.0784,\n                       -0.0787,  0.2766,  0.0595,  0.2425,  0.3210,  0.0618,  0.1267, -0.4041,\n                        0.0254,  0.3871, -0.1086,  0.0152,  0.1987, -0.0155,  0.1161,  0.1690,\n                        0.1361,  0.1512, -0.1187,  0.1123,  0.2600, -0.4365,  0.2390,  0.0704])),\n              ('layer1.1.bn1.running_mean',\n               tensor([-0.8222, -1.5670, -1.2657,  1.5592,  0.7096, -1.7939, -0.7122, -0.4772,\n                       -1.1753, -0.2912, -0.1181, -0.2472, -1.5922, -1.0239,  0.7073,  0.8373,\n                        0.7003,  0.2243, -1.7455,  0.3299, -0.8100,  0.6943, -0.5737, -0.2090,\n                        1.3693, -1.1105, -1.8528,  1.3880,  0.6186, -0.9455, -0.5822, -0.8346,\n                       -0.4783, -0.2438,  0.7731,  0.8430, -0.0039,  1.6393, -0.0891, -0.1809,\n                       -1.2547, -0.5324, -1.5555,  0.3281, -0.4340,  0.0892,  0.6436,  2.0885,\n                        0.6522, -1.4690, -0.2584,  1.1621, -2.3111,  0.9881, -0.9134, -1.2314,\n                       -1.2332,  0.0716,  1.1560,  0.0600, -0.4755,  0.4478, -0.8192, -0.3209])),\n              ('layer1.1.bn1.running_var',\n               tensor([1.0510, 1.2339, 1.3583, 1.1203, 1.0596, 1.1321, 1.2366, 0.5475, 0.8413,\n                       1.5250, 1.0514, 0.8557, 0.9644, 0.9134, 1.1233, 1.1177, 1.6833, 0.6421,\n                       0.8236, 0.9434, 1.1531, 0.6760, 1.2704, 0.9535, 0.8028, 1.1089, 1.0832,\n                       0.7720, 0.7437, 1.2155, 1.6544, 1.6697, 1.1130, 1.1563, 1.0284, 1.5366,\n                       1.1400, 0.9590, 0.9328, 0.8608, 1.5741, 1.0890, 1.1552, 0.9116, 1.6514,\n                       1.0009, 1.3117, 1.2572, 0.7858, 1.5634, 0.8391, 1.0550, 1.2895, 1.4191,\n                       0.7882, 0.8285, 1.2332, 1.2244, 0.9641, 1.1850, 1.0569, 0.6670, 1.4922,\n                       0.7450])),\n              ('layer1.1.bn1.num_batches_tracked', tensor(13572)),\n              ('layer1.1.conv2.weight',\n               tensor([[[[ 5.1559e-02, -1.8396e-02,  4.5181e-03],\n                         [-5.6128e-02, -2.4334e-02, -8.1426e-03],\n                         [ 1.6165e-03,  5.7569e-03,  1.2050e-02]],\n               \n                        [[ 2.0014e-02, -5.0612e-02,  8.3531e-02],\n                         [ 3.1576e-02,  3.8319e-02,  7.8841e-02],\n                         [ 5.7815e-02, -6.0088e-03, -1.7700e-03]],\n               \n                        [[-4.2704e-02, -5.5062e-02,  5.8660e-02],\n                         [-7.6073e-03, -1.2863e-03, -1.0022e-01],\n                         [-4.6148e-02, -6.1959e-02, -3.8804e-02]],\n               \n                        ...,\n               \n                        [[ 5.5075e-02,  4.4730e-02, -1.5111e-02],\n                         [ 4.4910e-02, -2.6517e-02,  2.1423e-02],\n                         [ 4.0429e-02,  8.1711e-02, -2.0791e-03]],\n               \n                        [[ 8.0336e-02,  1.0301e-02,  2.0367e-02],\n                         [-1.1994e-02, -1.1520e-01,  3.0788e-02],\n                         [-5.2763e-02,  4.6189e-02,  3.9775e-02]],\n               \n                        [[ 5.0823e-02,  4.6907e-02,  3.6086e-02],\n                         [ 8.2534e-02,  8.0844e-05,  1.4238e-01],\n                         [ 2.2360e-02,  8.9832e-02,  1.7122e-01]]],\n               \n               \n                       [[[ 3.7098e-02,  7.3784e-03, -2.0315e-02],\n                         [ 3.8651e-03,  1.4894e-01,  9.0839e-02],\n                         [-3.4627e-03,  5.7531e-02,  5.4829e-02]],\n               \n                        [[-1.8983e-02,  2.7148e-02,  2.6926e-02],\n                         [ 3.8448e-02,  5.6212e-03,  7.3749e-02],\n                         [ 2.8268e-02, -1.0630e-01, -2.0011e-03]],\n               \n                        [[ 2.1849e-02, -1.3892e-02,  3.9142e-03],\n                         [ 4.7406e-02,  9.4128e-03,  3.9428e-02],\n                         [ 1.8278e-02,  6.2112e-02,  2.5011e-02]],\n               \n                        ...,\n               \n                        [[ 5.2018e-03,  4.2799e-02, -1.5564e-03],\n                         [ 9.5450e-02,  8.2217e-03,  2.8523e-02],\n                         [-1.2074e-01, -2.2750e-03,  5.0672e-02]],\n               \n                        [[ 3.1492e-02,  5.6081e-02, -2.9571e-02],\n                         [-8.5317e-02,  8.6043e-02, -3.2145e-03],\n                         [ 5.4050e-03,  7.1945e-02,  5.6251e-02]],\n               \n                        [[-4.5333e-02, -1.1150e-02, -3.8036e-03],\n                         [-2.1563e-02, -4.8579e-02, -4.2066e-02],\n                         [-1.1289e-01, -4.4084e-02, -1.1966e-02]]],\n               \n               \n                       [[[-5.2975e-02,  1.6671e-02,  4.9575e-02],\n                         [-2.4989e-02,  1.8815e-02,  7.0871e-02],\n                         [ 2.6595e-03, -2.4241e-02, -7.2208e-03]],\n               \n                        [[ 6.0967e-02, -2.3426e-02, -6.4773e-02],\n                         [-3.8091e-02, -7.2573e-02,  5.5356e-02],\n                         [-6.7024e-03, -2.5017e-02,  4.2489e-02]],\n               \n                        [[-3.5128e-02,  1.2426e-02,  2.2769e-03],\n                         [-1.1141e-01, -5.6907e-02,  1.0824e-01],\n                         [-3.5580e-02,  7.2728e-02,  2.6324e-02]],\n               \n                        ...,\n               \n                        [[-3.5627e-02,  1.1755e-02, -1.0362e-01],\n                         [-1.7277e-02, -6.1096e-02, -6.4124e-03],\n                         [-2.2651e-02,  6.7109e-03, -2.8517e-02]],\n               \n                        [[-2.8136e-02, -4.0648e-02,  1.0223e-02],\n                         [ 6.9674e-02, -3.6321e-02, -1.4798e-01],\n                         [-2.2032e-02,  3.2016e-02, -1.8581e-02]],\n               \n                        [[-5.3636e-02,  3.7170e-02,  4.1166e-02],\n                         [-1.7733e-02,  4.1744e-02,  6.4962e-02],\n                         [ 2.9335e-02,  8.6319e-03,  4.1754e-03]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 5.6114e-02,  6.0423e-02, -2.4248e-02],\n                         [ 3.1976e-02,  7.0475e-02,  1.0475e-01],\n                         [ 6.4646e-03,  1.4951e-01,  7.8801e-02]],\n               \n                        [[-1.0987e-02,  9.8471e-02, -8.0169e-02],\n                         [ 4.3201e-02,  8.8156e-02,  8.8823e-02],\n                         [-1.7011e-02,  1.3421e-02, -7.9159e-03]],\n               \n                        [[ 5.2473e-04,  6.5097e-02, -3.6648e-02],\n                         [ 1.9703e-02, -2.5958e-02, -1.2501e-02],\n                         [-5.6750e-02, -7.5869e-02, -2.7337e-02]],\n               \n                        ...,\n               \n                        [[-3.5832e-02, -6.8293e-03,  5.8516e-02],\n                         [ 1.1510e-02, -1.2200e-01,  1.2791e-02],\n                         [ 3.6471e-02, -9.9188e-02,  1.5668e-03]],\n               \n                        [[ 9.4997e-02,  3.5895e-02,  2.4816e-02],\n                         [-9.3795e-03,  1.2062e-01, -3.0229e-02],\n                         [ 1.4472e-02,  5.5749e-02, -5.6753e-02]],\n               \n                        [[ 1.5369e-02,  2.2895e-02, -4.9099e-02],\n                         [ 3.1922e-02,  7.9520e-02,  2.1822e-02],\n                         [-2.1522e-02, -2.9107e-02,  5.4078e-02]]],\n               \n               \n                       [[[ 4.4568e-02, -1.3034e-02, -1.2101e-02],\n                         [-5.3676e-02,  8.4210e-02, -4.7950e-02],\n                         [ 7.5779e-02, -5.4330e-03, -4.8349e-02]],\n               \n                        [[-3.0242e-02,  5.9113e-02, -4.7162e-02],\n                         [ 2.0799e-03,  2.1335e-03,  2.3064e-02],\n                         [ 3.7182e-02,  6.7844e-02,  5.8383e-02]],\n               \n                        [[ 9.0478e-03,  4.4382e-02,  5.3685e-02],\n                         [ 9.2674e-03, -3.7647e-02,  1.9442e-02],\n                         [ 4.8675e-02,  4.1497e-02, -1.7973e-02]],\n               \n                        ...,\n               \n                        [[ 7.4562e-02,  5.3437e-02,  4.9761e-02],\n                         [ 3.4364e-02, -1.3836e-02,  1.9961e-02],\n                         [ 6.2677e-02,  4.2559e-02,  6.7718e-02]],\n               \n                        [[ 3.5892e-02,  1.0582e-02, -1.5201e-03],\n                         [ 1.1297e-01,  1.1137e-02, -7.4823e-02],\n                         [ 3.3706e-02, -1.0894e-01,  2.5400e-02]],\n               \n                        [[-9.3800e-02,  9.3055e-03, -5.3080e-02],\n                         [ 5.6571e-02, -2.5505e-02, -4.3511e-02],\n                         [-8.4278e-03, -4.3010e-02, -7.7071e-02]]],\n               \n               \n                       [[[-1.9728e-02,  4.6908e-02, -3.8657e-02],\n                         [-7.1157e-02, -2.8749e-02, -3.2950e-02],\n                         [-3.5148e-03, -4.3996e-02,  1.5779e-03]],\n               \n                        [[-8.8658e-02, -9.0025e-02, -3.0214e-02],\n                         [-5.5133e-02,  9.0577e-04,  7.1937e-02],\n                         [-4.7490e-02, -2.7143e-02, -1.6929e-02]],\n               \n                        [[-3.2635e-02,  2.7793e-02,  8.0928e-03],\n                         [ 4.1218e-02, -7.2578e-02, -4.6320e-02],\n                         [-2.3988e-02, -1.7839e-02, -8.0639e-02]],\n               \n                        ...,\n               \n                        [[ 3.0240e-02,  1.1802e-02, -5.9282e-02],\n                         [ 1.1758e-01,  2.3227e-03, -4.8204e-03],\n                         [ 3.0757e-02, -8.6152e-02,  1.8816e-03]],\n               \n                        [[-2.2472e-02, -1.1427e-01,  2.6871e-02],\n                         [ 3.7566e-02, -3.3833e-02, -2.2485e-02],\n                         [-2.5593e-02, -4.4569e-02, -2.2191e-02]],\n               \n                        [[-5.5569e-02,  4.4230e-02, -1.9094e-02],\n                         [ 3.4555e-02,  4.1599e-03,  1.1572e-01],\n                         [ 1.0371e-01, -1.2406e-02,  4.9384e-02]]]])),\n              ('layer1.1.bn2.weight',\n               tensor([0.9786, 0.8682, 0.9675, 1.0038, 0.9061, 1.0653, 1.0693, 0.9385, 0.9808,\n                       0.9594, 0.9884, 0.9256, 0.9928, 0.9886, 1.0720, 1.0785, 0.9026, 0.9973,\n                       1.0325, 1.1595, 0.9370, 0.9518, 0.9726, 0.9512, 1.0857, 0.9582, 1.0110,\n                       0.9702, 0.9697, 1.0003, 0.9410, 0.8860, 1.0677, 0.9835, 1.0005, 0.9021,\n                       1.0524, 0.9867, 1.0700, 1.0218, 1.0453, 0.9885, 0.9340, 0.9540, 0.9549,\n                       0.9040, 0.9788, 0.9173, 0.9985, 1.0169, 0.9760, 0.9980, 1.1258, 0.9575,\n                       0.9770, 0.9891, 1.0746, 0.9997, 1.0048, 1.0357, 0.9300, 1.0122, 0.9606,\n                       0.9311])),\n              ('layer1.1.bn2.bias',\n               tensor([ 0.5898,  0.1554, -0.0243,  0.0666,  0.0530,  0.1242, -0.0444,  0.1287,\n                        0.1775,  0.1807, -0.0547, -0.0766,  0.0306,  0.1293,  0.0229,  0.0240,\n                        0.0350,  0.1622,  0.0516, -0.0384,  0.1739, -0.0049,  0.1181,  0.1088,\n                       -0.0403, -0.0176,  0.2709, -0.0408,  0.0698,  0.1488, -0.1737,  0.0483,\n                        0.1384,  0.0541, -0.0053,  0.0708, -0.0456, -0.0199, -0.0374, -0.1086,\n                       -0.1489,  0.1611, -0.0195,  0.1208,  0.0215,  0.1315, -0.0311,  0.1070,\n                       -0.0360,  0.2161,  0.0342, -0.2760,  0.1871,  0.1557,  0.0129,  0.1078,\n                        0.1260,  0.1340,  0.0076, -0.0629, -0.0667,  0.1570,  0.0348,  0.0120])),\n              ('layer1.1.bn2.running_mean',\n               tensor([-0.3278, -0.3160,  0.5604,  0.3562,  1.2006, -1.2823, -2.5676, -1.0425,\n                       -1.4659,  0.6481,  1.4487, -1.4120, -2.2952, -0.4715, -0.3653, -1.3794,\n                       -0.8469, -1.0758,  0.8588,  1.0042,  0.3184, -1.4669,  0.6264,  1.4135,\n                       -0.2071,  2.0005, -0.1892,  0.0046, -1.2946, -0.5590,  0.3708, -0.7188,\n                        0.0319, -1.3993, -0.5417,  0.0459,  1.6399, -0.6099,  0.8943, -0.9451,\n                        0.0718,  1.3213, -0.6716, -0.6386, -0.3354,  0.6471,  0.4716,  0.9939,\n                       -1.9820,  0.5632, -1.2113,  0.0357, -2.3053, -0.7394, -2.2282,  0.7093,\n                        0.8551,  0.3842, -0.9326, -0.3025, -0.3988,  0.8370,  0.2367, -0.3684])),\n              ('layer1.1.bn2.running_var',\n               tensor([1.8323, 0.7160, 0.7840, 0.9319, 0.8346, 1.4758, 1.3264, 1.0249, 1.5573,\n                       1.3084, 0.7948, 1.3037, 1.0568, 0.8005, 0.8522, 1.0341, 1.1351, 1.4510,\n                       0.8212, 1.6163, 1.4789, 1.3859, 0.7650, 1.3806, 1.4420, 1.1236, 1.4290,\n                       1.3831, 1.0685, 1.3673, 1.4511, 0.9502, 1.1885, 1.1141, 1.0344, 0.9831,\n                       1.2736, 1.5704, 0.8801, 2.1192, 0.9081, 1.1811, 1.1131, 0.7737, 0.8832,\n                       0.7957, 1.0557, 0.7555, 0.9325, 1.3065, 1.6472, 0.7939, 1.0747, 1.1726,\n                       1.3483, 1.2182, 0.8633, 0.8856, 1.0594, 1.5610, 1.0485, 1.1219, 0.7645,\n                       1.5262])),\n              ('layer1.1.bn2.num_batches_tracked', tensor(13572)),\n              ('layer1.1.conv3.weight',\n               tensor([[[[-0.0278]],\n               \n                        [[-0.1151]],\n               \n                        [[-0.0074]],\n               \n                        ...,\n               \n                        [[-0.0191]],\n               \n                        [[-0.0237]],\n               \n                        [[ 0.0052]]],\n               \n               \n                       [[[ 0.0346]],\n               \n                        [[-0.0893]],\n               \n                        [[ 0.0315]],\n               \n                        ...,\n               \n                        [[-0.0259]],\n               \n                        [[-0.0174]],\n               \n                        [[-0.0655]]],\n               \n               \n                       [[[ 0.0141]],\n               \n                        [[ 0.0209]],\n               \n                        [[ 0.0610]],\n               \n                        ...,\n               \n                        [[ 0.0236]],\n               \n                        [[-0.1351]],\n               \n                        [[-0.0647]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0284]],\n               \n                        [[ 0.0020]],\n               \n                        [[-0.0180]],\n               \n                        ...,\n               \n                        [[ 0.1223]],\n               \n                        [[-0.0896]],\n               \n                        [[ 0.0049]]],\n               \n               \n                       [[[ 0.0841]],\n               \n                        [[-0.0752]],\n               \n                        [[ 0.0079]],\n               \n                        ...,\n               \n                        [[ 0.0316]],\n               \n                        [[ 0.0816]],\n               \n                        [[-0.0088]]],\n               \n               \n                       [[[-0.0094]],\n               \n                        [[ 0.0102]],\n               \n                        [[-0.0712]],\n               \n                        ...,\n               \n                        [[ 0.0123]],\n               \n                        [[ 0.0649]],\n               \n                        [[-0.0393]]]])),\n              ('layer1.1.bn3.weight',\n               tensor([-0.0448, -0.0829, -0.1817, -0.1952,  0.2036, -0.0370,  0.3224,  0.2043,\n                        0.1591, -0.1376, -0.2121,  0.1123, -0.2588, -0.1144,  0.1532,  0.2574,\n                       -0.2876, -0.3269,  0.2459, -0.0575,  0.2137,  0.3150, -0.1707, -0.2532,\n                       -0.1657,  0.0790,  0.3322,  0.0733,  0.1411,  0.1218,  0.2591,  0.1375,\n                        0.1254, -0.1874,  0.0555,  0.3902, -0.2601, -0.1585,  0.1494,  0.2616,\n                       -0.0618, -0.2147, -0.2432, -0.0353,  0.0316, -0.2724, -0.2389,  0.2266,\n                       -0.1333,  0.1189, -0.1146, -0.2228, -0.1258, -0.2924, -0.0731,  0.3102,\n                       -0.3049, -0.1973,  0.0680,  0.1390, -0.2949, -0.2725, -0.3507, -0.0344,\n                        0.2528,  0.2718, -0.1987, -0.3001,  0.2717, -0.1711,  0.1782, -0.1264,\n                       -0.3598, -0.2000,  0.0534, -0.1090, -0.0950,  0.0417, -0.1820, -0.1960,\n                        0.1969, -0.0318,  0.0689,  0.0406, -0.0177,  0.1556,  0.0781, -0.1335,\n                       -0.2252,  0.1211, -0.1201, -0.2713,  0.3056,  0.2382, -0.3585,  0.1372,\n                        0.0721,  0.2949,  0.1299,  0.2871, -0.1929,  0.1600,  0.2672,  0.2257,\n                        0.1726, -0.2575,  0.3427,  0.1348,  0.0609, -0.1123, -0.1216,  0.0493,\n                       -0.1249,  0.1996,  0.1894,  0.1889, -0.0811,  0.0495,  0.2095, -0.0545,\n                       -0.2227, -0.2995, -0.1957,  0.4136, -0.1810, -0.1238, -0.1850,  0.0446,\n                       -0.2378, -0.2060, -0.2792,  0.0910, -0.1665,  0.2388,  0.3138,  0.2116,\n                       -0.1276, -0.2575,  0.2461,  0.2036,  0.1750,  0.2203,  0.2665, -0.2902,\n                        0.1646, -0.2522, -0.2198,  0.0104, -0.2536,  0.2883,  0.1596, -0.2081,\n                        0.1638,  0.1720, -0.2482, -0.0740, -0.2753,  0.1551, -0.3286, -0.1751,\n                        0.2020,  0.1978, -0.2368,  0.3139,  0.2671, -0.2017, -0.3060,  0.0742,\n                       -0.2626,  0.2608, -0.2207,  0.2161,  0.3643, -0.2282,  0.2623,  0.0560,\n                        0.1512,  0.1062,  0.2079, -0.1816, -0.0648, -0.2564, -0.1082, -0.1078,\n                       -0.2307,  0.2237, -0.0867,  0.1426,  0.2276, -0.3316,  0.0842, -0.0921,\n                       -0.3121, -0.2629, -0.2096, -0.2466,  0.1817,  0.2293,  0.2054,  0.1093,\n                        0.2217,  0.1575,  0.1989,  0.1969, -0.2457,  0.3375, -0.2173,  0.0492,\n                       -0.0916,  0.2875,  0.2113,  0.1851,  0.1717, -0.1615,  0.2943,  0.1799,\n                       -0.1896, -0.3584, -0.2903, -0.2588, -0.2773, -0.2182,  0.2088, -0.2749,\n                        0.0409, -0.2419, -0.1399, -0.3147,  0.2066,  0.2230, -0.2167,  0.1672,\n                        0.3174, -0.1709,  0.1901, -0.1565, -0.3199,  0.1872,  0.2070, -0.1742,\n                       -0.2792,  0.2615, -0.2246,  0.1503, -0.2526,  0.1652, -0.1966,  0.2785,\n                        0.2278, -0.2470, -0.1718, -0.2255,  0.1476, -0.3412,  0.2046, -0.0510])),\n              ('layer1.1.bn3.bias',\n               tensor([-0.0036,  0.0805, -0.0334,  0.0825, -0.0016,  0.0520,  0.1689,  0.1427,\n                       -0.1072, -0.0843,  0.1517,  0.1067, -0.0446, -0.0180, -0.0093,  0.2357,\n                       -0.0392, -0.1321, -0.0591,  0.0063,  0.0749,  0.3193,  0.1310,  0.1241,\n                       -0.0031,  0.1235, -0.2724, -0.0327,  0.1101,  0.1903,  0.2575, -0.0889,\n                        0.1362, -0.1134,  0.1629, -0.0781,  0.2188,  0.0573,  0.1440,  0.1924,\n                       -0.0793, -0.0047, -0.1313, -0.0587, -0.0083,  0.3501,  0.1286, -0.0680,\n                       -0.0629,  0.1294,  0.1538,  0.1731, -0.1374, -0.0169,  0.1035,  0.0550,\n                        0.1694,  0.1938, -0.0500,  0.0086,  0.1041,  0.2816,  0.2166,  0.0014,\n                       -0.0119, -0.0054,  0.2469,  0.0346, -0.0451,  0.0730, -0.0400,  0.1742,\n                        0.0088, -0.0203, -0.0297,  0.0251, -0.1004,  0.1410,  0.0859, -0.0960,\n                        0.1836, -0.0354,  0.0980, -0.1118, -0.0871,  0.0436, -0.0165, -0.0734,\n                        0.0216, -0.0063,  0.0879,  0.0233,  0.2109,  0.1114,  0.0673, -0.0653,\n                       -0.1585,  0.0684,  0.2560, -0.0695, -0.0110, -0.0543, -0.0600,  0.0799,\n                       -0.0663,  0.0156,  0.2287,  0.1124,  0.1329,  0.0665,  0.2629,  0.1279,\n                       -0.0164, -0.0185,  0.1101,  0.2167,  0.1043,  0.0490,  0.1953,  0.1692,\n                        0.2180,  0.1622, -0.1294,  0.2621, -0.0956, -0.0640,  0.2643, -0.0386,\n                        0.1662,  0.0813, -0.1097,  0.2331,  0.0546,  0.0295,  0.2176,  0.0794,\n                        0.0010,  0.1685, -0.0400,  0.0858, -0.0009,  0.1875, -0.0627,  0.1422,\n                        0.1347,  0.2394,  0.0482,  0.1475, -0.0157,  0.2213,  0.0326,  0.1515,\n                        0.0026,  0.1196,  0.1693,  0.1658,  0.2382, -0.1450, -0.1120,  0.1581,\n                        0.2076,  0.2222,  0.1829, -0.0914,  0.0297,  0.0725,  0.0915, -0.1364,\n                        0.1273,  0.2023,  0.1292,  0.2688,  0.0071,  0.1658, -0.0134,  0.1179,\n                        0.0722,  0.0531, -0.1160, -0.0040,  0.1126,  0.1680,  0.0860, -0.0163,\n                        0.1631, -0.0879,  0.1745,  0.0468,  0.0133, -0.0879, -0.1375,  0.0366,\n                        0.2022,  0.1805,  0.1300,  0.0087,  0.1899,  0.2216, -0.0407,  0.1792,\n                       -0.1025, -0.0636,  0.1773,  0.0731, -0.0450,  0.0231,  0.1472,  0.0869,\n                       -0.0411,  0.1991,  0.0717, -0.1034,  0.1285,  0.0221, -0.0211,  0.0839,\n                        0.1504,  0.2138, -0.0862,  0.0763,  0.1234, -0.0520,  0.0333,  0.1524,\n                        0.1604,  0.3172, -0.0481,  0.0269,  0.2077,  0.1535,  0.0585,  0.0619,\n                       -0.0869,  0.0124, -0.0559,  0.1475,  0.1653,  0.1302,  0.1061,  0.0408,\n                        0.1976, -0.0199, -0.0293,  0.0778,  0.2454,  0.1543,  0.1548, -0.0758,\n                       -0.1394,  0.1546,  0.0907,  0.0292,  0.0494,  0.2867, -0.0192, -0.0026])),\n              ('layer1.1.bn3.running_mean',\n               tensor([-1.3770e-02,  2.4109e-03, -1.1751e-01, -4.8959e-03,  2.1210e-01,\n                        1.4830e-01,  3.0979e-01,  8.3354e-01, -5.3112e-02, -6.2007e-02,\n                       -4.3049e-01,  3.8105e-02, -8.0851e-02, -2.1906e-01, -2.1199e-01,\n                        1.3808e-01,  7.8238e-02,  6.0522e-03,  8.0106e-02, -2.8926e-01,\n                        2.8916e-02,  5.6964e-01,  9.0450e-02,  9.2922e-02, -3.6726e-01,\n                       -2.0065e-02,  5.5108e-01, -9.3485e-02,  4.1202e-01,  1.5827e-03,\n                       -2.2137e-01, -8.1524e-02,  2.3064e-01, -2.5465e-01, -2.0695e-01,\n                        4.4217e-01,  5.6489e-02,  1.5059e-01,  1.2015e-01,  4.6026e-01,\n                       -6.1249e-01, -4.2304e-01,  3.4164e-02, -9.8424e-04, -2.2770e-01,\n                        7.8759e-02,  6.9995e-02, -6.0575e-01, -1.6045e-01, -1.0948e-01,\n                        7.3906e-02,  3.5235e-01,  1.7506e-01, -2.2099e-01, -5.4532e-02,\n                        2.5890e-01, -3.8443e-01, -2.7016e-01,  3.4222e-01,  1.2917e-01,\n                       -1.8739e-01, -1.1472e-01,  8.0710e-02,  5.0401e-03,  1.6943e-02,\n                        1.7485e-01, -4.8387e-02, -2.7937e-01,  1.4522e-01,  4.6630e-01,\n                        3.3752e-01,  2.0946e-01, -7.0209e-03, -1.2860e-01,  3.8824e-02,\n                        2.8678e-03, -5.1125e-01, -6.6623e-02, -1.8418e-01, -6.7810e-02,\n                        6.1476e-03,  2.9975e-01, -4.2437e-01, -2.6599e-01, -7.1253e-02,\n                        3.8754e-01, -1.2633e-01, -3.9683e-01, -3.3656e-01,  3.5727e-02,\n                        1.2226e-01,  3.7922e-01,  2.0898e-01, -3.1366e-01, -2.9977e-01,\n                       -8.1759e-02,  1.0028e-01, -3.6786e-02,  3.6710e-01,  2.2659e-01,\n                       -1.5255e-01,  6.2827e-02, -6.8325e-02, -5.6507e-02,  1.8266e-01,\n                        3.8867e-02,  1.7187e-01,  1.3777e-01, -9.8601e-02,  1.0713e-02,\n                       -1.4547e-01,  3.0896e-01, -9.6198e-02,  1.1506e-01,  1.1020e-01,\n                       -4.7401e-01,  3.0582e-01,  5.2997e-02, -4.5383e-02,  4.8127e-01,\n                        4.9143e-01,  2.9860e-01, -7.2713e-01, -2.9105e-01,  1.1591e-01,\n                        2.1079e-01,  2.2571e-01,  1.4583e-01,  1.9022e-03, -1.8619e-01,\n                       -1.1979e-01, -1.2788e-02,  3.4741e-01,  1.7619e-01,  1.9509e-01,\n                        5.8060e-01,  1.3504e-01, -1.4195e-01,  1.6030e-01, -2.3652e-02,\n                        2.6861e-02,  5.5675e-01,  4.7930e-02, -1.5888e-02, -9.3656e-02,\n                        5.9428e-01,  3.5054e-01, -8.0238e-02,  7.0338e-02,  3.8370e-01,\n                       -2.0804e-01, -5.5514e-01, -2.4976e-01, -2.0874e-01,  8.4202e-02,\n                        1.5774e-01,  9.9774e-03,  3.9898e-01, -2.4499e-02, -1.1530e-01,\n                       -1.2298e-01, -5.4410e-01, -1.5075e-01,  3.5306e-01, -2.1391e-02,\n                        7.0395e-02, -2.4642e-01, -1.7361e-01, -9.1832e-02, -1.6013e-01,\n                       -6.9298e-03, -3.2840e-01,  5.9746e-02, -2.5921e-01,  4.5064e-02,\n                       -2.8970e-01,  2.8401e-02, -2.4808e-01,  2.3972e-01, -1.2142e-01,\n                       -1.8793e-02, -2.0517e-01, -1.0916e-01, -5.7696e-02,  7.4248e-02,\n                        9.5001e-02,  1.5323e-01, -1.1236e-01,  4.2946e-02, -9.4698e-02,\n                       -3.3039e-01,  1.3823e-01, -5.3819e-02,  3.4219e-01, -1.1302e-01,\n                       -7.0008e-04,  1.6741e-01, -4.0295e-01, -7.9585e-02, -2.9400e-02,\n                       -6.9133e-02, -1.1585e-01,  3.2552e-02,  2.9126e-02, -2.5403e-01,\n                        3.6268e-01, -3.3356e-02,  1.6623e-01,  3.0221e-01,  3.6195e-01,\n                        2.4834e-01,  4.0294e-01, -6.9310e-03,  1.3497e-01, -1.5641e-01,\n                        2.9582e-01,  6.5915e-04, -9.2481e-02, -1.6472e-01, -1.7771e-01,\n                       -1.5787e-01, -2.3704e-01, -4.3900e-02, -1.0716e-01, -1.6480e-01,\n                       -5.0264e-02, -7.5292e-02,  1.6485e-02, -5.1960e-01,  1.3088e-01,\n                       -1.4271e-01, -4.7917e-02, -2.9706e-02, -6.3037e-01, -2.7156e-01,\n                        1.4468e-01, -3.2569e-01,  3.4842e-02, -4.6601e-02, -1.5431e-01,\n                       -2.1303e-01,  3.3964e-02, -2.2688e-02, -3.4284e-01,  4.5815e-01,\n                       -1.7064e-02, -1.0618e-01,  2.4458e-01, -3.6359e-02,  4.6385e-01,\n                       -1.6478e-01,  1.8863e-01, -2.7211e-01, -6.1522e-02,  1.1212e-01,\n                        1.7778e-01])),\n              ('layer1.1.bn3.running_var',\n               tensor([0.0913, 0.0687, 0.1111, 0.1850, 0.0734, 0.0918, 0.1446, 0.2373, 0.0576,\n                       0.0991, 0.1338, 0.1000, 0.1235, 0.1165, 0.1028, 0.2071, 0.1276, 0.1420,\n                       0.1518, 0.0669, 0.1796, 0.1609, 0.1256, 0.1447, 0.1708, 0.0528, 0.1886,\n                       0.0629, 0.1181, 0.0924, 0.2207, 0.1563, 0.0923, 0.1457, 0.0685, 0.1473,\n                       0.1902, 0.1052, 0.1317, 0.2001, 0.0788, 0.2303, 0.1176, 0.0399, 0.0788,\n                       0.2623, 0.1553, 0.1360, 0.1332, 0.1074, 0.1033, 0.1975, 0.0814, 0.1944,\n                       0.0900, 0.2162, 0.1729, 0.1580, 0.0691, 0.0679, 0.2125, 0.1315, 0.2745,\n                       0.0783, 0.1817, 0.1077, 0.1377, 0.1003, 0.1070, 0.1180, 0.1483, 0.1189,\n                       0.1462, 0.0846, 0.0519, 0.1068, 0.0737, 0.0767, 0.1528, 0.0971, 0.1900,\n                       0.0728, 0.1038, 0.0934, 0.0694, 0.2995, 0.0880, 0.0942, 0.1585, 0.1499,\n                       0.0865, 0.2060, 0.1803, 0.1937, 0.3096, 0.1146, 0.0809, 0.1401, 0.1432,\n                       0.1343, 0.1108, 0.0846, 0.1534, 0.0954, 0.0969, 0.1967, 0.2587, 0.0727,\n                       0.0511, 0.0690, 0.1371, 0.0879, 0.0966, 0.0839, 0.1058, 0.1285, 0.0840,\n                       0.1164, 0.1272, 0.1381, 0.1172, 0.1944, 0.1891, 0.2376, 0.0888, 0.0839,\n                       0.1167, 0.0751, 0.1680, 0.1624, 0.1650, 0.0976, 0.1191, 0.1096, 0.2110,\n                       0.1342, 0.0857, 0.1181, 0.2384, 0.1665, 0.1614, 0.3560, 0.1282, 0.2173,\n                       0.1139, 0.2376, 0.1332, 0.0648, 0.1252, 0.2181, 0.1102, 0.1279, 0.0938,\n                       0.1011, 0.1867, 0.0982, 0.1799, 0.1728, 0.1318, 0.1277, 0.1467, 0.1158,\n                       0.1117, 0.1211, 0.1406, 0.1829, 0.1604, 0.0615, 0.1539, 0.1511, 0.1772,\n                       0.1251, 0.3348, 0.2137, 0.1374, 0.0601, 0.0875, 0.1024, 0.1130, 0.0986,\n                       0.0660, 0.2138, 0.1074, 0.1053, 0.1787, 0.1073, 0.1010, 0.0855, 0.2262,\n                       0.1365, 0.0656, 0.0939, 0.2208, 0.1790, 0.1080, 0.1585, 0.0936, 0.1447,\n                       0.1902, 0.0787, 0.0878, 0.1162, 0.1671, 0.2172, 0.1467, 0.1674, 0.1350,\n                       0.0868, 0.1330, 0.1756, 0.1190, 0.1085, 0.1299, 0.1052, 0.1070, 0.1215,\n                       0.1664, 0.1153, 0.0966, 0.1717, 0.1872, 0.1379, 0.2476, 0.1284, 0.1234,\n                       0.1503, 0.0955, 0.1761, 0.1851, 0.1845, 0.1934, 0.0841, 0.1012, 0.1631,\n                       0.1120, 0.1020, 0.1595, 0.1598, 0.1205, 0.1458, 0.1754, 0.1306, 0.1074,\n                       0.1857, 0.2153, 0.0888, 0.1383, 0.2154, 0.0933, 0.1745, 0.1280, 0.1322,\n                       0.1004, 0.1903, 0.1372, 0.0902])),\n              ('layer1.1.bn3.num_batches_tracked', tensor(13572)),\n              ('layer1.2.conv1.weight',\n               tensor([[[[ 0.0141]],\n               \n                        [[ 0.0667]],\n               \n                        [[-0.1319]],\n               \n                        ...,\n               \n                        [[ 0.0110]],\n               \n                        [[ 0.0732]],\n               \n                        [[-0.0137]]],\n               \n               \n                       [[[-0.0214]],\n               \n                        [[-0.0989]],\n               \n                        [[ 0.0255]],\n               \n                        ...,\n               \n                        [[-0.1315]],\n               \n                        [[ 0.0327]],\n               \n                        [[-0.0052]]],\n               \n               \n                       [[[ 0.1815]],\n               \n                        [[-0.0994]],\n               \n                        [[-0.0188]],\n               \n                        ...,\n               \n                        [[-0.1650]],\n               \n                        [[ 0.0365]],\n               \n                        [[ 0.0011]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0803]],\n               \n                        [[-0.0951]],\n               \n                        [[ 0.0385]],\n               \n                        ...,\n               \n                        [[-0.1148]],\n               \n                        [[ 0.1207]],\n               \n                        [[ 0.0863]]],\n               \n               \n                       [[[-0.1102]],\n               \n                        [[ 0.0566]],\n               \n                        [[-0.0140]],\n               \n                        ...,\n               \n                        [[ 0.0986]],\n               \n                        [[ 0.0297]],\n               \n                        [[ 0.0660]]],\n               \n               \n                       [[[ 0.0219]],\n               \n                        [[-0.0749]],\n               \n                        [[-0.0555]],\n               \n                        ...,\n               \n                        [[-0.0166]],\n               \n                        [[-0.1538]],\n               \n                        [[ 0.0255]]]])),\n              ('layer1.2.bn1.weight',\n               tensor([0.9281, 1.0469, 1.0830, 0.9795, 1.1842, 1.0061, 1.0407, 0.9576, 1.0205,\n                       0.9336, 0.9025, 0.9981, 0.9930, 0.9601, 1.0625, 1.0433, 1.0476, 0.9418,\n                       1.0128, 0.9982, 1.0393, 0.8889, 1.0125, 0.9591, 1.0219, 1.0212, 1.1229,\n                       0.9716, 0.9174, 0.9643, 0.8852, 1.0267, 0.9860, 1.0466, 1.0062, 0.9926,\n                       1.0290, 0.9889, 0.8980, 0.8905, 1.0371, 0.8544, 0.9726, 0.8982, 1.0108,\n                       0.9002, 1.0300, 0.9324, 0.9655, 1.0359, 0.9092, 0.9874, 1.0445, 0.9165,\n                       1.0007, 0.9097, 1.1043, 0.9890, 0.8662, 1.0971, 0.9749, 0.9874, 0.9672,\n                       0.8642])),\n              ('layer1.2.bn1.bias',\n               tensor([ 0.0985, -0.2343, -0.0313,  0.1941, -0.1361, -0.3227, -0.1124, -0.0386,\n                        0.3013, -0.1263, -0.1503,  0.0056,  0.2683, -0.0055,  0.1332, -0.0019,\n                        0.0652,  0.1488,  0.3279, -0.0708, -0.2421,  0.2999,  0.2106,  0.1660,\n                        0.0092,  0.0283, -0.1298,  0.1643,  0.0850, -0.0154,  0.0605,  0.0168,\n                        0.2898, -0.1337, -0.2609,  0.1790, -0.3988, -0.0603,  0.0497,  0.0136,\n                        0.0115,  0.0638,  0.2357, -0.0580,  0.2249,  0.0317,  0.0697,  0.1735,\n                       -0.0035,  0.0927, -0.1127,  0.0447,  0.1194,  0.2009, -0.0792,  0.0740,\n                        0.1162,  0.2738, -0.1814,  0.2051, -0.0391,  0.1967, -0.0306, -0.0222])),\n              ('layer1.2.bn1.running_mean',\n               tensor([-0.2156,  1.4673,  0.4420, -1.0895, -0.2796, -0.3801,  0.8820,  0.4789,\n                       -1.3713, -0.2069,  0.3887, -1.4704, -1.4408, -0.3167, -0.1457, -1.0642,\n                       -1.7927, -0.6094, -1.5159, -0.4966,  1.2038, -1.6963, -1.4249, -1.9039,\n                        0.0130,  0.2179,  0.3589,  0.9439, -0.8283,  1.0503,  0.2815, -1.6465,\n                       -1.0399,  1.1384, -0.0600, -2.0310, -0.9778, -1.2968,  0.3847, -1.3279,\n                       -1.2515, -1.7476, -0.7626,  1.4761, -0.5516,  0.4663, -0.6721, -2.1145,\n                       -0.5842, -1.3188,  0.1596, -1.2950,  0.1491,  0.7718, -1.6878,  0.1723,\n                       -1.7572, -0.4993,  0.5419, -0.9090, -0.6589, -1.7895,  3.2838,  0.5468])),\n              ('layer1.2.bn1.running_var',\n               tensor([0.9376, 0.7935, 1.3187, 0.9182, 1.7267, 1.2357, 0.7659, 0.9648, 1.2042,\n                       0.7724, 0.8127, 0.9894, 0.9615, 1.1262, 1.1216, 1.1280, 1.1643, 1.1174,\n                       1.2604, 0.9119, 1.0810, 1.3106, 1.1467, 1.0478, 1.2060, 1.0483, 1.3611,\n                       0.8935, 0.9137, 1.0909, 1.0914, 1.1250, 1.0649, 1.6036, 1.2031, 1.0682,\n                       0.6065, 1.2534, 1.1048, 1.1527, 1.2448, 0.8959, 1.4239, 0.8486, 1.2907,\n                       1.1565, 1.0547, 1.2063, 0.9400, 1.2575, 0.7720, 1.2462, 1.5027, 0.9581,\n                       1.6714, 0.8528, 0.9602, 1.4672, 0.6269, 1.7058, 0.9146, 1.1432, 1.1754,\n                       0.7599])),\n              ('layer1.2.bn1.num_batches_tracked', tensor(13572)),\n              ('layer1.2.conv2.weight',\n               tensor([[[[ 4.3317e-02,  3.9307e-02, -7.2104e-02],\n                         [-1.2326e-02, -7.1169e-02, -4.3669e-02],\n                         [-4.1455e-02, -7.9852e-03, -2.2470e-03]],\n               \n                        [[ 5.6371e-02,  3.4561e-03,  4.4159e-02],\n                         [-2.3993e-02, -7.1373e-02,  2.2847e-02],\n                         [-3.9654e-02, -1.9741e-02, -2.0024e-02]],\n               \n                        [[ 6.8857e-02,  3.6866e-02,  3.3913e-02],\n                         [ 9.5546e-02, -6.7670e-02,  1.4303e-01],\n                         [-3.3964e-02, -4.5531e-02,  9.4240e-03]],\n               \n                        ...,\n               \n                        [[-1.6665e-02, -2.9489e-02, -2.5206e-02],\n                         [-8.1062e-02,  6.8515e-02,  5.3260e-02],\n                         [-7.4252e-02,  5.3724e-02, -3.6589e-02]],\n               \n                        [[ 4.0739e-02, -2.9865e-02,  3.6574e-02],\n                         [ 5.2470e-02, -9.3623e-02, -9.2640e-04],\n                         [ 1.2909e-01, -3.2923e-04,  8.1411e-02]],\n               \n                        [[ 2.4717e-02, -1.0456e-01,  4.6931e-02],\n                         [ 4.9772e-02, -4.8878e-02,  1.7291e-02],\n                         [-7.7482e-03, -2.8400e-02, -1.9773e-02]]],\n               \n               \n                       [[[-5.9884e-02, -3.9385e-02, -4.8303e-02],\n                         [-4.2503e-03,  2.0800e-02, -4.4255e-02],\n                         [ 5.3817e-02,  2.0509e-02, -4.7127e-02]],\n               \n                        [[-5.6462e-02, -8.1953e-03,  2.4632e-02],\n                         [ 4.6845e-02,  1.0141e-02, -2.4738e-02],\n                         [-1.4764e-03,  2.4625e-02, -4.2299e-02]],\n               \n                        [[ 5.2902e-02,  8.6801e-02, -1.1879e-03],\n                         [-5.6112e-02, -1.6873e-02, -4.4412e-02],\n                         [ 9.0460e-03, -6.2554e-02,  6.7674e-03]],\n               \n                        ...,\n               \n                        [[ 2.2273e-02, -2.4934e-03,  4.3067e-02],\n                         [-2.1762e-02, -7.3602e-02, -3.3681e-03],\n                         [-5.0506e-02,  6.1208e-02,  6.7316e-02]],\n               \n                        [[-1.8809e-02,  1.2769e-02, -2.8242e-02],\n                         [ 5.8857e-02,  2.6527e-02, -7.4042e-02],\n                         [-2.3276e-03,  6.8908e-02, -5.9630e-03]],\n               \n                        [[ 1.2397e-02, -3.9324e-02,  2.8663e-02],\n                         [-4.8015e-03,  1.3681e-03, -3.4349e-03],\n                         [-3.0317e-02, -4.8729e-02, -5.4234e-02]]],\n               \n               \n                       [[[ 7.6103e-02,  1.0709e-01,  5.2261e-02],\n                         [-9.9505e-02, -3.8825e-02, -1.6548e-02],\n                         [-9.1455e-02, -3.7994e-03,  2.3879e-02]],\n               \n                        [[-4.3036e-02,  6.2183e-02, -3.9293e-03],\n                         [-5.5363e-02, -2.7547e-02, -3.0684e-03],\n                         [-6.5782e-04,  1.2612e-02, -7.4744e-02]],\n               \n                        [[ 2.6575e-02, -1.8588e-02,  3.5196e-02],\n                         [ 3.6410e-03, -2.1974e-03,  2.8348e-02],\n                         [-3.4242e-02,  2.9254e-02,  3.7285e-02]],\n               \n                        ...,\n               \n                        [[-1.4185e-02, -3.1280e-03, -1.7238e-02],\n                         [-2.3864e-02, -8.2021e-02, -3.6888e-03],\n                         [ 4.5688e-03, -3.3662e-02,  2.0917e-02]],\n               \n                        [[ 4.8398e-02, -3.7153e-02,  1.0866e-02],\n                         [ 7.0499e-02, -4.6190e-02, -6.5973e-04],\n                         [ 2.0851e-02,  8.2904e-02,  7.4505e-02]],\n               \n                        [[ 3.3169e-02, -3.7935e-02,  7.6016e-03],\n                         [-5.5114e-02, -9.1690e-03, -1.0520e-02],\n                         [ 3.0947e-04, -6.4777e-02, -2.6648e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-4.9657e-02, -5.0239e-02,  9.9660e-04],\n                         [ 2.7472e-02,  3.8231e-05, -1.0712e-02],\n                         [ 3.8707e-03,  5.2966e-02, -3.1589e-02]],\n               \n                        [[ 1.8680e-02,  2.7619e-02,  3.9724e-02],\n                         [ 4.8803e-02,  5.6992e-02, -3.9638e-05],\n                         [-1.0683e-02,  7.6538e-02,  5.3078e-02]],\n               \n                        [[-9.0755e-02, -8.9462e-02, -1.0456e-01],\n                         [ 3.1164e-02, -3.0792e-03,  2.5886e-02],\n                         [-3.8040e-02, -5.8022e-02, -1.0504e-01]],\n               \n                        ...,\n               \n                        [[ 8.2913e-02,  9.3736e-03,  2.3966e-02],\n                         [ 8.9006e-03,  2.1300e-02, -1.9345e-02],\n                         [ 1.0768e-02,  1.0226e-03, -7.0150e-03]],\n               \n                        [[ 4.6199e-02,  4.4167e-02, -4.0845e-02],\n                         [ 2.2324e-02, -1.2972e-02,  4.6047e-03],\n                         [-1.3458e-02,  3.0998e-02, -8.2763e-02]],\n               \n                        [[-5.4891e-02, -7.2444e-02,  2.9903e-02],\n                         [-6.6476e-02,  1.5865e-02,  2.0123e-02],\n                         [-4.3528e-02, -2.1171e-02,  7.0036e-04]]],\n               \n               \n                       [[[-9.7329e-02, -8.4502e-03,  1.0788e-02],\n                         [-8.1565e-02,  9.4332e-03, -9.6177e-02],\n                         [-5.4541e-02, -8.3791e-03, -4.1119e-02]],\n               \n                        [[-1.5436e-02, -8.7030e-03,  2.7747e-02],\n                         [ 5.3359e-02,  1.8935e-02,  6.1231e-03],\n                         [ 3.5512e-02,  1.3422e-02, -2.3224e-02]],\n               \n                        [[-1.9299e-03, -9.1769e-03,  2.5633e-02],\n                         [ 5.3615e-02, -5.8717e-02,  1.7419e-02],\n                         [ 8.6251e-02,  1.5929e-02,  8.0637e-02]],\n               \n                        ...,\n               \n                        [[-1.4688e-02, -2.9755e-02, -2.9282e-02],\n                         [-1.2867e-02, -4.9284e-02, -3.3202e-02],\n                         [ 4.8743e-02,  1.7718e-02, -2.8977e-02]],\n               \n                        [[-8.1343e-03,  1.0082e-02, -1.8828e-02],\n                         [ 1.3566e-02,  6.3576e-02,  7.9672e-02],\n                         [ 5.2537e-02, -1.3990e-03,  5.6235e-03]],\n               \n                        [[ 3.0519e-02, -1.1708e-02,  1.3686e-02],\n                         [-6.2169e-03, -3.6084e-02,  5.9814e-02],\n                         [ 5.2621e-03, -2.3243e-02,  2.8062e-02]]],\n               \n               \n                       [[[-3.8727e-02,  3.9954e-02,  1.7318e-02],\n                         [-2.1555e-02, -2.1554e-02, -2.6373e-02],\n                         [ 1.8124e-02,  2.1721e-03, -5.6803e-02]],\n               \n                        [[ 1.0746e-01,  3.1209e-03,  4.3264e-02],\n                         [-4.8291e-02,  1.3365e-02,  8.6189e-02],\n                         [ 1.3537e-02,  1.4108e-02,  1.1887e-02]],\n               \n                        [[ 3.2149e-02, -3.6651e-02, -2.1304e-02],\n                         [ 3.7172e-02,  7.5610e-03,  1.2060e-02],\n                         [ 2.4050e-02, -1.5989e-02,  1.0787e-02]],\n               \n                        ...,\n               \n                        [[ 1.0361e-02, -8.4612e-03,  4.1226e-03],\n                         [-2.4206e-03,  3.7393e-02,  2.6743e-02],\n                         [ 1.1212e-02,  9.9642e-02,  2.4109e-02]],\n               \n                        [[-7.1229e-03,  4.8517e-02,  4.9403e-02],\n                         [ 3.6775e-02, -1.5458e-03, -2.1535e-03],\n                         [-4.9112e-02,  7.2482e-02,  3.7932e-03]],\n               \n                        [[-2.1502e-02, -4.2175e-02,  2.4231e-02],\n                         [ 2.9779e-02,  2.3641e-02,  2.5499e-02],\n                         [ 3.2148e-02,  2.5523e-02,  3.2793e-02]]]])),\n              ('layer1.2.bn2.weight',\n               tensor([0.9855, 0.8588, 0.9465, 0.9453, 0.9529, 0.9892, 0.9086, 0.9090, 0.9567,\n                       1.0255, 0.8803, 1.0589, 0.9582, 0.9962, 0.9625, 0.9544, 1.4129, 0.8960,\n                       0.9528, 0.9472, 0.9256, 0.9818, 1.0030, 1.0661, 0.8866, 1.1475, 1.0388,\n                       1.0990, 0.8726, 0.8365, 1.0892, 0.7991, 1.1256, 0.8714, 0.9087, 0.9286,\n                       1.0024, 0.8952, 1.0406, 1.0295, 0.8939, 0.9402, 1.0926, 0.8955, 0.9492,\n                       0.9278, 0.9803, 1.2600, 0.9672, 0.9347, 0.9546, 0.9164, 0.9543, 0.9870,\n                       0.8478, 1.0083, 1.0488, 0.8812, 1.0637, 0.9573, 0.9681, 1.1335, 0.9645,\n                       0.8703])),\n              ('layer1.2.bn2.bias',\n               tensor([ 0.1230,  0.1431, -0.0618,  0.0741,  0.3146, -0.2283,  0.1335,  0.0140,\n                       -0.0158, -0.0466, -0.1189, -0.0305,  0.0409, -0.2074, -0.1306,  0.2081,\n                       -0.2300, -0.0105,  0.0171,  0.1616,  0.1000, -0.1387, -0.0524, -0.0558,\n                        0.0968, -0.0751,  0.0952, -0.0947,  0.0132,  0.0307, -0.1003,  0.2182,\n                       -0.0993, -0.0198,  0.0131, -0.1695, -0.1946,  0.1311, -0.0256,  0.0208,\n                        0.0405,  0.1038,  0.1166,  0.0808,  0.1605,  0.1163,  0.1586, -0.2267,\n                       -0.2100, -0.0288, -0.0832,  0.1288, -0.0099, -0.1957,  0.0247, -0.0601,\n                        0.1161,  0.0251, -0.2435, -0.0355,  0.0243, -0.0516, -0.0566, -0.0929])),\n              ('layer1.2.bn2.running_mean',\n               tensor([-2.3435,  0.6183, -0.9556,  0.5763, -0.5487, -0.4068,  0.7597,  0.8501,\n                       -0.5073,  0.4579, -0.9313, -0.1906, -0.2281, -0.0060,  0.2909, -1.0614,\n                        0.0940,  0.0668,  0.2985,  0.2297,  0.3307,  0.7693,  0.2863, -0.4849,\n                        0.9771,  0.3460, -0.4891, -0.7828, -1.0975,  0.0620,  0.2694, -1.2192,\n                        0.3935,  1.7574,  0.1548, -0.7182,  0.9607, -0.4506, -0.1390,  0.3975,\n                        0.6015, -1.2218, -0.0613,  1.7471, -0.4805, -0.4606,  1.9309,  0.0868,\n                        0.4070,  0.6350, -1.7876, -0.9746, -0.6617,  0.4630,  0.0616,  0.1342,\n                        0.1616, -0.7104, -0.3269, -1.0250,  0.9600, -0.1903, -0.4147, -0.2432])),\n              ('layer1.2.bn2.running_var',\n               tensor([1.2243, 0.9130, 1.2145, 1.0891, 1.5237, 1.1429, 1.6191, 1.4246, 0.7355,\n                       1.0221, 1.4047, 1.2199, 1.3497, 0.8702, 1.3684, 1.1286, 2.6324, 0.9048,\n                       1.4918, 0.8164, 0.9624, 0.8828, 0.8072, 0.8174, 0.5751, 1.2834, 1.1263,\n                       1.0464, 1.0946, 0.6595, 0.9879, 1.1449, 1.0311, 0.7706, 0.8702, 0.8900,\n                       1.0936, 0.7071, 0.9128, 1.3526, 1.0673, 0.7794, 1.4356, 0.9565, 0.8555,\n                       1.1215, 0.9876, 1.6724, 1.0331, 0.7303, 1.3492, 0.9613, 1.5425, 1.0300,\n                       1.0945, 1.3042, 1.2193, 0.7718, 1.1682, 1.1979, 0.8985, 1.1792, 1.1677,\n                       1.1601])),\n              ('layer1.2.bn2.num_batches_tracked', tensor(13572)),\n              ('layer1.2.conv3.weight',\n               tensor([[[[ 0.0640]],\n               \n                        [[-0.0629]],\n               \n                        [[-0.0788]],\n               \n                        ...,\n               \n                        [[ 0.0320]],\n               \n                        [[ 0.0474]],\n               \n                        [[ 0.0744]]],\n               \n               \n                       [[[-0.0058]],\n               \n                        [[ 0.0458]],\n               \n                        [[ 0.0454]],\n               \n                        ...,\n               \n                        [[ 0.0106]],\n               \n                        [[ 0.0090]],\n               \n                        [[-0.1170]]],\n               \n               \n                       [[[ 0.0448]],\n               \n                        [[-0.0560]],\n               \n                        [[ 0.0723]],\n               \n                        ...,\n               \n                        [[-0.0947]],\n               \n                        [[-0.0821]],\n               \n                        [[ 0.0022]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.1092]],\n               \n                        [[ 0.0054]],\n               \n                        [[ 0.0633]],\n               \n                        ...,\n               \n                        [[-0.0364]],\n               \n                        [[-0.0733]],\n               \n                        [[-0.0568]]],\n               \n               \n                       [[[ 0.0620]],\n               \n                        [[-0.0584]],\n               \n                        [[ 0.0159]],\n               \n                        ...,\n               \n                        [[ 0.0366]],\n               \n                        [[ 0.0698]],\n               \n                        [[-0.0223]]],\n               \n               \n                       [[[ 0.0410]],\n               \n                        [[-0.1006]],\n               \n                        [[-0.0005]],\n               \n                        ...,\n               \n                        [[-0.0383]],\n               \n                        [[ 0.0043]],\n               \n                        [[ 0.1130]]]])),\n              ('layer1.2.bn3.weight',\n               tensor([-0.0988, -0.1106, -0.1592, -0.1404, -0.2643,  0.1073, -0.0191,  0.1825,\n                        0.4242, -0.0565,  0.2851,  0.2328, -0.4940,  0.2734, -0.1802,  0.2796,\n                        0.1339, -0.2336, -0.3649, -0.0975,  0.2008,  0.1891,  0.1488,  0.1182,\n                       -0.1049,  0.4174, -0.2842, -0.0261,  0.2429, -0.1753, -0.2149, -0.1811,\n                       -0.2341, -0.3822,  0.1646,  0.2801,  0.2423, -0.1852,  0.2237, -0.1243,\n                        0.1264,  0.1964,  0.1312,  0.1381,  0.1201, -0.3409,  0.2534, -0.2513,\n                       -0.1098, -0.2543,  0.2647, -0.3056, -0.1652,  0.1885, -0.3385, -0.3225,\n                        0.2781, -0.0684, -0.2221, -0.1292, -0.2415, -0.1137, -0.2439, -0.0835,\n                       -0.1152,  0.2337, -0.1650,  0.2780,  0.2109,  0.1261, -0.2672,  0.2148,\n                        0.3640, -0.0788,  0.0834,  0.1970, -0.1918,  0.2679,  0.0197,  0.2323,\n                       -0.1410, -0.0488,  0.0501,  0.2151, -0.3889,  0.1148,  0.1888, -0.1843,\n                       -0.1590, -0.2188,  0.2011, -0.3492,  0.0803, -0.3450, -0.3118,  0.2169,\n                       -0.2639,  0.3017,  0.1590,  0.4475,  0.2605, -0.0624, -0.3008,  0.3089,\n                        0.0251, -0.2223,  0.1202,  0.1770, -0.1579,  0.2427,  0.1812,  0.2960,\n                       -0.1298,  0.1236, -0.2056,  0.1725,  0.2910, -0.1714, -0.2534, -0.1799,\n                       -0.1448, -0.1742, -0.2297, -0.1369,  0.0109, -0.2899,  0.1789, -0.0626,\n                        0.2552,  0.1772, -0.2667,  0.3292, -0.2907, -0.3629, -0.2921, -0.3638,\n                        0.0237,  0.0963, -0.0971, -0.1700, -0.2262,  0.1964, -0.2963, -0.3725,\n                       -0.0292,  0.2616,  0.3551, -0.2577,  0.2363, -0.2822,  0.1627, -0.0272,\n                        0.0010, -0.0929,  0.1499, -0.1591,  0.3030,  0.1694, -0.0455, -0.2510,\n                       -0.1219,  0.1596, -0.2462,  0.3705,  0.3693, -0.2682,  0.2861,  0.1923,\n                        0.2229,  0.2435,  0.2433,  0.2008, -0.2930, -0.3086, -0.2365,  0.2543,\n                       -0.0802, -0.2557,  0.2548,  0.0157, -0.0433, -0.2866,  0.2054, -0.0873,\n                        0.3521,  0.2090, -0.2226, -0.0760, -0.3046,  0.4400, -0.1146,  0.0837,\n                       -0.2935, -0.2611, -0.2736,  0.2193,  0.1969, -0.1416, -0.2503, -0.1534,\n                       -0.2768,  0.2494, -0.2383, -0.3635, -0.2068, -0.2250,  0.0196, -0.0904,\n                        0.1485,  0.2263, -0.1201,  0.1760,  0.2873,  0.2781,  0.3320, -0.3374,\n                       -0.2444,  0.3581, -0.4038,  0.2399, -0.1373,  0.2496,  0.2154,  0.1836,\n                       -0.2627, -0.2516, -0.1242, -0.2318, -0.0439,  0.1745,  0.1637, -0.2378,\n                       -0.2344,  0.1879, -0.2328, -0.2646, -0.2518,  0.1116, -0.1491,  0.1797,\n                       -0.3746, -0.0991, -0.3324,  0.3100,  0.1094,  0.4499, -0.2152,  0.2014,\n                       -0.1693,  0.1273, -0.2248, -0.2659, -0.2134,  0.2585,  0.3022, -0.1846])),\n              ('layer1.2.bn3.bias',\n               tensor([ 0.0341,  0.0236, -0.0789,  0.0402,  0.1340, -0.0222,  0.0432,  0.2321,\n                       -0.1124,  0.0307,  0.0872,  0.0215, -0.1261, -0.0639,  0.0070,  0.1599,\n                       -0.0556,  0.0782,  0.1552,  0.0722,  0.1953,  0.1361,  0.0716,  0.0705,\n                        0.0564,  0.1750, -0.0834, -0.0955,  0.1772,  0.1757,  0.2160, -0.0066,\n                        0.1352, -0.0542,  0.1711, -0.0825,  0.1905,  0.0201,  0.1897,  0.0875,\n                       -0.0750,  0.1451, -0.0599,  0.0055, -0.1007,  0.3468,  0.0834,  0.1087,\n                        0.0682,  0.1274,  0.0684,  0.2181, -0.0824,  0.0613,  0.0967,  0.2169,\n                        0.2577,  0.0636, -0.0434,  0.0275,  0.0619,  0.1056,  0.2094, -0.0861,\n                       -0.0072, -0.0158,  0.1853, -0.0551,  0.0547,  0.0854, -0.1233,  0.1593,\n                        0.0452,  0.0557, -0.0812,  0.0765,  0.0431,  0.1639,  0.0291,  0.1840,\n                        0.1398, -0.0680,  0.0766,  0.2576,  0.0337,  0.1222,  0.0457, -0.0747,\n                        0.0223, -0.0166,  0.0877,  0.0354,  0.1117,  0.0937,  0.0945, -0.0015,\n                       -0.1470,  0.1834,  0.1931, -0.0157, -0.0178, -0.0037, -0.0005, -0.0530,\n                       -0.1262,  0.0659,  0.1981,  0.1995,  0.1439,  0.0330,  0.2066,  0.1328,\n                        0.1875, -0.0035,  0.1607,  0.1906,  0.0822,  0.0147,  0.1698,  0.1032,\n                        0.1090,  0.0634, -0.1356,  0.0620, -0.0701,  0.0737,  0.1689,  0.0142,\n                        0.2547,  0.0885,  0.1168,  0.2102,  0.0634,  0.1337,  0.1740,  0.0281,\n                        0.0533,  0.1477, -0.0430,  0.0881, -0.0291,  0.1179,  0.0105,  0.0860,\n                        0.0488,  0.1439,  0.1137,  0.1506,  0.1122,  0.2228, -0.0269,  0.0519,\n                        0.0268,  0.0748,  0.1333,  0.0946,  0.1692, -0.0832, -0.0876,  0.2261,\n                        0.1669,  0.1307,  0.0461,  0.0420,  0.0161,  0.0769, -0.0080,  0.0346,\n                        0.1569,  0.1787,  0.2008,  0.1544,  0.1508,  0.1715, -0.0799,  0.0882,\n                        0.0638, -0.0492, -0.1147, -0.0074,  0.0942,  0.1733,  0.0918, -0.0106,\n                        0.2007, -0.0760,  0.1848, -0.0164,  0.0230, -0.0724, -0.0563,  0.0750,\n                        0.1260,  0.1797,  0.1083,  0.1806,  0.2424,  0.0972,  0.1098,  0.1061,\n                       -0.1675, -0.0564,  0.2277,  0.0316, -0.0896,  0.0977,  0.0580,  0.0704,\n                        0.0184,  0.1573,  0.0020, -0.0867,  0.0052,  0.0732, -0.1049,  0.0938,\n                        0.1245,  0.3073, -0.1021, -0.0590,  0.1211,  0.0226,  0.0261,  0.1373,\n                        0.1576,  0.2374,  0.0675,  0.0689,  0.0536,  0.1058,  0.0093,  0.1082,\n                        0.0676,  0.0486,  0.1051,  0.1420,  0.1746,  0.1203,  0.1063,  0.0636,\n                        0.1574,  0.0820,  0.0344,  0.0259,  0.1420,  0.1411,  0.1486,  0.0372,\n                        0.0862,  0.0937,  0.1586,  0.0965,  0.0978,  0.2915, -0.0573, -0.0110])),\n              ('layer1.2.bn3.running_mean',\n               tensor([ 0.2246,  0.1272, -0.1783, -0.1128, -0.1237,  0.0790, -0.0059, -0.1039,\n                        0.1151,  0.2815,  0.1253,  0.1105,  0.1332, -0.0804, -0.0224,  0.0312,\n                       -0.0468, -0.2128,  0.1825,  0.0831,  0.4133,  0.5319,  0.3776,  0.1752,\n                        0.2207,  0.2427, -0.4980,  0.4262,  0.2113, -0.0456, -0.1484, -0.2118,\n                        0.1023, -0.0788,  0.2850,  0.0060,  0.0281, -0.1764,  0.0596, -0.2181,\n                        0.2638,  0.0939, -0.2475,  0.0208,  0.1177,  0.4285,  0.0140, -0.0840,\n                        0.0920,  0.1681, -0.1843, -0.0052, -0.0820,  0.1285, -0.1909, -0.2425,\n                        0.3531, -0.3368,  0.0775,  0.0514,  0.0009, -0.0566, -0.0415,  0.0526,\n                       -0.2765,  0.0158, -0.1385,  0.0404,  0.3356,  0.0927, -0.0588,  0.1742,\n                       -0.0048,  0.2204, -0.0019, -0.0433, -0.0069,  0.1351, -0.0963, -0.1223,\n                       -0.0262,  0.1433, -0.2344, -0.0419,  0.2908,  0.1199,  0.1484, -0.0857,\n                       -0.2055, -0.0411, -0.0591, -0.1575, -0.2443, -0.5113, -0.3440,  0.1649,\n                       -0.4812, -0.0722, -0.0469, -0.0512,  0.1962,  0.0101, -0.1050,  0.0069,\n                        0.2085, -0.0348,  0.0601, -0.0329,  0.2029,  0.3392, -0.0751, -0.0043,\n                        0.1275,  0.2687, -0.1154, -0.1696,  0.0277, -0.1594,  0.0688, -0.3742,\n                        0.0627, -0.4675,  0.0369, -0.0037, -0.0009, -0.1552, -0.3252,  0.1126,\n                       -0.0813, -0.1334, -0.0397,  0.0121, -0.4569,  0.0020,  0.0579, -0.0761,\n                       -0.0701,  0.1742,  0.1421,  0.2877, -0.1195,  0.2504, -0.1827, -0.1944,\n                        0.1823, -0.1053,  0.2412, -0.1326,  0.0183, -0.0864, -0.1269, -0.2820,\n                       -0.1170,  0.1984, -0.3597, -0.0315,  0.0092,  0.1539, -0.1700,  0.1776,\n                        0.0676,  0.1467,  0.1997,  0.1534,  0.1128, -0.1385,  0.2878, -0.1661,\n                       -0.0754,  0.1031, -0.0560, -0.1274, -0.2321,  0.3218,  0.0562,  0.2870,\n                        0.2525, -0.2811, -0.0013, -0.1748, -0.1535,  0.1275, -0.0932, -0.0323,\n                        0.7140,  0.1760,  0.0986, -0.0916, -0.2768,  0.0744, -0.0617, -0.0897,\n                        0.1580,  0.0672, -0.2015, -0.1060,  0.0044, -0.2093, -0.2096,  0.1564,\n                       -0.1829,  0.2071,  0.0778, -0.1352, -0.0993, -0.1049, -0.0858, -0.2175,\n                       -0.1008,  0.1178,  0.0853,  0.0251,  0.2357, -0.0108, -0.0769, -0.2231,\n                       -0.1607, -0.0621, -0.1575, -0.1035, -0.1109,  0.3010,  0.1041,  0.0903,\n                       -0.1287, -0.2597,  0.1888, -0.0818,  0.0843,  0.1101, -0.0390,  0.3507,\n                       -0.0791, -0.0879,  0.0263,  0.1211,  0.0531,  0.1575, -0.0701,  0.0627,\n                       -0.1975, -0.1899, -0.1758, -0.1161, -0.3632,  0.1156,  0.1740,  0.0111,\n                       -0.1774, -0.1580, -0.0442, -0.2461, -0.2411, -0.0647,  0.5711, -0.2552])),\n              ('layer1.2.bn3.running_var',\n               tensor([0.1274, 0.0731, 0.1803, 0.1041, 0.0882, 0.1113, 0.0826, 0.1309, 0.1145,\n                       0.0618, 0.1564, 0.1463, 0.1634, 0.2033, 0.1031, 0.1590, 0.1399, 0.1512,\n                       0.1502, 0.0635, 0.1202, 0.1398, 0.0897, 0.0769, 0.0651, 0.1673, 0.1728,\n                       0.1292, 0.1235, 0.1434, 0.1816, 0.1234, 0.1061, 0.2048, 0.1005, 0.1794,\n                       0.1459, 0.1173, 0.1052, 0.1572, 0.0889, 0.1940, 0.0642, 0.0619, 0.1121,\n                       0.1966, 0.1524, 0.1860, 0.0953, 0.1338, 0.1523, 0.1717, 0.0956, 0.1963,\n                       0.1161, 0.2430, 0.1430, 0.1214, 0.0762, 0.0579, 0.1060, 0.1014, 0.1757,\n                       0.0994, 0.0936, 0.1349, 0.1359, 0.0865, 0.1338, 0.0671, 0.1244, 0.1548,\n                       0.2112, 0.0894, 0.0507, 0.1541, 0.1109, 0.1080, 0.0402, 0.0996, 0.0975,\n                       0.0682, 0.1257, 0.2242, 0.1484, 0.0819, 0.1524, 0.0811, 0.0782, 0.0975,\n                       0.1222, 0.2105, 0.0461, 0.1906, 0.2124, 0.0867, 0.1212, 0.1189, 0.1432,\n                       0.1131, 0.1174, 0.0967, 0.1407, 0.1425, 0.1168, 0.1175, 0.1069, 0.0618,\n                       0.1479, 0.1868, 0.1211, 0.2508, 0.0562, 0.1038, 0.0668, 0.0895, 0.1018,\n                       0.1428, 0.1165, 0.1069, 0.0613, 0.1314, 0.1026, 0.0754, 0.1117, 0.1548,\n                       0.0960, 0.0569, 0.1213, 0.0878, 0.1232, 0.1888, 0.1969, 0.2638, 0.1514,\n                       0.1979, 0.0728, 0.0850, 0.0865, 0.0869, 0.1195, 0.1423, 0.2550, 0.2652,\n                       0.0553, 0.1285, 0.1715, 0.1509, 0.0855, 0.1803, 0.0976, 0.0989, 0.0862,\n                       0.1176, 0.1122, 0.1283, 0.1625, 0.1076, 0.0848, 0.1079, 0.0713, 0.0814,\n                       0.1182, 0.1786, 0.1466, 0.1418, 0.1743, 0.0922, 0.1044, 0.1066, 0.0991,\n                       0.0996, 0.1673, 0.2010, 0.0966, 0.1485, 0.0724, 0.1508, 0.0982, 0.0582,\n                       0.0995, 0.1413, 0.0908, 0.0696, 0.2906, 0.0904, 0.1006, 0.0872, 0.2633,\n                       0.1924, 0.0740, 0.0492, 0.1545, 0.1490, 0.0844, 0.1141, 0.1084, 0.1020,\n                       0.1884, 0.1178, 0.2391, 0.1581, 0.1396, 0.2037, 0.1537, 0.1543, 0.0692,\n                       0.1409, 0.1008, 0.0994, 0.1652, 0.0769, 0.1464, 0.1398, 0.1173, 0.1479,\n                       0.1583, 0.2085, 0.1189, 0.1741, 0.0761, 0.1361, 0.0917, 0.1032, 0.1225,\n                       0.2118, 0.0911, 0.1719, 0.0489, 0.1150, 0.1119, 0.1191, 0.1153, 0.0855,\n                       0.1080, 0.1641, 0.1330, 0.0650, 0.0796, 0.0921, 0.3107, 0.0691, 0.1659,\n                       0.1499, 0.1052, 0.1392, 0.1297, 0.1623, 0.0842, 0.1038, 0.1088, 0.1045,\n                       0.2130, 0.1256, 0.2601, 0.1040])),\n              ('layer1.2.bn3.num_batches_tracked', tensor(13572)),\n              ('layer2.0.conv1.weight',\n               tensor([[[[-0.0648]],\n               \n                        [[-0.0189]],\n               \n                        [[-0.0509]],\n               \n                        ...,\n               \n                        [[-0.1173]],\n               \n                        [[ 0.0832]],\n               \n                        [[ 0.0498]]],\n               \n               \n                       [[[-0.0347]],\n               \n                        [[-0.0122]],\n               \n                        [[ 0.0066]],\n               \n                        ...,\n               \n                        [[ 0.0366]],\n               \n                        [[-0.0545]],\n               \n                        [[ 0.0640]]],\n               \n               \n                       [[[ 0.0441]],\n               \n                        [[-0.0188]],\n               \n                        [[ 0.0082]],\n               \n                        ...,\n               \n                        [[ 0.0175]],\n               \n                        [[-0.0974]],\n               \n                        [[ 0.1218]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.1064]],\n               \n                        [[ 0.0899]],\n               \n                        [[-0.0520]],\n               \n                        ...,\n               \n                        [[-0.0583]],\n               \n                        [[ 0.1617]],\n               \n                        [[-0.0349]]],\n               \n               \n                       [[[ 0.0223]],\n               \n                        [[-0.1071]],\n               \n                        [[-0.0291]],\n               \n                        ...,\n               \n                        [[-0.1134]],\n               \n                        [[-0.1689]],\n               \n                        [[-0.0704]]],\n               \n               \n                       [[[ 0.0145]],\n               \n                        [[ 0.0198]],\n               \n                        [[-0.0391]],\n               \n                        ...,\n               \n                        [[-0.0182]],\n               \n                        [[-0.0059]],\n               \n                        [[-0.0299]]]])),\n              ('layer2.0.bn1.weight',\n               tensor([1.0066, 1.0030, 0.8779, 0.9221, 0.8617, 0.9561, 1.0199, 0.8970, 0.8705,\n                       0.9476, 1.0377, 1.0293, 0.9858, 0.9766, 0.8426, 0.9014, 0.9527, 0.8853,\n                       1.0305, 1.0368, 1.1384, 0.9104, 1.0150, 1.0256, 0.9469, 1.0768, 0.9993,\n                       0.9201, 1.0368, 0.9650, 0.9928, 1.0023, 0.9369, 1.1098, 0.9963, 1.0758,\n                       0.8904, 0.9184, 0.9710, 0.9979, 1.0568, 0.8710, 1.0005, 0.9298, 1.0490,\n                       0.9474, 1.1242, 1.0232, 0.9783, 1.0187, 1.1035, 0.9624, 0.9314, 1.0113,\n                       1.5679, 0.9954, 0.8841, 0.9979, 0.9507, 0.8921, 1.0030, 0.8473, 0.9338,\n                       1.0883, 0.8728, 0.9732, 1.0362, 0.9901, 0.9609, 0.9336, 1.0029, 0.9405,\n                       1.0692, 0.8930, 0.9252, 1.0183, 1.0506, 0.9102, 0.9821, 0.9134, 1.0144,\n                       0.9667, 0.9776, 0.9987, 0.9562, 1.5599, 1.0230, 1.0268, 0.9956, 0.9346,\n                       1.0988, 0.9270, 0.8335, 0.8577, 0.9423, 0.9605, 0.8682, 1.0006, 0.9910,\n                       0.9552, 0.9794, 0.9582, 0.9110, 1.0731, 0.9740, 0.9402, 0.9953, 0.9608,\n                       0.9646, 0.9570, 0.9744, 1.0028, 1.0663, 0.9796, 0.9499, 0.9673, 0.9685,\n                       1.0724, 1.0349, 1.2255, 1.0007, 0.9676, 1.0164, 1.0045, 0.9377, 1.1112,\n                       0.9492, 0.9627])),\n              ('layer2.0.bn1.bias',\n               tensor([-3.7719e-02,  6.1852e-02, -7.6893e-03,  4.3763e-03,  2.6164e-02,\n                       -2.5673e-02,  9.4374e-02, -1.2506e-02, -2.2365e-02, -9.7956e-02,\n                        5.2357e-02, -9.1054e-02,  1.2786e-01,  1.5432e-01, -3.5471e-02,\n                        9.1104e-03, -9.1730e-02, -1.0200e-01, -1.5013e-01, -1.4168e-01,\n                        8.5713e-02, -1.6759e-01, -3.2426e-02, -6.2226e-02, -1.2957e-01,\n                       -9.0142e-02,  1.0672e-01, -1.4979e-01, -1.7682e-01, -7.3575e-02,\n                       -5.4815e-02, -1.2666e-02,  6.5952e-03,  4.1505e-02,  1.3079e-01,\n                        1.4624e-02, -7.4708e-02,  4.9665e-02,  5.1759e-02, -8.1337e-03,\n                       -7.8665e-05, -6.7393e-02, -4.3554e-02, -1.8681e-01, -1.0762e-01,\n                       -1.9018e-01, -2.0430e-01,  2.8553e-02, -2.7946e-02,  4.4625e-02,\n                        1.7751e-01, -1.3975e-02, -2.3945e-01,  3.2327e-02,  1.6489e-02,\n                       -4.0572e-04,  5.8716e-02, -1.9384e-01,  1.0746e-01, -6.8395e-02,\n                       -4.3897e-02, -2.4360e-02, -1.0706e-01,  1.3032e-01, -3.0111e-02,\n                       -8.0384e-03, -6.1209e-02, -1.6887e-01,  1.3890e-02, -5.2663e-03,\n                       -7.5254e-02,  3.1515e-02,  7.1801e-02,  2.3920e-02, -7.5193e-02,\n                       -7.6823e-02, -1.5083e-01, -1.1063e-01, -2.4761e-02,  5.1774e-02,\n                       -5.9536e-02,  9.7208e-02,  1.0120e-01, -3.5952e-02,  3.6088e-02,\n                       -1.6200e-01,  1.1207e-01, -1.1536e-01, -9.2013e-02,  5.1890e-03,\n                        2.0021e-01,  7.8195e-02, -6.5429e-02, -4.3779e-02, -9.2392e-02,\n                        4.5146e-02, -6.4778e-02, -5.7490e-02, -6.6309e-02, -4.0272e-02,\n                       -2.8712e-01, -4.9839e-02,  4.4353e-02, -7.8171e-02, -6.0798e-02,\n                       -4.4145e-02, -7.7737e-02,  3.5016e-02, -5.8501e-02,  5.6100e-02,\n                       -4.1780e-02, -1.7695e-01, -1.1192e-01, -4.2667e-02,  1.2119e-02,\n                       -4.0506e-02, -2.0298e-01,  4.8314e-02,  8.0080e-05, -4.2683e-02,\n                       -4.3269e-02, -1.3053e-02,  9.8955e-03, -7.3633e-02,  2.6687e-02,\n                       -4.2923e-01,  1.0845e-01, -6.2228e-02])),\n              ('layer2.0.bn1.running_mean',\n               tensor([-2.9522e+00, -8.0527e-01, -9.7572e-01, -1.3696e+00,  5.3795e-01,\n                        4.3053e-02, -9.2329e-01, -4.5927e-01, -1.5235e-01,  1.1034e-02,\n                        3.6923e-01, -2.8531e+00, -1.4139e+00, -1.3590e+00, -8.2375e-01,\n                       -1.6955e-01,  2.9018e-04,  1.5331e-01,  3.0413e-01, -6.1236e-02,\n                        1.5575e-01,  6.8151e-01, -7.6172e-01, -1.7788e+00, -7.5058e-01,\n                       -1.1134e+00, -1.2264e+00, -1.4068e+00,  1.1226e+00, -1.5615e+00,\n                       -1.5877e-01, -1.7858e+00, -1.8653e+00, -3.4531e+00, -2.4287e+00,\n                       -1.0950e+00,  6.9991e-01, -1.6198e+00, -7.0055e-01, -4.6776e+00,\n                       -1.4613e+00, -1.6548e+00,  1.0452e+00,  1.4070e+00,  9.2002e-01,\n                        2.6316e-01,  2.6911e-01, -1.5790e+00,  4.6398e-01, -1.1115e+00,\n                       -8.4101e-01, -1.8928e+00, -7.8963e-01, -1.1753e+00, -3.7584e-01,\n                        4.7924e-01,  1.2444e+00,  2.2026e-01, -1.9478e+00,  5.9286e-01,\n                        2.2954e+00,  3.7692e-01, -1.2229e+00, -1.5473e+00, -5.5079e-01,\n                       -2.0692e+00, -2.0653e+00, -1.1876e+00, -2.5642e-01, -1.0885e+00,\n                        6.7461e-01, -1.8314e+00, -2.3306e+00,  3.6848e+00, -1.6653e-01,\n                        2.4560e-01,  3.5501e-01,  1.5338e+00,  1.5619e+00, -6.3839e-01,\n                       -3.4284e-01, -1.5043e+00,  1.8087e-01, -1.2541e+00,  6.4551e-01,\n                        8.4412e-02, -9.7426e-01, -4.4361e-01, -1.6239e+00, -2.0866e+00,\n                       -1.4909e+00, -1.6870e+00, -8.8681e-01,  1.6213e+00, -1.6825e+00,\n                       -2.2097e-01, -1.9684e+00, -6.8231e-01, -2.8218e+00, -1.1098e+00,\n                        3.9026e-01, -2.1711e+00, -5.5467e-01, -1.6688e+00,  4.2299e-01,\n                       -9.7070e-01, -1.3084e+00,  1.4410e+00, -1.7322e+00, -1.7187e+00,\n                       -1.5540e-01, -1.9774e+00, -2.7756e+00,  3.1696e-01, -2.7777e+00,\n                       -2.7650e+00, -8.2204e-01, -1.2152e+00, -1.7917e+00, -4.6375e-01,\n                       -2.9379e-01, -8.5401e-01, -1.3187e+00, -5.4034e-01, -1.7685e+00,\n                        1.3183e-01, -1.2790e+00, -2.3339e+00])),\n              ('layer2.0.bn1.running_var',\n               tensor([1.0683, 1.1859, 0.7244, 0.9595, 0.7141, 0.8052, 1.3360, 0.7906, 0.5777,\n                       0.7388, 1.2427, 1.4318, 0.9728, 0.8721, 0.9103, 0.7405, 0.8609, 0.8856,\n                       0.9373, 0.9589, 1.2407, 0.8339, 0.9124, 1.2303, 1.0636, 1.0597, 0.8725,\n                       1.1482, 0.8619, 1.0365, 1.0262, 1.1821, 0.8181, 1.5573, 1.1413, 1.3659,\n                       0.5873, 0.5334, 0.7470, 1.7878, 1.4364, 0.8590, 1.0431, 0.7415, 0.8728,\n                       0.8867, 1.3267, 1.4202, 1.0011, 1.2786, 1.1531, 0.8159, 0.5228, 1.0217,\n                       2.3237, 0.8100, 0.6476, 1.0140, 1.1753, 0.9263, 0.7840, 0.6232, 0.7537,\n                       0.8457, 0.9179, 0.8923, 1.1706, 0.6101, 0.9093, 1.1670, 0.9842, 0.8952,\n                       1.4771, 0.8322, 0.6517, 1.2544, 0.8105, 0.6219, 1.4030, 0.8412, 0.7581,\n                       1.2372, 0.8006, 1.2953, 0.7206, 2.4866, 1.2025, 1.4746, 0.7939, 0.8397,\n                       1.5795, 0.9191, 0.5171, 0.7226, 0.8043, 1.0147, 0.6123, 1.0020, 0.9463,\n                       0.9835, 1.2300, 1.1071, 0.8729, 1.1160, 0.9590, 0.6821, 0.8437, 0.8273,\n                       1.0906, 1.2272, 1.1127, 1.1512, 1.1069, 1.2950, 1.0774, 1.0422, 0.5605,\n                       1.1532, 1.2993, 1.1507, 1.2085, 1.1880, 1.5595, 0.8651, 0.8615, 0.6843,\n                       1.2495, 1.0401])),\n              ('layer2.0.bn1.num_batches_tracked', tensor(13572)),\n              ('layer2.0.conv2.weight',\n               tensor([[[[-0.0978, -0.0687, -0.0587],\n                         [ 0.0022, -0.0087, -0.0301],\n                         [ 0.0371,  0.0667, -0.0061]],\n               \n                        [[ 0.0151, -0.0437, -0.0982],\n                         [ 0.0082, -0.0032,  0.0100],\n                         [ 0.0148,  0.0884,  0.0618]],\n               \n                        [[ 0.0104,  0.0110,  0.0041],\n                         [ 0.0241,  0.0193,  0.0132],\n                         [ 0.0319,  0.0212, -0.0465]],\n               \n                        ...,\n               \n                        [[-0.0370, -0.0180, -0.0119],\n                         [ 0.0049, -0.0198, -0.0557],\n                         [-0.0423, -0.0056, -0.0430]],\n               \n                        [[ 0.0089,  0.0205, -0.0349],\n                         [ 0.0517, -0.0168, -0.0172],\n                         [ 0.0311, -0.0244, -0.0022]],\n               \n                        [[ 0.0184, -0.0288, -0.0160],\n                         [-0.0041, -0.0090, -0.0112],\n                         [ 0.0367,  0.0286, -0.0042]]],\n               \n               \n                       [[[ 0.0011,  0.0255,  0.0021],\n                         [ 0.0623,  0.0093, -0.0096],\n                         [ 0.0004,  0.0194,  0.0404]],\n               \n                        [[ 0.0140,  0.0186,  0.0252],\n                         [-0.0023,  0.0181,  0.0439],\n                         [-0.0157,  0.0141,  0.0196]],\n               \n                        [[-0.0081,  0.0238,  0.0036],\n                         [ 0.0087,  0.0428,  0.0698],\n                         [-0.0230,  0.0215,  0.0023]],\n               \n                        ...,\n               \n                        [[-0.0315, -0.0231, -0.0050],\n                         [-0.0916, -0.0455, -0.0061],\n                         [-0.0173, -0.0565, -0.0169]],\n               \n                        [[ 0.0122,  0.0970,  0.0289],\n                         [ 0.0320, -0.0049, -0.0575],\n                         [ 0.0057,  0.0184,  0.0066]],\n               \n                        [[-0.0203,  0.0396,  0.0443],\n                         [-0.0141,  0.0249,  0.0148],\n                         [-0.0649, -0.0650, -0.0274]]],\n               \n               \n                       [[[-0.0222, -0.0384,  0.0370],\n                         [ 0.0229, -0.0793,  0.0644],\n                         [ 0.0199,  0.0614,  0.1208]],\n               \n                        [[ 0.0208,  0.0911,  0.0683],\n                         [ 0.0633, -0.0368,  0.0782],\n                         [ 0.0031,  0.0402,  0.0196]],\n               \n                        [[-0.0126,  0.0107,  0.0241],\n                         [ 0.0708,  0.0115,  0.0179],\n                         [ 0.0436,  0.0694,  0.0626]],\n               \n                        ...,\n               \n                        [[ 0.0026,  0.0402,  0.0492],\n                         [-0.0103, -0.0002,  0.0204],\n                         [-0.0457, -0.0062, -0.0408]],\n               \n                        [[ 0.0030, -0.0487, -0.0348],\n                         [-0.0424, -0.0259, -0.0298],\n                         [-0.0421, -0.0563, -0.0497]],\n               \n                        [[ 0.0195,  0.0256,  0.0355],\n                         [ 0.0254,  0.0205,  0.0633],\n                         [-0.0192,  0.0156,  0.0626]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0194,  0.0278,  0.0238],\n                         [ 0.0393, -0.0377, -0.0503],\n                         [-0.0402,  0.0048, -0.0464]],\n               \n                        [[ 0.0089,  0.0033,  0.0466],\n                         [-0.0058, -0.0342,  0.0404],\n                         [ 0.0049, -0.0195,  0.0390]],\n               \n                        [[ 0.0283, -0.0633, -0.0026],\n                         [-0.0131, -0.0236, -0.0119],\n                         [ 0.0369,  0.0019,  0.0228]],\n               \n                        ...,\n               \n                        [[-0.0464,  0.0192,  0.0653],\n                         [-0.0021, -0.0312, -0.0062],\n                         [ 0.0585,  0.0142,  0.0075]],\n               \n                        [[ 0.0619,  0.0323, -0.0033],\n                         [ 0.0345,  0.0178, -0.0665],\n                         [-0.0385,  0.0113, -0.0216]],\n               \n                        [[ 0.0110, -0.0184, -0.0039],\n                         [ 0.0632,  0.0349, -0.0544],\n                         [ 0.0271, -0.0234,  0.0172]]],\n               \n               \n                       [[[ 0.0508,  0.0462,  0.0101],\n                         [ 0.0019,  0.0100,  0.0030],\n                         [-0.0131, -0.0202, -0.0354]],\n               \n                        [[-0.0023,  0.0172,  0.0075],\n                         [ 0.0075, -0.1232, -0.0466],\n                         [ 0.0349,  0.0408,  0.0537]],\n               \n                        [[ 0.0242, -0.0247,  0.0340],\n                         [ 0.0676, -0.0135,  0.0073],\n                         [-0.0508,  0.0563, -0.0063]],\n               \n                        ...,\n               \n                        [[-0.0301,  0.0382,  0.0267],\n                         [-0.0018,  0.0696,  0.0165],\n                         [-0.0218,  0.0321,  0.0091]],\n               \n                        [[ 0.0174, -0.0055,  0.0041],\n                         [ 0.0412, -0.0013,  0.0520],\n                         [ 0.0440,  0.0807,  0.0731]],\n               \n                        [[-0.0326, -0.0219,  0.0084],\n                         [-0.0302, -0.0183,  0.0103],\n                         [ 0.0084,  0.0033,  0.0140]]],\n               \n               \n                       [[[ 0.0368, -0.0066, -0.0577],\n                         [-0.0130, -0.0290,  0.0120],\n                         [-0.0513, -0.0102,  0.0624]],\n               \n                        [[ 0.0003,  0.0020,  0.0265],\n                         [ 0.0205,  0.0490, -0.0209],\n                         [ 0.0352,  0.0271,  0.0345]],\n               \n                        [[-0.0025,  0.0279,  0.0658],\n                         [-0.0250, -0.0132,  0.0139],\n                         [ 0.0209, -0.0146, -0.0167]],\n               \n                        ...,\n               \n                        [[-0.0310, -0.0062, -0.0566],\n                         [-0.0401,  0.0400,  0.0360],\n                         [-0.0156,  0.0288,  0.0356]],\n               \n                        [[ 0.0778, -0.0252, -0.0364],\n                         [-0.0342, -0.0743, -0.0766],\n                         [-0.0332,  0.0005, -0.0176]],\n               \n                        [[-0.0147, -0.0439, -0.0039],\n                         [ 0.0465,  0.0208,  0.0555],\n                         [ 0.0912,  0.0622,  0.0800]]]])),\n              ('layer2.0.bn2.weight',\n               tensor([1.0744, 0.9856, 1.0396, 0.9172, 0.9596, 0.9008, 0.9731, 0.8809, 1.0229,\n                       0.9800, 0.9300, 0.9211, 0.8740, 1.0631, 1.0741, 0.9478, 0.9776, 0.9208,\n                       1.0208, 1.0510, 0.9552, 0.9646, 0.9682, 1.0045, 1.0669, 0.9909, 0.9794,\n                       0.8828, 0.9710, 0.9511, 1.1035, 0.9512, 1.0011, 1.0393, 0.9298, 1.0072,\n                       0.9485, 1.0192, 1.0666, 0.9904, 0.8904, 0.9101, 0.9661, 0.9459, 1.1593,\n                       0.9213, 1.1002, 0.9833, 1.0019, 0.9673, 1.2651, 1.0947, 1.0309, 1.0267,\n                       0.9371, 0.9097, 0.9852, 0.9976, 0.8825, 0.9957, 1.0874, 0.8591, 1.0219,\n                       0.9397, 0.9880, 0.9739, 0.9832, 1.0437, 0.9481, 1.1358, 0.9728, 0.9016,\n                       1.0592, 0.9929, 1.0049, 0.9632, 0.9851, 1.0000, 0.9482, 1.0312, 1.1157,\n                       0.9573, 0.9906, 0.9348, 0.9535, 1.0541, 0.9688, 0.9420, 1.0236, 0.9660,\n                       0.8462, 1.0069, 1.0097, 0.9965, 0.9515, 0.9626, 1.0086, 0.9149, 0.9971,\n                       0.9325, 0.9719, 1.0689, 1.1559, 1.0766, 1.0438, 1.0650, 1.0239, 1.0339,\n                       0.9477, 1.0117, 0.9868, 0.9863, 1.0061, 0.9663, 0.9047, 0.9378, 1.0522,\n                       0.8425, 1.0592, 0.9883, 1.0966, 1.0634, 0.9692, 0.9595, 0.9785, 1.0664,\n                       0.9805, 0.8904])),\n              ('layer2.0.bn2.bias',\n               tensor([-0.0023,  0.0385,  0.2569,  0.0572,  0.0990,  0.0311, -0.0433,  0.0874,\n                        0.0406, -0.0009, -0.0030,  0.1067,  0.1729,  0.0240,  0.0187,  0.1199,\n                        0.1134,  0.1330,  0.2389,  0.1390,  0.1549,  0.3198,  0.1490,  0.1361,\n                       -0.0201,  0.1669,  0.1484,  0.0532,  0.1805,  0.1295, -0.0041,  0.1616,\n                        0.1774,  0.0060,  0.0850,  0.0004,  0.0832,  0.0225, -0.0575,  0.0987,\n                        0.0872,  0.1260,  0.1467,  0.0758,  0.0923,  0.1257, -0.0443, -0.1126,\n                       -0.1476, -0.0526, -0.0591, -0.1191,  0.0495,  0.2729,  0.2025,  0.0434,\n                       -0.0167,  0.1864,  0.1419,  0.1604, -0.0603, -0.0306,  0.0127, -0.0894,\n                       -0.1163, -0.0005,  0.0433, -0.0873,  0.0582,  0.0299,  0.0944, -0.0139,\n                       -0.0201,  0.0344,  0.0553, -0.0267,  0.0709, -0.0987,  0.1781, -0.0461,\n                       -0.1240, -0.0525,  0.2016,  0.1850, -0.0970,  0.0234,  0.1438,  0.1041,\n                        0.1016,  0.0107,  0.0786,  0.0651,  0.0175,  0.2371,  0.0648, -0.0386,\n                       -0.0333,  0.1996, -0.0505, -0.0058,  0.0486, -0.1093, -0.1848, -0.0925,\n                        0.0276,  0.1181,  0.3167, -0.0412,  0.1160,  0.0362,  0.2817,  0.1597,\n                        0.2228, -0.1110,  0.2918,  0.1418, -0.0895, -0.1084,  0.2979,  0.1390,\n                       -0.1839,  0.0131,  0.2263, -0.0267,  0.1709, -0.1951,  0.1445, -0.0037])),\n              ('layer2.0.bn2.running_mean',\n               tensor([-0.3982, -1.4109, -0.8807, -0.6701, -0.3903, -0.6495, -0.0706, -0.3585,\n                        1.0717,  0.0287,  0.7220, -0.7408,  0.9049, -0.3028,  0.0471, -0.5856,\n                       -0.0219, -0.5854,  0.3759,  0.2039, -0.1714, -0.8401, -0.7495, -0.2323,\n                       -0.1742,  0.4100, -1.0761,  0.2599, -0.6289,  0.2480, -0.3550,  2.1322,\n                       -0.8217,  0.0947,  1.0018,  0.4624, -0.2714,  0.9598,  0.3329, -0.0818,\n                       -0.3569, -1.2364, -0.2276,  0.4572,  0.7672, -0.3710,  0.2513,  0.2537,\n                        0.2406,  0.2920, -0.3486, -0.3179, -0.8611, -0.1532,  0.1127, -0.7980,\n                       -0.7942, -0.9963, -0.2640, -0.8571,  0.2235,  0.6752, -0.0907,  0.3066,\n                        0.0623,  0.4368, -0.5507,  0.5292, -0.7273, -0.6098,  0.5325,  1.0522,\n                       -0.4122, -0.1659, -0.9027,  0.8648, -0.5966,  0.2808, -0.2857, -1.3053,\n                        0.4328,  0.3275,  0.4195,  0.0969,  0.2239,  0.0762,  0.0351, -0.3087,\n                        0.1880, -0.5588,  0.9264, -0.3128, -0.3769,  0.5523, -0.8304,  0.2148,\n                       -2.0240,  1.1851, -0.2633, -0.1301, -0.1768,  0.2239,  0.1420, -0.0402,\n                       -0.6589, -0.6330,  0.1802, -0.3598,  0.0931, -0.4525, -0.8366, -0.7326,\n                       -1.4173,  0.1813, -1.0732, -0.2975, -0.4975, -0.6993, -0.6679,  0.0601,\n                        0.5337, -1.9491,  0.3923,  0.4876, -0.7854,  0.3835,  0.2099, -0.3562])),\n              ('layer2.0.bn2.running_var',\n               tensor([1.1457, 2.9248, 1.4042, 0.9694, 1.2908, 1.2020, 1.3336, 0.8489, 1.3020,\n                       1.6372, 1.2759, 1.1551, 1.3861, 1.5243, 0.9091, 2.0933, 1.0379, 0.9830,\n                       1.2192, 0.9282, 0.9534, 1.2182, 1.1671, 1.1517, 1.3349, 1.2698, 1.5597,\n                       0.8573, 1.0380, 0.9310, 1.8204, 0.9946, 1.8220, 0.9994, 1.1380, 1.1966,\n                       0.9483, 1.8335, 1.6119, 1.3045, 1.2297, 1.3301, 1.4639, 1.1679, 2.5689,\n                       0.7997, 1.6976, 1.3775, 1.8035, 1.7606, 5.6659, 1.4725, 2.8353, 1.6438,\n                       1.4794, 1.0025, 1.1960, 1.9437, 1.1393, 2.0816, 1.9066, 1.0152, 1.2413,\n                       1.4089, 1.5973, 1.3527, 1.1769, 1.8317, 2.0843, 3.5690, 1.2706, 0.9955,\n                       1.3608, 1.3720, 1.3565, 1.0542, 2.2326, 1.3566, 1.8068, 2.3493, 1.9447,\n                       1.4062, 1.2852, 1.1478, 1.0756, 2.4329, 1.1071, 1.3519, 1.1520, 1.0843,\n                       1.1166, 1.1832, 1.2324, 1.0284, 1.0262, 1.1389, 2.2161, 1.5811, 1.3557,\n                       1.4897, 1.0925, 1.8368, 2.1452, 1.1224, 1.0469, 1.1491, 1.4800, 1.2821,\n                       1.8326, 1.1932, 1.4523, 1.0030, 1.7846, 1.3613, 1.0660, 0.9114, 1.6967,\n                       0.9919, 1.7739, 1.2014, 2.1439, 2.7023, 1.4003, 1.0260, 0.8089, 1.2326,\n                       1.0508, 1.1927])),\n              ('layer2.0.bn2.num_batches_tracked', tensor(13572)),\n              ('layer2.0.conv3.weight',\n               tensor([[[[-0.0151]],\n               \n                        [[-0.0027]],\n               \n                        [[-0.0932]],\n               \n                        ...,\n               \n                        [[ 0.0179]],\n               \n                        [[-0.0701]],\n               \n                        [[ 0.0902]]],\n               \n               \n                       [[[ 0.0448]],\n               \n                        [[ 0.0029]],\n               \n                        [[ 0.0640]],\n               \n                        ...,\n               \n                        [[ 0.0167]],\n               \n                        [[ 0.0123]],\n               \n                        [[ 0.0611]]],\n               \n               \n                       [[[ 0.0207]],\n               \n                        [[-0.0400]],\n               \n                        [[ 0.0106]],\n               \n                        ...,\n               \n                        [[-0.0199]],\n               \n                        [[-0.0451]],\n               \n                        [[ 0.0343]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0322]],\n               \n                        [[ 0.0338]],\n               \n                        [[-0.0804]],\n               \n                        ...,\n               \n                        [[ 0.0878]],\n               \n                        [[-0.0890]],\n               \n                        [[-0.0606]]],\n               \n               \n                       [[[ 0.0530]],\n               \n                        [[ 0.0413]],\n               \n                        [[ 0.0774]],\n               \n                        ...,\n               \n                        [[-0.0046]],\n               \n                        [[ 0.0743]],\n               \n                        [[-0.0252]]],\n               \n               \n                       [[[-0.0178]],\n               \n                        [[ 0.0477]],\n               \n                        [[-0.0977]],\n               \n                        ...,\n               \n                        [[ 0.0104]],\n               \n                        [[ 0.0609]],\n               \n                        [[-0.0060]]]])),\n              ('layer2.0.bn3.weight',\n               tensor([ 0.3701,  0.2254, -0.2010,  0.5020, -0.1159,  0.4381, -0.4087,  0.1354,\n                       -0.3562,  0.4299,  0.0573,  0.2591,  0.1864,  0.4060,  0.3392,  0.4688,\n                       -0.3329,  0.4805,  0.4958,  0.2686, -0.3483,  0.4172, -0.0059,  0.0422,\n                       -0.2609,  0.4111, -0.1674,  0.4455, -0.4326,  0.4163,  0.4322, -0.4898,\n                       -0.2954, -0.3525, -0.4196,  0.5168, -0.3435,  0.4520,  0.2878, -0.4292,\n                       -0.4540,  0.3424, -0.4173, -0.2961, -0.3335, -0.3236,  0.0070, -0.3695,\n                       -0.1240, -0.1357,  0.1041, -0.1846, -0.0163, -0.2021,  0.1969, -0.2040,\n                       -0.4790,  0.2645, -0.4497, -0.4029, -0.0367,  0.2510, -0.4043, -0.2199,\n                       -0.2154, -0.2921,  0.3545, -0.2279, -0.2995, -0.4125, -0.3460,  0.0194,\n                       -0.1487, -0.3158, -0.3714, -0.2796,  0.2973,  0.2991,  0.4756, -0.4432,\n                       -0.5183,  0.0820,  0.3069,  0.4148,  0.4411, -0.3817, -0.4529,  0.1015,\n                       -0.4238, -0.3775,  0.1360, -0.3588,  0.3860, -0.3192, -0.2955, -0.2200,\n                        0.4585, -0.3254, -0.2691,  0.5145,  0.0374,  0.2345,  0.1744,  0.2195,\n                        0.4697,  0.4543,  0.3690, -0.4490,  0.1638,  0.2688, -0.4350, -0.3459,\n                        0.3379,  0.2395, -0.3555, -0.3548, -0.2930, -0.1250,  0.3821, -0.4116,\n                       -0.2515, -0.2549, -0.3961,  0.2539, -0.2984,  0.3944, -0.3630, -0.0591,\n                       -0.3913, -0.3416, -0.3555, -0.4502,  0.3358, -0.3382,  0.3810,  0.3030,\n                        0.2721,  0.2665, -0.4595,  0.1361,  0.4852, -0.2651, -0.4171, -0.1991,\n                        0.3684, -0.4017,  0.1113, -0.3701, -0.4179,  0.4408,  0.0521, -0.1544,\n                       -0.2637, -0.2205, -0.2873,  0.3651,  0.0732, -0.2280,  0.3365, -0.4752,\n                       -0.4146,  0.4018,  0.4242,  0.3271, -0.2863,  0.4686,  0.3456,  0.0610,\n                       -0.4216,  0.6948, -0.3612, -0.2116, -0.4203, -0.2871, -0.3031, -0.0153,\n                        0.2645, -0.2173,  0.2604, -0.2966, -0.3731,  0.4173,  0.1722, -0.5126,\n                       -0.1246, -0.1937, -0.1818,  0.1177, -0.3323, -0.2920, -0.5008, -0.5217,\n                       -0.2533, -0.5033, -0.1773,  0.1169,  0.3874, -0.3543,  0.1458,  0.3847,\n                       -0.3144,  0.3597, -0.3418,  0.2449, -0.2060,  0.2785,  0.3271,  0.2372,\n                       -0.5325,  0.1545, -0.2503, -0.4785, -0.3950,  0.3609, -0.3237,  0.3124,\n                       -0.3310,  0.4323, -0.0763,  0.1085, -0.1878, -0.2244,  0.1069, -0.2006,\n                       -0.0076,  0.2196,  0.1640, -0.1272, -0.1854, -0.2198, -0.5500, -0.5799,\n                        0.3044, -0.3546, -0.0972,  0.0399,  0.3158,  0.0009, -0.2170, -0.3089,\n                        0.2403, -0.0966, -0.3820,  0.4616,  0.5055, -0.2906,  0.4486, -0.3320,\n                       -0.4230, -0.7002,  0.3482,  0.2950, -0.2909,  0.4078,  0.0980, -0.0736,\n                        0.3448,  0.3873, -0.4149,  0.1588,  0.3935, -0.2818, -0.1079,  0.4148,\n                       -0.4661,  0.0626,  0.0776,  0.3012,  0.2480,  0.1268, -0.2085, -0.4388,\n                       -0.1252, -0.3730, -0.2419, -0.3567, -0.4146,  0.2278, -0.1486,  0.1108,\n                        0.1982,  0.3344, -0.3790,  0.3926, -0.4156,  0.0176, -0.4892,  0.3315,\n                        0.2707, -0.2699,  0.7121,  0.2966,  0.0428,  0.5115, -0.2090, -0.4859,\n                       -0.1746,  0.2847,  0.2451,  0.3087,  0.3360, -0.3595,  0.2338, -0.3324,\n                        0.2926,  0.1297, -0.1694, -0.3670,  0.0963,  0.1989, -0.3365, -0.1244,\n                        0.0337,  0.0774,  0.3487, -0.4326, -0.3062,  0.3069, -0.0694, -0.4142,\n                       -0.3985,  0.3786, -0.3823, -0.2195, -0.1397,  0.3413, -0.3325, -0.3399,\n                       -0.1975, -0.2666, -0.2681,  0.4648, -0.4129, -0.2373,  0.4353, -0.4589,\n                       -0.0966,  0.3536, -0.3492, -0.3968, -0.3944,  0.2167, -0.2883,  0.2554,\n                        0.2753,  0.2574, -0.4835, -0.2702, -0.3919,  0.2750, -0.5269,  0.2974,\n                        0.0080,  0.4274, -0.2041,  0.2688, -0.0891,  0.6263, -0.1758,  0.0629,\n                        0.3114,  0.3771, -0.4536,  0.4098, -0.5436,  0.3006,  0.1951,  0.3043,\n                        0.2906, -0.4189,  0.3645, -0.3332, -0.4035,  0.3125,  0.3347, -0.0878,\n                       -0.2957,  0.4835,  0.3448, -0.2306,  0.4612,  0.1129,  0.1989, -0.2811,\n                        0.2071, -0.4115, -0.4109, -0.2168, -0.2716, -0.2548,  0.2438,  0.2759,\n                       -0.4033, -0.4005,  0.1793,  0.2248,  0.0219, -0.1783,  0.3498,  0.1495,\n                        0.4132, -0.2822, -0.3564,  0.4333,  0.5325, -0.4729,  0.1319,  0.3290,\n                        0.3363,  0.4438, -0.2439, -0.4748,  0.2956,  0.2936,  0.4582, -0.1389,\n                        0.1890, -0.2656, -0.5524,  0.3827, -0.1474, -0.2785, -0.7271,  0.3141,\n                       -0.3506,  0.1043,  0.5772,  0.3980, -0.3044,  0.2021, -0.3745, -0.2756,\n                        0.5432, -0.3417, -0.1482, -0.1596,  0.3896, -0.4975,  0.4220, -0.4281,\n                       -0.4322, -0.2265,  0.4207,  0.4219,  0.1139, -0.2953,  0.2926, -0.2791,\n                       -0.4155,  0.3059, -0.2310, -0.1932, -0.3294,  0.3941, -0.5404, -0.2987,\n                       -0.2311,  0.4330, -0.3967, -0.2306,  0.4779, -0.4113, -0.0168,  0.4170,\n                       -0.3562,  0.4337, -0.1208,  0.3012, -0.1189,  0.3769,  0.4008,  0.3687,\n                       -0.5135,  0.2901,  0.0636, -0.3847, -0.1869, -0.3622,  0.4452, -0.4807,\n                       -0.3661,  0.4604,  0.2275, -0.3903,  0.5073,  0.3873,  0.4435, -0.3958,\n                        0.3041,  0.4956, -0.3566, -0.4097, -0.4639,  0.3104, -0.2274, -0.3506,\n                        0.0302, -0.4695, -0.3634,  0.2146,  0.1112, -0.0592,  0.3049,  0.4435,\n                       -0.3592,  0.3700, -0.3921, -0.0914, -0.2521,  0.3033, -0.5127,  0.0330])),\n              ('layer2.0.bn3.bias',\n               tensor([ 7.2772e-02, -6.8790e-02,  4.4726e-02,  9.4366e-02,  1.7202e-02,\n                       -7.2461e-02, -1.9011e-02, -1.1996e-02, -2.8966e-02,  1.0434e-01,\n                       -3.9463e-02, -1.0471e-02,  9.7917e-03,  7.0516e-02,  2.4386e-04,\n                        7.7913e-02, -5.8665e-02,  1.3884e-01,  3.0873e-02, -7.3724e-02,\n                       -3.6645e-02,  3.5817e-02, -7.6026e-02, -4.5021e-02, -1.1793e-01,\n                        8.7404e-02, -5.4016e-02, -3.2672e-03,  1.5345e-01,  4.9387e-02,\n                        1.7085e-01,  9.4239e-02, -4.6989e-02,  4.9129e-02,  1.1779e-01,\n                        2.3703e-01,  4.5512e-02, -2.1395e-02, -1.0035e-01,  1.1968e-01,\n                        5.6978e-02,  5.6118e-02, -2.5819e-02, -2.9769e-02,  9.6195e-02,\n                        1.4522e-01, -1.1747e-02,  4.7371e-02, -6.5386e-02, -1.2394e-01,\n                       -6.7362e-02, -2.3442e-02, -6.3688e-02, -1.0101e-01,  5.1386e-02,\n                        1.2020e-02,  2.4666e-01,  3.6687e-02,  1.4761e-01, -7.3567e-02,\n                       -1.3175e-01,  9.6796e-02,  7.7306e-02, -7.7757e-02,  7.4445e-02,\n                        4.0937e-02, -2.0895e-02, -2.6817e-02,  4.0703e-02,  7.7672e-02,\n                        2.9121e-02, -1.3746e-02, -1.2551e-02, -2.0551e-02,  1.6204e-01,\n                       -1.1041e-01,  5.6710e-02,  1.3259e-02,  1.2201e-01,  1.7871e-01,\n                        5.5292e-02, -5.6783e-02, -2.0994e-02,  1.9898e-01,  5.7359e-02,\n                       -8.4766e-02,  4.3711e-02, -1.9782e-01,  4.0865e-02,  2.4604e-01,\n                       -7.7729e-02,  8.1093e-02,  9.5030e-02,  6.5134e-02,  1.2296e-01,\n                        2.7609e-02, -6.5488e-02,  1.5753e-03, -3.4012e-02,  2.0746e-01,\n                       -1.0347e-01, -1.3011e-01, -6.1559e-02, -6.5992e-02, -1.2152e-01,\n                       -4.7670e-02, -4.4360e-02,  1.0757e-02, -8.2507e-02, -4.8127e-02,\n                        1.0880e-01, -1.0767e-01,  8.5057e-02, -1.0043e-02, -4.2895e-02,\n                        1.6038e-02, -5.2530e-02, -7.8919e-02, -1.9300e-02,  6.2578e-02,\n                       -1.3458e-01, -9.1208e-02,  3.5881e-02, -7.1067e-02, -6.6957e-02,\n                        6.2160e-02,  1.3790e-01, -6.2705e-02,  1.2616e-01,  8.5808e-02,\n                       -6.2930e-02, -9.2372e-03, -5.9339e-02,  5.4615e-02,  7.2874e-02,\n                        8.5602e-02, -1.2114e-01, -1.2932e-01,  7.5443e-02,  3.1956e-02,\n                        1.6248e-01,  3.0199e-03, -2.8334e-03, -9.6228e-03,  1.9197e-02,\n                        4.5563e-03, -1.0493e-01,  3.3821e-02,  2.8421e-02,  1.8444e-01,\n                       -8.3574e-02, -2.7086e-02, -1.7740e-02, -6.1364e-02,  1.1880e-01,\n                        2.0306e-01,  2.6061e-02,  3.5017e-02,  1.3987e-02, -2.4613e-02,\n                        2.4622e-02, -6.0535e-02,  5.4075e-02, -9.4357e-02, -9.7178e-02,\n                        6.8038e-02, -1.6812e-02, -1.3676e-01,  4.4995e-02,  5.0133e-02,\n                        1.9924e-03, -9.2659e-03, -5.3121e-02,  3.8936e-02, -8.4166e-02,\n                       -7.0611e-02,  1.2787e-01,  5.2649e-02, -4.4588e-02, -7.0826e-02,\n                        8.7331e-02,  8.9796e-02,  1.1361e-02,  5.8759e-02, -1.3570e-01,\n                       -3.0810e-02, -7.6876e-02, -1.0586e-01,  1.0211e-01, -8.4552e-02,\n                        8.3321e-02,  2.2407e-01, -5.0362e-02,  8.1174e-02, -7.3176e-02,\n                       -2.8369e-02, -2.7519e-02, -4.5693e-02, -6.7316e-02,  1.0674e-01,\n                        1.1416e-02, -7.4735e-02, -5.6703e-02, -3.8452e-02, -3.4668e-02,\n                        2.2530e-02,  1.3074e-02,  4.7113e-03,  1.4795e-01, -1.0764e-01,\n                       -5.0841e-02,  1.2976e-01,  2.9153e-03,  3.7239e-02,  3.6436e-02,\n                        4.5193e-02,  5.6608e-02,  1.1032e-01, -1.2598e-02, -1.1100e-01,\n                       -1.3123e-01,  3.9681e-03, -7.6445e-02, -2.9538e-02,  4.3820e-02,\n                       -2.6767e-03, -2.8917e-02, -4.5348e-02, -7.4497e-02, -2.2352e-02,\n                        2.1604e-01, -1.4425e-01, -1.2318e-02, -5.1387e-02, -5.0469e-02,\n                       -1.1166e-01,  1.6551e-02, -9.7691e-02,  8.7044e-02,  1.4693e-01,\n                       -6.7109e-03,  3.3391e-02,  5.0526e-02,  1.8965e-01,  2.0448e-02,\n                        8.6791e-02,  1.2145e-01, -1.2405e-03,  1.3281e-01,  2.4065e-01,\n                        8.5654e-02,  6.7989e-02,  1.2267e-01, -1.3911e-02,  3.5767e-02,\n                        1.5869e-01,  3.5330e-02, -1.1821e-01, -5.4773e-02,  3.3388e-02,\n                        1.4373e-01, -5.0880e-02, -5.7052e-02,  1.9953e-02,  1.9700e-01,\n                        3.2147e-02, -1.1182e-01, -3.7277e-02, -3.0196e-02, -5.9099e-03,\n                       -1.1671e-01,  8.4760e-03, -1.0180e-01,  1.2407e-01, -1.0690e-01,\n                        1.9440e-01,  6.1933e-02,  6.4014e-02, -1.2034e-01, -2.1357e-01,\n                       -6.5639e-02,  3.6511e-02,  7.1705e-02,  4.5147e-02,  1.0829e-01,\n                       -1.0942e-01, -3.5108e-02,  1.8974e-01,  3.3617e-02,  9.4673e-02,\n                        1.0722e-01, -9.6649e-02, -1.1570e-02,  1.6678e-01,  1.8791e-02,\n                        2.5148e-01, -7.1840e-02,  1.6786e-01, -6.1633e-02,  9.3317e-02,\n                       -3.7112e-02,  9.6098e-02, -4.3294e-02,  1.0876e-01, -1.6018e-02,\n                       -8.5063e-02, -1.0716e-01,  5.4854e-02, -1.4376e-01, -6.9124e-03,\n                        6.2336e-02, -6.7622e-02,  8.2016e-02, -1.1930e-01,  2.0079e-02,\n                        2.1762e-01, -6.7748e-02, -1.0902e-02, -5.5168e-02,  1.2584e-01,\n                        6.9611e-02,  1.4257e-01, -5.7662e-02,  1.8828e-03, -7.4480e-02,\n                       -8.2589e-02,  6.3979e-02, -6.5034e-02, -3.2260e-02,  1.9411e-01,\n                        1.5446e-01, -2.6081e-02,  3.1896e-02,  1.6537e-02,  1.4232e-01,\n                        7.0454e-02, -8.3612e-02, -7.7748e-02, -2.8575e-02,  8.6742e-02,\n                        9.8929e-02,  1.9522e-02, -4.7438e-02,  5.6500e-02, -4.6840e-02,\n                        7.2954e-04,  2.6913e-01, -1.3796e-02,  1.0767e-01, -4.8736e-03,\n                       -4.1529e-04, -1.8772e-02, -6.3606e-02,  2.5774e-02,  6.8608e-02,\n                       -3.3224e-02, -9.7501e-02,  1.7389e-01, -9.9383e-02, -1.5862e-01,\n                        1.5909e-01,  1.6447e-01,  2.0575e-02, -8.2190e-02,  1.1324e-01,\n                       -3.6243e-02,  2.7434e-02, -7.9256e-03, -1.2686e-01,  2.3674e-02,\n                        6.1565e-02, -5.3804e-02,  1.3552e-01, -7.8113e-02, -3.2234e-02,\n                       -1.3768e-01, -8.8596e-02,  2.1213e-01,  6.0808e-03, -1.9812e-02,\n                        1.8065e-01, -1.3904e-01, -1.1172e-02,  2.1001e-03,  8.1255e-02,\n                        1.8764e-01, -9.4172e-03, -1.0667e-01, -2.8176e-02, -1.1433e-02,\n                        1.8087e-03,  3.5273e-02,  1.7311e-02, -5.9157e-02,  7.1723e-02,\n                       -5.1329e-02, -5.2184e-02, -1.3888e-01, -9.1249e-02, -9.6600e-02,\n                       -4.1593e-02, -5.0379e-03,  6.1522e-02,  1.0406e-01,  2.0850e-01,\n                        4.8160e-02,  2.6317e-02, -1.2541e-01,  5.0902e-03,  6.9262e-02,\n                        3.0473e-02,  2.5960e-01, -1.3073e-01, -1.0309e-02,  4.0851e-02,\n                        7.6019e-03,  1.0811e-01, -6.7274e-02, -1.0297e-01,  7.3587e-02,\n                        1.5165e-02,  1.9243e-02,  1.6600e-01,  4.4940e-02, -4.3895e-02,\n                       -5.5453e-02,  6.8412e-02, -4.2690e-02,  1.5001e-02, -7.5989e-02,\n                        2.4394e-02, -9.5253e-02,  6.5157e-02,  5.7743e-02, -7.0985e-02,\n                        4.1622e-02, -5.5616e-03,  1.3985e-01,  1.4997e-01, -4.0089e-02,\n                        9.0912e-02, -4.0115e-02,  1.1468e-01,  5.4305e-02, -5.0247e-02,\n                       -1.3764e-01,  4.7437e-02, -3.5240e-02,  9.9522e-02,  7.9754e-03,\n                       -4.7909e-02, -5.7668e-02,  6.2162e-02,  3.0080e-02,  1.7953e-02,\n                       -7.3181e-02, -6.9456e-02,  1.2605e-02, -7.2795e-02, -7.9646e-03,\n                        1.2299e-01,  5.2890e-02,  2.9619e-02,  4.1098e-02, -1.2080e-01,\n                        1.3241e-01, -9.5071e-02,  8.5868e-02, -7.2469e-02, -6.5235e-02,\n                        7.4478e-02,  6.5440e-02,  9.9015e-02, -7.0986e-02, -1.1172e-01,\n                       -6.7544e-02,  2.1362e-02,  5.2661e-02,  1.1153e-01,  2.2258e-01,\n                       -1.0079e-02, -4.2958e-02,  7.2424e-02,  1.3080e-01, -1.0800e-02,\n                       -1.0258e-01, -5.7658e-02,  1.5386e-02,  1.0718e-01, -4.3748e-03,\n                        1.0350e-01,  1.1787e-01,  5.5724e-02, -5.2429e-02, -2.4609e-02,\n                       -2.9340e-02, -6.2911e-02,  1.4026e-02, -9.4921e-02, -3.5944e-03,\n                       -8.9187e-02, -1.0514e-01, -3.6127e-02,  1.4885e-02,  1.0435e-01,\n                        3.5185e-02,  1.0603e-02,  1.1004e-01, -9.6598e-03,  2.6228e-02,\n                        4.8196e-02,  5.0906e-02])),\n              ('layer2.0.bn3.running_mean',\n               tensor([-0.0635,  0.0399, -0.4636, -0.3883, -0.0479,  0.2197, -0.0848,  0.2270,\n                       -0.5721, -0.0682, -0.1026, -0.1447, -0.4237,  0.2844,  0.0577,  0.4129,\n                       -0.0167, -0.1727,  0.3259,  0.2259,  0.0019,  0.3007, -0.0817,  0.1273,\n                       -0.2729,  0.3053,  0.0767, -0.1382, -0.1769,  0.1796, -0.1494, -0.5452,\n                       -0.2999,  0.2149, -0.3560,  0.0310,  0.0064,  0.0585, -0.2059, -0.0851,\n                        0.1191, -0.1297, -0.0779,  0.3201,  0.2363,  0.1987, -0.5428, -0.0288,\n                        0.1174,  0.2291,  0.1780, -0.0213,  0.3839,  0.1382, -0.0785, -0.0608,\n                        0.1941,  0.0414, -0.1668,  0.0524,  0.4533,  0.0958, -0.0926,  0.0847,\n                        0.0340,  0.0716, -0.1002, -0.0796,  0.3740,  0.0628,  0.0161, -0.0489,\n                        0.2949, -0.1582,  0.4012, -0.0175,  0.0775,  0.3719,  0.1917, -0.1781,\n                        0.3263,  0.0863,  0.0187,  0.5520, -0.0086, -0.0946, -0.1841, -0.1140,\n                       -0.0697, -0.0825, -0.1503,  0.0395,  0.4742,  0.0375,  0.0412, -0.1551,\n                       -0.1239, -0.1058,  0.0642, -0.0785, -0.1058, -0.0290,  0.0928, -0.0273,\n                        0.5384,  0.2026, -0.2288, -0.3189, -0.0736,  0.2365,  0.3381, -0.0720,\n                        0.3874, -0.1333, -0.1899, -0.0485,  0.4627,  0.1225,  0.1907, -0.1903,\n                       -0.0330, -0.2033, -0.3800, -0.0244,  0.2724, -0.0114, -0.0905,  0.2470,\n                        0.3386,  0.2374, -0.2050, -0.3413, -0.1976, -0.3110, -0.2511,  0.0894,\n                       -0.1014, -0.0255, -0.1657,  0.0445, -0.0376, -0.2053, -0.0021, -0.4550,\n                        0.1353, -0.3137, -0.3401, -0.1860,  0.0720,  0.2078,  0.0180,  0.2090,\n                        0.0131,  0.2122,  0.3162,  0.1659,  0.0212,  0.3372, -0.1380,  0.0451,\n                        0.2865,  0.0465,  0.0143, -0.2272, -0.0195, -0.0594, -0.0747, -0.0367,\n                        0.4513,  0.1889,  0.1565,  0.1483, -0.1267, -0.0923,  0.2729,  0.2129,\n                        0.2202,  0.0152,  0.0787,  0.3187,  0.0165,  0.1911, -0.2049, -0.0983,\n                        0.2303,  0.2288, -0.0045,  0.0819,  0.1133, -0.0668,  0.1849, -0.2018,\n                       -0.3873, -0.2265,  0.2183,  0.0547, -0.1160, -0.0461, -0.1834,  0.1142,\n                       -0.1751, -0.2722, -0.0221,  0.2744,  0.1499, -0.4046, -0.2563, -0.1828,\n                        0.3929,  0.1364, -0.2571, -0.2105, -0.2960,  0.5854,  0.0197, -0.1607,\n                        0.1867,  0.1118, -0.1929, -0.0301, -0.0620,  0.1330, -0.4169,  0.1735,\n                        0.0840,  0.0738,  0.2185,  0.1592, -0.1070,  0.0718, -0.1364,  0.0510,\n                       -0.0253, -0.1681, -0.0465,  0.0897,  0.0140, -0.0272, -0.0741, -0.4902,\n                       -0.0194, -0.1112,  0.2465,  0.1322,  0.1533,  0.0796, -0.0360, -0.3367,\n                       -0.0272, -0.3773,  0.3404,  0.3489,  0.2423, -0.4324, -0.0142, -0.1545,\n                       -0.0615,  0.0681,  0.0569,  0.0375,  0.3701,  0.1808, -0.0427, -0.0740,\n                       -0.0578,  0.1018,  0.0283, -0.0639, -0.4287, -0.0382,  0.3341,  0.3638,\n                       -0.1109, -0.0384,  0.0551, -0.1179, -0.2446, -0.1577,  0.0398, -0.3921,\n                       -0.3142,  0.1836, -0.6861, -0.1859, -0.2484,  0.0112, -0.1732,  0.0977,\n                       -0.1546,  0.3513,  0.1062,  0.1058, -0.3648,  0.0300,  0.0726, -0.0740,\n                        0.1134, -0.1759, -0.3834,  0.0594,  0.1294, -0.2548,  0.0284,  0.1210,\n                       -0.1141,  0.0801, -0.0058, -0.0431, -0.4401,  0.1193, -0.1034,  0.0241,\n                       -0.2545, -0.2649, -0.2800, -0.4196,  0.1888, -0.0989,  0.2142,  0.1019,\n                       -0.6421,  0.0301,  0.1115,  0.1037,  0.0359, -0.0062, -0.1326,  0.2605,\n                        0.2325, -0.1850,  0.1797, -0.4068, -0.2030,  0.1630, -0.0862,  0.5997,\n                       -0.0843, -0.0120,  0.1967,  0.1357, -0.2033, -0.4577, -0.0610,  0.0056,\n                       -0.2804, -0.2025, -0.3997,  0.2476, -0.3835, -0.1329, -0.1089, -0.0402,\n                        0.2883,  0.1801,  0.0233, -0.0412,  0.2292,  0.3025,  0.0357,  0.0344,\n                       -0.1344, -0.0307,  0.6687, -0.2232,  0.3006,  0.4602, -0.2450, -0.2209,\n                       -0.4476,  0.0016, -0.3242, -0.2923, -0.0724,  0.2093, -0.0317, -0.1033,\n                        0.2398,  0.5013,  0.1788, -0.1326, -0.1615, -0.4437, -0.0848, -0.3873,\n                        0.0389,  0.0875,  0.1894,  0.5115, -0.0692,  0.1726, -0.2838, -0.0106,\n                       -0.2138, -0.1592, -0.1478, -0.3170,  0.3190,  0.5341,  0.2367, -0.0872,\n                       -0.6654,  0.0061,  0.1565,  0.0723, -0.2724, -0.1593, -0.1609,  0.1556,\n                       -0.0160,  0.1946, -0.0782, -0.1286,  0.0916,  0.2101,  0.6376,  0.0132,\n                       -0.0010,  0.1322,  0.1442,  0.0505,  0.0074, -0.5104,  0.1567, -0.1103,\n                        0.2754,  0.0887,  0.7114, -0.1610,  0.0275, -0.3800,  0.0599, -0.0801,\n                       -0.5477, -0.3138, -0.2034,  0.2770, -0.5275,  0.0252,  0.1387,  0.4092,\n                       -0.2464, -0.0017,  0.0340,  0.2093,  0.1106,  0.0312, -0.0484,  0.1302,\n                       -0.2207,  0.2654, -0.1022,  0.1024, -0.1292, -0.3049, -0.5751,  0.2746,\n                       -0.1882, -0.1007, -0.1661, -0.1134,  0.1756, -0.0869,  0.2881,  0.4653,\n                        0.2533, -0.6826,  0.0226, -0.1579,  0.2691, -0.0634, -0.1136, -0.2314,\n                        0.1984, -0.4146, -0.2319,  0.0540,  0.1595, -0.0418, -0.0077,  0.1045,\n                        0.4031,  0.5761, -0.2637, -0.4388,  0.0348, -0.0866,  0.0103, -0.3361,\n                       -0.1341,  0.0219,  0.3136, -0.0167,  0.1116, -0.1094,  0.2540,  0.1440,\n                        0.2994,  0.1803,  0.4130, -0.2831, -0.0325,  0.0726, -0.3046, -0.5076,\n                       -0.2382, -0.0286, -0.1866, -0.0193,  0.4305, -0.1187, -0.2813,  0.2143])),\n              ('layer2.0.bn3.running_var',\n               tensor([0.1195, 0.0737, 0.0779, 0.3919, 0.0716, 0.0824, 0.0797, 0.0813, 0.1754,\n                       0.1577, 0.1051, 0.1106, 0.1030, 0.1131, 0.0851, 0.1683, 0.1171, 0.2442,\n                       0.1486, 0.1079, 0.1475, 0.1942, 0.0838, 0.0499, 0.0689, 0.1795, 0.1073,\n                       0.1239, 0.2199, 0.1290, 0.1874, 0.1970, 0.0750, 0.1499, 0.1290, 0.1979,\n                       0.1351, 0.1293, 0.0760, 0.2462, 0.1340, 0.0773, 0.1479, 0.0730, 0.1109,\n                       0.2153, 0.1060, 0.1358, 0.0557, 0.0676, 0.0726, 0.0798, 0.1042, 0.0637,\n                       0.0810, 0.0810, 0.1489, 0.0922, 0.2668, 0.0993, 0.0920, 0.1099, 0.1993,\n                       0.0949, 0.1798, 0.2209, 0.0862, 0.1037, 0.0783, 0.2241, 0.1419, 0.0735,\n                       0.0930, 0.1252, 0.1596, 0.0768, 0.1718, 0.1404, 0.1385, 0.2334, 0.3168,\n                       0.0877, 0.1001, 0.2009, 0.1076, 0.1245, 0.1699, 0.0542, 0.1168, 0.1446,\n                       0.0715, 0.0979, 0.1521, 0.1417, 0.1307, 0.0905, 0.1357, 0.0911, 0.0725,\n                       0.2106, 0.0617, 0.0874, 0.0803, 0.0643, 0.1844, 0.1248, 0.0739, 0.0776,\n                       0.0823, 0.0908, 0.1997, 0.0666, 0.1435, 0.1207, 0.1334, 0.1242, 0.1370,\n                       0.0704, 0.1851, 0.1327, 0.0802, 0.0964, 0.1224, 0.1016, 0.1001, 0.1474,\n                       0.2142, 0.0694, 0.1709, 0.1557, 0.1471, 0.1086, 0.0728, 0.1165, 0.1309,\n                       0.1217, 0.1062, 0.0795, 0.1370, 0.0761, 0.2110, 0.0745, 0.0979, 0.0887,\n                       0.1352, 0.1718, 0.0874, 0.1519, 0.1429, 0.2662, 0.0738, 0.0697, 0.0921,\n                       0.0827, 0.1123, 0.1806, 0.0659, 0.0701, 0.1017, 0.1127, 0.1447, 0.1247,\n                       0.0966, 0.0807, 0.0994, 0.1423, 0.1002, 0.0575, 0.1284, 0.2629, 0.1271,\n                       0.0801, 0.1791, 0.1535, 0.0872, 0.0554, 0.0938, 0.0849, 0.0798, 0.1471,\n                       0.1642, 0.1672, 0.0961, 0.1656, 0.0647, 0.0659, 0.0592, 0.0636, 0.1121,\n                       0.0700, 0.2288, 0.1841, 0.0896, 0.1295, 0.0498, 0.0750, 0.1145, 0.1242,\n                       0.0577, 0.1716, 0.1394, 0.1027, 0.1248, 0.0875, 0.0710, 0.1109, 0.1020,\n                       0.1075, 0.2219, 0.0710, 0.0663, 0.1836, 0.1604, 0.1312, 0.1027, 0.1219,\n                       0.0984, 0.1404, 0.0816, 0.0523, 0.0807, 0.0766, 0.1069, 0.0843, 0.0773,\n                       0.0929, 0.0688, 0.0769, 0.1067, 0.0658, 0.2098, 0.1024, 0.0921, 0.1294,\n                       0.0932, 0.0534, 0.1392, 0.1094, 0.0941, 0.1642, 0.1019, 0.0822, 0.1254,\n                       0.1632, 0.1459, 0.1052, 0.1326, 0.1234, 0.1475, 0.2330, 0.1671, 0.1031,\n                       0.1364, 0.1343, 0.0722, 0.0792, 0.0966, 0.1260, 0.1431, 0.0879, 0.1377,\n                       0.1393, 0.0854, 0.1080, 0.2792, 0.1254, 0.0504, 0.0788, 0.0953, 0.0840,\n                       0.0866, 0.1932, 0.0544, 0.1236, 0.0902, 0.1760, 0.1380, 0.1459, 0.0913,\n                       0.0463, 0.0613, 0.1159, 0.1775, 0.1818, 0.1639, 0.0434, 0.1320, 0.2074,\n                       0.1123, 0.1052, 0.2220, 0.0803, 0.0905, 0.1834, 0.0939, 0.2436, 0.0778,\n                       0.1591, 0.0999, 0.1297, 0.1040, 0.1733, 0.0964, 0.1405, 0.1099, 0.0694,\n                       0.0571, 0.1068, 0.0850, 0.0725, 0.1672, 0.0870, 0.1039, 0.1253, 0.0812,\n                       0.1927, 0.0805, 0.1095, 0.0735, 0.1788, 0.1986, 0.1114, 0.1031, 0.0880,\n                       0.0881, 0.1171, 0.1020, 0.1366, 0.0989, 0.1051, 0.0996, 0.1090, 0.2025,\n                       0.0888, 0.1457, 0.1520, 0.0712, 0.1090, 0.2426, 0.1397, 0.1423, 0.1113,\n                       0.0835, 0.1591, 0.0909, 0.0986, 0.2053, 0.0993, 0.2392, 0.0944, 0.1349,\n                       0.1467, 0.0491, 0.1505, 0.0740, 0.2355, 0.0992, 0.3292, 0.0597, 0.0595,\n                       0.1361, 0.1492, 0.2274, 0.1133, 0.1348, 0.0960, 0.0738, 0.0923, 0.0912,\n                       0.1583, 0.0945, 0.1191, 0.1507, 0.0776, 0.0873, 0.0604, 0.0983, 0.3061,\n                       0.0972, 0.0808, 0.2027, 0.0550, 0.0898, 0.1154, 0.1038, 0.1683, 0.1036,\n                       0.0594, 0.0869, 0.0986, 0.0842, 0.0866, 0.1348, 0.0909, 0.0762, 0.0782,\n                       0.0491, 0.0729, 0.0806, 0.0865, 0.1573, 0.0817, 0.1187, 0.1545, 0.1943,\n                       0.1390, 0.0599, 0.1156, 0.1348, 0.1405, 0.1192, 0.1817, 0.1101, 0.1145,\n                       0.2405, 0.0963, 0.0761, 0.0820, 0.0846, 0.1489, 0.0709, 0.1281, 0.2716,\n                       0.0659, 0.0704, 0.0717, 0.2862, 0.0930, 0.0907, 0.0854, 0.1431, 0.0618,\n                       0.1362, 0.1049, 0.1074, 0.0696, 0.1571, 0.1749, 0.2013, 0.1536, 0.1510,\n                       0.0890, 0.1634, 0.1258, 0.0579, 0.0823, 0.1077, 0.1002, 0.1521, 0.1069,\n                       0.1124, 0.0648, 0.1543, 0.1727, 0.2489, 0.0897, 0.0613, 0.1324, 0.0927,\n                       0.1042, 0.1975, 0.1348, 0.0657, 0.1687, 0.1034, 0.2138, 0.0956, 0.1543,\n                       0.0648, 0.0861, 0.1293, 0.1595, 0.1848, 0.0872, 0.0529, 0.1063, 0.0698,\n                       0.1765, 0.1328, 0.1919, 0.1375, 0.1227, 0.0820, 0.1405, 0.1397, 0.1421,\n                       0.1360, 0.1549, 0.1584, 0.1993, 0.2186, 0.1806, 0.1428, 0.1043, 0.1007,\n                       0.1142, 0.0543, 0.1676, 0.2176, 0.1018, 0.0539, 0.0633, 0.0794, 0.1509,\n                       0.1253, 0.1187, 0.1116, 0.0989, 0.1076, 0.1059, 0.1886, 0.0607])),\n              ('layer2.0.bn3.num_batches_tracked', tensor(13572)),\n              ('layer2.0.downsample.0.weight',\n               tensor([[[[-0.0820]],\n               \n                        [[ 0.0229]],\n               \n                        [[-0.0479]],\n               \n                        ...,\n               \n                        [[ 0.0167]],\n               \n                        [[-0.0054]],\n               \n                        [[-0.0449]]],\n               \n               \n                       [[[ 0.0444]],\n               \n                        [[-0.0170]],\n               \n                        [[-0.0371]],\n               \n                        ...,\n               \n                        [[ 0.1324]],\n               \n                        [[ 0.0811]],\n               \n                        [[ 0.0258]]],\n               \n               \n                       [[[ 0.0361]],\n               \n                        [[ 0.0198]],\n               \n                        [[-0.0666]],\n               \n                        ...,\n               \n                        [[-0.0337]],\n               \n                        [[ 0.0106]],\n               \n                        [[-0.1339]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0160]],\n               \n                        [[ 0.0224]],\n               \n                        [[ 0.0106]],\n               \n                        ...,\n               \n                        [[-0.0192]],\n               \n                        [[-0.0221]],\n               \n                        [[ 0.0116]]],\n               \n               \n                       [[[ 0.0372]],\n               \n                        [[-0.0010]],\n               \n                        [[-0.0178]],\n               \n                        ...,\n               \n                        [[-0.0221]],\n               \n                        [[-0.0510]],\n               \n                        [[-0.0467]]],\n               \n               \n                       [[[ 0.0767]],\n               \n                        [[-0.0747]],\n               \n                        [[ 0.0315]],\n               \n                        ...,\n               \n                        [[-0.0005]],\n               \n                        [[ 0.0317]],\n               \n                        [[ 0.0094]]]])),\n              ('layer2.0.downsample.1.weight',\n               tensor([0.8921, 0.9078, 0.7810, 0.8666, 0.7828, 0.8493, 0.8673, 0.8523, 0.8979,\n                       0.8967, 0.7613, 0.7994, 0.8621, 0.7449, 0.7823, 0.7354, 0.9519, 0.7085,\n                       0.7786, 0.9279, 0.9322, 0.8991, 0.7869, 0.8911, 0.8979, 0.7994, 0.7821,\n                       0.7909, 0.8936, 0.8120, 0.8576, 0.8115, 0.8157, 0.9431, 0.8368, 0.8367,\n                       0.8873, 0.8631, 0.8490, 0.7765, 0.7694, 0.8843, 0.8407, 0.8150, 0.9439,\n                       0.8350, 0.8092, 0.7476, 0.8365, 0.9735, 0.8354, 0.8274, 0.9494, 0.8333,\n                       0.9192, 0.8679, 0.8379, 0.8461, 0.7690, 0.7982, 0.8548, 0.8032, 0.9707,\n                       0.8638, 0.8544, 0.8183, 0.8230, 0.8908, 0.7904, 0.8587, 0.8828, 0.8038,\n                       0.8268, 0.8181, 0.8870, 0.8306, 0.9377, 0.8372, 0.9267, 0.9592, 0.8683,\n                       0.8965, 0.7770, 0.7589, 0.8631, 0.8399, 0.8374, 0.8945, 0.8613, 0.8438,\n                       0.8734, 0.8674, 0.8610, 0.8596, 0.8443, 0.7990, 0.8350, 0.8396, 0.8199,\n                       0.8413, 0.8056, 0.8032, 0.8073, 0.8298, 0.7612, 0.6876, 0.8426, 0.8616,\n                       0.8011, 0.8125, 0.9549, 0.8237, 0.9170, 0.7969, 0.8246, 0.9324, 0.9792,\n                       0.8899, 0.8957, 0.8232, 0.9028, 0.8028, 0.8509, 0.7792, 0.7938, 0.8732,\n                       0.8243, 0.8575, 0.8040, 0.8581, 0.8252, 0.8841, 0.8401, 0.8062, 0.8056,\n                       0.9582, 0.8702, 0.8638, 0.9257, 0.9015, 0.7846, 0.8194, 0.9081, 0.8097,\n                       0.9191, 0.7729, 0.8404, 0.7007, 0.8448, 0.7991, 0.8416, 0.8439, 0.8147,\n                       0.8868, 0.8101, 0.8794, 0.8924, 0.7413, 0.7982, 0.7295, 0.9141, 0.8693,\n                       0.8551, 0.7477, 0.8382, 0.7634, 0.7963, 0.7472, 0.9104, 0.8274, 0.8849,\n                       0.8872, 0.7799, 0.9569, 0.7965, 0.8850, 0.8717, 0.8322, 0.8312, 0.9037,\n                       0.8473, 0.7753, 0.9043, 0.8728, 0.8773, 0.8313, 0.9282, 0.8062, 0.8428,\n                       0.8867, 0.6885, 0.7268, 0.8396, 0.7896, 0.8354, 0.8583, 0.8795, 0.8007,\n                       0.8014, 0.8641, 0.8215, 0.8671, 0.8841, 0.7804, 0.8930, 0.8590, 0.9459,\n                       0.8217, 0.7688, 0.8771, 0.8290, 0.8767, 0.8938, 0.8205, 0.8914, 0.8984,\n                       0.8317, 0.8730, 0.9204, 0.8615, 0.8073, 0.9417, 0.9082, 0.9613, 1.0375,\n                       0.8031, 1.0025, 0.8866, 0.8742, 0.8846, 0.9027, 0.7985, 0.9091, 0.8082,\n                       0.8571, 0.8721, 0.9397, 0.8648, 0.8813, 0.9252, 0.8017, 0.9306, 0.7524,\n                       0.8308, 0.8860, 0.8675, 0.8581, 0.8797, 0.8842, 0.7153, 0.9022, 0.8951,\n                       0.9500, 0.7971, 0.8277, 0.8340, 0.9080, 0.8969, 0.7763, 0.7537, 0.8688,\n                       0.8208, 0.8918, 0.7087, 0.8670, 0.9198, 0.8546, 0.9412, 0.8371, 0.9165,\n                       0.8011, 0.8236, 0.9063, 0.9139, 0.8200, 0.8552, 0.8986, 0.9192, 0.9136,\n                       0.8305, 0.7924, 0.7271, 0.8326, 0.8074, 0.8833, 0.9060, 0.8120, 0.8237,\n                       0.8064, 0.8297, 0.7168, 0.8039, 0.9493, 0.7066, 0.8484, 0.7974, 0.9021,\n                       0.9330, 0.8631, 0.9398, 0.7952, 0.8283, 0.8475, 0.8598, 0.9061, 0.9196,\n                       0.9371, 0.8712, 0.9404, 0.8963, 0.8053, 0.8956, 0.9288, 0.8260, 0.7689,\n                       0.7216, 0.8227, 0.8829, 0.7932, 0.8923, 0.9450, 0.8426, 0.8111, 0.8917,\n                       0.8653, 0.7887, 0.8427, 0.9023, 0.8883, 0.9383, 0.8476, 0.8556, 0.8515,\n                       0.8570, 0.8794, 0.8816, 0.8311, 0.9002, 0.9575, 0.7792, 0.8399, 0.8295,\n                       0.8018, 0.8256, 0.8685, 0.8367, 0.8825, 0.8212, 0.8860, 0.8737, 0.7226,\n                       0.8578, 0.8757, 0.7806, 0.8078, 0.8918, 0.8300, 0.7721, 0.8011, 0.8763,\n                       0.8276, 0.8015, 0.8187, 0.8703, 0.8979, 0.8102, 0.8886, 0.8378, 0.8638,\n                       0.7705, 0.8577, 0.8270, 0.7228, 0.8737, 0.8451, 0.8892, 0.7917, 0.7289,\n                       0.9094, 0.8227, 0.7923, 0.9141, 0.7737, 0.8119, 0.8813, 0.8598, 0.8562,\n                       0.9052, 0.8497, 0.8799, 0.8294, 0.8848, 0.8404, 0.8608, 0.9373, 0.9270,\n                       0.8102, 0.9151, 0.7988, 0.7708, 0.8703, 0.9065, 0.8063, 0.7845, 0.7840,\n                       0.8496, 0.8398, 0.8229, 0.8385, 0.8905, 0.9166, 0.8897, 0.8059, 0.9555,\n                       0.8502, 0.9310, 0.9179, 0.8499, 0.7643, 0.8429, 0.7481, 0.8221, 0.7401,\n                       0.8604, 0.8907, 0.8676, 0.8183, 0.8552, 0.8049, 0.7927, 0.7977, 0.8278,\n                       0.7832, 0.8450, 0.8823, 0.9162, 0.8045, 0.7956, 0.8679, 0.9329, 0.8367,\n                       0.9213, 0.9671, 0.8764, 0.8434, 0.9411, 0.8638, 0.8190, 0.7329, 0.9172,\n                       0.9178, 0.8290, 0.8861, 0.8363, 0.8101, 0.8897, 0.8400, 0.7678, 0.8275,\n                       0.8835, 0.7049, 0.7885, 0.8839, 0.8530, 0.9138, 0.9472, 0.8619, 0.9128,\n                       0.8323, 0.7873, 0.8266, 0.7582, 0.8363, 0.8037, 0.7979, 0.8448, 0.8300,\n                       0.9056, 0.8528, 0.7435, 0.8888, 0.7713, 0.8586, 0.9222, 0.8383, 0.8708,\n                       0.8273, 0.8469, 0.8679, 0.7896, 0.8654, 0.8227, 0.7684, 0.8446, 0.8765,\n                       0.8302, 0.8269, 0.8533, 0.9484, 0.8995, 0.9144, 0.8135, 0.8507, 0.8245,\n                       0.8258, 0.9156, 0.7935, 0.9066, 0.9410, 0.9009, 0.8359, 0.9209])),\n              ('layer2.0.downsample.1.bias',\n               tensor([ 7.2772e-02, -6.8790e-02,  4.4726e-02,  9.4366e-02,  1.7202e-02,\n                       -7.2461e-02, -1.9011e-02, -1.1996e-02, -2.8966e-02,  1.0434e-01,\n                       -3.9463e-02, -1.0471e-02,  9.7917e-03,  7.0516e-02,  2.4386e-04,\n                        7.7913e-02, -5.8665e-02,  1.3884e-01,  3.0873e-02, -7.3724e-02,\n                       -3.6645e-02,  3.5817e-02, -7.6026e-02, -4.5021e-02, -1.1793e-01,\n                        8.7404e-02, -5.4016e-02, -3.2672e-03,  1.5345e-01,  4.9387e-02,\n                        1.7085e-01,  9.4239e-02, -4.6989e-02,  4.9129e-02,  1.1779e-01,\n                        2.3703e-01,  4.5512e-02, -2.1395e-02, -1.0035e-01,  1.1968e-01,\n                        5.6978e-02,  5.6118e-02, -2.5819e-02, -2.9769e-02,  9.6195e-02,\n                        1.4522e-01, -1.1747e-02,  4.7371e-02, -6.5386e-02, -1.2394e-01,\n                       -6.7362e-02, -2.3442e-02, -6.3688e-02, -1.0101e-01,  5.1386e-02,\n                        1.2020e-02,  2.4666e-01,  3.6687e-02,  1.4761e-01, -7.3567e-02,\n                       -1.3175e-01,  9.6796e-02,  7.7306e-02, -7.7757e-02,  7.4445e-02,\n                        4.0937e-02, -2.0895e-02, -2.6817e-02,  4.0703e-02,  7.7672e-02,\n                        2.9121e-02, -1.3746e-02, -1.2551e-02, -2.0551e-02,  1.6204e-01,\n                       -1.1041e-01,  5.6710e-02,  1.3259e-02,  1.2201e-01,  1.7871e-01,\n                        5.5292e-02, -5.6783e-02, -2.0994e-02,  1.9898e-01,  5.7359e-02,\n                       -8.4766e-02,  4.3711e-02, -1.9782e-01,  4.0865e-02,  2.4604e-01,\n                       -7.7729e-02,  8.1093e-02,  9.5030e-02,  6.5134e-02,  1.2296e-01,\n                        2.7609e-02, -6.5488e-02,  1.5753e-03, -3.4012e-02,  2.0746e-01,\n                       -1.0347e-01, -1.3011e-01, -6.1559e-02, -6.5992e-02, -1.2152e-01,\n                       -4.7670e-02, -4.4360e-02,  1.0757e-02, -8.2507e-02, -4.8127e-02,\n                        1.0880e-01, -1.0767e-01,  8.5057e-02, -1.0043e-02, -4.2895e-02,\n                        1.6038e-02, -5.2530e-02, -7.8919e-02, -1.9300e-02,  6.2578e-02,\n                       -1.3458e-01, -9.1208e-02,  3.5881e-02, -7.1067e-02, -6.6957e-02,\n                        6.2160e-02,  1.3790e-01, -6.2705e-02,  1.2616e-01,  8.5808e-02,\n                       -6.2930e-02, -9.2372e-03, -5.9339e-02,  5.4615e-02,  7.2874e-02,\n                        8.5602e-02, -1.2114e-01, -1.2932e-01,  7.5443e-02,  3.1956e-02,\n                        1.6248e-01,  3.0199e-03, -2.8334e-03, -9.6228e-03,  1.9197e-02,\n                        4.5563e-03, -1.0493e-01,  3.3821e-02,  2.8421e-02,  1.8444e-01,\n                       -8.3574e-02, -2.7086e-02, -1.7740e-02, -6.1364e-02,  1.1880e-01,\n                        2.0306e-01,  2.6061e-02,  3.5017e-02,  1.3987e-02, -2.4613e-02,\n                        2.4622e-02, -6.0535e-02,  5.4075e-02, -9.4357e-02, -9.7178e-02,\n                        6.8038e-02, -1.6812e-02, -1.3676e-01,  4.4995e-02,  5.0133e-02,\n                        1.9924e-03, -9.2659e-03, -5.3121e-02,  3.8936e-02, -8.4166e-02,\n                       -7.0611e-02,  1.2787e-01,  5.2649e-02, -4.4588e-02, -7.0826e-02,\n                        8.7331e-02,  8.9796e-02,  1.1361e-02,  5.8759e-02, -1.3570e-01,\n                       -3.0810e-02, -7.6876e-02, -1.0586e-01,  1.0211e-01, -8.4552e-02,\n                        8.3321e-02,  2.2407e-01, -5.0362e-02,  8.1174e-02, -7.3176e-02,\n                       -2.8369e-02, -2.7519e-02, -4.5693e-02, -6.7316e-02,  1.0674e-01,\n                        1.1416e-02, -7.4735e-02, -5.6703e-02, -3.8452e-02, -3.4668e-02,\n                        2.2530e-02,  1.3074e-02,  4.7113e-03,  1.4795e-01, -1.0764e-01,\n                       -5.0841e-02,  1.2976e-01,  2.9153e-03,  3.7239e-02,  3.6436e-02,\n                        4.5193e-02,  5.6608e-02,  1.1032e-01, -1.2598e-02, -1.1100e-01,\n                       -1.3123e-01,  3.9681e-03, -7.6445e-02, -2.9538e-02,  4.3820e-02,\n                       -2.6767e-03, -2.8917e-02, -4.5348e-02, -7.4497e-02, -2.2352e-02,\n                        2.1604e-01, -1.4425e-01, -1.2318e-02, -5.1387e-02, -5.0469e-02,\n                       -1.1166e-01,  1.6551e-02, -9.7691e-02,  8.7044e-02,  1.4693e-01,\n                       -6.7109e-03,  3.3391e-02,  5.0526e-02,  1.8965e-01,  2.0448e-02,\n                        8.6791e-02,  1.2145e-01, -1.2405e-03,  1.3281e-01,  2.4065e-01,\n                        8.5654e-02,  6.7989e-02,  1.2267e-01, -1.3911e-02,  3.5767e-02,\n                        1.5869e-01,  3.5330e-02, -1.1821e-01, -5.4773e-02,  3.3388e-02,\n                        1.4373e-01, -5.0880e-02, -5.7052e-02,  1.9953e-02,  1.9700e-01,\n                        3.2147e-02, -1.1182e-01, -3.7277e-02, -3.0196e-02, -5.9099e-03,\n                       -1.1671e-01,  8.4760e-03, -1.0180e-01,  1.2407e-01, -1.0690e-01,\n                        1.9440e-01,  6.1933e-02,  6.4014e-02, -1.2034e-01, -2.1357e-01,\n                       -6.5639e-02,  3.6511e-02,  7.1705e-02,  4.5147e-02,  1.0829e-01,\n                       -1.0942e-01, -3.5108e-02,  1.8974e-01,  3.3617e-02,  9.4673e-02,\n                        1.0722e-01, -9.6649e-02, -1.1570e-02,  1.6678e-01,  1.8791e-02,\n                        2.5148e-01, -7.1840e-02,  1.6786e-01, -6.1633e-02,  9.3317e-02,\n                       -3.7112e-02,  9.6098e-02, -4.3294e-02,  1.0876e-01, -1.6018e-02,\n                       -8.5063e-02, -1.0716e-01,  5.4854e-02, -1.4376e-01, -6.9124e-03,\n                        6.2336e-02, -6.7622e-02,  8.2016e-02, -1.1930e-01,  2.0079e-02,\n                        2.1762e-01, -6.7748e-02, -1.0902e-02, -5.5168e-02,  1.2584e-01,\n                        6.9611e-02,  1.4257e-01, -5.7662e-02,  1.8828e-03, -7.4480e-02,\n                       -8.2589e-02,  6.3979e-02, -6.5034e-02, -3.2260e-02,  1.9411e-01,\n                        1.5446e-01, -2.6081e-02,  3.1896e-02,  1.6537e-02,  1.4232e-01,\n                        7.0454e-02, -8.3612e-02, -7.7748e-02, -2.8575e-02,  8.6742e-02,\n                        9.8929e-02,  1.9522e-02, -4.7438e-02,  5.6500e-02, -4.6840e-02,\n                        7.2954e-04,  2.6913e-01, -1.3796e-02,  1.0767e-01, -4.8736e-03,\n                       -4.1529e-04, -1.8772e-02, -6.3606e-02,  2.5774e-02,  6.8608e-02,\n                       -3.3224e-02, -9.7501e-02,  1.7389e-01, -9.9383e-02, -1.5862e-01,\n                        1.5909e-01,  1.6447e-01,  2.0575e-02, -8.2190e-02,  1.1324e-01,\n                       -3.6243e-02,  2.7434e-02, -7.9256e-03, -1.2686e-01,  2.3674e-02,\n                        6.1565e-02, -5.3804e-02,  1.3552e-01, -7.8113e-02, -3.2234e-02,\n                       -1.3768e-01, -8.8596e-02,  2.1213e-01,  6.0808e-03, -1.9812e-02,\n                        1.8065e-01, -1.3904e-01, -1.1172e-02,  2.1001e-03,  8.1255e-02,\n                        1.8764e-01, -9.4172e-03, -1.0667e-01, -2.8176e-02, -1.1433e-02,\n                        1.8087e-03,  3.5273e-02,  1.7311e-02, -5.9157e-02,  7.1723e-02,\n                       -5.1329e-02, -5.2184e-02, -1.3888e-01, -9.1249e-02, -9.6600e-02,\n                       -4.1593e-02, -5.0379e-03,  6.1522e-02,  1.0406e-01,  2.0850e-01,\n                        4.8160e-02,  2.6317e-02, -1.2541e-01,  5.0902e-03,  6.9262e-02,\n                        3.0473e-02,  2.5960e-01, -1.3073e-01, -1.0309e-02,  4.0851e-02,\n                        7.6019e-03,  1.0811e-01, -6.7274e-02, -1.0297e-01,  7.3587e-02,\n                        1.5165e-02,  1.9243e-02,  1.6600e-01,  4.4940e-02, -4.3895e-02,\n                       -5.5453e-02,  6.8412e-02, -4.2690e-02,  1.5001e-02, -7.5989e-02,\n                        2.4394e-02, -9.5253e-02,  6.5157e-02,  5.7743e-02, -7.0985e-02,\n                        4.1622e-02, -5.5616e-03,  1.3985e-01,  1.4997e-01, -4.0089e-02,\n                        9.0912e-02, -4.0115e-02,  1.1468e-01,  5.4305e-02, -5.0247e-02,\n                       -1.3764e-01,  4.7437e-02, -3.5240e-02,  9.9522e-02,  7.9754e-03,\n                       -4.7909e-02, -5.7668e-02,  6.2162e-02,  3.0080e-02,  1.7953e-02,\n                       -7.3181e-02, -6.9456e-02,  1.2605e-02, -7.2795e-02, -7.9646e-03,\n                        1.2299e-01,  5.2890e-02,  2.9619e-02,  4.1098e-02, -1.2080e-01,\n                        1.3241e-01, -9.5071e-02,  8.5868e-02, -7.2469e-02, -6.5235e-02,\n                        7.4478e-02,  6.5440e-02,  9.9015e-02, -7.0986e-02, -1.1172e-01,\n                       -6.7544e-02,  2.1362e-02,  5.2661e-02,  1.1153e-01,  2.2258e-01,\n                       -1.0079e-02, -4.2958e-02,  7.2424e-02,  1.3080e-01, -1.0800e-02,\n                       -1.0258e-01, -5.7658e-02,  1.5386e-02,  1.0718e-01, -4.3748e-03,\n                        1.0350e-01,  1.1787e-01,  5.5724e-02, -5.2429e-02, -2.4609e-02,\n                       -2.9340e-02, -6.2911e-02,  1.4026e-02, -9.4921e-02, -3.5944e-03,\n                       -8.9187e-02, -1.0514e-01, -3.6127e-02,  1.4885e-02,  1.0435e-01,\n                        3.5185e-02,  1.0603e-02,  1.1004e-01, -9.6598e-03,  2.6228e-02,\n                        4.8196e-02,  5.0906e-02])),\n              ('layer2.0.downsample.1.running_mean',\n               tensor([-1.0169e+00, -8.0528e-01, -2.3745e-01, -3.9226e-02, -8.4845e-01,\n                        8.9161e-01, -6.6184e-02, -7.9039e-01,  2.3309e-01, -4.5971e-01,\n                       -3.3808e-03, -4.4578e-01, -5.5077e-01, -5.2867e-01,  1.5536e-01,\n                       -9.9486e-01, -3.2328e-01, -1.2681e-01,  1.6869e-01,  5.0568e-01,\n                       -6.3990e-01, -8.1599e-01, -4.0472e-01, -1.2210e+00,  1.4330e+00,\n                        7.1148e-01, -5.3792e-01,  2.8208e-01, -1.2392e+00, -2.5658e-01,\n                       -1.2307e+00, -1.5177e-01,  1.7395e+00, -1.9049e+00, -8.3144e-01,\n                       -1.2487e+00, -1.9022e-01, -9.9203e-02, -6.6629e-02, -1.4753e+00,\n                        2.4070e-01,  2.9281e-01,  2.9218e-01, -2.6649e-01, -6.1869e-01,\n                       -3.1871e-01, -1.8552e-01,  8.0196e-01, -4.5839e-01, -8.3928e-01,\n                       -2.6925e-01,  7.5019e-01, -8.5054e-01, -1.4808e-01, -9.0334e-01,\n                       -4.9420e-01, -1.4893e+00, -1.0154e+00, -2.4356e+00, -2.0404e-01,\n                        6.1993e-01, -1.9289e+00, -5.7443e-01, -8.0269e-01, -1.5624e+00,\n                       -1.2662e+00, -6.2011e-01,  2.9846e-01,  1.8473e-01, -1.0034e+00,\n                       -8.2069e-01, -6.3444e-01, -4.6816e-01, -1.1672e-01, -1.3501e+00,\n                        4.1917e-01, -7.6577e-01, -1.1611e+00,  7.0121e-01, -1.4376e+00,\n                        5.6867e-01, -3.4620e-01, -1.0156e+00, -3.3237e-01, -8.0574e-01,\n                        5.6291e-01, -1.0748e+00, -1.8780e-01,  3.6867e-02, -2.2304e+00,\n                        4.0113e-01, -5.9496e-01, -1.2410e-01, -1.4118e+00, -2.0242e+00,\n                        1.1195e-01,  9.1364e-02, -7.4377e-02, -8.6130e-01, -1.5653e+00,\n                       -5.4969e-01, -3.9623e-01,  1.2046e+00, -1.4379e-02, -1.4978e-01,\n                        8.4003e-02,  1.4410e+00, -1.5451e-01,  1.2732e+00, -1.3152e+00,\n                       -2.2479e-02, -4.2902e-01, -9.7238e-01, -7.2289e-01, -6.4183e-01,\n                       -1.3340e+00,  1.3269e+00,  3.2255e-01, -9.5451e-01, -2.3355e+00,\n                       -8.7772e-01, -4.7196e-02, -1.2633e+00, -7.4118e-01,  6.1654e-01,\n                        3.9575e-03, -1.2630e+00,  1.1438e-01,  3.9769e-01, -2.0846e+00,\n                        6.8881e-02,  3.8062e-01,  5.1095e-01, -1.9451e+00, -7.0231e-01,\n                       -5.7591e-01,  7.9327e-01, -8.3456e-02,  1.0627e+00, -3.2363e-01,\n                        1.8951e-01, -1.3982e+00, -7.5318e-01,  1.9060e-01,  1.8210e-01,\n                       -2.0156e-01,  5.2989e-01, -4.9094e-01,  7.7126e-01, -7.9138e-01,\n                       -4.8159e-01, -1.2434e+00, -1.4065e-01, -5.2680e-01, -1.4715e-01,\n                       -8.6826e-01, -1.0095e+00, -3.9369e-01,  6.8822e-01,  9.6507e-01,\n                        8.2761e-01,  1.0008e+00,  1.7172e-01, -2.2336e-01,  2.7686e-01,\n                       -1.2070e+00, -9.0818e-01,  5.3580e-01,  1.4109e+00,  8.3333e-01,\n                       -6.4303e-01, -4.0712e-01, -1.9319e-01,  1.8665e-02, -1.9821e-01,\n                       -9.9370e-01, -4.3759e-01,  4.1932e-01, -4.2976e-01,  1.6372e-01,\n                       -1.0590e+00, -1.1970e+00, -5.0507e-02,  1.0634e-01,  6.3034e-01,\n                        1.8534e+00, -1.3080e+00, -3.8531e-01, -1.4414e+00,  6.7148e-01,\n                       -4.5507e-01, -8.5517e-01, -4.9881e-01, -7.7786e-03,  6.1908e-01,\n                       -5.6015e-01, -6.2609e-01,  7.7945e-01, -1.0565e+00, -1.1361e+00,\n                       -8.4629e-01,  1.0107e+00,  6.8283e-01, -1.3176e+00,  1.1892e-01,\n                        3.9681e-01,  3.3253e-01, -7.4189e-01, -3.5089e-01, -9.0029e-02,\n                        1.2621e-01, -5.9800e-01, -1.1083e+00,  1.2693e-01, -1.7904e+00,\n                       -3.7165e-01, -1.3409e+00, -7.6978e-01, -5.3854e-02,  4.4182e-01,\n                       -9.4814e-01, -1.0537e-01, -4.6452e-01,  6.3104e-01, -3.8805e-01,\n                       -1.1215e+00, -1.0808e-01,  1.0544e+00,  3.4779e-01, -8.8519e-01,\n                       -1.5667e+00, -7.3663e-01, -1.4515e+00,  1.4670e-01, -9.6944e-01,\n                       -6.8750e-01, -6.9457e-01,  6.6440e-01,  5.0982e-01, -2.7120e-01,\n                       -1.0434e+00, -1.4349e+00, -1.1101e-01, -1.4788e+00,  1.7754e+00,\n                       -1.6302e+00, -7.8367e-01,  5.7474e-01, -4.7243e-01,  3.2306e-01,\n                       -4.4101e-01, -1.4837e-01, -1.2246e+00,  1.0959e+00, -5.7444e-02,\n                       -2.8011e-01, -1.4484e+00, -1.6667e+00, -1.8801e-02,  3.9263e-01,\n                        5.6562e-01,  5.4267e-01, -9.6794e-01,  1.0451e+00, -1.5024e+00,\n                       -7.6605e-04,  8.4317e-01, -1.2097e+00, -3.7892e-01,  6.6658e-01,\n                       -6.1794e-01,  7.9836e-01,  1.0050e+00, -3.4437e-01, -1.2841e+00,\n                       -7.6863e-01, -6.0267e-01, -3.2506e-02,  1.8338e+00,  4.7341e-01,\n                       -3.9505e-01, -4.1868e-03, -5.4598e-01,  1.9797e-01, -1.3301e+00,\n                        4.5430e-01, -1.1793e+00, -8.8915e-02, -1.4667e-01,  5.5861e-01,\n                       -2.2104e+00, -5.7065e-01,  6.3539e-01, -2.7812e-02,  7.9819e-02,\n                       -6.8914e-01, -1.7622e-01, -4.1054e-01,  8.3201e-01, -9.4578e-01,\n                       -1.0239e+00, -5.9488e-01, -1.6044e-01, -1.5179e-01,  4.4984e-01,\n                       -1.5241e-01,  1.2141e+00, -1.1649e+00,  1.0256e+00,  6.8214e-01,\n                       -3.7765e-01,  1.2834e-01, -1.0414e+00, -7.2959e-03, -1.0251e+00,\n                       -3.6016e-01, -9.9849e-01, -6.6806e-01, -5.8026e-01, -1.8669e+00,\n                       -2.1291e+00, -1.2538e+00, -9.4475e-01, -1.0934e+00, -7.3446e-01,\n                       -1.2929e+00, -8.4160e-01,  5.8369e-01, -1.2521e+00,  1.0298e-01,\n                       -1.2480e+00,  9.4381e-02,  8.9559e-01, -4.1991e-01, -8.8697e-02,\n                        3.2515e-01, -6.0204e-01,  1.2603e-01, -2.1652e+00,  1.4833e-01,\n                       -8.5854e-01, -2.1975e-01, -9.2012e-01, -2.0407e+00, -7.2543e-01,\n                       -3.2715e-01, -8.6850e-01,  6.9493e-01, -1.1081e+00,  6.0416e-01,\n                        1.2786e+00, -6.1319e-01, -5.2599e-01,  1.2950e+00, -3.4967e-01,\n                        9.2084e-02,  9.3442e-01, -1.6499e+00, -2.0960e-01,  6.4199e-01,\n                       -1.3709e+00, -1.4499e+00, -6.5010e-02,  5.2418e-03,  1.6439e+00,\n                       -6.5812e-01, -9.3153e-01,  9.8085e-01,  1.2226e+00,  7.5042e-02,\n                       -1.3482e+00, -8.0241e-02, -2.1095e-01,  1.3949e-01, -2.9481e-03,\n                        1.6491e+00,  6.8881e-01, -1.7138e+00, -1.2591e+00, -5.0412e-02,\n                       -1.1996e-02,  2.8272e-02,  7.8566e-01, -5.3598e-01, -8.0847e-01,\n                       -1.6764e+00,  3.1249e-01, -5.8582e-01, -1.1834e+00,  1.8537e-01,\n                       -4.3358e-01, -1.5854e-01,  5.8319e-01,  3.6000e-01, -1.2810e+00,\n                       -3.2124e-01,  7.0544e-01,  7.7855e-02, -6.6949e-02, -7.7044e-01,\n                        1.2250e+00, -1.9871e+00, -3.9181e-02, -1.0060e-01, -2.8762e-01,\n                       -1.6424e+00, -4.9317e-01,  6.3866e-01, -8.6960e-01,  3.0339e-01,\n                       -5.1454e-01, -1.8951e+00,  7.1387e-02, -1.0554e+00, -8.8342e-01,\n                       -1.0859e+00, -1.7585e+00, -7.9949e-01,  2.9814e-01,  2.1732e-02,\n                        1.2061e+00, -5.1967e-01,  3.5328e-01,  2.6389e-01,  1.1319e+00,\n                       -6.8298e-01, -7.8454e-01, -7.0926e-01, -1.0123e+00, -2.5447e-01,\n                        3.5682e-01,  1.4292e-01,  1.6215e+00, -5.9049e-01, -1.7562e-01,\n                        6.4964e-01,  2.1201e-01, -3.2223e-01, -3.4234e-01,  3.8159e-01,\n                       -1.2436e+00,  4.9370e-01, -1.1373e+00,  9.9600e-02, -2.6617e-02,\n                        8.7616e-02, -1.1003e+00, -9.0084e-01, -1.2461e+00, -1.5382e+00,\n                       -2.8544e-01,  3.6077e-01, -1.7750e+00, -2.0692e-01,  1.3508e+00,\n                       -1.4408e+00, -8.5466e-01, -9.1900e-02, -7.4731e-01, -1.4796e-01,\n                       -9.2823e-01, -6.8582e-01, -5.1497e-01, -1.1244e+00,  1.0441e-01,\n                        3.4820e-01,  2.8321e-01, -9.4946e-01,  2.6956e-02, -7.8006e-01,\n                       -1.3042e+00,  2.6394e-01,  3.5096e-03,  1.1842e+00,  4.8107e-02,\n                        5.2681e-03, -4.7123e-02, -9.4301e-01, -2.2952e+00, -1.1128e+00,\n                        3.1079e-01, -9.3015e-01, -9.1638e-01, -9.1956e-01, -1.6024e-01,\n                       -6.4228e-01,  3.9562e-01, -1.4548e+00, -2.7911e-01, -3.4379e-01,\n                       -1.5607e+00, -7.5875e-01, -1.0027e+00, -2.6845e-01, -4.8075e-01,\n                        2.4783e-01, -1.3513e+00, -4.0091e-01,  1.4133e+00, -8.2318e-01,\n                        9.0853e-01,  5.8520e-01, -9.0077e-01,  1.8723e-03, -4.8363e-01,\n                       -1.0695e-01, -3.2399e-01, -7.3150e-01,  1.9875e+00, -7.0053e-01,\n                       -5.6671e-01, -6.5833e-01])),\n              ('layer2.0.downsample.1.running_var',\n               tensor([1.2458, 0.5691, 0.6584, 0.8626, 0.4088, 0.8155, 0.5329, 0.4362, 0.8491,\n                       1.4762, 0.4502, 0.5258, 0.7926, 0.9714, 1.0532, 0.8537, 0.6616, 1.2542,\n                       1.1388, 0.5214, 0.7811, 0.9767, 0.4465, 0.5496, 0.4291, 0.8805, 0.5239,\n                       0.8988, 2.0866, 0.5829, 1.1155, 0.9523, 0.6583, 1.0367, 0.8784, 1.6478,\n                       0.5867, 0.5532, 0.4048, 1.0759, 0.7177, 0.5248, 0.7371, 0.6623, 1.1719,\n                       0.9013, 0.6471, 0.7029, 0.3077, 0.3486, 0.4324, 0.8720, 0.4121, 0.2807,\n                       0.6210, 0.7423, 1.4693, 0.9750, 2.2615, 0.4492, 0.3885, 0.7099, 1.4172,\n                       0.4647, 0.8614, 1.5630, 0.5966, 0.7588, 0.4852, 1.6153, 1.0142, 0.7665,\n                       0.6339, 0.7533, 1.5143, 0.4500, 0.7851, 0.7778, 1.3026, 1.9642, 2.3319,\n                       0.4996, 0.8081, 0.7572, 1.1820, 0.4481, 1.1862, 0.3397, 0.8130, 1.9119,\n                       0.3059, 0.6048, 0.9044, 1.0767, 1.4991, 0.5247, 0.6798, 0.7053, 0.4876,\n                       1.5881, 0.4484, 0.3094, 0.3104, 0.3640, 0.5033, 0.5014, 0.4529, 0.5182,\n                       0.5273, 0.3517, 1.2497, 0.5352, 1.2693, 0.7068, 0.7272, 0.7698, 0.8335,\n                       0.3023, 0.5940, 0.8038, 0.3145, 0.6288, 1.1024, 0.5731, 0.4611, 0.6279,\n                       1.2489, 0.3221, 0.7936, 1.4737, 0.6909, 1.0188, 0.4712, 0.5425, 1.0224,\n                       1.2443, 0.4633, 0.4026, 1.6862, 0.9931, 0.9641, 0.7693, 1.2114, 0.4891,\n                       0.6920, 0.6289, 0.2588, 0.6166, 0.9629, 1.7282, 0.5813, 0.5785, 0.7056,\n                       0.4995, 0.6392, 1.3471, 0.5498, 0.6269, 0.6095, 0.6912, 1.2110, 0.7554,\n                       0.4950, 0.4875, 0.3912, 1.0701, 0.8364, 0.3572, 1.3632, 1.6728, 0.8347,\n                       0.5356, 0.8295, 1.0108, 0.2818, 0.5566, 0.5805, 0.9917, 0.4882, 0.6585,\n                       1.0446, 0.6443, 0.7317, 0.8538, 0.3977, 0.5559, 0.3701, 0.2625, 0.9514,\n                       0.6003, 0.9059, 1.1013, 0.5756, 0.8581, 0.7928, 0.3752, 0.7421, 0.5474,\n                       0.3913, 0.6521, 1.1942, 0.5564, 0.9137, 0.9976, 0.6911, 0.8161, 0.5899,\n                       0.4750, 1.6257, 0.4435, 0.5429, 1.2540, 1.1591, 0.4015, 0.5434, 0.6348,\n                       0.9876, 0.8818, 0.9781, 0.4180, 0.2582, 0.7664, 0.6438, 0.9100, 0.7085,\n                       0.7123, 0.5085, 0.3249, 0.7795, 0.5652, 2.0794, 0.4709, 0.9363, 0.6349,\n                       0.5044, 0.4367, 1.2358, 0.4600, 0.7940, 0.9718, 0.5766, 1.0458, 0.8865,\n                       1.4256, 1.0686, 0.8338, 1.0819, 0.5203, 0.9010, 1.2375, 1.1962, 1.0180,\n                       1.6259, 0.6837, 0.6265, 0.6221, 0.9494, 0.6973, 0.5934, 0.6439, 0.9860,\n                       0.7025, 0.4003, 0.4377, 2.2741, 0.5775, 0.4650, 1.1278, 0.7356, 0.5836,\n                       0.5292, 0.8432, 0.8201, 0.9732, 0.4759, 1.1190, 1.0873, 1.1880, 0.5521,\n                       0.3105, 0.3907, 0.6761, 1.1225, 1.2263, 0.9704, 0.4994, 0.8434, 1.1198,\n                       1.0132, 0.7442, 2.2416, 0.3562, 0.5998, 1.0050, 0.5857, 1.8965, 0.5312,\n                       1.2446, 0.4682, 1.3936, 0.8254, 1.0649, 0.6916, 1.2072, 0.8575, 0.7014,\n                       0.9569, 0.7800, 0.5639, 0.4540, 0.9571, 0.3992, 0.7656, 0.6844, 0.5291,\n                       1.1657, 0.5359, 0.6859, 0.7815, 1.5135, 1.4468, 1.2104, 0.5081, 0.5872,\n                       0.5872, 0.4299, 0.8690, 0.7632, 0.9788, 0.7662, 1.3344, 0.9697, 1.0008,\n                       0.4669, 1.8294, 1.2300, 0.3733, 0.4612, 1.2579, 0.6997, 0.8955, 0.5898,\n                       0.5710, 1.3003, 0.5591, 0.8520, 2.1741, 0.8736, 1.2270, 0.5751, 0.8238,\n                       0.9428, 0.4427, 0.8109, 0.4279, 1.4726, 0.3748, 2.1430, 0.3092, 0.4965,\n                       1.3107, 1.1800, 1.1982, 0.7987, 0.6357, 0.5540, 0.7154, 0.7371, 0.6115,\n                       0.6538, 1.1722, 0.4730, 0.7773, 0.4380, 0.4575, 0.5244, 0.5687, 1.2591,\n                       0.8454, 0.7264, 1.3181, 0.4716, 0.4905, 0.6349, 0.6426, 1.6518, 0.9807,\n                       0.3820, 0.5748, 0.5836, 0.8873, 0.7816, 0.5187, 0.5456, 1.3058, 0.3864,\n                       0.4154, 0.4431, 0.4439, 0.3617, 0.7718, 0.8536, 0.6402, 0.6334, 1.1383,\n                       0.9008, 0.6417, 0.4631, 0.4508, 0.7070, 0.7146, 2.2967, 0.5143, 1.0293,\n                       1.7009, 1.0575, 0.8831, 0.6677, 0.5488, 1.1847, 0.3861, 0.4716, 1.4157,\n                       0.6013, 1.1852, 0.5533, 2.2796, 0.4897, 0.4530, 0.3115, 0.8089, 0.4544,\n                       0.7932, 0.7626, 0.5474, 0.9279, 0.8111, 0.8075, 1.1727, 1.1243, 1.0769,\n                       1.1281, 1.4509, 0.7424, 0.5474, 0.3903, 0.6545, 0.5880, 0.6308, 1.1588,\n                       0.5944, 0.7254, 1.0508, 0.7538, 0.6924, 0.6089, 0.4622, 0.6786, 0.6637,\n                       0.7099, 1.4633, 0.8587, 1.0671, 0.8189, 0.7177, 1.0325, 0.3057, 1.0172,\n                       0.4574, 0.3762, 1.0767, 0.7615, 1.1699, 0.4451, 0.6455, 0.5842, 0.8301,\n                       1.7583, 1.6958, 1.1451, 0.8916, 0.4328, 0.5105, 1.6931, 0.8523, 0.6237,\n                       0.7124, 1.2292, 0.6660, 0.9771, 3.0886, 1.0889, 0.9746, 0.5605, 0.4523,\n                       0.6624, 0.2883, 1.9144, 1.3555, 0.5351, 0.3107, 0.3549, 0.9935, 0.6254,\n                       0.6821, 0.7874, 0.4430, 0.7022, 0.8907, 1.0000, 0.5655, 0.6297])),\n              ('layer2.0.downsample.1.num_batches_tracked', tensor(13572)),\n              ('layer2.1.conv1.weight',\n               tensor([[[[ 0.0160]],\n               \n                        [[ 0.0118]],\n               \n                        [[ 0.0669]],\n               \n                        ...,\n               \n                        [[-0.0659]],\n               \n                        [[ 0.0961]],\n               \n                        [[ 0.0411]]],\n               \n               \n                       [[[ 0.0521]],\n               \n                        [[-0.0089]],\n               \n                        [[ 0.0011]],\n               \n                        ...,\n               \n                        [[ 0.0119]],\n               \n                        [[-0.0086]],\n               \n                        [[ 0.0250]]],\n               \n               \n                       [[[ 0.0772]],\n               \n                        [[-0.0766]],\n               \n                        [[ 0.0131]],\n               \n                        ...,\n               \n                        [[ 0.0532]],\n               \n                        [[ 0.1393]],\n               \n                        [[-0.0008]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0019]],\n               \n                        [[ 0.0352]],\n               \n                        [[ 0.0868]],\n               \n                        ...,\n               \n                        [[ 0.0659]],\n               \n                        [[-0.0068]],\n               \n                        [[ 0.0689]]],\n               \n               \n                       [[[ 0.0217]],\n               \n                        [[-0.0154]],\n               \n                        [[-0.0380]],\n               \n                        ...,\n               \n                        [[ 0.0378]],\n               \n                        [[-0.0685]],\n               \n                        [[-0.0402]]],\n               \n               \n                       [[[-0.0366]],\n               \n                        [[ 0.0757]],\n               \n                        [[ 0.0774]],\n               \n                        ...,\n               \n                        [[ 0.0262]],\n               \n                        [[ 0.0226]],\n               \n                        [[ 0.0278]]]])),\n              ('layer2.1.bn1.weight',\n               tensor([1.0300, 1.0532, 1.0611, 0.9994, 1.0145, 0.9377, 0.9652, 0.9961, 1.0421,\n                       0.9858, 0.9582, 1.0690, 0.9991, 1.0251, 1.0777, 0.9713, 1.1052, 0.9802,\n                       0.9697, 0.9794, 1.0288, 1.0023, 1.0943, 1.0529, 0.9624, 1.0157, 1.0580,\n                       0.9667, 1.0365, 1.0277, 1.3263, 0.9249, 1.0208, 1.0338, 0.9655, 1.0153,\n                       0.9406, 0.8959, 1.0460, 1.0760, 0.9660, 0.9605, 1.0362, 0.9902, 0.9249,\n                       0.9761, 1.0257, 1.0844, 0.9033, 0.9535, 0.9316, 1.0467, 0.9492, 0.9996,\n                       0.9629, 0.8883, 0.9986, 0.9866, 1.0672, 1.0546, 1.0300, 0.9572, 1.0128,\n                       1.0011, 0.8785, 1.0398, 0.9870, 0.9042, 1.0054, 1.0448, 1.0649, 1.0318,\n                       0.9660, 1.0399, 0.9885, 0.9541, 0.8714, 1.0109, 1.0188, 1.0257, 0.9989,\n                       0.9703, 0.9669, 0.9988, 0.9096, 1.0475, 0.9627, 1.0147, 0.9252, 1.0057,\n                       0.9541, 1.0316, 0.9603, 0.9374, 0.9079, 1.0014, 1.0914, 0.9808, 0.9856,\n                       1.0053, 1.0731, 1.0614, 0.8778, 1.0310, 1.0284, 1.0002, 0.9443, 1.0734,\n                       0.9235, 1.0282, 0.9573, 0.9833, 1.0083, 1.0048, 0.9777, 0.9405, 1.0271,\n                       1.0619, 0.9615, 0.9580, 0.9864, 1.0252, 0.9540, 0.9587, 0.9898, 0.9359,\n                       1.0305, 0.9986])),\n              ('layer2.1.bn1.bias',\n               tensor([ 0.0232, -0.0324,  0.0419,  0.0375,  0.1210,  0.0340, -0.0600,  0.0267,\n                        0.0908, -0.0119, -0.0381,  0.0717, -0.0148,  0.0477,  0.0845,  0.0026,\n                        0.0931, -0.0036, -0.0036, -0.0361,  0.0265,  0.1214,  0.0757,  0.1820,\n                        0.0636,  0.0416,  0.0079,  0.0090, -0.0230,  0.0543,  0.1611,  0.0514,\n                       -0.0656,  0.0206,  0.0654,  0.0724, -0.0994, -0.0187,  0.0506,  0.0667,\n                        0.0238, -0.0074,  0.1333, -0.0037, -0.0530,  0.0563,  0.0382,  0.0969,\n                       -0.0034,  0.0487,  0.0976,  0.0549, -0.0273,  0.1056,  0.0094, -0.0160,\n                        0.0273, -0.0259,  0.1002, -0.1043, -0.0866,  0.0351,  0.0456,  0.0835,\n                       -0.0046, -0.0085,  0.0886, -0.1009,  0.0429,  0.0674,  0.1163,  0.0550,\n                        0.0645,  0.0366,  0.0592, -0.0447, -0.0400,  0.0041,  0.0368,  0.0799,\n                        0.0721,  0.0840,  0.0278,  0.0380, -0.0396,  0.1100,  0.0364,  0.0566,\n                        0.0024,  0.0200, -0.0364,  0.1432,  0.0205,  0.0967, -0.0257, -0.0014,\n                        0.0543, -0.0182,  0.0368,  0.0998,  0.0803,  0.0891, -0.1121,  0.0477,\n                        0.0330, -0.0185, -0.0040,  0.1143, -0.0599, -0.0679, -0.0587,  0.0601,\n                       -0.0399,  0.0580,  0.0211, -0.0133,  0.1562,  0.0453,  0.0053,  0.0264,\n                       -0.0591,  0.0084, -0.0540, -0.0036, -0.0643, -0.1181,  0.0180,  0.0032])),\n              ('layer2.1.bn1.running_mean',\n               tensor([-3.7546e-01,  9.0655e-01, -1.6368e-01,  4.2074e-01, -4.7584e-01,\n                       -9.8071e-01, -3.6752e-01, -1.1757e+00, -1.5625e+00,  1.4076e-01,\n                       -5.5192e-01, -4.0629e-01,  5.9292e-01,  2.0062e-01, -1.0329e+00,\n                       -9.1384e-01, -2.1044e-01,  3.0528e-02, -2.1695e-01, -6.1418e-01,\n                       -4.6141e-01, -9.2968e-01,  2.1542e-01, -5.5676e-01,  1.9089e-02,\n                        5.0341e-01,  4.6830e-01, -7.6987e-01, -4.5441e-01, -3.4934e-01,\n                       -1.7365e-01, -8.6543e-02,  7.1944e-01,  6.8940e-02,  1.5351e-01,\n                       -1.9593e-01,  7.3418e-02, -5.9988e-02,  1.0465e+00,  3.1480e-01,\n                        1.9198e-01, -9.3765e-01, -5.0293e-02, -5.0152e-01, -9.6866e-02,\n                       -3.3544e-01, -8.4439e-01, -2.1912e-01, -5.6081e-01, -1.1445e+00,\n                       -1.7651e+00,  6.1339e-02, -5.6411e-01, -1.0443e+00, -2.4211e+00,\n                        1.3149e+00,  5.2419e-01,  3.2759e-01, -3.7362e-01,  7.9009e-01,\n                        4.5490e-01, -6.6873e-01, -4.6125e-01, -2.0160e-02,  5.4530e-01,\n                       -4.4821e-01, -9.8258e-01, -4.5019e-01, -2.1037e-01,  2.5919e-01,\n                       -8.1537e-01, -1.4489e-01, -1.1759e+00,  1.1146e+00,  5.6563e-01,\n                        2.2803e-02,  1.7233e-01, -7.7900e-02, -1.8690e+00, -7.9143e-01,\n                        4.5797e-01, -7.7849e-01, -8.3755e-01,  5.3134e-02,  1.1844e+00,\n                       -7.5775e-01,  1.7429e-01,  1.8787e-01,  4.6009e-01, -1.8475e-01,\n                       -3.5968e-02, -1.5542e+00, -1.4000e+00, -1.7007e+00, -2.5531e-01,\n                       -1.1262e+00, -2.1694e+00, -8.1337e-01,  1.1069e+00, -5.8711e-01,\n                        4.7342e-02, -3.3489e-01,  3.0335e-01, -1.1296e-02,  1.1055e-01,\n                       -8.5510e-01,  9.9042e-01,  2.9893e-01, -1.8212e-01,  1.1153e+00,\n                       -3.2051e-01, -3.1815e-01, -3.5056e-01,  3.0288e-01,  2.0143e-01,\n                        8.5794e-01, -4.6788e-01, -1.3650e+00, -5.8528e-01,  5.8480e-01,\n                        3.4216e-02, -1.2281e+00,  5.5405e-01, -1.5584e-02, -3.6869e-01,\n                        6.5076e-02, -1.1157e+00, -2.0860e-04])),\n              ('layer2.1.bn1.running_var',\n               tensor([2.1152, 0.9997, 1.6729, 1.5805, 1.5535, 1.6841, 1.2243, 1.5546, 1.4317,\n                       1.5184, 1.4628, 1.6244, 1.2408, 0.9238, 2.9200, 1.7547, 1.2275, 1.4157,\n                       1.4881, 0.9054, 2.0208, 1.4272, 2.5026, 2.4914, 0.9349, 2.5301, 1.2813,\n                       1.5322, 1.0700, 1.4902, 1.5992, 0.9887, 1.3906, 1.4120, 1.0355, 1.8407,\n                       1.3887, 1.2947, 1.3191, 1.8071, 1.9693, 0.9000, 1.4721, 1.8235, 1.0795,\n                       1.1910, 2.2381, 0.9525, 1.4041, 3.5658, 0.7800, 1.8803, 0.9938, 1.6441,\n                       1.8738, 1.5834, 1.3177, 1.2366, 1.2906, 1.2701, 0.8300, 1.8111, 2.5465,\n                       1.2283, 1.2321, 2.4950, 1.0883, 0.9208, 1.1130, 0.9154, 1.7120, 1.4559,\n                       1.1393, 1.5732, 1.5105, 0.6970, 1.1293, 1.5974, 1.9256, 1.5516, 1.0769,\n                       0.9905, 1.9520, 1.1143, 0.9465, 1.5021, 1.5091, 0.8429, 1.5799, 1.9300,\n                       1.1823, 1.0256, 1.4773, 1.2590, 1.4475, 1.1187, 1.7619, 2.9386, 1.1620,\n                       1.7014, 1.4723, 1.7824, 1.0957, 1.4252, 1.8982, 1.9090, 1.6162, 1.6549,\n                       1.0506, 0.9470, 1.7297, 1.0500, 1.5207, 1.3830, 1.8704, 1.4715, 1.4127,\n                       1.7515, 2.2053, 1.3139, 1.0172, 2.3734, 1.4817, 1.1879, 1.0832, 0.9180,\n                       2.6490, 1.2847])),\n              ('layer2.1.bn1.num_batches_tracked', tensor(13572)),\n              ('layer2.1.conv2.weight',\n               tensor([[[[ 7.7208e-03,  1.6740e-03,  7.2345e-03],\n                         [-1.1016e-02, -1.1497e-01, -2.5973e-02],\n                         [ 5.7644e-03,  5.5245e-02, -6.2795e-03]],\n               \n                        [[-2.4330e-03, -6.0018e-02,  2.7336e-02],\n                         [ 1.4213e-02,  4.9608e-03, -5.5082e-02],\n                         [ 2.8109e-02,  5.4030e-05, -1.6010e-02]],\n               \n                        [[ 1.6814e-02, -1.2095e-02,  6.6236e-04],\n                         [-2.5522e-02, -3.9558e-02, -1.9762e-02],\n                         [-1.0677e-02,  6.2000e-02, -1.1147e-02]],\n               \n                        ...,\n               \n                        [[-1.2519e-02, -2.3629e-02, -1.9015e-02],\n                         [-4.7805e-02, -2.1182e-02,  2.1039e-02],\n                         [-1.0548e-03,  2.6021e-02,  3.7764e-03]],\n               \n                        [[-2.4327e-02,  1.3088e-03, -1.6783e-02],\n                         [ 1.4114e-02, -9.1921e-03,  9.4881e-04],\n                         [-4.9334e-02,  2.3091e-02,  4.9383e-03]],\n               \n                        [[ 4.2889e-02, -1.9679e-02, -5.8134e-03],\n                         [-3.4080e-02,  3.5085e-02, -1.7101e-02],\n                         [-7.3449e-03,  1.9147e-02,  4.0576e-02]]],\n               \n               \n                       [[[ 8.3348e-04,  3.0365e-02, -3.7364e-02],\n                         [ 2.1272e-02, -1.4856e-03, -7.6929e-02],\n                         [-6.4915e-03, -6.1275e-02, -4.4019e-02]],\n               \n                        [[ 4.1678e-02,  3.0794e-02, -1.6469e-02],\n                         [-3.4170e-03, -2.4807e-02, -2.7399e-02],\n                         [ 9.5470e-03,  1.4451e-02, -3.3329e-02]],\n               \n                        [[-3.7725e-02,  3.8575e-02,  8.8528e-03],\n                         [-2.9850e-02, -2.0754e-02, -1.2521e-02],\n                         [ 2.5723e-03,  2.9815e-02, -6.7951e-02]],\n               \n                        ...,\n               \n                        [[ 1.9164e-02, -1.9378e-02, -8.9392e-03],\n                         [-1.0674e-02,  5.2541e-02, -5.8299e-02],\n                         [ 4.6915e-02, -7.7902e-02, -4.6475e-02]],\n               \n                        [[-1.8347e-02, -4.6903e-02,  1.1195e-02],\n                         [ 2.4458e-02, -9.6136e-03,  4.1138e-02],\n                         [-7.3119e-03, -2.2813e-02,  1.7921e-02]],\n               \n                        [[ 5.2836e-02, -3.1205e-02, -3.5325e-02],\n                         [-3.3250e-02,  3.1017e-02, -3.7767e-02],\n                         [-1.2230e-02, -8.5491e-02, -8.2552e-03]]],\n               \n               \n                       [[[ 5.7707e-02,  2.1465e-02, -5.3290e-02],\n                         [ 7.9865e-02,  4.2155e-02, -3.6607e-03],\n                         [-2.2376e-02, -9.2579e-03,  5.6089e-03]],\n               \n                        [[ 1.5599e-02,  4.4849e-02,  2.6128e-03],\n                         [ 1.5874e-02,  1.9849e-02, -5.1528e-03],\n                         [-8.9397e-03,  5.1475e-02,  6.2767e-02]],\n               \n                        [[-3.6243e-02, -5.2014e-02, -6.4107e-02],\n                         [-2.1890e-03,  6.8414e-02,  2.0339e-02],\n                         [-1.2077e-02,  2.2565e-02, -1.0152e-03]],\n               \n                        ...,\n               \n                        [[-3.8023e-02, -4.1272e-02,  1.5834e-02],\n                         [-4.1753e-02, -6.0186e-02, -1.3013e-02],\n                         [-8.5619e-03, -4.7420e-03,  4.4411e-03]],\n               \n                        [[ 6.1878e-02,  2.7364e-02, -8.4938e-03],\n                         [ 4.0741e-02, -5.6347e-02, -4.0807e-03],\n                         [ 1.9883e-02,  2.8904e-02,  4.5293e-02]],\n               \n                        [[ 3.2185e-02,  8.7092e-02, -9.5166e-03],\n                         [ 2.3113e-02, -8.2378e-02, -1.8627e-02],\n                         [-1.5078e-02,  1.1025e-01,  2.3264e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-1.3692e-02,  5.6480e-02,  9.0908e-02],\n                         [ 3.7413e-02,  2.6805e-02,  1.4243e-02],\n                         [ 3.2909e-02,  3.9958e-02,  2.4577e-02]],\n               \n                        [[-5.2520e-02, -2.1382e-02, -6.4666e-02],\n                         [-4.7125e-02, -2.3958e-02, -7.3733e-02],\n                         [ 2.5777e-02, -4.3289e-02, -1.1181e-02]],\n               \n                        [[ 3.4529e-02,  5.7082e-02,  2.6187e-02],\n                         [ 1.7553e-02,  4.7816e-03, -2.5930e-03],\n                         [-3.7120e-02,  2.7889e-02,  3.5806e-02]],\n               \n                        ...,\n               \n                        [[-1.0656e-01, -4.4174e-02,  4.7553e-02],\n                         [-2.1627e-02, -1.9330e-02,  2.8131e-03],\n                         [ 1.0483e-02, -4.6773e-02, -4.3095e-02]],\n               \n                        [[ 2.8759e-02,  4.4272e-02,  1.0092e-02],\n                         [-3.0583e-03,  4.1698e-03,  5.5940e-02],\n                         [ 2.5951e-02, -1.8005e-02,  1.6718e-02]],\n               \n                        [[-1.8488e-02, -3.3317e-02, -3.8265e-02],\n                         [ 2.0532e-02,  2.3151e-02,  2.0193e-03],\n                         [-4.1862e-02, -1.6087e-02,  1.9595e-02]]],\n               \n               \n                       [[[ 3.5998e-03,  1.8790e-02,  5.6773e-02],\n                         [ 3.8598e-02,  7.4191e-02,  5.0924e-02],\n                         [ 2.8814e-02,  3.2331e-02,  9.7264e-03]],\n               \n                        [[ 2.9704e-03,  2.1554e-02,  1.6278e-02],\n                         [-3.0993e-02,  9.5438e-04,  3.7083e-02],\n                         [ 2.1538e-04, -4.5704e-02, -3.1957e-02]],\n               \n                        [[ 2.6786e-02, -3.5351e-02,  8.6928e-03],\n                         [ 6.8253e-02,  5.9089e-03,  6.2040e-02],\n                         [ 4.8291e-03, -2.9267e-02, -4.8295e-02]],\n               \n                        ...,\n               \n                        [[ 1.0988e-02, -1.9325e-02, -3.9188e-02],\n                         [ 7.7195e-03, -2.8060e-04, -4.1958e-02],\n                         [-1.6954e-02, -3.8498e-02, -1.6727e-02]],\n               \n                        [[-4.3857e-02,  3.5910e-02, -2.4901e-02],\n                         [-6.6496e-02, -2.0176e-02, -1.0054e-02],\n                         [-8.5710e-02, -7.4051e-02,  4.4442e-02]],\n               \n                        [[-2.5402e-02, -2.5062e-02,  4.9806e-03],\n                         [ 7.3087e-03, -1.4033e-03,  4.5888e-02],\n                         [-2.4673e-02,  6.6438e-02,  2.1422e-02]]],\n               \n               \n                       [[[-1.1395e-02, -3.7063e-02, -2.3089e-02],\n                         [ 1.2365e-02, -7.0040e-03, -5.8612e-02],\n                         [-7.8782e-03, -2.3621e-02,  4.6038e-04]],\n               \n                        [[ 1.5690e-02, -3.7948e-02,  1.6080e-02],\n                         [-2.9367e-02,  7.0000e-02,  1.1179e-02],\n                         [ 1.3075e-02, -2.8740e-02, -9.0408e-03]],\n               \n                        [[-8.7749e-02,  6.2638e-03, -4.6221e-02],\n                         [ 4.2901e-02,  3.1809e-02, -6.0184e-02],\n                         [ 1.6328e-02,  1.2095e-02, -1.6935e-02]],\n               \n                        ...,\n               \n                        [[ 2.2551e-02,  1.5864e-02, -1.9348e-02],\n                         [-2.8672e-03, -1.8676e-02, -5.0099e-03],\n                         [-7.1295e-03, -2.1417e-02,  1.2585e-02]],\n               \n                        [[-4.2103e-02, -5.2559e-02,  2.0304e-02],\n                         [ 1.6011e-02, -1.3961e-02,  1.0355e-01],\n                         [-4.2282e-03,  6.8616e-02,  7.0098e-02]],\n               \n                        [[-1.4589e-02,  4.7515e-02, -2.6589e-02],\n                         [ 5.2914e-02, -6.0533e-02,  6.7787e-03],\n                         [ 9.4745e-03,  3.6754e-03,  1.1648e-02]]]])),\n              ('layer2.1.bn2.weight',\n               tensor([1.0015, 1.0706, 0.9501, 1.0215, 1.0338, 0.9621, 0.9819, 0.9521, 1.0451,\n                       0.8793, 0.9712, 0.9439, 0.9802, 0.9511, 0.9744, 1.0314, 0.9211, 0.9537,\n                       0.9358, 0.9500, 0.9924, 1.0412, 0.9603, 0.9677, 1.0016, 1.0550, 1.0526,\n                       0.8844, 1.1921, 1.0286, 1.0304, 0.9351, 0.8894, 1.0416, 1.0422, 0.9535,\n                       1.0406, 1.0679, 1.0032, 0.9573, 1.0683, 0.9623, 0.9110, 0.9193, 1.0810,\n                       1.0243, 1.0149, 0.9685, 1.1197, 0.9111, 0.9756, 0.9533, 0.9916, 1.0001,\n                       0.9597, 1.1768, 1.1177, 0.9620, 0.9575, 0.9975, 0.9844, 1.0312, 0.9690,\n                       0.9183, 0.9850, 0.9396, 1.0308, 1.0792, 0.9913, 1.0009, 0.9424, 0.9669,\n                       0.9859, 0.9618, 0.9443, 1.0332, 1.0339, 1.0220, 0.9382, 1.0748, 0.9602,\n                       1.0673, 1.1411, 0.9333, 0.8854, 0.9967, 0.9698, 0.9803, 0.9432, 0.9476,\n                       1.0675, 0.9613, 0.9671, 0.9657, 0.9642, 1.0389, 0.9646, 0.8725, 0.9522,\n                       0.9512, 0.9906, 0.9316, 1.0330, 1.0544, 1.0141, 0.9998, 1.1258, 1.0709,\n                       1.0201, 0.9015, 0.9929, 0.9626, 1.0386, 0.9972, 0.9391, 0.9546, 0.9487,\n                       1.1188, 0.9611, 1.0385, 0.9809, 1.0811, 0.9773, 0.9733, 0.9659, 0.9386,\n                       0.9962, 0.9757])),\n              ('layer2.1.bn2.bias',\n               tensor([-0.0795, -0.0354,  0.0091, -0.0142, -0.0329, -0.1616,  0.0359,  0.0058,\n                       -0.0223, -0.0157, -0.1304, -0.0503, -0.1423, -0.0182, -0.0343, -0.1681,\n                       -0.0609, -0.0401, -0.1101, -0.0537, -0.1646, -0.2390, -0.1265, -0.0244,\n                       -0.0664, -0.0541, -0.1551,  0.0146, -0.0624,  0.1557, -0.1516,  0.1096,\n                       -0.2505, -0.0935, -0.0733, -0.0154, -0.1850, -0.1708, -0.0679, -0.0157,\n                       -0.1126, -0.1675,  0.1244, -0.0061, -0.1401, -0.2096, -0.0244, -0.0191,\n                        0.0461, -0.0784, -0.0926, -0.0665,  0.0452, -0.0349,  0.0451, -0.0393,\n                       -0.0417,  0.0224,  0.0604, -0.1397, -0.1145,  0.0041, -0.0091, -0.2243,\n                       -0.1540, -0.0899, -0.0963, -0.1357, -0.0748, -0.0444, -0.0533, -0.0483,\n                        0.0208, -0.1444,  0.0037, -0.0591, -0.1663, -0.0571, -0.0009,  0.0207,\n                       -0.1303, -0.1161, -0.0038, -0.1913,  0.0175,  0.0274, -0.0711, -0.0148,\n                       -0.1323, -0.0287, -0.1887, -0.0233, -0.0686, -0.0398,  0.0098, -0.1541,\n                       -0.1881, -0.1249,  0.0675,  0.0020,  0.0861, -0.1051, -0.1556, -0.0234,\n                        0.1203, -0.0451, -0.1831, -0.0144, -0.2329,  0.0211, -0.0357, -0.1044,\n                       -0.1638, -0.0790, -0.2291, -0.0555, -0.0030, -0.1654, -0.0193, -0.0263,\n                       -0.1490, -0.1236,  0.1691,  0.0832, -0.1501, -0.0275, -0.0005,  0.0447])),\n              ('layer2.1.bn2.running_mean',\n               tensor([-1.2531e+00,  2.3847e-01,  1.9868e-01,  4.5215e-01, -4.4851e-01,\n                       -1.3160e+00, -8.6642e-01, -2.6765e-02, -7.4193e-01, -6.8196e-03,\n                       -1.1257e+00,  1.7239e-01,  1.3532e-01, -2.6509e-01,  2.1089e-01,\n                       -8.8951e-01, -3.7983e-01, -1.3026e-01, -8.3187e-01, -5.0929e-01,\n                       -1.3046e+00, -3.3510e-01,  1.2523e-01, -2.1950e-01, -4.8546e-01,\n                       -1.1913e+00, -2.3071e+00, -4.8739e-01, -7.7504e-01,  1.8460e+00,\n                       -6.2167e-02,  8.9438e-01, -1.3185e+00, -1.3288e+00,  2.8539e-01,\n                        1.7373e-01,  5.7546e-02, -6.6539e-01,  1.4165e-01,  1.1338e+00,\n                       -6.6376e-02, -5.5192e-01,  2.7619e-01, -9.4200e-01, -1.9201e-02,\n                       -1.0094e+00,  9.2954e-01,  9.4382e-01, -3.2673e-01,  6.3783e-01,\n                       -1.4855e+00,  1.2314e+00, -7.3140e-01, -8.0670e-01, -4.7880e-02,\n                       -3.6229e-01,  2.7278e-01,  1.7670e-01,  6.9980e-01, -8.1035e-01,\n                       -5.3307e-01, -1.9778e+00,  3.1711e-02, -1.2807e+00,  6.7496e-01,\n                       -6.5371e-01,  9.6156e-01,  1.4497e-01, -4.0234e-02,  4.3086e-01,\n                       -1.4650e+00, -2.1487e-01,  2.2569e-01, -2.0494e-01, -9.0502e-01,\n                       -5.2885e-01,  3.2546e-01, -5.0548e-01,  7.0148e-01, -5.8516e-01,\n                       -8.5251e-01,  4.4368e-01, -9.2615e-01, -1.1800e+00,  1.3047e-01,\n                        1.5134e+00, -1.1981e+00, -2.6410e-01, -1.2869e+00, -5.7077e-01,\n                        4.2576e-01,  3.1185e+00, -6.5136e-01,  6.6470e-01, -5.5603e-04,\n                        4.9481e-01, -6.3797e-02,  6.0591e-02, -4.3840e-01, -1.2903e+00,\n                       -6.5640e-01, -3.6425e-01,  3.2844e-01, -7.8075e-01, -6.8216e-01,\n                       -1.5798e+00,  7.0305e-01,  1.2933e-01, -4.4764e-01,  3.8990e-02,\n                       -6.3898e-01,  3.7556e-01, -7.0099e-01, -8.4724e-01,  2.1070e-01,\n                       -8.1178e-01, -1.8683e-01, -3.8490e-01, -6.9407e-01, -5.6918e-01,\n                       -1.1531e+00, -3.4612e-01,  3.2339e-01, -3.4506e-01, -1.3205e+00,\n                       -1.3805e+00, -1.3475e+00,  4.4123e-01])),\n              ('layer2.1.bn2.running_var',\n               tensor([2.2738, 1.3699, 0.9616, 0.8421, 1.2459, 1.1798, 0.8491, 1.1375, 1.7709,\n                       0.8494, 1.2658, 1.0980, 1.3155, 0.7309, 0.8689, 2.3792, 1.8299, 1.2316,\n                       0.9901, 1.4073, 1.7787, 1.3769, 1.4960, 1.7028, 1.5738, 2.4498, 1.8932,\n                       1.6877, 2.8801, 1.5197, 1.4215, 1.0018, 1.7559, 1.4160, 0.9870, 0.8689,\n                       1.1840, 1.2244, 1.0547, 0.9996, 1.3050, 1.4398, 1.1303, 1.0619, 1.5673,\n                       1.5540, 1.2454, 1.2191, 2.5524, 1.0383, 1.3137, 1.1560, 0.9259, 1.0249,\n                       0.9571, 1.7342, 1.1781, 1.0947, 1.3581, 2.0695, 0.7634, 0.8727, 0.8956,\n                       2.4146, 1.0791, 0.9953, 1.5330, 1.0684, 1.2637, 0.9559, 1.1632, 1.1437,\n                       2.1761, 0.9044, 1.0038, 1.5915, 1.1602, 1.1521, 0.9813, 1.1714, 1.1149,\n                       1.5526, 2.2405, 1.7425, 1.1555, 1.4592, 1.7220, 1.1104, 1.4045, 1.0882,\n                       1.5792, 1.6170, 1.5692, 1.6691, 0.8731, 1.2511, 2.0772, 1.3621, 1.1781,\n                       0.8179, 0.9833, 0.8595, 1.3901, 1.4742, 1.1562, 0.8791, 1.4215, 1.5371,\n                       0.7896, 0.8704, 0.8794, 1.1126, 1.8977, 1.3413, 0.7022, 1.1176, 0.8381,\n                       1.1982, 1.5206, 1.4261, 1.1163, 1.8216, 1.2669, 1.2842, 1.1886, 2.3894,\n                       0.9332, 0.9051])),\n              ('layer2.1.bn2.num_batches_tracked', tensor(13572)),\n              ('layer2.1.conv3.weight',\n               tensor([[[[ 0.0151]],\n               \n                        [[ 0.0069]],\n               \n                        [[ 0.0411]],\n               \n                        ...,\n               \n                        [[-0.0246]],\n               \n                        [[-0.0308]],\n               \n                        [[-0.0229]]],\n               \n               \n                       [[[ 0.0930]],\n               \n                        [[-0.0397]],\n               \n                        [[-0.0734]],\n               \n                        ...,\n               \n                        [[ 0.0325]],\n               \n                        [[ 0.0263]],\n               \n                        [[-0.0665]]],\n               \n               \n                       [[[ 0.0797]],\n               \n                        [[-0.0265]],\n               \n                        [[ 0.0122]],\n               \n                        ...,\n               \n                        [[-0.0256]],\n               \n                        [[ 0.0314]],\n               \n                        [[-0.0190]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0676]],\n               \n                        [[-0.0120]],\n               \n                        [[-0.0591]],\n               \n                        ...,\n               \n                        [[-0.0340]],\n               \n                        [[ 0.0599]],\n               \n                        [[-0.0687]]],\n               \n               \n                       [[[ 0.0103]],\n               \n                        [[-0.0390]],\n               \n                        [[-0.0081]],\n               \n                        ...,\n               \n                        [[ 0.0026]],\n               \n                        [[ 0.0591]],\n               \n                        [[-0.0326]]],\n               \n               \n                       [[[ 0.0126]],\n               \n                        [[ 0.0431]],\n               \n                        [[-0.0093]],\n               \n                        ...,\n               \n                        [[ 0.0130]],\n               \n                        [[-0.0521]],\n               \n                        [[ 0.0070]]]])),\n              ('layer2.1.bn3.weight',\n               tensor([-0.1334, -0.1247,  0.1470,  0.1812, -0.2360, -0.1712, -0.2239,  0.2646,\n                        0.1555,  0.2039,  0.1717, -0.2975,  0.2949, -0.0297,  0.2823, -0.2029,\n                       -0.3384, -0.2228,  0.2840, -0.1735,  0.1843, -0.2487, -0.1721, -0.3487,\n                        0.1160,  0.2518,  0.1477,  0.2192, -0.2009,  0.1812,  0.1227, -0.3012,\n                        0.3892, -0.2679,  0.3100, -0.0963, -0.2215, -0.0723,  0.0899,  0.2994,\n                        0.1281,  0.3432, -0.1547, -0.2695, -0.0496,  0.3605,  0.2618,  0.2417,\n                        0.1911,  0.0958, -0.2401,  0.1467, -0.0741,  0.0046,  0.2805, -0.2099,\n                       -0.3417, -0.1982, -0.2050, -0.2453,  0.2945, -0.1172,  0.3559,  0.2020,\n                       -0.2692, -0.2607, -0.1176, -0.2062, -0.2347, -0.2434,  0.1712, -0.2718,\n                       -0.2994, -0.1230,  0.2889, -0.0542,  0.1216, -0.1643,  0.2065, -0.2931,\n                        0.3136,  0.0530, -0.2997, -0.1421,  0.1543, -0.0558, -0.2746,  0.0177,\n                       -0.2489,  0.1283, -0.0441,  0.0780, -0.2140,  0.2438, -0.3599,  0.2625,\n                       -0.1989,  0.1686,  0.2413, -0.1472,  0.2711, -0.1314,  0.0873, -0.2339,\n                        0.1671,  0.0893, -0.1534, -0.0951, -0.3642, -0.0375, -0.2208, -0.0428,\n                        0.2804,  0.2138,  0.0086,  0.2407,  0.3624,  0.0137, -0.1560, -0.1129,\n                        0.0865,  0.2547,  0.0398, -0.2332,  0.2659, -0.3684, -0.2393, -0.2728,\n                        0.0512, -0.1453, -0.2090, -0.2341,  0.1536,  0.1764,  0.3115,  0.2227,\n                        0.2601, -0.1218,  0.3273,  0.3345,  0.2437, -0.3576,  0.0534,  0.2066,\n                       -0.2062, -0.0589,  0.1183,  0.2371,  0.2487,  0.2461, -0.2991, -0.2376,\n                       -0.2923,  0.0335,  0.3301,  0.3351,  0.0429, -0.2900, -0.1617, -0.3057,\n                        0.3052,  0.2214, -0.0583, -0.0208, -0.1847,  0.1198, -0.2602, -0.0949,\n                       -0.2726,  0.3346, -0.1814, -0.1515, -0.1126, -0.1512,  0.0975, -0.2654,\n                       -0.2391,  0.3115, -0.1628, -0.0262,  0.1160,  0.2224,  0.1799, -0.2443,\n                       -0.3241,  0.3194, -0.1477, -0.0141,  0.2304,  0.1508,  0.1488,  0.1144,\n                       -0.1089,  0.2487, -0.3261, -0.1910, -0.2329, -0.1419,  0.0347, -0.2451,\n                        0.0284, -0.2374,  0.2461,  0.1444, -0.0178, -0.2577, -0.1794,  0.1401,\n                       -0.0133,  0.1479,  0.2341, -0.2796,  0.3029,  0.1751, -0.1899,  0.2195,\n                        0.2509,  0.2598, -0.3499, -0.2052, -0.1152,  0.2819, -0.2539, -0.2535,\n                        0.3251, -0.2442, -0.1564,  0.0986, -0.1791, -0.2447,  0.3076, -0.1294,\n                        0.3079,  0.2640,  0.2268,  0.3924, -0.2334, -0.2380,  0.2210, -0.3173,\n                        0.0620,  0.3198,  0.2240, -0.0891, -0.1639,  0.2787,  0.1227,  0.0972,\n                       -0.2533, -0.2800, -0.2910,  0.1769,  0.2001, -0.1971, -0.0478,  0.2064,\n                       -0.1358,  0.1501,  0.1744, -0.3332,  0.1984,  0.1823, -0.2286, -0.2289,\n                       -0.0461,  0.2696,  0.0954, -0.1678, -0.1736,  0.2949,  0.0638,  0.1814,\n                       -0.3746,  0.1102, -0.1816, -0.2256,  0.1037,  0.2991,  0.0847, -0.2258,\n                        0.1722,  0.0357, -0.2008, -0.2982, -0.1694, -0.2156, -0.2662,  0.3673,\n                        0.3395,  0.1923, -0.3488, -0.1581, -0.2701,  0.1873, -0.1230, -0.0105,\n                        0.2377,  0.3038, -0.1405, -0.2098,  0.2408,  0.2578,  0.2259,  0.2916,\n                        0.3557, -0.0898, -0.2881,  0.1487,  0.2770,  0.2392,  0.2670, -0.1766,\n                       -0.2675,  0.1689, -0.1846,  0.1323,  0.1604,  0.2139,  0.3209,  0.0300,\n                        0.1997,  0.2485, -0.1093, -0.1957, -0.1855, -0.1793,  0.1187, -0.3125,\n                       -0.3687, -0.0567, -0.2350, -0.1638, -0.1778,  0.1547,  0.2997,  0.3265,\n                       -0.1875, -0.1295,  0.3757, -0.2410, -0.1777, -0.2116,  0.1796, -0.2462,\n                       -0.2731,  0.2403, -0.1214,  0.2622,  0.2982,  0.2460,  0.2870, -0.1608,\n                        0.1354,  0.3146, -0.0904, -0.3172,  0.3161, -0.1350,  0.0025, -0.0252,\n                        0.3532,  0.1029, -0.3548, -0.2826,  0.3032,  0.1817, -0.2431,  0.3082,\n                        0.2263, -0.2598,  0.0694,  0.1325, -0.1582, -0.0271, -0.2088,  0.2455,\n                       -0.3347,  0.3092, -0.2096, -0.1439,  0.0622, -0.1808,  0.1620,  0.2763,\n                        0.1865,  0.1133, -0.2828, -0.3108, -0.2955, -0.1713,  0.1036, -0.2867,\n                        0.1847, -0.1970, -0.2405,  0.2319, -0.2340, -0.2487,  0.0547,  0.1576,\n                       -0.2275,  0.1986,  0.2946, -0.2663, -0.2966,  0.2194,  0.2433,  0.2124,\n                       -0.0299, -0.2664,  0.2093,  0.2454,  0.2582, -0.1267, -0.1878,  0.2439,\n                       -0.3049,  0.2820, -0.1147,  0.1914, -0.1646,  0.1216, -0.5284,  0.0268,\n                        0.3239,  0.1386,  0.2919, -0.0992,  0.0489,  0.0948, -0.2548,  0.1730,\n                       -0.2123,  0.1712,  0.0855,  0.1964,  0.2018,  0.1691,  0.1853,  0.2002,\n                       -0.0875, -0.3259,  0.2264,  0.2118,  0.3361, -0.0425,  0.1785,  0.2797,\n                        0.2064, -0.2513,  0.2404, -0.2408,  0.2910, -0.1942,  0.1809,  0.0134,\n                        0.1745, -0.2536, -0.1480, -0.1001, -0.3087, -0.0802,  0.3753, -0.1563,\n                        0.2124, -0.2883,  0.1618, -0.2727, -0.1808, -0.0898,  0.1940, -0.1989,\n                        0.3471, -0.1008,  0.4010, -0.2340, -0.2826,  0.2646,  0.2967,  0.2411,\n                        0.3063,  0.3040,  0.1889,  0.2371, -0.2303, -0.2211,  0.2054,  0.3452,\n                        0.2430,  0.2879, -0.3096,  0.0594,  0.1401,  0.2199,  0.1690, -0.2149,\n                       -0.1413,  0.2536,  0.2953,  0.2328,  0.0488,  0.1967, -0.2380, -0.2823,\n                       -0.2947, -0.2585, -0.1550,  0.3681, -0.2568, -0.2604,  0.1513, -0.2460])),\n              ('layer2.1.bn3.bias',\n               tensor([ 0.0506, -0.0215,  0.0861, -0.0792,  0.1075, -0.0772, -0.0791, -0.0269,\n                        0.0494,  0.1081,  0.0800, -0.1329,  0.1371,  0.1164, -0.0396,  0.0455,\n                        0.0182,  0.0203, -0.0710, -0.0477, -0.1031,  0.0148, -0.0821, -0.0441,\n                        0.0192,  0.0308,  0.1202,  0.1027,  0.1351,  0.0113, -0.0276,  0.0890,\n                        0.1235, -0.0432,  0.1379,  0.1310,  0.1982, -0.0064, -0.0920, -0.0274,\n                        0.1016, -0.1617,  0.0540,  0.1154,  0.1050, -0.0575,  0.1399, -0.0337,\n                       -0.0842, -0.1389,  0.0798,  0.1166, -0.0466, -0.0841, -0.0746, -0.0481,\n                        0.0738,  0.0474,  0.0736, -0.0933,  0.0286,  0.0138,  0.0443, -0.0752,\n                        0.1071, -0.0072, -0.0250,  0.0657,  0.0401,  0.0759, -0.0197,  0.0395,\n                        0.0810,  0.0999,  0.1414, -0.1477,  0.0520, -0.0187,  0.1426,  0.0848,\n                       -0.0633, -0.0715,  0.1714,  0.0233,  0.0119,  0.0233,  0.1575, -0.2227,\n                        0.0421,  0.1695, -0.0584,  0.0329,  0.1285,  0.1832,  0.0736,  0.0093,\n                        0.1092, -0.0133, -0.0629,  0.0550, -0.0848, -0.0879, -0.0886, -0.0175,\n                        0.0224,  0.1364, -0.0395,  0.0098, -0.0540, -0.0521, -0.0801, -0.1113,\n                        0.1036,  0.1122, -0.0506,  0.0568,  0.2120, -0.0614, -0.0906,  0.0127,\n                       -0.1068, -0.0469,  0.0042, -0.0249,  0.0898,  0.0395,  0.2113,  0.0020,\n                        0.0355,  0.0493,  0.0412, -0.0428, -0.0585,  0.1276,  0.0493,  0.0828,\n                       -0.0547,  0.0269,  0.0873,  0.0856,  0.1276,  0.0263, -0.0208,  0.1015,\n                       -0.0106, -0.0390, -0.0616,  0.1939,  0.1359,  0.0111,  0.0204,  0.0322,\n                        0.0670, -0.0564,  0.1159,  0.1884, -0.0021,  0.1791,  0.1156,  0.0059,\n                       -0.1387, -0.0915,  0.0371,  0.0254, -0.1569, -0.0035, -0.0612, -0.1210,\n                        0.2228,  0.0177, -0.0643,  0.0489,  0.2334,  0.0097, -0.1079,  0.0240,\n                        0.1217,  0.1756, -0.0743, -0.0714, -0.0075, -0.0372, -0.0344, -0.1172,\n                       -0.0032,  0.1560, -0.0483, -0.0918,  0.1048,  0.0236,  0.0549,  0.1426,\n                        0.0166,  0.1602,  0.2194,  0.0402, -0.0523, -0.0762, -0.0480, -0.0152,\n                        0.0490, -0.0311,  0.0535, -0.0006, -0.0343,  0.0514, -0.0462,  0.1228,\n                        0.0644,  0.0784, -0.0203,  0.0371, -0.0075,  0.0943,  0.0231,  0.1449,\n                        0.0482,  0.0398,  0.0869,  0.0645, -0.0830,  0.0948, -0.0658,  0.0088,\n                       -0.2431,  0.0695, -0.0723, -0.0635, -0.0548,  0.0812,  0.0471, -0.1566,\n                       -0.0343,  0.0003, -0.0388, -0.0182, -0.0368,  0.0127, -0.0350, -0.0405,\n                       -0.0596,  0.0640,  0.0244,  0.0661,  0.0371,  0.1861,  0.0265, -0.0134,\n                       -0.0306, -0.0169,  0.1518,  0.0776,  0.1409, -0.0143,  0.0664,  0.1646,\n                        0.0207, -0.1517,  0.0927,  0.1810,  0.0243,  0.1390,  0.0087,  0.1995,\n                        0.0894, -0.0175, -0.0861, -0.0121,  0.0792, -0.1278, -0.0972, -0.0478,\n                       -0.0544,  0.0508,  0.0389,  0.2346, -0.0046,  0.2368, -0.1348, -0.1057,\n                       -0.0443,  0.1420,  0.2120,  0.0071,  0.0777, -0.0551,  0.0511, -0.0296,\n                        0.0464,  0.1438, -0.0797, -0.0582, -0.0340, -0.0109,  0.0733,  0.0278,\n                       -0.0607,  0.0664,  0.0836,  0.0535, -0.0753, -0.0141, -0.0457,  0.1684,\n                        0.2024, -0.1051,  0.0501, -0.0135,  0.0735,  0.1491,  0.1705, -0.1358,\n                        0.0153,  0.0128,  0.0265,  0.0943, -0.0301,  0.0410,  0.0818,  0.0284,\n                        0.0649,  0.0962, -0.0754,  0.0563, -0.0066, -0.0714,  0.0902,  0.1067,\n                        0.1442,  0.0862,  0.1609,  0.0730,  0.0647,  0.1362,  0.1767, -0.0189,\n                       -0.0568, -0.0839, -0.1694,  0.1980,  0.0958, -0.0440, -0.0867,  0.0394,\n                       -0.0072,  0.1275,  0.0976,  0.0811,  0.0506,  0.0143, -0.0583,  0.0430,\n                       -0.0412,  0.2179,  0.0650, -0.0206, -0.0007,  0.0173, -0.0987, -0.1516,\n                        0.1773,  0.0072, -0.1539, -0.0641, -0.0118, -0.0038,  0.1588,  0.0402,\n                       -0.0714, -0.0901,  0.0697, -0.0353,  0.0648, -0.0734, -0.0430,  0.0818,\n                        0.1084,  0.0761, -0.0715,  0.0460,  0.1649, -0.0707, -0.0294, -0.0184,\n                        0.0725,  0.0366,  0.2158,  0.0780, -0.0919, -0.0225,  0.0116,  0.0675,\n                        0.1543, -0.1292,  0.0390, -0.0805, -0.0164,  0.0762, -0.0892, -0.0712,\n                        0.0135,  0.0372, -0.0578, -0.0800, -0.1082, -0.0478,  0.1073, -0.0846,\n                       -0.0264, -0.1289,  0.0394,  0.1213,  0.1258,  0.0570,  0.0426,  0.0843,\n                        0.2455, -0.0536, -0.1163,  0.0978,  0.0744,  0.0161, -0.1060,  0.0044,\n                        0.0873,  0.0169, -0.0899,  0.0691, -0.0225, -0.1013,  0.0303, -0.1366,\n                        0.1514,  0.0704, -0.0692,  0.1229,  0.0472, -0.0400,  0.1061, -0.0833,\n                        0.0239,  0.1026, -0.0550,  0.1604, -0.0010, -0.0890,  0.0469, -0.0602,\n                        0.1310, -0.0123, -0.0636,  0.0588,  0.1098, -0.0208, -0.0485, -0.0781,\n                       -0.1089, -0.0102, -0.1267, -0.0263, -0.0418,  0.0122,  0.0810, -0.0362,\n                       -0.0048,  0.0657, -0.1360,  0.0640, -0.0552, -0.1103,  0.0016,  0.1592,\n                       -0.1265,  0.0102,  0.0263,  0.0069,  0.1564,  0.0104,  0.0234,  0.1328,\n                        0.1025, -0.1005,  0.0014,  0.0611, -0.0661, -0.0951, -0.0667, -0.0155,\n                        0.0636,  0.0742,  0.1634,  0.0592,  0.1457,  0.0146,  0.0293,  0.0037,\n                       -0.0439, -0.0076,  0.0262, -0.0517, -0.0710, -0.1022, -0.0733, -0.0470,\n                        0.0512,  0.0255,  0.0266, -0.2143, -0.0067,  0.1066, -0.0628,  0.1408])),\n              ('layer2.1.bn3.running_mean',\n               tensor([-1.9740e-02, -4.8755e-02, -1.1450e-01,  1.5775e-01, -3.2519e-01,\n                        3.1106e-01,  2.7814e-02,  3.7532e-02,  1.2001e-01, -4.9198e-01,\n                        2.4684e-02,  3.3987e-02, -1.8131e-01, -1.6528e-02,  3.0935e-01,\n                       -3.3195e-01, -4.5243e-01,  2.6205e-01,  2.9508e-01,  6.2179e-02,\n                       -2.3834e-01, -4.3848e-01, -9.0645e-02, -1.5639e-01, -3.1231e-01,\n                       -1.8793e-01, -4.0189e-01, -5.2580e-03, -4.3967e-01,  1.5939e-01,\n                       -1.3300e-01, -2.6322e-01,  9.4499e-02, -2.3403e-02, -1.7278e-01,\n                        7.3984e-02,  1.5770e-01, -2.0855e-01, -7.4131e-02,  2.2066e-01,\n                       -4.3562e-01,  4.6645e-03, -2.7603e-01,  1.6764e-01, -1.8641e-01,\n                        2.4969e-01, -1.9617e-01, -1.0025e-01, -1.8998e-01, -1.2981e-01,\n                        1.2858e-01, -1.3708e-01, -2.9676e-01,  2.8958e-02, -2.0465e-01,\n                        2.6238e-01,  9.1441e-02, -2.4365e-01, -6.8765e-01,  4.3011e-02,\n                       -5.4198e-02,  5.2222e-02, -1.4414e-01, -1.6264e-01, -1.8000e-01,\n                       -2.2518e-01, -1.4206e-01, -1.0745e-01,  5.3529e-02, -3.5220e-01,\n                        1.3591e-01,  1.3137e-01,  4.0420e-02,  1.5316e-01, -4.8224e-01,\n                        3.6550e-02, -5.6412e-02, -2.5231e-01, -2.7112e-01, -5.1857e-01,\n                       -1.4732e-01, -1.3725e-01,  1.6074e-01,  3.5808e-02, -2.0038e-01,\n                        3.4325e-01,  4.4621e-02, -3.2406e-01,  3.6129e-01,  2.1732e-01,\n                        7.9864e-02, -2.8322e-02,  3.8078e-01, -1.4594e-02, -7.9782e-02,\n                        6.6179e-02,  2.3246e-01, -3.0536e-01,  1.0821e-01, -8.0142e-02,\n                        1.3481e-01,  2.4853e-01, -1.1359e-01, -2.5649e-01, -8.7155e-02,\n                       -2.5680e-01,  3.9907e-01, -5.0914e-02, -1.6811e-01, -1.6270e-01,\n                        1.2891e-01, -2.9319e-01, -9.2610e-02, -1.0401e-01, -1.9015e-01,\n                        1.4233e-01, -4.5764e-01, -1.3062e-01, -1.5001e-01, -1.7312e-02,\n                        1.5634e-01, -2.1890e-01,  1.3485e-02, -1.5295e-01, -8.0472e-02,\n                       -2.9104e-03, -4.5001e-01, -2.5586e-01, -2.5416e-01,  3.7906e-01,\n                       -6.5684e-02,  4.9907e-02, -1.7116e-01, -1.1175e-01,  9.9148e-02,\n                       -8.8578e-03, -8.2554e-02, -1.4406e-01, -3.4263e-01,  5.7584e-02,\n                       -3.4682e-01,  6.1254e-02, -2.7222e-02, -3.1764e-01,  1.3047e-01,\n                       -2.2735e-01, -2.1262e-02,  1.4577e-01,  5.6197e-02,  2.2519e-02,\n                        3.7779e-01,  6.0967e-02, -1.2913e-01,  1.1712e-01, -3.8737e-02,\n                        7.5096e-02, -2.5926e-01,  2.0195e-02, -1.1256e-01,  2.3523e-01,\n                       -3.9402e-01,  3.0992e-01,  9.9421e-02, -3.2710e-02,  2.1432e-01,\n                        2.8539e-01, -8.0325e-02,  1.7769e-01,  6.2062e-01, -1.9964e-01,\n                        2.2343e-01,  3.7163e-02,  5.6482e-02, -1.8888e-01, -5.2444e-02,\n                        1.3977e-01,  3.1453e-01, -5.4851e-02, -2.2969e-01,  1.7673e-01,\n                       -2.2700e-01, -3.9025e-02, -1.7328e-01,  5.5932e-01,  2.0122e-01,\n                       -3.9905e-01,  5.3434e-03,  4.1688e-03, -1.5451e-01, -3.1559e-01,\n                       -1.0791e-01,  8.0465e-02, -7.3225e-02, -1.9455e-01,  4.8421e-01,\n                        1.6635e-01, -1.5002e-01, -3.1959e-02, -8.2695e-02,  1.1865e-01,\n                       -2.1257e-01,  3.3968e-01, -1.5546e-01,  1.0168e-01,  5.6941e-03,\n                       -2.1682e-01,  1.5913e-01, -3.3643e-02,  2.9414e-01, -3.9635e-01,\n                        1.6455e-01,  4.9632e-02,  3.9909e-01,  1.8134e-01,  8.2946e-02,\n                       -2.7621e-01,  1.1921e-01, -2.7132e-01,  5.3901e-02,  5.9140e-02,\n                       -1.6000e-02, -1.2409e-01, -7.4745e-02,  3.1574e-01,  2.1174e-01,\n                       -4.0161e-01, -2.1005e-01, -1.5263e-01,  1.6903e-01, -5.5646e-02,\n                       -5.6399e-02, -2.0394e-02, -1.3274e-01, -2.4456e-01,  3.5489e-02,\n                       -8.9142e-03,  2.3300e-01,  1.4611e-01,  1.6955e-01,  3.6876e-02,\n                        9.8961e-02,  5.5174e-02, -2.7475e-01,  2.6959e-01,  2.1371e-01,\n                        2.8093e-01,  4.4287e-02, -2.6456e-01,  1.6418e-01,  2.5227e-01,\n                        1.9932e-01, -2.4559e-01,  2.1582e-01,  2.6272e-01, -2.4985e-01,\n                        9.0763e-02, -3.7744e-02,  4.7219e-02, -1.7162e-01,  3.6994e-01,\n                       -5.0061e-01, -1.4128e-01, -1.7728e-01,  4.7634e-01, -4.4358e-03,\n                        2.0966e-01, -3.5689e-01, -2.1744e-01, -1.1753e-01,  1.9221e-01,\n                        6.7008e-02, -1.1339e-01, -3.2167e-01,  1.5761e-01,  2.9237e-01,\n                       -5.4089e-02,  2.1031e-01, -4.4276e-01, -9.1927e-02,  2.7166e-01,\n                       -1.4216e-01, -2.4425e-02, -1.4112e-01,  5.3676e-01, -1.0214e-01,\n                        1.5562e-01,  6.1521e-02, -5.4633e-02, -1.9625e-01,  6.4936e-02,\n                       -3.5724e-01,  3.3212e-01,  9.0128e-02,  2.3434e-02,  1.2189e-01,\n                        3.0492e-01, -1.5423e-01, -1.8620e-02,  4.8623e-02, -1.3514e-01,\n                        1.4661e-01, -2.0166e-01, -1.2125e-01, -1.4546e-01, -2.7522e-01,\n                       -2.6719e-01,  2.0799e-01,  1.2289e-01, -7.9297e-02,  1.3688e-01,\n                       -5.2736e-01, -4.2369e-01, -2.7688e-01,  1.3540e-01, -1.5143e-01,\n                       -1.3551e-01, -3.1868e-01, -3.1722e-01, -3.2060e-01, -1.2154e-01,\n                        4.3331e-01,  1.2886e-01, -2.9706e-02,  1.7405e-01,  3.6982e-02,\n                       -1.8180e-01, -9.7197e-02, -5.5431e-03, -1.6475e-01, -4.2095e-02,\n                       -8.7411e-02,  2.3523e-01,  3.5919e-01,  1.9167e-01, -3.2021e-01,\n                       -1.5732e-01,  1.2384e-01, -1.4398e-01, -4.8241e-01,  4.7281e-01,\n                        3.2076e-02,  3.4028e-01, -1.6935e-01, -3.9056e-01,  2.3720e-01,\n                       -3.8491e-01, -3.2526e-01, -1.6738e-01,  1.0905e-01,  2.2815e-01,\n                       -1.9443e-01,  4.2490e-01,  5.2941e-02, -1.6105e-01,  2.0180e-01,\n                       -2.1633e-01, -1.4776e-01, -2.7283e-03, -3.1377e-01,  1.1177e-01,\n                        3.5469e-03,  2.0862e-01,  4.0058e-01, -2.1823e-01, -3.0539e-01,\n                        2.5632e-01,  1.4254e-01,  5.9112e-02, -1.3687e-01,  8.9681e-02,\n                        1.1881e-01,  6.9726e-02, -4.4651e-04, -3.6945e-02,  3.4453e-01,\n                       -2.3141e-01, -1.2211e-01,  2.2425e-01,  1.3277e-02,  1.4948e-01,\n                       -2.5794e-01,  3.5005e-01,  6.5619e-02,  4.8286e-02, -1.9684e-01,\n                       -6.5985e-03,  3.7018e-02,  1.5962e-01, -5.3335e-02, -1.3679e-02,\n                       -6.9314e-02,  3.6205e-02, -1.3672e-01,  1.1836e-01,  8.5316e-02,\n                       -2.8942e-01, -1.3131e-01,  5.2786e-01, -8.8365e-02, -9.7562e-02,\n                        3.8185e-01,  6.4150e-02,  1.7126e-01,  1.2938e-02,  5.6005e-02,\n                       -3.6157e-02, -5.3169e-01, -7.3883e-02,  1.3126e-01, -7.0219e-02,\n                        2.1121e-01,  3.6241e-01, -2.7310e-02, -1.1263e-01, -2.2309e-01,\n                       -9.2279e-04,  1.9232e-01,  6.1815e-02,  1.2965e-01, -2.1844e-01,\n                        2.4245e-01, -2.7280e-01, -6.0272e-02,  1.7481e-03, -6.3258e-01,\n                       -8.2904e-02,  4.3114e-01, -4.9324e-03,  3.8980e-02, -9.4933e-02,\n                        1.6203e-01,  8.5268e-02,  4.3846e-01,  9.5086e-02, -1.9479e-01,\n                       -3.3160e-01, -1.9986e-01,  1.1094e-01,  4.5559e-01,  2.9357e-02,\n                        7.9085e-02, -1.3022e-01,  4.0884e-01, -1.3252e-01, -4.2708e-01,\n                       -6.4392e-02,  1.5483e-01, -7.3082e-02,  3.7347e-01, -1.0599e-01,\n                       -2.0111e-01,  4.6040e-01,  2.9552e-01, -1.4460e-01,  1.6606e-01,\n                       -3.8912e-03,  6.4437e-02, -2.6535e-02, -1.0685e-01, -1.3090e-01,\n                       -5.9261e-02,  5.5087e-02, -6.0072e-02,  1.1331e-01,  3.1147e-02,\n                        4.0705e-01, -1.8898e-01, -2.3438e-01,  1.8145e-01,  1.2861e-01,\n                       -2.7151e-01,  3.7187e-01,  1.5437e-02, -1.6099e-01,  4.3350e-01,\n                       -1.2934e-01,  1.9296e-01, -2.9057e-01,  4.1302e-01,  1.0750e-01,\n                       -4.8628e-02,  4.4694e-01,  1.2074e-02, -2.8927e-01,  2.1736e-01,\n                       -3.9468e-01,  7.0205e-02,  5.1124e-01, -2.6323e-01,  2.2812e-01,\n                        3.2605e-02, -1.0719e-01, -2.8069e-01,  7.8315e-02, -2.0778e-01,\n                        1.2160e-01, -1.5855e-01,  1.8874e-02, -7.2682e-02, -1.8285e-02,\n                        2.7737e-02,  6.8626e-04, -2.9557e-01,  1.5919e-01,  3.8223e-02,\n                       -2.4839e-01, -2.0484e-02,  3.0329e-01,  4.7635e-01,  1.2836e-01,\n                        6.6424e-02,  3.3572e-01])),\n              ('layer2.1.bn3.running_var',\n               tensor([0.1086, 0.0689, 0.0930, 0.1376, 0.1084, 0.0742, 0.0732, 0.1099, 0.0790,\n                       0.0898, 0.0753, 0.1015, 0.1141, 0.0494, 0.1096, 0.1132, 0.1769, 0.1105,\n                       0.1272, 0.0978, 0.1013, 0.1317, 0.0645, 0.1380, 0.0593, 0.1338, 0.0631,\n                       0.1354, 0.1330, 0.1290, 0.0910, 0.1532, 0.1258, 0.1634, 0.1236, 0.0751,\n                       0.0972, 0.0447, 0.0605, 0.1423, 0.1049, 0.1837, 0.1001, 0.1030, 0.0632,\n                       0.1971, 0.1251, 0.0856, 0.0626, 0.0413, 0.0931, 0.0728, 0.0509, 0.0355,\n                       0.1414, 0.0788, 0.1718, 0.0804, 0.1616, 0.0946, 0.0890, 0.0618, 0.2071,\n                       0.0814, 0.1130, 0.1492, 0.0605, 0.0673, 0.1005, 0.1615, 0.1006, 0.1104,\n                       0.1152, 0.0658, 0.1414, 0.0672, 0.0628, 0.0671, 0.1289, 0.1654, 0.1510,\n                       0.0416, 0.1348, 0.0798, 0.0631, 0.0734, 0.1594, 0.0456, 0.1552, 0.0933,\n                       0.0394, 0.0689, 0.1172, 0.1205, 0.1869, 0.1489, 0.0764, 0.0586, 0.0669,\n                       0.0983, 0.1263, 0.0639, 0.0438, 0.0875, 0.0877, 0.0737, 0.0605, 0.0673,\n                       0.1515, 0.0414, 0.1616, 0.0647, 0.1228, 0.1324, 0.0512, 0.1076, 0.1153,\n                       0.0407, 0.0908, 0.0798, 0.0544, 0.1472, 0.0561, 0.1026, 0.1094, 0.1544,\n                       0.1519, 0.1093, 0.0731, 0.1036, 0.0890, 0.1235, 0.0593, 0.1051, 0.1353,\n                       0.1446, 0.0827, 0.0941, 0.1407, 0.1328, 0.1226, 0.1605, 0.0569, 0.1060,\n                       0.1301, 0.0589, 0.0599, 0.1130, 0.1108, 0.1749, 0.0959, 0.0791, 0.1346,\n                       0.0547, 0.1862, 0.1793, 0.0742, 0.0836, 0.0872, 0.0859, 0.1658, 0.0892,\n                       0.0574, 0.0463, 0.0656, 0.0668, 0.1036, 0.0570, 0.1211, 0.1558, 0.0804,\n                       0.0897, 0.1047, 0.1289, 0.0464, 0.1052, 0.1188, 0.1239, 0.1078, 0.0573,\n                       0.0804, 0.1439, 0.0747, 0.1041, 0.1142, 0.1068, 0.0637, 0.0529, 0.1025,\n                       0.0741, 0.0757, 0.0844, 0.0538, 0.0946, 0.1137, 0.0718, 0.1087, 0.0880,\n                       0.0454, 0.1535, 0.0612, 0.1005, 0.1120, 0.0788, 0.0515, 0.1299, 0.0817,\n                       0.0866, 0.0438, 0.0910, 0.0975, 0.1359, 0.1515, 0.0929, 0.0965, 0.1305,\n                       0.0966, 0.0940, 0.1291, 0.0828, 0.0590, 0.0949, 0.1059, 0.1021, 0.1308,\n                       0.1152, 0.0744, 0.0626, 0.1223, 0.1177, 0.1398, 0.0530, 0.1068, 0.0743,\n                       0.0820, 0.1329, 0.1417, 0.0933, 0.1178, 0.1781, 0.0565, 0.1031, 0.1144,\n                       0.0920, 0.1001, 0.1343, 0.0792, 0.0555, 0.1597, 0.1142, 0.1649, 0.0634,\n                       0.1445, 0.1098, 0.0651, 0.1051, 0.0632, 0.0513, 0.1000, 0.1206, 0.0957,\n                       0.0912, 0.1374, 0.1172, 0.0879, 0.1010, 0.0685, 0.0628, 0.0846, 0.1392,\n                       0.0542, 0.1067, 0.1286, 0.0675, 0.0923, 0.1828, 0.0392, 0.1606, 0.0531,\n                       0.0678, 0.0579, 0.0630, 0.1981, 0.0990, 0.0868, 0.0733, 0.1039, 0.2109,\n                       0.1412, 0.0899, 0.1910, 0.0529, 0.1045, 0.0988, 0.0710, 0.0503, 0.0995,\n                       0.1854, 0.0480, 0.1241, 0.0928, 0.1385, 0.1194, 0.1386, 0.1732, 0.0757,\n                       0.1277, 0.0630, 0.1276, 0.1191, 0.1626, 0.0914, 0.1479, 0.0527, 0.1143,\n                       0.0843, 0.0543, 0.0821, 0.1533, 0.0612, 0.1144, 0.1322, 0.0491, 0.0971,\n                       0.1105, 0.0728, 0.0722, 0.1143, 0.1284, 0.0777, 0.1293, 0.0956, 0.1206,\n                       0.0983, 0.1815, 0.0978, 0.0715, 0.0602, 0.2441, 0.2095, 0.1101, 0.0918,\n                       0.0534, 0.1262, 0.1063, 0.1364, 0.1111, 0.1571, 0.2250, 0.0793, 0.1355,\n                       0.1093, 0.0628, 0.1127, 0.0590, 0.1672, 0.1086, 0.1187, 0.0549, 0.0470,\n                       0.1610, 0.0730, 0.2227, 0.1020, 0.1548, 0.0575, 0.1002, 0.0838, 0.0603,\n                       0.1229, 0.0849, 0.0840, 0.1089, 0.0622, 0.0878, 0.0786, 0.1220, 0.2511,\n                       0.0978, 0.0506, 0.0556, 0.0582, 0.0622, 0.0927, 0.1194, 0.0891, 0.1279,\n                       0.0804, 0.0879, 0.1014, 0.0522, 0.1157, 0.1021, 0.0747, 0.1253, 0.0644,\n                       0.1478, 0.0737, 0.0510, 0.0773, 0.0792, 0.0757, 0.1462, 0.1398, 0.0954,\n                       0.0938, 0.1103, 0.0897, 0.0938, 0.0945, 0.0696, 0.1313, 0.1080, 0.0579,\n                       0.1056, 0.0633, 0.1325, 0.0970, 0.0763, 0.1285, 0.0745, 0.0518, 0.1776,\n                       0.0557, 0.1234, 0.0523, 0.2738, 0.0500, 0.0460, 0.0500, 0.1307, 0.0869,\n                       0.1180, 0.1198, 0.0377, 0.0739, 0.0882, 0.0786, 0.1526, 0.1200, 0.0465,\n                       0.1662, 0.1414, 0.0901, 0.1334, 0.0625, 0.1171, 0.0948, 0.1348, 0.1685,\n                       0.0916, 0.1053, 0.1438, 0.0826, 0.1026, 0.0642, 0.0688, 0.0976, 0.0987,\n                       0.0604, 0.1611, 0.0723, 0.1510, 0.0630, 0.1090, 0.1612, 0.0672, 0.1528,\n                       0.0704, 0.0511, 0.0840, 0.0929, 0.1666, 0.0642, 0.0978, 0.0992, 0.1506,\n                       0.1476, 0.1232, 0.1638, 0.1182, 0.1181, 0.0959, 0.1573, 0.1622, 0.0990,\n                       0.0674, 0.1297, 0.1171, 0.1378, 0.3021, 0.0526, 0.1033, 0.1305, 0.0833,\n                       0.1080, 0.0599, 0.1188, 0.1265, 0.0575, 0.0507, 0.0594, 0.0845, 0.0858,\n                       0.1513, 0.1314, 0.0860, 0.1281, 0.1069, 0.1066, 0.0802, 0.1182])),\n              ('layer2.1.bn3.num_batches_tracked', tensor(13572)),\n              ('layer2.2.conv1.weight',\n               tensor([[[[-0.0042]],\n               \n                        [[-0.0394]],\n               \n                        [[ 0.0009]],\n               \n                        ...,\n               \n                        [[ 0.0372]],\n               \n                        [[-0.0903]],\n               \n                        [[ 0.0730]]],\n               \n               \n                       [[[-0.0037]],\n               \n                        [[-0.0111]],\n               \n                        [[-0.0861]],\n               \n                        ...,\n               \n                        [[ 0.0062]],\n               \n                        [[ 0.0198]],\n               \n                        [[ 0.0740]]],\n               \n               \n                       [[[-0.0889]],\n               \n                        [[ 0.0659]],\n               \n                        [[-0.0083]],\n               \n                        ...,\n               \n                        [[ 0.0846]],\n               \n                        [[ 0.0371]],\n               \n                        [[ 0.0372]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0230]],\n               \n                        [[ 0.0380]],\n               \n                        [[ 0.0649]],\n               \n                        ...,\n               \n                        [[ 0.0552]],\n               \n                        [[-0.1171]],\n               \n                        [[ 0.0256]]],\n               \n               \n                       [[[ 0.0166]],\n               \n                        [[-0.0223]],\n               \n                        [[ 0.1502]],\n               \n                        ...,\n               \n                        [[ 0.0366]],\n               \n                        [[ 0.0186]],\n               \n                        [[ 0.0742]]],\n               \n               \n                       [[[ 0.0377]],\n               \n                        [[ 0.0791]],\n               \n                        [[ 0.0618]],\n               \n                        ...,\n               \n                        [[-0.0026]],\n               \n                        [[-0.0717]],\n               \n                        [[-0.0068]]]])),\n              ('layer2.2.bn1.weight',\n               tensor([0.9166, 1.0407, 0.9194, 0.9708, 1.0186, 1.0112, 0.9562, 0.9904, 1.0798,\n                       1.0323, 1.0291, 0.9975, 1.0764, 0.9776, 1.0945, 1.0209, 1.0595, 1.0341,\n                       0.9471, 1.0190, 1.0576, 0.9622, 1.0723, 1.0364, 0.9557, 0.9555, 0.9614,\n                       1.0062, 1.0361, 1.0009, 0.9619, 0.9822, 0.9210, 1.1269, 1.0532, 0.9594,\n                       1.1365, 0.9255, 0.9989, 0.9212, 1.0144, 0.9079, 0.9591, 0.9531, 0.9956,\n                       0.9892, 1.0221, 0.9651, 0.9898, 0.9870, 0.9490, 1.0027, 0.9930, 0.9826,\n                       1.0171, 0.9472, 0.9892, 1.0077, 0.9746, 0.9870, 0.9998, 1.0084, 1.0197,\n                       1.0223, 0.9483, 0.9990, 1.0104, 0.9777, 1.0279, 1.0228, 1.0137, 0.9528,\n                       0.9301, 0.9922, 0.9819, 0.9985, 1.0400, 0.9842, 0.9525, 0.9757, 0.9277,\n                       1.0302, 0.9841, 1.0105, 0.9885, 1.1461, 0.9850, 0.9453, 1.0068, 1.0012,\n                       1.0589, 1.0491, 1.0343, 1.0087, 1.0208, 0.9364, 0.9966, 1.0265, 0.9786,\n                       0.9761, 0.9981, 0.9791, 1.0795, 0.9920, 0.9855, 1.0203, 0.9913, 1.0495,\n                       0.9795, 1.0088, 0.9320, 0.8838, 0.9755, 0.9726, 1.0296, 0.9915, 0.9207,\n                       1.0107, 1.0311, 1.0099, 1.0680, 0.9432, 1.1066, 0.9850, 0.9896, 0.9383,\n                       1.0398, 0.9381])),\n              ('layer2.2.bn1.bias',\n               tensor([ 1.6069e-02,  6.4728e-02, -4.3421e-02, -1.5861e-02, -6.0416e-02,\n                       -2.8199e-04, -4.3987e-02, -5.6329e-02, -1.2064e-01, -7.1664e-02,\n                       -7.3642e-02, -8.3734e-02,  8.6515e-03, -1.9738e-02, -2.6788e-02,\n                       -5.8073e-02, -4.7478e-02, -5.2868e-02, -4.2990e-02,  6.6891e-02,\n                       -2.1225e-02,  3.6464e-02, -2.1221e-01,  5.7815e-02, -7.5482e-02,\n                       -6.8651e-02, -4.9182e-03, -8.4357e-03,  2.2845e-02, -1.0444e-01,\n                       -1.0246e-01, -1.4480e-02, -6.5405e-02,  3.2378e-02, -3.6952e-02,\n                        8.7198e-02,  5.6411e-03, -4.8361e-02, -9.8109e-02, -8.3653e-02,\n                        1.2811e-03, -2.5171e-02, -7.2084e-02, -3.3001e-02, -6.8893e-03,\n                        3.0475e-02, -9.7575e-03, -5.4656e-05, -3.8416e-02, -7.3015e-02,\n                       -1.1476e-01, -3.0924e-02, -4.7221e-02,  1.7939e-02, -9.1491e-02,\n                        2.9410e-02, -7.0946e-02, -4.3358e-02, -9.9885e-02,  3.5343e-02,\n                        9.3842e-02, -1.0264e-01,  4.9442e-02,  4.3543e-02, -5.0158e-02,\n                        1.7495e-04, -1.5475e-01, -1.1174e-01,  5.2128e-02,  4.2387e-02,\n                        3.4750e-02,  1.2440e-02, -8.4596e-02, -5.1501e-02, -8.4020e-02,\n                        2.3661e-02, -1.3569e-01, -6.2827e-03, -1.3102e-01, -1.0284e-01,\n                       -7.7193e-02,  4.1445e-02, -6.7406e-02,  4.6160e-02, -4.4350e-03,\n                       -9.1072e-02, -2.9751e-02,  9.6258e-03,  7.6176e-02, -7.1040e-02,\n                       -9.8275e-02, -3.5390e-02,  4.1463e-03,  1.9061e-02,  1.2341e-01,\n                        7.0984e-03, -1.3941e-02, -5.4700e-02, -1.0836e-01, -1.3580e-02,\n                        5.5810e-03, -3.0139e-02, -3.0697e-02,  6.9409e-02, -4.1008e-02,\n                       -9.4604e-02, -4.7622e-02,  5.0917e-02, -1.1602e-01, -6.0594e-02,\n                       -8.1584e-02, -6.0431e-02, -1.4101e-01, -6.4179e-02,  5.2073e-02,\n                        3.9130e-02, -5.5302e-02, -5.3274e-02, -6.4564e-02,  1.6621e-02,\n                       -5.4189e-02, -8.5087e-02, -1.1570e-01,  3.9751e-02,  1.3041e-02,\n                       -1.5214e-01,  6.4174e-02,  2.7849e-02])),\n              ('layer2.2.bn1.running_mean',\n               tensor([-1.2577e+00, -2.5328e-01, -7.9744e-02, -8.4514e-02, -1.6793e+00,\n                       -5.9463e-01,  4.5233e-01,  7.0839e-02,  8.5984e-01, -1.1361e+00,\n                        3.7447e-01,  3.2137e-01, -1.1991e-01, -1.5373e-01, -8.3884e-01,\n                       -5.5121e-02, -6.4691e-01,  9.5361e-02, -1.1618e+00, -1.7763e-02,\n                       -2.1007e+00, -4.6004e-02,  3.8192e-01,  1.3983e-01, -1.4606e-01,\n                        7.4835e-01, -5.6699e-01, -2.5113e-01, -6.0992e-01, -4.6991e-01,\n                       -1.5051e+00, -2.1875e-01, -1.0079e+00,  7.1489e-01,  2.6724e-01,\n                       -5.0270e-01,  6.9567e-02, -9.6690e-01, -4.3519e-01,  1.0379e-01,\n                       -1.8768e+00, -3.4827e-02,  1.1749e-01,  2.0165e-01, -6.4259e-01,\n                        4.2244e-02, -9.2686e-01, -2.1514e-01, -6.6432e-01, -7.7956e-01,\n                       -1.3124e+00, -8.7653e-01, -8.2060e-01, -5.0827e-01, -1.1054e+00,\n                        7.4746e-01, -1.4087e-01, -4.0956e-01,  3.0009e-02,  5.1064e-02,\n                        1.1166e-01, -3.3719e-01, -1.0892e+00, -7.6316e-01,  2.6456e-01,\n                       -6.9221e-01,  5.7432e-01,  2.6522e-01, -7.9345e-01,  1.9957e-01,\n                       -1.1530e+00, -4.7341e-01,  5.9495e-01, -2.1850e-01, -7.6911e-01,\n                       -1.1524e+00,  4.9580e-01,  5.5103e-03,  2.0448e-01,  3.9667e-01,\n                       -4.9595e-02, -1.6200e+00, -2.4417e-01, -5.1279e-01, -2.2676e-04,\n                        6.3774e-01, -1.2199e-01, -1.1608e+00,  5.3892e-01,  7.9560e-01,\n                        3.9044e-02,  6.6981e-01, -1.6005e+00, -1.0871e+00, -1.4495e+00,\n                       -5.6935e-01, -8.9033e-01, -2.0657e+00, -4.9787e-01, -2.6582e-01,\n                       -7.7545e-01, -3.7988e-01, -6.1481e-01, -1.0795e-01, -1.1992e-01,\n                        1.9247e+00,  1.2465e+00, -1.8230e+00, -5.4629e-01,  9.0946e-01,\n                        3.9949e-01, -7.8806e-01,  9.6730e-01, -2.7728e-01, -1.4096e+00,\n                       -7.6492e-01, -6.5791e-01, -4.8028e-01,  5.6840e-01, -1.1569e+00,\n                        1.0586e+00, -8.1955e-02,  9.7654e-02, -2.1089e+00,  3.1887e-02,\n                       -6.9963e-01, -1.2160e+00, -1.1271e-01])),\n              ('layer2.2.bn1.running_var',\n               tensor([1.2309, 1.2324, 1.1247, 1.0111, 1.9112, 1.1329, 1.1357, 0.8203, 1.0493,\n                       0.9177, 0.9754, 0.8012, 1.1614, 2.2431, 1.0453, 0.8189, 1.9840, 1.6473,\n                       1.1406, 1.8526, 1.8397, 1.1470, 1.3073, 1.1307, 1.1524, 1.0883, 0.9600,\n                       1.1640, 0.8307, 1.0697, 1.0486, 0.9816, 0.7401, 1.2445, 1.0029, 1.1480,\n                       0.9905, 0.9608, 0.7810, 1.0508, 1.3889, 0.8324, 0.9611, 1.6551, 1.0642,\n                       1.0520, 1.0510, 0.7735, 1.4367, 1.4562, 1.3335, 1.1904, 2.0872, 1.0591,\n                       1.4017, 1.1717, 1.2512, 1.4339, 1.3804, 1.5774, 0.9457, 1.2470, 1.7555,\n                       0.9377, 1.0346, 0.8900, 1.0316, 0.9981, 1.2241, 1.0325, 1.1640, 1.7193,\n                       0.8198, 1.1320, 1.3347, 1.5188, 0.8090, 1.6581, 0.9233, 0.7999, 0.9936,\n                       1.4202, 1.0899, 1.3116, 1.1771, 1.2759, 1.3389, 0.8201, 2.1229, 1.0654,\n                       1.2448, 1.2472, 1.2904, 1.2040, 1.2919, 1.2187, 1.2558, 1.5220, 1.0331,\n                       1.2007, 1.3905, 1.0318, 1.6218, 1.7120, 1.0443, 2.0494, 1.0776, 1.8103,\n                       1.1528, 1.7039, 0.9280, 0.9419, 1.3274, 1.0481, 1.6637, 0.7633, 1.2122,\n                       1.4735, 1.1337, 1.2395, 1.3780, 1.0229, 0.8932, 1.4868, 0.7177, 1.4891,\n                       2.3377, 1.0434])),\n              ('layer2.2.bn1.num_batches_tracked', tensor(13572)),\n              ('layer2.2.conv2.weight',\n               tensor([[[[-5.8642e-02, -6.8722e-02,  2.4099e-02],\n                         [-1.2723e-02, -4.5792e-02, -1.2724e-02],\n                         [-4.2544e-02,  1.1644e-02,  3.4874e-02]],\n               \n                        [[-2.4973e-02,  2.0230e-02,  4.2793e-02],\n                         [ 9.4359e-03,  3.7734e-03, -6.6294e-03],\n                         [-2.1413e-02, -1.0205e-02, -1.0767e-02]],\n               \n                        [[ 7.3632e-03,  3.2821e-02,  2.3343e-03],\n                         [-1.1984e-04,  2.2871e-02,  1.5920e-03],\n                         [ 5.5632e-03,  6.0406e-02,  1.3512e-02]],\n               \n                        ...,\n               \n                        [[ 2.2348e-02,  1.1622e-02, -6.2509e-03],\n                         [ 2.2509e-02, -6.7871e-03,  1.1726e-02],\n                         [-1.0761e-02, -1.1195e-02, -4.4281e-02]],\n               \n                        [[-7.7445e-02, -3.5758e-02, -9.1578e-03],\n                         [ 9.9827e-03,  3.2007e-02,  8.6724e-03],\n                         [-5.7539e-04, -3.2664e-02,  4.3452e-02]],\n               \n                        [[-3.9949e-03,  3.8531e-02, -2.5822e-02],\n                         [-3.1993e-02,  4.7368e-02,  1.5595e-02],\n                         [ 1.0820e-03,  8.0854e-02, -4.8589e-02]]],\n               \n               \n                       [[[ 3.5025e-02, -2.9902e-02,  4.1521e-02],\n                         [ 1.8076e-03, -8.8661e-02,  3.5551e-02],\n                         [-7.9283e-03,  2.7630e-02,  1.2067e-03]],\n               \n                        [[-9.0458e-04, -3.5861e-02, -3.1636e-02],\n                         [-5.0333e-03,  1.2048e-02, -2.7479e-02],\n                         [-3.8827e-03,  7.9496e-02,  4.5520e-02]],\n               \n                        [[ 2.6113e-02,  7.1831e-02, -3.9396e-03],\n                         [ 7.6727e-02,  1.0523e-01,  1.0440e-01],\n                         [-3.3187e-02, -1.2624e-02,  2.6739e-02]],\n               \n                        ...,\n               \n                        [[-1.3874e-02, -9.1315e-03, -2.6785e-02],\n                         [-4.1244e-02,  2.2445e-02,  6.7241e-02],\n                         [ 1.5930e-02, -5.7148e-03, -4.1715e-02]],\n               \n                        [[-2.1446e-02,  2.6242e-02, -2.3264e-04],\n                         [-4.6902e-02,  3.5232e-02, -2.9145e-02],\n                         [-4.6265e-02, -6.1051e-03, -5.4291e-02]],\n               \n                        [[ 1.3300e-02, -9.3431e-02,  1.8817e-02],\n                         [ 1.3665e-02,  9.0341e-03, -1.6118e-02],\n                         [-2.0438e-02, -2.5399e-02,  1.0312e-02]]],\n               \n               \n                       [[[ 4.6771e-02,  1.6575e-02,  4.9016e-02],\n                         [-3.1196e-02,  8.2525e-03,  1.8644e-02],\n                         [ 9.1973e-03,  5.8574e-03,  4.7318e-02]],\n               \n                        [[-7.1461e-02, -7.1360e-02, -7.8968e-02],\n                         [ 3.0788e-02, -1.3905e-02, -4.0538e-02],\n                         [-8.6184e-03, -2.0822e-02, -2.0360e-02]],\n               \n                        [[ 4.7143e-02,  2.7398e-02,  3.1768e-02],\n                         [-4.6467e-02, -5.7868e-04, -1.0350e-02],\n                         [ 8.2993e-03,  4.2293e-03, -1.2723e-02]],\n               \n                        ...,\n               \n                        [[ 1.7835e-02, -4.2814e-02,  3.5318e-02],\n                         [ 2.8332e-02,  3.8931e-02, -2.4962e-02],\n                         [ 4.7198e-02, -2.0227e-02,  6.2579e-03]],\n               \n                        [[ 3.8815e-02,  3.4368e-02, -1.0617e-02],\n                         [-2.7913e-02, -1.3637e-02, -3.7015e-02],\n                         [-1.8659e-02,  2.4826e-03, -3.2564e-02]],\n               \n                        [[-1.9895e-04, -2.1645e-02,  5.6730e-02],\n                         [-1.4146e-02, -3.3626e-02,  1.2280e-01],\n                         [-4.8614e-03, -5.0651e-02,  3.6783e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-1.6502e-02, -8.8427e-03,  1.8446e-02],\n                         [ 3.3614e-02,  1.8761e-02,  6.0272e-02],\n                         [-9.7257e-03,  1.9191e-02,  1.3599e-02]],\n               \n                        [[ 1.5673e-02,  2.7204e-03,  8.1518e-02],\n                         [-1.9656e-02, -2.0531e-02, -2.0543e-03],\n                         [-9.9562e-03, -1.4706e-02, -4.4732e-02]],\n               \n                        [[ 6.8693e-02,  4.0902e-02,  2.7825e-02],\n                         [-8.2212e-03, -9.1422e-03, -4.3761e-02],\n                         [ 5.5022e-03,  5.7314e-03,  1.4849e-02]],\n               \n                        ...,\n               \n                        [[-2.5424e-02,  1.1970e-02,  2.4116e-02],\n                         [ 4.0969e-03,  4.4303e-02, -4.1264e-02],\n                         [ 4.5195e-03,  1.2116e-02, -1.2648e-02]],\n               \n                        [[ 4.4592e-02, -5.9786e-03,  1.4499e-02],\n                         [-3.2489e-02, -5.2937e-02, -1.7690e-02],\n                         [ 1.5617e-02, -3.6276e-02,  1.9031e-02]],\n               \n                        [[-5.4139e-02,  1.6233e-02, -2.2726e-02],\n                         [ 1.5088e-03,  7.1977e-03, -2.2329e-02],\n                         [-1.4051e-02, -3.3982e-02,  1.8286e-02]]],\n               \n               \n                       [[[ 3.2974e-02,  6.0890e-03,  4.4655e-03],\n                         [ 2.0440e-02, -4.7415e-02, -1.9896e-02],\n                         [ 9.9084e-03, -1.9133e-02, -1.5236e-02]],\n               \n                        [[-1.4065e-02, -6.6886e-02, -2.1537e-02],\n                         [-2.5916e-02,  1.0964e-03, -2.8582e-02],\n                         [-1.0284e-02,  2.1325e-02,  1.2178e-02]],\n               \n                        [[ 2.1879e-03,  9.0156e-02,  3.9252e-03],\n                         [-3.6219e-03,  4.7945e-03,  2.0792e-02],\n                         [-3.4533e-02,  2.7315e-02, -4.8147e-02]],\n               \n                        ...,\n               \n                        [[-5.1317e-03, -6.3545e-02, -2.7328e-02],\n                         [ 1.0079e-02,  8.1623e-03,  1.2843e-02],\n                         [ 7.7290e-03,  2.6336e-02, -4.5044e-03]],\n               \n                        [[ 1.4316e-02,  9.7973e-02,  1.8425e-02],\n                         [-1.8871e-02,  9.3460e-03, -2.1767e-03],\n                         [ 1.2177e-02,  2.5343e-03,  3.8772e-03]],\n               \n                        [[-2.1453e-02, -1.2160e-02,  2.9871e-03],\n                         [-2.4657e-02, -4.7319e-02, -5.7170e-02],\n                         [ 2.6257e-02,  1.0782e-03,  1.7413e-02]]],\n               \n               \n                       [[[-8.9350e-03,  2.3923e-02,  3.0894e-02],\n                         [ 1.4396e-02,  9.7736e-03, -2.6842e-02],\n                         [-3.6748e-02, -4.2377e-02, -3.6651e-02]],\n               \n                        [[-7.4581e-03,  2.0636e-02,  1.1363e-02],\n                         [ 2.5769e-02, -3.9973e-02,  1.8680e-02],\n                         [ 1.1063e-02, -2.2539e-02, -3.0885e-02]],\n               \n                        [[-5.4930e-02, -2.7764e-02, -1.1454e-02],\n                         [-2.8839e-02, -7.1929e-02, -2.7094e-02],\n                         [-1.3778e-02,  6.3858e-03, -2.2420e-02]],\n               \n                        ...,\n               \n                        [[ 3.8399e-02,  3.1832e-02, -2.9264e-02],\n                         [-1.3495e-02,  3.1961e-02,  5.7024e-02],\n                         [ 7.1723e-02,  3.1096e-02,  5.8430e-02]],\n               \n                        [[-1.7770e-02,  3.9552e-02, -3.4955e-02],\n                         [ 9.6925e-03,  9.8508e-02,  3.5301e-03],\n                         [ 1.8504e-02, -1.8129e-02,  7.4654e-03]],\n               \n                        [[ 2.5914e-02,  1.5515e-02,  3.1818e-02],\n                         [-3.0179e-02, -5.0947e-02,  5.3168e-03],\n                         [ 2.0746e-03,  3.3233e-02, -7.3178e-03]]]])),\n              ('layer2.2.bn2.weight',\n               tensor([0.9965, 0.9503, 0.9692, 1.1457, 1.0066, 0.9461, 0.9546, 0.9950, 0.9641,\n                       0.9538, 1.0074, 1.0051, 1.0515, 0.9445, 0.9387, 0.9924, 0.9980, 0.9645,\n                       0.9706, 1.1422, 0.9478, 1.1108, 1.0744, 1.0130, 0.9289, 0.9765, 1.0054,\n                       1.0478, 0.9867, 0.8799, 1.0098, 0.9496, 0.9315, 0.9633, 1.0208, 0.9817,\n                       0.9650, 1.0021, 0.9997, 1.0381, 1.1050, 1.0498, 1.0714, 0.9573, 0.9276,\n                       0.9495, 0.9266, 1.0026, 0.9977, 0.9803, 0.9509, 0.9739, 0.9802, 1.0301,\n                       0.9975, 0.9751, 1.0156, 0.9800, 0.9420, 0.9331, 0.9925, 0.9930, 0.9706,\n                       0.9788, 0.9681, 0.9315, 1.0132, 1.1417, 1.0169, 1.0200, 0.9898, 1.0230,\n                       1.0067, 0.9383, 0.9375, 0.9741, 0.9609, 0.9989, 0.9444, 1.0233, 1.0245,\n                       0.9741, 1.0110, 1.0370, 1.0484, 1.0736, 0.9634, 0.9686, 1.0347, 1.0694,\n                       0.9716, 0.9605, 1.0246, 0.9327, 1.0082, 0.9741, 1.0262, 0.9334, 0.9741,\n                       0.9470, 1.0151, 0.9778, 0.9262, 0.9804, 1.0553, 0.9997, 0.9910, 1.1188,\n                       0.9957, 1.0323, 0.9661, 1.0413, 0.9870, 0.9679, 1.0426, 1.0560, 0.9236,\n                       1.0000, 1.0100, 0.9858, 1.0089, 0.9683, 1.0631, 0.9794, 0.9811, 0.9584,\n                       1.0087, 1.0027])),\n              ('layer2.2.bn2.bias',\n               tensor([-0.0307, -0.1259, -0.0145, -0.2088, -0.0915, -0.1196, -0.0053, -0.1414,\n                        0.0533, -0.0320, -0.0139, -0.1185, -0.0604,  0.0332, -0.0211, -0.0335,\n                       -0.0093,  0.0313, -0.0718, -0.0256,  0.0182, -0.1703, -0.0267, -0.0506,\n                       -0.1026, -0.0102,  0.1483, -0.0607, -0.0490,  0.0649, -0.0969,  0.0259,\n                       -0.0202, -0.1467, -0.1765, -0.0285, -0.0120,  0.0338, -0.0805,  0.0537,\n                       -0.1197,  0.0449, -0.0707, -0.0291,  0.0256,  0.0128, -0.0681, -0.0562,\n                       -0.0105, -0.0208, -0.0042, -0.0131, -0.0155, -0.2492, -0.1516, -0.0914,\n                       -0.0609, -0.1301, -0.0194, -0.1312, -0.0496,  0.0342, -0.0765, -0.0087,\n                       -0.0200, -0.0410, -0.0624, -0.0971, -0.0537, -0.1133, -0.0106, -0.0514,\n                        0.0539, -0.0143,  0.0181, -0.1167, -0.1689, -0.1060, -0.1596, -0.2294,\n                       -0.0359, -0.0114,  0.0177, -0.0748, -0.0535,  0.0363, -0.0581, -0.0034,\n                       -0.0326,  0.0023, -0.0789, -0.0070,  0.1105, -0.0227, -0.1049, -0.0368,\n                        0.0087, -0.1064, -0.0490, -0.0717, -0.0331, -0.0695,  0.1128, -0.0966,\n                       -0.0715, -0.1065, -0.2201, -0.1265,  0.0007,  0.0196, -0.0022, -0.0762,\n                        0.0076, -0.0698,  0.0157, -0.0618, -0.0802, -0.0616,  0.0204, -0.0978,\n                       -0.0860, -0.0223, -0.0608, -0.1007, -0.0427, -0.0798, -0.1038, -0.0493])),\n              ('layer2.2.bn2.running_mean',\n               tensor([-0.4171,  0.1833, -0.3706, -0.6213, -0.8390, -0.3160,  0.1698, -0.8356,\n                        0.3132,  0.2551,  0.3382, -1.1848, -0.4136, -0.4900, -1.4613,  0.1891,\n                        0.0736, -0.1202, -0.1016, -0.2277, -0.3985,  1.0272, -1.2607, -1.1689,\n                        0.2332, -0.4175,  0.3383, -0.1551, -1.1337, -0.5043, -1.4577, -0.2140,\n                        0.2457, -0.9760, -1.2071, -1.4285,  0.1830, -0.8916, -0.6832,  0.0249,\n                        0.3356,  1.6222,  0.3097,  0.0859,  0.2344,  0.0552,  0.0264, -1.3559,\n                        0.9056,  0.0964,  0.2481, -0.1195,  0.0323, -0.5271,  0.7253, -0.1676,\n                        0.3291, -0.4767, -0.1803, -0.4288, -0.2660,  0.3388, -0.1348, -0.7124,\n                       -0.9530, -0.6279, -0.0237, -0.3769, -0.6980,  0.5717,  0.7640, -1.4989,\n                        0.5564,  0.6928,  0.4977, -0.3751, -1.0199,  0.3875, -0.3459, -0.5973,\n                       -0.1128, -0.4001, -0.9291, -1.0843, -1.0508, -1.0621, -1.6022,  0.2242,\n                       -0.7525, -1.2298, -0.1095, -0.2060,  0.3938, -0.4219, -0.8388, -0.9117,\n                        0.1769,  0.3223,  0.3082, -0.4264,  0.4662,  0.7458, -0.5970, -1.2225,\n                        0.1968, -0.6186, -1.5027, -1.0159, -0.7035, -0.5130, -0.3175, -0.9191,\n                       -0.0415,  0.7276, -0.9050,  0.1487, -0.5979, -1.0504, -0.3826, -0.9682,\n                       -0.0820, -1.3989, -0.0185, -0.8904, -0.4202,  0.0726, -0.5767, -1.2421])),\n              ('layer2.2.bn2.running_var',\n               tensor([0.9903, 0.9541, 0.7050, 1.0457, 0.9198, 0.9074, 0.8578, 0.8267, 0.6423,\n                       0.7524, 0.7966, 0.8222, 0.9195, 0.7872, 0.8179, 1.1962, 0.7989, 0.7753,\n                       0.9292, 1.2597, 0.8576, 1.3307, 1.0125, 0.9747, 0.9137, 0.8185, 0.8214,\n                       1.3257, 0.7547, 0.6765, 1.1400, 1.2019, 0.7645, 1.2801, 1.1963, 0.7576,\n                       0.9163, 0.8427, 0.8410, 0.8603, 0.8521, 0.9936, 0.7378, 0.8622, 0.8804,\n                       0.7626, 0.7220, 1.3741, 0.8796, 0.7074, 0.7746, 0.8524, 0.6995, 1.0892,\n                       1.3500, 0.7975, 1.0178, 0.7138, 0.6687, 0.5940, 0.9993, 0.6177, 0.5833,\n                       1.0683, 0.7966, 0.9137, 0.6854, 1.0582, 1.2753, 1.0239, 0.6648, 0.8591,\n                       0.7424, 0.8344, 0.7447, 0.7758, 1.1030, 0.8439, 0.6532, 0.8842, 0.8502,\n                       0.8776, 0.7897, 0.9666, 1.0134, 0.8828, 1.1513, 0.7915, 0.9002, 1.6235,\n                       0.6428, 0.6434, 0.7938, 0.7614, 0.8619, 0.7047, 0.9477, 0.7420, 0.8323,\n                       0.9048, 0.8184, 0.7991, 0.7044, 1.0125, 1.2671, 1.0217, 1.8256, 0.8220,\n                       0.6818, 0.7775, 0.9034, 1.0982, 0.9456, 0.8314, 0.7204, 1.1709, 0.7403,\n                       0.7497, 0.8273, 1.2202, 0.9694, 0.7362, 0.9435, 1.0466, 0.5907, 0.5422,\n                       0.8988, 0.7744])),\n              ('layer2.2.bn2.num_batches_tracked', tensor(13572)),\n              ('layer2.2.conv3.weight',\n               tensor([[[[-0.0310]],\n               \n                        [[ 0.0057]],\n               \n                        [[ 0.0173]],\n               \n                        ...,\n               \n                        [[ 0.0165]],\n               \n                        [[-0.0412]],\n               \n                        [[-0.0174]]],\n               \n               \n                       [[[ 0.0197]],\n               \n                        [[ 0.0425]],\n               \n                        [[ 0.0021]],\n               \n                        ...,\n               \n                        [[-0.0527]],\n               \n                        [[-0.0059]],\n               \n                        [[-0.0994]]],\n               \n               \n                       [[[-0.0178]],\n               \n                        [[-0.0502]],\n               \n                        [[-0.0051]],\n               \n                        ...,\n               \n                        [[ 0.0055]],\n               \n                        [[-0.0646]],\n               \n                        [[-0.0520]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0137]],\n               \n                        [[-0.0134]],\n               \n                        [[-0.0959]],\n               \n                        ...,\n               \n                        [[ 0.0657]],\n               \n                        [[-0.0368]],\n               \n                        [[-0.0085]]],\n               \n               \n                       [[[ 0.0500]],\n               \n                        [[-0.0045]],\n               \n                        [[-0.0676]],\n               \n                        ...,\n               \n                        [[-0.0088]],\n               \n                        [[-0.0556]],\n               \n                        [[ 0.0216]]],\n               \n               \n                       [[[ 0.0692]],\n               \n                        [[ 0.0407]],\n               \n                        [[-0.0033]],\n               \n                        ...,\n               \n                        [[-0.0169]],\n               \n                        [[ 0.0626]],\n               \n                        [[-0.0527]]]])),\n              ('layer2.2.bn3.weight',\n               tensor([ 3.3469e-01, -2.5997e-01,  1.9389e-01,  6.0512e-02,  1.5775e-01,\n                        1.6481e-01, -5.2572e-02, -1.5287e-01, -2.9280e-01, -2.9170e-01,\n                        1.5373e-01, -3.7238e-02,  2.1588e-01, -3.8826e-01,  8.8450e-02,\n                       -1.1084e-01,  3.2373e-01,  2.0556e-01, -2.3070e-01, -1.3506e-01,\n                        2.2464e-01,  1.2744e-01,  3.8307e-02,  1.0537e-02, -2.0192e-01,\n                       -2.4558e-01, -2.8324e-01, -9.5903e-02,  6.0852e-04, -1.5547e-01,\n                        3.6618e-02, -6.8333e-03,  1.8157e-01, -2.7349e-01, -8.2779e-02,\n                       -2.3951e-02, -1.9835e-01,  2.6497e-02, -1.7392e-01,  1.8638e-01,\n                       -2.3494e-01,  2.2147e-01, -1.3515e-01, -2.3757e-01,  1.5771e-01,\n                       -2.8512e-01,  2.9156e-01, -2.1422e-01, -3.5392e-02, -2.4471e-01,\n                        7.6651e-02, -2.6941e-01,  1.7909e-01, -1.3701e-01, -1.4267e-01,\n                       -1.2570e-01, -2.7917e-02,  2.6401e-01,  1.7821e-01, -7.5886e-02,\n                        3.0478e-01, -1.9466e-01,  1.7660e-01,  2.1682e-01,  1.7052e-01,\n                       -1.4618e-01, -2.5697e-01,  3.0102e-01, -2.5034e-01,  5.5813e-02,\n                       -1.1651e-01,  2.2760e-01,  2.7848e-01,  7.4305e-02, -2.9816e-01,\n                       -1.4263e-01, -3.6252e-01,  2.0756e-01,  5.2514e-02,  1.9949e-01,\n                       -1.7480e-01,  9.1150e-02,  5.1680e-02,  1.4825e-01,  1.0639e-01,\n                        2.3595e-01,  1.1591e-01, -7.3024e-02,  3.3005e-01,  2.4327e-01,\n                       -1.8172e-02, -1.9181e-01, -1.8185e-01, -2.0515e-01, -2.5344e-01,\n                       -1.5390e-01,  9.2485e-02,  2.1441e-01,  3.3235e-01, -7.4767e-02,\n                        2.0305e-01,  1.3904e-01,  2.9774e-04,  2.1100e-01,  7.4179e-02,\n                       -2.4315e-01,  1.7063e-01,  2.7281e-02,  2.7165e-01,  9.2434e-02,\n                       -1.6361e-01, -2.0101e-01,  1.1832e-01, -2.0064e-01,  2.2526e-01,\n                       -2.8937e-01,  3.3608e-02, -3.6121e-02, -1.8602e-01,  8.7818e-02,\n                       -1.3061e-02, -3.4168e-01, -2.4202e-01,  1.8483e-01, -1.7688e-01,\n                        8.3579e-02, -2.3972e-01, -4.1238e-02,  8.9901e-02,  1.2602e-01,\n                        1.8235e-01, -1.1762e-01, -2.0630e-01,  2.3602e-01, -1.7460e-01,\n                       -4.4423e-02,  3.3239e-02,  1.5128e-01, -1.6071e-02, -2.7109e-01,\n                        2.4459e-01, -2.7743e-01, -9.1799e-02,  1.4668e-01, -2.9065e-01,\n                        1.4777e-01, -8.3470e-02,  8.7961e-02,  2.5795e-01,  2.4864e-01,\n                        2.7640e-01, -4.4833e-02,  1.5650e-01, -8.7209e-02,  5.4513e-02,\n                       -1.0814e-01, -1.7230e-01, -3.2110e-01,  1.0237e-02,  2.3354e-01,\n                       -1.9386e-01,  2.0636e-01, -1.9411e-01, -3.7627e-02,  1.3665e-01,\n                        2.0358e-01, -2.7677e-01,  3.0523e-01,  3.0708e-01,  1.9691e-02,\n                       -2.6262e-01, -2.0848e-02, -2.3826e-01, -2.6100e-01, -1.0478e-01,\n                       -2.8267e-01, -7.2405e-02,  2.2752e-01,  2.0731e-01, -1.8807e-01,\n                       -2.3302e-01,  1.8445e-01, -2.6848e-01, -1.6170e-01, -2.5664e-01,\n                        2.2896e-01, -2.3095e-02,  3.7862e-02, -1.0026e-02, -2.7975e-01,\n                       -1.0852e-01,  1.1433e-02,  1.6111e-01,  1.9832e-01,  1.3526e-01,\n                       -9.8774e-03,  2.3285e-01, -2.0459e-01, -2.0991e-01,  2.6700e-01,\n                       -1.9673e-01, -1.2485e-01, -6.9271e-02,  2.0025e-01, -7.8179e-02,\n                       -2.6860e-01,  1.4708e-01,  1.0145e-01, -2.7001e-01, -1.9801e-01,\n                        1.7736e-01, -1.9194e-01,  8.8406e-02, -2.2701e-01,  1.6653e-01,\n                        2.8535e-01, -1.8100e-01, -1.0066e-01,  2.3691e-01, -1.3690e-01,\n                       -1.2063e-01,  9.2927e-02,  3.1006e-01, -2.7032e-01,  2.4867e-01,\n                        1.0874e-01,  1.4745e-01, -9.0968e-02, -1.8925e-01, -1.4093e-01,\n                       -8.6182e-02, -9.2607e-02,  1.7995e-01, -2.2034e-01, -1.0143e-01,\n                       -7.3933e-03,  4.0147e-01,  1.6339e-01, -8.4427e-02,  2.3744e-01,\n                       -5.7127e-02, -2.6691e-01,  7.4354e-02, -2.1518e-01,  1.6318e-01,\n                       -1.7495e-01, -2.2269e-01,  2.1145e-02, -2.4367e-01, -3.5061e-01,\n                       -1.8055e-01, -2.0977e-01,  1.7507e-01,  1.1837e-01, -2.2456e-01,\n                        1.1119e-01,  5.3167e-02, -1.4770e-01,  6.0984e-02, -2.5740e-01,\n                       -2.6181e-01,  1.0925e-01,  1.7349e-01,  8.4862e-02, -1.6742e-01,\n                        2.0999e-01,  1.1199e-01,  3.5003e-01, -3.3882e-01,  2.8536e-01,\n                       -8.0595e-02, -1.4232e-01,  2.9048e-01, -1.8716e-01, -2.5547e-02,\n                       -2.0397e-01, -7.7410e-02, -3.3695e-01, -1.8465e-01, -2.0287e-03,\n                       -1.6484e-01, -1.9405e-01,  2.2905e-01,  4.3055e-01,  1.2859e-01,\n                       -1.3662e-01, -9.1633e-02,  1.4690e-01,  2.4844e-01, -1.7963e-01,\n                       -3.8141e-01,  1.6469e-01, -2.7612e-01,  2.1983e-01,  2.5104e-01,\n                        1.8431e-01, -1.1019e-01, -2.7465e-01,  5.5037e-02, -1.1300e-01,\n                        2.3842e-01,  1.3998e-01, -7.7792e-02,  4.0915e-01,  2.7070e-01,\n                       -2.0068e-01,  2.6013e-01,  1.5790e-01, -2.4811e-01,  1.2427e-01,\n                       -2.4502e-01,  3.8039e-01,  1.9534e-01,  1.2410e-01,  1.3134e-01,\n                       -2.4492e-01,  2.3004e-01, -4.5332e-02,  2.8492e-01, -2.7814e-01,\n                       -2.0323e-01, -1.3215e-01, -8.0829e-02, -1.5654e-01,  1.6830e-01,\n                        2.5168e-01,  1.3022e-01, -1.2529e-01, -1.6808e-01,  1.2405e-01,\n                       -2.1825e-01, -3.8318e-01, -2.4717e-01,  2.0494e-01, -2.6765e-01,\n                       -2.1735e-01,  2.6746e-01,  2.0729e-01, -2.7778e-01,  1.6574e-01,\n                        5.1371e-02,  1.4541e-01,  7.6311e-02, -3.3879e-01,  2.2421e-01,\n                        1.7823e-01,  1.2061e-01, -2.2812e-01,  2.9266e-01,  1.9377e-01,\n                        2.7297e-01, -1.2652e-01,  2.2773e-01, -1.4174e-01, -6.1616e-02,\n                        1.2026e-01, -1.0314e-01,  1.2901e-01,  9.6645e-02,  2.9580e-02,\n                        2.0644e-01,  2.4070e-01,  2.5624e-01, -2.2522e-01, -1.3205e-01,\n                        2.9311e-01,  1.7690e-01,  2.4197e-01,  2.1613e-01, -3.4644e-01,\n                       -1.8966e-01, -1.6856e-01,  1.8124e-01, -1.4523e-01, -5.0324e-02,\n                        2.4853e-01,  1.6500e-01,  2.4538e-01, -1.0180e-01, -1.7617e-01,\n                       -2.0297e-01, -3.9457e-02, -1.8462e-01,  1.6618e-01, -1.7494e-01,\n                        1.2596e-02, -2.6556e-01, -1.4277e-01,  2.1599e-01, -1.9433e-01,\n                       -1.6685e-01, -1.3313e-01,  8.0191e-02,  1.8951e-01,  2.7484e-01,\n                       -2.3777e-01, -2.8019e-01, -5.3172e-02,  9.0101e-02,  9.1246e-02,\n                        1.2630e-01, -2.5437e-01, -3.1367e-01,  2.2165e-01,  5.2138e-02,\n                        1.8308e-01,  3.4306e-01, -1.7003e-01,  2.1093e-01, -2.2897e-01,\n                       -1.1804e-01,  1.7119e-01,  1.1661e-01, -1.5922e-01,  2.1890e-01,\n                       -9.6777e-02, -2.5145e-01,  2.8856e-02,  1.6811e-01,  2.5800e-01,\n                        2.4895e-01, -2.3055e-01,  3.2457e-01, -7.9369e-02, -3.8216e-02,\n                       -2.9751e-01,  2.6443e-01, -2.1796e-01, -2.1460e-02, -1.6539e-01,\n                        1.3104e-01, -1.1295e-01,  8.8842e-02,  1.7424e-01,  2.1190e-01,\n                        2.8048e-01,  1.6014e-01,  1.6970e-01,  1.3326e-01,  2.7507e-01,\n                        6.8198e-02,  2.8891e-01,  1.9195e-01, -2.0330e-01, -2.6997e-01,\n                       -2.5485e-01,  1.4751e-01,  2.5579e-01,  2.1386e-01,  2.4220e-01,\n                        1.8629e-01,  2.9556e-01,  2.5011e-01, -2.6800e-01, -8.5031e-02,\n                        1.6428e-02,  8.8376e-02,  2.7598e-01,  1.1068e-01, -2.6092e-01,\n                       -3.2792e-01,  7.3923e-02, -4.0076e-01,  3.3252e-02, -2.9983e-01,\n                       -4.2580e-01,  3.1375e-02,  1.4320e-01,  1.2350e-01,  9.0115e-02,\n                       -3.6417e-02, -2.4294e-01,  1.2919e-01, -7.7093e-02, -1.9261e-01,\n                        7.1754e-02,  3.1855e-01, -1.8630e-01,  3.0562e-01, -2.4247e-01,\n                        3.6883e-02, -8.8752e-02, -1.2817e-01, -1.2541e-01, -2.2495e-01,\n                        2.8081e-01,  1.8060e-01,  2.0812e-01,  2.0919e-01, -2.1605e-01,\n                        3.5019e-01,  2.5811e-01,  1.6164e-01, -2.0325e-01,  1.1364e-01,\n                        1.9988e-01,  2.3990e-01, -2.2998e-01, -3.0469e-01,  1.3050e-01,\n                       -1.7156e-01,  1.8295e-01,  4.1255e-01,  2.9159e-01, -4.5244e-02,\n                        3.1484e-01,  7.0799e-02,  2.6481e-01, -2.4213e-01,  9.5715e-02,\n                        2.6553e-01, -2.1633e-01])),\n              ('layer2.2.bn3.bias',\n               tensor([ 7.9536e-02, -3.5147e-02,  6.2365e-02, -6.3681e-02,  3.0289e-02,\n                       -7.1426e-02, -1.1614e-01,  2.1476e-03,  6.1944e-02,  4.7299e-02,\n                        1.3102e-01, -1.8438e-01,  6.1693e-02,  1.3098e-01,  1.0135e-02,\n                        1.5129e-02,  1.5811e-03,  7.5033e-02, -1.9232e-02, -1.0542e-01,\n                       -9.7682e-02,  6.0826e-02,  5.9227e-02, -6.3144e-02,  7.4295e-02,\n                        6.0538e-02,  1.0640e-01,  8.1771e-02,  8.5680e-02, -2.2796e-02,\n                       -3.1487e-02,  5.1860e-02,  9.6682e-02, -7.7784e-02,  8.8035e-02,\n                        6.7074e-02,  1.4627e-01, -1.3964e-02,  9.3369e-03,  3.4755e-02,\n                        5.9572e-02, -1.7183e-01,  1.3728e-01,  3.7195e-02,  1.3275e-01,\n                       -1.2380e-01,  1.6290e-01, -5.3580e-02, -9.5828e-02, -9.6613e-02,\n                        8.8113e-02,  1.2239e-01, -4.9548e-02, -7.1852e-02, -5.0330e-02,\n                       -3.5433e-02,  7.1868e-02,  6.5046e-02,  6.1259e-02, -8.4842e-02,\n                        3.6764e-02,  8.6919e-02,  8.5284e-02, -5.8509e-03,  1.1451e-01,\n                        2.0372e-04, -5.3601e-02,  2.8214e-02,  3.8544e-02,  2.5163e-02,\n                       -1.9083e-02, -7.5412e-04,  8.0755e-02,  8.5862e-02,  1.4771e-01,\n                       -1.2812e-01,  3.2748e-02,  4.2358e-02,  5.1823e-02,  8.6001e-02,\n                       -7.0879e-02, -3.5180e-02,  9.6692e-02,  2.0831e-02, -6.3796e-02,\n                        5.6901e-02,  1.0392e-01, -1.6456e-01,  9.5316e-03,  1.8400e-01,\n                       -2.0828e-02,  3.0274e-02,  1.0393e-01,  1.6495e-01,  1.2055e-01,\n                        7.6628e-03,  9.8338e-02, -3.8428e-02, -5.4842e-02,  3.9614e-02,\n                       -1.0696e-01, -1.2482e-01, -7.8566e-02, -5.3537e-03,  3.7218e-02,\n                        1.2573e-01, -7.3630e-02,  1.4578e-02,  1.7185e-02, -7.5122e-02,\n                       -5.7261e-02, -6.0216e-02,  7.3849e-02,  1.2925e-01, -9.0800e-02,\n                        9.8130e-02,  6.2838e-02, -4.1767e-02, -1.2323e-01,  5.4424e-02,\n                       -1.0799e-01,  6.4092e-05,  9.9500e-03, -3.2162e-03,  4.4489e-02,\n                        5.2720e-03,  1.3038e-01, -2.9667e-02,  2.1232e-02,  4.2801e-02,\n                        1.0011e-01, -3.2422e-02, -1.5332e-02,  1.5457e-01,  6.1794e-02,\n                        7.5843e-02, -6.4362e-02, -5.0181e-04,  9.6123e-02,  1.9669e-01,\n                        9.5663e-02,  1.4947e-01, -6.0794e-02,  8.3036e-02,  2.6237e-02,\n                       -4.2770e-02, -4.5616e-02,  8.1778e-02,  1.2707e-01,  1.8059e-02,\n                        8.5695e-02,  1.0435e-03,  1.0236e-01, -3.7525e-02,  5.4799e-03,\n                        1.5211e-01,  1.1214e-02,  2.4073e-01,  4.6534e-02,  4.4087e-02,\n                       -3.2104e-02, -4.4475e-02,  4.6167e-02,  3.0209e-02, -9.0560e-02,\n                        5.7976e-02,  3.5380e-03,  9.6546e-02,  1.5686e-01,  6.9815e-02,\n                       -5.8549e-02,  1.9487e-02,  2.3992e-01,  8.1394e-02, -1.2416e-01,\n                        5.4751e-02,  3.8171e-02,  1.3113e-01, -4.4699e-02, -1.5475e-02,\n                        3.2377e-02, -8.2931e-02,  1.7955e-03, -1.6628e-01, -4.1742e-02,\n                        1.6746e-01,  6.5373e-02, -8.8440e-02,  2.0402e-02,  3.7036e-02,\n                        4.9382e-02,  7.4348e-02,  9.1826e-02,  1.0959e-01,  1.3732e-01,\n                        2.4950e-02, -2.1458e-02, -7.4143e-02,  7.4639e-02,  3.1776e-02,\n                        4.5012e-02, -1.9233e-02,  6.4758e-02,  1.2326e-01, -6.4257e-02,\n                       -5.7331e-03, -7.6428e-02,  8.9115e-02,  6.4962e-02,  1.0719e-01,\n                        2.4548e-02, -6.2708e-02, -4.5124e-02,  1.2203e-01,  2.0188e-02,\n                        9.8370e-02,  2.5124e-02,  5.0419e-02,  7.8336e-02,  6.8285e-02,\n                       -1.1174e-01, -5.4248e-03,  1.4703e-02, -4.2850e-02, -9.3518e-02,\n                        1.7144e-02,  1.7879e-03, -7.2565e-02,  7.6141e-02, -3.2756e-03,\n                       -2.2542e-02, -1.7476e-01, -1.2334e-02,  3.9413e-02, -7.2979e-02,\n                       -8.0875e-02, -7.7752e-02,  2.1095e-02, -1.9426e-02, -7.8178e-02,\n                       -5.5257e-02, -7.3481e-03, -5.5939e-03,  7.4192e-02,  8.4356e-02,\n                        2.2199e-01, -3.4337e-02, -3.2709e-03, -1.0952e-01,  8.8944e-02,\n                        1.7336e-01,  4.1792e-02,  9.6050e-02,  4.5967e-03,  6.1151e-02,\n                        1.1269e-01,  1.2300e-03, -1.1715e-01,  1.1131e-01,  8.6056e-02,\n                       -5.4657e-04,  1.4360e-01, -3.5794e-03,  1.5218e-01,  7.5474e-02,\n                       -2.0177e-02, -9.3854e-02,  2.7766e-02,  1.1953e-01, -3.0987e-02,\n                       -1.0858e-01, -3.3518e-02, -1.8143e-03,  3.1689e-02,  1.7621e-03,\n                        2.1777e-01,  3.8910e-02,  2.6456e-01, -1.0216e-01,  5.8015e-02,\n                       -3.1910e-02,  1.4388e-01,  1.6189e-01, -3.3796e-02,  7.0717e-02,\n                       -7.8632e-03,  3.4395e-03, -4.1036e-02,  1.0693e-01,  1.3865e-01,\n                       -5.1073e-02, -4.0061e-02, -2.0553e-02,  2.8976e-02,  9.1594e-02,\n                        6.1360e-02, -1.9878e-02,  1.2861e-01,  6.1946e-02,  9.3271e-02,\n                       -1.0369e-01,  8.8322e-02, -4.6887e-02,  1.2603e-01,  1.9966e-01,\n                        3.1249e-03,  1.1088e-01, -1.1089e-02,  1.3383e-01,  9.9692e-02,\n                        1.4233e-01, -1.2294e-01,  3.7277e-02,  3.3802e-02,  1.6706e-02,\n                        8.6696e-02, -5.7718e-02,  5.8666e-02,  9.1801e-02, -4.8017e-02,\n                        5.3124e-02,  5.9722e-02, -7.8187e-02,  6.6169e-03, -1.3096e-02,\n                        1.0061e-01,  5.5682e-02,  6.6445e-02,  1.2308e-01,  6.5954e-02,\n                        1.1366e-01,  9.6337e-02,  1.3177e-01,  1.6365e-01,  1.0969e-01,\n                       -9.5122e-03, -1.9517e-02, -8.0498e-02, -2.0092e-01,  1.5166e-01,\n                        1.2218e-01, -6.7778e-02, -6.5522e-02,  8.2927e-02,  2.6193e-02,\n                        1.0794e-01,  6.7432e-02,  2.6426e-02,  3.6837e-02, -3.6971e-03,\n                       -9.2920e-02,  1.0630e-01,  2.9622e-02,  2.2455e-01,  5.1596e-02,\n                       -1.4770e-02,  5.2093e-02, -2.1048e-03, -7.8542e-02, -1.3351e-01,\n                        1.7551e-01, -5.7310e-02, -7.7007e-02, -9.1550e-02,  9.2312e-03,\n                        4.2545e-02,  1.4286e-01, -9.9549e-04, -1.9842e-02,  4.6848e-02,\n                        7.9358e-02, -2.2804e-02,  2.4033e-03, -3.9937e-02, -7.5479e-02,\n                        9.7048e-02,  1.1371e-01,  4.7703e-02,  2.9959e-02,  1.0749e-01,\n                        1.4172e-01, -6.9036e-02, -1.9398e-02,  3.3980e-02,  5.9481e-02,\n                        7.1752e-02,  2.1331e-01,  8.7502e-02, -7.9472e-02, -3.8532e-02,\n                       -1.8778e-02,  9.1237e-02,  4.1568e-02, -1.6167e-01,  4.8575e-02,\n                       -2.0616e-02,  7.2718e-02,  9.0300e-02, -7.7720e-02, -4.9460e-02,\n                        6.9443e-02, -6.1799e-02, -5.2528e-02, -2.8092e-02, -8.8026e-02,\n                       -4.2386e-02,  9.3989e-02, -5.4613e-02, -1.5596e-02, -1.2030e-01,\n                        5.5806e-02,  4.3444e-02,  5.5617e-02,  1.4910e-02,  8.3082e-02,\n                        4.0232e-02,  1.9513e-01, -6.1837e-02, -6.0819e-02,  1.4822e-01,\n                        6.4025e-02, -9.8203e-03, -1.4620e-01, -4.4106e-02,  2.8976e-03,\n                       -2.2183e-04, -1.4766e-01,  6.7877e-02, -1.9930e-02, -3.6261e-02,\n                       -4.2116e-02, -7.0142e-02,  9.9119e-02,  1.1989e-01, -6.6262e-03,\n                        1.3292e-01,  1.4763e-01, -1.0543e-01,  1.0863e-01, -8.6787e-03,\n                       -2.9080e-02,  8.8982e-02, -1.5358e-01,  1.6120e-01, -3.8763e-02,\n                       -3.1029e-02,  7.1458e-02, -2.8860e-02,  1.1594e-01,  2.6933e-02,\n                       -5.2192e-02,  1.5948e-01,  1.3019e-01, -1.6629e-02, -7.0056e-02,\n                       -7.1011e-02, -1.1359e-01,  2.4685e-03, -1.3584e-01,  4.7546e-02,\n                       -6.4561e-02, -1.4454e-02,  8.2169e-02, -8.3856e-02, -3.3632e-02,\n                        6.8537e-02, -1.1002e-01,  3.4267e-02, -4.0851e-02, -1.0952e-01,\n                       -7.8501e-03,  1.1771e-01, -1.7196e-02,  8.6243e-02,  2.0902e-04,\n                        2.5948e-02,  1.4241e-01, -2.9973e-02, -4.9146e-03,  1.2533e-01,\n                        1.3862e-01, -1.2929e-01, -7.0814e-02,  1.2569e-02,  2.1505e-02,\n                       -8.1801e-02,  3.1539e-02, -5.0873e-02, -2.5448e-02,  1.0019e-01,\n                        1.2184e-01,  1.4457e-02,  8.0501e-02,  6.9938e-02,  3.1358e-02,\n                        4.0740e-02, -4.4835e-02, -9.7997e-02, -2.7892e-02, -5.8693e-02,\n                        8.9381e-02, -1.3423e-01, -1.0948e-01, -1.0312e-01,  1.3990e-02,\n                       -1.8177e-03, -1.8099e-02, -2.1918e-01,  1.0756e-01,  6.5761e-02,\n                       -6.2478e-02,  8.5507e-02])),\n              ('layer2.2.bn3.running_mean',\n               tensor([ 0.0605, -0.0540, -0.1088,  0.0958,  0.0414, -0.3372,  0.0446, -0.0120,\n                       -0.2227, -0.1227, -0.1149, -0.2927, -0.0011, -0.3799,  0.2303, -0.1323,\n                        0.3015,  0.1625, -0.2486,  0.1627,  0.2874,  0.1502, -0.1055,  0.0325,\n                        0.0308,  0.7824,  0.1346, -0.0073,  0.0508, -0.1230,  0.1217,  0.2966,\n                        0.0885, -0.1485, -0.1033, -0.3681, -0.1926, -0.0445,  0.0220,  0.6538,\n                        0.6242,  0.0204, -0.0487,  0.1755, -0.1961,  0.3780, -0.1006,  0.3281,\n                        0.0304,  0.1468, -0.1920,  0.2558, -0.1860, -0.0833, -0.3504,  0.1735,\n                        0.0904,  0.0045,  0.6038,  0.1502,  0.2958,  0.0381, -0.0430,  0.1520,\n                        0.1476, -0.2816, -0.0543, -0.1588, -0.4761,  0.0686, -0.0636,  0.2857,\n                       -0.1178, -0.3226,  0.1966,  0.3066, -0.1449,  0.1024, -0.1162,  0.2002,\n                       -0.2511,  0.0299, -0.1898, -0.4196, -0.0317,  0.1586,  0.0304, -0.0843,\n                        0.4163, -0.0847, -0.1380,  0.0388,  0.1947,  0.3046, -0.3312,  0.1671,\n                       -0.1062, -0.0543,  0.2485, -0.1333,  0.1931, -0.1574,  0.0797, -0.2426,\n                       -0.1428,  0.1675, -0.1662,  0.0089, -0.1538, -0.2719,  0.0574,  0.1644,\n                        0.0649, -0.0285,  0.1284, -0.0889, -0.1059,  0.0566, -0.0609,  0.0736,\n                        0.3765, -0.2031, -0.3667,  0.0342, -0.1492, -0.1593,  0.0812,  0.0592,\n                        0.0689, -0.1478,  0.2825,  0.1629, -0.1711, -0.2468,  0.1385,  0.2487,\n                       -0.0134, -0.1340, -0.0373,  0.3026,  0.0190, -0.2556,  0.0162,  0.1026,\n                       -0.2247, -0.0946, -0.0490, -0.2093,  0.1660,  0.3296, -0.1071,  0.0236,\n                        0.2770,  0.0797, -0.0630, -0.1183,  0.3114,  0.2592,  0.0556,  0.2389,\n                       -0.2548, -0.0349,  0.0685,  0.0215,  0.0270,  0.0466, -0.2595, -0.2722,\n                       -0.2203, -0.1209, -0.3804, -0.1100,  0.1111, -0.1432, -0.0752, -0.1562,\n                       -0.1294, -0.3200,  0.1702,  0.2239,  0.2110,  0.0813, -0.0437,  0.0915,\n                       -0.2493, -0.2757,  0.1228, -0.1267,  0.0249,  0.0474,  0.3375, -0.0230,\n                        0.0041, -0.2044,  0.1377,  0.2032, -0.0294,  0.2652,  0.0515,  0.2760,\n                       -0.0521,  0.0317,  0.1733, -0.0839, -0.1206,  0.4181, -0.1046,  0.1782,\n                        0.2366,  0.2079,  0.3514,  0.2454,  0.2652, -0.1387,  0.2684, -0.2729,\n                        0.0041,  0.0846,  0.3322,  0.1299,  0.0618,  0.0227,  0.3688,  0.1772,\n                       -0.0301, -0.1690,  0.4204,  0.2378,  0.1984,  0.2695, -0.2872, -0.0133,\n                       -0.3521, -0.1486,  0.1878,  0.0579,  0.2175, -0.2752, -0.2982, -0.2047,\n                        0.0859, -0.2349, -0.4429,  0.0413, -0.3702,  0.0657, -0.0171, -0.0945,\n                       -0.0358,  0.1687,  0.4456,  0.1288,  0.2016, -0.0541,  0.3622,  0.2958,\n                       -0.0786, -0.2144,  0.0822, -0.0198,  0.2151, -0.0914,  0.2343, -0.3013,\n                        0.1688, -0.2739, -0.1294,  0.0516,  0.4449, -0.3660,  0.1141,  0.0961,\n                       -0.2404,  0.0431,  0.0671, -0.0383,  0.0515,  0.2284, -0.1235, -0.1072,\n                        0.0178, -0.1996, -0.1685,  0.3483,  0.1579,  0.1373,  0.3036, -0.1273,\n                       -0.0431, -0.1253,  0.0684,  0.3014, -0.0019, -0.3208, -0.3464,  0.3649,\n                        0.1420,  0.3037, -0.1498,  0.2453,  0.2094, -0.5282, -0.1497, -0.1442,\n                       -0.2536,  0.2031, -0.0638, -0.2572,  0.6861,  0.1619,  0.2112,  0.4477,\n                        0.4010, -0.0184, -0.1049,  0.2887, -0.1027,  0.1483,  0.1283,  0.3000,\n                       -0.2006, -0.2552, -0.0607, -0.1485, -0.3463,  0.0597,  0.1335,  0.0359,\n                       -0.0453, -0.2969, -0.2702,  0.0717,  0.6030, -0.5462,  0.3888,  0.3175,\n                       -0.0955, -0.1289, -0.5261, -0.3344,  0.2279, -0.2191,  0.1000, -0.3375,\n                       -0.0614, -0.1286, -0.1312,  0.1974,  0.0231, -0.0350,  0.4041,  0.2224,\n                        0.1735,  0.2554,  0.1568,  0.3439,  0.2337,  0.4210, -0.1947, -0.0973,\n                        0.4333, -0.0431,  0.5720,  0.0618,  0.0299, -0.0320,  0.0504, -0.1434,\n                       -0.1707, -0.2271, -0.0646, -0.0852,  0.0862,  0.1360, -0.0804, -0.0296,\n                       -0.2667,  0.1748, -0.1334,  0.3293,  0.4922,  0.1143,  0.1130,  0.0042,\n                        0.2731,  0.0073,  0.0845,  0.0945,  0.0832, -0.3860,  0.1824, -0.2131,\n                        0.0076,  0.0102,  0.0178, -0.0650, -0.0609,  0.2115, -0.0866, -0.1660,\n                       -0.1307, -0.0434,  0.0274,  0.1273,  0.0390,  0.0055, -0.3731, -0.1754,\n                        0.5285, -0.3256,  0.3299, -0.1047, -0.3772, -0.0937,  0.2181, -0.2616,\n                       -0.2006,  0.2869, -0.0636, -0.0712, -0.1469,  0.1778, -0.1698,  0.1440,\n                        0.0932, -0.5203,  0.4953, -0.1479, -0.2072,  0.1074,  0.0245,  0.0176,\n                       -0.3882,  0.3017,  0.1027,  0.2092, -0.1136,  0.2118,  0.1333,  0.1674,\n                        0.0378, -0.3903,  0.3176,  0.3160,  0.0625,  0.2644, -0.0885, -0.0873,\n                       -0.2849, -0.1511, -0.1146, -0.3366,  0.0702, -0.1563, -0.3257, -0.0680,\n                       -0.2052, -0.0600, -0.4057,  0.3140, -0.2715, -0.1482,  0.0269,  0.4150,\n                        0.2699, -0.1203,  0.1445,  0.0721, -0.0767,  0.0900,  0.1359,  0.1382,\n                        0.2695,  0.1816, -0.3148, -0.2517, -0.0433,  0.2384,  0.0637, -0.2635,\n                        0.0295, -0.0775,  0.0381,  0.1648, -0.1856,  0.4591, -0.0185,  0.1719,\n                       -0.2960,  0.0750, -0.2440, -0.0624,  0.0239, -0.1960,  0.1396, -0.2535,\n                        0.0415,  0.0211, -0.3842,  0.0132,  0.2000,  0.0267, -0.0333, -0.1603,\n                       -0.1556, -0.1909, -0.1184, -0.1301,  0.0073,  0.1663, -0.2201,  0.0403])),\n              ('layer2.2.bn3.running_var',\n               tensor([0.1800, 0.1207, 0.0867, 0.0532, 0.0767, 0.0948, 0.0402, 0.0661, 0.1315,\n                       0.1220, 0.0779, 0.0671, 0.1094, 0.1916, 0.0704, 0.1029, 0.1594, 0.1347,\n                       0.0948, 0.0546, 0.1055, 0.1046, 0.0532, 0.0623, 0.0923, 0.1155, 0.0916,\n                       0.0440, 0.0506, 0.0766, 0.0580, 0.0660, 0.0945, 0.1808, 0.0808, 0.0585,\n                       0.1085, 0.0723, 0.1067, 0.1529, 0.1489, 0.1202, 0.0711, 0.1017, 0.1017,\n                       0.1531, 0.1266, 0.0981, 0.0532, 0.0601, 0.0669, 0.1158, 0.0735, 0.0668,\n                       0.0819, 0.0823, 0.0593, 0.1022, 0.1449, 0.0454, 0.1056, 0.1542, 0.1013,\n                       0.1032, 0.1235, 0.1330, 0.0865, 0.1410, 0.1043, 0.0568, 0.0524, 0.0972,\n                       0.1229, 0.0781, 0.1473, 0.0639, 0.2003, 0.0908, 0.0589, 0.1664, 0.1681,\n                       0.0714, 0.0469, 0.0957, 0.0447, 0.0830, 0.0859, 0.0515, 0.1702, 0.1464,\n                       0.0499, 0.1000, 0.1315, 0.1519, 0.1624, 0.0880, 0.0894, 0.0886, 0.1049,\n                       0.0522, 0.1095, 0.0568, 0.0593, 0.0896, 0.0559, 0.1322, 0.0732, 0.0440,\n                       0.1432, 0.0604, 0.1385, 0.0694, 0.0812, 0.1025, 0.0894, 0.1029, 0.0441,\n                       0.0514, 0.1165, 0.0579, 0.0478, 0.1128, 0.1113, 0.0722, 0.0892, 0.0699,\n                       0.1370, 0.0514, 0.0679, 0.0941, 0.1006, 0.0662, 0.0927, 0.1094, 0.0782,\n                       0.0831, 0.0509, 0.0666, 0.0676, 0.1248, 0.1196, 0.1258, 0.0646, 0.0796,\n                       0.1368, 0.0946, 0.0715, 0.0840, 0.1408, 0.2116, 0.0882, 0.0622, 0.0904,\n                       0.0458, 0.0686, 0.1070, 0.0917, 0.1578, 0.0547, 0.0813, 0.0934, 0.0996,\n                       0.0747, 0.0591, 0.0710, 0.0935, 0.1151, 0.0959, 0.1108, 0.0591, 0.1015,\n                       0.0526, 0.1140, 0.1790, 0.0715, 0.0928, 0.0639, 0.1168, 0.1065, 0.0842,\n                       0.1351, 0.1013, 0.1318, 0.0855, 0.0976, 0.1042, 0.0636, 0.0518, 0.0529,\n                       0.0885, 0.0700, 0.0618, 0.0663, 0.1022, 0.0611, 0.0501, 0.1058, 0.1016,\n                       0.1032, 0.1445, 0.0806, 0.0782, 0.0584, 0.0585, 0.0596, 0.1229, 0.0664,\n                       0.0884, 0.1173, 0.0735, 0.0908, 0.0884, 0.0960, 0.1143, 0.0983, 0.1155,\n                       0.0801, 0.0835, 0.1003, 0.0940, 0.0496, 0.0651, 0.1106, 0.1019, 0.1382,\n                       0.0604, 0.0765, 0.0560, 0.0975, 0.0705, 0.0889, 0.0621, 0.0715, 0.0875,\n                       0.0626, 0.0510, 0.1203, 0.0730, 0.0995, 0.1096, 0.0570, 0.0867, 0.0647,\n                       0.1107, 0.1171, 0.1240, 0.1055, 0.0431, 0.0980, 0.2223, 0.1318, 0.0873,\n                       0.1310, 0.0807, 0.1179, 0.0908, 0.0672, 0.0752, 0.0420, 0.0978, 0.1334,\n                       0.0871, 0.0947, 0.0670, 0.1323, 0.1003, 0.0545, 0.1716, 0.1401, 0.1137,\n                       0.0513, 0.0753, 0.1324, 0.0989, 0.0720, 0.1210, 0.0635, 0.1568, 0.0578,\n                       0.0426, 0.0793, 0.1046, 0.1200, 0.1705, 0.1109, 0.0502, 0.0575, 0.0864,\n                       0.1283, 0.1010, 0.1815, 0.0700, 0.1285, 0.1569, 0.1154, 0.1472, 0.0723,\n                       0.1708, 0.0395, 0.0832, 0.0969, 0.1073, 0.0554, 0.1879, 0.1395, 0.0859,\n                       0.1298, 0.0659, 0.1232, 0.0866, 0.1510, 0.1700, 0.1269, 0.0723, 0.0574,\n                       0.1256, 0.0755, 0.0666, 0.1265, 0.1260, 0.0961, 0.0967, 0.0458, 0.0867,\n                       0.0698, 0.1145, 0.0693, 0.0613, 0.0773, 0.0863, 0.1052, 0.1287, 0.1836,\n                       0.0827, 0.1424, 0.0739, 0.1077, 0.1135, 0.1380, 0.1102, 0.0701, 0.0858,\n                       0.0490, 0.1720, 0.0819, 0.0817, 0.0878, 0.1371, 0.3083, 0.0753, 0.1153,\n                       0.0745, 0.0645, 0.1019, 0.0580, 0.1089, 0.0901, 0.1146, 0.0643, 0.0596,\n                       0.1857, 0.1734, 0.1150, 0.0910, 0.0863, 0.1021, 0.0728, 0.1077, 0.1001,\n                       0.1598, 0.1043, 0.0965, 0.0923, 0.0529, 0.0465, 0.1063, 0.0991, 0.2033,\n                       0.0544, 0.0721, 0.1282, 0.0623, 0.0762, 0.0747, 0.1036, 0.0497, 0.1019,\n                       0.0731, 0.0990, 0.0968, 0.1253, 0.0615, 0.0608, 0.0678, 0.1657, 0.1056,\n                       0.1419, 0.0626, 0.0654, 0.0565, 0.0559, 0.0971, 0.1084, 0.0813, 0.0545,\n                       0.0958, 0.1459, 0.0726, 0.1176, 0.1202, 0.0553, 0.1170, 0.0676, 0.0833,\n                       0.1234, 0.0562, 0.1032, 0.0535, 0.0686, 0.1482, 0.0874, 0.1101, 0.1021,\n                       0.0544, 0.0422, 0.1125, 0.1485, 0.0993, 0.0629, 0.0860, 0.0733, 0.0713,\n                       0.0607, 0.1065, 0.0856, 0.1158, 0.0670, 0.0748, 0.0861, 0.1156, 0.0789,\n                       0.1483, 0.1033, 0.0954, 0.1044, 0.0858, 0.0887, 0.0728, 0.1441, 0.1297,\n                       0.1015, 0.1538, 0.1463, 0.1055, 0.0520, 0.0589, 0.0514, 0.1351, 0.0557,\n                       0.1249, 0.1531, 0.0702, 0.1880, 0.0635, 0.1187, 0.1503, 0.0603, 0.1064,\n                       0.0472, 0.0593, 0.0550, 0.1822, 0.0732, 0.0692, 0.0824, 0.0678, 0.1317,\n                       0.0951, 0.1499, 0.1775, 0.0599, 0.0684, 0.0862, 0.1081, 0.1156, 0.1632,\n                       0.0900, 0.0769, 0.1214, 0.1215, 0.2240, 0.1775, 0.0936, 0.0899, 0.0680,\n                       0.1007, 0.0702, 0.0704, 0.1561, 0.0498, 0.0915, 0.0623, 0.1940, 0.0913,\n                       0.0616, 0.1244, 0.0576, 0.0913, 0.0827, 0.0616, 0.1638, 0.0777])),\n              ('layer2.2.bn3.num_batches_tracked', tensor(13572)),\n              ('layer2.3.conv1.weight',\n               tensor([[[[ 0.0040]],\n               \n                        [[-0.0900]],\n               \n                        [[-0.0764]],\n               \n                        ...,\n               \n                        [[ 0.0149]],\n               \n                        [[ 0.1463]],\n               \n                        [[-0.1662]]],\n               \n               \n                       [[[-0.0719]],\n               \n                        [[ 0.0809]],\n               \n                        [[ 0.1580]],\n               \n                        ...,\n               \n                        [[-0.0053]],\n               \n                        [[-0.0885]],\n               \n                        [[ 0.0398]]],\n               \n               \n                       [[[ 0.0418]],\n               \n                        [[ 0.0105]],\n               \n                        [[ 0.0259]],\n               \n                        ...,\n               \n                        [[ 0.0316]],\n               \n                        [[-0.1291]],\n               \n                        [[ 0.0031]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0007]],\n               \n                        [[ 0.0095]],\n               \n                        [[ 0.0678]],\n               \n                        ...,\n               \n                        [[ 0.0061]],\n               \n                        [[-0.0631]],\n               \n                        [[ 0.0256]]],\n               \n               \n                       [[[-0.0530]],\n               \n                        [[ 0.0151]],\n               \n                        [[-0.0214]],\n               \n                        ...,\n               \n                        [[-0.0390]],\n               \n                        [[-0.0361]],\n               \n                        [[-0.0974]]],\n               \n               \n                       [[[-0.0131]],\n               \n                        [[ 0.0133]],\n               \n                        [[-0.0222]],\n               \n                        ...,\n               \n                        [[-0.0091]],\n               \n                        [[ 0.0351]],\n               \n                        [[-0.0077]]]])),\n              ('layer2.3.bn1.weight',\n               tensor([1.0442, 1.0034, 0.9464, 1.0253, 0.9146, 0.9667, 0.9927, 0.9134, 1.0548,\n                       0.8880, 0.9969, 1.0735, 1.0222, 0.9611, 0.9182, 1.0786, 1.0520, 1.0314,\n                       0.9640, 0.9699, 1.0574, 0.8990, 0.9982, 0.9781, 0.9927, 0.9833, 0.9348,\n                       1.0432, 0.9734, 1.0111, 0.9803, 1.0034, 0.9557, 0.9879, 1.0417, 0.9900,\n                       1.0265, 0.9729, 0.9502, 0.9452, 0.9225, 0.9403, 0.9997, 1.1487, 1.0877,\n                       0.9670, 0.9440, 1.0565, 1.0045, 0.9825, 1.1468, 1.1364, 0.9802, 0.9609,\n                       1.0106, 0.9136, 1.0483, 0.9677, 0.9423, 0.9516, 0.9978, 0.9742, 1.0033,\n                       1.0351, 0.9504, 1.0505, 1.0271, 1.0302, 1.1294, 1.1349, 1.0125, 1.0373,\n                       0.9679, 0.9340, 1.0017, 0.8897, 0.9718, 0.9307, 0.9977, 1.0117, 0.8963,\n                       0.9734, 0.9785, 1.0850, 0.9559, 1.0105, 0.9151, 0.9354, 1.0274, 0.9555,\n                       1.0818, 0.9056, 0.9576, 0.9958, 1.0126, 0.9597, 0.9541, 0.8697, 1.0068,\n                       1.0432, 0.9905, 1.0131, 0.9904, 1.0643, 1.0036, 0.9448, 0.9664, 1.0379,\n                       1.0018, 0.8618, 0.9457, 1.0393, 0.9451, 1.0034, 0.9426, 1.0563, 1.0960,\n                       0.9514, 1.0419, 0.9723, 0.9519, 1.0339, 0.9798, 0.9919, 0.9435, 0.9449,\n                       1.0320, 1.0341])),\n              ('layer2.3.bn1.bias',\n               tensor([ 0.0027, -0.1743, -0.0026,  0.0618, -0.0443, -0.2405, -0.1183, -0.0740,\n                       -0.0473,  0.0071, -0.0595, -0.0137, -0.0931, -0.1499, -0.0593, -0.0895,\n                       -0.0459, -0.1419, -0.0361, -0.0380,  0.0209, -0.1660,  0.0011, -0.0338,\n                        0.0308, -0.0222, -0.0749, -0.0340, -0.0148, -0.0518, -0.0718,  0.0485,\n                       -0.1346, -0.1497, -0.0068, -0.0152, -0.0961, -0.1883, -0.0679, -0.0410,\n                       -0.0761, -0.0848, -0.0289,  0.0621, -0.1236, -0.0611, -0.0378, -0.0736,\n                       -0.0499, -0.1812, -0.0577, -0.4847, -0.1611,  0.0116, -0.0793,  0.0052,\n                       -0.1073, -0.0122,  0.0036, -0.1889, -0.0083, -0.0014, -0.2178, -0.2654,\n                        0.0125, -0.0744, -0.0133, -0.0370, -0.2230,  0.0425, -0.0112,  0.0074,\n                       -0.0635, -0.1684,  0.0838, -0.1973, -0.1299, -0.0847, -0.2422, -0.1360,\n                       -0.1066, -0.0974, -0.0100, -0.3807, -0.0808, -0.0494, -0.0367, -0.1117,\n                       -0.0480, -0.0674, -0.0189, -0.0924, -0.1535, -0.1606, -0.0189, -0.0211,\n                       -0.0681, -0.0355, -0.0391, -0.0332, -0.0180, -0.0047, -0.0007,  0.0375,\n                       -0.1132, -0.0899, -0.0431, -0.1343, -0.3489, -0.0037, -0.0386,  0.0362,\n                       -0.1034, -0.1894, -0.0259,  0.0561, -0.0413,  0.0446, -0.0651, -0.0006,\n                        0.0106, -0.1676,  0.0213, -0.0371,  0.0256, -0.0975, -0.0202, -0.1289])),\n              ('layer2.3.bn1.running_mean',\n               tensor([-0.3122, -1.0688, -1.4736, -1.1438, -0.6074, -0.7574,  1.2072,  0.4275,\n                       -0.8261, -0.1678, -0.7477, -2.7239,  0.2077,  0.6178, -0.5916,  0.1142,\n                        0.3213,  0.2355, -0.7366, -1.1104, -1.8794, -0.1254, -0.3685, -0.0302,\n                       -2.1152,  0.2211, -0.6930, -1.0795, -0.2975,  0.0895, -0.8905, -2.7977,\n                       -0.4587, -0.0378, -0.6813, -0.1841,  0.8251,  0.0087, -0.3974, -1.4515,\n                        1.0782, -0.7471,  0.6085, -1.9491, -0.6230,  0.3286, -0.5790, -1.2790,\n                       -0.6100,  0.0952, -3.1164,  0.3486,  0.2113, -1.4863, -1.8120, -2.4862,\n                       -2.4479,  1.4772, -0.3513, -0.2688, -0.6193, -3.3151, -0.2686, -1.2081,\n                       -1.4229, -1.0638, -1.5796, -0.8987,  0.5281, -2.7268, -1.0329, -0.7713,\n                       -0.0107,  1.5542, -1.3252,  0.0544, -0.9368, -1.1682, -0.9854, -0.4116,\n                       -0.3517, -0.8568, -0.4993, -0.3859,  0.6100, -1.5482,  0.0415, -1.0607,\n                        0.2310,  0.5303, -0.7579,  0.8135, -0.3958,  0.2795, -1.3110, -1.9917,\n                       -0.0473, -0.1809, -1.3152, -1.9523, -0.3495, -1.5667, -0.1433, -1.5256,\n                       -0.8178, -0.6010, -1.0575, -1.7264, -0.9008,  0.5310, -0.1139, -1.6590,\n                       -0.0661,  0.8595, -1.4794, -1.4570,  0.9431,  1.2328,  1.3019,  0.1684,\n                        0.6069, -2.0306, -1.1598, -1.7353, -2.6730, -0.0172, -2.2614, -0.2791])),\n              ('layer2.3.bn1.running_var',\n               tensor([1.4267, 1.8325, 1.4107, 1.9022, 1.1454, 1.1848, 1.3149, 1.0464, 1.7127,\n                       1.0526, 1.2976, 1.7287, 1.7314, 0.9528, 0.8428, 1.3253, 2.0942, 1.6539,\n                       0.7259, 1.6431, 2.3580, 0.9168, 1.7689, 1.1914, 2.2335, 0.9422, 1.0244,\n                       1.7745, 1.0409, 1.2564, 1.2816, 1.6409, 0.8065, 1.1558, 1.5585, 1.4250,\n                       1.1390, 1.1162, 1.0241, 1.2053, 1.1114, 1.1136, 1.3815, 2.6729, 1.7002,\n                       1.2851, 0.9971, 1.6553, 1.6096, 1.3246, 2.6355, 1.1190, 1.4100, 1.3607,\n                       1.2038, 1.4603, 1.6676, 1.5174, 1.2595, 1.3537, 1.3571, 1.9165, 1.0596,\n                       1.7502, 1.5004, 2.3574, 1.8788, 1.5436, 1.3598, 3.2403, 1.1281, 1.7151,\n                       1.5007, 1.4294, 1.2751, 1.1377, 1.4837, 0.9963, 1.0371, 1.3635, 1.0782,\n                       1.3455, 1.1412, 1.4128, 1.8462, 1.1571, 1.2749, 1.2635, 1.3390, 1.4149,\n                       1.6320, 1.4662, 1.1545, 1.5425, 1.2833, 1.3740, 0.8687, 1.2486, 0.9233,\n                       1.3790, 1.3202, 1.3006, 1.2236, 2.6959, 1.1059, 1.2885, 1.2924, 2.0987,\n                       1.1884, 1.0231, 1.3753, 3.5153, 1.7106, 1.1955, 1.5477, 2.9272, 1.5410,\n                       1.2062, 1.3594, 1.0012, 1.0405, 2.6230, 2.7874, 2.7878, 1.5386, 1.3447,\n                       1.8957, 1.3693])),\n              ('layer2.3.bn1.num_batches_tracked', tensor(13572)),\n              ('layer2.3.conv2.weight',\n               tensor([[[[ 0.0385,  0.0627,  0.0420],\n                         [ 0.0411, -0.0319,  0.0592],\n                         [ 0.0265,  0.0544,  0.0045]],\n               \n                        [[-0.0070, -0.0109,  0.0529],\n                         [-0.0309, -0.0562, -0.0013],\n                         [-0.0128, -0.0018,  0.0250]],\n               \n                        [[ 0.0013, -0.0298,  0.0048],\n                         [ 0.0213, -0.0070, -0.0145],\n                         [-0.0168, -0.0413, -0.0082]],\n               \n                        ...,\n               \n                        [[ 0.0014, -0.0450, -0.0724],\n                         [ 0.0774,  0.0758, -0.0558],\n                         [-0.0259, -0.0002, -0.0200]],\n               \n                        [[-0.0141, -0.0529, -0.0271],\n                         [-0.0346, -0.0142,  0.0229],\n                         [-0.0273, -0.0230,  0.0101]],\n               \n                        [[ 0.0047,  0.0069,  0.0442],\n                         [-0.0007, -0.0484, -0.0092],\n                         [ 0.0041, -0.0346,  0.0153]]],\n               \n               \n                       [[[-0.0084, -0.0347,  0.0465],\n                         [-0.0314,  0.0097,  0.0090],\n                         [-0.0058, -0.0228, -0.0167]],\n               \n                        [[-0.0333,  0.0325, -0.0141],\n                         [-0.0097, -0.0053,  0.0288],\n                         [ 0.0284,  0.0216,  0.0428]],\n               \n                        [[ 0.0090,  0.0451, -0.0050],\n                         [-0.0122, -0.0253, -0.0384],\n                         [ 0.0484,  0.0277, -0.0139]],\n               \n                        ...,\n               \n                        [[-0.0243, -0.0082,  0.0507],\n                         [-0.0454, -0.0468,  0.0373],\n                         [-0.0543, -0.0018,  0.0172]],\n               \n                        [[-0.0562,  0.0122,  0.0042],\n                         [ 0.0183,  0.0399,  0.0479],\n                         [-0.0288,  0.0262, -0.0408]],\n               \n                        [[-0.0194,  0.0170, -0.0062],\n                         [-0.0370, -0.0368,  0.0046],\n                         [-0.0031,  0.0046,  0.0439]]],\n               \n               \n                       [[[-0.0470, -0.0694, -0.0072],\n                         [-0.0594, -0.0237, -0.0014],\n                         [-0.0541, -0.0931, -0.0680]],\n               \n                        [[-0.0073,  0.0070, -0.0241],\n                         [ 0.0603, -0.0571,  0.0104],\n                         [ 0.0050, -0.0185, -0.0690]],\n               \n                        [[ 0.0548,  0.0231,  0.0441],\n                         [ 0.0398,  0.0122,  0.0647],\n                         [-0.0351, -0.0483, -0.0218]],\n               \n                        ...,\n               \n                        [[-0.0225,  0.0258,  0.0208],\n                         [ 0.0204,  0.0073, -0.0089],\n                         [ 0.0879,  0.0701,  0.0355]],\n               \n                        [[ 0.0012, -0.0106, -0.0005],\n                         [ 0.0084,  0.0226,  0.0561],\n                         [-0.0238,  0.0246,  0.0174]],\n               \n                        [[-0.0462, -0.0169,  0.0240],\n                         [ 0.0215, -0.0390, -0.0061],\n                         [-0.0005,  0.0371,  0.0384]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0151, -0.0288,  0.0183],\n                         [ 0.0048,  0.0924,  0.0354],\n                         [-0.0023,  0.0148, -0.0892]],\n               \n                        [[-0.0638, -0.0168, -0.0237],\n                         [-0.0702, -0.0633, -0.0007],\n                         [-0.0643, -0.0504,  0.0147]],\n               \n                        [[ 0.0391, -0.0645,  0.0214],\n                         [ 0.0386,  0.0969,  0.0372],\n                         [ 0.0613,  0.0935,  0.0069]],\n               \n                        ...,\n               \n                        [[ 0.0288,  0.0189, -0.0037],\n                         [ 0.0590,  0.0618,  0.0261],\n                         [ 0.0385, -0.0086,  0.0063]],\n               \n                        [[ 0.0409, -0.0078,  0.0650],\n                         [ 0.0074, -0.0922,  0.0242],\n                         [ 0.0159, -0.0522,  0.0132]],\n               \n                        [[-0.0148, -0.0214, -0.0034],\n                         [ 0.0095, -0.0087,  0.0422],\n                         [ 0.0330,  0.0532,  0.1136]]],\n               \n               \n                       [[[ 0.0091, -0.0454,  0.0202],\n                         [-0.0499, -0.0397, -0.0719],\n                         [-0.0083,  0.0254, -0.0413]],\n               \n                        [[-0.0259, -0.0130, -0.0529],\n                         [ 0.0014, -0.0375,  0.0186],\n                         [-0.0253, -0.0159,  0.0516]],\n               \n                        [[-0.0007, -0.0373,  0.0157],\n                         [-0.0047, -0.0053,  0.0234],\n                         [-0.0286, -0.0121,  0.0366]],\n               \n                        ...,\n               \n                        [[ 0.0033, -0.0226,  0.0292],\n                         [ 0.0872, -0.0833, -0.0097],\n                         [ 0.1193,  0.0659, -0.0032]],\n               \n                        [[-0.0068,  0.0399, -0.0137],\n                         [-0.0082, -0.0258,  0.0625],\n                         [-0.0025, -0.0277,  0.0057]],\n               \n                        [[ 0.0264,  0.0401,  0.0553],\n                         [-0.0378,  0.0561,  0.0056],\n                         [-0.0304,  0.0666, -0.0051]]],\n               \n               \n                       [[[ 0.0344,  0.0254,  0.0116],\n                         [ 0.0053,  0.0112,  0.0239],\n                         [ 0.0978,  0.0840,  0.0509]],\n               \n                        [[-0.0596, -0.0097, -0.0049],\n                         [-0.0263,  0.0026, -0.0125],\n                         [-0.0099,  0.0129,  0.0139]],\n               \n                        [[-0.0228,  0.0242, -0.0123],\n                         [-0.0305, -0.0184,  0.0032],\n                         [-0.0669, -0.0095, -0.0192]],\n               \n                        ...,\n               \n                        [[-0.0523,  0.0079,  0.0474],\n                         [-0.0170, -0.0220, -0.0179],\n                         [-0.0227, -0.0407, -0.0086]],\n               \n                        [[-0.0041, -0.0016,  0.0250],\n                         [-0.0223, -0.0359,  0.0131],\n                         [ 0.0186,  0.0185, -0.0128]],\n               \n                        [[ 0.0213,  0.0244, -0.0213],\n                         [ 0.0093, -0.0551, -0.0085],\n                         [-0.0318,  0.0150, -0.0215]]]])),\n              ('layer2.3.bn2.weight',\n               tensor([1.0417, 0.9540, 0.9581, 1.0160, 0.9491, 1.0041, 1.0213, 0.9914, 0.9584,\n                       0.9880, 0.9347, 0.9066, 1.0437, 1.0060, 1.0075, 0.9372, 1.0224, 0.9795,\n                       0.9182, 0.9733, 1.0358, 0.9784, 1.0548, 0.9811, 0.8896, 0.9834, 0.9343,\n                       0.9585, 0.9661, 1.0231, 1.0212, 1.0454, 0.9318, 1.0721, 0.9921, 0.9801,\n                       1.0055, 0.9807, 1.0316, 0.9802, 1.0546, 0.9048, 0.9851, 0.9640, 1.0744,\n                       0.9662, 1.0091, 0.9877, 0.9796, 0.9630, 0.9717, 1.0080, 1.0706, 1.0412,\n                       1.0385, 0.9629, 1.1314, 1.0517, 1.0016, 0.9940, 0.9863, 1.0167, 1.0063,\n                       0.9335, 0.9752, 1.0516, 1.0221, 1.0772, 1.0722, 0.9304, 0.9513, 1.0073,\n                       1.0536, 1.0015, 0.9574, 0.9438, 1.0557, 1.0139, 0.9846, 0.9806, 0.9592,\n                       0.9097, 0.9203, 1.1108, 0.9634, 0.9557, 0.9515, 0.9907, 0.9488, 0.9807,\n                       0.9626, 1.0194, 1.0339, 0.9405, 1.0020, 1.1151, 0.9422, 1.0167, 0.9665,\n                       0.9483, 1.0182, 0.9770, 1.1152, 1.0941, 0.9757, 0.9764, 0.9795, 1.0118,\n                       0.9580, 1.0721, 1.0581, 1.0601, 1.0624, 0.9159, 1.0060, 0.9528, 0.9426,\n                       0.9309, 0.9818, 0.9565, 0.9338, 1.0321, 0.9888, 0.9604, 0.9891, 1.1067,\n                       0.9674, 0.9742])),\n              ('layer2.3.bn2.bias',\n               tensor([-0.0323, -0.0167,  0.0115, -0.0010, -0.0986,  0.0276, -0.1263,  0.0717,\n                        0.0462, -0.0180,  0.0278, -0.1326,  0.0341, -0.1003,  0.0060,  0.0098,\n                        0.0440, -0.0983, -0.0479, -0.0645, -0.0872, -0.0275, -0.0340, -0.0210,\n                       -0.0612, -0.1278, -0.1708, -0.0196,  0.0210, -0.0637, -0.0670, -0.0060,\n                        0.0352, -0.0867,  0.0380, -0.1174, -0.0292, -0.1204, -0.0654, -0.0287,\n                        0.0218, -0.0942, -0.0738, -0.1293,  0.0704,  0.0039, -0.0390,  0.0527,\n                        0.0349, -0.0539, -0.0474, -0.0228, -0.0121,  0.0206, -0.1344,  0.0084,\n                       -0.1152, -0.0921,  0.0652,  0.0674, -0.0838,  0.0130, -0.0930,  0.0265,\n                       -0.0302,  0.0153,  0.0058, -0.0050, -0.0340, -0.1754, -0.0421,  0.0687,\n                       -0.0123, -0.0282, -0.0760, -0.0162,  0.0126, -0.0453, -0.0144, -0.0939,\n                       -0.1345,  0.0141,  0.0185, -0.0448, -0.0799,  0.0173, -0.1501,  0.0169,\n                        0.0033,  0.0684, -0.0995, -0.0514, -0.0764, -0.0499, -0.1220, -0.0281,\n                        0.0409, -0.0074, -0.0406,  0.0068,  0.0182, -0.2224, -0.0675, -0.0903,\n                       -0.0416,  0.0489, -0.0542, -0.0832, -0.0756, -0.0453,  0.0378,  0.0356,\n                        0.0604, -0.0121, -0.0075, -0.3907, -0.0389,  0.0656, -0.0624, -0.0098,\n                       -0.0506, -0.0365, -0.0730, -0.0165, -0.0839, -0.1490, -0.0853,  0.0305])),\n              ('layer2.3.bn2.running_mean',\n               tensor([-0.8364, -0.3476, -0.5912, -0.5814,  1.0322,  0.4831, -1.6434,  0.4757,\n                       -0.3961,  0.0979,  0.0087, -0.8687, -1.3918, -1.0205,  0.1028,  0.3637,\n                        0.1334, -0.3185,  0.3677, -1.3945, -0.4934, -0.9608,  0.2932, -0.5909,\n                       -0.5946,  0.2472, -0.4375, -0.2362, -0.1472, -1.3878,  0.6851, -0.2488,\n                        0.5890, -0.4566, -0.5151,  0.1178, -0.3370, -0.3224, -0.1091, -0.0517,\n                       -0.9459, -0.4924, -1.0288, -0.0979, -1.3618, -0.5916, -1.8327,  0.0618,\n                       -0.3198, -1.3591,  0.4882, -1.1856, -0.1264, -1.1955, -1.8346, -0.0584,\n                       -0.8433,  0.3606,  0.0535,  0.7795,  0.0065,  0.7335, -0.6649, -0.6171,\n                       -0.9025,  0.0905, -0.3788,  0.6360, -0.4665, -0.3635, -1.5364,  0.0542,\n                       -1.2494, -1.1402, -1.2096,  0.0399, -1.0646, -1.2477,  0.9411, -1.6802,\n                       -0.8972,  0.6590,  0.3225, -2.1621, -0.4871, -0.7052, -0.3183, -1.7098,\n                       -0.5942,  1.0037, -0.1672, -1.1345, -0.0975,  0.1762, -0.3108, -0.6516,\n                       -1.5141, -1.4720,  0.0319, -0.0882, -1.0704,  0.3363, -3.0098, -0.8776,\n                        0.0478,  0.6130, -0.7408, -0.1852,  0.1192, -0.8214, -0.4674, -0.6127,\n                       -0.3543, -0.2828, -0.8098, -0.2718,  0.3116,  0.1581, -0.6121,  0.6161,\n                       -0.1602, -0.6212,  0.8514,  0.6680, -0.1014, -1.0930, -0.0084, -0.8344])),\n              ('layer2.3.bn2.running_var',\n               tensor([0.8976, 0.6626, 0.7639, 0.8091, 0.6068, 0.6551, 1.4972, 0.6553, 0.6689,\n                       0.8974, 0.7053, 0.8423, 1.0606, 0.9982, 1.3145, 0.7293, 0.7999, 0.5716,\n                       0.5872, 1.0626, 0.7831, 0.6292, 1.2030, 0.7265, 0.5951, 0.8442, 0.6591,\n                       0.6166, 0.7064, 0.9957, 1.0995, 0.7560, 0.7309, 0.9137, 0.9569, 0.9777,\n                       0.6499, 0.7827, 1.0560, 0.7207, 0.9268, 0.4993, 0.7889, 0.5703, 1.1329,\n                       0.5260, 1.1436, 0.5978, 0.7976, 0.9864, 0.7956, 0.6721, 0.9003, 0.9895,\n                       1.1360, 0.6238, 0.8958, 1.1848, 0.6483, 1.2078, 0.9644, 0.7741, 0.8902,\n                       0.6185, 0.9331, 0.8158, 1.5566, 1.0180, 0.8260, 0.8655, 1.0206, 0.5604,\n                       0.7229, 0.9177, 0.8790, 0.6014, 0.6314, 0.9043, 0.8288, 0.7815, 1.2031,\n                       0.8730, 1.0061, 1.3693, 0.7353, 0.5654, 0.6841, 0.7299, 0.6374, 0.6760,\n                       0.7392, 0.6686, 0.8764, 0.8233, 1.1486, 1.1295, 0.6952, 1.1780, 0.8788,\n                       0.6201, 0.7204, 0.8808, 1.6880, 0.9442, 0.7877, 0.5124, 0.8183, 0.8245,\n                       1.0156, 0.9935, 1.0592, 0.8639, 0.9681, 0.7635, 0.7458, 0.8274, 0.6427,\n                       0.6943, 0.7080, 0.6488, 0.5661, 0.9537, 1.4364, 0.7732, 0.8359, 1.2753,\n                       0.6751, 0.8957])),\n              ('layer2.3.bn2.num_batches_tracked', tensor(13572)),\n              ('layer2.3.conv3.weight',\n               tensor([[[[ 0.0174]],\n               \n                        [[-0.0213]],\n               \n                        [[ 0.0132]],\n               \n                        ...,\n               \n                        [[-0.0702]],\n               \n                        [[ 0.0365]],\n               \n                        [[-0.0314]]],\n               \n               \n                       [[[ 0.0247]],\n               \n                        [[-0.0365]],\n               \n                        [[ 0.0148]],\n               \n                        ...,\n               \n                        [[-0.0324]],\n               \n                        [[-0.0313]],\n               \n                        [[ 0.0124]]],\n               \n               \n                       [[[ 0.0013]],\n               \n                        [[ 0.0007]],\n               \n                        [[ 0.0267]],\n               \n                        ...,\n               \n                        [[ 0.0370]],\n               \n                        [[-0.0369]],\n               \n                        [[-0.0134]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0481]],\n               \n                        [[-0.0714]],\n               \n                        [[ 0.0420]],\n               \n                        ...,\n               \n                        [[-0.0455]],\n               \n                        [[ 0.0043]],\n               \n                        [[-0.0979]]],\n               \n               \n                       [[[-0.0111]],\n               \n                        [[ 0.0255]],\n               \n                        [[ 0.0036]],\n               \n                        ...,\n               \n                        [[ 0.0125]],\n               \n                        [[ 0.0456]],\n               \n                        [[ 0.0361]]],\n               \n               \n                       [[[ 0.0544]],\n               \n                        [[-0.0405]],\n               \n                        [[ 0.0158]],\n               \n                        ...,\n               \n                        [[ 0.0353]],\n               \n                        [[-0.0386]],\n               \n                        [[ 0.0400]]]])),\n              ('layer2.3.bn3.weight',\n               tensor([ 0.2748,  0.0061, -0.0474, -0.2224,  0.1018, -0.0847, -0.1515, -0.0329,\n                       -0.3662,  0.2381,  0.2207, -0.1059,  0.1483,  0.1693, -0.2934,  0.1844,\n                       -0.3564, -0.2900,  0.3251,  0.1605,  0.3172, -0.2622, -0.0599,  0.1966,\n                       -0.4041,  0.0181, -0.2177, -0.2041, -0.2915, -0.1248, -0.1924, -0.1808,\n                       -0.2883, -0.3609,  0.1843, -0.1366,  0.2208,  0.0856,  0.0177,  0.1991,\n                       -0.2145,  0.3093,  0.2641,  0.1023,  0.1349,  0.2925,  0.3239, -0.1203,\n                       -0.1702,  0.4175, -0.2347, -0.2055, -0.1082,  0.0325,  0.1869, -0.2942,\n                        0.2032, -0.1169,  0.0803,  0.2177, -0.3246,  0.0698,  0.2614,  0.1827,\n                        0.1370, -0.3092, -0.0621, -0.1929,  0.1521,  0.2124,  0.2137,  0.1213,\n                       -0.2462, -0.1492,  0.2066, -0.1303,  0.2849,  0.1238, -0.2464, -0.1079,\n                       -0.3303,  0.0848,  0.2639, -0.2195,  0.0289,  0.0279, -0.0435, -0.0560,\n                        0.3540, -0.2042, -0.0339,  0.1339, -0.3020, -0.2230,  0.1021, -0.1185,\n                       -0.1676,  0.0701,  0.2035,  0.0241,  0.3027, -0.0333,  0.0862,  0.1176,\n                        0.1919, -0.0421, -0.0053,  0.2691, -0.2053,  0.1708,  0.2076,  0.1808,\n                       -0.3154, -0.2139, -0.3457,  0.2095, -0.0705,  0.1822, -0.1175,  0.1571,\n                       -0.0216, -0.3478,  0.1429,  0.2081, -0.0995, -0.3215, -0.2303,  0.0115,\n                        0.2238, -0.2450, -0.2356,  0.3496,  0.2658, -0.2677,  0.1079, -0.1416,\n                       -0.1079, -0.2335, -0.4486, -0.2258, -0.0818,  0.3770,  0.0369, -0.2911,\n                       -0.2534,  0.1779, -0.1242, -0.0676,  0.2005,  0.3132, -0.1828,  0.0212,\n                        0.3130,  0.1687, -0.0426,  0.2300, -0.1441,  0.0517,  0.0483, -0.1850,\n                        0.3128, -0.2173,  0.1282, -0.2552,  0.2532, -0.1255, -0.2719,  0.1037,\n                        0.1300, -0.3763, -0.2755,  0.1087, -0.2680,  0.2822,  0.2681,  0.2212,\n                       -0.1129,  0.3310,  0.2411,  0.1706,  0.0816,  0.0532, -0.2429,  0.2076,\n                        0.2409,  0.1254,  0.1023, -0.0504,  0.1641,  0.3064,  0.1650,  0.1376,\n                        0.1181,  0.1210, -0.1229,  0.1772,  0.3187,  0.3270,  0.0726, -0.3345,\n                        0.0729, -0.1891, -0.3324,  0.2588, -0.0331, -0.2743, -0.0656,  0.0517,\n                        0.0983,  0.2148,  0.2315, -0.2830, -0.2827, -0.1397,  0.2438, -0.0392,\n                       -0.1671, -0.2483, -0.3214, -0.1632,  0.0790,  0.0483, -0.0102,  0.2900,\n                        0.2483, -0.2869, -0.0154, -0.0707, -0.2654, -0.1725, -0.1599, -0.1139,\n                       -0.2782, -0.3186, -0.1491,  0.0784, -0.4792,  0.2029,  0.2906,  0.2946,\n                        0.2310,  0.0267, -0.1247,  0.1605, -0.0988, -0.2327,  0.0840,  0.2119,\n                        0.2349,  0.3675,  0.2669, -0.1605, -0.2372,  0.3540, -0.2237, -0.0138,\n                        0.1594, -0.1855,  0.1512,  0.2649, -0.2196,  0.2384,  0.1859,  0.1592,\n                       -0.2668, -0.1401,  0.1776, -0.2780, -0.0900, -0.0648,  0.0360, -0.2999,\n                       -0.2624,  0.1340, -0.1120, -0.1920,  0.1965, -0.4108,  0.2687, -0.1872,\n                       -0.2130, -0.2726,  0.1711, -0.4064,  0.2174, -0.0831,  0.2402,  0.2992,\n                        0.1578, -0.1976,  0.3128,  0.2451, -0.2631,  0.2867,  0.0184,  0.1633,\n                       -0.1449,  0.2612, -0.2060, -0.1907,  0.1464,  0.2846, -0.2944,  0.1662,\n                        0.0089, -0.1776, -0.2633,  0.1290,  0.2604, -0.1604, -0.2587,  0.1023,\n                       -0.0502, -0.0833, -0.0564,  0.1457,  0.3364, -0.2179,  0.1899,  0.2272,\n                       -0.2788, -0.2675,  0.0971, -0.1996, -0.0274, -0.1429,  0.0860,  0.1329,\n                       -0.2717, -0.0933,  0.1928,  0.4118, -0.2937, -0.2030, -0.2743, -0.3029,\n                       -0.2035,  0.1049, -0.1585,  0.2255,  0.1955, -0.0360,  0.3064, -0.1912,\n                       -0.2171,  0.2550,  0.1175, -0.0389,  0.2039,  0.2502,  0.0389,  0.1320,\n                        0.2468,  0.3378, -0.2184, -0.3635,  0.1575, -0.2477, -0.2051,  0.0441,\n                       -0.2527,  0.3063, -0.3557,  0.2639,  0.0702, -0.1291, -0.1787,  0.2160,\n                       -0.3256,  0.2697, -0.0474,  0.2204, -0.3315,  0.1621, -0.1576,  0.1451,\n                       -0.1607,  0.3146,  0.2417,  0.2061,  0.1842,  0.0178, -0.0590,  0.0127,\n                       -0.1608,  0.2136,  0.1117,  0.2290,  0.0525,  0.2415,  0.2339,  0.2120,\n                        0.0520, -0.1926, -0.1301,  0.3283,  0.0733, -0.1303,  0.2918, -0.2888,\n                       -0.0828, -0.2588, -0.1729, -0.2281,  0.2235,  0.2997, -0.1231, -0.2745,\n                        0.1126, -0.2857, -0.1128,  0.2278, -0.2667, -0.0683, -0.0141,  0.0964,\n                        0.1528, -0.1313, -0.0654, -0.2282, -0.1226, -0.0757, -0.1675, -0.2566,\n                        0.2684,  0.2142, -0.3350,  0.2883,  0.0142,  0.0938, -0.1806, -0.0328,\n                       -0.2719,  0.1192, -0.1987, -0.3349, -0.2492, -0.0971, -0.0719, -0.3097,\n                       -0.1329,  0.2199, -0.3006,  0.0157, -0.2704, -0.1991,  0.1974, -0.1003,\n                       -0.1707, -0.1830, -0.2403, -0.2650, -0.2573,  0.2838, -0.1407, -0.1429,\n                       -0.3058, -0.0879, -0.0936, -0.2153,  0.2319,  0.0613, -0.2335, -0.2737,\n                       -0.3481, -0.3354, -0.2383,  0.1714,  0.1012,  0.0888,  0.0243,  0.2477,\n                       -0.1256, -0.1462, -0.3254, -0.1548, -0.3178, -0.2640,  0.4316, -0.1281,\n                        0.2194,  0.1002, -0.0266,  0.2566,  0.2590, -0.1647,  0.0175, -0.0911,\n                        0.2700,  0.2793, -0.3179,  0.0668,  0.0026,  0.0374,  0.1995,  0.2730,\n                        0.1728, -0.2316,  0.3884, -0.0778,  0.1146, -0.1435,  0.2717, -0.1624,\n                       -0.2634,  0.1729,  0.1202,  0.2169,  0.2188, -0.2844, -0.3158, -0.0301])),\n              ('layer2.3.bn3.bias',\n               tensor([ 4.9749e-02, -3.2398e-02,  3.7366e-02, -1.0278e-01,  1.7873e-02,\n                       -9.2692e-02, -6.3279e-02, -8.1378e-03,  7.2318e-02,  4.3267e-02,\n                        1.1357e-01, -1.5841e-01,  1.0175e-01,  1.2822e-01,  4.0051e-02,\n                        3.9933e-02,  1.9581e-02,  6.9072e-02, -2.4634e-02, -6.8100e-02,\n                       -9.4918e-02,  2.0222e-02,  5.2815e-02,  1.4024e-02,  9.1055e-02,\n                        3.4059e-03,  7.1635e-02,  1.3373e-01,  7.1860e-02, -8.7664e-02,\n                       -7.2654e-02,  4.2418e-02,  3.8029e-02, -1.0647e-01,  7.2418e-02,\n                        7.1252e-02,  7.9180e-02, -1.7265e-02,  2.5941e-02, -2.3889e-02,\n                        8.5871e-02, -9.1810e-03,  1.5844e-01,  6.5122e-02,  6.9588e-02,\n                       -9.8764e-02,  1.1929e-01,  2.8565e-02, -8.4968e-02,  8.4783e-03,\n                        6.5894e-02,  1.0878e-01, -7.2977e-02, -5.9931e-02, -1.5605e-02,\n                        8.4584e-03,  6.4193e-02,  6.7139e-02,  2.0206e-02, -4.4584e-02,\n                        1.0340e-02,  4.1944e-02,  2.0654e-02,  3.6176e-02,  4.3084e-02,\n                       -1.4609e-02, -3.4152e-02,  4.9409e-03,  1.4311e-01,  2.8548e-02,\n                        1.3712e-03,  3.8675e-03,  5.4965e-02,  8.7425e-02,  1.0031e-01,\n                       -1.4517e-01,  8.8744e-02,  4.3048e-02,  3.6848e-02,  4.1747e-02,\n                       -1.0282e-02, -2.8174e-02,  7.0129e-02,  3.5410e-02, -5.7805e-02,\n                        2.4608e-02,  3.6158e-02, -2.0892e-03,  3.2176e-03,  1.4694e-01,\n                        1.6950e-02,  7.4464e-03,  4.8062e-02,  1.4570e-01,  2.9550e-02,\n                        3.5511e-02,  4.6867e-02, -8.0296e-02,  1.8991e-02,  2.3184e-02,\n                       -1.5286e-02, -8.8332e-02, -8.0216e-02,  3.2491e-02,  3.2813e-02,\n                        4.5840e-02, -1.7778e-01, -7.3112e-03, -2.5503e-02,  1.9621e-02,\n                       -1.6419e-02, -5.7226e-02,  8.7806e-02,  9.7624e-02, -1.3609e-01,\n                        8.4792e-02,  5.1029e-02, -2.3292e-02, -4.6042e-02,  4.6850e-02,\n                       -1.2922e-01,  5.3508e-02,  1.1508e-01, -1.3176e-02,  8.7911e-02,\n                        7.7675e-03,  1.4965e-01, -1.4158e-02, -1.5748e-02,  2.5663e-02,\n                        7.5003e-02, -7.2748e-02,  2.0282e-02,  1.5684e-01,  6.2664e-02,\n                        6.1654e-02, -1.1442e-01,  6.5055e-02,  9.2464e-02,  1.6569e-01,\n                        3.6382e-02,  1.5601e-01, -8.0819e-02,  7.2325e-02, -2.8284e-02,\n                        5.8192e-02, -4.0854e-02,  3.5399e-02,  1.2207e-01,  4.8990e-02,\n                        6.3548e-02,  3.7867e-02,  1.1267e-01,  6.8999e-03,  2.6748e-02,\n                        1.1394e-01,  1.8197e-02,  3.9505e-02,  3.4433e-02,  8.3716e-02,\n                       -1.5543e-02,  7.9508e-03,  5.2206e-02,  1.9859e-02, -1.2512e-02,\n                        9.6723e-02,  1.5999e-02,  9.4707e-02,  1.0753e-01,  1.1018e-01,\n                        1.6794e-04, -5.4656e-03,  2.0931e-01,  1.5874e-01, -9.3927e-02,\n                        2.9324e-02,  2.7871e-02,  8.5509e-02,  1.1627e-01,  5.4366e-03,\n                        1.4090e-02, -4.4780e-02,  6.8531e-03, -2.1013e-01,  1.0967e-01,\n                        1.2099e-01,  6.2812e-02, -7.5816e-02, -7.3736e-04,  2.1572e-02,\n                        7.2506e-02,  7.5093e-02,  3.5952e-02,  8.4766e-02,  9.5761e-02,\n                        7.2330e-02, -4.7112e-02,  9.3648e-02,  3.7022e-02,  2.5441e-02,\n                        4.5285e-02,  4.4881e-02,  7.8844e-02,  4.0634e-03, -3.1049e-02,\n                       -4.5508e-02, -1.4692e-02,  2.0318e-02,  3.9226e-02,  8.8644e-02,\n                        7.8602e-04,  4.6551e-03, -4.5072e-02,  6.6176e-02,  2.6823e-03,\n                        4.0482e-02,  6.1291e-02,  1.8458e-02,  7.7251e-02,  2.9726e-02,\n                       -1.1858e-01,  1.4927e-02,  8.5462e-03, -4.4753e-02, -9.6644e-02,\n                        2.5008e-02,  2.6441e-02, -5.4312e-02,  8.7453e-02,  5.5934e-02,\n                       -2.6574e-02, -1.2512e-01, -7.4281e-03,  3.6515e-02, -6.3475e-02,\n                       -5.1682e-02, -9.5609e-02,  4.7263e-02,  5.4186e-02, -1.2650e-01,\n                       -7.3948e-02, -1.4407e-02, -2.4588e-02,  3.1054e-02, -2.6748e-04,\n                        1.4257e-01, -4.9716e-02, -4.5262e-02, -9.3286e-02,  1.3794e-01,\n                        1.4747e-01,  4.7353e-05,  1.4090e-01,  1.9138e-02,  3.5112e-02,\n                        1.7551e-02,  3.3789e-02, -8.4166e-02,  1.0919e-01,  9.7611e-02,\n                        5.2134e-02,  1.5132e-01,  9.5652e-03,  1.2898e-01,  4.0440e-02,\n                        1.1119e-02, -8.9954e-02,  1.0253e-01,  6.9708e-02, -6.0523e-02,\n                       -9.7119e-02, -7.1971e-02, -1.3193e-02,  3.2120e-02,  3.7883e-02,\n                        1.6073e-01,  6.5608e-02,  1.7691e-01, -3.2982e-02,  5.2921e-02,\n                       -1.1155e-02,  1.3251e-01,  1.1405e-01, -5.5283e-02,  8.4558e-02,\n                       -6.2164e-02,  2.0041e-02, -1.9982e-02,  8.8420e-02,  1.0920e-01,\n                        7.1539e-02,  1.2274e-02,  1.6563e-01,  3.7827e-02,  2.2989e-02,\n                       -5.4875e-02, -9.8160e-03,  2.9807e-02,  5.5520e-02,  7.5507e-02,\n                       -6.4028e-02,  5.3376e-02,  9.7378e-02,  6.9733e-02,  2.0661e-02,\n                        3.9181e-02,  5.2233e-02,  1.4063e-02,  1.0781e-01,  5.8093e-02,\n                        1.0076e-01, -1.2715e-01,  1.9893e-02,  7.1039e-02, -2.3415e-03,\n                        1.2511e-01, -6.9354e-02,  7.5386e-02,  9.0603e-02, -9.4942e-03,\n                        9.4920e-02,  5.6707e-02, -7.8829e-02,  1.1165e-02, -3.5513e-02,\n                        2.1238e-02,  3.2838e-02,  8.2766e-02,  9.0887e-02,  6.4171e-02,\n                        7.3056e-02,  5.1034e-02,  1.1001e-01,  1.4005e-01,  1.3777e-01,\n                        1.4804e-02,  6.8072e-04, -3.5365e-02, -9.5584e-02,  1.6101e-01,\n                        1.1810e-01,  4.5765e-02, -4.4880e-02,  6.3838e-02,  1.1833e-02,\n                        8.8543e-02,  1.3953e-02,  4.6367e-02,  1.1618e-01,  4.7846e-02,\n                       -8.7393e-02,  8.8010e-02,  2.4159e-02,  2.2686e-01,  7.6581e-02,\n                       -4.4915e-02,  5.6971e-04, -4.5763e-02, -7.7600e-02, -1.4835e-01,\n                        1.4904e-01, -1.3517e-02,  2.9531e-02,  6.2784e-02, -3.5152e-02,\n                        3.7241e-03,  1.0182e-01,  3.8634e-03,  5.7665e-02, -8.4230e-02,\n                        2.8268e-02,  3.0856e-02,  3.7271e-02, -5.9760e-02, -6.1586e-02,\n                        1.2078e-01,  9.2253e-02,  6.4473e-02,  6.2533e-02,  1.3369e-01,\n                        1.1182e-01, -6.1606e-02, -5.1127e-02, -2.6157e-03,  1.9461e-02,\n                        7.5724e-02,  8.3959e-02,  1.7334e-03, -1.2055e-01, -4.7920e-03,\n                        9.8750e-02,  1.1405e-01,  1.2614e-02, -1.4207e-01,  5.3356e-02,\n                        3.1296e-02,  5.4809e-02,  9.0677e-02, -7.2806e-02, -4.7224e-02,\n                        5.0339e-02, -4.5228e-02, -3.5176e-02,  5.3511e-02, -4.5041e-02,\n                        8.4799e-03,  9.6619e-03, -8.3995e-02,  2.5788e-02, -1.6543e-01,\n                        2.2832e-02,  3.7199e-02,  2.3751e-02, -2.2821e-02,  2.7402e-02,\n                       -4.8208e-03,  1.2087e-01, -6.5969e-02, -7.2244e-02,  7.5092e-02,\n                        8.5754e-02,  1.4152e-02, -6.2681e-02, -6.5344e-02, -1.7582e-03,\n                       -6.3747e-03, -6.5889e-02,  8.0880e-02, -1.6036e-02,  3.8996e-02,\n                       -4.5667e-02, -5.9898e-02,  1.0576e-01,  8.1146e-02, -2.5098e-02,\n                        8.3629e-02,  1.2833e-01, -8.2042e-02,  4.5833e-02,  2.5942e-02,\n                       -4.1740e-02,  3.2361e-02, -1.5301e-01,  4.2923e-02,  8.0507e-03,\n                        9.6862e-02,  9.3510e-02, -5.3759e-02,  7.1393e-02,  8.2208e-03,\n                        6.8770e-02,  8.6194e-02,  1.2961e-01,  4.9786e-02, -4.9592e-02,\n                       -9.7398e-02, -1.0092e-01,  7.9062e-03, -1.4078e-01,  3.7422e-02,\n                       -6.2862e-02,  8.5094e-03,  3.3855e-02, -3.1987e-02,  4.2503e-02,\n                        7.0202e-02, -7.5163e-03,  5.6823e-02, -2.1892e-02, -1.6014e-01,\n                       -1.7498e-02,  4.6772e-02, -2.4475e-02,  6.5092e-02, -3.3493e-02,\n                        4.6304e-02,  8.0590e-02,  8.6019e-03,  3.7736e-02,  6.6531e-02,\n                        1.6124e-01, -1.2310e-01, -1.1773e-02,  9.2189e-02,  5.8917e-02,\n                       -5.7058e-02,  3.2494e-02, -7.5800e-02,  7.3465e-03,  6.5168e-02,\n                        3.2510e-02,  3.6267e-02,  1.9754e-02,  5.0104e-02, -2.6800e-03,\n                        9.3519e-02, -3.7480e-02, -1.0930e-01,  2.9878e-02, -8.0523e-02,\n                        3.8621e-02, -1.3031e-01, -6.8954e-02, -4.7424e-02,  3.0237e-02,\n                        1.0708e-02, -1.0672e-01, -1.8543e-01,  1.3417e-01,  8.8677e-02,\n                       -9.1218e-02,  2.3881e-02])),\n              ('layer2.3.bn3.running_mean',\n               tensor([ 1.2655e-01, -6.9454e-02,  1.6392e-01, -6.1803e-02,  1.2101e-01,\n                        5.1551e-02, -3.7416e-01, -1.3553e-01, -6.0345e-02, -1.0465e-01,\n                       -2.3874e-01, -2.6441e-01,  8.6829e-02, -3.0140e-01,  2.1936e-02,\n                       -2.0339e-01, -7.0412e-02,  1.3066e-01,  6.6991e-01,  9.7499e-02,\n                       -2.3666e-01,  5.3037e-02,  3.6067e-01,  1.7294e-01,  1.0369e-02,\n                        1.2981e-01,  3.8930e-01,  2.9048e-01, -3.2917e-01, -1.3240e-01,\n                        1.3157e-01,  5.5732e-02,  2.0869e-01,  8.8150e-02,  2.0367e-02,\n                        2.5645e-02, -2.0024e-01, -1.2373e-01, -4.8450e-02,  5.7868e-01,\n                        3.1264e-01,  1.2567e-03, -1.4430e-01, -3.5109e-02, -7.4240e-02,\n                        2.7524e-01, -1.1374e-01,  3.5616e-02, -4.3113e-02, -2.7553e-01,\n                       -2.8962e-02,  2.5120e-02,  1.4861e-01,  1.2227e-01, -1.8446e-01,\n                        9.2312e-02,  2.5844e-01,  5.0233e-04,  1.8051e-01, -1.0621e-01,\n                       -2.7605e-01,  1.5599e-01, -1.8013e-01,  1.6023e-02, -1.6881e-01,\n                        4.7375e-02,  1.2009e-01, -5.4049e-02, -3.9684e-01,  3.5284e-01,\n                       -3.3553e-01,  6.7730e-02,  2.9027e-01,  2.0994e-01,  7.5849e-02,\n                        2.4658e-01, -1.3794e-01, -1.7246e-01,  2.9143e-01, -1.7025e-01,\n                        4.3361e-01,  1.5302e-01, -2.2104e-01,  2.4324e-01, -2.1996e-01,\n                       -8.2210e-02,  6.6899e-02, -1.7843e-01, -8.9199e-02,  2.1460e-01,\n                       -2.3068e-01, -3.8059e-01,  1.3329e-01,  5.2421e-02,  4.1749e-02,\n                       -8.3397e-02,  1.0399e-01,  1.1398e-02,  1.7839e-01,  1.8913e-01,\n                        1.8047e-01,  1.8605e-01,  1.1721e-02, -9.6537e-02,  1.9743e-01,\n                       -3.0128e-01, -1.1805e-01,  3.2856e-01, -1.0378e-01, -4.2099e-01,\n                       -6.4488e-02,  1.1432e-01, -1.1275e-01, -4.9379e-02, -4.0691e-01,\n                       -4.2241e-01,  1.2842e-01, -3.5326e-01, -1.1425e-01,  6.3965e-02,\n                       -2.6330e-01, -7.3724e-02,  2.2371e-01,  1.4416e-01,  2.1383e-01,\n                       -1.4182e-02,  4.5210e-02,  1.2014e-01, -4.6733e-02,  1.2418e-01,\n                       -6.3600e-01,  1.0660e-01, -8.9445e-02,  2.1022e-01, -8.0996e-02,\n                        3.9959e-01, -2.6988e-01,  1.1392e-01, -1.8697e-02,  2.2820e-01,\n                       -2.0366e-01,  5.0441e-01, -9.9443e-02,  2.4910e-01, -2.4667e-01,\n                        6.8790e-02,  9.0718e-02,  3.2774e-02,  3.7973e-02,  3.0106e-01,\n                       -1.7366e-01, -4.0579e-02, -3.6725e-02, -1.7482e-01, -1.7172e-01,\n                       -7.3078e-02,  1.5480e-01, -6.2620e-02, -4.8150e-02,  9.9032e-02,\n                       -1.2738e-01, -2.3814e-01, -1.8194e-01,  3.4997e-01,  3.5705e-02,\n                        1.6466e-01, -8.8200e-02,  3.7997e-02, -6.9484e-03,  3.6362e-01,\n                       -1.5001e-01, -2.9210e-01,  4.1878e-02,  4.1963e-01,  1.5011e-01,\n                       -1.0361e-01, -4.8859e-02, -7.5157e-02, -2.1740e-01, -2.8969e-01,\n                       -1.7805e-01,  3.7128e-01,  1.7888e-01, -4.6737e-01,  2.7001e-02,\n                       -2.0957e-01, -5.1300e-01, -2.3100e-02,  2.4822e-01, -8.3062e-02,\n                       -1.1241e-01,  1.6589e-01,  1.3915e-01, -2.3681e-01,  3.6037e-01,\n                       -1.4186e-01, -1.7651e-01, -7.1506e-02,  9.3541e-02, -3.6316e-01,\n                        3.0055e-01,  4.1932e-01,  5.1732e-02,  2.1757e-01, -9.7395e-02,\n                       -2.3963e-01,  1.3549e-01,  9.6981e-02, -1.7537e-01,  1.4651e-01,\n                        3.0540e-01,  6.9431e-02, -4.5534e-01, -6.2186e-02,  2.1081e-01,\n                        3.5757e-02, -3.8335e-02, -7.3730e-03,  1.8986e-01,  1.5314e-01,\n                       -9.8502e-02,  2.5372e-01,  3.1946e-02, -1.6542e-01,  2.3274e-01,\n                       -3.0905e-01, -1.6049e-01,  1.9110e-01,  3.3939e-01, -2.2531e-01,\n                       -5.0540e-01,  4.2964e-02, -1.3393e-01,  3.4678e-01,  1.9964e-01,\n                        2.2256e-01,  3.0589e-01, -2.0856e-01,  8.5523e-02,  3.0977e-01,\n                        1.7729e-01,  7.3426e-02,  9.9080e-03, -3.5226e-01, -1.3282e-01,\n                       -3.5713e-01, -1.0074e-01,  5.9501e-02, -4.5144e-02,  6.4016e-02,\n                        2.6117e-01, -2.8260e-01,  1.1053e-01, -3.7483e-03, -2.1695e-02,\n                       -1.6168e-01, -3.3295e-01, -2.7294e-01, -2.3988e-01, -1.6982e-01,\n                       -2.8252e-01, -1.9508e-01,  2.9764e-02, -3.0577e-01,  9.9102e-02,\n                        1.0143e-01,  9.2954e-02, -3.3611e-02,  1.0616e-01,  1.4696e-01,\n                       -3.6368e-01, -7.7140e-02, -2.4529e-01,  1.2231e-02, -2.3848e-01,\n                        7.3169e-02, -1.5072e-01,  2.7452e-01, -5.3401e-02,  1.0114e-01,\n                        6.0089e-01, -3.2449e-02,  9.0246e-02,  1.2397e-02,  1.0042e-01,\n                        4.1468e-01, -1.1325e-01, -1.7801e-01,  2.6199e-01,  5.6593e-01,\n                        8.6561e-02,  1.1468e-01, -7.7429e-02, -1.7284e-01,  1.4743e-01,\n                        5.6060e-02,  2.6218e-01,  1.3544e-01,  3.0745e-02,  3.9611e-02,\n                        3.1977e-01,  2.7176e-01,  2.6874e-01,  1.4771e-01,  4.3784e-02,\n                        7.1232e-02,  3.1141e-02, -1.5922e-01, -1.4877e-01,  1.6116e-01,\n                        1.9076e-01, -1.5348e-01,  2.2609e-01, -1.1826e-02, -1.7168e-01,\n                        4.3280e-02,  2.9185e-01, -4.2835e-02,  2.4033e-02, -3.0981e-01,\n                       -4.7769e-01, -5.4589e-01,  2.0516e-03, -5.1211e-02,  9.3044e-02,\n                       -5.2182e-02, -5.2566e-02, -7.0474e-02, -5.4078e-02, -9.3174e-02,\n                        2.1092e-01, -3.3483e-01, -7.6383e-02,  2.8799e-01,  5.4265e-02,\n                       -5.0959e-02,  2.0063e-01, -3.2943e-01, -3.7032e-02, -5.4416e-02,\n                        3.2287e-02,  2.6753e-01,  1.7597e-01, -2.2409e-01,  8.0264e-02,\n                       -1.9402e-01,  2.7255e-01,  7.8582e-02, -5.1020e-01,  1.9028e-01,\n                        1.2263e-01, -2.4595e-01,  9.2722e-02, -2.9533e-01,  2.7004e-01,\n                       -3.3090e-01, -5.2925e-03, -5.6603e-01,  2.0528e-01, -3.9612e-01,\n                       -1.4700e-01, -2.1517e-01,  1.9447e-02,  9.2852e-06, -1.0365e-01,\n                        7.9284e-02,  6.3577e-02, -1.8580e-02,  1.1789e-01,  1.1842e-01,\n                        6.2761e-03,  4.2791e-01, -2.0486e-01,  2.4727e-01,  3.5659e-01,\n                       -2.0798e-01,  1.2468e-01,  4.8239e-01, -1.3247e-03, -3.2227e-01,\n                       -3.3518e-01,  6.5548e-02,  1.7062e-01,  3.0350e-01,  2.0367e-01,\n                       -8.9338e-02, -1.5783e-01, -4.8544e-03, -8.1216e-02,  8.9503e-02,\n                       -1.2614e-02,  4.3390e-01,  6.0023e-02,  2.1972e-01, -1.9925e-01,\n                       -1.0654e-02, -1.4278e-02,  3.8239e-01, -7.2035e-02,  1.1904e-01,\n                       -3.5254e-01, -2.2925e-01, -1.3448e-01, -3.2993e-01,  2.2972e-01,\n                       -1.0610e-01, -4.7151e-02, -2.8892e-01,  7.0462e-01,  1.8475e-02,\n                        1.7431e-03,  3.9097e-01, -1.1872e-01, -8.0856e-02,  6.6268e-02,\n                        4.7320e-01, -2.4654e-03, -1.7292e-01,  1.9575e-02,  3.2486e-01,\n                       -2.9771e-02, -2.5362e-01, -2.1280e-02,  2.5885e-01,  2.2458e-02,\n                       -1.0231e-01, -4.5592e-01, -1.7738e-01,  4.3347e-01, -1.7058e-01,\n                       -6.6495e-02, -2.5583e-02,  1.3005e-01,  1.7330e-01,  1.1377e-01,\n                        1.4797e-01,  1.9973e-01, -5.0595e-02, -2.0204e-01,  4.6450e-01,\n                        7.1089e-02, -2.6963e-02, -1.9317e-01, -1.0056e-05,  1.0409e-01,\n                        1.8307e-01, -2.7474e-01, -1.1283e-01,  3.1436e-01,  1.7054e-01,\n                        3.0624e-02,  2.0066e-01, -2.7268e-01,  7.9152e-02, -3.6781e-01,\n                        3.9681e-01,  1.2862e-01, -7.5334e-02,  3.3829e-03, -4.0919e-02,\n                        1.4765e-01,  1.2367e-01,  3.0337e-02, -1.1068e-02,  5.6322e-02,\n                        4.7771e-03, -1.2501e-01,  2.8361e-02, -1.5074e-01,  2.3539e-01,\n                        2.0973e-01, -7.3456e-02,  2.9151e-02,  2.6542e-01,  2.9852e-04,\n                        1.8113e-01,  3.7122e-03, -3.7139e-01,  3.9119e-01,  6.1062e-02,\n                        7.8519e-02,  4.3498e-02,  9.8920e-02,  3.4764e-01, -1.2705e-02,\n                       -2.5452e-01,  1.1796e-01,  9.2979e-03,  2.1489e-01,  1.4773e-01,\n                        5.1383e-02, -4.7578e-03, -4.4574e-02, -1.2242e-01, -4.3763e-02,\n                       -2.9580e-01,  9.1018e-02, -1.9663e-01,  1.7614e-01,  2.1577e-01,\n                       -1.8968e-01, -1.4112e-02,  3.6728e-01,  9.3773e-02,  2.5896e-01,\n                       -1.2128e-01, -1.3583e-01,  1.9872e-01, -4.3583e-01,  2.3697e-01,\n                       -4.0855e-01,  5.6838e-02])),\n              ('layer2.3.bn3.running_var',\n               tensor([0.0930, 0.0416, 0.0760, 0.2322, 0.0573, 0.0451, 0.0800, 0.0475, 0.1811,\n                       0.0811, 0.0993, 0.0662, 0.0653, 0.0926, 0.1452, 0.1035, 0.1885, 0.1566,\n                       0.1652, 0.0764, 0.0890, 0.1371, 0.0593, 0.0945, 0.1887, 0.0547, 0.1014,\n                       0.0697, 0.1722, 0.0668, 0.1379, 0.0818, 0.1128, 0.1754, 0.1133, 0.0686,\n                       0.0863, 0.0920, 0.0440, 0.1515, 0.0887, 0.1341, 0.1112, 0.0635, 0.0702,\n                       0.1362, 0.1181, 0.0784, 0.0547, 0.1205, 0.1123, 0.1095, 0.0765, 0.0572,\n                       0.0766, 0.0940, 0.0987, 0.0676, 0.0872, 0.0856, 0.1433, 0.0860, 0.1099,\n                       0.0697, 0.0710, 0.1503, 0.0414, 0.0789, 0.0848, 0.1420, 0.1010, 0.0560,\n                       0.0898, 0.0873, 0.1001, 0.0426, 0.1044, 0.0722, 0.1333, 0.0599, 0.2161,\n                       0.0677, 0.1133, 0.1771, 0.0463, 0.0563, 0.0520, 0.0882, 0.1534, 0.1455,\n                       0.0592, 0.0844, 0.1210, 0.1130, 0.0599, 0.0872, 0.0673, 0.0505, 0.0800,\n                       0.0582, 0.1040, 0.0855, 0.0412, 0.0643, 0.0756, 0.0605, 0.0593, 0.0811,\n                       0.1052, 0.0851, 0.1490, 0.0963, 0.1476, 0.0971, 0.1066, 0.0923, 0.0620,\n                       0.0738, 0.0835, 0.0950, 0.0845, 0.1295, 0.0839, 0.0721, 0.0646, 0.1216,\n                       0.1044, 0.0648, 0.0945, 0.1046, 0.1259, 0.1255, 0.1077, 0.0897, 0.0711,\n                       0.0758, 0.0658, 0.0675, 0.1768, 0.0970, 0.0420, 0.1415, 0.0596, 0.1238,\n                       0.1775, 0.0877, 0.0624, 0.0585, 0.0908, 0.2032, 0.0773, 0.0469, 0.1346,\n                       0.0547, 0.0480, 0.1349, 0.0574, 0.0428, 0.0540, 0.0710, 0.1375, 0.1817,\n                       0.0633, 0.0969, 0.0796, 0.0695, 0.0932, 0.0561, 0.0779, 0.1591, 0.0953,\n                       0.0574, 0.2282, 0.2251, 0.0814, 0.0925, 0.0445, 0.1054, 0.1469, 0.0952,\n                       0.0973, 0.0747, 0.0863, 0.1048, 0.0785, 0.0626, 0.1130, 0.0537, 0.0677,\n                       0.1166, 0.0756, 0.0756, 0.0671, 0.0750, 0.0738, 0.0732, 0.1031, 0.1183,\n                       0.0566, 0.1310, 0.0657, 0.0843, 0.1250, 0.1142, 0.0598, 0.1118, 0.0718,\n                       0.0519, 0.0772, 0.0859, 0.0830, 0.1283, 0.0976, 0.0518, 0.1312, 0.0622,\n                       0.0624, 0.0892, 0.0990, 0.0585, 0.0647, 0.0581, 0.0441, 0.1223, 0.1518,\n                       0.1342, 0.0997, 0.0563, 0.1405, 0.0717, 0.0809, 0.0470, 0.1004, 0.1087,\n                       0.0549, 0.0577, 0.1228, 0.0752, 0.1799, 0.1246, 0.0971, 0.0566, 0.0691,\n                       0.0666, 0.0684, 0.1069, 0.0610, 0.0913, 0.0668, 0.2023, 0.1079, 0.0912,\n                       0.1133, 0.1231, 0.1415, 0.0394, 0.0809, 0.0848, 0.0803, 0.1450, 0.1231,\n                       0.1280, 0.1108, 0.0677, 0.1744, 0.0774, 0.0595, 0.1159, 0.0394, 0.0464,\n                       0.0584, 0.0958, 0.1412, 0.0813, 0.0630, 0.1328, 0.1050, 0.1741, 0.1095,\n                       0.0666, 0.0873, 0.0972, 0.0938, 0.1756, 0.1044, 0.0575, 0.1052, 0.1651,\n                       0.0724, 0.1259, 0.1399, 0.1087, 0.1023, 0.1177, 0.0603, 0.1059, 0.0825,\n                       0.0989, 0.0745, 0.1051, 0.0876, 0.1335, 0.1234, 0.0816, 0.0416, 0.0931,\n                       0.0820, 0.0637, 0.1415, 0.1195, 0.1023, 0.0662, 0.0763, 0.0570, 0.0488,\n                       0.0750, 0.1150, 0.0807, 0.0995, 0.1416, 0.1440, 0.1185, 0.0510, 0.0606,\n                       0.0549, 0.0926, 0.0463, 0.0654, 0.0840, 0.0805, 0.1182, 0.1116, 0.1546,\n                       0.0782, 0.1548, 0.1330, 0.0707, 0.0726, 0.0914, 0.0980, 0.1183, 0.0691,\n                       0.0840, 0.0812, 0.0760, 0.0908, 0.0621, 0.0542, 0.1152, 0.1051, 0.0572,\n                       0.0789, 0.0721, 0.1723, 0.1106, 0.2502, 0.0939, 0.1264, 0.0768, 0.0620,\n                       0.1199, 0.1014, 0.1900, 0.1084, 0.0921, 0.0563, 0.0915, 0.0834, 0.0894,\n                       0.0798, 0.0688, 0.1031, 0.1017, 0.0695, 0.0657, 0.0645, 0.0974, 0.2171,\n                       0.0906, 0.1008, 0.0759, 0.0400, 0.0643, 0.0730, 0.0654, 0.1565, 0.0653,\n                       0.0705, 0.0495, 0.0806, 0.1156, 0.0864, 0.0480, 0.0650, 0.0798, 0.1264,\n                       0.0632, 0.0786, 0.0764, 0.0975, 0.0700, 0.0981, 0.0783, 0.1282, 0.0879,\n                       0.1119, 0.0996, 0.1270, 0.1067, 0.0981, 0.0666, 0.1489, 0.0935, 0.0599,\n                       0.0373, 0.0603, 0.0885, 0.0566, 0.0539, 0.0925, 0.0909, 0.0705, 0.0615,\n                       0.1217, 0.1051, 0.0992, 0.1448, 0.1108, 0.1042, 0.0625, 0.0834, 0.0515,\n                       0.1066, 0.0700, 0.0810, 0.1427, 0.0957, 0.0720, 0.0641, 0.1517, 0.0638,\n                       0.0872, 0.1420, 0.0516, 0.1065, 0.1169, 0.1134, 0.0412, 0.0883, 0.0812,\n                       0.0904, 0.0938, 0.1877, 0.1351, 0.0696, 0.0533, 0.0720, 0.0654, 0.0640,\n                       0.1045, 0.0792, 0.0629, 0.0825, 0.1246, 0.1168, 0.1519, 0.0823, 0.0912,\n                       0.0593, 0.0766, 0.0513, 0.1708, 0.0612, 0.0817, 0.0776, 0.0686, 0.1298,\n                       0.1104, 0.1351, 0.0690, 0.1171, 0.0786, 0.0412, 0.1331, 0.1501, 0.1274,\n                       0.0759, 0.0504, 0.1148, 0.1174, 0.1693, 0.0580, 0.0521, 0.0577, 0.0764,\n                       0.1388, 0.0747, 0.1120, 0.2125, 0.0578, 0.0782, 0.0612, 0.1087, 0.0648,\n                       0.1264, 0.0587, 0.0633, 0.1174, 0.1084, 0.1475, 0.1447, 0.0474])),\n              ('layer2.3.bn3.num_batches_tracked', tensor(13572)),\n              ('layer3.0.conv1.weight',\n               tensor([[[[-0.1021]],\n               \n                        [[ 0.0476]],\n               \n                        [[-0.0013]],\n               \n                        ...,\n               \n                        [[-0.0680]],\n               \n                        [[-0.0309]],\n               \n                        [[-0.0238]]],\n               \n               \n                       [[[-0.1422]],\n               \n                        [[ 0.0317]],\n               \n                        [[ 0.0258]],\n               \n                        ...,\n               \n                        [[ 0.0188]],\n               \n                        [[ 0.0919]],\n               \n                        [[ 0.0211]]],\n               \n               \n                       [[[ 0.0519]],\n               \n                        [[ 0.0548]],\n               \n                        [[ 0.0003]],\n               \n                        ...,\n               \n                        [[-0.0364]],\n               \n                        [[ 0.1583]],\n               \n                        [[-0.0413]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0110]],\n               \n                        [[ 0.0191]],\n               \n                        [[ 0.0576]],\n               \n                        ...,\n               \n                        [[ 0.0065]],\n               \n                        [[-0.0336]],\n               \n                        [[ 0.0257]]],\n               \n               \n                       [[[ 0.0007]],\n               \n                        [[ 0.0644]],\n               \n                        [[-0.0741]],\n               \n                        ...,\n               \n                        [[-0.0555]],\n               \n                        [[-0.0157]],\n               \n                        [[-0.0415]]],\n               \n               \n                       [[[ 0.0173]],\n               \n                        [[-0.0748]],\n               \n                        [[ 0.0157]],\n               \n                        ...,\n               \n                        [[-0.0344]],\n               \n                        [[ 0.0196]],\n               \n                        [[ 0.0220]]]])),\n              ('layer3.0.bn1.weight',\n               tensor([0.9410, 0.9815, 0.9291, 0.9599, 1.0032, 1.0165, 1.0002, 0.9728, 0.9991,\n                       0.9780, 1.0305, 0.9301, 0.9628, 1.0551, 0.9797, 0.9700, 0.9863, 0.9891,\n                       0.9174, 1.0185, 1.0158, 0.9474, 0.9121, 0.9842, 0.9743, 0.9293, 0.9462,\n                       1.0655, 0.9966, 1.0024, 0.9520, 0.9963, 0.9159, 0.9673, 0.9881, 0.8942,\n                       0.9343, 0.9811, 0.9924, 0.9982, 1.0082, 0.9607, 1.0367, 0.9562, 1.0223,\n                       1.0306, 0.9595, 0.9596, 1.0375, 0.9983, 0.9925, 1.0178, 0.9830, 1.0060,\n                       0.9587, 0.9508, 1.0196, 0.9962, 0.9173, 0.9731, 0.9459, 0.9634, 0.9442,\n                       0.9662, 0.9854, 1.0188, 0.9865, 1.0377, 0.9868, 1.0184, 0.9424, 1.0263,\n                       0.9690, 0.9712, 1.0032, 1.0010, 0.9842, 1.0309, 0.9943, 0.9481, 0.9884,\n                       1.0181, 1.0640, 0.9841, 1.0268, 0.9692, 1.0344, 0.9810, 1.0551, 0.9974,\n                       0.9580, 0.9582, 0.9829, 0.9550, 1.0110, 1.0256, 0.9898, 0.9825, 0.9881,\n                       0.9853, 0.9574, 1.0284, 1.0008, 0.9721, 0.9522, 0.9629, 1.0207, 1.0294,\n                       1.0219, 1.0153, 1.0121, 0.9922, 1.0363, 0.9425, 0.9480, 1.0018, 0.9875,\n                       1.1088, 0.9552, 0.9655, 0.9774, 0.9409, 0.9777, 1.0568, 0.9525, 0.9489,\n                       1.0199, 1.0645, 0.9452, 0.9828, 0.9537, 0.9706, 1.0021, 0.9671, 0.9675,\n                       0.9828, 1.0016, 0.9674, 0.9438, 1.1856, 0.9447, 0.9748, 0.9908, 0.9480,\n                       0.9835, 1.0680, 0.9468, 0.9654, 1.0001, 1.0159, 0.9629, 0.9506, 0.9507,\n                       1.0117, 1.0684, 0.9934, 1.0308, 1.0834, 0.9607, 0.9880, 0.9726, 0.9444,\n                       0.9536, 0.9871, 0.9910, 1.0659, 0.9332, 0.9989, 1.0401, 0.9840, 0.9770,\n                       0.9331, 1.0124, 0.9410, 1.0118, 0.9943, 0.9534, 1.0263, 0.9746, 0.9570,\n                       0.9806, 1.0148, 0.9915, 0.9533, 0.9719, 0.9283, 0.9257, 0.9467, 0.9905,\n                       1.0230, 0.9810, 1.0085, 0.9917, 1.0167, 1.0565, 1.0189, 1.0006, 0.9531,\n                       0.9728, 1.0261, 1.0022, 0.9427, 0.9950, 0.9993, 1.0349, 0.9759, 0.9338,\n                       0.9955, 1.0104, 0.9829, 0.9978, 1.0431, 0.9815, 0.9587, 0.9841, 1.0236,\n                       1.0364, 0.9852, 0.9992, 0.9900, 1.0152, 1.0140, 0.9764, 1.0513, 0.9152,\n                       1.0207, 0.9731, 0.9827, 0.9874, 0.9775, 0.9793, 0.9440, 1.0218, 1.0334,\n                       0.9483, 0.9809, 0.9464, 0.9875, 0.9488, 0.9389, 0.8778, 1.0054, 0.9980,\n                       0.9974, 1.0112, 0.9175, 0.9714, 1.0053, 0.9563, 0.9190, 0.9345, 0.8974,\n                       0.9438, 1.0184, 0.9852, 0.9831])),\n              ('layer3.0.bn1.bias',\n               tensor([-3.5304e-02, -1.1206e-01, -1.7119e-01, -1.1921e-01, -1.2251e-01,\n                       -5.6766e-02, -2.6582e-01, -7.2107e-02, -3.6935e-02, -1.3429e-01,\n                       -2.9388e-01, -1.0815e-01, -1.5848e-01, -2.3525e-01, -2.3255e-01,\n                       -1.8319e-01, -2.9012e-01, -1.6111e-02, -5.6830e-02, -1.4272e-01,\n                       -3.6908e-01, -5.7273e-02, -1.1709e-01, -1.1378e-02, -1.6969e-01,\n                       -1.4347e-01, -1.7556e-01, -2.7149e-01, -1.5888e-02, -1.6708e-02,\n                       -1.3016e-01, -4.8529e-02, -1.5274e-01, -3.9433e-02, -8.9521e-02,\n                       -4.4216e-02, -6.5915e-02, -1.1138e-01, -2.5230e-01, -1.8653e-01,\n                       -9.5160e-02, -9.2823e-02, -1.7558e-01, -1.3482e-01, -3.0232e-01,\n                       -6.9348e-02, -1.8822e-01, -2.0316e-01, -3.1304e-01, -2.3523e-01,\n                       -3.0226e-01, -2.2859e-01, -1.7584e-01, -1.5570e-01, -1.2551e-01,\n                       -1.5794e-01, -1.6411e-01,  2.2092e-03, -7.7408e-02, -9.5465e-02,\n                       -5.0380e-02, -2.3604e-01, -1.2105e-01, -8.1009e-02, -7.5521e-02,\n                       -1.9074e-02, -1.2256e-01, -1.8469e-02, -2.3643e-01, -2.1586e-01,\n                       -7.4266e-02, -1.3924e-01, -4.9020e-02, -6.3194e-02, -1.4520e-01,\n                       -1.4572e-01, -2.6019e-01, -1.3248e-01, -1.1426e-01, -2.2461e-01,\n                       -1.6318e-01, -1.4828e-01, -7.2321e-02, -1.9352e-01, -1.6576e-01,\n                       -1.0055e-01, -3.3686e-02, -1.0328e-01, -9.5940e-02,  5.2884e-02,\n                       -1.4430e-01, -1.4240e-01, -1.9771e-01, -1.0504e-01, -1.4346e-01,\n                       -1.4793e-01, -1.0236e-01, -1.8283e-01, -2.6860e-01, -2.1858e-01,\n                       -2.6994e-01, -2.5395e-01, -2.0066e-01, -4.9948e-02, -2.5582e-01,\n                       -1.7623e-01, -2.6309e-01, -2.4108e-01, -1.5776e-01, -2.2204e-01,\n                       -2.3878e-01, -1.1997e-01, -9.3684e-02, -2.5131e-01, -7.2922e-02,\n                       -6.6523e-02, -1.7209e-01, -3.9889e-01, -6.7428e-02, -1.0177e-01,\n                       -8.2702e-02, -1.5420e-01, -1.2183e-01, -2.8337e-01, -2.5177e-01,\n                       -9.7519e-02, -9.9551e-02, -2.6561e-01, -8.1424e-02, -1.9574e-01,\n                       -2.9147e-01, -1.2031e-01, -1.1527e-01, -2.0801e-01, -1.9298e-01,\n                       -1.7471e-01, -3.8897e-02, -3.8809e-02, -6.6161e-02, -3.9872e-01,\n                       -3.5006e-02, -1.9387e-01, -1.1532e-01, -3.8850e-01, -1.0907e-01,\n                       -1.2318e-01, -1.2667e-01,  3.3417e-04, -3.2543e-01, -1.6484e-01,\n                       -1.9655e-01, -1.0170e-01, -1.4128e-01, -3.2486e-01, -2.7999e-01,\n                       -1.0365e-01, -8.6175e-02, -3.6856e-01, -2.0023e-01, -1.2979e-01,\n                       -1.3658e-01, -4.8229e-02, -2.2597e-01, -2.1210e-01, -1.5625e-01,\n                       -1.5636e-01, -5.1046e-02, -2.0419e-01, -1.1982e-01, -1.3709e-01,\n                       -7.1010e-02, -1.2434e-01, -3.0875e-01, -8.2511e-02, -3.7720e-02,\n                       -2.3172e-01, -1.1701e-01, -2.7710e-01, -5.4832e-02, -1.9552e-01,\n                       -1.6627e-01, -7.7741e-02,  9.7427e-03, -1.1829e-01, -5.7186e-02,\n                       -5.7146e-02, -1.0922e-01, -5.0539e-02, -2.2223e-01, -2.6806e-01,\n                       -2.5181e-01, -1.2353e-02, -1.7990e-01, -1.0616e-01, -3.5216e-01,\n                       -8.6085e-02, -6.7735e-02,  1.6076e-02, -1.3448e-01, -2.5062e-01,\n                       -6.8471e-02, -4.9327e-02, -9.4439e-02, -1.2862e-01, -3.6209e-02,\n                       -3.6195e-02, -3.5923e-02, -3.4976e-02, -7.1417e-02, -1.4413e-01,\n                       -2.3048e-01, -2.0314e-01, -1.4538e-01, -3.4077e-02, -6.3497e-02,\n                       -2.3221e-01, -3.5443e-02, -1.7299e-01, -8.5644e-02, -1.0143e-01,\n                       -1.5685e-01, -6.2784e-02, -1.1944e-01, -3.1950e-01, -1.3470e-01,\n                       -4.4968e-02, -1.6920e-01, -1.9334e-01, -9.8502e-02, -1.9092e-01,\n                       -2.9060e-02, -1.4123e-01, -1.8016e-01, -3.2666e-01, -4.6243e-02,\n                       -1.4599e-01, -1.0676e-01, -3.4848e-01, -1.7369e-01, -9.7442e-02,\n                       -9.8232e-02, -2.3626e-01,  3.6512e-02, -7.4360e-02, -2.4457e-01,\n                       -6.9518e-02, -3.0125e-01, -9.2963e-02, -2.6776e-02, -8.1974e-02,\n                       -1.5832e-01, -1.4257e-01, -2.6459e-01, -2.2919e-02, -4.2190e-02,\n                       -1.5256e-02])),\n              ('layer3.0.bn1.running_mean',\n               tensor([-1.4243e+00, -8.2243e-01, -3.4757e-01,  2.5353e-01, -4.8083e-01,\n                       -1.5186e+00, -8.6434e-02, -7.7397e-01, -1.5038e+00, -8.7778e-01,\n                       -1.8840e-02, -6.7451e-01, -7.7593e-01, -5.9928e-01, -6.7800e-01,\n                       -2.1759e+00, -9.3342e-01, -1.6930e+00, -1.6235e-01, -6.1870e-01,\n                        4.9350e-01, -2.9723e-01, -9.0417e-01, -1.3633e+00,  2.2540e-02,\n                       -1.1307e-01,  2.9574e-01, -2.3268e-02, -2.4014e+00, -1.7731e+00,\n                       -1.0432e+00, -1.2521e+00, -3.6154e-01, -2.2857e+00, -4.0172e-01,\n                       -3.2275e-01, -1.5375e+00, -3.3626e-01, -1.2490e+00,  8.2313e-02,\n                        7.3846e-01,  7.1676e-02, -3.7873e-01,  5.3994e-01,  1.0503e+00,\n                       -1.4372e+00,  7.6742e-01, -2.0911e-02, -1.5542e-01,  1.1118e-01,\n                       -2.7655e-01, -1.9985e+00, -8.3433e-01, -5.4487e-01, -1.0615e+00,\n                        8.2834e-01,  2.2544e-01, -2.1448e+00, -1.7814e-02, -7.3821e-01,\n                       -6.1966e-01, -5.3393e-02, -9.1033e-01, -8.7920e-01, -9.9537e-01,\n                       -1.2223e+00,  1.8170e-01, -1.7443e+00,  1.2042e-01, -1.6030e+00,\n                       -1.0618e+00, -9.5970e-01, -2.0034e-01, -6.4758e-01, -1.4105e+00,\n                       -7.7283e-01, -7.7470e-01, -1.4764e+00, -4.8721e-02, -3.2994e-01,\n                       -1.7813e-01, -4.5117e-01, -5.7872e-02,  2.8624e-01, -2.2300e+00,\n                       -1.5958e-01, -1.0582e+00, -1.4527e+00, -1.0496e+00, -1.7440e+00,\n                        1.2025e-01, -1.0098e+00,  4.2773e-01, -7.8441e-01, -1.6463e-01,\n                       -7.2959e-01, -1.3545e+00,  3.7068e-01, -9.4973e-01,  2.2697e-01,\n                       -1.8877e-02, -6.3218e-01,  1.2934e+00, -5.6897e-01,  2.9517e-01,\n                       -1.2950e+00, -6.8950e-01, -1.0999e-01,  1.2029e-01, -7.4275e-01,\n                       -8.9885e-01, -1.4442e+00, -1.6375e+00, -6.3618e-01,  7.7298e-02,\n                        3.6600e-01, -7.3259e-01,  8.8846e-01, -4.9696e-01, -7.6147e-01,\n                       -4.2255e-01, -7.3834e-04,  1.0454e-01,  2.5105e-01,  5.5921e-01,\n                       -1.2639e+00, -1.3076e+00, -7.4599e-01, -7.2908e-01, -6.1944e-01,\n                        7.7462e-01,  2.7968e-01,  1.3652e+00, -7.7792e-01, -2.0509e-01,\n                       -1.7733e+00, -1.5155e+00, -6.6964e-01, -1.3730e+00,  8.5989e-01,\n                       -1.6447e+00, -5.0951e-01, -1.4294e+00, -3.8961e-01, -1.4552e+00,\n                       -1.3580e+00, -8.7078e-01, -6.0346e-01, -6.9935e-01,  8.3974e-02,\n                       -2.2880e-01, -2.0792e+00, -1.5122e+00, -3.7810e-02,  7.8686e-01,\n                       -6.6931e-01,  1.3510e-02,  3.9272e-01, -1.3787e+00, -1.4396e+00,\n                        9.4636e-01, -2.2665e+00, -8.6907e-01,  4.8757e-02, -7.0262e-01,\n                       -1.4259e+00, -1.6979e+00,  4.0313e-01, -3.8557e-01, -4.2546e-01,\n                       -2.0153e+00,  4.2366e-03,  4.7783e-01, -9.6408e-01, -1.2487e+00,\n                        4.2620e-01, -1.7898e+00, -3.3626e-01, -9.1632e-01, -1.3348e-01,\n                        3.6204e-01, -1.4900e+00, -1.9943e+00, -1.7446e+00, -1.8040e+00,\n                       -2.4482e-02, -6.5110e-02, -7.8613e-01, -4.5955e-01, -2.3022e-01,\n                       -9.7206e-02, -1.8231e+00,  7.7919e-01, -1.2092e+00, -8.6509e-01,\n                       -1.2598e+00, -1.7335e+00,  5.6542e-01,  2.9500e-01, -1.4537e+00,\n                       -1.2305e+00, -1.1190e+00, -3.9656e-01, -1.1335e+00, -1.3550e+00,\n                       -6.3106e-01, -6.6996e-01, -1.9079e+00,  2.0186e-01, -2.7591e-01,\n                        2.0021e-01,  2.9620e-01, -1.3124e+00, -1.0032e+00, -8.2916e-01,\n                       -1.4338e-01, -1.4409e+00, -1.0008e+00, -1.1052e+00, -1.7643e+00,\n                        9.5465e-02, -2.3292e+00, -1.8447e+00,  4.0660e-01, -1.1978e+00,\n                       -7.5379e-01, -8.0048e-01, -7.0135e-01, -6.3273e-01, -1.4283e+00,\n                       -1.3898e+00,  1.6300e-01, -8.3207e-01, -2.5334e-01,  1.7557e-01,\n                        4.3964e-02,  3.1273e-01, -1.3568e+00,  1.5829e-01, -1.0065e+00,\n                        8.4224e-01, -3.9106e-01, -1.5507e+00, -1.2518e+00, -9.8573e-01,\n                       -1.5863e+00,  7.3636e-01, -2.3216e+00, -1.3480e+00, -4.1501e-01,\n                        4.1857e-01, -6.9808e-01, -1.3932e+00, -7.6197e-01, -1.0281e+00,\n                       -1.6003e+00])),\n              ('layer3.0.bn1.running_var',\n               tensor([1.0096, 1.1985, 1.0855, 1.4065, 1.3684, 1.1330, 0.9254, 1.6507, 2.4054,\n                       1.5936, 0.9184, 0.8600, 0.9613, 1.0653, 1.1484, 1.0488, 0.6859, 1.0146,\n                       0.7038, 1.4275, 0.8375, 0.9297, 1.0150, 1.3832, 1.3599, 0.6787, 1.4124,\n                       1.3641, 1.1716, 1.1897, 0.8570, 1.0776, 1.4992, 1.3045, 0.9886, 0.7022,\n                       0.6690, 1.3676, 1.1607, 1.0888, 1.2027, 0.8026, 1.0839, 0.7571, 1.5558,\n                       1.5026, 0.9236, 1.2698, 0.7762, 0.9159, 0.8873, 1.6516, 1.1780, 0.8726,\n                       1.1534, 0.8794, 1.1042, 1.3991, 1.3138, 1.2387, 0.9378, 0.8687, 1.4149,\n                       1.3747, 1.2739, 1.4479, 1.4278, 1.9409, 1.0016, 1.0923, 0.8239, 1.1883,\n                       0.9182, 1.0325, 0.9873, 1.3240, 0.9655, 1.2845, 0.7590, 0.8112, 1.5984,\n                       0.9813, 1.0217, 0.8317, 1.1466, 1.5275, 1.8254, 1.2666, 1.1761, 2.0056,\n                       0.7409, 0.8488, 1.2802, 0.6041, 0.8918, 1.0534, 1.7921, 0.9632, 0.7174,\n                       0.8616, 1.2854, 1.1697, 1.0856, 1.2061, 0.8510, 1.2151, 1.0246, 1.6371,\n                       1.0115, 1.0934, 1.0006, 1.5030, 1.4194, 0.6213, 0.9674, 1.5868, 1.0285,\n                       0.9754, 0.8464, 0.9659, 1.0796, 0.9921, 1.0089, 0.7928, 1.2083, 0.9445,\n                       0.9418, 1.0540, 0.9137, 0.8151, 1.0594, 1.0034, 1.6878, 1.1980, 0.9051,\n                       0.9424, 2.2367, 1.1872, 1.1613, 1.0484, 1.2565, 0.7955, 1.4608, 0.6537,\n                       0.9651, 1.7164, 0.6708, 1.8337, 1.1736, 0.9516, 0.5393, 1.2152, 0.9825,\n                       1.1479, 1.1373, 0.7141, 1.5199, 1.1546, 0.8257, 0.6691, 0.9585, 1.2467,\n                       0.7745, 0.9113, 1.3159, 1.3020, 0.8739, 1.0951, 1.3832, 1.5414, 1.1835,\n                       1.0396, 1.0862, 1.0656, 1.4472, 1.0225, 0.8689, 1.0164, 0.7971, 1.1226,\n                       0.9847, 1.3098, 1.6014, 1.3332, 1.0811, 0.8841, 0.6769, 2.0009, 0.9433,\n                       1.0849, 1.1546, 1.2488, 1.0218, 1.8117, 1.9120, 1.1149, 1.4536, 1.3765,\n                       1.1536, 1.3834, 1.1716, 1.0092, 1.2011, 1.6848, 2.0347, 1.1243, 0.9141,\n                       1.0282, 1.3546, 0.9000, 1.0215, 0.9508, 1.4200, 1.0436, 1.1781, 1.0060,\n                       1.3466, 1.0188, 1.3793, 1.4852, 1.3836, 1.5578, 0.9969, 0.9323, 1.4376,\n                       0.9745, 0.8676, 1.1407, 1.0084, 2.1522, 1.3789, 0.9407, 1.1715, 0.9335,\n                       1.0125, 0.9077, 1.1200, 1.6353, 1.0091, 1.0528, 0.9642, 0.7633, 1.9121,\n                       0.9524, 0.9344, 0.8096, 0.7970, 1.1699, 0.7907, 1.0264, 0.7622, 0.7792,\n                       0.9085, 1.2264, 0.8363, 1.1554])),\n              ('layer3.0.bn1.num_batches_tracked', tensor(13572)),\n              ('layer3.0.conv2.weight',\n               tensor([[[[-0.0473, -0.0013, -0.0226],\n                         [-0.0054,  0.0152, -0.0007],\n                         [-0.0005,  0.0458, -0.0067]],\n               \n                        [[-0.0330,  0.0309, -0.0146],\n                         [-0.0164,  0.0015, -0.0085],\n                         [-0.0091,  0.0080, -0.0301]],\n               \n                        [[-0.0103, -0.0280, -0.0235],\n                         [-0.0118,  0.0091, -0.0381],\n                         [-0.0008,  0.0081, -0.0472]],\n               \n                        ...,\n               \n                        [[-0.0199, -0.0267, -0.0104],\n                         [ 0.0023, -0.0027, -0.0028],\n                         [ 0.0070, -0.0019,  0.0361]],\n               \n                        [[ 0.0007,  0.0257,  0.0174],\n                         [ 0.0336, -0.0398,  0.0162],\n                         [ 0.0364,  0.0457,  0.0701]],\n               \n                        [[-0.0161, -0.0314, -0.0073],\n                         [-0.0266, -0.0272, -0.0221],\n                         [ 0.0207, -0.0056, -0.0127]]],\n               \n               \n                       [[[ 0.0049,  0.0234, -0.0381],\n                         [-0.0233,  0.0277, -0.0053],\n                         [-0.0304, -0.0335,  0.0117]],\n               \n                        [[-0.0077, -0.0006, -0.0057],\n                         [-0.0131,  0.0350, -0.0562],\n                         [ 0.0075,  0.0007, -0.0304]],\n               \n                        [[ 0.0031,  0.0466,  0.0370],\n                         [-0.0157,  0.0223,  0.0112],\n                         [ 0.0013,  0.0178, -0.0082]],\n               \n                        ...,\n               \n                        [[-0.0380,  0.0276,  0.0072],\n                         [ 0.0094, -0.0115, -0.0188],\n                         [-0.0078, -0.0111, -0.0026]],\n               \n                        [[ 0.0026,  0.0104,  0.0063],\n                         [ 0.0225, -0.0241,  0.0025],\n                         [ 0.0101,  0.0218, -0.0295]],\n               \n                        [[ 0.0161, -0.0118,  0.0347],\n                         [ 0.0130,  0.0257,  0.0250],\n                         [ 0.0205,  0.0152, -0.0020]]],\n               \n               \n                       [[[ 0.0142,  0.0298,  0.0317],\n                         [-0.0173,  0.0210,  0.0033],\n                         [ 0.0024, -0.0048, -0.0072]],\n               \n                        [[ 0.0163, -0.0025,  0.0340],\n                         [ 0.0796,  0.0560,  0.0515],\n                         [ 0.0604,  0.0835,  0.0708]],\n               \n                        [[ 0.0101, -0.0183, -0.0158],\n                         [-0.0473, -0.0057, -0.0364],\n                         [-0.0254, -0.0261, -0.0382]],\n               \n                        ...,\n               \n                        [[-0.0270,  0.0080, -0.0113],\n                         [-0.0278, -0.0428, -0.0073],\n                         [-0.0333, -0.0111, -0.0333]],\n               \n                        [[-0.0083, -0.0042, -0.0108],\n                         [ 0.0223,  0.0046,  0.0346],\n                         [ 0.0105,  0.0484,  0.0025]],\n               \n                        [[-0.0096, -0.0362, -0.0083],\n                         [ 0.0254,  0.0162, -0.0250],\n                         [ 0.0290,  0.0179, -0.0027]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0556, -0.0074,  0.0185],\n                         [ 0.0583,  0.0414,  0.0030],\n                         [ 0.0442,  0.0316, -0.0254]],\n               \n                        [[-0.0007, -0.0180,  0.0085],\n                         [-0.0442,  0.0049, -0.0576],\n                         [-0.0220, -0.0435,  0.0079]],\n               \n                        [[ 0.0070, -0.0149, -0.0740],\n                         [-0.0026, -0.0439, -0.0144],\n                         [-0.0112, -0.0256, -0.0484]],\n               \n                        ...,\n               \n                        [[ 0.0128, -0.0314, -0.0243],\n                         [ 0.0256, -0.0063, -0.0506],\n                         [-0.0115,  0.0072,  0.0219]],\n               \n                        [[ 0.0505,  0.0305, -0.0092],\n                         [ 0.0372, -0.0122,  0.0291],\n                         [ 0.0107,  0.0583, -0.0254]],\n               \n                        [[-0.0099,  0.0137, -0.0098],\n                         [ 0.0131,  0.0320,  0.0026],\n                         [-0.0071, -0.0118,  0.0029]]],\n               \n               \n                       [[[-0.0201,  0.0283, -0.0150],\n                         [-0.0318, -0.0348, -0.0166],\n                         [ 0.0232, -0.0450,  0.0077]],\n               \n                        [[ 0.0191,  0.0158, -0.0060],\n                         [ 0.0168, -0.0002, -0.0314],\n                         [-0.0337, -0.0123, -0.0075]],\n               \n                        [[ 0.0148,  0.0392,  0.0671],\n                         [ 0.0471,  0.0608,  0.0468],\n                         [-0.0065, -0.0412, -0.0258]],\n               \n                        ...,\n               \n                        [[-0.0128, -0.0447,  0.0089],\n                         [ 0.0290,  0.0366,  0.0346],\n                         [ 0.0057,  0.0140,  0.0141]],\n               \n                        [[-0.0378, -0.0323, -0.0467],\n                         [-0.0418, -0.0024, -0.0034],\n                         [-0.0130, -0.0134, -0.0280]],\n               \n                        [[ 0.0152, -0.0051, -0.0142],\n                         [-0.0460, -0.0034,  0.0220],\n                         [ 0.0181, -0.0265, -0.0058]]],\n               \n               \n                       [[[ 0.0124,  0.0092, -0.0097],\n                         [-0.0121, -0.0137, -0.0242],\n                         [-0.0163, -0.0220, -0.0260]],\n               \n                        [[-0.0078, -0.0353,  0.0141],\n                         [ 0.0075,  0.0062,  0.0148],\n                         [-0.0027,  0.0015, -0.0093]],\n               \n                        [[ 0.0365, -0.0162, -0.0382],\n                         [ 0.0282,  0.0379, -0.0286],\n                         [ 0.0107,  0.0019, -0.0521]],\n               \n                        ...,\n               \n                        [[-0.0072, -0.0043, -0.0181],\n                         [ 0.0328,  0.0257,  0.0157],\n                         [ 0.0101, -0.0444,  0.0414]],\n               \n                        [[ 0.0167, -0.0266, -0.0138],\n                         [ 0.0814, -0.0170, -0.0221],\n                         [ 0.0602, -0.0033, -0.0351]],\n               \n                        [[ 0.0445,  0.0216, -0.0233],\n                         [ 0.0114,  0.0035, -0.0286],\n                         [ 0.0086, -0.0147, -0.0171]]]])),\n              ('layer3.0.bn2.weight',\n               tensor([1.0435, 1.0811, 1.0218, 0.9786, 1.0063, 1.0138, 1.0153, 1.0396, 1.0311,\n                       0.9768, 0.9736, 1.0000, 0.9801, 0.9627, 1.0130, 1.0396, 1.0410, 0.9938,\n                       1.0096, 1.0011, 0.9448, 0.9843, 0.9764, 1.0252, 1.0043, 0.9600, 0.9596,\n                       1.0063, 1.1000, 0.9686, 0.9147, 1.0501, 0.9965, 0.9831, 0.9954, 0.9880,\n                       0.9555, 0.9941, 0.9735, 1.0376, 0.9838, 0.9608, 1.0368, 1.0135, 1.0088,\n                       0.9535, 1.0067, 0.9822, 1.0113, 1.0384, 0.9976, 1.0149, 1.0298, 1.0127,\n                       1.0065, 1.0086, 1.0056, 0.9609, 0.9906, 0.9620, 0.9903, 0.9968, 1.0244,\n                       1.0373, 1.0036, 0.9605, 0.9942, 0.9732, 1.0037, 0.9477, 0.9356, 1.0238,\n                       1.0258, 1.0251, 1.0013, 0.9855, 0.9946, 1.0050, 1.0179, 0.9532, 1.0099,\n                       0.9428, 1.0253, 0.9706, 1.0390, 1.0358, 1.0071, 1.0643, 0.9819, 1.0376,\n                       1.0154, 1.0136, 0.9931, 0.9790, 1.0755, 0.9686, 1.0173, 0.9862, 1.0051,\n                       1.0849, 1.0032, 0.9689, 0.9859, 1.0090, 0.9543, 1.0168, 0.9900, 0.9544,\n                       0.9397, 1.0020, 0.9771, 1.0110, 0.9865, 1.0314, 1.0188, 1.0019, 0.9776,\n                       0.9637, 1.0223, 1.0333, 1.0066, 0.9699, 1.0208, 0.9839, 1.0325, 0.9727,\n                       0.9553, 1.0211, 0.9440, 1.0541, 0.9395, 0.9654, 0.9670, 1.0604, 0.9522,\n                       1.0473, 0.9829, 0.9522, 0.9600, 0.9670, 1.0252, 1.0075, 1.0373, 0.9445,\n                       1.0047, 0.9717, 0.9555, 0.9734, 1.0078, 0.9730, 1.0226, 1.0216, 0.9994,\n                       0.9649, 0.9917, 0.9761, 1.0099, 0.9489, 1.0086, 0.9286, 0.9670, 1.0762,\n                       1.0732, 1.0180, 0.9368, 1.0197, 1.0397, 0.9645, 0.9992, 1.0113, 0.9645,\n                       1.0267, 0.9825, 1.0834, 1.0054, 0.9874, 0.9801, 1.0477, 1.0064, 0.9617,\n                       0.9614, 0.9497, 0.9860, 0.9967, 0.9982, 1.0426, 0.9664, 0.9585, 0.9368,\n                       0.9959, 0.9819, 0.9681, 0.9792, 1.0200, 0.9651, 0.9738, 0.9805, 0.9703,\n                       0.9521, 0.9879, 0.9854, 0.9595, 1.0467, 0.9631, 1.0322, 1.0526, 0.9931,\n                       0.9721, 1.0147, 0.9736, 0.9819, 1.0142, 0.9997, 1.0043, 0.9355, 1.0335,\n                       0.9940, 1.0067, 1.0159, 0.9854, 1.0079, 1.0009, 0.9701, 0.9943, 0.9428,\n                       1.0310, 0.9990, 1.0298, 1.0513, 0.9896, 0.9608, 1.0071, 0.9655, 0.9378,\n                       0.9425, 0.9677, 1.0174, 1.0048, 0.9864, 1.0084, 1.0282, 0.9597, 0.9805,\n                       0.9589, 0.9993, 1.0428, 1.0131, 0.9533, 0.9660, 0.9911, 0.9212, 1.0132,\n                       0.9549, 1.0387, 1.0758, 1.0137])),\n              ('layer3.0.bn2.bias',\n               tensor([ 0.0777,  0.0525,  0.0798,  0.0730,  0.2024,  0.0160, -0.0201,  0.1037,\n                        0.0915,  0.0801,  0.0452,  0.1839,  0.0004, -0.0410, -0.0282,  0.1706,\n                        0.1123,  0.1019,  0.0533,  0.1717,  0.0200,  0.0431,  0.0701,  0.0955,\n                        0.0268,  0.0037,  0.0538,  0.0310, -0.0427,  0.0882, -0.0303,  0.1825,\n                        0.0363,  0.0654,  0.0759,  0.1600,  0.0182,  0.2079, -0.0040,  0.0888,\n                        0.1487,  0.0249, -0.0036, -0.0235,  0.1346,  0.2381,  0.0573,  0.1248,\n                        0.1498,  0.0875, -0.0273,  0.1378,  0.0353,  0.0886,  0.0867, -0.0529,\n                        0.1769,  0.0297, -0.0189,  0.1163,  0.0878, -0.0189,  0.1291,  0.0106,\n                        0.0023,  0.1356,  0.0791,  0.0601,  0.0769,  0.0919,  0.1128, -0.0093,\n                        0.0214, -0.0175,  0.1264,  0.1317,  0.1276,  0.1153,  0.1711,  0.1182,\n                        0.0967,  0.1224,  0.1285,  0.1234,  0.0770,  0.0505,  0.0886,  0.0892,\n                        0.0978,  0.1854,  0.0466,  0.0857,  0.1133,  0.0585,  0.0508,  0.0706,\n                        0.0653,  0.1297,  0.1091, -0.0191,  0.1138,  0.0065,  0.0201, -0.0153,\n                        0.0127,  0.0324,  0.0642,  0.1697,  0.1354,  0.1880,  0.1378,  0.0184,\n                        0.1661,  0.1077, -0.0359,  0.1006,  0.0067,  0.1371, -0.0247,  0.1695,\n                       -0.0261,  0.0921,  0.0186,  0.1586, -0.0268,  0.1063,  0.1266,  0.1518,\n                        0.1100, -0.0480,  0.1674,  0.0893,  0.0140, -0.0338,  0.0312,  0.0962,\n                        0.1409,  0.0731,  0.0804,  0.1017,  0.0348,  0.0348,  0.0258,  0.0860,\n                        0.0139,  0.0176,  0.1989,  0.1178, -0.0440,  0.1553, -0.0276,  0.0179,\n                       -0.0246,  0.0655,  0.1059, -0.0044,  0.0712,  0.0509,  0.1204,  0.0026,\n                       -0.0026,  0.1069,  0.0551, -0.0035,  0.0877,  0.0678,  0.0930,  0.0860,\n                        0.0389,  0.0444,  0.0512,  0.0469,  0.0778,  0.0815,  0.0493, -0.0467,\n                        0.0628,  0.0556,  0.0817,  0.1800, -0.0439,  0.1177,  0.0838,  0.1518,\n                        0.2402,  0.1579,  0.0801,  0.1522,  0.0043,  0.0232,  0.0787,  0.0236,\n                        0.1080,  0.1361,  0.0669, -0.0815, -0.0010,  0.1778,  0.0057,  0.0698,\n                        0.0367,  0.0840, -0.0072,  0.2014,  0.0581,  0.0523,  0.2159,  0.0585,\n                        0.0902,  0.1191,  0.0931,  0.0853,  0.0652, -0.0615,  0.1687,  0.0525,\n                        0.0300,  0.0440,  0.0379,  0.0826,  0.2425,  0.0579,  0.0471,  0.1587,\n                        0.0511,  0.0100,  0.1553,  0.0097, -0.0082,  0.2141,  0.0785,  0.1227,\n                        0.1299, -0.0156,  0.1050,  0.1583, -0.0348,  0.1685,  0.1382,  0.0423,\n                        0.0146,  0.1093,  0.0891,  0.1262,  0.0908,  0.0475,  0.0989, -0.0085,\n                       -0.0557,  0.1222,  0.0973,  0.1551,  0.0698, -0.0434, -0.0554, -0.1022])),\n              ('layer3.0.bn2.running_mean',\n               tensor([-4.7020e-01, -1.4275e-01, -6.9504e-02,  4.9718e-01, -1.1358e-02,\n                       -2.2658e-02,  1.7872e-01, -3.3353e-02,  2.9278e-01,  4.5796e-01,\n                        6.0568e-02,  5.6479e-01,  2.8675e-01, -8.4859e-01,  3.5143e-01,\n                        1.3766e-01,  6.0869e-02,  1.1261e-01,  3.2658e-01,  5.9856e-01,\n                       -3.8188e-01, -5.1848e-02,  1.5583e-01,  7.6094e-01, -6.9941e-01,\n                        4.3684e-01,  3.5201e-01, -8.6205e-01, -7.2273e-01, -3.2262e-01,\n                       -2.4332e-01,  4.8991e-01, -2.0030e-01, -3.4897e-01,  3.5369e-01,\n                        4.0391e-01,  9.3845e-02,  4.7787e-01,  4.6529e-02,  3.7742e-01,\n                        5.6459e-02, -3.1882e-01, -2.0097e-01,  6.7261e-01,  1.1092e-01,\n                        8.3761e-01, -4.2306e-01,  5.4418e-01,  5.3489e-01,  2.7834e-01,\n                       -2.9870e-01, -1.8056e-01, -5.6375e-01, -4.2745e-01,  2.1394e-01,\n                       -5.7080e-01,  8.2905e-02,  1.3690e-01, -4.5326e-01,  7.3710e-01,\n                        2.3806e-01, -1.7252e-01, -4.9362e-01, -5.8622e-01,  4.2740e-02,\n                        3.4396e-01,  2.2781e-01,  9.3970e-02,  1.6006e-01, -1.7227e-01,\n                        9.9804e-01, -1.9991e-01, -3.1786e-01, -6.1791e-01,  3.6176e-01,\n                        3.3456e-01, -2.8836e-01,  1.8048e-01, -1.6670e-01,  4.0756e-01,\n                        5.4043e-01,  3.1833e-01,  1.1749e-01, -4.3438e-01,  3.2749e-01,\n                       -6.0962e-01, -2.8174e-02,  4.4041e-01, -2.2831e-01,  7.6884e-01,\n                        3.0047e-01,  1.0185e-01,  1.4033e-01,  6.9830e-02, -1.7828e-02,\n                        6.0817e-01, -1.2583e-01, -4.8545e-01, -3.3267e-01, -9.9242e-01,\n                        6.5393e-01,  8.0165e-02, -6.8194e-01, -3.1520e-01,  2.3780e-01,\n                       -2.2908e-01,  4.3592e-01,  4.3279e-01,  1.3384e-01, -5.1399e-01,\n                        5.6074e-01, -5.4443e-01,  2.9212e-01, -4.0953e-01, -5.8414e-02,\n                       -8.1605e-01,  7.9450e-02,  1.4404e-01, -7.1376e-02, -2.2433e-01,\n                        8.0514e-02,  7.5003e-02, -1.2494e-01,  8.7760e-01, -1.6455e-01,\n                        7.2731e-01, -8.7913e-02,  5.0023e-01,  3.3898e-01,  2.1895e-01,\n                       -1.3188e-01,  7.2039e-01,  4.7533e-01,  3.7546e-01,  5.9678e-01,\n                        3.4894e-01, -8.3896e-01, -1.1510e-01,  4.1534e-01,  5.5701e-01,\n                        4.0437e-01,  8.9667e-03, -3.2816e-01, -4.2109e-01, -5.9815e-01,\n                       -4.5916e-01, -5.9908e-01,  8.1895e-02,  1.8627e-01, -5.9215e-01,\n                       -1.2682e-02, -3.9327e-01, -3.7417e-01, -9.1899e-02, -4.4091e-01,\n                        3.5177e-01, -9.2815e-02, -2.2295e-01, -2.9214e-01, -3.4485e-01,\n                        3.1612e-01,  1.7970e+00,  4.6090e-01,  2.1821e-02,  3.7634e-01,\n                        5.1261e-01, -5.3193e-01, -4.2629e-03,  1.1355e-01,  1.9258e-01,\n                        1.5794e-01, -7.5551e-01, -4.5311e-01, -2.0275e-01, -3.3669e-01,\n                       -3.9539e-01,  5.7375e-01,  2.0169e-01,  3.6207e-03,  2.7775e-02,\n                        3.4982e-02,  3.0174e-01, -3.3246e-01, -1.7405e-01,  5.2888e-01,\n                        2.5602e-01,  2.3103e-01,  6.8769e-01,  2.5910e-01, -4.5215e-01,\n                       -1.1345e-01,  3.1955e-01, -1.1987e-01,  2.6548e-01,  5.8975e-01,\n                       -8.1998e-01, -1.0853e-01,  7.6322e-01, -6.9927e-01,  3.1388e-01,\n                        2.0619e-01,  2.3553e-01, -4.5888e-01,  4.7145e-01, -3.4805e-01,\n                       -5.6993e-01,  4.0712e-01,  1.1203e+00,  6.8319e-01,  8.7015e-01,\n                        8.1815e-01, -8.7175e-01, -3.9289e-01,  1.4621e-01, -1.1839e-01,\n                        8.2676e-02, -6.5758e-01, -4.1262e-01, -7.2128e-02, -1.3469e-01,\n                        4.4567e-01, -4.5934e-01,  1.3393e+00, -4.3535e-01, -7.5980e-02,\n                       -1.3380e-01,  1.6777e-02,  5.6857e-01, -7.4901e-01,  2.9049e-01,\n                        1.8595e-01, -3.1180e-01,  6.5418e-01, -2.7704e-01,  1.1187e+00,\n                        2.3027e-01, -1.9321e-01, -1.5780e-01,  6.2029e-01, -8.8073e-02,\n                       -1.3558e-01, -1.6011e-01, -2.1625e-01, -2.3787e-01,  1.0528e-01,\n                       -9.3302e-02, -3.9381e-01,  1.9947e-01, -5.0900e-01,  2.1039e-02,\n                        1.2526e+00,  3.8222e-02,  2.2222e-01,  1.1285e-01, -3.1432e-04,\n                       -1.8491e-01])),\n              ('layer3.0.bn2.running_var',\n               tensor([0.6324, 0.7690, 0.7751, 0.7936, 0.6941, 1.0416, 0.8989, 1.1692, 0.7983,\n                       0.6824, 0.6613, 0.8385, 0.7514, 0.7107, 0.6383, 1.0622, 0.6988, 0.6913,\n                       0.5511, 0.9649, 0.4725, 0.6223, 0.8068, 0.5539, 0.7909, 0.7651, 0.7015,\n                       0.8567, 0.9130, 0.5424, 0.8033, 1.0406, 0.5651, 0.5879, 0.9419, 0.8789,\n                       0.7000, 0.6560, 0.6248, 0.9748, 0.6363, 0.7331, 0.9151, 0.8612, 0.6028,\n                       0.6388, 0.7419, 0.7118, 0.7178, 0.7377, 0.7972, 0.6219, 0.6681, 0.6100,\n                       1.0677, 0.6337, 0.7386, 0.8488, 0.8830, 0.9472, 0.6749, 0.5706, 0.5780,\n                       0.8359, 0.9772, 0.7988, 0.6236, 0.5345, 0.7424, 0.7159, 0.6233, 0.7685,\n                       0.7378, 0.8391, 0.6962, 0.7121, 0.8130, 0.7950, 0.8356, 0.8384, 0.7304,\n                       0.7724, 0.8513, 0.6900, 0.9326, 0.6542, 0.7486, 0.6979, 0.6235, 0.9739,\n                       0.7338, 0.6053, 0.7366, 0.4668, 0.9256, 0.5372, 0.6957, 0.7919, 0.7615,\n                       0.9037, 0.8235, 0.7486, 0.6292, 0.7609, 0.7253, 0.6965, 0.6660, 1.0590,\n                       0.6097, 0.7056, 0.9248, 0.6490, 0.5802, 0.6642, 0.7028, 0.7918, 0.8663,\n                       0.5698, 0.9240, 0.9327, 0.8101, 0.6805, 0.9874, 0.9093, 0.6365, 0.8068,\n                       0.6922, 0.8427, 0.8119, 1.0527, 0.5836, 0.8276, 0.8508, 0.7017, 0.7831,\n                       0.7390, 0.5618, 0.5236, 0.6301, 0.4928, 0.7731, 0.9517, 0.5457, 0.8146,\n                       0.9817, 0.7209, 0.7261, 0.8042, 0.6338, 0.5118, 0.8020, 0.5565, 0.7815,\n                       0.7102, 0.5723, 0.5909, 0.7020, 0.8513, 0.5477, 0.7396, 0.8862, 1.1972,\n                       1.2016, 0.5676, 0.8531, 0.9417, 0.6093, 0.8056, 0.5880, 0.4884, 0.7508,\n                       0.6317, 0.7375, 1.1675, 0.7805, 0.7412, 0.7531, 0.8047, 0.4744, 0.7935,\n                       0.7492, 0.7993, 0.6928, 0.6433, 0.6822, 0.8954, 0.8813, 0.8358, 0.7670,\n                       0.7990, 0.6608, 0.9731, 0.6697, 0.7986, 0.7979, 0.7661, 0.5567, 0.8225,\n                       0.7403, 0.6235, 0.6115, 0.7125, 0.9566, 0.7633, 0.6647, 0.6085, 0.8477,\n                       0.6463, 0.7369, 0.7644, 0.7856, 0.4991, 0.6585, 1.0658, 0.6520, 1.0523,\n                       0.8149, 0.6310, 0.7124, 0.5683, 1.0281, 0.5130, 1.2042, 0.9112, 0.5384,\n                       0.7448, 0.6721, 0.9034, 0.8546, 0.5999, 0.5619, 0.8366, 0.6800, 1.0440,\n                       0.7883, 0.9578, 0.9935, 0.5386, 0.4750, 0.8620, 0.5933, 0.6925, 0.6839,\n                       0.8990, 0.6711, 0.7264, 0.5317, 1.0669, 0.7859, 0.6471, 0.7424, 0.8287,\n                       0.7883, 0.9531, 1.2976, 0.9327])),\n              ('layer3.0.bn2.num_batches_tracked', tensor(13572)),\n              ('layer3.0.conv3.weight',\n               tensor([[[[-0.0483]],\n               \n                        [[-0.0484]],\n               \n                        [[-0.0276]],\n               \n                        ...,\n               \n                        [[-0.0013]],\n               \n                        [[ 0.0493]],\n               \n                        [[ 0.0177]]],\n               \n               \n                       [[[ 0.0458]],\n               \n                        [[-0.0601]],\n               \n                        [[ 0.0265]],\n               \n                        ...,\n               \n                        [[-0.0239]],\n               \n                        [[ 0.0054]],\n               \n                        [[ 0.0308]]],\n               \n               \n                       [[[-0.0015]],\n               \n                        [[-0.0192]],\n               \n                        [[-0.0223]],\n               \n                        ...,\n               \n                        [[-0.0128]],\n               \n                        [[ 0.0398]],\n               \n                        [[ 0.0138]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0434]],\n               \n                        [[ 0.0417]],\n               \n                        [[ 0.0333]],\n               \n                        ...,\n               \n                        [[-0.0526]],\n               \n                        [[ 0.0258]],\n               \n                        [[-0.0133]]],\n               \n               \n                       [[[ 0.0271]],\n               \n                        [[ 0.0418]],\n               \n                        [[-0.0405]],\n               \n                        ...,\n               \n                        [[ 0.0331]],\n               \n                        [[ 0.0280]],\n               \n                        [[-0.0443]]],\n               \n               \n                       [[[ 0.0236]],\n               \n                        [[ 0.0715]],\n               \n                        [[ 0.0433]],\n               \n                        ...,\n               \n                        [[-0.0204]],\n               \n                        [[-0.0170]],\n               \n                        [[ 0.0070]]]])),\n              ('layer3.0.bn3.weight',\n               tensor([ 0.2648, -0.2485, -0.1526,  ..., -0.3143,  0.3000,  0.1927])),\n              ('layer3.0.bn3.bias',\n               tensor([-0.0433,  0.0210, -0.1012,  ...,  0.0217,  0.0075, -0.0037])),\n              ('layer3.0.bn3.running_mean',\n               tensor([-0.0868, -0.2579, -0.0314,  ...,  0.2085, -0.1690, -0.3094])),\n              ('layer3.0.bn3.running_var',\n               tensor([0.1463, 0.2336, 0.0785,  ..., 0.1885, 0.2816, 0.1533])),\n              ('layer3.0.bn3.num_batches_tracked', tensor(13572)),\n              ('layer3.0.downsample.0.weight',\n               tensor([[[[ 1.0588e-04]],\n               \n                        [[-3.3857e-02]],\n               \n                        [[-6.5362e-02]],\n               \n                        ...,\n               \n                        [[-1.6453e-02]],\n               \n                        [[-6.1187e-02]],\n               \n                        [[ 8.0661e-03]]],\n               \n               \n                       [[[-2.8871e-02]],\n               \n                        [[-1.1799e-02]],\n               \n                        [[-7.5274e-02]],\n               \n                        ...,\n               \n                        [[-6.0427e-02]],\n               \n                        [[-4.5110e-02]],\n               \n                        [[-1.0263e-02]]],\n               \n               \n                       [[[-6.9799e-02]],\n               \n                        [[ 2.7669e-04]],\n               \n                        [[ 9.0298e-03]],\n               \n                        ...,\n               \n                        [[ 6.4290e-03]],\n               \n                        [[-2.8309e-02]],\n               \n                        [[-1.7712e-03]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-1.0110e-03]],\n               \n                        [[-7.7312e-03]],\n               \n                        [[ 5.0799e-02]],\n               \n                        ...,\n               \n                        [[-7.8299e-02]],\n               \n                        [[-3.2949e-02]],\n               \n                        [[ 1.0428e-02]]],\n               \n               \n                       [[[ 1.6176e-02]],\n               \n                        [[-1.1309e-01]],\n               \n                        [[-5.2224e-02]],\n               \n                        ...,\n               \n                        [[-5.1984e-02]],\n               \n                        [[ 2.2173e-02]],\n               \n                        [[-3.8342e-02]]],\n               \n               \n                       [[[-1.1645e-02]],\n               \n                        [[-4.4504e-03]],\n               \n                        [[-4.7257e-02]],\n               \n                        ...,\n               \n                        [[-8.9153e-02]],\n               \n                        [[ 9.3166e-03]],\n               \n                        [[-4.2152e-02]]]])),\n              ('layer3.0.downsample.1.weight',\n               tensor([0.8793, 0.8252, 0.8813,  ..., 0.9008, 0.8689, 0.9230])),\n              ('layer3.0.downsample.1.bias',\n               tensor([-0.0433,  0.0210, -0.1012,  ...,  0.0217,  0.0075, -0.0037])),\n              ('layer3.0.downsample.1.running_mean',\n               tensor([-1.1992, -1.6832, -1.0310,  ..., -2.4559, -1.3677, -1.8506])),\n              ('layer3.0.downsample.1.running_var',\n               tensor([1.9236, 2.1002, 1.3206,  ..., 6.0192, 2.0721, 2.5512])),\n              ('layer3.0.downsample.1.num_batches_tracked', tensor(13572)),\n              ('layer3.1.conv1.weight',\n               tensor([[[[-0.0307]],\n               \n                        [[ 0.0288]],\n               \n                        [[-0.0222]],\n               \n                        ...,\n               \n                        [[-0.0091]],\n               \n                        [[-0.0020]],\n               \n                        [[ 0.0638]]],\n               \n               \n                       [[[ 0.0425]],\n               \n                        [[ 0.0079]],\n               \n                        [[-0.0839]],\n               \n                        ...,\n               \n                        [[-0.1050]],\n               \n                        [[ 0.0106]],\n               \n                        [[-0.0208]]],\n               \n               \n                       [[[ 0.0372]],\n               \n                        [[ 0.0337]],\n               \n                        [[ 0.0247]],\n               \n                        ...,\n               \n                        [[-0.0121]],\n               \n                        [[-0.0149]],\n               \n                        [[ 0.0636]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0374]],\n               \n                        [[-0.0508]],\n               \n                        [[ 0.0290]],\n               \n                        ...,\n               \n                        [[-0.0241]],\n               \n                        [[-0.0183]],\n               \n                        [[ 0.0111]]],\n               \n               \n                       [[[ 0.0161]],\n               \n                        [[ 0.0446]],\n               \n                        [[ 0.0198]],\n               \n                        ...,\n               \n                        [[-0.0257]],\n               \n                        [[ 0.0490]],\n               \n                        [[-0.0066]]],\n               \n               \n                       [[[-0.0518]],\n               \n                        [[-0.0050]],\n               \n                        [[-0.0311]],\n               \n                        ...,\n               \n                        [[-0.0101]],\n               \n                        [[-0.0145]],\n               \n                        [[-0.0003]]]])),\n              ('layer3.1.bn1.weight',\n               tensor([1.0288, 0.9863, 1.0457, 0.9812, 1.0310, 1.0120, 0.9734, 1.0130, 0.9921,\n                       0.9453, 0.9588, 1.0346, 0.9928, 0.9723, 0.9734, 1.0163, 0.9773, 0.9843,\n                       0.9673, 0.9772, 0.9584, 1.0271, 1.0299, 0.9393, 1.0021, 0.9869, 1.0016,\n                       0.9616, 0.9751, 0.9674, 1.0114, 0.9986, 0.9738, 0.9578, 0.9753, 1.0122,\n                       1.0368, 1.0019, 1.0391, 1.0120, 0.9901, 0.9985, 0.9752, 0.9392, 1.0168,\n                       0.9869, 0.9856, 1.0227, 0.9625, 0.9858, 0.9873, 1.0125, 0.9929, 1.0578,\n                       0.9618, 0.9652, 1.0300, 0.9563, 0.9909, 0.9927, 1.0130, 0.9753, 0.9852,\n                       1.0091, 0.9623, 0.9885, 0.9404, 0.9547, 1.0341, 1.0172, 0.9855, 1.0601,\n                       0.9617, 0.9028, 0.9730, 0.9822, 1.0289, 0.9179, 0.9998, 0.9872, 0.9701,\n                       1.0259, 0.9960, 0.9968, 0.9961, 0.9748, 1.0130, 0.9844, 0.9805, 0.9895,\n                       0.9693, 0.9707, 1.0620, 0.9720, 1.0296, 1.0204, 1.0232, 0.9724, 0.9837,\n                       0.9947, 1.0013, 1.0094, 1.0165, 1.0121, 1.0299, 1.0005, 0.9756, 0.9935,\n                       1.0211, 0.9848, 1.0382, 1.0341, 1.0123, 0.9536, 1.0530, 1.0418, 1.0168,\n                       0.9498, 0.9483, 1.0129, 1.0568, 0.9929, 0.9591, 1.0009, 0.9888, 1.0080,\n                       0.9620, 0.9657, 0.9932, 0.9998, 1.0111, 0.9960, 0.9727, 1.0559, 1.0078,\n                       1.0092, 0.9479, 1.0044, 0.9915, 0.9910, 1.0183, 0.9922, 0.9923, 0.9888,\n                       0.9852, 0.9470, 0.9915, 0.9613, 0.9597, 0.9828, 0.9951, 1.0158, 1.0045,\n                       1.0338, 0.9916, 1.0364, 0.9701, 1.0147, 1.0715, 1.0033, 0.9917, 0.9715,\n                       1.0293, 0.9727, 0.9946, 1.0137, 1.0055, 0.9666, 1.0106, 0.9772, 1.0205,\n                       0.9799, 0.9951, 1.0013, 1.0543, 1.0291, 0.9813, 0.9828, 0.9914, 1.0145,\n                       0.9710, 1.0359, 1.0240, 1.0491, 1.0227, 0.9689, 1.0110, 1.0362, 0.9947,\n                       0.9735, 1.0615, 1.0712, 0.9492, 0.9660, 1.0200, 0.9669, 0.9734, 1.0267,\n                       0.9576, 1.0032, 0.9659, 1.0241, 1.0212, 1.0493, 1.0227, 0.9708, 1.0393,\n                       1.0121, 1.0031, 0.9531, 1.0369, 0.9655, 0.9875, 1.0111, 1.0196, 1.0288,\n                       0.9920, 1.0334, 0.9638, 0.9893, 1.0075, 1.0110, 0.9945, 1.0720, 1.0260,\n                       1.0050, 1.0390, 1.0260, 0.9880, 0.9435, 1.0182, 1.0090, 0.9411, 1.0080,\n                       0.9975, 0.9813, 0.9884, 1.0050, 1.0185, 1.0078, 0.9992, 0.9914, 0.9835,\n                       1.0863, 1.0409, 1.0361, 1.0419, 1.0081, 1.0051, 0.9859, 0.9635, 1.0536,\n                       1.0861, 1.0008, 0.9706, 0.9764])),\n              ('layer3.1.bn1.bias',\n               tensor([-0.0677, -0.0332, -0.0686,  0.0181, -0.0419, -0.0007, -0.0524, -0.0191,\n                       -0.0150, -0.0641, -0.0702,  0.0160, -0.0280, -0.0522, -0.0203,  0.0330,\n                       -0.0277, -0.0368, -0.0599, -0.0300, -0.0037, -0.0195, -0.0476, -0.1154,\n                       -0.0378, -0.0724, -0.0857, -0.0579, -0.0681, -0.0086, -0.0197, -0.0565,\n                       -0.0598, -0.0284, -0.0610, -0.1198, -0.0021, -0.0435, -0.0200,  0.0237,\n                       -0.0561,  0.0032, -0.0270, -0.0719, -0.0234, -0.0544, -0.0832,  0.0134,\n                       -0.0646, -0.0395, -0.0723, -0.0367, -0.0444, -0.0683, -0.0665, -0.0567,\n                       -0.0248, -0.0941, -0.0016, -0.0043, -0.0629, -0.0425, -0.0390, -0.0252,\n                       -0.0464, -0.0317, -0.0612, -0.0969, -0.0040, -0.0568, -0.0647,  0.0050,\n                       -0.0746, -0.0477, -0.0170, -0.0877,  0.0105, -0.0880, -0.0885, -0.0586,\n                       -0.0091, -0.0541, -0.0096, -0.0492, -0.0296, -0.0458, -0.0874, -0.0415,\n                       -0.0477, -0.0808, -0.0682, -0.0578, -0.0189, -0.0491, -0.0515,  0.0147,\n                        0.0038, -0.0456, -0.0181, -0.0593,  0.0194, -0.0227, -0.0478, -0.0127,\n                       -0.0151, -0.0690, -0.0429,  0.0138, -0.0428,  0.0519, -0.0361, -0.0502,\n                       -0.0074, -0.0963, -0.0940,  0.0135, -0.0466, -0.1397, -0.0787,  0.0259,\n                       -0.0150, -0.0718, -0.0514, -0.0650, -0.0748, -0.0530, -0.0557, -0.0371,\n                       -0.0560, -0.0542, -0.0276, -0.0102, -0.0453,  0.0431, -0.0644, -0.0192,\n                       -0.0594, -0.0362, -0.0435, -0.0570, -0.0064, -0.0576, -0.0546, -0.0049,\n                       -0.0361, -0.0359, -0.0528, -0.0394, -0.0461,  0.0240, -0.0342, -0.0128,\n                       -0.0029, -0.0279, -0.0360, -0.0184, -0.0782, -0.0635,  0.0011, -0.0125,\n                       -0.0151, -0.0625,  0.0651, -0.0768, -0.0600, -0.0407, -0.0505, -0.0580,\n                       -0.0078, -0.0588, -0.0167, -0.0477, -0.0378, -0.0229,  0.0139, -0.0359,\n                       -0.1003,  0.0031, -0.0464, -0.0332, -0.0411, -0.0319, -0.0727, -0.0412,\n                       -0.0917, -0.0674, -0.0264, -0.0568, -0.0662, -0.0391,  0.0436, -0.0191,\n                       -0.0844, -0.1495, -0.0705, -0.0833, -0.0575, -0.0217, -0.0419,  0.0024,\n                       -0.0480, -0.0063, -0.0071, -0.1124,  0.0064, -0.0832, -0.0073, -0.0759,\n                       -0.0185, -0.0488, -0.0109, -0.0487, -0.0527,  0.0022, -0.0563, -0.0962,\n                       -0.0093, -0.0139, -0.0604, -0.0311, -0.0394, -0.0603, -0.0766,  0.0149,\n                       -0.0396, -0.0715, -0.0784, -0.0585, -0.0253, -0.0750, -0.0399,  0.0005,\n                       -0.0838, -0.0652, -0.0311, -0.0488, -0.0595, -0.0737, -0.0381, -0.0089,\n                       -0.0562, -0.0820, -0.0522, -0.0602, -0.0417,  0.0069,  0.0032, -0.0026,\n                       -0.0980, -0.0249, -0.0631, -0.0708, -0.0303, -0.0917, -0.0489, -0.0655])),\n              ('layer3.1.bn1.running_mean',\n               tensor([-4.0775e-01, -2.0382e-01, -1.1319e-01, -7.9759e-01, -6.9952e-01,\n                       -1.0435e+00, -8.1684e-01, -2.6332e-03, -3.3051e-01, -5.4036e-01,\n                       -7.7439e-02, -7.2007e-01, -7.0696e-01, -1.4412e-01, -7.4417e-01,\n                       -1.2661e+00, -4.0156e-01, -1.0949e-01,  7.4104e-01, -8.3413e-02,\n                        4.7621e-01, -6.5848e-02,  3.6405e-01,  1.3238e-01, -4.2056e-01,\n                        1.0504e+00,  8.1901e-01,  1.6243e-02,  1.6875e-02, -4.2170e-01,\n                       -3.4169e-01, -1.3032e-02, -1.9799e-01, -2.0067e-01,  2.9809e-01,\n                       -2.0644e-01, -6.8764e-02,  2.7968e-01,  6.3347e-02, -4.1267e-01,\n                        1.2160e-01, -2.7390e-01, -3.9194e-01, -1.5578e-01,  9.9726e-02,\n                       -2.8196e-02,  1.8490e-01, -2.4319e-01, -1.6156e-01, -6.0096e-01,\n                       -2.2691e-01, -7.8307e-01, -1.5875e-03, -5.4728e-01, -5.7594e-01,\n                        1.0330e-02, -6.1216e-01, -4.4689e-01, -4.4266e-01, -3.5018e-01,\n                        1.0143e+00,  9.5036e-02, -4.7805e-01, -5.0492e-01, -9.5935e-01,\n                       -8.8118e-01, -4.4888e-01, -4.5488e-01, -3.9200e-01,  3.7576e-01,\n                        3.3379e-01,  3.0197e-01,  7.5313e-01,  1.8557e-01, -5.8135e-01,\n                        3.7031e-01, -6.0751e-01,  1.4668e-01, -3.1408e-02, -4.4043e-01,\n                        1.3867e-01, -2.5292e-01, -6.0689e-01,  5.9909e-01,  2.8286e-01,\n                        1.2653e+00, -1.8667e-01, -4.9262e-01, -6.9165e-01,  7.1419e-01,\n                        2.4793e-01,  5.9687e-01,  9.5294e-02,  4.6499e-01,  3.8657e-01,\n                       -3.6626e-01, -3.4438e-01,  1.8927e-01,  1.4602e-01, -1.5251e-01,\n                        1.5628e-02, -5.4459e-01, -1.3465e+00, -4.9632e-01,  1.6647e-02,\n                       -1.5551e-01,  6.7017e-02, -7.5165e-01,  1.6163e-01, -6.4803e-01,\n                        1.8617e-02, -2.4758e-01,  2.1425e-01,  2.5890e-01, -1.2028e-03,\n                       -4.9380e-02,  3.0466e-01, -3.4763e-02,  4.2816e-01, -1.0683e+00,\n                       -3.2072e-01, -8.8080e-01,  7.1442e-02,  3.5015e-01, -2.1050e-01,\n                        8.6193e-02, -1.4051e-02,  1.0348e-01, -4.4015e-01, -1.3936e-01,\n                       -6.9318e-01, -7.8069e-02,  5.3857e-01,  1.2111e-02,  1.7787e-01,\n                       -1.8700e-01,  3.9707e-01, -1.0080e-02,  3.9104e-01,  3.6770e-01,\n                       -5.7970e-01, -9.9535e-02,  9.7470e-02, -3.7533e-02, -7.7562e-01,\n                        4.7492e-01,  2.2849e-02, -8.8644e-02, -8.0492e-01, -1.2636e-01,\n                        2.2514e-01, -5.0049e-01, -7.6062e-02, -2.3371e-01, -1.0491e-01,\n                       -2.6527e-01,  7.3045e-01, -2.0078e-01, -5.7452e-01, -4.1744e-01,\n                       -1.0258e+00,  5.8801e-01, -6.2878e-01, -1.6189e-01, -4.1527e-03,\n                        7.0517e-02,  4.5093e-01, -2.9029e-01,  1.0512e-02, -6.6497e-01,\n                       -7.2894e-01, -4.6755e-02, -3.2214e-02,  7.0547e-02,  3.6097e-02,\n                       -2.3635e-01,  2.3399e-01, -3.7584e-01, -2.2919e-01, -8.0238e-01,\n                       -1.9683e-01, -2.6782e-01,  4.9405e-01,  4.1815e-02,  2.4998e-01,\n                       -3.5208e-02,  1.3510e-01, -1.4057e+00, -3.8471e-01,  1.3632e-01,\n                       -6.7162e-01, -3.0870e-01, -7.9909e-01, -2.8133e-03,  2.0186e-01,\n                       -4.3397e-01, -9.8269e-01, -2.1089e-01,  6.7789e-01, -2.1118e-01,\n                       -5.5104e-02,  3.4682e-01, -1.1322e-01, -1.3061e-01, -5.2198e-01,\n                       -3.5681e-01, -5.1591e-01, -9.3994e-02, -3.0440e-01, -2.5987e-01,\n                       -3.9053e-01, -5.9386e-01, -5.5552e-01, -7.0282e-01, -5.1354e-02,\n                        5.3839e-01, -8.4467e-02, -5.3451e-01,  7.0848e-01, -8.9564e-01,\n                        5.1282e-02, -5.7855e-02, -1.9750e-01, -7.9169e-02, -1.9831e-01,\n                       -3.2335e-02, -1.3190e-01, -2.7055e-01,  1.3461e-01, -4.2601e-01,\n                        2.2640e-01, -5.2456e-01, -2.4468e-02, -4.8816e-01, -4.6735e-01,\n                        3.6574e-01,  9.1265e-02,  4.1835e-01, -3.9964e-01,  8.6230e-01,\n                        2.1094e-01,  4.3554e-01,  2.6778e-01, -9.7891e-02, -3.7743e-01,\n                        1.6932e-02, -3.3149e-01,  3.0942e-02, -2.3351e-01, -3.7454e-01,\n                       -4.2009e-01, -2.7564e-01, -2.4016e-01,  4.1539e-03, -3.0912e-01,\n                        3.7819e-01])),\n              ('layer3.1.bn1.running_var',\n               tensor([0.4341, 0.4458, 0.4204, 0.4013, 0.5509, 0.5645, 0.4090, 0.3978, 0.6258,\n                       0.3860, 0.5347, 0.4368, 0.4919, 0.3631, 0.3896, 0.5379, 0.4617, 0.5691,\n                       0.6357, 0.4048, 0.5291, 0.5093, 0.5715, 0.4302, 0.5048, 0.4299, 0.7308,\n                       0.4288, 0.3936, 0.4283, 0.6481, 0.3828, 0.4861, 0.5296, 0.5210, 0.4421,\n                       0.5377, 0.4207, 0.6737, 0.4779, 0.4111, 0.3903, 0.4621, 0.5898, 0.3874,\n                       0.4150, 0.5304, 0.4345, 0.5527, 0.4244, 0.5111, 0.5156, 0.3479, 0.6366,\n                       0.5793, 0.5705, 0.5651, 0.3972, 0.3620, 0.7579, 0.6487, 0.5842, 0.3869,\n                       0.5217, 0.4444, 0.4177, 0.4860, 0.5875, 0.5260, 0.4892, 0.3833, 0.4490,\n                       0.5958, 0.6153, 0.4775, 0.5014, 0.4617, 0.3512, 0.5935, 0.4760, 0.4775,\n                       0.3606, 0.3863, 0.4779, 0.4774, 0.5943, 0.5486, 0.5777, 0.4758, 0.5786,\n                       0.5160, 0.4606, 0.5240, 0.5213, 0.4694, 0.3310, 0.5200, 0.3837, 0.3566,\n                       0.4458, 0.4726, 0.6341, 0.4799, 0.5202, 0.4442, 0.5047, 0.4178, 0.4493,\n                       0.3694, 0.4407, 0.5821, 0.5767, 0.4978, 0.4619, 0.5911, 0.5882, 0.4131,\n                       0.4498, 0.6265, 0.4951, 0.5312, 0.3426, 0.4919, 0.4739, 0.5965, 0.4493,\n                       0.4711, 0.4644, 0.4734, 0.5187, 0.5215, 0.4006, 0.4985, 0.5489, 0.5240,\n                       0.5639, 0.5366, 0.4180, 0.5287, 0.4650, 0.5289, 0.4227, 0.4219, 0.4498,\n                       0.4582, 0.4765, 0.4064, 0.4530, 0.3920, 0.5678, 0.3759, 0.4929, 0.3802,\n                       0.5087, 0.4868, 0.5758, 0.4999, 0.5543, 0.4712, 0.4885, 0.3838, 0.4563,\n                       0.4597, 0.3685, 0.5490, 0.4565, 0.4267, 0.4186, 0.4577, 0.5050, 0.4377,\n                       0.2803, 0.4133, 0.5549, 0.3859, 0.4823, 0.4479, 0.4460, 0.4344, 0.4537,\n                       0.6143, 0.4097, 0.6113, 0.6226, 0.4385, 0.5012, 0.6974, 0.5913, 0.6474,\n                       0.5000, 0.4893, 0.6010, 0.4730, 0.3818, 0.5754, 0.3739, 0.4687, 0.4953,\n                       0.4994, 0.4024, 0.4046, 0.6553, 0.4515, 0.5235, 0.4817, 0.4030, 0.4967,\n                       0.4803, 0.5403, 0.4603, 0.5371, 0.4759, 0.4025, 0.3479, 0.4572, 0.4619,\n                       0.4484, 0.5667, 0.5796, 0.4112, 0.3740, 0.4379, 0.4223, 0.4443, 0.4994,\n                       0.5272, 0.5195, 0.4547, 0.3415, 0.4309, 0.3177, 0.5245, 0.5736, 0.4332,\n                       0.4510, 0.5355, 0.5169, 0.5270, 0.5234, 0.5531, 0.4140, 0.6120, 0.5586,\n                       0.5847, 0.6930, 0.5953, 0.4429, 0.5001, 0.4316, 0.3656, 0.4035, 0.6035,\n                       0.5495, 0.5825, 0.4466, 0.5014])),\n              ('layer3.1.bn1.num_batches_tracked', tensor(13572)),\n              ('layer3.1.conv2.weight',\n               tensor([[[[-3.9254e-02, -1.4513e-02, -6.0010e-02],\n                         [-7.1544e-03, -8.1212e-02, -1.3943e-02],\n                         [-3.7272e-02, -5.3339e-02, -2.9250e-02]],\n               \n                        [[ 1.4684e-02,  6.9175e-02,  2.8368e-02],\n                         [ 1.8266e-02,  1.3841e-02,  2.3836e-02],\n                         [ 1.1643e-02, -2.3841e-03, -6.7257e-03]],\n               \n                        [[ 1.9258e-02, -5.7941e-03, -6.3541e-03],\n                         [-1.3364e-02, -2.7159e-02,  1.3226e-02],\n                         [ 2.8144e-02, -1.5114e-04,  3.5819e-03]],\n               \n                        ...,\n               \n                        [[-1.1906e-03,  7.0549e-03,  1.8804e-02],\n                         [ 2.6152e-04,  6.1772e-02,  2.5839e-02],\n                         [-1.1556e-02,  5.8033e-03, -6.1180e-03]],\n               \n                        [[-1.7450e-02,  4.2356e-02,  2.7686e-02],\n                         [ 1.4589e-02,  4.2995e-02,  2.6544e-02],\n                         [ 2.2310e-02, -4.6707e-02,  3.5664e-03]],\n               \n                        [[-6.8288e-03, -5.5023e-02, -1.7900e-02],\n                         [-2.5030e-02, -1.4334e-02, -2.7996e-02],\n                         [-1.0664e-02, -5.3369e-02, -2.5835e-02]]],\n               \n               \n                       [[[-1.7126e-02, -3.3967e-02, -2.4377e-02],\n                         [-3.0786e-02,  8.9720e-03, -5.6546e-02],\n                         [ 2.6539e-04, -1.6083e-02,  4.7892e-03]],\n               \n                        [[-8.8026e-03, -1.9831e-02, -4.2782e-02],\n                         [ 1.2662e-02,  4.1085e-02, -1.2768e-02],\n                         [-2.4150e-02,  1.5040e-02, -5.4130e-02]],\n               \n                        [[ 7.9597e-03, -2.4501e-02, -2.4056e-02],\n                         [ 6.4862e-02, -3.5216e-02,  4.4001e-02],\n                         [ 1.5408e-02,  1.0342e-02, -2.8882e-02]],\n               \n                        ...,\n               \n                        [[ 4.1100e-02, -1.2106e-02,  9.3368e-04],\n                         [ 2.3812e-02,  5.6130e-02,  5.2768e-02],\n                         [ 5.0859e-02,  7.2740e-02,  5.9755e-02]],\n               \n                        [[ 3.9227e-02,  3.8678e-02,  4.6874e-03],\n                         [ 2.5175e-02,  4.5885e-04,  3.4089e-02],\n                         [-3.0255e-03,  3.1119e-02, -8.8241e-03]],\n               \n                        [[-3.4181e-02, -3.1093e-02, -2.4761e-03],\n                         [-2.8280e-02, -2.5160e-02, -1.0108e-02],\n                         [-1.0334e-02,  1.3465e-02, -3.2701e-02]]],\n               \n               \n                       [[[ 3.3614e-02,  2.3878e-02,  5.1628e-03],\n                         [ 6.3905e-02, -3.1527e-02, -1.3337e-03],\n                         [-5.5007e-03,  5.8653e-02,  1.3600e-02]],\n               \n                        [[-3.0281e-02,  2.5222e-02,  8.1185e-03],\n                         [ 7.6530e-03,  8.8063e-03,  4.3789e-02],\n                         [ 1.8264e-02,  4.4457e-02, -8.6435e-03]],\n               \n                        [[-1.6418e-02, -2.5502e-02, -3.0674e-03],\n                         [-7.6047e-02,  1.8207e-03,  9.3485e-03],\n                         [-2.4266e-02, -1.1134e-02, -9.2828e-03]],\n               \n                        ...,\n               \n                        [[-6.8881e-03,  1.6369e-02,  3.1584e-02],\n                         [ 7.1562e-03,  2.4120e-02, -5.6565e-03],\n                         [-2.0046e-02, -2.3121e-02,  5.4630e-03]],\n               \n                        [[ 3.3820e-02,  7.5666e-02,  3.6529e-02],\n                         [-4.7667e-03, -7.5126e-05,  1.1918e-02],\n                         [-3.0059e-02, -8.9184e-03, -2.7806e-02]],\n               \n                        [[ 9.3683e-03, -2.4222e-02, -1.0449e-02],\n                         [-6.0883e-02, -2.5253e-02, -6.7310e-02],\n                         [-1.9615e-02, -2.0462e-02, -2.3214e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-4.4090e-03,  1.0857e-02, -4.6322e-03],\n                         [ 3.3637e-02, -2.7485e-03,  1.7330e-02],\n                         [ 2.5775e-02,  7.6032e-03,  2.6636e-02]],\n               \n                        [[-1.5679e-02, -1.3645e-02, -2.9014e-02],\n                         [-1.3463e-02, -2.7434e-02, -2.4954e-02],\n                         [ 2.0658e-02,  1.2310e-02,  1.3808e-02]],\n               \n                        [[-3.4293e-02,  1.2963e-02,  2.0318e-02],\n                         [ 3.8683e-02,  7.3270e-03, -1.7929e-02],\n                         [ 3.0815e-03,  3.1514e-03, -2.2425e-02]],\n               \n                        ...,\n               \n                        [[ 3.3540e-02,  3.4752e-03,  9.6262e-03],\n                         [ 1.7169e-02,  7.5156e-03, -1.3103e-02],\n                         [ 4.2323e-02,  1.8248e-02, -1.8656e-02]],\n               \n                        [[ 2.0034e-02, -2.8338e-02,  3.3811e-02],\n                         [ 1.2063e-02, -2.6087e-02,  1.1481e-02],\n                         [ 2.3922e-02, -1.2311e-02,  1.5337e-02]],\n               \n                        [[ 1.8975e-02,  1.8836e-02,  1.5439e-02],\n                         [ 2.5680e-02, -1.3274e-02,  1.2411e-02],\n                         [-9.7903e-03, -3.4530e-02,  2.6772e-03]]],\n               \n               \n                       [[[-2.3286e-02, -1.8075e-02,  2.4302e-02],\n                         [-2.4436e-03, -1.7178e-02, -9.5733e-03],\n                         [-2.0791e-03, -9.7196e-03,  6.4226e-03]],\n               \n                        [[ 6.0665e-03, -5.2592e-03,  5.4187e-03],\n                         [ 4.3147e-02, -1.9656e-03, -4.7068e-03],\n                         [-2.2448e-02, -2.6248e-02,  3.0851e-03]],\n               \n                        [[-4.7552e-03, -1.7886e-02, -3.6452e-02],\n                         [-5.4049e-02, -8.8212e-02, -3.1539e-03],\n                         [-2.0802e-02, -2.5236e-02,  3.1197e-02]],\n               \n                        ...,\n               \n                        [[ 2.1282e-02,  8.5515e-03,  8.8495e-03],\n                         [ 3.2076e-03,  2.8622e-02,  1.4264e-02],\n                         [-1.3263e-03,  4.7118e-03,  3.4518e-02]],\n               \n                        [[ 2.6124e-02,  2.9026e-03,  1.6454e-02],\n                         [ 2.5165e-02, -1.1353e-02,  2.5503e-02],\n                         [ 1.7364e-02,  1.3498e-02,  3.1996e-02]],\n               \n                        [[-1.5600e-02, -1.5027e-03, -7.3418e-03],\n                         [-5.4257e-03,  1.2747e-02,  3.2720e-03],\n                         [ 2.7291e-02,  5.0475e-02, -8.4643e-03]]],\n               \n               \n                       [[[ 4.4617e-02,  4.0796e-03,  6.1399e-03],\n                         [ 5.0575e-02,  9.0564e-04, -5.8817e-03],\n                         [-3.8382e-02, -2.6981e-03, -1.6723e-02]],\n               \n                        [[ 1.3884e-02, -3.7417e-02, -4.5841e-03],\n                         [-4.0414e-02, -1.3718e-02, -4.6031e-02],\n                         [ 6.0408e-03, -1.4813e-02, -1.0789e-02]],\n               \n                        [[ 1.2200e-02,  3.2159e-02,  1.2822e-02],\n                         [ 2.7527e-02, -9.5924e-03,  1.0361e-02],\n                         [ 7.7824e-03, -4.2864e-03,  1.0973e-02]],\n               \n                        ...,\n               \n                        [[-1.6953e-02, -3.5908e-02, -2.2882e-02],\n                         [-5.7616e-04,  4.7708e-03, -3.3241e-02],\n                         [-5.6541e-02, -1.6769e-02, -2.6708e-02]],\n               \n                        [[-7.3444e-03, -3.0903e-02,  1.9360e-02],\n                         [-1.9223e-03,  2.5468e-02, -1.5829e-02],\n                         [ 2.6762e-02, -4.9177e-03, -1.7293e-02]],\n               \n                        [[-2.2073e-02,  2.1675e-02, -1.9611e-02],\n                         [ 1.6410e-02,  1.4705e-02,  1.7584e-02],\n                         [-2.9026e-03, -4.4010e-03,  2.3023e-02]]]])),\n              ('layer3.1.bn2.weight',\n               tensor([0.9727, 0.9782, 0.9650, 1.0182, 1.0417, 1.0026, 0.9836, 1.0528, 0.9920,\n                       1.0386, 1.0027, 0.9760, 0.9652, 0.9752, 0.9775, 0.9564, 0.9594, 1.0341,\n                       1.0718, 1.0010, 0.9941, 0.9555, 0.9896, 0.9624, 0.9653, 0.9683, 0.9624,\n                       0.9701, 0.9958, 0.9567, 1.0155, 0.9603, 0.9930, 0.9920, 0.9775, 1.0076,\n                       0.9342, 1.0295, 0.9836, 0.9828, 0.9206, 0.9686, 1.0415, 0.9640, 1.0251,\n                       1.0056, 1.0131, 1.0152, 0.9683, 0.9401, 1.0613, 1.0171, 1.0309, 1.0018,\n                       0.9396, 0.9506, 1.0389, 0.9498, 0.9519, 0.9611, 0.9895, 0.9446, 1.0124,\n                       1.0417, 0.9821, 1.0741, 0.9824, 0.9865, 0.9621, 0.9847, 0.9880, 0.9734,\n                       0.9572, 0.9942, 0.9307, 1.0031, 1.0158, 1.0305, 0.9725, 0.9592, 0.9613,\n                       0.9731, 1.0039, 0.9655, 1.0057, 0.9294, 0.9861, 0.9903, 1.0624, 1.0526,\n                       0.9452, 0.9553, 0.9264, 0.9777, 0.9611, 0.9770, 0.9701, 0.9713, 1.0244,\n                       0.9801, 1.2149, 0.9422, 1.0273, 0.9386, 1.0120, 1.0032, 0.9957, 0.9301,\n                       1.0891, 0.9409, 0.9841, 0.9746, 0.9726, 1.0380, 0.9845, 1.0219, 0.9741,\n                       0.9129, 1.0135, 0.9695, 0.9779, 0.9738, 0.9220, 0.9416, 1.0032, 1.0049,\n                       1.0286, 1.0978, 1.1033, 1.0006, 1.1063, 0.9622, 0.9749, 0.9904, 0.9727,\n                       0.9942, 1.0759, 0.9919, 1.0485, 1.0065, 0.9842, 1.0230, 0.9663, 0.9736,\n                       0.9921, 0.9634, 1.0604, 1.0224, 0.9830, 1.0014, 1.0134, 0.9469, 1.0028,\n                       1.0025, 0.9433, 0.9541, 0.9606, 1.0058, 0.9915, 0.9803, 1.0385, 1.0064,\n                       1.0080, 0.9821, 1.0488, 0.9424, 1.0086, 0.9292, 1.0136, 0.9476, 0.9695,\n                       1.0347, 0.9493, 0.9993, 0.9684, 1.0112, 0.9561, 0.9750, 1.0237, 0.9896,\n                       0.9809, 1.0181, 1.0426, 1.0604, 1.0020, 1.0149, 1.0248, 1.0430, 0.9575,\n                       1.0006, 0.9705, 0.9348, 1.0043, 1.0160, 0.9677, 0.9989, 0.9185, 0.9484,\n                       0.9162, 0.9553, 0.9615, 1.0070, 1.0214, 0.9919, 0.9771, 0.9801, 1.0045,\n                       0.9750, 0.9961, 0.9941, 1.0715, 1.1108, 1.0028, 0.9492, 0.9789, 0.9847,\n                       0.9761, 1.0080, 0.9457, 0.9973, 0.9746, 0.9826, 0.9709, 1.0121, 0.9626,\n                       1.0287, 0.9786, 0.9684, 1.0425, 0.9564, 0.9817, 1.0238, 0.9701, 0.9970,\n                       0.9814, 1.0114, 1.0167, 0.9541, 1.0799, 1.0350, 0.9957, 0.9982, 1.0334,\n                       0.9991, 0.9710, 0.9717, 0.9909, 0.9932, 0.9768, 0.9869, 0.9786, 0.9653,\n                       0.9783, 1.0020, 0.9982, 0.9838])),\n              ('layer3.1.bn2.bias',\n               tensor([-0.0229, -0.0862, -0.0653, -0.0273, -0.0877, -0.1500, -0.1098, -0.0273,\n                       -0.0787, -0.0259, -0.1766, -0.0651, -0.1785, -0.1075, -0.0233, -0.1120,\n                       -0.0547, -0.0909, -0.0164, -0.0415, -0.1166, -0.1272, -0.0949, -0.0693,\n                       -0.0696, -0.1125, -0.1561, -0.0807, -0.0509, -0.0329, -0.0278, -0.0980,\n                       -0.1002, -0.0910, -0.0838, -0.0961, -0.0310, -0.0704, -0.0933, -0.1491,\n                       -0.0900, -0.0798, -0.0846, -0.0552, -0.0498, -0.0464, -0.1025, -0.0483,\n                       -0.0283, -0.0654, -0.0337, -0.1126, -0.0027, -0.0535, -0.1024, -0.0684,\n                       -0.1122, -0.0702, -0.0995, -0.0794, -0.0292, -0.0467, -0.0891, -0.0629,\n                       -0.0967, -0.0880, -0.0736, -0.0265, -0.0430, -0.0464, -0.0302, -0.0590,\n                       -0.0566, -0.1265, -0.0991, -0.0566, -0.0657, -0.1016, -0.0988, -0.1159,\n                       -0.0836, -0.0961, -0.0652, -0.1142, -0.1240, -0.0830, -0.0500, -0.1283,\n                       -0.1583, -0.1265, -0.0204, -0.1269, -0.0848, -0.0902, -0.0237, -0.1256,\n                       -0.0907, -0.0840, -0.1024, -0.1235,  0.0940, -0.1264, -0.0853, -0.1164,\n                       -0.0941, -0.1752, -0.0960, -0.0798, -0.1797, -0.0932, -0.1149, -0.0972,\n                       -0.0528, -0.1575, -0.0617, -0.0547, -0.1364, -0.1047, -0.0681, -0.0938,\n                       -0.0773, -0.0687, -0.1082, -0.1069, -0.0997, -0.0724, -0.0464,  0.0015,\n                       -0.1469, -0.1061, -0.2368, -0.1162, -0.0350, -0.1338, -0.0786, -0.1714,\n                       -0.0991, -0.1077, -0.0807, -0.0718, -0.1689, -0.0888, -0.0672, -0.2270,\n                       -0.0790, -0.0916, -0.2120, -0.0170, -0.0794, -0.0718, -0.0831, -0.0627,\n                        0.0004, -0.1141, -0.0937, -0.1661, -0.0706, -0.0201, -0.0042, -0.1103,\n                       -0.1333, -0.0495, -0.1219, -0.1372, -0.1469, -0.0465, -0.0855, -0.0906,\n                       -0.0838, -0.0627, -0.0883, -0.0584, -0.0558, -0.0370, -0.0654, -0.1120,\n                       -0.0819, -0.0775, -0.2570, -0.0764, -0.1271, -0.1773, -0.0930, -0.0734,\n                       -0.1020, -0.0628, -0.1355, -0.1367, -0.0460, -0.0809, -0.0548, -0.1058,\n                       -0.1133, -0.1178, -0.1288, -0.0805, -0.0635, -0.0587, -0.0795, -0.1079,\n                       -0.1249, -0.0885, -0.1399, -0.1078, -0.1077, -0.1233, -0.0774, -0.0598,\n                       -0.0504, -0.1531, -0.1157, -0.1353, -0.1437, -0.1234, -0.0674, -0.1335,\n                       -0.1029, -0.0950, -0.0674, -0.1091, -0.1163, -0.1023, -0.1028, -0.1693,\n                       -0.1596, -0.0721, -0.0963, -0.0818, -0.0502, -0.0783, -0.1449, -0.0875,\n                       -0.1087, -0.0404, -0.1348, -0.1147, -0.0340, -0.0601, -0.1059, -0.0847,\n                       -0.0614, -0.0125, -0.0420, -0.1443, -0.0630, -0.0845, -0.1103, -0.1269,\n                       -0.0475, -0.1745, -0.0568, -0.0583, -0.0449, -0.1133, -0.0764, -0.0829])),\n              ('layer3.1.bn2.running_mean',\n               tensor([-8.7089e-01, -7.2481e-01, -4.4883e-01, -2.0385e+00, -7.0495e-01,\n                       -1.3535e+00, -3.6581e-01, -9.8914e-01, -1.4439e+00,  1.1853e-03,\n                       -4.2863e-01, -1.2894e-01, -4.1440e-02, -9.5436e-01, -1.1844e+00,\n                       -6.5495e-01,  1.7323e+00,  3.6768e-02, -1.1354e+00, -6.3549e-01,\n                       -1.3008e+00, -2.4703e-01, -5.1851e-02,  3.4801e-01,  1.1194e+00,\n                        4.1757e-02, -7.3593e-01, -8.5439e-02,  1.4522e+00,  1.1166e+00,\n                        1.5656e-01, -5.8287e-01, -7.8092e-02, -8.4396e-01, -2.8662e-01,\n                       -1.6436e+00, -1.6787e-01, -5.7706e-02, -4.3412e-01, -3.8143e-01,\n                       -1.1755e-01, -5.1554e-01, -5.5876e-01, -1.7938e-01, -8.5666e-01,\n                       -2.1065e-01, -3.9308e-01, -7.7889e-01, -5.5878e-01,  2.1754e-01,\n                       -1.3524e+00, -1.1170e+00, -4.4722e-01, -7.0707e-01, -4.7792e-01,\n                        2.1827e-01, -1.5868e-01,  2.1526e-01, -8.7663e-01, -3.6346e-01,\n                       -7.2681e-01,  1.2177e-02,  4.3110e-01,  9.2379e-03, -1.1354e-01,\n                        1.7817e+00, -3.5885e-01, -3.5599e-01, -5.1044e-01,  1.7349e-01,\n                       -5.1292e-03, -6.8508e-01, -1.1204e+00, -1.1835e+00, -8.9512e-01,\n                       -6.3060e-01, -1.1915e+00,  1.5691e-01,  5.4953e-02,  7.2595e-02,\n                        6.9002e-01, -1.6618e+00, -8.6394e-01, -3.7525e-01,  1.7932e-01,\n                        1.2720e-01,  2.9491e-01,  1.9372e-01, -5.9021e-01, -5.3340e-02,\n                        2.1788e-01, -8.2747e-01, -6.5789e-02, -3.2891e-01,  6.5979e-02,\n                       -1.3768e+00, -8.9656e-01,  4.3652e-01, -2.8018e-01, -5.4519e-01,\n                        6.4920e-02, -6.6543e-01, -4.7349e-01, -4.8224e-01,  6.3997e-02,\n                       -6.9450e-01,  9.4679e-01,  1.4466e-01, -2.3755e-01,  2.8932e-02,\n                       -4.4692e-01, -1.6015e+00, -1.3323e+00, -6.2775e-01,  4.1042e-01,\n                       -6.3646e-01, -4.6516e-01,  4.2373e-01,  3.1963e-01, -2.8349e-01,\n                       -9.6784e-01, -3.1997e-02,  1.0419e+00, -8.0364e-02, -8.0488e-01,\n                        1.5827e+00, -1.9129e+00,  8.7651e-02, -2.9953e-01, -3.3008e-01,\n                       -3.4876e-03, -1.5823e-02,  9.7680e-03, -2.7427e-01,  4.6712e-01,\n                        1.9517e-01,  9.4081e-01, -4.9200e-01,  2.6970e-01, -1.1665e+00,\n                       -1.8118e-01,  9.6272e-01, -6.2438e-01, -7.2490e-01, -2.9814e-01,\n                       -9.6505e-01, -1.8469e-01,  1.8385e-01, -1.1647e+00, -1.1170e+00,\n                       -6.1339e-01,  8.0906e-01, -1.2580e+00, -1.2871e+00, -1.8223e-01,\n                       -3.1428e-01, -1.2881e-01, -2.6408e-01, -1.3068e-01, -1.0730e+00,\n                       -1.8584e-01, -6.5919e-01, -2.9133e-01, -4.5378e-01, -1.9250e+00,\n                        3.7806e-01, -7.9841e-02,  5.6059e-01, -8.5724e-01,  2.5293e-01,\n                        1.3650e+00, -5.2990e-01, -1.1128e-01, -1.0302e+00, -6.8322e-01,\n                       -1.1945e+00,  8.1441e-01, -7.6280e-01,  1.0217e-01, -9.6398e-01,\n                       -1.0731e+00, -6.1779e-01, -1.1281e-01, -7.2173e-01, -6.4587e-01,\n                       -8.7364e-01, -1.7978e-01, -1.0303e+00,  8.8403e-01, -1.8151e+00,\n                       -8.8951e-01, -5.8383e-01, -1.6394e-01, -6.6661e-01,  4.5420e-01,\n                        3.5043e-01,  3.5174e-01, -7.5505e-01,  8.4229e-01,  1.6605e-01,\n                       -3.1665e-02, -2.4564e-01, -1.0920e+00, -9.1351e-01,  2.9611e-01,\n                        2.5212e-01, -2.7913e-01, -1.1651e+00, -9.0532e-01, -6.1237e-01,\n                        8.9913e-02,  2.0341e+00, -6.7781e-02, -3.7375e-01, -8.1566e-01,\n                       -3.0442e-01, -9.3046e-01, -4.5745e-01,  1.3673e+00, -1.1661e+00,\n                        4.4138e-01,  4.4256e-02, -1.2089e+00,  7.0957e-02, -5.8924e-01,\n                       -1.0516e+00, -6.2280e-01, -3.7498e-02, -2.7763e-01, -7.5126e-01,\n                        1.0291e-01, -4.8707e-01,  2.8734e-01, -8.8151e-01, -2.1098e-01,\n                       -3.2067e-01,  6.1485e-02, -3.1295e-02,  5.7003e-01, -5.2456e-01,\n                       -1.3220e+00, -6.7247e-01, -4.9369e-01, -6.2262e-01,  2.5598e-01,\n                        2.1084e-01, -8.7196e-01, -9.7834e-01,  6.6416e-02,  1.9274e-01,\n                       -5.1831e-02, -1.1197e+00, -4.0226e-01, -6.2090e-01, -6.7690e-02,\n                       -5.2882e-01])),\n              ('layer3.1.bn2.running_var',\n               tensor([1.3948, 1.5074, 1.0931, 1.0797, 1.2543, 1.6857, 1.0920, 1.5974, 1.0367,\n                       0.9795, 2.0963, 0.8631, 1.5299, 2.1931, 1.1181, 1.2191, 1.6232, 1.2194,\n                       1.2404, 1.0283, 1.6039, 0.9486, 1.4549, 1.8383, 1.3437, 1.1167, 1.6866,\n                       1.1949, 1.6242, 1.0209, 1.0303, 1.2652, 1.3072, 1.5763, 1.4305, 1.3109,\n                       0.8302, 1.9588, 1.1792, 2.1165, 0.9945, 1.1056, 1.8794, 1.1196, 1.1659,\n                       1.1991, 1.8384, 1.0369, 1.8102, 0.9787, 1.3912, 1.8145, 1.2446, 1.4846,\n                       1.1774, 1.2387, 1.8041, 1.1159, 1.4272, 1.5481, 1.3208, 1.0848, 1.6950,\n                       1.2396, 1.1284, 1.8580, 1.1559, 1.1724, 0.9660, 0.9777, 1.1493, 1.1440,\n                       1.4262, 1.6470, 1.0195, 1.5995, 1.2819, 1.1621, 1.1061, 1.1111, 1.2785,\n                       1.4580, 1.2103, 1.5992, 1.9573, 1.3419, 1.2492, 1.1661, 1.1618, 2.4734,\n                       0.8841, 1.4408, 1.1710, 1.0980, 0.9979, 1.1749, 1.6340, 1.1703, 1.4270,\n                       1.2333, 2.4759, 1.0308, 1.1395, 1.1792, 1.1095, 1.3635, 1.7092, 1.3192,\n                       1.8145, 1.0193, 1.3460, 1.1031, 1.6080, 1.8690, 1.5194, 1.7777, 2.1574,\n                       1.1258, 1.1383, 1.0818, 1.0991, 0.9539, 1.0548, 1.2077, 1.4246, 2.3016,\n                       2.3130, 1.9522, 1.6474, 1.4490, 1.9745, 1.2624, 1.2241, 1.8859, 1.7586,\n                       1.7126, 1.5169, 1.6840, 1.7851, 1.7301, 1.6120, 1.3098, 1.1028, 1.3340,\n                       1.1335, 1.4024, 2.0984, 1.1319, 1.4066, 1.1134, 1.3515, 1.0201, 0.8690,\n                       1.4443, 1.0202, 1.5086, 1.0929, 0.9969, 0.9397, 1.0446, 1.3896, 0.9482,\n                       1.5615, 2.0549, 1.5003, 0.9807, 1.3827, 1.2231, 1.1472, 1.1183, 1.9885,\n                       1.7107, 1.1755, 1.4144, 0.8947, 2.0748, 1.0995, 1.4367, 1.1967, 1.3959,\n                       1.1869, 1.7677, 1.9112, 1.5024, 1.8274, 1.1928, 1.2503, 1.5750, 1.2784,\n                       1.3090, 1.0917, 1.3700, 2.0926, 1.0635, 1.2468, 0.9884, 0.9087, 0.9868,\n                       1.2031, 1.0165, 1.0333, 1.7875, 1.5588, 1.5398, 0.8162, 1.8487, 1.3715,\n                       1.0564, 1.1308, 1.4516, 1.2794, 2.5562, 1.5293, 1.5112, 0.8428, 1.0241,\n                       1.2873, 1.5720, 1.0817, 1.4097, 1.3283, 1.1403, 1.1902, 1.5140, 1.7056,\n                       1.1336, 1.1259, 0.8421, 2.1252, 1.0415, 1.3069, 1.7818, 1.2865, 1.6669,\n                       1.2721, 1.8178, 1.0449, 1.0048, 1.7932, 1.4257, 2.3503, 0.9482, 1.3091,\n                       1.2984, 1.4282, 1.4157, 1.2195, 1.1141, 1.1698, 0.9085, 1.2222, 0.9518,\n                       1.1790, 1.4835, 2.0221, 1.3978])),\n              ('layer3.1.bn2.num_batches_tracked', tensor(13572)),\n              ('layer3.1.conv3.weight',\n               tensor([[[[ 0.0700]],\n               \n                        [[ 0.0202]],\n               \n                        [[ 0.0143]],\n               \n                        ...,\n               \n                        [[-0.0518]],\n               \n                        [[ 0.0117]],\n               \n                        [[ 0.0542]]],\n               \n               \n                       [[[-0.0055]],\n               \n                        [[ 0.0142]],\n               \n                        [[ 0.0665]],\n               \n                        ...,\n               \n                        [[ 0.0534]],\n               \n                        [[-0.0637]],\n               \n                        [[ 0.0137]]],\n               \n               \n                       [[[-0.0188]],\n               \n                        [[ 0.0115]],\n               \n                        [[ 0.0117]],\n               \n                        ...,\n               \n                        [[-0.0389]],\n               \n                        [[-0.0361]],\n               \n                        [[ 0.0116]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0180]],\n               \n                        [[ 0.0294]],\n               \n                        [[-0.0117]],\n               \n                        ...,\n               \n                        [[ 0.0209]],\n               \n                        [[-0.0500]],\n               \n                        [[-0.0057]]],\n               \n               \n                       [[[ 0.0031]],\n               \n                        [[ 0.0083]],\n               \n                        [[ 0.0245]],\n               \n                        ...,\n               \n                        [[ 0.0713]],\n               \n                        [[ 0.0469]],\n               \n                        [[-0.0224]]],\n               \n               \n                       [[[ 0.0418]],\n               \n                        [[ 0.0322]],\n               \n                        [[-0.0330]],\n               \n                        ...,\n               \n                        [[ 0.0566]],\n               \n                        [[ 0.0109]],\n               \n                        [[-0.0042]]]])),\n              ('layer3.1.bn3.weight',\n               tensor([-0.1900, -0.1380,  0.2953,  ..., -0.0677, -0.1652,  0.1460])),\n              ('layer3.1.bn3.bias',\n               tensor([ 0.1070,  0.0511, -0.0300,  ...,  0.0737,  0.0493,  0.0517])),\n              ('layer3.1.bn3.running_mean',\n               tensor([ 0.1545,  0.3977,  0.2199,  ..., -0.3244, -0.2064, -0.0686])),\n              ('layer3.1.bn3.running_var',\n               tensor([0.1301, 0.1124, 0.1325,  ..., 0.1112, 0.1803, 0.1366])),\n              ('layer3.1.bn3.num_batches_tracked', tensor(13572)),\n              ('layer3.2.conv1.weight',\n               tensor([[[[-0.0020]],\n               \n                        [[ 0.0066]],\n               \n                        [[-0.0798]],\n               \n                        ...,\n               \n                        [[-0.0677]],\n               \n                        [[-0.0292]],\n               \n                        [[ 0.0428]]],\n               \n               \n                       [[[ 0.0331]],\n               \n                        [[ 0.1077]],\n               \n                        [[-0.0788]],\n               \n                        ...,\n               \n                        [[ 0.0657]],\n               \n                        [[-0.0040]],\n               \n                        [[-0.0167]]],\n               \n               \n                       [[[ 0.0349]],\n               \n                        [[-0.0139]],\n               \n                        [[ 0.0271]],\n               \n                        ...,\n               \n                        [[ 0.0295]],\n               \n                        [[-0.0810]],\n               \n                        [[-0.0057]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0070]],\n               \n                        [[-0.0182]],\n               \n                        [[ 0.0021]],\n               \n                        ...,\n               \n                        [[-0.0841]],\n               \n                        [[ 0.0239]],\n               \n                        [[ 0.0587]]],\n               \n               \n                       [[[ 0.0144]],\n               \n                        [[-0.0330]],\n               \n                        [[ 0.0305]],\n               \n                        ...,\n               \n                        [[ 0.0229]],\n               \n                        [[ 0.0584]],\n               \n                        [[-0.0177]]],\n               \n               \n                       [[[-0.0122]],\n               \n                        [[-0.0272]],\n               \n                        [[ 0.0246]],\n               \n                        ...,\n               \n                        [[-0.0539]],\n               \n                        [[-0.0832]],\n               \n                        [[-0.0324]]]])),\n              ('layer3.2.bn1.weight',\n               tensor([0.9601, 0.9675, 0.9592, 1.0527, 0.9663, 0.9787, 0.9922, 1.0063, 0.9599,\n                       0.9872, 0.9943, 1.0643, 0.9713, 0.9805, 0.9700, 1.0348, 0.9786, 0.9989,\n                       0.9578, 1.0107, 1.0012, 0.9721, 0.9962, 0.9239, 0.9493, 0.9474, 1.0352,\n                       1.0216, 0.9536, 0.9911, 0.9645, 1.0288, 1.0229, 0.9712, 0.9988, 0.9332,\n                       0.9767, 0.9948, 1.0085, 1.0103, 1.0206, 1.0358, 1.0263, 1.0221, 0.9888,\n                       1.0252, 0.9934, 0.9614, 1.0481, 0.9716, 0.9873, 0.9419, 1.0013, 0.9923,\n                       0.9884, 1.0093, 0.9892, 0.9301, 0.9934, 1.0120, 0.9954, 0.9655, 0.9811,\n                       0.9928, 1.0095, 1.0562, 0.9879, 1.0299, 0.9340, 0.9808, 0.9184, 1.0095,\n                       1.0392, 1.0525, 0.9898, 0.9761, 1.0539, 0.9968, 0.9995, 1.0097, 0.9788,\n                       0.9768, 0.9763, 0.9781, 0.9306, 0.9990, 1.0322, 1.0016, 1.0291, 1.0138,\n                       0.9794, 0.9877, 1.0084, 1.0523, 1.0292, 0.8930, 1.0149, 1.0168, 1.0336,\n                       1.0624, 0.9639, 0.9240, 1.0357, 0.9908, 1.0408, 0.9593, 1.0228, 1.0276,\n                       1.0272, 0.9971, 1.0448, 1.0080, 1.0211, 0.9797, 1.0629, 1.0091, 0.9730,\n                       0.9964, 1.0669, 0.9800, 1.0091, 0.9696, 1.0688, 1.0194, 1.0031, 0.9946,\n                       1.0205, 1.0229, 1.0202, 0.9642, 1.0081, 1.0370, 1.0472, 0.9851, 1.0005,\n                       1.0394, 0.9660, 0.9601, 1.0680, 1.0242, 0.9707, 1.0313, 1.0138, 1.0668,\n                       0.9876, 1.0190, 0.9795, 0.9823, 1.0071, 1.0004, 0.9506, 1.0321, 0.9643,\n                       0.9882, 0.9764, 1.0244, 1.0025, 1.0058, 0.9780, 0.9977, 1.0112, 1.0143,\n                       0.9851, 0.9976, 0.9535, 1.0324, 0.9693, 1.0226, 0.9522, 1.0116, 1.0085,\n                       0.9563, 1.0021, 0.9912, 0.9893, 1.0050, 0.9680, 0.9611, 0.9915, 1.0035,\n                       1.0220, 1.0641, 1.0729, 1.0196, 0.9887, 1.0063, 1.0032, 0.9676, 0.9613,\n                       1.0117, 0.9775, 1.0481, 0.9736, 0.9878, 0.9886, 0.9787, 0.9900, 1.0199,\n                       1.0072, 0.9814, 0.9856, 1.1052, 1.0087, 1.0000, 1.0170, 0.9863, 1.0322,\n                       0.9944, 1.0284, 0.9807, 1.0022, 0.9997, 0.9653, 0.9645, 1.0362, 0.9514,\n                       1.0142, 1.0263, 1.0498, 1.0030, 0.9713, 0.9793, 0.9610, 0.9987, 0.9780,\n                       0.9984, 0.9917, 0.9773, 0.9592, 1.0889, 0.9688, 0.9812, 1.0287, 0.9487,\n                       1.0038, 0.9539, 0.9922, 0.9884, 0.9650, 1.0185, 0.9491, 1.0070, 0.9881,\n                       1.0150, 0.9419, 0.9612, 1.0195, 0.9782, 0.9601, 0.9956, 0.9697, 0.9555,\n                       0.9964, 1.0124, 1.0211, 0.9688])),\n              ('layer3.2.bn1.bias',\n               tensor([-6.3536e-02, -7.7390e-02, -3.9929e-02, -8.5383e-02, -7.2088e-02,\n                       -4.0983e-02, -6.7411e-02, -2.2064e-02, -6.4233e-02, -6.1333e-02,\n                       -3.8914e-02, -5.9662e-02, -7.1989e-02, -4.5645e-02, -6.8783e-02,\n                       -3.0091e-02, -8.2460e-02, -5.0174e-02, -9.2289e-02, -1.2072e-01,\n                       -2.6638e-02, -8.2320e-02, -7.3349e-02, -6.4913e-02,  9.9557e-03,\n                       -4.4335e-02, -6.2748e-02, -7.3469e-02, -6.3420e-02, -6.6430e-02,\n                       -1.3441e-01, -2.4990e-02, -1.0780e-02, -1.2428e-01, -4.9221e-02,\n                       -1.1076e-01, -7.5960e-02, -6.8632e-02, -3.5913e-02, -4.2136e-02,\n                       -3.1100e-02, -2.2876e-02, -5.0221e-02, -4.0113e-02, -4.6376e-02,\n                       -5.5028e-02, -3.5787e-02, -4.6905e-02,  5.1010e-03, -2.1234e-02,\n                       -1.1930e-01, -6.1124e-02, -1.3358e-01, -6.2487e-02, -7.9851e-02,\n                       -1.1804e-01,  7.7079e-04, -1.1213e-01, -5.3989e-02, -3.0642e-02,\n                       -5.2274e-02, -8.9933e-02, -6.7823e-02, -4.7991e-02, -8.7718e-02,\n                       -2.0627e-01, -6.0674e-02, -3.5033e-02, -6.3772e-02, -5.3288e-02,\n                       -1.1996e-01,  7.9822e-03, -3.1254e-02, -5.3102e-02, -5.1590e-02,\n                       -7.5631e-02, -1.7718e-01, -8.3066e-02, -2.6038e-02, -5.1186e-02,\n                       -5.0113e-02, -3.0971e-02, -4.3847e-02, -2.7734e-02, -1.3848e-01,\n                       -1.3710e-01, -7.5225e-02, -5.7319e-02, -2.4656e-02, -6.0408e-02,\n                       -6.8878e-02, -2.1777e-02, -6.3012e-02, -1.2212e-01, -5.9332e-02,\n                       -6.7897e-02, -8.4496e-04, -8.3630e-02, -7.1241e-02, -5.9411e-02,\n                       -1.0116e-01, -1.3407e-01, -1.6535e-01, -2.7824e-02, -1.1649e-02,\n                       -5.1640e-02, -4.0906e-02, -5.0281e-02, -8.6660e-02, -1.0101e-01,\n                       -7.3692e-02, -1.0364e-04, -3.9452e-02, -8.5712e-02, -5.7043e-02,\n                       -1.3614e-01, -5.0406e-02, -4.6699e-02, -1.1450e-01, -9.0613e-02,\n                       -3.9375e-02, -3.2520e-02, -7.0129e-02, -5.1777e-02, -2.4752e-02,\n                       -1.6448e-02, -8.5575e-02, -6.4801e-02, -6.8025e-02, -5.6733e-02,\n                       -1.3201e-01, -6.2044e-02, -7.7310e-02, -7.4122e-02, -5.0187e-02,\n                       -7.8201e-02, -1.5185e-01, -7.9734e-02, -2.1898e-01,  3.0344e-02,\n                       -1.3077e-01, -3.5864e-02, -8.1181e-02, -2.2427e-01, -4.8702e-02,\n                       -6.7518e-02, -8.2895e-02, -5.6221e-02,  1.1867e-02, -2.4083e-02,\n                       -7.3584e-02, -3.7034e-02, -1.0284e-01, -8.5331e-02, -2.1404e-02,\n                       -7.6265e-02, -6.4465e-02, -1.0631e-02, -9.3124e-02, -3.5340e-02,\n                       -1.0257e-01, -1.0614e-01, -4.5428e-02, -5.6792e-02, -8.8725e-02,\n                       -4.4911e-02, -1.2573e-01, -7.7757e-02, -6.4430e-02,  1.2430e-02,\n                       -5.2171e-02, -1.6067e-02, -8.6674e-02, -8.5290e-02, -3.4793e-02,\n                       -7.3295e-02, -8.7873e-02, -3.4376e-02, -1.0662e-01, -4.2160e-02,\n                       -6.7338e-02, -5.1466e-02, -1.7915e-01, -1.2681e-01, -5.4127e-02,\n                       -5.3434e-02, -7.4224e-02, -1.1425e-01, -7.7123e-02, -4.0776e-02,\n                       -9.2010e-02, -2.6577e-02, -5.6249e-02, -4.7210e-02, -7.5247e-02,\n                       -2.2271e-02, -6.1744e-02, -1.3896e-02, -6.1180e-02, -8.4568e-02,\n                       -3.5238e-02,  1.6753e-02,  2.1180e-02, -8.5603e-04, -2.6321e-02,\n                       -6.6731e-02, -3.4409e-02, -6.8958e-02, -5.3089e-02, -2.4841e-02,\n                       -3.6461e-02, -2.9774e-02, -6.8735e-02, -3.8070e-02, -8.6761e-02,\n                       -7.8912e-02, -1.5138e-01, -3.5010e-02,  1.2886e-02, -1.3037e-03,\n                       -4.6545e-02, -9.0847e-02, -6.7066e-02, -7.1788e-02, -5.0205e-02,\n                       -1.0278e-01, -8.0977e-02, -7.3923e-02, -5.2688e-02, -3.2831e-03,\n                       -1.1936e-01, -7.9000e-02, -1.3351e-01, -3.6149e-02,  8.9579e-03,\n                       -7.4064e-02, -8.6029e-02, -8.2090e-02, -3.4469e-02, -6.9096e-02,\n                       -7.3176e-02, -8.2784e-02, -6.5904e-02, -9.4916e-02, -5.1944e-02,\n                       -5.6415e-02, -6.3835e-02, -7.5275e-02, -9.9554e-02, -6.0189e-02,\n                       -1.3619e-01, -9.7153e-03,  1.1436e-02, -4.3616e-02, -6.2778e-02,\n                       -1.2804e-01])),\n              ('layer3.2.bn1.running_mean',\n               tensor([-0.5044, -0.9277, -0.3216, -0.7218,  0.2311, -0.7632,  0.5713, -1.0345,\n                        0.2553, -0.7016, -0.9507,  0.3191, -0.3801, -0.1112,  0.1125, -0.2686,\n                       -0.8267, -0.7487, -0.4474, -0.1096, -0.7738, -0.0618,  0.3642,  0.0780,\n                       -0.7589,  0.2074,  0.0205, -0.6096,  0.5919, -0.3758,  0.3882, -0.5640,\n                        0.0544,  0.7631, -0.7031, -0.7975, -0.9895, -0.6522, -0.2383, -0.4946,\n                       -0.7041,  0.0709, -0.1686, -0.6361, -0.2641,  0.1293,  0.2818,  0.7129,\n                       -0.0876, -0.0091,  0.1329,  0.4781, -0.4662, -0.7021, -0.3849, -0.1140,\n                       -0.8445, -0.0986, -0.0404,  0.2572, -0.3159, -0.2297, -0.2615,  0.3951,\n                        0.1539, -0.5448,  0.3424, -1.5218, -0.0332, -0.0570, -0.4743,  0.1173,\n                       -0.9462, -0.7591, -0.2564, -0.3768, -0.4872, -1.1566, -0.5091,  0.5827,\n                        0.3352, -0.4146, -0.2615, -0.1309,  0.7359,  0.2952,  0.0025, -0.1322,\n                       -0.4808, -0.4327, -0.0855, -0.1884, -0.6470, -0.7030, -0.4610, -0.3402,\n                       -0.5087, -0.1940,  0.3640,  0.4884, -0.1662, -0.8126, -0.1491, -0.2388,\n                       -0.0079, -0.3791,  0.6140, -0.0546,  0.2680,  0.0394, -0.8002,  0.0144,\n                       -0.2529, -0.2641, -1.1249, -0.5768, -0.0293,  0.0141, -0.7354,  0.2445,\n                       -0.7992, -0.0440,  0.5923, -0.2126, -0.5680, -0.2758, -0.6585, -0.7425,\n                        0.1326,  0.2207, -0.1869, -0.7267, -0.9158,  0.0914, -1.1397, -0.2985,\n                        0.5075, -0.7730, -0.5702, -0.7053, -0.3061,  0.1708,  0.1473, -0.8089,\n                        0.5297, -0.8505,  0.1158, -0.2055, -0.8513, -0.6098, -0.5158, -1.3152,\n                        0.6290,  0.0293, -0.6843, -0.3739,  0.0244, -0.7873, -0.7878,  0.3092,\n                       -0.6298,  0.3300, -0.2208, -1.3610, -0.3190, -0.6042, -0.0290, -0.5621,\n                       -0.3416, -0.1142,  0.8988,  0.3592, -0.1965, -0.5100, -0.0800,  0.1105,\n                       -0.5378, -0.4556, -1.2299,  0.5061,  0.3287, -0.4113, -0.0244, -0.3106,\n                        0.2026, -1.0068, -0.1211, -0.5520, -0.3395, -0.6041,  0.3280, -0.8243,\n                       -0.0926, -0.0250,  0.4086, -0.4299,  0.1040,  0.2423, -0.5432,  0.9965,\n                       -0.2473, -0.4033, -0.7178, -0.2711,  0.1003, -0.0519, -0.1876, -0.5578,\n                       -0.1343, -0.4115, -0.0369,  0.1109,  0.3194, -0.5239, -0.3506, -0.2304,\n                       -0.0151, -0.3894, -0.2632, -0.5149, -0.8318, -0.0341, -0.3029,  0.1132,\n                       -0.5215,  0.4353, -0.6794,  0.1216, -0.6426,  0.1827, -0.2093, -0.2272,\n                       -0.8978, -0.4551,  0.2004, -0.2861, -0.4049, -0.5366, -0.3148, -0.6321,\n                       -0.1394, -0.3782,  0.0677, -0.8201, -0.3261, -0.0288, -1.0437, -0.2822,\n                       -0.2217,  0.2868, -0.4174, -0.2196,  0.1331, -0.3211, -0.6049, -0.3625])),\n              ('layer3.2.bn1.running_var',\n               tensor([0.4945, 0.4017, 0.5362, 0.5849, 0.4646, 0.4363, 0.5419, 0.4672, 0.5689,\n                       0.4349, 0.4080, 0.4393, 0.5386, 0.4158, 0.3969, 0.3645, 0.3834, 0.4083,\n                       0.3683, 0.5589, 0.5205, 0.5750, 0.4575, 0.5268, 0.3901, 0.4119, 0.7339,\n                       0.5640, 0.3658, 0.5342, 0.5138, 0.3735, 0.3642, 0.5601, 0.4250, 0.4151,\n                       0.4943, 0.3483, 0.5004, 0.3774, 0.5331, 0.5180, 0.5139, 0.4991, 0.4107,\n                       0.4256, 0.4728, 0.5716, 0.4543, 0.5061, 0.5151, 0.5768, 0.4928, 0.3622,\n                       0.4779, 0.6073, 0.3664, 0.4325, 0.4445, 0.4760, 0.4989, 0.5154, 0.3991,\n                       0.5288, 0.4583, 0.5817, 0.4312, 0.5066, 0.4577, 0.4474, 0.3682, 0.6124,\n                       0.5066, 0.5220, 0.3997, 0.4095, 0.4834, 0.4209, 0.5724, 0.5022, 0.6611,\n                       0.5011, 0.4418, 0.4678, 0.3831, 0.4613, 0.3947, 0.3967, 0.5145, 0.3874,\n                       0.3917, 0.4725, 0.4695, 0.5876, 0.5024, 0.4203, 0.4127, 0.4689, 0.6421,\n                       0.4692, 0.4314, 0.4277, 0.5710, 0.4182, 0.5069, 0.4886, 0.5005, 0.5051,\n                       0.5780, 0.4758, 0.5017, 0.4886, 0.4113, 0.4133, 0.5726, 0.4809, 0.4570,\n                       0.4082, 0.5281, 0.4548, 0.5576, 0.4946, 0.5955, 0.5549, 0.4585, 0.5125,\n                       0.4530, 0.4700, 0.4674, 0.5329, 0.5493, 0.4730, 0.5112, 0.4028, 0.3815,\n                       0.4701, 0.4187, 0.4839, 0.5377, 0.5170, 0.3291, 0.4978, 0.4920, 0.5055,\n                       0.5233, 0.5451, 0.4070, 0.5090, 0.4884, 0.4530, 0.4290, 0.4417, 0.5657,\n                       0.4109, 0.3665, 0.5708, 0.4457, 0.4617, 0.4467, 0.5351, 0.4282, 0.5232,\n                       0.4071, 0.4594, 0.4039, 0.4900, 0.4365, 0.5271, 0.4996, 0.4797, 0.6649,\n                       0.4127, 0.5127, 0.3746, 0.4682, 0.3875, 0.5296, 0.4062, 0.5083, 0.4826,\n                       0.5689, 0.4741, 0.6337, 0.5191, 0.4684, 0.5308, 0.4522, 0.4520, 0.4484,\n                       0.4317, 0.5140, 0.5362, 0.4832, 0.4265, 0.6055, 0.4548, 0.3458, 0.4672,\n                       0.4272, 0.5089, 0.5217, 0.3381, 0.3200, 0.4536, 0.5431, 0.4707, 0.4343,\n                       0.4229, 0.4935, 0.3886, 0.4430, 0.4312, 0.4757, 0.5763, 0.4858, 0.4958,\n                       0.5569, 0.4120, 0.5092, 0.3764, 0.5725, 0.4275, 0.3871, 0.3871, 0.4768,\n                       0.6416, 0.4530, 0.4289, 0.5724, 0.4384, 0.5061, 0.4773, 0.4856, 0.3444,\n                       0.4656, 0.4594, 0.6259, 0.3702, 0.4471, 0.4105, 0.4773, 0.4956, 0.4772,\n                       0.4344, 0.5092, 0.3336, 0.3957, 0.4071, 0.4972, 0.4258, 0.4677, 0.3377,\n                       0.4292, 0.5045, 0.5384, 0.5249])),\n              ('layer3.2.bn1.num_batches_tracked', tensor(13572)),\n              ('layer3.2.conv2.weight',\n               tensor([[[[-1.3275e-02,  8.3177e-03, -1.8553e-02],\n                         [-5.2242e-03,  3.5351e-03, -7.9906e-03],\n                         [-3.1850e-02, -6.7259e-02, -2.0783e-02]],\n               \n                        [[ 1.0408e-03, -1.9314e-02,  1.9353e-02],\n                         [ 1.2109e-02, -2.9797e-03, -3.0464e-02],\n                         [ 3.6376e-03,  5.4329e-03,  2.7543e-02]],\n               \n                        [[-3.1791e-02,  2.2331e-03,  3.5516e-03],\n                         [-1.1095e-02, -3.2470e-02,  3.0963e-02],\n                         [ 3.2752e-02, -1.1042e-02,  4.4643e-03]],\n               \n                        ...,\n               \n                        [[ 9.1127e-03,  1.2057e-02, -1.9204e-02],\n                         [ 3.8558e-02,  1.1266e-02,  4.7510e-03],\n                         [-1.5410e-02,  5.4792e-02,  1.2739e-02]],\n               \n                        [[ 6.2680e-03,  1.6922e-02,  2.6185e-02],\n                         [-2.6503e-03,  3.0018e-03, -2.0701e-02],\n                         [ 1.9941e-02, -4.1867e-02,  1.2423e-02]],\n               \n                        [[ 2.2549e-02, -7.2033e-03,  2.7416e-02],\n                         [ 4.4923e-03,  2.7349e-02,  3.8010e-02],\n                         [-1.1012e-02, -3.1656e-02,  2.4964e-02]]],\n               \n               \n                       [[[ 1.1953e-04, -1.4449e-02, -2.5917e-02],\n                         [-1.8964e-02,  1.1353e-03, -8.4769e-03],\n                         [ 5.1961e-02, -1.1796e-03,  3.6056e-02]],\n               \n                        [[ 1.4093e-02, -2.2088e-02, -2.7726e-02],\n                         [ 2.8866e-02,  3.2885e-04, -7.2822e-04],\n                         [ 2.3483e-03, -1.0403e-02, -1.2271e-02]],\n               \n                        [[ 5.8868e-03,  4.6069e-03,  7.4171e-03],\n                         [-2.4564e-02, -7.5115e-03,  1.5065e-02],\n                         [ 1.2700e-02,  1.8100e-02,  4.4153e-03]],\n               \n                        ...,\n               \n                        [[-6.0958e-03,  4.5470e-02,  6.0441e-02],\n                         [ 1.0941e-02,  2.4796e-02,  6.0579e-02],\n                         [-8.5973e-03,  2.5293e-02,  1.5660e-02]],\n               \n                        [[-2.8425e-02,  3.2961e-03,  3.3122e-02],\n                         [ 1.0762e-02, -2.1716e-04, -5.8202e-03],\n                         [ 3.3111e-02,  5.1020e-02,  2.1190e-02]],\n               \n                        [[ 1.8034e-02,  4.9319e-04,  2.2422e-02],\n                         [ 6.9399e-03, -1.1638e-02,  4.5344e-02],\n                         [-1.3080e-03,  1.5160e-02,  1.4255e-02]]],\n               \n               \n                       [[[-1.5455e-02, -5.2506e-03, -1.1084e-02],\n                         [ 2.2895e-02,  2.7344e-02,  1.8781e-02],\n                         [-7.5120e-04, -3.1215e-03,  2.1223e-02]],\n               \n                        [[ 2.6237e-02, -9.6784e-03, -2.4332e-02],\n                         [-1.2293e-02, -2.3960e-02, -1.3295e-02],\n                         [-3.5941e-02,  2.7562e-02,  5.1324e-03]],\n               \n                        [[ 1.3697e-02, -1.8052e-02, -5.9724e-03],\n                         [-4.0314e-02, -9.5239e-03, -2.0732e-02],\n                         [-1.7785e-02, -1.9010e-02,  6.0624e-03]],\n               \n                        ...,\n               \n                        [[ 1.6475e-02,  1.4429e-02, -1.3887e-02],\n                         [ 1.1733e-02, -7.7444e-03,  1.1251e-02],\n                         [-3.2310e-06, -9.3437e-03,  8.2717e-03]],\n               \n                        [[-4.9284e-02, -1.2686e-02, -3.6275e-02],\n                         [-2.5384e-02, -1.0730e-02, -4.7277e-02],\n                         [ 4.6452e-02,  1.7389e-03,  3.4684e-02]],\n               \n                        [[ 1.7006e-02,  8.1930e-03,  4.9493e-03],\n                         [ 4.9251e-04,  3.8306e-02, -2.0187e-02],\n                         [-4.2392e-03,  2.1352e-02,  4.6487e-03]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-3.7031e-03,  2.7942e-02, -8.8772e-03],\n                         [ 6.0740e-03,  1.4082e-02, -2.9617e-03],\n                         [-1.3205e-02, -3.4538e-03,  8.7276e-03]],\n               \n                        [[ 9.0098e-03, -8.1254e-03, -3.5871e-02],\n                         [-1.6649e-02, -4.2077e-02, -4.6685e-03],\n                         [-1.3578e-02, -4.9230e-02, -3.9121e-02]],\n               \n                        [[-3.2745e-02, -1.6349e-03, -1.3528e-02],\n                         [ 1.7812e-02,  2.3903e-02, -1.4719e-02],\n                         [-3.6317e-03, -2.4422e-02, -1.8327e-02]],\n               \n                        ...,\n               \n                        [[ 1.9172e-02,  2.5096e-02,  3.5266e-02],\n                         [ 2.6479e-02,  2.6750e-02,  3.6398e-02],\n                         [ 2.4667e-02, -3.3805e-03,  2.7365e-02]],\n               \n                        [[ 1.7159e-02, -6.4591e-03, -3.0407e-02],\n                         [ 1.6128e-02,  1.3171e-02, -1.4175e-02],\n                         [-2.4046e-03, -3.1480e-02, -8.7061e-03]],\n               \n                        [[ 1.9291e-02, -4.1180e-03,  2.8123e-03],\n                         [ 2.1113e-02, -1.5034e-02, -1.1681e-02],\n                         [ 2.8774e-02,  1.4999e-02, -1.3879e-03]]],\n               \n               \n                       [[[ 2.8349e-02,  2.3633e-02, -2.7025e-02],\n                         [ 3.1544e-03,  8.8924e-03,  5.2687e-02],\n                         [ 9.1935e-03, -3.5648e-02,  3.2536e-02]],\n               \n                        [[ 9.0175e-04,  2.8654e-03,  6.1803e-03],\n                         [-5.8989e-03,  4.3878e-02,  5.3975e-03],\n                         [-4.5820e-02, -1.0904e-02,  1.8458e-02]],\n               \n                        [[ 8.0222e-03, -1.1107e-02,  3.9565e-03],\n                         [ 3.5751e-03, -2.6514e-02, -3.8639e-02],\n                         [-1.6938e-02, -1.4145e-02,  1.7631e-02]],\n               \n                        ...,\n               \n                        [[-4.7714e-03,  1.6050e-02,  1.4361e-02],\n                         [ 8.4059e-03,  2.8069e-02,  6.2531e-02],\n                         [ 1.5396e-03,  2.6889e-02, -2.3779e-02]],\n               \n                        [[-8.6854e-03, -1.7678e-02,  2.8712e-02],\n                         [ 3.4758e-02, -5.5744e-02, -3.5297e-03],\n                         [-1.1851e-02, -2.4335e-02, -2.9948e-02]],\n               \n                        [[-5.3950e-02, -1.6327e-02,  3.7900e-03],\n                         [-1.3480e-02, -5.0962e-03, -1.3634e-02],\n                         [-6.1977e-03,  9.4585e-03,  3.2312e-03]]],\n               \n               \n                       [[[-1.1157e-02,  4.8852e-02,  4.9729e-03],\n                         [ 1.5097e-02,  9.4966e-03,  3.4913e-02],\n                         [ 1.0559e-02,  4.8064e-02,  2.0401e-02]],\n               \n                        [[-1.3318e-02,  2.7942e-02,  1.0889e-02],\n                         [-3.3734e-02, -4.8863e-03,  4.8861e-03],\n                         [ 3.8633e-03,  9.4710e-03,  1.4377e-02]],\n               \n                        [[ 1.7692e-02, -1.1077e-02,  1.0010e-02],\n                         [-2.3616e-02, -1.9782e-02,  1.1781e-02],\n                         [ 3.0790e-02, -4.8640e-03,  4.9589e-03]],\n               \n                        ...,\n               \n                        [[-1.1033e-02, -6.6251e-02,  1.2666e-02],\n                         [ 1.2684e-02,  1.5739e-02, -3.1672e-02],\n                         [ 1.2337e-02, -7.9368e-03, -3.1339e-02]],\n               \n                        [[ 1.2961e-02, -1.0485e-02,  2.1401e-02],\n                         [ 6.4934e-03, -2.0865e-02,  5.2259e-03],\n                         [ 3.7946e-02,  3.4285e-02,  1.6653e-02]],\n               \n                        [[-3.4994e-02,  2.2834e-02, -5.4555e-04],\n                         [ 3.6794e-02,  2.6724e-02,  3.2763e-02],\n                         [ 2.2716e-02,  3.1527e-02,  2.6157e-02]]]])),\n              ('layer3.2.bn2.weight',\n               tensor([0.9598, 0.9689, 1.0135, 1.0349, 0.9613, 0.9899, 0.9786, 0.9821, 1.0210,\n                       0.9959, 0.9923, 1.0114, 0.9493, 0.9971, 0.9582, 0.9824, 0.9486, 0.9766,\n                       0.9829, 0.9534, 0.9605, 1.0035, 1.0316, 1.0315, 1.1086, 0.9622, 1.0134,\n                       1.0035, 1.0085, 0.9828, 0.9544, 0.9636, 0.9864, 0.9802, 0.9810, 0.9605,\n                       1.0223, 0.9721, 0.9806, 1.0392, 1.0695, 0.9651, 1.0300, 0.9694, 1.0421,\n                       0.9693, 0.9856, 1.0352, 0.9854, 0.9706, 1.0110, 0.9632, 1.0316, 1.0203,\n                       0.9961, 1.0222, 0.9373, 0.9318, 1.0439, 1.0043, 0.9779, 0.9667, 0.9649,\n                       1.0298, 0.9740, 0.9307, 0.9499, 0.9704, 1.0735, 1.0103, 0.9548, 0.9310,\n                       1.0533, 1.0130, 1.0678, 1.0609, 1.0566, 1.0031, 1.0508, 1.0585, 0.9293,\n                       0.9787, 1.0219, 1.0332, 1.0286, 0.9579, 0.9901, 0.9884, 0.9546, 0.9987,\n                       1.0029, 0.9478, 0.9492, 0.9915, 0.9653, 0.9992, 1.0464, 1.1092, 0.9564,\n                       0.9519, 0.9385, 0.9509, 0.9977, 1.0395, 0.9429, 1.0144, 0.9704, 0.9970,\n                       0.9956, 1.0221, 0.9498, 1.0401, 1.0106, 0.9921, 1.0227, 0.9534, 0.9329,\n                       0.9627, 1.0001, 1.1024, 0.9725, 0.9527, 1.0491, 0.9283, 0.9884, 0.9833,\n                       0.9589, 0.9705, 0.9341, 0.9523, 0.9836, 1.1464, 0.9682, 1.0222, 1.0265,\n                       1.0140, 0.9860, 1.0046, 0.9846, 0.9920, 0.9967, 0.9685, 1.0485, 1.0184,\n                       0.9912, 0.9583, 0.9664, 0.9982, 0.9761, 1.0372, 0.9975, 0.9721, 0.9706,\n                       0.9676, 0.9676, 0.9603, 1.0032, 1.0116, 0.9771, 1.0610, 0.9670, 0.9372,\n                       0.9842, 0.9960, 0.9707, 1.0016, 0.9458, 0.9639, 1.0263, 0.9962, 1.0137,\n                       0.9637, 0.9885, 0.9686, 0.9925, 1.0481, 0.9903, 0.9162, 0.9820, 1.0254,\n                       1.0124, 1.0232, 0.9805, 1.0139, 1.0558, 1.0040, 0.9618, 1.0260, 0.9704,\n                       1.0376, 0.9840, 1.0772, 0.9542, 0.9644, 0.9950, 1.0471, 0.9896, 1.1057,\n                       1.0799, 0.9777, 0.9614, 0.9534, 0.9728, 0.9762, 1.0275, 1.0558, 1.0216,\n                       0.9712, 0.9459, 0.9651, 0.9443, 1.0270, 0.9517, 1.0379, 0.9569, 1.0330,\n                       1.0035, 0.9550, 1.0440, 0.9478, 1.0394, 1.0290, 1.0492, 0.9790, 1.0467,\n                       0.9626, 1.0150, 0.9659, 1.0077, 1.0041, 0.9961, 1.0046, 1.0505, 1.0014,\n                       0.9883, 0.9763, 0.9750, 0.9650, 0.9796, 0.9644, 0.9709, 0.9585, 1.0154,\n                       0.9526, 0.9631, 0.9736, 1.0219, 0.9420, 0.9624, 0.9885, 1.0122, 1.0039,\n                       0.9861, 0.9534, 0.9869, 0.9318])),\n              ('layer3.2.bn2.bias',\n               tensor([-2.8297e-02, -5.4968e-02, -1.4326e-01, -6.2786e-02, -9.1424e-02,\n                       -6.2177e-02, -9.0570e-02,  1.3568e-04, -1.1863e-01, -1.1265e-01,\n                       -6.4022e-02, -4.9262e-02, -7.1262e-02, -1.0395e-01, -7.8478e-02,\n                       -6.3502e-02, -7.7907e-02, -1.0245e-01, -6.9198e-02, -1.3080e-01,\n                       -9.1575e-02, -1.3994e-01, -1.0636e-01, -4.2935e-02, -4.8606e-02,\n                       -9.8826e-02, -5.5184e-02, -7.7982e-02, -2.7455e-02, -3.7980e-02,\n                       -7.5352e-02, -7.7261e-02, -1.5803e-01, -8.9166e-02, -1.1983e-01,\n                       -1.8588e-02, -3.5125e-02, -4.3333e-02, -7.2194e-02, -9.1434e-02,\n                       -1.0279e-01, -4.2992e-02, -1.1713e-01, -1.0991e-02, -1.9993e-01,\n                       -9.2179e-02, -9.0651e-02, -1.8463e-02, -1.0348e-01, -1.3268e-01,\n                       -1.7157e-01, -1.2403e-01, -6.8824e-02, -1.3584e-01, -1.0146e-01,\n                       -1.4548e-01, -5.8483e-02, -9.3107e-02, -1.5888e-01, -1.4350e-01,\n                       -1.0936e-01, -1.6748e-01, -4.4810e-02, -9.1817e-02, -8.5578e-02,\n                       -1.3632e-01, -8.6279e-02, -9.7626e-02, -8.8792e-02, -5.9484e-02,\n                       -6.2277e-02, -1.0955e-01, -1.6578e-01, -9.2236e-02, -1.7968e-01,\n                       -1.1467e-01, -5.6890e-02, -7.1896e-02, -4.8928e-02, -2.0006e-01,\n                       -9.7992e-02, -8.9036e-02, -7.3914e-02, -6.2217e-02, -7.7921e-02,\n                       -7.8625e-02, -6.2459e-02, -7.1955e-02, -2.4583e-02, -1.0765e-01,\n                       -6.9687e-02, -6.7620e-02, -2.5774e-02, -1.0200e-01, -6.0908e-02,\n                       -5.0596e-02, -8.7756e-02, -1.5534e-01, -1.2945e-01, -1.4256e-01,\n                       -1.3830e-01, -9.7554e-02, -3.0523e-02, -2.4729e-02, -1.2923e-01,\n                       -2.1038e-02, -9.4800e-02, -1.2347e-01, -7.4377e-02, -9.8231e-02,\n                       -6.3074e-02, -3.8702e-03, -1.2710e-01, -8.9997e-02, -1.6983e-01,\n                       -9.5283e-02, -8.7245e-02, -1.5535e-01, -7.8661e-02, -1.0757e-01,\n                       -9.7245e-02, -4.4322e-02, -1.1694e-01, -6.8834e-02, -1.0277e-01,\n                       -1.0094e-01, -1.0228e-01, -6.1472e-02, -1.0962e-01, -4.2736e-02,\n                       -8.7454e-02,  1.0261e-01, -4.9946e-02, -1.0896e-01, -1.3696e-01,\n                       -9.8816e-02, -6.0527e-02, -1.1756e-01, -1.1375e-01, -1.4383e-01,\n                       -8.6428e-02, -1.4204e-02, -1.3433e-01, -6.8937e-02, -7.4266e-02,\n                       -9.6952e-02, -1.1698e-01, -1.1509e-01, -1.6909e-01, -8.3981e-02,\n                       -6.8263e-02, -1.0367e-01, -6.8925e-02, -1.1762e-01, -9.9676e-02,\n                       -9.9767e-02, -3.7475e-02, -4.4422e-02, -2.0286e-02, -4.9554e-02,\n                       -5.3544e-02, -1.1827e-01, -5.9928e-02, -9.0625e-02, -4.3459e-02,\n                       -1.2644e-01, -9.2285e-02, -5.8998e-02, -8.4379e-02, -6.6319e-02,\n                       -6.7275e-02, -7.7522e-02, -2.4193e-02, -1.0627e-01, -6.2389e-02,\n                       -4.9177e-02, -1.3912e-01, -1.2251e-01, -1.1631e-01, -3.5029e-02,\n                       -1.2265e-01, -1.0350e-01, -2.5582e-02, -1.0771e-01, -9.4038e-02,\n                       -7.1282e-02, -9.6867e-02, -1.4414e-01, -7.8909e-02, -7.1249e-02,\n                       -6.3203e-02, -8.2943e-02, -6.1954e-02, -4.0687e-02, -1.2932e-01,\n                       -5.0179e-02, -5.2537e-02, -1.4621e-01, -2.3078e-01, -9.4236e-02,\n                       -1.0516e-01, -8.3087e-02, -9.0123e-02, -7.1775e-02, -5.6268e-02,\n                       -1.5220e-01, -1.1124e-01, -6.9822e-02, -7.5115e-02, -8.2603e-02,\n                       -6.8097e-02, -4.9944e-02, -5.4227e-02, -8.5349e-02, -5.0771e-02,\n                       -8.9805e-02, -9.8309e-02, -1.2378e-01, -6.7870e-02, -3.8371e-02,\n                       -7.3976e-02, -1.0912e-01, -5.0627e-03, -9.3295e-02, -1.6759e-01,\n                       -1.0944e-01, -1.6796e-01, -1.2727e-01, -1.2016e-01, -7.8721e-02,\n                       -7.3026e-02, -7.6962e-02, -7.6679e-02, -9.0911e-02, -8.1178e-02,\n                       -7.2412e-02, -1.0596e-01, -1.2401e-01, -6.3726e-02, -1.1780e-01,\n                       -1.4963e-01, -1.4936e-01, -5.6951e-02, -5.5505e-02, -1.0589e-01,\n                       -7.0630e-02, -1.4587e-01, -8.4857e-02, -6.3642e-02, -7.3493e-02,\n                       -8.3424e-02, -2.3819e-02, -1.1818e-01, -6.9104e-02, -1.4735e-01,\n                       -1.0335e-01])),\n              ('layer3.2.bn2.running_mean',\n               tensor([ 3.4934e-01,  4.2194e-01, -6.2503e-01,  1.5695e+00,  3.1443e-01,\n                       -5.3293e-01, -3.8243e-01, -1.0021e+00,  6.5865e-01, -9.1046e-02,\n                        3.1550e-01,  9.4963e-02,  1.8938e-01,  1.9687e-01,  4.7300e-01,\n                       -8.8591e-01,  2.0098e-01, -2.9336e-02, -4.4725e-01, -9.8029e-01,\n                       -7.3882e-01, -7.9187e-02,  5.5654e-01, -4.0861e-01, -7.6888e-01,\n                       -5.5291e-01, -5.4696e-01, -4.5310e-01, -5.7760e-01, -7.8461e-01,\n                        1.3562e-02, -3.1112e-01, -1.5213e+00, -6.9377e-01, -3.7211e-01,\n                       -4.1609e-01, -6.0847e-01,  3.3869e-02,  6.4250e-02,  5.5624e-01,\n                       -3.7781e-01, -6.8383e-02, -9.3169e-01, -7.4639e-01,  7.8063e-01,\n                       -3.0788e-01, -3.3564e-01,  5.8416e-02, -6.4394e-01, -3.6274e-01,\n                       -6.9678e-01, -6.4913e-01, -4.7640e-01, -2.9640e-01,  6.1686e-01,\n                       -3.7836e-01, -1.3887e-01,  2.6612e-01, -2.5860e-01, -4.5858e-01,\n                       -1.7678e+00, -3.9323e-02,  4.7934e-01, -6.2450e-01,  1.1744e-01,\n                       -6.0900e-01,  6.5871e-01, -2.4236e-01, -8.8500e-02, -1.1925e+00,\n                        6.6624e-01,  6.4696e-01, -2.0124e-01, -1.8533e-01, -2.4691e+00,\n                       -4.6436e-01, -5.2818e-01,  1.4235e-01, -5.3797e-01, -7.9286e-01,\n                       -4.9577e-01,  1.9974e-01, -1.5863e+00,  2.7936e+00, -7.7410e-01,\n                        1.3225e-01, -4.9783e-02, -6.1184e-01,  1.1575e-01, -3.2548e-02,\n                       -3.3694e-01,  3.5082e-01,  7.1761e-01, -8.9662e-02, -1.7015e-01,\n                       -6.5723e-02,  3.5150e-01,  2.4573e-01, -5.7972e-01,  9.2542e-01,\n                        6.1887e-01, -4.9124e-01,  5.4301e-01, -1.6989e-01,  3.3155e-01,\n                        1.3409e+00,  8.6314e-02, -8.0147e-01, -4.3641e-01,  1.0552e+00,\n                       -7.2355e-01,  5.4074e-01, -1.4710e+00,  1.0891e-01, -9.7028e-01,\n                       -3.6364e-01, -1.1190e-01, -3.4558e-01,  4.4035e-01,  7.4312e-01,\n                       -4.6639e-01, -3.6105e-01, -5.2353e-01,  4.5482e-01,  1.0775e-01,\n                        3.9639e-01,  3.5178e-01,  1.3290e+00,  2.1254e-01, -2.3396e-01,\n                       -6.2052e-01, -6.6409e-01,  3.0888e-01, -1.8410e-01,  3.1947e-01,\n                       -2.0747e-01,  2.5590e-01, -1.5404e-01,  6.1935e-01, -8.8421e-01,\n                       -4.6175e-01, -9.5136e-02, -2.5806e-01,  2.6976e-01,  3.2677e-02,\n                       -1.3076e-02, -4.5628e-01, -1.2910e+00,  4.3722e-01, -3.5181e-01,\n                        3.6508e-01, -3.2001e-01, -2.8984e-02, -4.7914e-01, -7.1823e-01,\n                       -7.7082e-01, -2.4577e-01, -8.5876e-02, -1.4569e-01, -9.9375e-03,\n                       -9.5756e-01,  5.5230e-01,  4.1167e-02, -1.2055e+00,  7.8005e-02,\n                       -3.3351e-01,  6.0791e-02, -8.7884e-01, -3.6701e-01,  1.0097e-01,\n                       -1.6268e+00, -2.0084e-01,  4.2192e-01, -6.9544e-01,  8.9563e-01,\n                        2.5075e-01, -9.5156e-01, -1.8442e-02, -2.1809e-02, -1.3530e-01,\n                       -8.3998e-01, -9.1380e-01, -2.7783e-01,  2.6983e-01, -1.6596e+00,\n                       -3.1088e-01,  1.8744e-01, -8.2962e-01, -6.8393e-01, -6.6682e-01,\n                       -5.4621e-01,  2.5751e-01, -3.6887e-01,  1.8594e-01, -8.7747e-02,\n                        2.1182e-01, -5.8329e-01, -8.8399e-01,  9.0074e-03, -1.0045e+00,\n                       -4.9601e-01,  2.3727e-01, -7.8652e-01,  2.9775e-01, -2.0314e-01,\n                       -6.3485e-01,  2.8638e-01, -1.1953e-01, -8.3245e-01,  4.8822e-01,\n                       -2.5230e-01, -1.0600e+00, -3.1658e-01, -1.2484e+00, -6.3789e-01,\n                        9.3793e-01,  2.4814e-01, -5.3302e-01, -1.3033e-01,  4.2692e-01,\n                       -7.7658e-02, -5.4430e-01, -2.8680e-01,  6.2536e-01, -4.5415e-01,\n                       -2.0292e-01, -3.1234e-01, -4.4009e-01, -9.2971e-01,  1.8157e-01,\n                       -7.4938e-01, -9.6653e-01,  2.1094e-04, -8.5421e-01, -5.7929e-01,\n                        1.3294e-01,  2.0279e-02, -5.7685e-01, -4.0288e-01,  1.5593e-01,\n                       -9.6995e-01,  3.3868e-01, -2.2492e-01,  1.1742e-01,  1.1787e-01,\n                        2.8197e-01, -7.5730e-01,  8.6973e-01, -1.2700e-01, -1.3258e-01,\n                       -3.7878e-01, -8.8497e-01, -4.9276e-01,  3.3635e-01, -2.8804e-01,\n                       -3.5929e-01])),\n              ('layer3.2.bn2.running_var',\n               tensor([0.8044, 0.7153, 1.1750, 1.0457, 1.1868, 0.8164, 0.8904, 1.0045, 1.3428,\n                       1.1260, 0.8862, 0.9162, 0.6704, 0.9950, 1.0623, 0.9983, 1.0272, 1.0112,\n                       0.9790, 0.8482, 0.9188, 0.9803, 1.2147, 0.8638, 0.8395, 1.0058, 1.0194,\n                       0.9645, 1.1005, 0.9952, 1.1010, 0.8658, 1.4538, 0.8760, 1.1041, 0.7567,\n                       0.8312, 0.7283, 0.8455, 1.2592, 1.9385, 0.7709, 1.4457, 0.9759, 1.7687,\n                       0.8620, 0.8267, 0.9925, 1.4544, 1.0778, 1.0640, 1.0916, 1.0194, 1.2339,\n                       1.2064, 1.3573, 0.8290, 0.7542, 1.9866, 1.2537, 1.1315, 1.0519, 0.9320,\n                       1.3480, 0.9741, 1.0622, 1.1693, 0.9741, 1.2586, 0.9999, 0.9540, 0.7017,\n                       1.3558, 1.0711, 1.5518, 1.4722, 1.2862, 0.9264, 0.8956, 1.5215, 1.0273,\n                       1.1321, 1.1183, 2.0514, 1.0048, 0.8706, 0.8847, 1.2701, 0.8124, 1.2370,\n                       1.4449, 0.8761, 0.9466, 1.1016, 0.9192, 0.9070, 1.0628, 1.0967, 1.0298,\n                       0.8883, 0.9558, 0.7227, 1.0796, 1.6120, 1.1135, 0.9522, 0.9640, 0.8809,\n                       0.9096, 1.1956, 0.7490, 0.9651, 1.3051, 0.8751, 1.7610, 0.8487, 0.8797,\n                       0.9747, 0.8220, 1.7599, 0.7546, 0.7622, 1.7282, 0.7644, 0.8354, 1.0984,\n                       1.0159, 1.1243, 0.7427, 0.9678, 0.8523, 2.1728, 0.8606, 0.8831, 1.2383,\n                       1.0548, 0.9494, 1.1482, 0.8095, 0.9736, 1.2754, 0.9718, 0.9935, 1.3206,\n                       0.8127, 0.8436, 1.0155, 1.5597, 1.1410, 1.1246, 0.9797, 0.8413, 0.8845,\n                       1.0310, 0.8404, 0.8819, 0.8722, 1.3794, 0.7704, 1.0480, 1.1094, 1.0193,\n                       0.8620, 0.8054, 0.8452, 0.9699, 0.8441, 0.9226, 1.3586, 1.2931, 1.1022,\n                       0.8308, 1.1282, 0.8070, 1.2882, 1.0724, 0.9379, 0.8122, 0.8019, 0.9240,\n                       2.0012, 0.8795, 0.8933, 1.3436, 1.2006, 1.1811, 0.9628, 1.9204, 1.0751,\n                       1.0478, 1.1244, 1.1413, 1.0721, 1.0319, 1.0130, 1.6929, 0.9389, 1.4748,\n                       1.3941, 1.0697, 0.9717, 0.9163, 0.7734, 1.2846, 1.1939, 2.3536, 0.9875,\n                       0.8296, 0.8339, 0.7122, 0.7812, 1.0091, 0.6843, 1.1068, 0.6596, 1.0418,\n                       0.8582, 1.0556, 1.0198, 0.7417, 1.1148, 1.3203, 0.9451, 0.9221, 2.1836,\n                       0.7260, 0.9693, 1.0753, 1.2706, 0.8576, 1.4644, 1.0536, 0.9274, 0.8687,\n                       1.5906, 1.0107, 1.0864, 0.8790, 0.9032, 0.8635, 1.3858, 0.9759, 1.2797,\n                       0.8521, 1.1158, 0.8496, 1.1180, 0.8379, 0.7979, 1.2861, 1.5137, 0.8522,\n                       1.0013, 0.9439, 0.8553, 0.7117])),\n              ('layer3.2.bn2.num_batches_tracked', tensor(13572)),\n              ('layer3.2.conv3.weight',\n               tensor([[[[ 0.0295]],\n               \n                        [[ 0.0134]],\n               \n                        [[ 0.0092]],\n               \n                        ...,\n               \n                        [[ 0.0053]],\n               \n                        [[ 0.0250]],\n               \n                        [[-0.0792]]],\n               \n               \n                       [[[ 0.0055]],\n               \n                        [[ 0.0271]],\n               \n                        [[ 0.0108]],\n               \n                        ...,\n               \n                        [[ 0.0347]],\n               \n                        [[-0.0119]],\n               \n                        [[ 0.0292]]],\n               \n               \n                       [[[ 0.0139]],\n               \n                        [[ 0.0186]],\n               \n                        [[ 0.0144]],\n               \n                        ...,\n               \n                        [[ 0.0490]],\n               \n                        [[ 0.0103]],\n               \n                        [[ 0.0059]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0117]],\n               \n                        [[ 0.0177]],\n               \n                        [[-0.0242]],\n               \n                        ...,\n               \n                        [[ 0.0223]],\n               \n                        [[ 0.0326]],\n               \n                        [[-0.0007]]],\n               \n               \n                       [[[-0.0420]],\n               \n                        [[ 0.0854]],\n               \n                        [[-0.0194]],\n               \n                        ...,\n               \n                        [[-0.0043]],\n               \n                        [[-0.0261]],\n               \n                        [[-0.0354]]],\n               \n               \n                       [[[ 0.0058]],\n               \n                        [[-0.0171]],\n               \n                        [[-0.0031]],\n               \n                        ...,\n               \n                        [[-0.0060]],\n               \n                        [[ 0.0427]],\n               \n                        [[ 0.0276]]]])),\n              ('layer3.2.bn3.weight',\n               tensor([-0.2297, -0.2494,  0.1628,  ...,  0.0228, -0.1397, -0.2141])),\n              ('layer3.2.bn3.bias',\n               tensor([ 0.0634,  0.0854, -0.0053,  ...,  0.0418,  0.0268,  0.0911])),\n              ('layer3.2.bn3.running_mean',\n               tensor([ 0.4244,  0.0913, -0.0762,  ...,  0.0302, -0.2005,  0.1414])),\n              ('layer3.2.bn3.running_var',\n               tensor([0.1267, 0.1471, 0.0869,  ..., 0.0628, 0.1275, 0.1595])),\n              ('layer3.2.bn3.num_batches_tracked', tensor(13572)),\n              ('layer3.3.conv1.weight',\n               tensor([[[[ 0.0979]],\n               \n                        [[-0.0322]],\n               \n                        [[-0.0395]],\n               \n                        ...,\n               \n                        [[-0.0549]],\n               \n                        [[-0.0702]],\n               \n                        [[-0.0528]]],\n               \n               \n                       [[[-0.0169]],\n               \n                        [[ 0.0414]],\n               \n                        [[-0.0473]],\n               \n                        ...,\n               \n                        [[ 0.0212]],\n               \n                        [[ 0.0551]],\n               \n                        [[-0.0379]]],\n               \n               \n                       [[[ 0.0144]],\n               \n                        [[ 0.0091]],\n               \n                        [[ 0.0166]],\n               \n                        ...,\n               \n                        [[ 0.0208]],\n               \n                        [[-0.0056]],\n               \n                        [[-0.0122]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0168]],\n               \n                        [[ 0.0134]],\n               \n                        [[ 0.0091]],\n               \n                        ...,\n               \n                        [[ 0.0598]],\n               \n                        [[-0.0200]],\n               \n                        [[ 0.0332]]],\n               \n               \n                       [[[-0.0503]],\n               \n                        [[-0.0192]],\n               \n                        [[-0.0124]],\n               \n                        ...,\n               \n                        [[ 0.0076]],\n               \n                        [[-0.0422]],\n               \n                        [[ 0.0007]]],\n               \n               \n                       [[[ 0.0152]],\n               \n                        [[ 0.0083]],\n               \n                        [[-0.0297]],\n               \n                        ...,\n               \n                        [[-0.0342]],\n               \n                        [[-0.0065]],\n               \n                        [[ 0.0104]]]])),\n              ('layer3.3.bn1.weight',\n               tensor([0.9812, 0.9665, 0.9394, 0.9859, 1.0315, 1.0210, 1.0065, 0.9266, 1.0165,\n                       1.0324, 0.9749, 1.0211, 0.9995, 0.9606, 0.9535, 0.9495, 1.0038, 1.0161,\n                       1.0495, 0.9970, 1.0101, 0.9329, 0.9907, 0.9423, 1.0216, 0.9927, 0.9567,\n                       1.0077, 0.9496, 0.9447, 0.9805, 0.9927, 0.9947, 0.9276, 1.0616, 0.9899,\n                       1.0267, 1.0120, 0.9961, 1.0015, 1.0828, 1.0098, 0.9804, 1.0150, 0.9463,\n                       1.0235, 0.9539, 0.9512, 0.9672, 0.9346, 0.9747, 0.9533, 1.0708, 0.9691,\n                       1.0148, 1.0071, 1.0296, 1.0598, 1.0175, 0.9903, 0.9902, 0.9676, 0.9736,\n                       0.9474, 0.9728, 1.0094, 0.9899, 0.9328, 1.0253, 0.9960, 0.9964, 0.9915,\n                       1.0457, 0.9726, 0.9767, 1.0642, 1.0037, 0.9511, 0.9528, 0.9643, 1.0291,\n                       1.0079, 0.9705, 0.9594, 0.9394, 0.9666, 1.0382, 0.9816, 1.0023, 1.0255,\n                       1.0087, 0.9902, 0.9574, 0.9832, 1.0268, 0.9778, 0.9825, 0.9786, 1.0036,\n                       0.9710, 1.0459, 0.9652, 1.0134, 1.0581, 0.9600, 0.9716, 0.9892, 0.9637,\n                       1.0241, 0.9754, 0.9988, 0.9990, 1.0322, 1.0107, 1.0228, 0.9532, 1.0006,\n                       0.9916, 0.9479, 0.9719, 0.9937, 1.0334, 0.9509, 1.0269, 0.9951, 0.9580,\n                       0.9798, 1.0393, 1.0525, 0.9339, 0.9730, 1.0666, 1.0084, 0.9738, 0.9810,\n                       0.9399, 1.0505, 0.9520, 0.9860, 0.9829, 1.0217, 0.9675, 0.9897, 1.0718,\n                       1.0439, 0.9880, 0.9786, 1.0669, 1.0751, 0.9510, 0.9960, 0.9840, 0.9704,\n                       1.0358, 1.0298, 1.0114, 1.0072, 1.0332, 0.9670, 1.0261, 0.9890, 1.0321,\n                       0.9944, 1.0334, 0.9901, 1.0219, 0.9530, 1.0237, 1.0010, 0.9770, 0.9571,\n                       1.0333, 0.9679, 0.9615, 1.0029, 1.0266, 0.9855, 0.9973, 0.9882, 0.9535,\n                       1.0127, 0.9818, 1.0254, 1.0257, 0.9699, 1.0109, 0.9339, 0.9657, 0.9584,\n                       1.0026, 0.9829, 0.9718, 0.9259, 0.9999, 0.9639, 0.9897, 0.9862, 1.0074,\n                       1.0007, 1.0900, 0.9954, 0.9693, 0.9362, 1.0097, 1.0038, 1.0059, 0.9658,\n                       0.9842, 1.0223, 0.9889, 0.9769, 0.9642, 0.9886, 1.0126, 1.0924, 0.9925,\n                       0.9666, 1.0084, 0.9752, 0.9990, 0.9918, 0.9584, 0.9985, 1.0229, 1.0726,\n                       0.9777, 0.9504, 1.0005, 0.9710, 0.9761, 0.9743, 1.0117, 1.0173, 1.0075,\n                       0.9567, 0.9833, 1.0231, 1.0192, 1.0074, 1.0089, 0.9619, 0.9914, 0.9863,\n                       1.0392, 1.0172, 0.9539, 0.9617, 1.0320, 0.9657, 1.0052, 1.0176, 1.0137,\n                       1.0141, 0.9566, 0.9608, 1.0084])),\n              ('layer3.3.bn1.bias',\n               tensor([-0.1059, -0.1080, -0.1141, -0.1007, -0.1447, -0.0954, -0.1774, -0.0955,\n                       -0.1483, -0.0908, -0.0170, -0.0889, -0.0764, -0.0993, -0.0801, -0.0710,\n                       -0.1067, -0.2909, -0.0327, -0.0864, -0.0386, -0.1814, -0.0446, -0.1060,\n                       -0.0523, -0.1658, -0.1383, -0.1195, -0.0742, -0.1357, -0.0322, -0.1552,\n                       -0.1532, -0.1535, -0.1865, -0.0965,  0.0050, -0.0955, -0.1352, -0.0472,\n                       -0.0192, -0.0942, -0.0328, -0.0941, -0.0923, -0.0583, -0.0506, -0.0620,\n                       -0.0523, -0.1255, -0.1180, -0.0949, -0.0360, -0.1326, -0.1590, -0.0487,\n                       -0.0460, -0.1247, -0.0591, -0.0879, -0.0257, -0.0478, -0.0932, -0.1387,\n                       -0.0263, -0.0859, -0.0424, -0.0828, -0.0584, -0.1840, -0.1082, -0.0212,\n                        0.0041, -0.0952, -0.0926,  0.0489, -0.1398, -0.1368, -0.0668, -0.1149,\n                       -0.2025, -0.1451, -0.1220, -0.0478, -0.1342, -0.0882, -0.1927, -0.1083,\n                       -0.1079, -0.0222, -0.1477, -0.0115, -0.1311, -0.1072, -0.1633, -0.0687,\n                       -0.0953, -0.1520, -0.1269, -0.1167, -0.0857, -0.1726, -0.0830, -0.1165,\n                       -0.0515, -0.1122, -0.0336, -0.1459, -0.0591, -0.2127, -0.0440, -0.0420,\n                       -0.1305, -0.2274, -0.1155, -0.1063, -0.1322, -0.1492, -0.1629, -0.0668,\n                       -0.1466, -0.0333, -0.1690, -0.0362, -0.0171, -0.0730, -0.1115, -0.1257,\n                       -0.1074, -0.1476, -0.1064, -0.0911, -0.0627, -0.0864, -0.0983, -0.0870,\n                       -0.1708, -0.2044, -0.0571, -0.0804, -0.1281, -0.0714, -0.0918, -0.0971,\n                       -0.2084, -0.0534, -0.1747, -0.0719, -0.0836, -0.0826, -0.0435, -0.1844,\n                       -0.0778, -0.1004, -0.0495, -0.2361, -0.1453, -0.1195, -0.0422, -0.2088,\n                       -0.0156, -0.0569, -0.1058, -0.1363, -0.0645, -0.0760, -0.1002, -0.1211,\n                       -0.1024, -0.0824, -0.0882, -0.1605, -0.0994, -0.0445,  0.0298, -0.0068,\n                       -0.0880, -0.0974, -0.0345, -0.0679, -0.0624, -0.1464, -0.0842, -0.1902,\n                       -0.0984, -0.0954, -0.0465, -0.1696, -0.0853, -0.0934, -0.1132, -0.0913,\n                       -0.1243, -0.0388, -0.1083, -0.0236, -0.1801, -0.0665, -0.0899, -0.1437,\n                       -0.2293, -0.0853, -0.0654, -0.1188, -0.1585, -0.2238, -0.1258, -0.1056,\n                       -0.0694, -0.0697, -0.0613, -0.0941, -0.1345, -0.1589, -0.1816, -0.1745,\n                       -0.0624, -0.0994, -0.0858, -0.0238, -0.1022, -0.0924, -0.0622, -0.0657,\n                       -0.1141, -0.0852, -0.0847, -0.0631, -0.0557, -0.1449, -0.0600, -0.1394,\n                       -0.0746, -0.1261, -0.0707, -0.0361, -0.2166, -0.1345, -0.1531, -0.2146,\n                       -0.1773, -0.0905, -0.0991, -0.0127, -0.0877, -0.0723, -0.0691, -0.1169,\n                       -0.0827, -0.0379, -0.1388, -0.0513, -0.0434, -0.0701, -0.1132, -0.0713])),\n              ('layer3.3.bn1.running_mean',\n               tensor([-1.5953, -0.4016,  0.5641, -0.6632, -0.5596, -0.4438, -0.3558, -0.2419,\n                        0.1282, -0.8504, -0.8383,  0.7094,  0.0966, -0.7750, -0.3080,  0.0675,\n                       -0.4755,  0.0846, -0.5444, -0.5620, -0.9851, -0.7984, -0.9661,  0.1531,\n                        0.8368, -0.9492, -0.4692, -0.4450, -0.9125, -0.0047, -0.2507, -0.2321,\n                        0.4039, -0.6046,  0.2000, -0.3521, -0.6722, -0.0838, -0.8857, -0.7061,\n                       -0.6348,  0.3856, -0.0919, -0.9719, -0.6180, -0.4351, -0.4486, -0.1482,\n                        0.2664, -0.6362, -0.4671, -0.5584, -1.0418, -0.2500,  0.5190, -0.3240,\n                       -1.0942, -0.0950,  0.5635, -1.1361, -0.1219,  0.6351,  0.2725, -0.3385,\n                        0.2056, -0.6183, -0.6537,  0.0956, -0.0933, -0.2452, -0.2357, -0.7173,\n                       -0.5458,  0.7905,  0.5724, -0.1922,  0.3876,  0.0754,  0.1017,  0.1961,\n                       -1.0067, -0.4175, -0.8078, -0.3799, -0.1699,  0.3711, -0.8076, -0.0262,\n                       -0.2501, -1.6480, -0.1515, -0.0604,  0.1589, -1.0363, -0.2765, -0.6024,\n                       -0.8000,  0.4250,  0.6451, -0.2449, -0.0889, -0.3403,  0.7590,  0.6195,\n                       -0.3183, -0.3431, -0.2089, -0.7606, -0.1623,  0.7266,  0.2481, -1.3084,\n                       -0.4831, -0.7742, -0.6810,  0.4102, -0.3248, -0.1552, -0.0171, -0.4025,\n                       -0.9856,  0.2911, -0.8444,  0.4275, -1.1436, -0.5621, -0.3913, -0.1227,\n                        0.1823, -0.6596,  0.3073, -0.9892,  0.0469,  0.4033, -0.3314, -0.8674,\n                       -0.2224, -0.3212, -0.7545, -0.4830, -0.2727, -0.8927, -0.3935, -0.7195,\n                        0.1484, -0.5832,  0.8823, -0.2297, -0.9383, -0.2923, -0.3609, -0.8887,\n                        0.1848,  0.4242, -0.5295, -0.5682, -0.6605,  0.0404, -1.3330, -0.2391,\n                       -1.0608, -0.4170, -0.7915,  0.1444, -0.2011,  0.0212, -0.5482,  0.0504,\n                       -1.0388,  0.3863, -1.2946, -0.2686,  0.3042,  0.3766, -0.5541, -0.6049,\n                       -0.4228, -0.5570, -0.4195, -0.1696, -0.6619, -0.3410, -0.7877, -0.8867,\n                       -1.2296, -0.6860, -0.8754, -0.2285, -0.2176, -0.2512, -0.5455, -0.3045,\n                       -0.1304, -0.7267,  0.0639, -0.9691, -0.4257,  0.1348, -0.5993,  0.6743,\n                        0.7018, -0.0606,  0.5570, -0.4703, -0.9758, -0.0216, -0.2988,  0.3041,\n                       -0.5731, -0.0255, -0.5555, -0.0908, -0.9561, -0.1279,  0.0499,  0.3892,\n                       -0.4013,  0.5512, -0.6031, -0.4612, -0.5619,  0.2932, -0.1760, -0.1109,\n                       -0.4483,  0.1332, -0.3428, -0.4030, -0.4044, -0.0396, -0.4104, -1.6336,\n                       -0.2432,  0.1264,  0.3733,  0.1196,  0.5992, -0.9352, -0.7271, -0.9953,\n                       -0.7227, -0.2595, -0.0849, -0.3717, -0.5704, -0.8688, -0.3907, -0.0440,\n                       -0.1846, -0.5251, -0.7944, -0.4507, -0.5069, -0.4161, -0.5984, -0.2999])),\n              ('layer3.3.bn1.running_var',\n               tensor([0.4608, 0.5042, 0.4477, 0.5114, 0.6544, 0.4721, 0.5172, 0.4638, 0.5130,\n                       0.4795, 0.4720, 0.6125, 0.4841, 0.4712, 0.4052, 0.5850, 0.6097, 0.5668,\n                       0.5613, 0.4773, 0.4711, 0.6634, 0.4835, 0.5292, 0.4451, 0.4049, 0.5718,\n                       0.5379, 0.3965, 0.4580, 0.4642, 0.5099, 0.7482, 0.5990, 0.7076, 0.5743,\n                       0.5294, 0.5476, 0.4902, 0.5305, 0.6008, 0.5996, 0.4666, 0.6295, 0.5198,\n                       0.7279, 0.4095, 0.5560, 0.4555, 0.4894, 0.5094, 0.4627, 0.5307, 0.4958,\n                       0.5526, 0.4818, 0.4411, 0.7279, 0.5324, 0.4979, 0.3900, 0.4008, 0.4811,\n                       0.5445, 0.4454, 0.4475, 0.4785, 0.4332, 0.4568, 0.5732, 0.5385, 0.4553,\n                       0.4867, 0.5158, 0.5355, 0.5725, 0.6413, 0.4516, 0.4589, 0.5375, 0.5592,\n                       0.4922, 0.4058, 0.4747, 0.4933, 0.5262, 0.6512, 0.5145, 0.5110, 0.4693,\n                       0.5662, 0.5778, 0.6096, 0.5694, 0.5866, 0.4706, 0.4516, 0.4742, 0.5210,\n                       0.5308, 0.6535, 0.5498, 0.5023, 0.5473, 0.4322, 0.5370, 0.4191, 0.6584,\n                       0.4744, 0.4720, 0.4951, 0.5478, 0.5628, 0.5861, 0.6026, 0.4119, 0.5894,\n                       0.5225, 0.5391, 0.4502, 0.5410, 0.5304, 0.5120, 0.5058, 0.4750, 0.5213,\n                       0.4288, 0.5371, 0.4965, 0.5246, 0.4878, 0.5824, 0.4973, 0.4975, 0.4900,\n                       0.4533, 0.6738, 0.6092, 0.4127, 0.4300, 0.4401, 0.4455, 0.7087, 0.5851,\n                       0.5679, 0.4946, 0.6120, 0.6594, 0.5129, 0.4443, 0.4642, 0.4465, 0.4707,\n                       0.4901, 0.5293, 0.6831, 0.6628, 0.5671, 0.5473, 0.5360, 0.5483, 0.5732,\n                       0.5506, 0.6854, 0.4519, 0.5928, 0.4836, 0.5748, 0.5294, 0.4323, 0.4916,\n                       0.6842, 0.5037, 0.5550, 0.5333, 0.6050, 0.4325, 0.5971, 0.3845, 0.4508,\n                       0.6098, 0.5402, 0.5932, 0.6755, 0.5616, 0.4674, 0.4932, 0.5356, 0.5979,\n                       0.4707, 0.4513, 0.4943, 0.4896, 0.5275, 0.5006, 0.4988, 0.6011, 0.3805,\n                       0.5195, 0.7779, 0.5771, 0.5607, 0.4591, 0.7742, 0.5308, 0.5214, 0.4095,\n                       0.8042, 0.5440, 0.4710, 0.4534, 0.4640, 0.6414, 0.4991, 0.6252, 0.5063,\n                       0.5063, 0.6994, 0.4823, 0.4946, 0.5974, 0.5363, 0.5325, 0.5160, 0.5446,\n                       0.5460, 0.4432, 0.5853, 0.4720, 0.4802, 0.6015, 0.5210, 0.5435, 0.5170,\n                       0.5087, 0.5202, 0.7793, 0.5749, 0.5278, 0.6443, 0.4061, 0.5309, 0.5016,\n                       0.5201, 0.5780, 0.5201, 0.5251, 0.5517, 0.5106, 0.5686, 0.6108, 0.4548,\n                       0.6432, 0.4154, 0.5335, 0.4834])),\n              ('layer3.3.bn1.num_batches_tracked', tensor(13572)),\n              ('layer3.3.conv2.weight',\n               tensor([[[[ 2.0515e-02, -3.1368e-02, -1.5233e-02],\n                         [-6.6139e-03,  2.1015e-03, -1.7741e-02],\n                         [ 6.5658e-03, -2.2816e-02, -3.2469e-03]],\n               \n                        [[ 5.2192e-02,  6.1808e-02,  1.3830e-02],\n                         [ 2.8287e-02,  9.4478e-03,  2.7515e-02],\n                         [ 9.3762e-03, -3.7182e-03,  1.9592e-03]],\n               \n                        [[ 1.6168e-02, -1.8371e-02, -6.2352e-03],\n                         [-3.5323e-02, -3.8788e-02,  2.2246e-02],\n                         [-1.9515e-02, -3.4834e-02, -5.4332e-03]],\n               \n                        ...,\n               \n                        [[ 2.4496e-03,  1.8805e-03, -3.5811e-02],\n                         [ 1.7045e-02,  2.1923e-02,  1.7641e-02],\n                         [ 4.3646e-03,  3.4077e-02, -5.4300e-03]],\n               \n                        [[-1.8426e-02, -3.3571e-03, -1.7187e-02],\n                         [ 1.4764e-02,  2.0518e-02,  3.8592e-02],\n                         [-1.0729e-02,  1.4693e-02,  2.6691e-02]],\n               \n                        [[ 1.6070e-02, -1.5254e-02,  4.1668e-04],\n                         [-3.5925e-03, -2.5192e-02, -1.5083e-02],\n                         [-3.0384e-02, -4.0295e-03, -1.8992e-02]]],\n               \n               \n                       [[[ 1.1022e-02, -7.0115e-02, -1.8230e-02],\n                         [-8.4060e-03, -2.8697e-02,  1.7692e-02],\n                         [ 1.6049e-02,  5.1161e-02,  6.7261e-02]],\n               \n                        [[ 6.8910e-03,  7.7207e-04, -9.9167e-03],\n                         [ 8.2397e-03,  1.3669e-02, -5.2377e-02],\n                         [-1.3763e-03,  2.9169e-02,  2.9690e-03]],\n               \n                        [[ 4.4270e-02, -1.7570e-02, -1.2146e-02],\n                         [-1.6671e-02, -2.0102e-02,  6.0945e-03],\n                         [ 3.7377e-02, -2.4310e-02, -9.7379e-03]],\n               \n                        ...,\n               \n                        [[-1.7630e-02, -1.1207e-02, -2.1129e-02],\n                         [-7.9344e-03,  6.8444e-03,  1.7671e-02],\n                         [ 2.0164e-05,  4.9008e-02,  4.6152e-02]],\n               \n                        [[-1.6101e-02,  2.7046e-02,  1.6012e-02],\n                         [-4.5518e-02,  1.0710e-02, -5.2011e-02],\n                         [-1.8652e-02,  9.8910e-04, -2.6732e-02]],\n               \n                        [[ 1.8670e-02,  2.5552e-02,  2.5569e-02],\n                         [ 1.3252e-02, -7.5959e-03, -4.8017e-03],\n                         [ 2.2970e-03, -2.4248e-02, -1.8094e-02]]],\n               \n               \n                       [[[-2.4354e-02, -1.4252e-02,  1.9680e-02],\n                         [-5.9669e-03, -3.5570e-03,  1.9521e-02],\n                         [ 1.0702e-02,  1.3695e-02,  3.5587e-02]],\n               \n                        [[ 1.2098e-02,  8.9433e-03,  1.0723e-02],\n                         [-3.2797e-02, -9.6238e-03, -2.2948e-02],\n                         [-4.2956e-03, -1.8588e-02, -2.1784e-02]],\n               \n                        [[-4.9762e-02,  2.7594e-02,  3.0767e-02],\n                         [-7.7672e-03, -1.0170e-02,  7.3435e-03],\n                         [-1.4709e-02, -3.3052e-02, -3.0430e-02]],\n               \n                        ...,\n               \n                        [[-2.9805e-02, -1.4101e-02, -1.5062e-02],\n                         [-3.1180e-03, -2.1520e-02,  9.8633e-03],\n                         [ 4.0308e-03,  4.2535e-03, -2.2982e-02]],\n               \n                        [[-4.0158e-02, -5.4039e-03,  3.9028e-03],\n                         [ 4.4488e-02,  2.2808e-02,  3.6558e-02],\n                         [ 4.7591e-02,  3.2509e-02,  1.7101e-02]],\n               \n                        [[ 1.0530e-02, -1.5705e-03,  6.2585e-03],\n                         [ 5.3463e-03,  1.3358e-02,  1.1349e-02],\n                         [-3.0563e-03,  6.2129e-03,  2.0051e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-1.7036e-02, -9.9336e-03,  2.2905e-02],\n                         [ 3.6736e-02, -9.2596e-04,  1.4912e-02],\n                         [ 4.7060e-02,  5.3708e-02, -1.6480e-02]],\n               \n                        [[ 2.1972e-02, -2.6460e-02,  9.4520e-03],\n                         [ 1.4410e-03, -1.8852e-02, -3.0299e-02],\n                         [-3.0720e-03, -9.6031e-03,  1.0990e-02]],\n               \n                        [[ 6.4807e-03, -1.7585e-02,  2.7030e-02],\n                         [-1.5398e-02, -3.9825e-03,  8.6402e-03],\n                         [-2.3463e-02, -2.5088e-04, -6.6632e-03]],\n               \n                        ...,\n               \n                        [[-1.7515e-02, -8.1271e-03, -4.9489e-03],\n                         [ 6.5796e-03, -2.0602e-02,  3.7071e-02],\n                         [ 2.6977e-02, -1.6734e-02,  3.8263e-02]],\n               \n                        [[ 1.9260e-02, -4.7690e-03, -2.9572e-02],\n                         [-9.6822e-03,  2.8796e-03, -1.1591e-02],\n                         [-7.0058e-04,  1.3931e-02,  5.2771e-02]],\n               \n                        [[ 3.3726e-03, -2.6392e-02, -2.2309e-02],\n                         [-4.1018e-02, -1.4278e-02, -5.2659e-02],\n                         [-1.0895e-02, -2.2742e-02, -7.6450e-03]]],\n               \n               \n                       [[[ 1.1867e-02,  5.4862e-02,  1.9135e-02],\n                         [-3.4086e-04,  6.5043e-02,  4.7561e-02],\n                         [-1.3620e-02,  2.6392e-02,  5.0679e-02]],\n               \n                        [[ 2.7474e-03,  2.3138e-02, -3.9352e-03],\n                         [-7.2861e-03, -2.6150e-02, -1.4499e-03],\n                         [-4.5638e-02, -5.3594e-03,  2.8084e-02]],\n               \n                        [[ 2.3193e-02,  2.7933e-02,  3.2554e-02],\n                         [ 5.0743e-02,  1.3500e-02,  2.5520e-02],\n                         [-4.9901e-02, -3.9683e-02, -5.1930e-02]],\n               \n                        ...,\n               \n                        [[-1.6147e-02,  8.9710e-03,  4.3056e-03],\n                         [-2.1224e-02,  4.0228e-03,  1.0973e-03],\n                         [ 2.6043e-02,  5.6768e-03, -1.8491e-02]],\n               \n                        [[ 2.5150e-03, -6.0699e-03,  1.5317e-02],\n                         [ 9.8678e-03, -5.0294e-02, -3.6053e-02],\n                         [ 5.4578e-03, -1.7063e-02, -4.2147e-02]],\n               \n                        [[-6.4941e-03,  3.0525e-02,  2.0444e-02],\n                         [ 2.0335e-02,  3.0679e-02,  1.7811e-02],\n                         [-1.6825e-02,  1.2395e-03, -2.4531e-02]]],\n               \n               \n                       [[[-1.9022e-02,  1.6771e-03, -2.2378e-03],\n                         [-9.1444e-03,  5.0931e-03,  2.7061e-02],\n                         [-2.2535e-02,  3.6020e-02,  2.7706e-02]],\n               \n                        [[ 3.3678e-04,  3.1480e-02,  1.5093e-02],\n                         [ 1.5663e-02, -7.8872e-03, -3.5249e-02],\n                         [ 1.8073e-02, -3.0548e-02, -2.0953e-02]],\n               \n                        [[ 1.6793e-03,  5.1730e-03,  3.0155e-02],\n                         [ 2.4309e-02,  1.8486e-02,  4.2249e-02],\n                         [ 1.9391e-02,  2.3032e-02,  1.6250e-02]],\n               \n                        ...,\n               \n                        [[ 1.8220e-03,  1.5381e-02, -1.2607e-02],\n                         [ 4.6662e-03,  1.0439e-02, -1.6583e-03],\n                         [-3.6080e-02, -2.8070e-02, -6.4231e-02]],\n               \n                        [[-1.9125e-03,  3.7428e-02,  2.5717e-02],\n                         [ 5.0348e-02, -2.5546e-02, -2.1494e-02],\n                         [ 1.1764e-02, -3.0739e-02,  1.7397e-02]],\n               \n                        [[-1.7393e-02,  6.7749e-03,  1.5728e-02],\n                         [ 7.7112e-03,  5.6589e-03,  1.3665e-04],\n                         [-1.5115e-02, -2.0535e-02,  2.4041e-02]]]])),\n              ('layer3.3.bn2.weight',\n               tensor([1.0072, 0.9957, 0.9653, 0.9584, 1.0700, 1.0058, 1.0040, 0.9599, 1.0076,\n                       0.9872, 0.9579, 1.0254, 0.9499, 0.9729, 0.9820, 0.9903, 0.9990, 0.9765,\n                       0.9939, 0.9970, 0.9514, 1.0018, 1.0119, 0.9682, 0.9825, 0.9542, 0.9960,\n                       0.9477, 1.1011, 0.9707, 1.0070, 1.0294, 0.9711, 1.0311, 1.0181, 1.0245,\n                       1.0278, 1.0568, 0.9868, 1.0216, 0.9151, 0.9705, 1.0002, 0.9928, 0.9977,\n                       0.9334, 1.0040, 0.9495, 1.0037, 1.0482, 0.9753, 0.9904, 0.9967, 1.0026,\n                       1.0570, 0.9604, 0.9650, 0.9698, 0.9716, 0.9915, 1.0312, 0.9632, 0.9787,\n                       1.0244, 1.0138, 1.0105, 0.9969, 1.0183, 0.9793, 0.9802, 1.0200, 0.9823,\n                       0.9995, 1.0152, 0.9690, 0.9658, 1.0154, 0.9572, 0.9786, 0.9386, 0.9681,\n                       1.0121, 1.0025, 0.9644, 1.0195, 0.9558, 0.9839, 1.0254, 0.9591, 1.0044,\n                       1.0058, 1.0561, 0.9626, 1.0175, 1.0476, 1.0640, 1.0251, 0.9585, 1.0078,\n                       1.0027, 0.9581, 0.9853, 1.0116, 0.9553, 0.9538, 0.9785, 1.0546, 0.9711,\n                       0.9372, 0.9769, 1.0570, 0.9595, 0.9505, 0.9998, 0.9700, 0.9855, 0.9539,\n                       0.9662, 1.0106, 0.9542, 1.0884, 0.9917, 0.9774, 1.0252, 0.9318, 0.9657,\n                       1.0391, 1.0517, 0.9704, 1.0142, 1.0078, 0.9211, 0.9369, 0.9649, 0.9611,\n                       1.0159, 0.9945, 1.0215, 1.0833, 1.0142, 0.9967, 0.9584, 0.9819, 1.0332,\n                       0.9998, 0.9890, 0.9818, 0.9875, 0.9898, 0.9957, 1.0047, 0.9729, 0.9976,\n                       1.0040, 0.9859, 0.9970, 1.0547, 0.9665, 1.0474, 1.0652, 1.0263, 0.9396,\n                       0.9394, 1.0124, 1.1157, 0.9781, 0.9959, 0.9764, 0.9474, 1.0536, 0.9523,\n                       0.9877, 1.0222, 1.0294, 1.0191, 1.0236, 0.9725, 1.0194, 0.9599, 1.0072,\n                       1.0595, 1.0265, 1.0096, 0.9587, 1.0376, 1.0200, 0.9289, 0.9832, 1.0002,\n                       1.0063, 0.9483, 0.9594, 0.9929, 1.0372, 0.9753, 0.9487, 1.0214, 0.9644,\n                       1.0209, 0.9800, 1.0003, 1.0185, 0.9719, 0.9932, 0.9671, 1.0059, 0.9803,\n                       0.9399, 0.9964, 1.0288, 0.9779, 1.0220, 1.0285, 0.9823, 0.9750, 0.9690,\n                       0.9816, 0.9733, 1.0002, 0.9860, 1.0189, 0.9745, 1.0288, 1.0441, 1.0083,\n                       0.9998, 1.0788, 1.0267, 0.9691, 0.9836, 0.9704, 1.0282, 0.9945, 0.9661,\n                       0.9747, 0.9550, 1.0450, 0.9402, 0.9353, 1.0100, 0.9700, 0.9649, 1.0066,\n                       0.9833, 1.0406, 1.0008, 0.9693, 0.9836, 1.0909, 0.9693, 0.9575, 0.9852,\n                       1.0054, 1.0473, 1.0535, 0.9852])),\n              ('layer3.3.bn2.bias',\n               tensor([-5.2568e-02, -4.6910e-02, -1.0183e-01, -1.0029e-01, -1.4930e-01,\n                       -4.9852e-02, -4.3982e-02, -6.7952e-02, -1.3365e-01, -8.1125e-02,\n                       -5.3571e-02, -4.7386e-02, -6.2630e-02, -1.1729e-01, -1.0825e-01,\n                       -2.7724e-02, -8.5531e-02, -7.1814e-02, -8.7047e-02, -5.1900e-02,\n                       -8.7358e-02, -6.3109e-02, -6.6594e-02, -8.3107e-02, -5.1934e-02,\n                       -4.8786e-02, -3.4341e-02, -1.1172e-01,  5.5807e-03, -8.1097e-02,\n                       -6.1220e-02, -3.5685e-02, -9.4634e-02, -9.4421e-02, -7.5970e-02,\n                       -5.5297e-02, -7.8747e-02, -1.7978e-02, -1.0623e-01, -4.0341e-02,\n                       -7.6769e-02, -1.1864e-01, -7.3410e-02, -1.2352e-01, -1.0579e-01,\n                       -8.1704e-02, -9.5939e-02, -9.1248e-02, -1.4861e-01, -7.6568e-02,\n                       -1.0189e-01, -4.7613e-02, -4.3745e-02, -8.1574e-02, -6.5830e-03,\n                       -5.1769e-02, -6.7051e-02, -9.5627e-02, -8.2331e-02, -5.3017e-03,\n                       -8.0110e-02, -4.3321e-02, -9.1465e-02, -8.2722e-02, -5.3050e-02,\n                       -5.3872e-02, -5.7877e-02, -1.3525e-01, -4.8619e-02, -9.3847e-02,\n                       -1.1120e-01, -5.3303e-02, -6.8501e-02, -1.0483e-01, -5.5150e-02,\n                       -5.3821e-02, -9.6413e-02, -7.6680e-02, -1.2851e-01, -9.5582e-02,\n                       -1.3363e-01, -2.0495e-02, -9.0043e-02, -9.4133e-02,  3.5535e-03,\n                       -1.2700e-01, -1.1989e-01, -5.6154e-02, -6.2101e-02, -1.1717e-01,\n                       -1.0205e-01, -1.3719e-02, -8.4489e-02, -3.7118e-02, -9.1814e-02,\n                       -5.1748e-02, -1.2227e-01, -1.3371e-01, -6.7892e-02, -6.7853e-02,\n                       -5.5270e-02, -9.8712e-02, -5.6088e-02, -1.1451e-01, -1.2916e-01,\n                       -1.0223e-01, -3.4194e-02, -7.3514e-02, -4.4742e-02, -9.5413e-02,\n                       -1.2542e-01, -1.3602e-01, -1.1808e-01, -7.7558e-02, -5.9000e-02,\n                       -1.2186e-01, -9.5554e-02, -7.2147e-02, -6.7972e-02, -7.0255e-02,\n                       -7.8517e-02, -6.5611e-02, -4.6932e-02, -8.2861e-02, -1.0794e-01,\n                       -1.1177e-01, -1.8359e-01, -1.0992e-01, -6.7091e-02, -8.0559e-02,\n                       -9.2100e-02, -5.8341e-02, -1.0584e-01, -9.8790e-02, -6.1886e-02,\n                       -9.6454e-03, -4.4350e-02, -9.3888e-02, -9.5678e-02, -7.8350e-02,\n                       -1.0208e-02, -3.3820e-02, -1.0161e-01,  5.8357e-03, -3.3638e-02,\n                       -6.2057e-02, -4.1546e-02, -7.3119e-02, -1.0730e-01, -8.8545e-02,\n                       -9.1483e-02, -4.7890e-02, -8.0288e-02, -9.0663e-02, -8.9809e-02,\n                        4.9088e-03, -7.6123e-02, -1.0004e-02, -9.5782e-02, -9.1453e-02,\n                       -7.5142e-02, -8.6806e-02, -1.2930e-01, -3.6559e-02, -1.2418e-01,\n                       -3.3811e-02, -5.5326e-02, -8.1387e-02, -7.3020e-02, -8.7995e-02,\n                       -5.0229e-02, -1.1662e-01, -1.0117e-01, -1.0520e-01, -4.3680e-02,\n                       -5.4345e-02, -7.5602e-02, -2.5582e-01, -1.1345e-01, -8.3927e-02,\n                       -3.4845e-02, -1.0959e-01, -7.0988e-02, -1.1129e-01, -2.3445e-02,\n                       -4.4618e-02, -5.1438e-02, -9.8354e-02, -1.5583e-02, -7.0558e-02,\n                       -7.1282e-02, -5.8760e-02, -2.9380e-02, -1.0735e-01, -5.1454e-02,\n                       -4.0325e-02, -6.5809e-02, -3.4121e-02, -1.0787e-01, -4.7873e-02,\n                       -1.0353e-01, -2.4900e-02, -1.2072e-02, -1.2093e-01, -9.8010e-02,\n                       -1.5311e-02, -9.3335e-02, -2.4904e-02, -9.2023e-02, -6.7732e-02,\n                       -3.9422e-02, -6.6769e-02,  1.2358e-02, -1.2576e-01, -1.1828e-01,\n                       -3.2225e-02, -6.4361e-02, -1.1303e-01, -9.0342e-02, -9.4428e-04,\n                       -1.1934e-01, -1.2146e-01, -7.1268e-02, -1.3366e-01, -7.6636e-02,\n                       -1.0361e-01, -9.3017e-02, -9.3190e-02, -1.3236e-01, -3.1590e-02,\n                       -6.4250e-02, -7.2722e-02, -9.1741e-02, -6.6666e-02, -5.9332e-02,\n                       -6.8995e-02, -9.7725e-02, -1.0157e-01, -1.7372e-01, -1.2517e-01,\n                       -7.7511e-02, -3.3122e-02, -1.0549e-01, -1.2918e-01, -9.5312e-03,\n                       -1.2951e-01, -1.1847e-01, -8.3434e-02, -8.5188e-02, -2.2574e-03,\n                       -6.2096e-02, -8.5570e-02, -1.0845e-01,  2.4154e-04, -8.2013e-02,\n                       -1.1624e-01])),\n              ('layer3.3.bn2.running_mean',\n               tensor([-2.7343e-01,  1.7071e-02,  3.0359e-02,  1.1836e-01,  4.6509e-01,\n                        4.1992e-01, -5.4193e-01, -2.1742e-01,  5.8352e-02, -1.8623e-01,\n                        1.8831e-01, -4.3433e-01,  8.7091e-01,  2.9369e-02, -9.3497e-01,\n                       -9.9126e-02, -8.1013e-01, -9.7705e-02,  6.0373e-01,  4.3436e-02,\n                        1.1817e-01, -6.3724e-01, -1.7338e-01,  2.1848e-01,  1.5888e-01,\n                       -2.0924e-01, -1.0888e+00,  3.1911e-01, -3.1568e-01,  4.1518e-01,\n                       -2.5211e-01, -1.2344e-01,  4.9628e-01,  1.4847e-01, -9.1606e-01,\n                        9.5206e-01, -5.4574e-01,  4.9548e-01, -5.2532e-01,  2.4336e-02,\n                       -2.2685e-01, -2.7198e-01,  1.4854e-01,  2.6293e-01,  1.6257e-01,\n                        1.9889e-02, -1.0032e-01,  1.1069e-03, -2.9557e-01, -3.4709e-01,\n                       -1.7684e-01, -1.7216e-01, -2.5255e-01, -3.1046e-01, -6.3966e-01,\n                       -4.1769e-01,  1.4601e-03,  9.5769e-02, -5.1579e-01,  1.6776e+00,\n                       -8.9076e-01,  1.7635e-01, -8.6591e-01, -2.4039e-01, -5.1059e-01,\n                       -7.4616e-01, -2.0630e-01, -7.3073e-01,  8.5201e-01, -1.6293e-01,\n                       -7.9842e-01, -2.3774e-01,  3.5932e-01,  3.0774e-01, -1.4036e-01,\n                        2.3286e-01, -6.4972e-01,  1.1383e-01, -2.0829e-01, -7.5009e-02,\n                        8.0652e-01, -1.2006e-01, -1.1516e+00,  4.7223e-01, -9.6150e-01,\n                        5.1600e-01, -2.5964e-01,  1.0102e-01, -5.5892e-02,  3.9908e-01,\n                       -3.2601e-01, -4.2954e-02, -1.4813e-01, -1.5283e-01, -3.8913e-01,\n                       -6.4457e-01,  6.1010e-01,  6.5726e-01,  3.1096e-01, -3.3569e-01,\n                       -6.9158e-01, -1.1000e-01, -3.4042e-01,  7.0620e-01, -6.7294e-01,\n                        3.5744e-02,  1.8651e-01, -6.2436e-01,  2.9849e-01, -2.2862e-01,\n                       -4.9128e-01, -5.6340e-01,  6.2714e-01, -9.0490e-01, -4.9499e-01,\n                       -7.3437e-01, -4.8494e-01,  2.2655e-01, -7.3897e-01,  5.1670e-03,\n                       -1.0579e+00, -5.4859e-01, -1.7122e-01, -2.9711e-01,  6.9710e-02,\n                       -1.1878e-01, -5.0386e-01, -3.7459e-01,  2.1809e-01, -1.5414e-01,\n                       -5.9421e-01, -7.3119e-01, -1.6464e-01, -3.8198e-01, -1.2708e-01,\n                       -8.7973e-01, -1.0506e+00, -1.8327e-01, -4.0895e-01,  1.1121e-01,\n                        1.0155e+00,  1.4594e-01, -5.9955e-01, -4.4929e-01, -6.5545e-01,\n                       -1.1658e-01,  1.0868e-01,  5.2781e-01,  9.2174e-03, -2.1308e-01,\n                       -4.6860e-01,  4.3291e-01, -4.7911e-01,  4.4155e-02, -9.6345e-01,\n                        1.1364e+00, -4.8570e-01,  1.7135e-01,  6.7148e-01, -4.2636e-02,\n                        5.2183e-02,  1.4461e-01, -4.2030e-01, -7.2195e-01, -6.3433e-01,\n                       -6.4878e-01, -6.8227e-01, -6.9799e-02, -1.3247e-01, -4.9167e-01,\n                       -1.8834e-01, -1.6672e-01, -8.2209e-02, -3.4113e-01,  3.7763e-01,\n                       -3.2664e-01, -6.5118e-01, -1.3380e-01,  2.3145e-01, -1.2977e+00,\n                        8.3200e-01, -2.3722e-01, -1.1852e-01, -2.8874e-01,  1.1795e-01,\n                       -1.8029e-01, -2.0563e-01, -7.4116e-01, -9.2901e-01, -1.3841e+00,\n                        2.0109e-01, -5.5846e-02, -3.3601e-01, -2.4301e-01, -8.3289e-02,\n                       -6.4766e-01, -6.5492e-01, -4.6103e-01,  5.6432e-01,  1.9364e-01,\n                       -5.1901e-01,  9.9518e-02, -5.3517e-01, -3.4132e-01,  1.1130e-01,\n                        4.0850e-01,  3.5368e-01, -1.7370e-01,  6.7465e-02, -1.0823e+00,\n                       -1.7134e-01, -5.3764e-01, -9.3083e-01,  3.7319e-01, -2.2722e-01,\n                       -1.2851e-01, -3.9737e-01,  1.4138e-01, -1.8701e-01,  5.8748e-01,\n                       -9.8118e-01, -7.8923e-01, -6.1569e-01, -2.6854e-01, -1.2818e-01,\n                        3.2730e-01, -3.4581e-01, -4.4545e-01,  5.4008e-01, -4.6769e-01,\n                        1.0346e+00,  1.0094e+00,  1.0485e+00,  2.1136e-01, -1.6478e-01,\n                        1.3546e-01,  8.9875e-01, -7.0667e-02, -4.9563e-01, -1.2112e-01,\n                       -1.2232e-01, -6.5595e-01, -6.8563e-01, -2.5549e-02, -3.3676e-01,\n                        2.4893e-01,  1.4167e-01, -4.1350e-01, -3.2909e-01, -5.7035e-01,\n                        1.0269e-01, -4.8737e-01,  1.2722e-01, -9.8347e-01,  1.4622e-01,\n                       -1.5810e-02])),\n              ('layer3.3.bn2.running_var',\n               tensor([0.8321, 0.8836, 0.7414, 0.8213, 1.5942, 0.8943, 1.0409, 1.1227, 0.8834,\n                       0.7072, 0.8285, 1.0128, 0.9047, 0.9018, 0.8869, 0.8534, 0.9294, 0.8256,\n                       0.8689, 0.8721, 0.7459, 0.8506, 0.8800, 0.7788, 0.7141, 0.7545, 0.8306,\n                       0.8132, 1.2531, 0.6420, 0.9289, 0.9631, 0.9259, 0.9914, 0.9439, 1.5495,\n                       0.8386, 1.1720, 0.7835, 0.7654, 0.7385, 0.8446, 0.6926, 0.8149, 0.8937,\n                       0.8001, 0.7738, 0.7333, 0.8819, 1.0025, 0.8498, 0.9457, 0.7246, 0.7803,\n                       0.9203, 0.9591, 0.6653, 0.8968, 0.8337, 1.2062, 0.9517, 0.8376, 0.9218,\n                       0.8732, 1.0540, 0.7640, 0.7493, 1.0872, 1.3730, 1.2680, 1.2853, 0.7219,\n                       0.9951, 0.7986, 0.7771, 0.7663, 1.2997, 0.8923, 0.9090, 0.8197, 0.8429,\n                       0.9688, 0.7841, 0.7525, 0.9107, 1.0912, 0.8277, 0.8369, 0.7201, 0.9439,\n                       1.0875, 0.8312, 0.8137, 0.7064, 0.9688, 1.0249, 1.1648, 0.7751, 1.2491,\n                       0.9267, 0.7121, 0.7894, 0.7198, 1.0727, 1.0418, 1.0002, 0.7404, 0.7297,\n                       0.7330, 0.8209, 1.2467, 0.8989, 0.9389, 0.8684, 1.0149, 0.9053, 0.7449,\n                       0.7908, 0.9951, 0.6440, 1.3839, 0.9733, 0.8524, 0.8836, 0.8337, 0.8068,\n                       0.8744, 1.0575, 0.7511, 1.0924, 0.9181, 0.6941, 0.7387, 0.7411, 1.0435,\n                       0.8563, 0.8839, 1.0396, 1.0836, 0.8510, 0.9281, 0.7175, 1.1568, 0.7662,\n                       0.7035, 0.8396, 0.7466, 1.0234, 0.8173, 0.7560, 0.9542, 0.7495, 0.8597,\n                       0.9507, 0.7709, 0.9862, 1.0250, 0.5797, 1.1647, 1.1593, 0.9773, 0.8163,\n                       0.7407, 0.7044, 1.4556, 0.9633, 0.8390, 0.6902, 0.7457, 1.2009, 0.6860,\n                       0.6284, 1.0179, 0.9868, 0.8820, 0.9159, 0.7879, 1.2822, 0.8573, 0.8844,\n                       0.9760, 0.9041, 0.8044, 0.8436, 0.8468, 0.9159, 0.6414, 0.8258, 0.8496,\n                       1.0651, 0.8468, 0.8969, 0.8117, 1.0464, 0.7782, 0.8236, 0.8216, 0.7993,\n                       1.0792, 0.8957, 0.9932, 1.1810, 0.6542, 0.8868, 0.8430, 0.9748, 0.9244,\n                       0.6910, 0.7650, 1.0820, 0.6635, 0.8786, 0.9023, 0.8317, 0.8996, 0.7694,\n                       0.7025, 0.8719, 0.7290, 0.8906, 0.9700, 1.0199, 0.7389, 1.1871, 0.8079,\n                       1.2448, 1.3225, 0.7725, 0.8954, 0.6643, 1.1262, 1.1015, 0.9418, 0.6639,\n                       0.7996, 0.8069, 1.9772, 0.7741, 0.7078, 0.9353, 0.9585, 0.8562, 1.4415,\n                       0.8348, 0.8513, 0.8968, 0.7412, 0.8033, 1.0579, 0.6636, 0.6499, 1.0618,\n                       0.8637, 0.8359, 1.1919, 0.7545])),\n              ('layer3.3.bn2.num_batches_tracked', tensor(13572)),\n              ('layer3.3.conv3.weight',\n               tensor([[[[ 0.0779]],\n               \n                        [[-0.0077]],\n               \n                        [[-0.0054]],\n               \n                        ...,\n               \n                        [[-0.0263]],\n               \n                        [[ 0.0423]],\n               \n                        [[ 0.0361]]],\n               \n               \n                       [[[ 0.0279]],\n               \n                        [[-0.0184]],\n               \n                        [[-0.0083]],\n               \n                        ...,\n               \n                        [[-0.0768]],\n               \n                        [[-0.0702]],\n               \n                        [[ 0.0334]]],\n               \n               \n                       [[[-0.0001]],\n               \n                        [[-0.0001]],\n               \n                        [[ 0.0166]],\n               \n                        ...,\n               \n                        [[-0.0617]],\n               \n                        [[-0.0063]],\n               \n                        [[-0.0498]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0080]],\n               \n                        [[ 0.0186]],\n               \n                        [[ 0.0098]],\n               \n                        ...,\n               \n                        [[-0.0053]],\n               \n                        [[-0.0189]],\n               \n                        [[-0.0128]]],\n               \n               \n                       [[[-0.0246]],\n               \n                        [[ 0.0208]],\n               \n                        [[ 0.0012]],\n               \n                        ...,\n               \n                        [[ 0.0471]],\n               \n                        [[-0.0521]],\n               \n                        [[-0.0665]]],\n               \n               \n                       [[[-0.0182]],\n               \n                        [[ 0.0845]],\n               \n                        [[-0.0424]],\n               \n                        ...,\n               \n                        [[-0.0112]],\n               \n                        [[-0.0191]],\n               \n                        [[-0.0560]]]])),\n              ('layer3.3.bn3.weight',\n               tensor([ 0.1608,  0.2333,  0.0143,  ..., -0.1088, -0.1720, -0.1674])),\n              ('layer3.3.bn3.bias',\n               tensor([ 0.0876,  0.0740,  0.0096,  ...,  0.0469, -0.0144,  0.0674])),\n              ('layer3.3.bn3.running_mean',\n               tensor([-0.1526,  0.0473, -0.0670,  ..., -0.1613, -0.1892, -0.0563])),\n              ('layer3.3.bn3.running_var',\n               tensor([0.0937, 0.1354, 0.0619,  ..., 0.0904, 0.1429, 0.1217])),\n              ('layer3.3.bn3.num_batches_tracked', tensor(13572)),\n              ('layer3.4.conv1.weight',\n               tensor([[[[ 0.0066]],\n               \n                        [[-0.0018]],\n               \n                        [[ 0.0961]],\n               \n                        ...,\n               \n                        [[-0.0442]],\n               \n                        [[-0.0217]],\n               \n                        [[-0.0111]]],\n               \n               \n                       [[[-0.0325]],\n               \n                        [[ 0.0787]],\n               \n                        [[-0.0204]],\n               \n                        ...,\n               \n                        [[ 0.0248]],\n               \n                        [[-0.0179]],\n               \n                        [[-0.0023]]],\n               \n               \n                       [[[ 0.0278]],\n               \n                        [[ 0.0529]],\n               \n                        [[ 0.0354]],\n               \n                        ...,\n               \n                        [[-0.0176]],\n               \n                        [[-0.0176]],\n               \n                        [[-0.0058]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0774]],\n               \n                        [[ 0.0282]],\n               \n                        [[-0.0229]],\n               \n                        ...,\n               \n                        [[ 0.0027]],\n               \n                        [[ 0.0116]],\n               \n                        [[ 0.0003]]],\n               \n               \n                       [[[-0.0008]],\n               \n                        [[-0.0119]],\n               \n                        [[-0.0276]],\n               \n                        ...,\n               \n                        [[-0.0453]],\n               \n                        [[-0.0858]],\n               \n                        [[ 0.0017]]],\n               \n               \n                       [[[-0.0297]],\n               \n                        [[-0.0263]],\n               \n                        [[-0.0172]],\n               \n                        ...,\n               \n                        [[-0.0652]],\n               \n                        [[ 0.0440]],\n               \n                        [[ 0.0276]]]])),\n              ('layer3.4.bn1.weight',\n               tensor([0.9798, 1.0187, 0.9498, 0.9604, 0.9227, 0.9909, 1.0130, 1.0256, 0.9937,\n                       0.9701, 1.0287, 0.9720, 0.9898, 0.9983, 0.9661, 1.0259, 1.0233, 0.9648,\n                       0.9909, 0.9746, 0.9705, 1.0198, 0.9384, 0.9906, 0.9996, 0.9987, 0.9729,\n                       0.9532, 1.0182, 0.9571, 1.0689, 0.9514, 0.9799, 1.0054, 0.9712, 1.0063,\n                       1.0919, 0.9414, 1.0421, 0.9320, 0.9362, 0.9697, 0.9870, 0.9945, 1.0242,\n                       1.0689, 1.0211, 1.0509, 0.9953, 0.9947, 0.9905, 1.0057, 1.0051, 0.9881,\n                       0.9846, 1.0852, 1.0244, 1.0191, 0.9952, 1.0713, 1.0203, 1.0246, 1.0285,\n                       0.9888, 0.9797, 0.9791, 1.0183, 0.9776, 0.9537, 0.9468, 0.9949, 1.0409,\n                       1.0727, 1.0323, 1.0018, 0.9912, 1.0065, 0.9788, 0.9680, 0.9962, 0.9377,\n                       1.0136, 0.9616, 1.0289, 0.9598, 0.9976, 0.9785, 1.0129, 0.9807, 0.9509,\n                       1.0003, 0.9826, 1.0552, 1.0171, 1.0196, 0.9492, 1.0122, 1.0134, 1.0171,\n                       0.9543, 0.9562, 1.0063, 1.0253, 0.9448, 0.9927, 0.9798, 1.0087, 1.0216,\n                       1.0203, 0.9748, 0.9435, 1.0298, 0.9815, 1.0285, 0.9840, 1.0052, 0.9600,\n                       1.0241, 0.9742, 0.9537, 0.9864, 1.0232, 0.9944, 0.9796, 1.0044, 1.0248,\n                       0.9599, 0.9989, 1.0324, 0.9639, 1.0580, 0.9783, 0.9933, 0.9795, 0.9864,\n                       0.9859, 1.0003, 0.9941, 1.0374, 1.0201, 0.9872, 0.9737, 0.9988, 0.9629,\n                       1.0067, 0.9774, 0.9338, 0.9775, 0.9500, 1.0327, 1.0101, 0.9638, 0.9515,\n                       0.9740, 1.0286, 0.9659, 0.9989, 0.9923, 1.0103, 0.9728, 1.0077, 1.0185,\n                       0.9766, 1.0105, 0.9627, 0.9920, 0.9829, 0.9838, 1.0119, 0.9449, 0.9477,\n                       0.9891, 1.0203, 1.0179, 0.9469, 1.0324, 0.9893, 0.9906, 0.9838, 1.0160,\n                       0.9614, 1.0197, 0.9774, 0.9889, 1.0075, 1.0305, 0.9809, 0.9709, 0.9689,\n                       1.0226, 0.9990, 0.9526, 0.9899, 0.9317, 1.0241, 1.0026, 1.0505, 0.9752,\n                       1.0361, 0.9595, 0.9638, 1.0370, 0.9464, 1.0228, 0.9349, 0.9412, 1.0384,\n                       1.0002, 0.9548, 0.9795, 1.0087, 0.9761, 0.9516, 1.0381, 0.9491, 1.0050,\n                       0.9853, 0.9811, 0.9762, 0.9925, 0.9574, 1.0381, 1.0131, 0.9843, 0.9838,\n                       1.0893, 0.9907, 1.0056, 1.0254, 1.0130, 1.0303, 0.9499, 0.9885, 0.9742,\n                       0.9363, 0.9934, 1.0333, 1.0328, 0.9724, 0.9839, 0.9960, 0.9340, 1.0216,\n                       0.9895, 1.0210, 1.0817, 0.9812, 0.9722, 0.9765, 0.9969, 0.9675, 0.9474,\n                       1.0049, 1.0289, 0.9994, 0.9871])),\n              ('layer3.4.bn1.bias',\n               tensor([-0.1445, -0.1045, -0.0880, -0.1263, -0.1047, -0.0630, -0.0661,  0.0294,\n                       -0.1415, -0.0958, -0.0893, -0.1231, -0.1240, -0.0760, -0.1023, -0.1240,\n                       -0.0856, -0.0909, -0.0794, -0.1058, -0.1237, -0.1207, -0.0862, -0.0582,\n                       -0.0883, -0.1153, -0.0851, -0.1104, -0.0683, -0.0925, -0.0858, -0.1534,\n                       -0.0536, -0.1642, -0.1047, -0.0865, -0.0494, -0.1258, -0.0672, -0.0782,\n                       -0.1617, -0.1344, -0.1016, -0.0787, -0.1503, -0.0916, -0.1495, -0.0603,\n                       -0.1531, -0.0682, -0.0809, -0.1163, -0.1450, -0.1151, -0.1178, -0.0895,\n                       -0.0304,  0.0296, -0.0831, -0.1499, -0.0697, -0.0958, -0.1280, -0.0329,\n                       -0.0640, -0.0284, -0.1469, -0.0588, -0.1188, -0.0972, -0.1160, -0.0733,\n                       -0.0780, -0.1507, -0.2343, -0.0779, -0.1284, -0.1630, -0.0375, -0.1154,\n                       -0.1483, -0.1850, -0.2053, -0.1570, -0.1389, -0.0985, -0.0511, -0.0674,\n                       -0.0259, -0.1819, -0.1315, -0.0936, -0.0571, -0.0974, -0.0300, -0.0954,\n                       -0.2278, -0.1068, -0.2642, -0.0747, -0.0861, -0.0728, -0.1344, -0.1941,\n                       -0.1202, -0.1319, -0.0571, -0.1059, -0.0724, -0.1683, -0.1666, -0.1095,\n                       -0.1385, -0.1465, -0.1298, -0.2405, -0.0782, -0.0616, -0.1814, -0.0888,\n                       -0.0951, -0.0481, -0.1555, -0.1062, -0.0943, -0.0585, -0.0507, -0.2246,\n                       -0.0646, -0.1144, -0.1091, -0.1250, -0.1207, -0.1269, -0.1473, -0.0943,\n                       -0.0780, -0.0395, -0.1429, -0.1023, -0.1180, -0.0873, -0.0975, -0.1626,\n                       -0.1257, -0.1050, -0.1368, -0.1047, -0.0155, -0.1903, -0.1108, -0.0679,\n                       -0.1261, -0.1352, -0.1340, -0.1149, -0.1253, -0.1782, -0.0877, -0.1403,\n                       -0.0881, -0.0876, -0.1068, -0.0478, -0.0735, -0.0707, -0.0712, -0.1067,\n                       -0.0976, -0.0829, -0.1603, -0.0623, -0.0850, -0.1897, -0.2577, -0.1659,\n                       -0.1449, -0.0808, -0.1059, -0.1017, -0.1657, -0.1236, -0.1082, -0.1195,\n                       -0.0641, -0.1122, -0.0755, -0.0506, -0.1018, -0.0642, -0.0702, -0.1268,\n                       -0.0940, -0.2038, -0.0660, -0.0979, -0.0901, -0.0835, -0.1052, -0.0628,\n                       -0.1557, -0.1127, -0.1429, -0.0297, -0.1433, -0.1230, -0.0464, -0.2768,\n                       -0.1456, -0.1159, -0.1004, -0.1305, -0.1224, -0.1239, -0.0704, -0.0510,\n                       -0.2403,  0.0063, -0.1316, -0.1069, -0.1183, -0.0529, -0.1158, -0.1835,\n                       -0.0976, -0.1297, -0.1782, -0.1134, -0.0430, -0.1593, -0.1435, -0.1543,\n                       -0.1873, -0.1008, -0.1582, -0.1643, -0.0820, -0.2319, -0.1370, -0.0612,\n                       -0.0153, -0.1262, -0.1057, -0.1582, -0.0587, -0.1360, -0.0954, -0.1120,\n                       -0.1407, -0.0370, -0.1900, -0.0348, -0.1115, -0.1749, -0.0292, -0.0648])),\n              ('layer3.4.bn1.running_mean',\n               tensor([-0.2248, -0.7971,  0.4432, -1.0414, -0.9098, -0.6024, -0.7337, -0.4783,\n                        0.1417, -0.1148, -0.3435, -0.2078, -1.0964, -0.6647, -1.0110, -0.3514,\n                       -0.9376,  0.4235, -0.6185,  0.0388,  0.1106, -1.3832, -1.7734,  0.2330,\n                        0.2895, -0.5878, -0.1805,  0.5572, -1.0128, -0.3563, -0.7248,  0.0672,\n                       -0.5436, -0.5927,  0.4502, -1.0543,  0.0682,  0.4326, -1.1050,  0.1553,\n                       -0.3220, -1.7926,  0.2305, -0.6574,  0.1012, -0.7507, -0.8182, -1.1719,\n                       -0.4272, -0.9036,  0.2236, -1.1807, -0.0698, -0.4420, -0.0766,  0.0543,\n                       -0.8301, -0.5238, -0.0613, -0.2916, -0.1790, -0.5660, -0.9958, -0.9668,\n                       -0.0477, -0.7831, -0.8872,  0.5514, -1.5111, -0.3865, -0.7969, -0.7091,\n                        0.1362, -0.3760, -0.8328, -0.6208, -0.5882,  0.2020, -0.9336,  0.5367,\n                       -0.7593, -1.0764, -0.1263, -0.6366, -1.0180,  0.6527, -0.5873, -0.0732,\n                        0.7700, -0.1341, -1.5173, -0.9125, -1.2597, -0.3987, -1.2233,  0.2810,\n                       -0.6916, -0.6208, -1.4220, -1.0068, -0.5593, -1.0744, -0.2141, -0.8816,\n                       -1.1372, -0.0462, -1.7929, -1.0119, -1.1373, -0.3145, -0.0044, -0.6126,\n                       -0.3932, -0.7341, -0.5051, -0.3615,  0.2559, -0.7185, -0.9683, -0.6532,\n                        0.1979, -0.5680,  0.4891,  0.2833,  0.9346,  0.0321,  0.0108, -0.5083,\n                        0.0584, -0.8650, -1.4750, -0.4291, -0.4702, -0.5212,  0.2115, -0.2384,\n                        0.3835, -0.0484, -0.2132, -0.5612, -0.0525,  0.4780, -0.2548, -0.6569,\n                       -0.4475, -0.5856, -0.3033, -0.7833,  0.2791, -0.7216,  0.4702, -0.3530,\n                       -0.6980, -0.8075, -0.5110, -0.8190, -1.2838, -0.3817, -0.3383, -0.3023,\n                       -0.7700, -1.1732, -0.8577, -0.4535, -1.4547, -0.4233, -0.3074, -0.5268,\n                       -1.3587,  0.0764, -0.7299,  0.0287,  0.1242,  0.5846, -0.7408, -1.7805,\n                       -0.8064, -0.0667, -0.8911,  0.0275,  0.4150, -1.1792,  0.1376, -0.2717,\n                       -0.8103,  1.0308,  0.0385, -0.8787, -0.7339, -0.2562, -0.9209,  0.2304,\n                        0.0154,  0.3477, -0.6974, -0.4713, -0.0203, -0.5961, -0.1577, -0.8419,\n                       -0.7523, -0.0533,  0.2727,  0.2340,  0.1440, -0.1141, -0.5132, -0.5936,\n                       -0.1700, -0.7148, -0.3585, -0.7023, -0.7404,  0.3686, -0.4905, -0.0379,\n                       -0.3300, -1.1306,  0.1085, -0.4524, -0.8448,  0.0081,  0.5255, -0.1380,\n                        0.5482, -0.7817, -0.6655,  0.7135, -0.5978,  0.5839, -0.0433, -0.4524,\n                       -0.0171, -0.1009, -0.5505, -1.2186, -0.8834, -0.3459, -1.2670,  0.5317,\n                       -0.4405,  0.3021,  1.1005, -0.0717, -0.4198, -0.1246, -0.4171,  0.6535,\n                        0.0898, -0.1089, -0.8468,  0.8576, -0.2415, -0.7829, -1.1698,  0.4091])),\n              ('layer3.4.bn1.running_var',\n               tensor([0.5851, 0.5161, 0.5444, 0.5290, 0.6118, 0.5557, 0.5759, 0.6123, 0.6175,\n                       0.5334, 0.5692, 0.5513, 0.5108, 0.5329, 0.6290, 0.4973, 0.6341, 0.5825,\n                       0.5224, 0.5483, 0.6407, 0.6607, 0.6142, 0.7090, 0.6155, 0.6286, 0.5669,\n                       0.5178, 0.6077, 0.5675, 0.6775, 0.5119, 0.5282, 0.7465, 0.5523, 0.6860,\n                       0.7765, 0.4966, 0.6183, 0.4923, 0.5846, 0.6497, 0.5635, 0.5507, 0.7810,\n                       0.6736, 0.6539, 0.5410, 0.6278, 0.5443, 0.6213, 0.4739, 0.6703, 0.5107,\n                       0.6079, 0.5679, 0.5767, 0.5701, 0.6290, 0.5662, 0.4749, 0.5496, 0.6995,\n                       0.5864, 0.5527, 0.5071, 0.5724, 0.5658, 0.4624, 0.5633, 0.6122, 0.5802,\n                       0.7728, 0.6281, 0.8334, 0.7009, 0.6305, 0.5561, 0.5736, 0.6697, 0.5738,\n                       0.6447, 0.5646, 0.6666, 0.7606, 0.5444, 0.5386, 0.5768, 0.6097, 0.5450,\n                       0.5687, 0.5488, 0.7511, 0.6340, 0.5515, 0.5310, 0.6475, 0.6917, 0.6919,\n                       0.5434, 0.4980, 0.5072, 0.5858, 0.7133, 0.5547, 0.5938, 0.5405, 0.7005,\n                       0.5258, 0.7127, 0.6858, 0.5105, 0.6014, 0.7114, 0.5129, 0.4829, 0.5958,\n                       0.5873, 0.5548, 0.4627, 0.5988, 0.4495, 0.6167, 0.4519, 0.6515, 0.5855,\n                       0.4098, 0.6373, 0.5959, 0.5759, 0.6527, 0.5626, 0.6191, 0.5800, 0.6125,\n                       0.6502, 0.5191, 0.6177, 0.5225, 0.5433, 0.5341, 0.4964, 0.5621, 0.7213,\n                       0.7089, 0.4985, 0.5127, 0.6993, 0.5131, 0.6531, 0.5831, 0.5362, 0.5643,\n                       0.6662, 0.6873, 0.5768, 0.6384, 0.7156, 0.4985, 0.5094, 0.5702, 0.6877,\n                       0.4979, 0.5578, 0.6183, 0.5134, 0.5261, 0.6419, 0.6379, 0.5688, 0.4535,\n                       0.5162, 0.6806, 0.5905, 0.8196, 0.6592, 0.6178, 0.5546, 0.5849, 0.4985,\n                       0.7411, 0.7433, 0.6709, 0.6225, 0.6228, 0.6748, 0.4769, 0.5219, 0.5861,\n                       0.6207, 0.5478, 0.6318, 0.6319, 0.5810, 0.6323, 0.5743, 0.6815, 0.6328,\n                       0.6493, 0.5050, 0.6280, 0.6786, 0.6182, 0.5810, 0.5491, 0.5889, 0.6490,\n                       0.7007, 0.5807, 0.5185, 0.6667, 0.5118, 0.5172, 0.8517, 0.7398, 0.6321,\n                       0.6425, 0.6750, 0.5234, 0.6820, 0.6662, 0.5881, 0.7203, 0.5849, 0.8346,\n                       0.7642, 0.6558, 0.5739, 0.6906, 0.5708, 0.7467, 0.5684, 0.7128, 0.5927,\n                       0.6081, 0.5749, 0.5906, 0.7914, 0.5601, 0.5352, 0.5862, 0.5342, 0.6215,\n                       0.5428, 0.5359, 0.7513, 0.6345, 0.5944, 0.5747, 0.6460, 0.7023, 0.5578,\n                       0.5806, 0.5167, 0.7550, 0.5403])),\n              ('layer3.4.bn1.num_batches_tracked', tensor(13572)),\n              ('layer3.4.conv2.weight',\n               tensor([[[[-5.5462e-03,  5.2293e-03,  4.4855e-02],\n                         [-2.4952e-02,  2.0622e-02,  6.1304e-03],\n                         [-9.1431e-03,  5.7404e-02,  1.8571e-02]],\n               \n                        [[ 1.2388e-02, -8.5708e-03, -7.4526e-03],\n                         [ 1.6308e-02, -6.1642e-03, -3.6804e-04],\n                         [-3.3491e-03,  4.2493e-02,  1.8106e-02]],\n               \n                        [[ 7.8719e-03,  4.0834e-03,  3.5236e-03],\n                         [ 1.1025e-02,  5.2824e-04, -4.7313e-03],\n                         [ 1.8173e-02,  3.3013e-02,  3.7309e-02]],\n               \n                        ...,\n               \n                        [[ 1.4577e-02, -8.5067e-03, -1.0219e-02],\n                         [ 4.6425e-03,  6.7751e-03,  4.9149e-02],\n                         [-5.7086e-03,  4.1230e-02,  2.7586e-02]],\n               \n                        [[ 4.2564e-03,  2.1709e-02, -1.0719e-02],\n                         [-1.1187e-02, -1.5476e-02, -2.6602e-02],\n                         [-3.6416e-02, -3.3159e-03,  1.0250e-02]],\n               \n                        [[ 1.3007e-02, -2.6130e-02, -1.1726e-02],\n                         [ 2.1258e-02, -8.7878e-03, -1.2130e-02],\n                         [-1.9521e-02, -6.2900e-02, -1.4050e-02]]],\n               \n               \n                       [[[-1.4667e-02, -4.4173e-03,  1.1302e-03],\n                         [ 2.8365e-02,  6.6704e-04,  7.6236e-03],\n                         [-6.3544e-03, -4.5819e-03,  3.9669e-02]],\n               \n                        [[-1.4314e-02, -7.3155e-03,  3.1714e-02],\n                         [-1.5796e-02,  4.2526e-02,  4.4337e-03],\n                         [-1.5239e-02,  2.3714e-02,  2.9159e-02]],\n               \n                        [[-1.3682e-02,  2.8048e-02,  8.6298e-04],\n                         [ 5.7783e-03, -8.7800e-03,  2.0989e-02],\n                         [-2.4693e-02,  2.3301e-03,  1.8717e-02]],\n               \n                        ...,\n               \n                        [[ 2.2143e-03, -3.4376e-02, -1.9147e-02],\n                         [-9.9221e-03,  2.6796e-03, -4.1218e-02],\n                         [-2.7094e-02, -2.2231e-03, -6.6571e-03]],\n               \n                        [[ 2.7448e-03,  1.5565e-02, -9.7991e-03],\n                         [-1.1827e-03, -2.4061e-02,  3.2653e-02],\n                         [-9.7919e-03,  6.5784e-02,  3.5526e-02]],\n               \n                        [[-2.9073e-02,  8.2382e-03, -1.6620e-02],\n                         [-6.0019e-02, -2.4329e-03, -1.1746e-02],\n                         [-2.5060e-03, -2.2431e-02, -2.8308e-02]]],\n               \n               \n                       [[[ 7.8165e-03, -3.0821e-02,  6.0890e-03],\n                         [ 7.1154e-03, -2.3638e-02,  4.4471e-02],\n                         [ 7.9859e-03, -2.1297e-02,  3.9662e-02]],\n               \n                        [[-3.3101e-02, -7.3350e-03,  8.4333e-03],\n                         [ 5.7741e-03, -1.9258e-02, -4.4928e-02],\n                         [-4.2394e-03, -1.0049e-02, -4.6677e-02]],\n               \n                        [[ 1.1221e-03, -3.0590e-02,  1.5528e-02],\n                         [-7.7489e-03, -7.2573e-03, -1.6785e-02],\n                         [ 9.9303e-03,  5.1828e-03,  2.4112e-02]],\n               \n                        ...,\n               \n                        [[-4.4405e-03, -6.8260e-03, -1.5468e-02],\n                         [ 1.0609e-02,  1.0456e-02, -1.8473e-02],\n                         [ 2.2710e-02,  2.4825e-02,  1.9567e-02]],\n               \n                        [[-1.6333e-02, -3.5102e-03,  1.9551e-02],\n                         [-2.0155e-02, -3.4068e-02,  1.0583e-02],\n                         [-1.4323e-02, -3.1121e-02,  1.0297e-02]],\n               \n                        [[ 2.1316e-03,  4.8005e-02,  1.8753e-02],\n                         [ 1.3601e-02,  2.6797e-02,  5.5963e-03],\n                         [-1.5781e-05,  2.5370e-02,  2.8067e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-2.2615e-03,  3.9800e-02, -1.0344e-02],\n                         [ 2.4174e-02,  1.5973e-02,  8.9276e-03],\n                         [ 2.6696e-02,  1.0189e-02,  5.0624e-02]],\n               \n                        [[-9.5528e-04,  2.2083e-02,  5.1163e-02],\n                         [-2.7700e-02, -1.2773e-02,  3.2364e-03],\n                         [-2.0188e-02, -2.2931e-02,  1.2817e-03]],\n               \n                        [[-3.7444e-02, -2.7998e-02,  5.3009e-04],\n                         [-3.3035e-02,  1.1745e-02,  1.2531e-03],\n                         [-4.5576e-02,  2.8725e-02,  2.1059e-02]],\n               \n                        ...,\n               \n                        [[-3.2832e-04,  5.3366e-02,  4.5197e-02],\n                         [-7.0106e-02,  6.7738e-03,  8.0625e-02],\n                         [-2.0293e-02,  5.4937e-02,  3.4111e-02]],\n               \n                        [[ 2.4766e-03, -9.2711e-03,  2.0012e-02],\n                         [ 1.7457e-02,  8.3689e-03, -1.2777e-02],\n                         [-8.7845e-03, -1.5019e-02,  1.8955e-03]],\n               \n                        [[-1.4047e-02, -1.6657e-02,  1.8601e-03],\n                         [ 3.7103e-02,  2.2033e-02, -7.1866e-04],\n                         [-6.8638e-03, -2.1357e-02,  7.3873e-03]]],\n               \n               \n                       [[[-2.8360e-02,  6.9888e-03,  2.1125e-02],\n                         [-3.1588e-02, -5.2703e-02, -9.1965e-03],\n                         [-1.6895e-02,  1.1147e-02, -2.5652e-02]],\n               \n                        [[ 2.6947e-03,  1.5387e-02,  5.1731e-02],\n                         [ 1.2509e-02, -8.6745e-03,  2.1284e-02],\n                         [ 1.9398e-02, -5.8659e-03,  1.4138e-02]],\n               \n                        [[-2.7037e-02, -2.0817e-02, -3.3387e-02],\n                         [ 7.9335e-03, -2.2991e-02, -3.2104e-03],\n                         [-3.7422e-03,  9.3008e-03, -1.1364e-02]],\n               \n                        ...,\n               \n                        [[-4.5962e-03,  1.4363e-02,  2.6045e-02],\n                         [ 4.9214e-03,  2.3998e-03, -4.8035e-03],\n                         [-3.0762e-03, -4.1361e-02, -2.1025e-02]],\n               \n                        [[-2.5260e-02, -6.6419e-02, -7.5044e-04],\n                         [-5.0901e-02, -8.1802e-03, -3.6232e-02],\n                         [-3.0893e-03,  1.2178e-02, -4.5106e-03]],\n               \n                        [[-4.4248e-04, -1.1261e-02, -1.0042e-02],\n                         [ 1.1838e-02,  3.0961e-02,  6.1721e-04],\n                         [-2.6527e-02,  3.1176e-02,  4.1542e-02]]],\n               \n               \n                       [[[-6.4839e-03,  4.0752e-03,  1.2921e-02],\n                         [-4.0123e-02, -2.3350e-02, -2.1098e-02],\n                         [-4.3160e-02, -2.3460e-02, -3.6072e-02]],\n               \n                        [[ 1.8366e-02, -7.8802e-04,  9.7096e-03],\n                         [-8.9227e-03,  1.9580e-02, -1.1799e-02],\n                         [-2.0041e-02, -1.6207e-02, -1.2063e-02]],\n               \n                        [[ 8.6296e-03,  2.1031e-02,  3.5346e-03],\n                         [ 8.2423e-03,  1.0770e-02,  9.8460e-03],\n                         [-4.5872e-03, -2.1471e-02, -3.6032e-02]],\n               \n                        ...,\n               \n                        [[-1.2655e-02, -2.1641e-02,  1.5210e-02],\n                         [ 5.0790e-02,  1.6403e-02,  4.4823e-02],\n                         [-2.2294e-03, -1.2537e-02, -3.0981e-02]],\n               \n                        [[-3.1826e-02, -1.9612e-02,  2.5811e-02],\n                         [ 2.2575e-02,  1.9316e-04, -6.5248e-03],\n                         [ 2.7087e-02,  3.7824e-02,  2.3733e-02]],\n               \n                        [[-3.0002e-03,  3.9859e-03, -3.0547e-02],\n                         [ 2.1429e-02, -3.4863e-03, -2.6949e-02],\n                         [ 7.9497e-03, -7.8010e-03, -5.7959e-03]]]])),\n              ('layer3.4.bn2.weight',\n               tensor([1.0017, 1.0377, 0.9751, 0.9734, 1.0081, 0.9955, 1.0516, 0.9440, 1.0041,\n                       1.0250, 0.9764, 1.0230, 0.9715, 0.9682, 0.9889, 1.0128, 0.9577, 1.0224,\n                       0.9463, 1.0072, 0.9825, 1.0138, 0.9828, 0.9837, 0.9761, 0.9937, 0.9345,\n                       0.9764, 0.9781, 1.0251, 1.0079, 1.0056, 0.9767, 0.9840, 1.0037, 0.9722,\n                       0.9761, 1.0562, 0.9757, 0.9781, 1.0235, 0.9931, 0.9863, 0.9973, 1.0323,\n                       1.0324, 0.9680, 0.9518, 1.0036, 1.0052, 0.9989, 0.9568, 1.0322, 0.9793,\n                       1.0218, 1.0140, 1.0796, 1.0552, 1.0287, 0.9895, 0.9440, 1.0255, 0.9887,\n                       1.0054, 0.9897, 1.0201, 0.9650, 1.0129, 0.9942, 1.0616, 1.0269, 0.9893,\n                       0.9515, 0.9793, 0.9747, 1.0444, 0.9580, 0.9751, 1.0708, 0.9874, 0.9867,\n                       1.0553, 0.9957, 1.0222, 1.0004, 0.9398, 0.9832, 0.9143, 1.0300, 0.9686,\n                       0.9649, 0.9806, 1.0040, 1.0051, 0.9745, 1.0611, 0.9950, 0.9638, 0.9781,\n                       0.9920, 0.9922, 1.0241, 0.9539, 0.9942, 0.9968, 1.0222, 0.9662, 0.9665,\n                       1.0346, 1.0318, 0.9842, 0.9886, 1.0183, 1.0266, 0.9859, 0.9718, 0.9789,\n                       1.0433, 1.0138, 1.0587, 0.9431, 0.9878, 1.0066, 1.0234, 0.9567, 0.9916,\n                       0.9637, 0.9788, 1.0019, 0.9888, 0.9979, 0.9269, 1.0003, 1.0157, 0.9719,\n                       0.9530, 0.9881, 1.0151, 1.0353, 0.9964, 1.0032, 1.0140, 1.0290, 0.9963,\n                       0.9852, 1.0067, 0.9681, 1.0443, 1.0176, 0.9844, 0.9544, 0.9620, 0.9491,\n                       1.0214, 1.0172, 0.9879, 0.9812, 0.9875, 0.9816, 0.9478, 1.0296, 1.0281,\n                       0.9887, 1.0644, 0.9915, 0.9828, 0.9894, 0.9787, 0.9872, 0.9711, 0.9954,\n                       0.9977, 0.9755, 1.0297, 1.0936, 0.9848, 1.0220, 1.0202, 0.9468, 0.9410,\n                       0.9683, 0.9748, 0.9511, 0.9992, 0.9972, 0.9464, 1.0230, 1.0455, 1.0211,\n                       0.9509, 0.9684, 0.9748, 0.9664, 0.9907, 0.9726, 0.9774, 1.0162, 0.9725,\n                       1.0182, 1.0126, 0.9749, 0.9729, 1.0188, 0.9917, 0.9679, 0.9660, 1.0022,\n                       0.9896, 0.9733, 1.0889, 0.9928, 1.0220, 1.0143, 1.0010, 1.0064, 0.9928,\n                       1.0101, 1.0235, 0.9692, 1.0046, 0.9469, 0.9510, 0.9759, 1.0236, 1.0214,\n                       0.9565, 0.9483, 1.0105, 1.0016, 1.1201, 1.0495, 1.0011, 0.9778, 0.9902,\n                       1.0229, 0.9938, 0.9815, 0.9447, 0.9777, 0.9459, 0.9868, 0.9844, 0.9999,\n                       0.9917, 1.0533, 0.9607, 0.9910, 1.0115, 0.9918, 1.0213, 1.0077, 0.9728,\n                       1.0095, 1.0241, 0.9906, 1.0242])),\n              ('layer3.4.bn2.bias',\n               tensor([-0.0769, -0.0568, -0.0756, -0.0728, -0.0480, -0.0649, -0.0640, -0.0873,\n                       -0.0569, -0.0587, -0.1012, -0.1264, -0.0711, -0.0175, -0.1296, -0.0691,\n                       -0.0982, -0.0799, -0.0765, -0.0608, -0.0765, -0.0846, -0.0145, -0.0582,\n                       -0.0571, -0.0891, -0.0374, -0.0959, -0.1689, -0.1275, -0.0672, -0.0628,\n                       -0.0423, -0.1327, -0.1064, -0.0521, -0.0621, -0.0158, -0.0253, -0.0420,\n                       -0.0204, -0.0815, -0.0396, -0.0561, -0.0069, -0.1229, -0.0789, -0.0611,\n                       -0.1707, -0.0328, -0.0036, -0.1000, -0.0796, -0.0586, -0.0470, -0.0744,\n                       -0.0648, -0.1040, -0.0801, -0.0806, -0.1006, -0.1006, -0.0832, -0.1082,\n                       -0.0526, -0.1213, -0.0387, -0.1556, -0.1118, -0.0595, -0.1112, -0.0845,\n                       -0.0677, -0.0294, -0.1025, -0.0670, -0.1145,  0.0127, -0.1751, -0.0262,\n                       -0.0909, -0.0411, -0.1004, -0.0917, -0.0814, -0.0862, -0.0593, -0.0581,\n                       -0.0675, -0.1008, -0.0871, -0.0908, -0.0780, -0.1087, -0.0438, -0.2080,\n                       -0.0341, -0.0739, -0.1348, -0.0792, -0.0592, -0.0670, -0.0959, -0.0412,\n                       -0.0935, -0.1379, -0.1031, -0.0826, -0.0576, -0.0328, -0.1157, -0.0576,\n                       -0.0535, -0.0651, -0.0448, -0.0857, -0.1539, -0.0961, -0.0361, -0.0516,\n                       -0.1227, -0.1056, -0.0158, -0.1657, -0.0667, -0.0536, -0.0376, -0.0527,\n                       -0.0699, -0.0655, -0.0988, -0.1489, -0.0225, -0.0776, -0.0911, -0.0601,\n                       -0.0364,  0.0121,  0.0111, -0.1362, -0.0530, -0.1135, -0.0858, -0.1135,\n                       -0.0422, -0.0272, -0.0699, -0.0620, -0.0480, -0.0581, -0.0951, -0.0614,\n                       -0.0694, -0.0352, -0.1021, -0.0667, -0.0772, -0.0971, -0.0319, -0.0634,\n                       -0.0950, -0.0378, -0.0397, -0.0922, -0.0422, -0.1060, -0.1092, -0.0666,\n                       -0.0231, -0.1016, -0.1025, -0.0881, -0.0625, -0.0337, -0.0165, -0.0646,\n                       -0.0419, -0.1061, -0.0781, -0.0860, -0.0515, -0.0684, -0.0200, -0.0845,\n                       -0.1274, -0.0102, -0.0680, -0.1871, -0.1000, -0.0828, -0.0236, -0.1037,\n                       -0.0212, -0.0858, -0.0204, -0.0933, -0.0627, -0.0702, -0.0840, -0.1078,\n                       -0.0482, -0.0355, -0.0733, -0.1365, -0.0131, -0.0825, -0.0770, -0.0619,\n                       -0.0697, -0.0129, -0.0739, -0.1160, -0.0466, -0.0916, -0.0808, -0.0554,\n                       -0.0820, -0.0813, -0.0539, -0.1013, -0.0794, -0.0927, -0.0636, -0.1178,\n                       -0.0759, -0.0751, -0.1398, -0.0743, -0.1311, -0.3014, -0.0490, -0.0415,\n                       -0.0431, -0.0152, -0.0667, -0.0956, -0.0762, -0.0984, -0.0571, -0.0492,\n                       -0.0676, -0.0460, -0.1401, -0.0740, -0.0915, -0.1087, -0.0502, -0.0724,\n                        0.0300, -0.0721, -0.0525, -0.0845, -0.0253, -0.0689, -0.0415, -0.0959])),\n              ('layer3.4.bn2.running_mean',\n               tensor([ 0.3838,  0.1866,  0.2700,  0.7682,  0.1868,  0.1107, -0.1398,  0.3504,\n                       -0.0998, -0.6488,  0.1144,  0.2336, -0.2402, -0.1022,  0.1718, -0.3619,\n                       -0.8039, -0.4075, -0.4608,  0.4400,  0.0049, -0.0861,  0.1789, -0.0676,\n                        0.6205, -0.0874, -0.1465, -0.5786, -0.0650, -0.1008, -0.6383, -0.3813,\n                        0.2125, -0.1134,  0.1050, -0.0101,  0.1428, -0.5998,  0.0730,  0.2142,\n                        0.6369, -0.0593, -0.1905, -0.8298, -0.0900, -0.1096, -0.2425,  0.6684,\n                       -0.6436, -0.7091,  0.3002,  0.2065, -0.8984, -0.2930,  0.0462,  0.8009,\n                       -1.2985,  0.1431, -0.7015,  0.5096, -0.6598,  0.8335, -0.1538, -1.0878,\n                        0.1218, -0.2218, -0.7795, -0.2827, -0.1390, -0.4047, -0.2448,  0.2660,\n                       -0.4236, -0.1550, -0.3102, -0.0848, -0.6447, -0.0973, -0.6145,  0.4975,\n                        0.1318,  0.3003,  0.2872,  0.2864, -0.6461,  0.0311,  0.1107, -0.1659,\n                       -0.6388,  0.5246, -0.0193, -0.0073, -0.0458,  0.0207,  0.1827, -0.3311,\n                        0.1697,  0.4118,  0.1849, -0.0656, -0.5911,  0.0116, -0.5546, -0.6743,\n                       -0.7727,  0.2256, -0.3198,  0.3114, -0.4930, -0.7496,  0.0547, -0.1590,\n                       -0.1416, -0.8887,  0.1365, -0.2902, -0.4945, -0.3094, -0.3540,  0.5733,\n                        0.1361,  0.0254,  0.2982, -0.1456,  0.0450, -0.2443, -0.4769, -1.2338,\n                       -0.3231,  0.4879, -0.5437,  0.4348,  0.2503, -0.4051, -0.4108,  0.1886,\n                       -0.3890,  0.0526, -0.0619,  0.7011,  0.1871, -1.1731, -0.1632, -0.2437,\n                       -0.3712, -0.1889,  0.0209, -0.3219, -0.7274,  0.7765,  0.2576,  0.5677,\n                       -0.3291, -0.5969,  0.2259, -0.2426, -0.2741,  0.0396, -0.1420, -0.3366,\n                       -0.5054, -0.3565,  0.0085,  1.3507, -0.4685, -0.1866,  0.0449, -0.4021,\n                       -0.4212,  0.7010, -0.0350, -0.5393, -0.0951, -0.1488,  0.0236, -0.5269,\n                       -0.0788, -0.4379,  0.7209, -0.3609, -0.6242,  0.4920,  0.0346, -0.3380,\n                        0.0353, -0.6840,  0.5674, -0.3078, -0.2172, -0.2423, -0.1010,  0.4362,\n                       -0.2978, -0.2310, -0.4023,  0.7217,  0.3266, -0.1839,  0.3202,  0.3949,\n                        0.2610,  0.4938, -0.0820,  0.2168,  0.1866, -0.1838, -0.0463,  0.3709,\n                       -0.5098, -0.7139, -0.0720, -0.7378, -0.2928, -0.6911,  0.0510,  0.0317,\n                       -0.0490, -0.5169, -0.1409, -0.4275, -0.6684, -0.0853,  0.2386, -0.6046,\n                       -0.5294,  0.4099, -0.3210, -0.9660,  0.0991, -0.9760, -0.0999, -0.4794,\n                        0.4587, -0.4420, -0.6367, -0.2346,  0.0338, -0.8784,  0.4579,  0.9699,\n                        0.5056, -0.0914,  0.3345, -0.1654, -0.3415, -0.4767,  0.1723,  0.5518,\n                        0.3210, -0.4131, -0.0548, -0.1652, -0.4749, -0.1003,  0.5613,  0.2277])),\n              ('layer3.4.bn2.running_var',\n               tensor([0.6833, 1.0854, 0.7706, 0.7548, 0.9444, 0.7707, 0.8638, 0.8010, 0.7913,\n                       0.8290, 0.7485, 0.9756, 0.7810, 0.8757, 0.7435, 0.8007, 0.7306, 0.9419,\n                       0.8547, 1.0346, 0.9524, 0.7478, 0.7574, 0.7612, 0.7495, 0.8458, 0.8035,\n                       0.7625, 0.9476, 1.0346, 1.1759, 0.8282, 0.7094, 0.8451, 0.8614, 0.5848,\n                       0.7084, 0.8777, 0.6911, 0.6335, 1.0287, 0.8370, 0.6131, 1.0409, 0.8869,\n                       0.8779, 0.8510, 0.7900, 0.7203, 0.8798, 0.6286, 0.6656, 1.0942, 0.5910,\n                       0.8815, 1.0199, 1.1615, 1.2818, 1.0783, 0.8817, 0.7324, 0.9711, 0.6967,\n                       0.7156, 0.8323, 0.9001, 0.8269, 1.0584, 0.7925, 1.0889, 0.8996, 0.8519,\n                       0.6402, 0.8527, 0.7407, 0.8312, 0.8045, 0.8194, 1.0001, 0.9786, 0.8781,\n                       0.9274, 0.7851, 1.1690, 1.0320, 0.8402, 0.8439, 0.8428, 1.1113, 0.7732,\n                       0.6644, 0.9145, 0.8259, 0.6967, 0.8513, 1.0880, 0.8161, 0.7913, 1.1181,\n                       0.7320, 0.7658, 0.9239, 0.6651, 0.7384, 0.7328, 1.0633, 0.7807, 0.7057,\n                       0.8990, 0.7876, 0.7612, 0.8273, 0.8111, 0.8291, 0.8693, 0.7936, 0.9287,\n                       0.9236, 0.7440, 1.1573, 0.7717, 1.0216, 0.8111, 0.8590, 0.8355, 0.8238,\n                       0.7936, 0.7018, 0.7582, 0.9512, 0.6984, 0.7507, 0.7991, 0.8317, 0.9048,\n                       0.6476, 0.8150, 0.8670, 0.7781, 0.9610, 0.9528, 1.0981, 0.7937, 1.2218,\n                       0.5417, 0.8062, 0.9254, 0.9036, 0.7257, 0.9531, 0.9369, 0.8215, 0.6802,\n                       0.8649, 0.8473, 0.7346, 0.9121, 0.7680, 0.7342, 0.7606, 0.9552, 0.9381,\n                       0.9102, 1.1186, 0.7905, 0.7875, 0.9740, 0.7582, 0.6289, 0.8740, 0.9784,\n                       0.8306, 0.7231, 1.0167, 0.8333, 0.7702, 0.7924, 0.9990, 0.6993, 0.6996,\n                       0.7920, 0.9236, 0.7456, 0.9407, 0.8163, 0.7490, 1.0422, 0.8164, 1.1649,\n                       0.6251, 0.7166, 0.7133, 0.8733, 0.8059, 0.8448, 0.6706, 1.4736, 0.9271,\n                       1.0546, 0.9300, 0.6716, 0.7266, 1.1004, 0.6929, 0.8416, 0.7903, 0.8016,\n                       0.6856, 0.8078, 1.0680, 0.6745, 0.8884, 0.7410, 1.0543, 0.8313, 0.7778,\n                       0.8639, 0.8915, 0.9255, 0.8318, 0.7037, 0.6860, 0.7856, 0.7153, 0.7952,\n                       0.7976, 0.8467, 0.7365, 0.9529, 1.5051, 1.1703, 0.8210, 0.9738, 0.8987,\n                       0.6901, 0.7512, 0.6995, 0.7286, 0.7783, 0.6075, 0.7584, 0.6990, 0.8011,\n                       0.8460, 0.8623, 0.8624, 0.8261, 0.9866, 0.6854, 1.0751, 0.9560, 0.7563,\n                       0.8250, 1.2747, 1.0074, 0.8749])),\n              ('layer3.4.bn2.num_batches_tracked', tensor(13572)),\n              ('layer3.4.conv3.weight',\n               tensor([[[[ 0.0186]],\n               \n                        [[ 0.0020]],\n               \n                        [[-0.0360]],\n               \n                        ...,\n               \n                        [[-0.0044]],\n               \n                        [[-0.0004]],\n               \n                        [[-0.0278]]],\n               \n               \n                       [[[ 0.0728]],\n               \n                        [[-0.0116]],\n               \n                        [[-0.0373]],\n               \n                        ...,\n               \n                        [[ 0.0383]],\n               \n                        [[ 0.0203]],\n               \n                        [[ 0.0429]]],\n               \n               \n                       [[[-0.0258]],\n               \n                        [[-0.0280]],\n               \n                        [[ 0.0046]],\n               \n                        ...,\n               \n                        [[-0.0057]],\n               \n                        [[-0.0436]],\n               \n                        [[ 0.0141]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0107]],\n               \n                        [[ 0.0770]],\n               \n                        [[-0.0339]],\n               \n                        ...,\n               \n                        [[ 0.0323]],\n               \n                        [[-0.0575]],\n               \n                        [[-0.0064]]],\n               \n               \n                       [[[ 0.0202]],\n               \n                        [[-0.0007]],\n               \n                        [[ 0.0052]],\n               \n                        ...,\n               \n                        [[-0.0066]],\n               \n                        [[ 0.0486]],\n               \n                        [[-0.0386]]],\n               \n               \n                       [[[ 0.0207]],\n               \n                        [[-0.0022]],\n               \n                        [[-0.0596]],\n               \n                        ...,\n               \n                        [[-0.0150]],\n               \n                        [[-0.0163]],\n               \n                        [[ 0.0252]]]])),\n              ('layer3.4.bn3.weight',\n               tensor([-0.1173,  0.1743, -0.2116,  ..., -0.3014, -0.2209,  0.1997])),\n              ('layer3.4.bn3.bias',\n               tensor([ 0.0721,  0.0514, -0.0078,  ...,  0.0300, -0.0222,  0.0836])),\n              ('layer3.4.bn3.running_mean',\n               tensor([ 0.0955, -0.1976, -0.0695,  ..., -0.1009, -0.2504, -0.0153])),\n              ('layer3.4.bn3.running_var',\n               tensor([0.0760, 0.1237, 0.1000,  ..., 0.1243, 0.1394, 0.1314])),\n              ('layer3.4.bn3.num_batches_tracked', tensor(13572)),\n              ('layer3.5.conv1.weight',\n               tensor([[[[-0.0242]],\n               \n                        [[-0.0288]],\n               \n                        [[-0.0523]],\n               \n                        ...,\n               \n                        [[ 0.0130]],\n               \n                        [[ 0.0148]],\n               \n                        [[ 0.0264]]],\n               \n               \n                       [[[-0.0021]],\n               \n                        [[-0.0230]],\n               \n                        [[-0.0700]],\n               \n                        ...,\n               \n                        [[ 0.0973]],\n               \n                        [[-0.0531]],\n               \n                        [[-0.0205]]],\n               \n               \n                       [[[-0.0331]],\n               \n                        [[-0.0054]],\n               \n                        [[-0.0244]],\n               \n                        ...,\n               \n                        [[ 0.0191]],\n               \n                        [[-0.0220]],\n               \n                        [[-0.1018]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0151]],\n               \n                        [[ 0.0056]],\n               \n                        [[-0.0007]],\n               \n                        ...,\n               \n                        [[ 0.0208]],\n               \n                        [[-0.0203]],\n               \n                        [[-0.0234]]],\n               \n               \n                       [[[-0.0443]],\n               \n                        [[-0.0400]],\n               \n                        [[ 0.0416]],\n               \n                        ...,\n               \n                        [[ 0.0621]],\n               \n                        [[ 0.0640]],\n               \n                        [[ 0.0024]]],\n               \n               \n                       [[[-0.0691]],\n               \n                        [[-0.0235]],\n               \n                        [[-0.0054]],\n               \n                        ...,\n               \n                        [[ 0.0019]],\n               \n                        [[-0.0153]],\n               \n                        [[-0.0384]]]])),\n              ('layer3.5.bn1.weight',\n               tensor([0.9822, 1.0071, 0.9608, 0.9787, 1.0016, 0.9848, 1.0692, 0.9832, 0.9550,\n                       0.9866, 0.9862, 0.9814, 1.0832, 0.9833, 1.0503, 1.0469, 0.9635, 1.0080,\n                       1.0529, 1.0416, 1.0294, 0.9793, 0.9878, 0.9785, 0.9893, 1.0216, 0.9843,\n                       0.9598, 1.0140, 0.9871, 1.0097, 1.0481, 0.9727, 1.0227, 0.9860, 1.0073,\n                       1.0044, 0.9872, 0.9835, 0.9848, 0.9694, 1.0189, 1.0636, 0.9854, 1.0177,\n                       0.9881, 0.9657, 1.0079, 0.9769, 0.9516, 0.9701, 0.9737, 0.9923, 0.9975,\n                       0.9831, 0.9721, 1.0711, 0.9602, 0.9378, 0.9897, 1.0067, 0.9836, 0.9846,\n                       0.9628, 0.9742, 1.0256, 1.0231, 0.9724, 0.9823, 1.0076, 1.0022, 0.9792,\n                       1.0057, 0.9561, 0.9727, 0.9544, 0.9704, 1.0535, 0.9749, 1.0274, 1.0055,\n                       1.0223, 1.0051, 0.9675, 0.9671, 1.0260, 1.0080, 0.9698, 1.0184, 0.9967,\n                       1.0146, 0.9656, 0.9781, 0.9827, 0.9687, 1.0158, 1.0013, 1.0178, 0.9741,\n                       1.0364, 0.9850, 1.0585, 1.0580, 1.0499, 0.9886, 0.9993, 0.9388, 0.9817,\n                       0.9839, 0.9841, 0.9874, 1.0016, 0.9594, 0.9689, 0.9969, 0.9959, 0.9947,\n                       0.9500, 0.9924, 1.0114, 0.9807, 1.0234, 0.9370, 0.9954, 0.9670, 1.0284,\n                       1.0093, 1.0118, 0.9564, 1.0537, 0.9889, 1.0488, 0.9343, 0.9924, 1.0071,\n                       0.9462, 1.0063, 1.0093, 1.0250, 1.0123, 0.9826, 0.9992, 0.9828, 0.9582,\n                       1.0277, 1.0132, 0.9415, 1.0328, 0.9577, 0.9937, 0.9500, 0.9707, 0.9624,\n                       0.9696, 0.9801, 0.9938, 1.0211, 1.0314, 0.9680, 0.9635, 0.9991, 1.0191,\n                       0.9729, 0.9704, 0.9892, 0.9618, 0.9811, 1.0138, 1.0199, 0.9762, 0.9943,\n                       0.9959, 0.9948, 0.9957, 1.0348, 0.9965, 0.9351, 0.9841, 0.9417, 0.9898,\n                       0.9912, 1.0260, 0.9878, 0.9873, 0.9721, 1.0293, 0.9614, 1.0357, 1.0076,\n                       0.9626, 1.0081, 1.0603, 1.0044, 0.9513, 0.9837, 1.0070, 0.9569, 1.0300,\n                       1.0174, 0.9563, 0.9862, 1.0125, 0.9808, 0.9729, 0.9994, 0.9903, 0.9465,\n                       1.0044, 1.0040, 1.0355, 1.0399, 0.9808, 1.0175, 0.9607, 0.9975, 1.0025,\n                       1.0525, 1.0004, 1.0047, 0.9877, 0.9717, 0.9752, 1.0212, 1.0306, 1.0168,\n                       0.9567, 1.0343, 0.9880, 1.0772, 0.9969, 1.0321, 0.9590, 1.0199, 0.9533,\n                       0.9571, 0.9344, 1.0170, 0.9611, 0.9896, 1.0335, 1.0050, 0.9772, 1.0084,\n                       0.9737, 1.0368, 0.9724, 0.9517, 0.9879, 0.9696, 1.0133, 0.9663, 0.9794,\n                       0.9730, 1.0041, 0.9542, 0.9863])),\n              ('layer3.5.bn1.bias',\n               tensor([-0.1014, -0.0781, -0.1007, -0.0638, -0.1294, -0.0898, -0.0167, -0.1527,\n                       -0.0694, -0.1366, -0.1724, -0.0823, -0.2443, -0.0801, -0.2176, -0.0998,\n                       -0.0886, -0.0829, -0.0064,  0.0108, -0.2688, -0.0261, -0.0920, -0.0915,\n                       -0.1743, -0.0605, -0.1313, -0.1009, -0.0756, -0.0744, -0.1053, -0.0411,\n                       -0.0881, -0.0921, -0.0925, -0.0652, -0.1909, -0.1244, -0.1640, -0.0805,\n                       -0.0772, -0.0834, -0.0525, -0.0747, -0.0085, -0.0898, -0.0635, -0.1011,\n                       -0.1128, -0.1395, -0.1393, -0.1351, -0.1826, -0.1421, -0.0966, -0.0661,\n                        0.0099, -0.1057, -0.1037, -0.1087, -0.0520, -0.1526, -0.0409, -0.1544,\n                       -0.1391, -0.1493, -0.1564, -0.1123, -0.1344, -0.0270, -0.0713, -0.0537,\n                       -0.0568, -0.0829, -0.1196, -0.0792, -0.0670, -0.0944, -0.2334, -0.2040,\n                       -0.0789, -0.1024, -0.0687, -0.0520, -0.1160, -0.1184, -0.0940, -0.1494,\n                       -0.0349, -0.0710, -0.0720, -0.1373, -0.0782, -0.1169, -0.1217, -0.1089,\n                       -0.0381, -0.0339, -0.0675, -0.0851, -0.0726, -0.0731, -0.1474, -0.0781,\n                       -0.0487, -0.1173, -0.0686, -0.1433, -0.0720, -0.0944, -0.0531, -0.1834,\n                       -0.0964, -0.1458, -0.0749, -0.1567, -0.1241, -0.0893, -0.0478, -0.0568,\n                       -0.1330, -0.0613, -0.0853, -0.1448, -0.1140, -0.0641, -0.1130, -0.1347,\n                       -0.1063, -0.0923, -0.1435, -0.0220, -0.0234, -0.1337, -0.1715, -0.0614,\n                       -0.1265, -0.1329, -0.2599, -0.1212, -0.1565, -0.0948, -0.0488, -0.0413,\n                       -0.0958, -0.0820, -0.0512, -0.1024, -0.0616, -0.0911, -0.0649, -0.1272,\n                       -0.0857, -0.0851, -0.1559, -0.0715, -0.1415, -0.0750, -0.1386, -0.1725,\n                       -0.1743, -0.0901, -0.1707, -0.1016, -0.1494, -0.1943, -0.0575, -0.0541,\n                       -0.0720, -0.1042, -0.0506, -0.0814, -0.1393, -0.0446, -0.0994, -0.0920,\n                       -0.0926, -0.0551, -0.1788, -0.0479, -0.1622, -0.1005, -0.2407, -0.1191,\n                       -0.0862, -0.2807, -0.0729, -0.0589, -0.1935, -0.1444, -0.0672, -0.0550,\n                       -0.0644, -0.0736, -0.1309, -0.1135, -0.1746, -0.0488, -0.0284, -0.0998,\n                       -0.0374, -0.0680, -0.0938, -0.0959, -0.0441, -0.1415, -0.1072, -0.1796,\n                       -0.1418, -0.1357, -0.1543, -0.1067, -0.1640, -0.2077, -0.1390, -0.1402,\n                       -0.0277, -0.1148, -0.0627, -0.0811, -0.1771, -0.0867, -0.1340, -0.1021,\n                       -0.0966, -0.0465, -0.0858, -0.1118, -0.1212, -0.1067, -0.0359, -0.1104,\n                       -0.1817, -0.0465, -0.1084, -0.0611, -0.0532, -0.1221, -0.1866, -0.1450,\n                       -0.1311, -0.1791, -0.0757, -0.1206, -0.1846, -0.0749, -0.1280, -0.0434,\n                       -0.1197, -0.1094, -0.1152, -0.1369, -0.1567, -0.0850, -0.0355, -0.1429])),\n              ('layer3.5.bn1.running_mean',\n               tensor([-1.5991e-03, -7.1972e-01,  3.2478e-01,  2.9537e-01, -7.2060e-01,\n                        2.3390e-01, -1.6089e-01, -6.9706e-01,  2.4245e-02, -1.1691e+00,\n                       -1.3612e-01, -1.1974e+00,  2.7306e-01,  4.4855e-01,  3.6503e-02,\n                        9.6441e-01, -2.1129e-01, -1.2907e+00, -1.7556e+00, -1.4383e+00,\n                        7.3970e-01, -5.3320e-01, -2.3484e-01,  8.5393e-02, -7.2777e-01,\n                       -5.4208e-01,  1.1455e+00, -4.2611e-01, -3.0550e-01, -7.5614e-01,\n                       -4.1387e-01,  1.3079e+00,  4.9495e-02,  1.1797e+00, -2.8633e-01,\n                        4.3451e-01,  5.0754e-02, -3.1630e-01,  3.9663e-02, -3.2874e-01,\n                        1.6844e-01, -7.5217e-01, -6.4162e-01, -1.8697e+00, -1.0870e+00,\n                       -9.7345e-02, -4.5017e-01, -9.4206e-01, -2.0850e-01, -2.9959e-01,\n                        1.3369e+00, -6.3148e-01, -3.5153e-01, -1.3398e-01, -4.1594e-01,\n                        1.1236e-01, -8.6240e-01,  1.9784e-02, -1.3385e-01, -6.6607e-02,\n                       -1.1348e+00,  4.9573e-01, -4.2258e-01,  3.3660e-03, -4.3208e-02,\n                       -5.0322e-01,  1.6608e-02, -7.8115e-01, -7.7476e-01, -9.4640e-02,\n                        3.6300e-02,  5.8446e-01, -1.3716e+00, -1.3671e-01,  3.0569e-01,\n                       -7.5861e-01,  1.6994e-01, -5.9166e-01, -7.1993e-01, -1.0273e+00,\n                        6.1862e-02,  3.1244e-01, -1.3309e+00, -1.1757e-01, -2.6794e-01,\n                       -1.0434e+00,  8.4887e-02,  3.6730e-01, -6.8002e-01, -1.4332e-01,\n                       -1.6440e+00, -9.8322e-01, -5.3910e-01, -3.7603e-03,  3.8236e-01,\n                       -9.9038e-02, -1.1953e+00, -9.6726e-01, -3.5586e-01, -5.5536e-01,\n                       -7.4908e-01, -1.5102e-03, -7.9469e-01,  2.6153e-01, -6.7077e-01,\n                       -4.3664e-01, -6.9599e-02,  1.8036e-01, -1.8427e+00, -5.2652e-01,\n                        3.4255e-01, -6.1018e-01, -9.0699e-01, -1.5318e+00, -9.9388e-02,\n                        3.5988e-01,  1.0451e+00, -6.5791e-01,  3.2933e-01, -4.5146e-01,\n                       -5.1487e-01, -5.5702e-01, -2.0276e-01, -7.0017e-01, -5.8479e-01,\n                       -1.1933e+00, -5.2219e-01, -1.9959e-01, -3.4398e-02, -1.4919e-01,\n                       -6.5404e-01,  2.6450e-01, -1.3547e-01,  4.1171e-02, -2.7532e-02,\n                       -8.4751e-01,  1.2185e+00,  2.9878e-02, -3.2563e-01, -5.1188e-01,\n                       -7.6056e-01, -2.6137e-01, -6.3967e-01,  2.2069e-01, -2.7899e-01,\n                        6.6934e-01,  4.5527e-01, -6.5231e-01, -3.8814e-01, -8.0397e-01,\n                        1.9018e-01,  4.2588e-01, -4.5402e-01, -7.4719e-01, -4.1950e-01,\n                       -2.2693e-01, -1.6247e+00,  1.9816e+00, -3.6926e-01, -6.2581e-01,\n                       -6.0242e-01, -2.8564e-01,  1.7383e-01, -1.0765e+00, -9.1676e-01,\n                       -4.2896e-01,  1.2255e-01, -4.7694e-01, -7.4240e-01, -3.1973e-01,\n                       -1.0053e+00, -1.2099e+00, -7.4912e-01,  8.0862e-01,  8.8534e-01,\n                       -8.0942e-01,  5.5234e-01, -1.3958e-02,  5.2683e-01, -2.7213e-01,\n                       -3.7542e-01,  9.9121e-02,  5.0247e-01,  8.1265e-01, -1.7326e-01,\n                       -1.2032e+00, -7.5918e-01, -9.1177e-01, -3.5255e-01, -9.4942e-01,\n                       -1.0584e+00, -9.7602e-01, -1.0319e+00, -4.0990e-01, -2.1639e-02,\n                        5.8365e-01, -1.5166e-01, -1.2797e+00, -1.2391e+00, -3.2490e-01,\n                       -2.8834e-02, -7.7884e-01,  3.2808e-01,  5.2656e-01,  8.6248e-01,\n                       -3.5885e-01,  7.8199e-02, -8.9153e-01,  5.7738e-03, -4.0184e-01,\n                       -1.2890e+00, -2.1784e-01,  2.6421e-01, -7.4173e-01, -2.4941e-01,\n                       -6.4291e-01, -9.0317e-01, -1.1632e+00, -1.7126e+00, -5.8632e-01,\n                       -6.6867e-01, -3.0477e-01,  7.4347e-01, -1.0071e+00, -7.4594e-02,\n                       -6.6963e-01, -1.1496e+00, -5.7938e-01, -1.0598e+00, -1.0647e+00,\n                       -1.1008e+00, -3.2275e-01,  3.9375e-02, -2.8480e-01, -3.2290e-01,\n                       -4.3087e-01, -9.8939e-01, -2.7070e-01, -2.1647e-01, -3.9922e-01,\n                       -4.3063e-01, -2.5208e-01, -9.4316e-01, -3.3161e-01,  9.1642e-02,\n                       -1.1154e+00,  2.3939e-01, -1.8447e-03,  7.1703e-01, -3.1230e-01,\n                       -1.3666e+00,  8.6869e-01, -5.3746e-01,  3.3374e-01,  6.4661e-02,\n                       -1.7356e-01])),\n              ('layer3.5.bn1.running_var',\n               tensor([0.6749, 0.7792, 0.7153, 0.9811, 0.9849, 0.5865, 0.6706, 0.7128, 0.5126,\n                       0.7521, 0.6740, 0.6079, 1.1541, 0.6641, 0.8219, 0.7118, 0.6749, 0.7175,\n                       0.7069, 0.7816, 0.7176, 0.6846, 0.8100, 0.5809, 0.7828, 0.6834, 0.8237,\n                       0.6922, 0.6244, 0.8042, 0.6113, 0.7720, 0.7737, 0.6532, 0.7213, 0.7576,\n                       0.7644, 0.6387, 0.7680, 0.8023, 0.7586, 0.9161, 0.7124, 0.7276, 0.7277,\n                       0.6901, 0.5780, 0.6703, 0.6434, 0.5557, 0.7048, 0.7808, 0.7220, 0.8795,\n                       0.8671, 0.5863, 0.6353, 0.6288, 0.6974, 0.8777, 0.6186, 0.8206, 0.6410,\n                       0.7420, 0.7821, 0.7601, 0.7537, 0.8660, 0.8487, 0.7072, 0.6994, 0.5630,\n                       0.7890, 0.5969, 0.7138, 0.6822, 0.7711, 0.7358, 0.9179, 0.9222, 0.9047,\n                       0.8720, 0.5887, 0.6746, 0.6145, 0.7014, 0.7141, 0.8110, 0.6924, 0.7868,\n                       0.8025, 0.6469, 0.7000, 0.6576, 0.6549, 0.7461, 0.6326, 0.6641, 0.5848,\n                       0.7782, 0.6696, 0.6867, 0.8841, 1.0081, 0.5804, 0.6948, 0.6169, 0.7242,\n                       0.6026, 0.8201, 0.5856, 0.9019, 0.6156, 0.6911, 0.6405, 0.8055, 0.6664,\n                       0.7354, 0.7395, 0.7154, 0.6340, 0.7186, 0.7366, 0.6645, 0.6470, 0.6813,\n                       0.7811, 0.6534, 0.7096, 0.8801, 0.8614, 0.7002, 0.7778, 0.7789, 0.7172,\n                       0.6902, 0.7833, 0.7793, 0.8527, 0.7416, 0.8028, 0.6271, 0.6773, 0.5517,\n                       0.7907, 0.9494, 0.6579, 0.7746, 0.5508, 0.7377, 0.5440, 0.8638, 0.5755,\n                       0.5816, 0.8089, 0.8375, 0.8364, 0.8460, 0.7900, 0.8224, 0.6126, 1.0321,\n                       0.7575, 0.7039, 0.7643, 0.8395, 0.6248, 0.6302, 0.6049, 0.6526, 0.5971,\n                       0.6710, 0.8193, 1.0493, 0.9402, 0.8347, 0.7200, 0.7501, 0.7124, 0.5904,\n                       0.5801, 0.7602, 0.9104, 0.7913, 0.7702, 1.0601, 0.7880, 0.7459, 0.9755,\n                       0.7398, 0.6622, 0.7469, 0.6356, 0.6379, 1.0484, 0.7071, 0.7155, 0.7728,\n                       0.5970, 0.6483, 0.5970, 0.6334, 0.7670, 0.6192, 0.8541, 0.6440, 0.6423,\n                       0.7667, 0.7507, 0.7755, 0.7451, 0.7152, 0.8557, 0.9168, 0.8467, 0.7433,\n                       0.7942, 0.8026, 0.7070, 0.6476, 0.8833, 0.5923, 0.9131, 0.7671, 0.9761,\n                       0.7198, 0.7646, 0.7434, 0.9617, 0.7769, 0.6261, 0.6655, 0.6320, 0.6204,\n                       0.5482, 0.5659, 0.6366, 0.7844, 0.7886, 0.8359, 0.6592, 0.7793, 0.7942,\n                       0.9419, 0.7755, 0.8560, 0.6712, 0.6827, 0.6170, 0.7259, 0.6690, 0.6087,\n                       0.8657, 0.7322, 0.7579, 0.6917])),\n              ('layer3.5.bn1.num_batches_tracked', tensor(13572)),\n              ('layer3.5.conv2.weight',\n               tensor([[[[ 4.1314e-03, -1.2829e-02,  1.1450e-02],\n                         [ 2.4370e-02, -2.1748e-02, -5.4557e-02],\n                         [ 1.2838e-02, -2.0996e-02,  1.7998e-02]],\n               \n                        [[-7.8145e-03,  1.3264e-02, -1.0251e-02],\n                         [ 3.8267e-03,  3.5913e-02,  4.8145e-05],\n                         [-4.6218e-03, -6.2258e-03, -3.1060e-03]],\n               \n                        [[ 1.8858e-02,  2.1137e-02,  4.3583e-02],\n                         [-3.5968e-02, -2.8227e-03, -4.0043e-02],\n                         [-1.8096e-02, -8.5644e-02, -4.2299e-02]],\n               \n                        ...,\n               \n                        [[ 1.3735e-02,  2.4599e-02, -4.4637e-03],\n                         [-1.5580e-03,  2.6011e-02,  1.2210e-02],\n                         [-5.6141e-02, -1.1061e-02, -1.9239e-02]],\n               \n                        [[ 1.8850e-02,  2.3800e-02,  2.5859e-02],\n                         [-3.3412e-02,  1.2934e-02, -1.4138e-02],\n                         [-1.2552e-02, -3.7636e-02, -4.3256e-02]],\n               \n                        [[ 1.4519e-02, -2.2034e-02,  5.3732e-04],\n                         [-2.5994e-02, -2.7063e-02, -1.0587e-02],\n                         [-1.0830e-02,  7.4022e-03, -5.9705e-03]]],\n               \n               \n                       [[[ 8.4996e-03,  8.5607e-04,  1.4887e-02],\n                         [-2.4291e-02,  5.2890e-03,  4.9540e-04],\n                         [ 3.6952e-03,  1.0157e-02, -1.0483e-02]],\n               \n                        [[-2.0937e-02,  1.6307e-02,  9.4417e-03],\n                         [ 6.2223e-03, -3.0152e-02, -5.1012e-04],\n                         [ 2.5905e-02,  4.2742e-03,  2.3154e-02]],\n               \n                        [[ 9.1737e-03, -2.3254e-03,  7.4326e-03],\n                         [-1.6893e-02, -2.4313e-02,  1.8998e-02],\n                         [-9.2992e-03,  2.8822e-02, -2.4859e-02]],\n               \n                        ...,\n               \n                        [[ 2.2641e-02,  1.8764e-02,  3.8358e-02],\n                         [ 3.3689e-02,  2.4269e-02,  3.8720e-02],\n                         [-7.5041e-03,  5.5133e-03,  3.3617e-02]],\n               \n                        [[ 1.3617e-02, -5.2044e-02, -2.1491e-02],\n                         [-4.3464e-03, -1.8083e-02, -7.7230e-03],\n                         [ 4.7549e-03,  7.7202e-03, -3.6479e-02]],\n               \n                        [[-2.0536e-02, -1.9992e-02, -2.1719e-02],\n                         [-1.9723e-02, -2.7016e-02, -3.4391e-02],\n                         [-2.2083e-02,  2.9624e-03, -5.9119e-04]]],\n               \n               \n                       [[[ 3.5942e-02, -2.0281e-03,  4.0045e-02],\n                         [ 6.1277e-04, -1.6935e-02,  4.6862e-03],\n                         [-7.3361e-03,  4.0708e-02,  1.1599e-02]],\n               \n                        [[-1.0993e-02, -2.1741e-02, -6.7023e-03],\n                         [ 1.5515e-02, -1.9677e-02, -7.8830e-03],\n                         [-3.3770e-03, -1.8113e-03, -3.3220e-03]],\n               \n                        [[ 3.7402e-02, -3.1554e-02,  1.6297e-02],\n                         [ 4.5361e-02,  4.3956e-02,  2.9349e-02],\n                         [ 3.1784e-02,  2.9834e-02,  2.1597e-02]],\n               \n                        ...,\n               \n                        [[-2.9540e-02,  1.0977e-02, -2.6393e-02],\n                         [ 1.2165e-02, -5.8594e-03,  1.4791e-02],\n                         [ 3.5675e-03,  1.2915e-02, -4.6357e-03]],\n               \n                        [[-2.9579e-03,  3.4873e-02,  3.0667e-02],\n                         [-1.9696e-03, -6.5215e-03, -2.7245e-02],\n                         [-1.2465e-02, -5.4296e-03,  7.1676e-04]],\n               \n                        [[ 1.0815e-03,  8.2803e-03,  2.3556e-02],\n                         [ 1.7158e-02,  3.0689e-02,  3.7624e-02],\n                         [-6.2264e-03,  6.0370e-02,  3.6038e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-9.2198e-04, -2.8259e-02, -1.4536e-02],\n                         [ 1.8966e-03, -1.0238e-02, -2.0840e-02],\n                         [ 1.4598e-02,  3.2300e-02,  3.2932e-02]],\n               \n                        [[ 6.3342e-03, -1.3856e-02,  8.8145e-03],\n                         [-2.6460e-02, -3.8094e-02, -2.8739e-03],\n                         [-3.1102e-02, -3.0549e-02, -2.2152e-02]],\n               \n                        [[-1.9573e-02, -4.9158e-02, -6.0671e-03],\n                         [-1.1367e-02, -2.1921e-03, -5.1163e-02],\n                         [ 7.5375e-03, -3.0965e-02, -6.1825e-02]],\n               \n                        ...,\n               \n                        [[ 3.9197e-03,  5.3862e-03,  5.7023e-03],\n                         [ 1.7525e-02, -2.0253e-02,  7.0787e-03],\n                         [ 5.6954e-03, -8.3735e-03,  6.7046e-03]],\n               \n                        [[ 1.7067e-02,  5.5016e-03, -7.2782e-03],\n                         [ 1.7457e-03, -1.2509e-02, -1.8040e-02],\n                         [ 3.5360e-03,  1.4681e-02, -9.9399e-03]],\n               \n                        [[-1.0978e-02,  1.8613e-02,  5.0572e-02],\n                         [ 2.3582e-02,  5.6782e-02, -3.5167e-02],\n                         [ 2.8595e-03,  1.9269e-02,  1.4027e-02]]],\n               \n               \n                       [[[-2.1400e-02, -1.2247e-02,  2.4355e-02],\n                         [-1.9675e-02, -4.7676e-02, -4.9504e-02],\n                         [-1.7005e-03, -7.2252e-02, -8.3205e-03]],\n               \n                        [[-2.5896e-02, -2.5511e-02, -3.0276e-03],\n                         [-8.2221e-03, -4.8598e-02, -4.4091e-02],\n                         [ 1.7656e-02, -2.1715e-02, -3.4766e-02]],\n               \n                        [[-4.7180e-02,  7.9110e-03, -3.6505e-02],\n                         [ 2.2123e-02,  2.4688e-03,  5.1993e-02],\n                         [ 3.7755e-02,  3.7953e-02,  2.2568e-02]],\n               \n                        ...,\n               \n                        [[ 3.0867e-02,  2.5170e-02,  2.4298e-02],\n                         [ 4.3826e-02,  7.1427e-03, -5.1037e-03],\n                         [-2.2132e-03,  1.2189e-02,  5.2565e-03]],\n               \n                        [[ 9.3717e-03, -3.5775e-03, -4.0966e-03],\n                         [-7.3495e-03,  1.6954e-02,  2.3277e-02],\n                         [ 1.3044e-02,  6.7407e-03, -5.8877e-03]],\n               \n                        [[-4.4183e-03,  3.2980e-02,  3.1942e-02],\n                         [ 2.6335e-02,  5.0730e-02,  2.2818e-02],\n                         [ 5.2895e-02,  2.7794e-02,  1.0710e-02]]],\n               \n               \n                       [[[ 1.8145e-02, -3.7664e-02, -1.1429e-02],\n                         [ 4.3176e-02,  2.5340e-02,  8.1488e-03],\n                         [ 1.1387e-02, -1.7037e-02,  1.6774e-02]],\n               \n                        [[-7.4899e-03,  4.5159e-02,  3.7498e-02],\n                         [ 1.8806e-02,  6.8572e-03,  3.3789e-02],\n                         [-1.0771e-02,  4.1278e-02,  5.1071e-02]],\n               \n                        [[-3.6357e-02,  4.6766e-02, -2.0957e-02],\n                         [ 1.7346e-02, -6.3283e-03,  1.2668e-02],\n                         [ 1.7196e-02,  2.6625e-02, -9.3699e-03]],\n               \n                        ...,\n               \n                        [[ 9.7375e-03,  4.0309e-02, -1.0542e-02],\n                         [ 9.1560e-03, -8.5943e-03,  2.6744e-02],\n                         [ 9.9850e-03,  8.5660e-03,  3.4624e-02]],\n               \n                        [[-1.6588e-02, -4.4890e-02, -1.9021e-02],\n                         [-1.1516e-03,  2.0207e-02,  6.0338e-03],\n                         [ 8.8553e-03,  9.2853e-03, -1.9554e-02]],\n               \n                        [[ 7.7759e-02,  1.0618e-02,  1.2874e-02],\n                         [-1.3045e-03,  3.5377e-02,  3.4554e-02],\n                         [ 2.9975e-02, -9.8127e-03,  5.8492e-03]]]])),\n              ('layer3.5.bn2.weight',\n               tensor([0.9642, 1.0285, 0.9822, 1.0315, 0.9975, 0.9923, 0.9659, 0.9309, 0.9824,\n                       1.0003, 0.9814, 0.9801, 1.0055, 0.9725, 0.9686, 1.0198, 1.0479, 0.9846,\n                       1.0901, 0.9656, 1.0730, 1.0320, 0.9995, 0.9690, 0.9683, 0.9778, 1.0454,\n                       0.9877, 1.0541, 0.9529, 1.0080, 0.9839, 1.0276, 1.0182, 1.0099, 1.0080,\n                       1.0403, 0.9768, 1.0216, 0.9771, 1.0446, 0.9831, 0.9713, 0.9995, 0.9680,\n                       0.9722, 0.9779, 1.0097, 0.9799, 0.9958, 0.9791, 1.0396, 0.9863, 0.9944,\n                       0.9716, 0.9773, 1.0951, 1.0105, 0.9851, 0.9688, 1.0035, 1.0124, 0.9782,\n                       1.0128, 0.9761, 0.9832, 0.9542, 0.9883, 0.9931, 0.9935, 0.9607, 1.0218,\n                       0.9800, 1.0008, 0.9537, 0.9855, 0.9762, 0.9741, 0.9848, 0.9605, 0.9702,\n                       0.9787, 0.9768, 1.0045, 1.0114, 1.0251, 0.9780, 0.9986, 0.9965, 1.0037,\n                       1.0016, 0.9752, 0.9806, 0.9636, 0.9862, 1.0051, 0.9543, 0.9476, 1.0018,\n                       0.9950, 0.9785, 0.9645, 0.9845, 0.9971, 0.9926, 0.9836, 0.9977, 0.9948,\n                       1.0104, 0.9838, 0.9874, 0.9564, 0.9576, 1.0086, 0.9512, 0.9666, 1.0445,\n                       0.9726, 1.0137, 0.9925, 0.9492, 0.9786, 0.9845, 0.9593, 1.0024, 0.9794,\n                       1.0106, 0.9976, 0.9926, 0.9973, 1.0138, 1.0164, 1.0183, 1.0427, 1.0290,\n                       0.9150, 0.9884, 1.0273, 1.0495, 1.0478, 1.0101, 1.0147, 0.9842, 0.9840,\n                       1.0519, 1.0098, 1.0035, 0.9884, 0.9816, 1.0111, 1.0126, 0.9587, 0.9734,\n                       1.0412, 1.0014, 0.9237, 1.0083, 0.9667, 1.0346, 1.0320, 0.9840, 0.9817,\n                       1.0177, 1.0393, 0.9846, 1.0645, 1.0203, 0.9766, 0.9693, 0.9654, 1.0689,\n                       1.0109, 1.0081, 1.0256, 1.0087, 0.9981, 1.0589, 0.9890, 1.0344, 0.9924,\n                       1.0138, 1.0091, 1.0197, 0.9826, 1.0231, 0.9179, 1.0404, 1.0021, 0.9652,\n                       0.9787, 1.0773, 1.0233, 0.9873, 1.0050, 0.9869, 0.9777, 0.9831, 0.9838,\n                       1.0388, 0.9934, 1.0005, 0.9977, 1.0054, 1.0085, 0.9733, 0.9435, 0.9644,\n                       1.0054, 1.0067, 1.0117, 0.9918, 0.9684, 0.9990, 0.9573, 0.9757, 0.9807,\n                       1.0008, 0.9743, 0.9758, 0.9815, 0.9815, 0.9989, 1.0784, 0.9628, 0.9571,\n                       0.9884, 0.9748, 0.9709, 0.9719, 1.1333, 0.9887, 0.9613, 1.0225, 0.9809,\n                       0.9884, 1.0074, 1.0080, 1.0004, 1.0098, 0.9958, 1.0107, 0.9838, 1.0290,\n                       0.9545, 0.9926, 1.0145, 1.0230, 0.9839, 0.9539, 0.9824, 0.9970, 1.0396,\n                       1.0080, 1.0222, 1.0024, 0.9918])),\n              ('layer3.5.bn2.bias',\n               tensor([-0.1680, -0.0991, -0.0260, -0.1127, -0.0573, -0.1532, -0.0923, -0.0594,\n                       -0.1179, -0.0890, -0.0957, -0.0644, -0.1000, -0.0856, -0.0607, -0.0916,\n                       -0.0634, -0.0267, -0.0941, -0.0858, -0.0653, -0.0697, -0.0566, -0.0613,\n                       -0.0638, -0.0755, -0.0074, -0.1003, -0.0408, -0.0649, -0.0318, -0.0316,\n                       -0.1301, -0.1521, -0.0885, -0.0286, -0.1192, -0.0734, -0.0918, -0.0441,\n                       -0.0618, -0.0961, -0.0619, -0.0618, -0.0830, -0.0678, -0.0820, -0.1284,\n                       -0.0823, -0.0390, -0.0526, -0.0861, -0.0387, -0.0554, -0.0865, -0.0687,\n                       -0.0933, -0.0805, -0.1014, -0.0776, -0.0102, -0.0232, -0.0404, -0.0742,\n                       -0.0802, -0.0602, -0.0664, -0.0224, -0.0872, -0.0653, -0.1310, -0.1298,\n                       -0.0743, -0.0709, -0.0607, -0.0864, -0.0557, -0.0656, -0.0898, -0.0985,\n                       -0.1035, -0.0652, -0.0628, -0.0657, -0.1119, -0.0742, -0.1215, -0.0400,\n                       -0.0315, -0.0664, -0.0769, -0.0440, -0.0723, -0.0638, -0.0764, -0.1218,\n                       -0.0673, -0.0546, -0.0747, -0.0861, -0.0277, -0.1263, -0.0900, -0.0676,\n                       -0.1028, -0.1008, -0.0257, -0.0858, -0.0677, -0.0621, -0.0644, -0.0642,\n                       -0.0111, -0.0741, -0.0811, -0.0758, -0.0359, -0.0910, -0.1161, -0.0231,\n                       -0.0449, -0.0214, -0.0784, -0.0847, -0.0897, -0.0755, -0.0544, -0.1145,\n                       -0.0671, -0.0684, -0.1005, -0.0909, -0.0732, -0.0547, -0.1047, -0.0719,\n                       -0.0566, -0.0400, -0.1317, -0.0092, -0.0584, -0.0617, -0.0634, -0.0572,\n                       -0.1237, -0.1203, -0.0590, -0.1163, -0.0644, -0.0513, -0.0875, -0.0377,\n                       -0.1304, -0.0435,  0.0036, -0.0596, -0.0449, -0.1395, -0.0727, -0.0881,\n                       -0.0755, -0.1448, -0.0878, -0.0545, -0.0860, -0.0255, -0.0389, -0.0470,\n                       -0.1277, -0.0331, -0.1292, -0.0936, -0.0910, -0.0443, -0.0648, -0.0858,\n                       -0.0871, -0.0948, -0.0585, -0.1349, -0.0816, -0.0318, -0.0514, -0.1019,\n                       -0.0214, -0.0746, -0.1121, -0.0654, -0.0247, -0.0614, -0.2601, -0.1144,\n                       -0.0789, -0.0670, -0.0380, -0.0919, -0.0673, -0.0492, -0.1275, -0.1043,\n                       -0.0790, -0.1099, -0.0746, -0.0943, -0.0670, -0.0708, -0.0386, -0.0722,\n                       -0.0477, -0.0493, -0.0395, -0.0425, -0.0315, -0.0450, -0.1153, -0.0925,\n                       -0.0713, -0.1396, -0.0715, -0.0962, -0.0612, -0.0807, -0.0822, -0.0566,\n                       -0.0938, -0.0230, -0.0920, -0.0637, -0.0838, -0.0515, -0.0986, -0.1417,\n                       -0.0409, -0.0427, -0.0843, -0.0738, -0.0651,  0.0018, -0.0923, -0.0443,\n                       -0.0257, -0.0611, -0.0516, -0.0823, -0.0671, -0.0418, -0.1336, -0.0876,\n                       -0.0895, -0.0825, -0.0792, -0.0062, -0.0489, -0.1221, -0.0581, -0.0264])),\n              ('layer3.5.bn2.running_mean',\n               tensor([-0.3021,  0.3956,  0.2843,  0.1232, -0.5544,  0.0377,  0.2278, -0.3756,\n                        0.0699, -0.3617, -0.2039,  0.5209, -0.3939, -0.4179,  0.3057, -0.2015,\n                        0.0604,  0.6161, -0.9698, -0.0917, -0.2298,  0.4684,  0.1667, -0.3807,\n                        0.1342, -0.1098, -0.0624, -0.0278,  0.1018, -0.0192, -0.0840, -0.2725,\n                        0.3436,  0.1297,  0.2557,  0.1247, -0.0683, -0.0340, -0.3948,  0.5187,\n                        0.0766,  0.0805, -0.4881,  0.1797, -0.0471, -0.0348,  0.0060, -0.3219,\n                        0.1455, -0.3935, -0.3698, -0.6251, -0.4441, -0.5370, -0.1716, -0.2135,\n                        0.1086, -0.2892, -0.0881, -0.4384,  0.3097,  0.4053, -0.1751,  0.2399,\n                       -0.7764,  0.2110,  0.1037,  0.4588, -0.3094, -0.1370,  0.0564, -0.6885,\n                       -0.1870, -0.3195, -0.3453,  0.2985, -0.8943, -0.4854,  0.2449,  0.2604,\n                       -0.7807, -0.1920, -0.0470, -0.0886, -0.7405,  0.3981, -0.7937,  0.5441,\n                        0.0140,  0.5478, -0.5445, -0.1453, -0.3086,  0.2513,  0.3850,  0.9823,\n                       -0.0489,  0.1875,  0.4245,  0.1287,  0.3561,  1.3751, -0.6449,  0.2450,\n                       -0.3203, -0.0931, -0.2648, -0.1617, -0.1949, -0.2747,  0.9741, -0.2118,\n                       -0.2714, -0.3786, -0.0177, -0.2860, -0.2466, -0.6649, -0.5607, -0.0393,\n                       -0.2447, -0.4409, -0.1416, -0.1677, -0.2308, -0.1938,  0.2267, -0.4202,\n                        0.0564,  0.4960, -0.5911, -0.8999, -0.2932, -0.8283,  0.2730,  0.4215,\n                       -0.4977, -0.2085, -0.4761,  0.1622,  0.2606, -0.4034, -0.1668, -0.0979,\n                       -0.5464, -0.4320, -0.4686,  0.0828,  0.4535,  0.2059, -0.1582,  0.4121,\n                       -0.2958, -0.5969,  0.2876, -0.0031, -0.1665, -0.2074, -0.1888, -0.1447,\n                        0.2011, -0.4701, -0.1020, -0.0212, -0.2426,  0.0807, -0.5326, -0.2686,\n                        0.2175, -0.0930, -0.4909, -0.2804, -1.3863, -0.1329,  0.1543,  0.4948,\n                       -0.6352, -0.5171, -0.9381, -0.1016, -0.1154,  0.1619, -0.1397, -0.1440,\n                       -0.0671,  0.2109,  0.4359,  0.6453, -0.1611, -0.0688, -0.8296, -0.0764,\n                        0.2617,  0.1001, -0.6941, -0.1893, -0.6430, -0.0832, -0.0576,  0.0482,\n                       -0.3200, -0.0422,  0.3971, -0.0966,  0.0418, -0.1209,  0.3686, -0.2672,\n                       -0.6280, -0.5113,  0.5583, -0.1602,  0.4146, -0.3285, -0.2517,  0.2476,\n                       -0.2963,  0.3527, -0.4933, -0.2553, -0.2294, -0.6430,  0.3304, -0.2539,\n                        0.3297,  0.1014, -0.2918, -0.2737,  0.0962, -0.8061, -0.4427,  0.3224,\n                       -0.4416, -0.2310,  0.0428, -0.0535, -0.1180, -0.9112,  0.2851,  0.5545,\n                        0.5565,  0.4328, -0.1984, -0.5945,  0.0379, -0.3624, -0.4923, -0.1409,\n                       -0.0506, -0.2487, -0.2782,  0.3163,  0.1792, -0.2779,  0.0151, -0.0302])),\n              ('layer3.5.bn2.running_var',\n               tensor([1.2702, 0.9848, 0.9275, 0.8649, 1.0916, 0.8051, 0.7289, 0.8669, 0.9449,\n                       0.9330, 0.8914, 0.7182, 0.7896, 0.8486, 0.7845, 1.0854, 0.9197, 0.7484,\n                       1.4822, 0.7198, 1.2987, 0.8038, 0.9660, 0.6557, 0.6516, 1.1562, 1.0655,\n                       0.7470, 1.0316, 0.8015, 0.9471, 1.0872, 1.0262, 1.1484, 0.9704, 0.8341,\n                       0.8862, 1.1245, 0.8504, 0.6864, 0.9613, 0.9080, 1.0952, 1.3680, 0.8502,\n                       0.7369, 0.9512, 1.0642, 0.9351, 0.7480, 0.8356, 1.2470, 0.8602, 1.0526,\n                       0.7910, 0.7794, 0.9425, 0.7757, 1.0954, 0.7464, 1.2369, 0.8575, 0.7679,\n                       1.0115, 0.7808, 0.7687, 0.8872, 0.6743, 1.1974, 0.7007, 0.8088, 0.9094,\n                       1.0233, 0.9907, 0.8357, 1.1372, 0.7389, 0.9662, 0.8092, 0.9933, 0.7104,\n                       0.8039, 0.8554, 0.7475, 1.0109, 1.1139, 0.9102, 0.8886, 0.9468, 0.8317,\n                       0.9509, 0.8141, 0.7599, 0.6981, 0.7608, 0.9873, 0.6767, 0.9400, 0.9228,\n                       0.7653, 0.6757, 1.3009, 0.8403, 0.8548, 0.9423, 0.9258, 0.9862, 0.9350,\n                       1.3771, 0.8452, 1.0634, 0.7540, 0.8521, 0.8537, 0.8093, 0.7599, 0.9936,\n                       0.9019, 0.8550, 0.8343, 0.7770, 0.8519, 0.7721, 0.6974, 0.8481, 0.7736,\n                       1.0049, 0.9254, 0.9260, 0.7882, 1.1017, 0.9215, 0.9538, 1.1020, 0.6838,\n                       0.8842, 1.0772, 0.8509, 1.7153, 0.9966, 0.8659, 0.9570, 0.7539, 0.8113,\n                       1.2064, 1.0617, 0.7719, 0.7477, 1.0162, 0.7921, 0.9338, 0.9556, 0.8229,\n                       0.5387, 0.8729, 0.5856, 0.8471, 0.7185, 1.0349, 1.4008, 0.8091, 0.9932,\n                       0.6762, 1.1553, 0.7994, 1.0017, 0.8941, 0.6836, 0.7958, 1.1046, 1.2894,\n                       0.7497, 0.7067, 0.7757, 0.9103, 0.7509, 1.6537, 0.9529, 1.0173, 0.8676,\n                       0.8503, 0.9613, 0.9438, 0.7770, 1.0474, 0.7914, 1.0315, 1.0466, 0.6675,\n                       0.9270, 1.1569, 1.0678, 0.7670, 0.8694, 0.9454, 0.9738, 0.8656, 0.9870,\n                       1.2170, 0.9330, 0.8450, 0.7516, 0.7742, 1.0837, 0.8694, 0.6854, 0.6863,\n                       0.9572, 0.9534, 0.7718, 0.8888, 0.8033, 0.8166, 0.6249, 0.8894, 0.9641,\n                       1.0997, 0.8493, 0.6466, 0.8726, 0.8167, 0.7144, 1.0441, 0.7974, 0.8125,\n                       1.1688, 0.8302, 0.6897, 0.8124, 1.2852, 0.8353, 0.9821, 0.8928, 0.8296,\n                       0.8978, 0.9417, 0.9907, 0.7013, 0.8639, 0.7647, 0.9931, 0.7253, 0.7012,\n                       0.8659, 1.2119, 0.9840, 1.1651, 1.0067, 0.7130, 0.8375, 0.8267, 0.8733,\n                       0.8130, 1.1867, 1.0689, 0.8484])),\n              ('layer3.5.bn2.num_batches_tracked', tensor(13572)),\n              ('layer3.5.conv3.weight',\n               tensor([[[[-0.0191]],\n               \n                        [[-0.0219]],\n               \n                        [[ 0.0380]],\n               \n                        ...,\n               \n                        [[-0.0598]],\n               \n                        [[-0.0319]],\n               \n                        [[ 0.0359]]],\n               \n               \n                       [[[-0.0588]],\n               \n                        [[ 0.0443]],\n               \n                        [[ 0.0268]],\n               \n                        ...,\n               \n                        [[ 0.0742]],\n               \n                        [[ 0.0333]],\n               \n                        [[-0.0405]]],\n               \n               \n                       [[[-0.0115]],\n               \n                        [[-0.0441]],\n               \n                        [[-0.0080]],\n               \n                        ...,\n               \n                        [[-0.0746]],\n               \n                        [[ 0.0045]],\n               \n                        [[-0.0668]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0295]],\n               \n                        [[ 0.0185]],\n               \n                        [[ 0.0199]],\n               \n                        ...,\n               \n                        [[ 0.0377]],\n               \n                        [[-0.0092]],\n               \n                        [[-0.0027]]],\n               \n               \n                       [[[ 0.0208]],\n               \n                        [[-0.0801]],\n               \n                        [[ 0.0403]],\n               \n                        ...,\n               \n                        [[ 0.0440]],\n               \n                        [[-0.0405]],\n               \n                        [[-0.0330]]],\n               \n               \n                       [[[ 0.0837]],\n               \n                        [[-0.0351]],\n               \n                        [[ 0.0452]],\n               \n                        ...,\n               \n                        [[-0.0094]],\n               \n                        [[ 0.0076]],\n               \n                        [[ 0.0212]]]])),\n              ('layer3.5.bn3.weight',\n               tensor([ 0.2573, -0.3282, -0.3261,  ...,  0.0767,  0.2883,  0.1715])),\n              ('layer3.5.bn3.bias',\n               tensor([ 0.0468,  0.0402, -0.0305,  ...,  0.0389, -0.0344,  0.1104])),\n              ('layer3.5.bn3.running_mean',\n               tensor([-0.1059,  0.3147,  0.1548,  ...,  0.0495, -0.0432,  0.2429])),\n              ('layer3.5.bn3.running_var',\n               tensor([0.1059, 0.1572, 0.1210,  ..., 0.0578, 0.1499, 0.1113])),\n              ('layer3.5.bn3.num_batches_tracked', tensor(13572)),\n              ('layer4.0.conv1.weight',\n               tensor([[[[-0.0544]],\n               \n                        [[-0.0731]],\n               \n                        [[ 0.0052]],\n               \n                        ...,\n               \n                        [[ 0.0236]],\n               \n                        [[ 0.0330]],\n               \n                        [[ 0.0356]]],\n               \n               \n                       [[[-0.0143]],\n               \n                        [[-0.0026]],\n               \n                        [[-0.0276]],\n               \n                        ...,\n               \n                        [[-0.0276]],\n               \n                        [[-0.0102]],\n               \n                        [[ 0.0444]]],\n               \n               \n                       [[[ 0.0211]],\n               \n                        [[ 0.0393]],\n               \n                        [[-0.0157]],\n               \n                        ...,\n               \n                        [[-0.0034]],\n               \n                        [[-0.0047]],\n               \n                        [[ 0.0480]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0806]],\n               \n                        [[-0.0235]],\n               \n                        [[ 0.0269]],\n               \n                        ...,\n               \n                        [[ 0.0197]],\n               \n                        [[ 0.0523]],\n               \n                        [[-0.0118]]],\n               \n               \n                       [[[ 0.0001]],\n               \n                        [[-0.0228]],\n               \n                        [[-0.0605]],\n               \n                        ...,\n               \n                        [[-0.0039]],\n               \n                        [[ 0.0257]],\n               \n                        [[ 0.0332]]],\n               \n               \n                       [[[-0.0204]],\n               \n                        [[-0.0062]],\n               \n                        [[ 0.0204]],\n               \n                        ...,\n               \n                        [[ 0.0333]],\n               \n                        [[-0.0380]],\n               \n                        [[-0.0337]]]])),\n              ('layer4.0.bn1.weight',\n               tensor([1.0274, 0.9518, 1.0404, 0.9471, 0.9694, 1.0465, 1.0382, 0.9921, 0.9736,\n                       0.9198, 0.9454, 0.9397, 0.9758, 1.0408, 0.9422, 1.0388, 1.0583, 0.9523,\n                       0.9643, 1.0414, 1.0066, 1.0284, 0.9640, 0.9616, 0.9933, 1.0118, 1.0481,\n                       0.9936, 0.9849, 1.0324, 0.9761, 0.9796, 1.0900, 1.0224, 0.9855, 0.9448,\n                       1.0437, 0.9448, 1.0277, 0.9859, 1.0489, 0.9799, 0.9674, 0.9634, 1.0517,\n                       0.9536, 1.0174, 0.9451, 1.0057, 1.0413, 1.0065, 1.0254, 1.0083, 0.9698,\n                       1.0367, 1.0548, 1.0666, 1.0172, 0.9880, 0.9980, 1.0084, 1.0395, 0.9314,\n                       0.9668, 0.9576, 0.9681, 0.9967, 0.9846, 1.0385, 0.9728, 1.0195, 0.9727,\n                       1.0391, 1.0682, 0.9715, 1.0015, 0.9531, 0.9664, 1.0146, 0.9461, 1.0590,\n                       0.9497, 1.0391, 1.0305, 0.9651, 1.0272, 1.0184, 1.0341, 1.0020, 0.9914,\n                       1.0104, 0.9512, 1.0024, 1.0193, 1.1200, 1.0023, 0.9535, 1.0303, 0.9186,\n                       1.0016, 1.0244, 1.0177, 1.0157, 0.9767, 1.0410, 0.9753, 1.0058, 0.9808,\n                       0.9889, 0.9575, 1.0093, 1.0325, 0.9481, 1.0340, 0.9875, 1.0077, 1.0311,\n                       1.0284, 0.9409, 0.9754, 0.9953, 0.9443, 1.0050, 0.9671, 1.0262, 1.0167,\n                       0.9912, 0.9549, 0.9347, 1.0136, 0.9796, 1.0211, 1.0299, 1.0022, 1.0323,\n                       1.0041, 0.9379, 1.0333, 0.9736, 1.0025, 0.9289, 0.9630, 0.9902, 0.9394,\n                       0.9886, 0.9640, 0.9815, 0.9490, 0.9794, 1.0511, 1.0456, 1.0345, 0.9765,\n                       1.0044, 1.0209, 1.0250, 0.9648, 1.0318, 1.0092, 0.9672, 0.9673, 0.9681,\n                       1.0351, 0.9933, 0.9834, 1.0367, 0.9976, 1.0318, 1.0062, 0.9622, 0.9489,\n                       1.0601, 0.9605, 1.0515, 1.0167, 0.9686, 0.9795, 0.9694, 0.9859, 0.9644,\n                       1.0255, 0.9895, 1.0442, 0.9680, 1.0085, 0.9850, 1.0484, 1.0486, 1.0462,\n                       1.0079, 1.0058, 0.9871, 1.0041, 1.0418, 0.9744, 0.9487, 0.9446, 1.0047,\n                       0.9342, 1.0419, 1.0425, 0.9498, 1.0245, 0.9816, 1.0054, 0.9822, 1.0181,\n                       0.9682, 0.9856, 1.0057, 1.0039, 1.0310, 1.0141, 1.0459, 1.0057, 1.0161,\n                       0.9954, 0.9867, 0.9504, 0.9972, 0.9760, 0.9992, 1.0317, 0.9443, 1.0027,\n                       0.9882, 0.9837, 0.9588, 1.0444, 1.0019, 1.0193, 0.9154, 1.0309, 0.9409,\n                       0.9544, 0.9821, 0.9741, 1.0382, 0.9341, 1.0107, 0.9470, 1.0323, 1.0133,\n                       0.9919, 1.0362, 0.9650, 1.0185, 1.0844, 1.0575, 0.9686, 1.0564, 1.0177,\n                       0.9799, 0.9576, 0.9622, 0.9519, 0.9444, 1.0337, 0.9859, 0.9697, 0.9906,\n                       1.0278, 1.0206, 1.0218, 1.0387, 0.9704, 1.0581, 1.0610, 1.0267, 0.9331,\n                       0.9844, 1.0244, 0.9771, 0.9713, 1.0148, 0.9452, 0.9484, 0.9854, 0.9738,\n                       0.9988, 0.9682, 0.9759, 1.0330, 1.0402, 1.0036, 0.9944, 0.9290, 1.0133,\n                       1.0092, 1.0441, 0.9651, 1.0578, 0.9653, 1.0200, 0.9525, 1.0790, 0.9293,\n                       0.9973, 1.0439, 0.9878, 1.0524, 1.0118, 1.0226, 0.9858, 1.0313, 0.9500,\n                       0.9697, 1.0093, 0.9829, 0.9413, 1.0337, 0.9535, 0.9685, 0.9825, 1.0066,\n                       0.9990, 0.9725, 1.0539, 0.9795, 1.0300, 1.0370, 0.9568, 0.9510, 1.0363,\n                       0.9855, 0.9757, 0.9399, 1.0131, 0.9684, 0.9373, 1.0229, 0.9433, 0.9905,\n                       0.9962, 0.9640, 0.9863, 1.0131, 1.0342, 0.9949, 0.9789, 0.9944, 0.9671,\n                       1.0328, 1.0227, 1.0072, 1.0135, 0.9457, 0.9574, 1.0198, 0.9709, 0.9966,\n                       0.9770, 0.9463, 1.0365, 1.0169, 0.9881, 0.9612, 0.9424, 0.9814, 1.0373,\n                       0.9516, 1.0064, 0.9980, 1.0221, 1.0384, 0.9793, 1.0222, 1.0039, 0.9381,\n                       0.9576, 0.9801, 0.9704, 1.0325, 0.9144, 0.9994, 1.0410, 1.0330, 0.9777,\n                       0.9997, 0.9541, 0.9642, 0.9854, 0.9257, 0.9371, 1.0277, 0.9520, 0.9526,\n                       1.0140, 0.9611, 1.0661, 1.0288, 1.0251, 0.9652, 0.9891, 0.9707, 0.9463,\n                       0.9764, 0.9966, 1.0707, 0.9277, 0.9826, 0.9978, 1.0216, 0.9653, 1.0349,\n                       1.0237, 0.9692, 1.0663, 1.0175, 0.9859, 0.9717, 0.9909, 1.0073, 1.0407,\n                       1.0146, 1.0429, 1.0235, 1.0513, 1.0006, 0.9903, 0.9651, 1.0006, 0.9744,\n                       1.0386, 0.9725, 0.9734, 0.9835, 0.9441, 0.9414, 0.9691, 0.9816, 0.9924,\n                       0.9943, 0.9653, 0.9918, 0.9443, 1.0516, 1.0212, 0.9646, 0.9639, 1.0428,\n                       1.0084, 1.0192, 1.0256, 0.9833, 1.0751, 1.0183, 0.9857, 0.9857, 1.0197,\n                       0.9773, 0.9690, 0.9878, 1.0151, 1.0172, 1.0310, 1.0284, 0.9755, 0.9941,\n                       0.9633, 1.0369, 0.9696, 1.0099, 1.0227, 0.9282, 0.9875, 0.9880, 0.9434,\n                       0.9472, 0.9692, 1.0330, 0.9897, 0.9952, 0.9530, 0.9781, 1.0442, 0.9753,\n                       1.0777, 0.9646, 0.9809, 1.0109, 0.9588, 1.0222, 0.9230, 0.9644, 1.0077,\n                       0.9996, 1.0085, 1.0247, 1.0040, 1.0101, 0.9736, 1.0170, 1.0230, 0.9545,\n                       1.0016, 1.0392, 0.9731, 1.0239, 1.0299, 1.0508, 1.0501, 0.9958, 1.0076,\n                       1.0605, 0.9553, 0.9036, 0.9635, 1.0492, 0.9592, 0.9435, 1.0406])),\n              ('layer4.0.bn1.bias',\n               tensor([-7.6670e-03, -1.1578e-01, -1.0715e-02, -1.0487e-01, -9.9615e-02,\n                       -3.5793e-02, -5.0207e-03, -7.6962e-02, -7.2617e-02, -1.2665e-01,\n                       -1.1477e-01, -1.0801e-01, -1.1329e-01, -7.2412e-02, -1.1861e-01,\n                       -8.3759e-02, -1.0048e-01, -4.8998e-02, -9.2247e-02,  3.3713e-02,\n                       -1.0736e-01, -8.7694e-02, -5.5448e-02, -8.4274e-02, -6.8008e-02,\n                       -6.2305e-02, -9.0596e-02, -1.2425e-02, -3.0047e-02, -1.0579e-02,\n                       -8.3406e-02, -9.4961e-02, -2.4573e-02, -6.3458e-02, -3.3297e-02,\n                       -1.5012e-01, -3.1894e-03, -8.2568e-02, -4.9505e-02, -4.7311e-02,\n                       -6.5107e-02, -4.7967e-02, -1.5273e-01, -8.6417e-02, -3.0753e-02,\n                       -1.3245e-01, -7.2677e-02, -4.4583e-02, -4.5036e-02,  3.8077e-03,\n                       -5.0006e-02, -6.6456e-02, -4.8552e-02, -9.1031e-02, -2.4574e-02,\n                       -3.1918e-02, -1.3339e-02, -4.0951e-02, -6.5404e-02, -9.5490e-02,\n                       -3.4933e-02, -2.1549e-02, -1.0745e-01, -9.4151e-02, -6.4910e-02,\n                       -6.8278e-02, -6.2912e-02, -1.8332e-02, -5.5470e-02, -6.5371e-02,\n                       -8.0887e-04, -7.6419e-02, -2.9947e-02,  1.3493e-02, -1.0113e-01,\n                       -8.2405e-02, -1.1996e-01, -5.2280e-02, -5.7388e-02, -1.4830e-01,\n                       -2.6317e-06, -1.0320e-01, -8.0227e-02, -6.3376e-02, -8.7874e-02,\n                       -9.5235e-02, -6.0523e-02, -3.9711e-02, -6.8867e-02, -7.4042e-02,\n                       -6.7097e-02, -1.3269e-01, -1.0215e-01, -3.9968e-02, -9.1064e-03,\n                       -7.0711e-02, -9.6131e-02, -4.0690e-02, -1.6848e-01, -4.9251e-02,\n                       -4.1814e-02, -1.0583e-01, -8.5516e-02, -1.1680e-01, -1.0193e-01,\n                       -7.9558e-02, -7.4751e-03, -5.6035e-02, -3.3804e-02, -1.1117e-01,\n                       -7.5676e-02, -7.1274e-02, -8.9391e-02, -4.7204e-02, -1.4222e-01,\n                       -7.7408e-02, -6.1983e-02, -7.7032e-02, -1.0313e-01, -1.0668e-01,\n                       -3.4871e-02, -3.0789e-02, -3.6515e-02, -1.1290e-01, -8.3858e-02,\n                       -3.4708e-02, -6.0531e-02, -8.7476e-02, -9.0353e-02, -6.9616e-02,\n                       -6.6810e-02, -2.3618e-02, -1.1904e-02, -9.4327e-02, -1.1392e-02,\n                       -3.8840e-02, -1.4610e-01, -5.2776e-02, -5.8002e-02, -7.1077e-02,\n                       -5.4434e-02, -1.1326e-01, -6.7170e-02, -1.1518e-01, -7.8093e-02,\n                       -1.0621e-01, -6.6802e-02, -7.8084e-02, -1.0695e-01, -6.5664e-03,\n                       -2.8955e-03, -1.0043e-01, -7.3176e-02, -3.4715e-02, -5.0478e-02,\n                       -8.3986e-02, -7.0237e-02,  1.3841e-02, -3.1834e-02, -7.8771e-02,\n                       -1.0671e-01, -7.7381e-02, -7.9841e-02, -2.4431e-02, -7.8635e-02,\n                       -3.2469e-02, -7.7820e-02, -3.9254e-02, -6.0127e-02, -7.0795e-02,\n                       -9.7454e-02, -1.1111e-02, -8.1776e-02, -9.3967e-02, -1.0121e-01,\n                       -1.5798e-01, -5.0556e-02, -8.5448e-02, -7.1437e-02, -1.4835e-01,\n                       -9.7527e-02, -9.7772e-02, -9.7293e-02, -1.4696e-01, -4.5890e-02,\n                       -2.8516e-02, -2.2551e-02, -3.0908e-02, -4.3631e-02, -4.5461e-02,\n                       -6.9022e-02, -7.9505e-02, -3.7270e-02, -1.0395e-02, -1.3217e-01,\n                       -1.3751e-01, -7.4783e-02, -6.4392e-02, -4.5483e-02, -3.4098e-02,\n                       -6.8698e-02, -9.9031e-02, -5.9331e-02, -8.7352e-02, -4.7442e-02,\n                       -7.7170e-02, -5.6498e-02, -7.4010e-02, -5.2703e-02, -1.0565e-03,\n                       -1.5695e-02, -3.1509e-02, -1.1971e-01, -3.6092e-02,  4.0683e-03,\n                       -4.8184e-02, -3.8245e-02, -3.3208e-02, -7.4559e-02, -5.5143e-02,\n                       -8.2255e-02, -8.7676e-02, -5.5631e-02, -5.9868e-02, -7.1040e-02,\n                       -3.7917e-02, -1.1217e-01, -1.0171e-01, -3.0299e-02, -5.6392e-02,\n                       -8.1502e-03, -9.9018e-02, -3.8634e-02, -9.9597e-02, -1.5163e-01,\n                       -7.5847e-02, -7.4977e-02, -6.2969e-02, -1.4455e-01, -5.3297e-02,\n                       -8.4110e-02, -4.9279e-02, -3.4814e-02, -1.0743e-01, -4.4634e-02,\n                       -7.3444e-02, -3.8425e-02, -3.3945e-02, -4.8018e-02, -5.8899e-02,\n                        2.7614e-03, -7.2865e-02, -1.4293e-01, -9.5202e-02, -1.5621e-01,\n                       -8.0429e-02, -1.2202e-01, -2.8046e-02, -1.0051e-01, -1.4350e-01,\n                       -6.9663e-02, -3.8656e-02, -6.9611e-02, -4.9282e-02,  1.1422e-03,\n                       -5.0582e-02, -8.4562e-03,  4.5878e-03, -2.3632e-02, -1.0803e-01,\n                       -6.2722e-02, -1.0911e-01, -7.9185e-02, -2.4414e-02, -2.2459e-02,\n                       -4.3868e-02, -1.5921e-01, -4.7515e-02, -1.2896e-01,  4.0395e-03,\n                       -5.5604e-02, -1.1875e-01, -4.5473e-02, -8.0390e-02, -1.4732e-01,\n                       -3.9208e-02, -1.0442e-01, -1.2985e-01, -7.6574e-02, -6.7041e-02,\n                       -7.1078e-02, -3.3100e-02, -8.9906e-02, -2.5549e-02, -4.7613e-02,\n                       -2.0830e-02, -1.2573e-01,  3.1643e-03, -1.7506e-02, -5.3796e-02,\n                       -9.1125e-03, -8.5793e-02, -9.4048e-02, -5.8001e-02, -3.9139e-02,\n                       -1.1438e-01, -9.8144e-02, -2.4834e-02, -5.0963e-02, -7.2110e-02,\n                       -2.0904e-02, -8.5856e-02, -9.3664e-02, -2.7018e-02, -5.0632e-02,\n                       -4.1894e-02, -7.6108e-02, -3.5153e-02, -8.1941e-02, -4.6800e-02,\n                        1.4363e-03, -6.4425e-02, -6.2496e-02, -1.9419e-02, -8.3749e-02,\n                       -9.5784e-02, -1.2836e-01, -6.5310e-02, -5.5175e-02, -1.0007e-01,\n                       -6.8817e-02, -1.2624e-01, -1.4240e-01, -6.5925e-02, -1.1081e-01,\n                       -8.6718e-02, -1.0553e-01, -4.6314e-02, -9.1073e-02, -5.9067e-02,\n                       -7.2524e-02, -9.8142e-02, -7.1605e-03, -1.3020e-02, -5.4819e-02,\n                       -3.9546e-02, -9.2143e-02, -1.1848e-01, -9.2458e-03, -8.3177e-02,\n                       -7.3544e-02, -4.1835e-02, -1.1062e-01, -5.5702e-02,  1.3503e-04,\n                       -1.1317e-02, -8.0058e-02, -1.1409e-01, -2.2305e-02, -2.9441e-02,\n                       -5.7551e-02, -8.5413e-02, -9.9164e-02, -1.8260e-02,  1.2289e-02,\n                       -5.5979e-02, -7.2338e-02, -7.7515e-02, -1.1255e-01, -8.3769e-02,\n                       -1.3101e-01, -9.8261e-02, -5.4941e-02, -1.3215e-01, -9.8968e-02,\n                       -3.6145e-02, -3.9139e-02, -5.5067e-02, -1.2272e-01, -1.1412e-01,\n                       -1.2639e-01, -1.7399e-01, -1.3458e-01, -1.0662e-01, -2.8370e-02,\n                       -1.1547e-01, -9.4941e-02, -5.4764e-02, -1.2345e-01, -1.4248e-02,\n                       -4.2242e-02, -7.8813e-02, -5.8459e-02, -6.2160e-02, -2.7357e-02,\n                       -8.1914e-02, -9.2288e-02, -1.2461e-01, -2.6842e-02, -9.3196e-02,\n                       -8.4009e-02, -7.4990e-02, -5.4435e-02, -1.0252e-01, -3.9284e-02,\n                       -1.0894e-03, -4.0884e-02, -7.0526e-03, -1.3170e-01, -7.4453e-02,\n                       -1.4887e-01, -9.5018e-02, -6.2196e-02, -1.3269e-02, -5.3399e-02,\n                       -9.5873e-03, -5.5003e-02,  9.9982e-03, -9.6529e-02, -8.7384e-02,\n                       -5.3383e-02, -2.0638e-02, -9.8151e-02, -5.2711e-02, -7.5819e-03,\n                       -1.1551e-01, -7.9879e-02, -6.4768e-02, -1.0195e-01, -1.1059e-01,\n                       -5.0407e-02, -6.3736e-02, -1.2193e-01, -1.4841e-01, -1.2146e-01,\n                       -1.7196e-01, -3.8994e-02, -4.5172e-02, -1.3919e-01, -9.5346e-02,\n                       -5.6500e-02, -7.1431e-02, -9.4761e-02, -4.9981e-02, -9.7717e-02,\n                       -4.9041e-02, -4.2257e-02, -1.5811e-01, -4.7668e-02, -4.3554e-02,\n                       -2.6879e-02, -1.2581e-01, -9.6397e-02, -1.1879e-01, -7.4318e-02,\n                        9.7830e-03, -1.7534e-02, -6.4964e-02, -6.3529e-02, -5.0688e-02,\n                        3.1754e-02, -1.1406e-01, -3.4157e-02, -4.6640e-02, -1.0354e-01,\n                       -6.8470e-02, -8.1425e-02, -9.0394e-02, -1.0081e-01, -7.4904e-02,\n                       -8.7757e-02, -4.6743e-02, -2.1506e-02, -1.2694e-01, -1.1960e-01,\n                       -1.8029e-02, -1.7182e-02, -1.1508e-02, -7.1300e-02, -1.0623e-01,\n                       -6.5935e-02, -1.4972e-01, -4.9211e-02, -1.4720e-01, -8.2256e-02,\n                       -3.5954e-02, -5.5151e-02, -9.6558e-02, -9.8645e-02, -5.5570e-02,\n                       -8.4180e-02, -8.8054e-02, -4.8913e-02,  6.0362e-05, -8.0120e-02,\n                       -6.1741e-02, -2.1942e-02, -1.3509e-01, -6.1402e-03, -5.8204e-02,\n                       -4.7335e-02, -1.3834e-02, -2.6814e-02, -4.7211e-02, -1.4052e-02,\n                       -1.1229e-01, -1.1399e-01, -7.9888e-02, -4.5700e-02, -9.9658e-02,\n                       -1.4492e-01, -4.0268e-02])),\n              ('layer4.0.bn1.running_mean',\n               tensor([ 7.2998e-02, -4.2631e-01, -1.5454e-01, -2.2870e-01, -2.4967e-01,\n                       -1.7621e-01, -4.6175e-01, -6.8774e-01, -5.0617e-02,  1.1715e-02,\n                        6.9179e-01, -7.2777e-02, -7.4534e-01,  1.9410e-01,  1.4111e-01,\n                       -7.1091e-01,  2.7739e-01,  8.1148e-02,  8.4043e-01, -1.9710e-01,\n                       -4.5560e-01, -1.0518e+00, -5.8229e-01, -4.1399e-01, -9.2908e-01,\n                       -7.0343e-01, -4.3476e-01,  5.8744e-03, -2.3676e-01, -1.4050e-01,\n                       -2.8417e-01, -2.6518e-01, -7.0181e-01,  1.9420e-01, -6.5058e-01,\n                       -1.7488e-02, -1.4641e-01, -2.9378e-01,  1.0395e-01, -9.4567e-01,\n                       -6.9452e-01,  2.9214e-01, -3.8791e-01,  2.9541e-01, -3.0253e-01,\n                       -2.0322e-01, -3.8365e-01, -9.2975e-01,  3.7588e-01, -1.2632e+00,\n                       -6.5237e-01, -7.5325e-01, -3.1063e-02, -5.8537e-01, -3.9496e-01,\n                        2.5690e-01, -3.9933e-01,  9.2939e-02, -3.1123e-01,  2.7600e-01,\n                        5.7568e-02,  9.6768e-02, -2.1765e-01,  6.7225e-01,  1.9584e-02,\n                       -5.5736e-01, -1.7700e-01,  5.5417e-01,  5.8076e-02, -1.0777e-01,\n                       -2.5520e-01, -3.8483e-01, -7.7157e-02, -2.2668e-01, -2.1627e-01,\n                       -1.9945e-01,  9.0454e-02,  2.6369e-01,  4.8641e-02, -8.2874e-01,\n                       -9.1312e-01, -3.5921e-01, -3.0896e-01, -6.9962e-01,  3.7411e-01,\n                       -3.3019e-01,  1.8564e-01, -4.3314e-01, -3.3659e-01,  3.5002e-01,\n                       -1.4818e-01, -3.4815e-01,  6.9827e-02, -7.6939e-02,  9.9834e-01,\n                       -3.7017e-01, -8.5888e-02, -4.2231e-01, -2.2847e-01,  4.8426e-01,\n                       -6.2516e-01,  4.7258e-03,  8.2129e-01, -3.1234e-01,  8.8710e-02,\n                       -8.2166e-01, -7.3404e-02, -6.2353e-01,  2.3117e-01, -6.2091e-01,\n                       -9.1436e-01, -1.4572e-01,  1.5934e-01, -3.7608e-01, -1.6370e-01,\n                        3.8258e-01, -4.9397e-01, -9.6047e-02, -7.5681e-01, -7.0318e-01,\n                       -9.9049e-01,  5.6638e-01, -2.8960e-01, -1.3983e-01, -4.5117e-02,\n                       -4.1935e-01, -7.0696e-01, -4.3936e-01, -3.6078e-01,  2.3124e-01,\n                       -3.5744e-01,  1.8307e-01, -6.0495e-02, -2.4714e-01, -2.2293e-01,\n                        2.1420e-01, -2.8135e-02, -8.6057e-02, -9.5350e-02, -2.3727e-01,\n                        1.7012e-02,  3.6948e-02, -1.6246e-01, -3.7927e-01, -8.2009e-01,\n                        2.2107e-04, -7.1649e-02,  7.3059e-01,  5.9310e-01,  2.3877e-02,\n                       -4.0438e-01, -3.7288e-01, -3.4009e-02,  4.1762e-01,  4.2985e-02,\n                       -5.5030e-01, -1.3384e-01, -2.3027e-01,  5.8159e-01, -3.8556e-01,\n                       -3.6283e-01, -2.3334e-01, -3.0898e-01, -7.1795e-01,  1.9874e-01,\n                        2.6505e-01, -1.4642e-01,  1.7807e-01, -4.7568e-01,  5.5272e-01,\n                       -3.5075e-01, -6.5209e-01, -2.4952e-01,  6.7658e-02,  3.5242e-01,\n                       -3.1474e-01,  3.2470e-01,  6.1389e-01, -2.1651e-01,  1.3368e-01,\n                       -1.7958e-02, -7.3957e-02, -4.3168e-02, -7.9953e-01,  4.4057e-01,\n                       -4.1898e-01,  1.5797e-01, -3.0089e-01,  4.0456e-01, -3.9119e-01,\n                       -2.9707e-01, -5.2412e-01, -7.0937e-02, -9.8056e-04, -1.9109e-01,\n                        2.8989e-02, -8.9503e-01,  8.4162e-02, -1.4761e-01,  5.1655e-01,\n                       -2.1567e-01, -2.8370e-01, -1.2288e-01, -2.7448e-01, -9.8657e-02,\n                       -1.6539e-01, -1.5668e-01, -3.4534e-01,  1.4303e-01, -4.9289e-01,\n                       -4.4719e-01, -3.8285e-01, -5.7606e-01, -1.5385e-01,  2.1452e-01,\n                        4.5166e-01,  5.3280e-01, -5.1998e-01, -8.2701e-01,  5.3499e-03,\n                       -8.1729e-01, -4.9954e-01, -5.1127e-01,  1.2329e-02, -2.9883e-01,\n                       -5.3514e-01, -2.7019e-01, -4.0511e-01, -2.0575e-01,  4.1498e-02,\n                        5.9055e-02, -4.5818e-01, -5.2037e-01, -1.5548e-01, -3.1604e-01,\n                       -3.1474e-01, -1.7855e-02, -1.0709e+00,  5.1914e-02, -4.3144e-01,\n                       -1.8605e-01, -1.2889e-01,  2.2020e-01,  7.0865e-02, -3.4558e-01,\n                       -2.3143e-01,  7.9136e-02,  3.9677e-01, -1.1834e-01, -7.8243e-01,\n                       -1.6491e-01, -6.1361e-01, -5.2908e-01,  4.8394e-01,  3.8452e-02,\n                        1.8807e-01, -3.2038e-01,  1.9198e-01, -6.0079e-01, -1.3928e+00,\n                       -4.8264e-01, -6.9647e-01, -9.0683e-02, -8.0727e-01,  6.7116e-01,\n                        6.8988e-02, -5.3281e-01, -4.6772e-01, -2.5266e-01, -1.3628e-01,\n                       -6.8823e-01,  2.8877e-01, -4.0506e-01, -5.9756e-01,  8.9323e-03,\n                        2.9968e-02, -7.1861e-01,  2.1398e-01, -1.5521e-01, -2.2544e-01,\n                       -4.6558e-01, -9.2387e-01, -4.8108e-01, -8.9719e-02, -5.1493e-01,\n                       -3.2079e-01, -7.3364e-01,  1.8350e-02,  9.3936e-02, -1.4795e+00,\n                        3.5323e-01,  2.6203e-01, -9.7086e-02, -1.0153e+00,  2.3624e-01,\n                        2.5939e-02, -3.3474e-01, -2.1995e-01, -2.8424e-01, -1.7999e-01,\n                        1.8803e-01,  4.2021e-02, -4.4447e-01, -7.7774e-01, -3.1427e-02,\n                       -5.4510e-01,  1.4513e-01, -6.9138e-01, -3.6582e-02,  3.7046e-01,\n                       -5.4771e-01,  1.3178e-01,  6.0213e-01, -5.6781e-01, -6.3862e-02,\n                       -5.5840e-02, -3.5105e-01, -3.4661e-01, -3.5124e-01, -2.3725e-01,\n                       -6.7194e-01, -8.4360e-02, -1.1332e+00, -3.9066e-01, -6.2629e-01,\n                       -1.9310e-01, -2.5614e-01, -4.1605e-01, -4.1654e-01, -7.6574e-01,\n                       -2.6166e-01, -5.1198e-01, -2.7550e-02,  8.7226e-01, -5.3880e-01,\n                       -3.6221e-01, -9.5817e-02, -5.9399e-01,  1.3972e-01, -3.6889e-01,\n                       -3.6493e-01, -1.6241e-01, -2.0553e-01,  8.6491e-01, -3.2376e-01,\n                        1.7086e-02,  3.2692e-01,  6.5554e-02, -1.1713e+00,  3.7449e-01,\n                       -4.7016e-01, -6.7972e-01, -4.1833e-01, -8.2732e-01, -1.8230e-01,\n                        1.2098e-02, -1.7837e-01, -3.0698e-01, -2.9989e-01, -3.2826e-01,\n                       -3.5463e-01, -5.9956e-01, -2.1713e-01, -6.5036e-01,  1.0531e-01,\n                       -4.8486e-01, -1.1698e-01, -8.1754e-02, -3.4873e-01, -6.4456e-01,\n                       -6.8436e-01, -3.7613e-01, -2.7614e-01,  4.9836e-01,  4.4040e-02,\n                       -4.9508e-01, -1.9181e-01, -4.3945e-01, -2.9646e-02,  7.5172e-01,\n                       -2.5913e-01, -3.2351e-01,  2.0259e-01, -3.2182e-01,  5.1118e-01,\n                       -1.3666e-01, -7.2194e-02, -4.8057e-01, -2.9160e-01, -5.4419e-03,\n                       -4.8564e-01,  4.2491e-01,  8.4420e-02, -8.2156e-01, -7.7950e-01,\n                       -3.5619e-01, -9.9850e-02, -1.3997e-01, -5.5219e-01, -3.1120e-01,\n                       -9.9281e-02,  1.6223e-01,  8.8964e-02, -5.4383e-01, -5.8048e-01,\n                       -2.5803e-01,  4.4290e-02,  1.9566e-01, -1.0131e-01, -3.9925e-01,\n                       -3.4625e-01, -9.8277e-01, -2.8167e-01,  3.7837e-01, -3.4038e-01,\n                       -4.1017e-01, -2.3031e-01, -5.6166e-01,  3.9016e-01,  7.8430e-02,\n                        8.0500e-02,  2.4490e-01,  1.3216e-01, -3.9268e-01, -9.4665e-01,\n                        1.5312e-01, -7.1473e-02,  1.2036e-01, -9.5914e-01, -7.0443e-01,\n                       -4.5874e-01, -6.2864e-01, -5.2517e-01,  2.4611e-01, -5.7617e-01,\n                       -1.0032e-01, -4.3558e-01,  1.0649e-01, -3.8191e-01, -1.9375e-01,\n                       -2.9021e-01,  9.2202e-02, -2.2110e-01,  3.2202e-02,  1.0019e-01,\n                       -7.1798e-02, -3.8741e-01, -3.0578e-02,  1.8199e-01,  4.4156e-02,\n                       -3.6397e-01, -1.8538e-01, -3.1914e-01, -3.6414e-01, -3.2536e-01,\n                       -9.6833e-01, -8.5667e-01,  2.3326e-01,  2.5836e-01, -5.1849e-02,\n                        2.1935e-01, -3.0385e-01, -3.0061e-01,  2.4611e-01, -1.2255e+00,\n                        1.7933e-01, -2.2708e-01, -2.6969e-01, -6.0976e-01,  7.4698e-03,\n                       -3.9498e-01,  5.1515e-01, -5.4643e-01,  8.4468e-02, -1.8517e-01,\n                       -6.0631e-01,  1.6461e-01, -7.3241e-02, -2.4350e-01,  2.7459e-01,\n                       -3.2187e-01, -2.2189e-02, -5.2435e-01,  9.5862e-02,  2.7607e-01,\n                       -3.5972e-01, -5.3574e-01,  8.2451e-01,  2.1415e-02,  2.7234e-01,\n                       -3.2237e-01, -2.7104e-01, -5.2500e-01,  3.6539e-01, -1.0947e-01,\n                        4.5122e-02, -2.6404e-01, -5.7802e-01, -5.2465e-01, -8.7109e-01,\n                       -3.4765e-01, -2.2885e-01, -2.6764e-01, -7.3461e-01,  1.4874e-01,\n                       -4.0682e-01, -6.6778e-01, -2.4493e-01,  2.2740e-01, -9.3507e-01,\n                       -3.8224e-01,  1.3183e-01])),\n              ('layer4.0.bn1.running_var',\n               tensor([0.3642, 0.3789, 0.3814, 0.3233, 0.2876, 0.4394, 0.3135, 0.3829, 0.3479,\n                       0.3120, 0.3333, 0.3490, 0.4273, 0.4103, 0.3412, 0.4009, 0.4045, 0.3270,\n                       0.3837, 0.3494, 0.3987, 0.5177, 0.3115, 0.3235, 0.3269, 0.3860, 0.3704,\n                       0.3470, 0.3197, 0.4012, 0.3330, 0.3916, 0.4203, 0.3251, 0.3437, 0.3773,\n                       0.3856, 0.2540, 0.3867, 0.3099, 0.3853, 0.3602, 0.3920, 0.3331, 0.3522,\n                       0.3644, 0.3765, 0.3549, 0.3723, 0.3283, 0.3390, 0.3893, 0.3022, 0.3262,\n                       0.3782, 0.4988, 0.4384, 0.4020, 0.3149, 0.3986, 0.3970, 0.4061, 0.3347,\n                       0.3045, 0.3409, 0.2878, 0.3707, 0.3397, 0.3328, 0.3146, 0.3822, 0.3252,\n                       0.4344, 0.3790, 0.3454, 0.4168, 0.3099, 0.3223, 0.4400, 0.3388, 0.3834,\n                       0.3113, 0.3626, 0.3731, 0.3126, 0.3824, 0.3355, 0.3674, 0.3757, 0.3843,\n                       0.4126, 0.2972, 0.3372, 0.3755, 0.7375, 0.3643, 0.3124, 0.4057, 0.3416,\n                       0.4374, 0.3502, 0.3933, 0.5019, 0.3495, 0.4261, 0.3219, 0.4806, 0.3907,\n                       0.3382, 0.2985, 0.3656, 0.4057, 0.2820, 0.3911, 0.3831, 0.3961, 0.3258,\n                       0.3556, 0.3884, 0.2842, 0.3880, 0.2877, 0.5134, 0.3658, 0.3813, 0.3526,\n                       0.2872, 0.4679, 0.4023, 0.3711, 0.3408, 0.3698, 0.3297, 0.3944, 0.4433,\n                       0.3643, 0.3618, 0.3808, 0.3125, 0.4070, 0.3152, 0.3701, 0.4213, 0.3231,\n                       0.3840, 0.3167, 0.2896, 0.3172, 0.3640, 0.3276, 0.3100, 0.4010, 0.2765,\n                       0.3437, 0.4174, 0.4213, 0.2916, 0.3564, 0.3844, 0.3485, 0.4497, 0.3450,\n                       0.3263, 0.3926, 0.4107, 0.3631, 0.3636, 0.4351, 0.3446, 0.3311, 0.3230,\n                       0.4142, 0.2625, 0.4656, 0.4833, 0.4500, 0.3889, 0.2816, 0.3845, 0.3208,\n                       0.4310, 0.3225, 0.3902, 0.3969, 0.4576, 0.3561, 0.3511, 0.4184, 0.3992,\n                       0.3472, 0.4130, 0.3421, 0.3410, 0.4082, 0.4113, 0.3172, 0.3930, 0.3991,\n                       0.2831, 0.4298, 0.3383, 0.3050, 0.3145, 0.3207, 0.3260, 0.3076, 0.3647,\n                       0.3477, 0.3524, 0.3519, 0.2905, 0.4231, 0.3461, 0.3708, 0.3950, 0.3207,\n                       0.3524, 0.3218, 0.3103, 0.3535, 0.3082, 0.3845, 0.3690, 0.3226, 0.4277,\n                       0.3864, 0.3158, 0.3056, 0.3905, 0.3562, 0.2987, 0.2645, 0.3923, 0.2770,\n                       0.3369, 0.3309, 0.3867, 0.4735, 0.2848, 0.4162, 0.3557, 0.3782, 0.3917,\n                       0.3549, 0.4271, 0.4573, 0.3284, 0.4414, 0.3416, 0.3338, 0.3760, 0.3200,\n                       0.3070, 0.3955, 0.4199, 0.2602, 0.3316, 0.4072, 0.3265, 0.4661, 0.3077,\n                       0.3495, 0.4407, 0.3838, 0.3684, 0.4074, 0.3581, 0.2789, 0.4350, 0.3104,\n                       0.3500, 0.3583, 0.3458, 0.3727, 0.3880, 0.2963, 0.3860, 0.3589, 0.3860,\n                       0.3083, 0.3621, 0.3372, 0.3721, 0.4110, 0.3552, 0.3846, 0.3868, 0.3788,\n                       0.3796, 0.3674, 0.3404, 0.3842, 0.3523, 0.3970, 0.2931, 0.3841, 0.3286,\n                       0.3248, 0.3132, 0.3067, 0.4588, 0.3715, 0.3722, 0.3652, 0.3831, 0.3168,\n                       0.3518, 0.3044, 0.3488, 0.2902, 0.3794, 0.3021, 0.3587, 0.3282, 0.3413,\n                       0.3202, 0.2898, 0.3917, 0.3515, 0.3811, 0.3077, 0.3070, 0.3411, 0.4298,\n                       0.3440, 0.3494, 0.3485, 0.3520, 0.3071, 0.2734, 0.3210, 0.4316, 0.3484,\n                       0.3786, 0.2805, 0.3631, 0.3585, 0.3444, 0.2726, 0.3513, 0.2803, 0.2806,\n                       0.4145, 0.3781, 0.3105, 0.4252, 0.3686, 0.3407, 0.3529, 0.3260, 0.3350,\n                       0.3934, 0.3162, 0.4039, 0.3262, 0.3350, 0.3493, 0.3198, 0.3623, 0.3624,\n                       0.2824, 0.3773, 0.3145, 0.3180, 0.3679, 0.3212, 0.3952, 0.4099, 0.3089,\n                       0.2674, 0.3381, 0.5038, 0.4137, 0.3256, 0.3629, 0.3811, 0.3769, 0.2880,\n                       0.3659, 0.4516, 0.4791, 0.4165, 0.2838, 0.2872, 0.4720, 0.3692, 0.3201,\n                       0.4284, 0.3061, 0.4227, 0.4786, 0.5674, 0.4388, 0.3238, 0.3707, 0.3120,\n                       0.2869, 0.3996, 0.4311, 0.3187, 0.3204, 0.3347, 0.3544, 0.3327, 0.3706,\n                       0.4129, 0.3351, 0.4309, 0.4395, 0.3306, 0.3729, 0.3518, 0.3636, 0.4126,\n                       0.3804, 0.3117, 0.3531, 0.4003, 0.4018, 0.3648, 0.4030, 0.3491, 0.3392,\n                       0.3777, 0.3895, 0.3898, 0.3377, 0.3052, 0.4200, 0.3361, 0.3560, 0.3184,\n                       0.3553, 0.3565, 0.3131, 0.3143, 0.3621, 0.3370, 0.3094, 0.3777, 0.4406,\n                       0.3890, 0.3399, 0.3351, 0.3146, 0.4741, 0.3881, 0.3114, 0.3023, 0.3455,\n                       0.2807, 0.3875, 0.3095, 0.4149, 0.4421, 0.3629, 0.3475, 0.3382, 0.4296,\n                       0.3259, 0.3590, 0.3500, 0.3153, 0.3942, 0.3169, 0.3720, 0.3433, 0.3106,\n                       0.3752, 0.3003, 0.4219, 0.4147, 0.3137, 0.3003, 0.3050, 0.4043, 0.3729,\n                       0.4007, 0.3716, 0.3790, 0.3835, 0.3335, 0.3323, 0.3772, 0.3429, 0.3991,\n                       0.4099, 0.4189, 0.4722, 0.4714, 0.3514, 0.2876, 0.3524, 0.3093, 0.2714,\n                       0.4296, 0.4387, 0.3550, 0.3834, 0.3927, 0.4937, 0.3974, 0.3182, 0.3301,\n                       0.3705, 0.3253, 0.3992, 0.3274, 0.3954, 0.3896, 0.3768, 0.4266])),\n              ('layer4.0.bn1.num_batches_tracked', tensor(13572)),\n              ('layer4.0.conv2.weight',\n               tensor([[[[ 0.0138,  0.0043,  0.0096],\n                         [ 0.0147, -0.0019,  0.0025],\n                         [ 0.0058, -0.0309, -0.0093]],\n               \n                        [[-0.0019, -0.0014, -0.0152],\n                         [-0.0182,  0.0234, -0.0006],\n                         [-0.0121,  0.0027, -0.0184]],\n               \n                        [[-0.0141,  0.0042, -0.0206],\n                         [-0.0112, -0.0140,  0.0101],\n                         [-0.0004, -0.0050,  0.0016]],\n               \n                        ...,\n               \n                        [[ 0.0022,  0.0058, -0.0093],\n                         [-0.0048,  0.0323,  0.0016],\n                         [-0.0098, -0.0015,  0.0179]],\n               \n                        [[-0.0066,  0.0079,  0.0061],\n                         [-0.0036, -0.0077,  0.0055],\n                         [-0.0064, -0.0132,  0.0055]],\n               \n                        [[ 0.0070, -0.0083,  0.0176],\n                         [ 0.0300, -0.0106,  0.0116],\n                         [ 0.0014, -0.0039, -0.0009]]],\n               \n               \n                       [[[ 0.0037, -0.0125,  0.0211],\n                         [ 0.0032,  0.0003, -0.0108],\n                         [ 0.0226, -0.0083, -0.0032]],\n               \n                        [[-0.0087, -0.0017, -0.0054],\n                         [ 0.0005,  0.0211, -0.0065],\n                         [ 0.0233, -0.0043,  0.0096]],\n               \n                        [[-0.0029, -0.0177, -0.0153],\n                         [-0.0172, -0.0179,  0.0029],\n                         [-0.0265, -0.0284, -0.0211]],\n               \n                        ...,\n               \n                        [[-0.0038, -0.0400, -0.0001],\n                         [ 0.0163, -0.0335, -0.0160],\n                         [-0.0088, -0.0142,  0.0042]],\n               \n                        [[ 0.0120, -0.0154, -0.0213],\n                         [ 0.0140, -0.0359,  0.0065],\n                         [-0.0028, -0.0064,  0.0153]],\n               \n                        [[-0.0064,  0.0138,  0.0095],\n                         [-0.0098, -0.0065,  0.0139],\n                         [ 0.0261,  0.0264,  0.0257]]],\n               \n               \n                       [[[ 0.0079, -0.0160, -0.0137],\n                         [ 0.0010, -0.0154,  0.0041],\n                         [-0.0080, -0.0079,  0.0131]],\n               \n                        [[-0.0309, -0.0106, -0.0056],\n                         [ 0.0104, -0.0139,  0.0026],\n                         [ 0.0214,  0.0152,  0.0020]],\n               \n                        [[ 0.0003,  0.0075, -0.0050],\n                         [-0.0001,  0.0004, -0.0164],\n                         [-0.0032, -0.0124, -0.0128]],\n               \n                        ...,\n               \n                        [[-0.0111,  0.0036, -0.0225],\n                         [ 0.0113, -0.0278, -0.0157],\n                         [-0.0103,  0.0125, -0.0082]],\n               \n                        [[-0.0112,  0.0306, -0.0115],\n                         [ 0.0313,  0.0363,  0.0127],\n                         [ 0.0279,  0.0105,  0.0021]],\n               \n                        [[-0.0330, -0.0109,  0.0072],\n                         [-0.0240, -0.0074,  0.0092],\n                         [ 0.0038,  0.0155, -0.0018]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0043,  0.0039,  0.0079],\n                         [-0.0268, -0.0029,  0.0048],\n                         [-0.0054,  0.0057, -0.0228]],\n               \n                        [[-0.0091, -0.0238, -0.0163],\n                         [-0.0027, -0.0067, -0.0090],\n                         [ 0.0038,  0.0023, -0.0250]],\n               \n                        [[-0.0056, -0.0204, -0.0286],\n                         [-0.0167, -0.0232, -0.0153],\n                         [-0.0024,  0.0122,  0.0096]],\n               \n                        ...,\n               \n                        [[-0.0003,  0.0101, -0.0216],\n                         [-0.0071,  0.0105,  0.0217],\n                         [ 0.0014,  0.0111, -0.0130]],\n               \n                        [[ 0.0120,  0.0078,  0.0109],\n                         [ 0.0138,  0.0148,  0.0241],\n                         [ 0.0124,  0.0030,  0.0252]],\n               \n                        [[ 0.0124,  0.0033, -0.0008],\n                         [ 0.0101,  0.0111,  0.0215],\n                         [ 0.0071,  0.0130,  0.0116]]],\n               \n               \n                       [[[-0.0105, -0.0093,  0.0090],\n                         [ 0.0070, -0.0072,  0.0160],\n                         [-0.0100,  0.0059, -0.0045]],\n               \n                        [[ 0.0023, -0.0010, -0.0275],\n                         [ 0.0111,  0.0062,  0.0165],\n                         [ 0.0037,  0.0308, -0.0288]],\n               \n                        [[ 0.0180,  0.0605,  0.0383],\n                         [ 0.0228,  0.0188,  0.0365],\n                         [ 0.0157,  0.0493,  0.0167]],\n               \n                        ...,\n               \n                        [[ 0.0011, -0.0071, -0.0062],\n                         [ 0.0148,  0.0103, -0.0117],\n                         [-0.0040,  0.0235,  0.0176]],\n               \n                        [[ 0.0218,  0.0068,  0.0077],\n                         [ 0.0024,  0.0073, -0.0091],\n                         [-0.0056, -0.0152, -0.0064]],\n               \n                        [[ 0.0045, -0.0221, -0.0034],\n                         [ 0.0104, -0.0152, -0.0039],\n                         [-0.0050, -0.0104,  0.0048]]],\n               \n               \n                       [[[ 0.0054,  0.0058,  0.0033],\n                         [ 0.0007,  0.0398, -0.0061],\n                         [-0.0168, -0.0150, -0.0082]],\n               \n                        [[-0.0204, -0.0073, -0.0116],\n                         [-0.0034,  0.0454,  0.0110],\n                         [ 0.0024,  0.0116,  0.0003]],\n               \n                        [[-0.0026, -0.0016, -0.0024],\n                         [ 0.0034, -0.0233, -0.0111],\n                         [ 0.0118, -0.0080,  0.0151]],\n               \n                        ...,\n               \n                        [[ 0.0028,  0.0133, -0.0265],\n                         [-0.0045, -0.0025, -0.0012],\n                         [ 0.0069, -0.0051,  0.0336]],\n               \n                        [[-0.0104,  0.0201, -0.0086],\n                         [ 0.0297, -0.0045, -0.0052],\n                         [ 0.0091,  0.0159, -0.0077]],\n               \n                        [[ 0.0070,  0.0042,  0.0138],\n                         [ 0.0069,  0.0080, -0.0152],\n                         [-0.0265, -0.0096, -0.0129]]]])),\n              ('layer4.0.bn2.weight',\n               tensor([0.9224, 0.9310, 0.9500, 0.9430, 1.0810, 1.0981, 1.0581, 1.0803, 0.9284,\n                       0.9222, 0.9833, 1.0440, 1.0463, 0.9117, 1.0118, 0.8917, 0.9660, 1.1027,\n                       1.0145, 0.9977, 1.0505, 0.9295, 0.9656, 0.9701, 1.0516, 1.0946, 0.9474,\n                       0.9844, 1.0293, 0.9389, 1.0280, 1.0614, 1.0615, 0.9899, 0.9158, 0.9694,\n                       1.0517, 0.9314, 0.9358, 0.9433, 1.0820, 1.0990, 1.0827, 0.9457, 1.0735,\n                       1.0644, 0.9640, 0.9653, 1.0947, 1.0248, 0.9773, 1.0970, 0.9277, 0.9086,\n                       0.9185, 1.0766, 0.9353, 1.0570, 0.9948, 0.9399, 0.9054, 1.0635, 0.9691,\n                       0.9824, 0.9865, 1.0343, 0.9820, 0.9378, 1.0074, 1.0919, 0.8845, 1.0190,\n                       0.9005, 0.9103, 1.0446, 0.8939, 1.0004, 0.9672, 1.0773, 1.0333, 1.0516,\n                       1.0118, 0.9308, 0.9598, 1.0602, 0.9741, 0.9678, 0.9831, 0.9787, 1.0613,\n                       1.0379, 0.9069, 1.1037, 0.9692, 1.0312, 0.9391, 0.9258, 0.9565, 1.0824,\n                       0.9579, 0.9872, 0.9649, 0.9700, 1.0117, 0.9382, 1.0318, 0.9683, 0.9446,\n                       1.0224, 0.9316, 1.0775, 1.0762, 0.9209, 0.9253, 1.0582, 1.0058, 0.9740,\n                       1.0320, 0.9166, 1.0330, 1.1226, 0.9211, 1.0297, 0.9991, 1.0520, 0.9247,\n                       1.0819, 0.9603, 0.9773, 1.0263, 1.0454, 0.9710, 1.0692, 1.0545, 0.9633,\n                       1.1035, 1.0648, 1.0320, 1.0688, 0.9398, 1.0350, 0.9460, 0.9361, 0.9088,\n                       0.9528, 0.8965, 0.9675, 1.0065, 0.9389, 1.0408, 0.9457, 1.1028, 1.0465,\n                       0.9291, 0.9216, 0.9453, 1.1235, 0.9701, 0.9082, 0.9969, 1.0582, 0.9652,\n                       0.9553, 0.9432, 0.9534, 1.0534, 1.0147, 1.0313, 1.0952, 1.0714, 1.0622,\n                       0.9236, 0.9650, 1.0045, 1.0430, 0.8991, 0.9208, 1.0287, 0.9936, 0.9205,\n                       0.9149, 0.9721, 0.9680, 0.9602, 0.9582, 1.0278, 0.9604, 0.9478, 1.0357,\n                       0.9150, 0.9628, 0.9743, 1.0209, 0.9337, 1.0154, 0.9069, 1.0162, 1.0352,\n                       1.0572, 1.0677, 1.0140, 1.0708, 1.0301, 0.9262, 0.8974, 0.9134, 1.0371,\n                       0.9205, 0.9316, 1.0590, 1.0396, 0.9205, 0.9407, 0.9608, 0.9815, 0.9980,\n                       1.0130, 0.8888, 0.9892, 1.0530, 0.9395, 0.9179, 0.9661, 0.9706, 0.9244,\n                       0.9204, 0.9692, 1.0423, 0.9667, 1.0953, 0.8999, 1.0325, 0.9703, 1.1017,\n                       1.0338, 0.9349, 0.9160, 1.0655, 0.9199, 0.9358, 1.0601, 1.1032, 1.0494,\n                       1.0063, 1.1008, 0.9627, 0.9870, 0.9050, 0.9841, 0.9783, 1.0705, 1.0374,\n                       1.0251, 0.9502, 0.9541, 0.9573, 0.9555, 0.9546, 0.9883, 1.0028, 0.9385,\n                       0.9460, 0.9221, 0.9776, 0.8873, 1.0518, 1.1003, 0.9423, 0.9178, 1.0058,\n                       1.0985, 0.9583, 0.9973, 1.0236, 0.9874, 1.0821, 1.0468, 1.0818, 0.9472,\n                       0.9060, 0.9457, 0.9580, 1.0398, 1.0219, 0.9943, 1.0466, 1.0834, 0.9155,\n                       0.9467, 0.9785, 1.0594, 0.9603, 1.0495, 0.9120, 1.0417, 0.9326, 0.9152,\n                       0.9775, 0.9695, 1.0342, 0.9413, 1.0090, 1.0544, 1.0858, 1.0873, 0.9256,\n                       0.9366, 0.9722, 0.9867, 0.9603, 1.0807, 1.0029, 0.9534, 0.9297, 0.9432,\n                       0.9242, 1.0549, 0.9151, 1.0793, 0.9416, 1.0787, 1.0080, 1.0523, 1.0728,\n                       0.9210, 1.0233, 1.0575, 0.9675, 1.0422, 1.0075, 0.9256, 0.9217, 0.9658,\n                       0.9482, 0.9646, 0.9392, 0.9350, 1.0513, 1.0431, 1.0848, 1.0027, 0.9222,\n                       0.9350, 1.0907, 0.9818, 0.9904, 0.9488, 0.9772, 1.0415, 1.0820, 0.9796,\n                       0.9248, 1.0811, 0.9675, 1.0184, 0.9205, 1.0320, 0.9293, 1.0615, 0.9544,\n                       0.9447, 0.9513, 1.0099, 0.9679, 0.9183, 0.9912, 1.0150, 1.0619, 1.0220,\n                       1.0732, 0.9799, 0.9414, 1.0001, 1.0840, 1.0260, 0.9596, 1.0496, 0.9986,\n                       1.0107, 0.9221, 1.0096, 0.9539, 0.9394, 0.9297, 0.9308, 0.9392, 1.0426,\n                       0.9102, 1.0328, 0.9295, 0.9137, 0.9333, 0.9485, 0.9679, 1.0384, 0.9419,\n                       0.9513, 0.9591, 0.9223, 1.0407, 0.9999, 1.0023, 1.0438, 0.9622, 1.0560,\n                       0.8919, 0.9607, 1.0009, 1.0820, 0.9989, 1.0072, 1.0339, 1.0358, 0.9355,\n                       0.9438, 0.9620, 0.9858, 0.9878, 0.9596, 0.9307, 0.9361, 1.0144, 1.0732,\n                       0.9274, 0.9695, 0.9482, 1.0538, 0.9671, 1.1098, 1.0665, 0.9385, 0.9027,\n                       1.0072, 0.9361, 0.9764, 1.0138, 1.0717, 1.0940, 0.9100, 1.0333, 1.0138,\n                       0.8998, 0.9265, 0.9001, 1.0776, 0.9328, 0.9204, 0.9195, 1.0478, 1.0121,\n                       0.8954, 1.0580, 1.0584, 0.9668, 0.9283, 1.0039, 1.0823, 1.0840, 0.9454,\n                       1.0115, 1.1087, 0.9911, 1.0209, 0.9177, 1.0564, 0.9324, 0.9386, 1.0528,\n                       0.9281, 0.9558, 1.0661, 1.1163, 1.0751, 1.0139, 1.0391, 0.9647, 0.9227,\n                       1.0384, 1.0591, 0.9887, 1.0630, 1.0624, 0.9246, 1.0695, 1.0774, 0.9295,\n                       1.0461, 1.0479, 0.9276, 0.9431, 1.0033, 0.9435, 0.9862, 1.0561, 0.9046,\n                       0.9873, 0.9139, 1.1026, 0.9311, 0.9380, 1.0573, 0.9251, 0.9161, 0.9976,\n                       1.1186, 1.0860, 1.0363, 0.9597, 0.9549, 1.0905, 0.9621, 1.0696])),\n              ('layer4.0.bn2.bias',\n               tensor([-1.3180e-01, -6.3026e-02, -2.4862e-03, -1.0772e-01,  5.2167e-02,\n                        8.6873e-02, -4.7114e-02, -2.9296e-03, -9.8838e-02, -1.6346e-01,\n                       -3.3195e-03,  1.4714e-02, -5.7710e-02, -1.8864e-01, -3.2051e-02,\n                       -1.4848e-01,  2.5865e-02,  7.2350e-02, -2.2081e-03,  2.3818e-02,\n                        1.3368e-02, -3.7283e-02, -2.4039e-02, -7.5541e-02, -3.8946e-03,\n                        3.0658e-02, -1.2260e-01, -1.6098e-02,  1.3970e-02, -7.5407e-03,\n                        1.0188e-02,  1.4977e-02,  8.2492e-02,  3.5699e-02, -1.8000e-01,\n                       -4.5892e-02, -4.6980e-03, -2.2408e-02, -1.0957e-01, -8.9279e-02,\n                        1.6964e-02,  7.6039e-02,  4.1847e-02, -2.1282e-02,  1.1344e-03,\n                        6.6351e-03, -3.2744e-02, -1.1978e-01,  4.7576e-02,  6.4782e-05,\n                       -3.6198e-02,  9.5419e-03, -1.0544e-01, -1.0873e-01, -1.5082e-01,\n                        2.3153e-02, -1.2757e-01, -1.2305e-02, -9.6640e-03, -9.7843e-02,\n                       -1.4710e-01,  1.5278e-02, -6.9265e-02, -3.6786e-02,  2.8720e-02,\n                        1.4403e-02, -4.9903e-03, -1.1392e-01, -1.1014e-02,  4.8172e-02,\n                       -7.3930e-02,  6.3226e-03, -1.3503e-01, -1.2342e-01,  4.1563e-02,\n                       -1.0183e-01, -5.2669e-02, -3.7267e-02, -1.4976e-02,  2.5277e-02,\n                        4.3048e-02,  3.6357e-02, -6.5561e-02, -4.6488e-02,  3.0226e-02,\n                       -3.3160e-02, -1.7584e-02, -7.0754e-02, -4.6863e-02,  3.0679e-02,\n                        2.4304e-02, -9.7921e-02,  5.3860e-02, -6.0464e-02,  2.4066e-02,\n                       -8.3907e-02, -1.6959e-01, -6.6043e-02,  7.7740e-02, -3.9702e-02,\n                       -1.0551e-02, -2.8717e-02, -3.5426e-02, -2.1142e-02, -6.6236e-02,\n                       -3.7337e-02, -2.8363e-02, -8.5424e-02,  1.4502e-02, -9.3918e-02,\n                        6.1799e-02,  7.9055e-02, -9.7147e-02, -5.1689e-02,  1.1370e-03,\n                        1.3540e-04, -8.1493e-02,  4.5552e-02, -1.0742e-01, -8.3743e-03,\n                        5.7982e-02, -9.2753e-02,  1.3923e-02, -3.7594e-02,  2.3920e-02,\n                       -6.4647e-02, -1.4854e-04, -1.3092e-01, -1.2197e-02,  1.2961e-02,\n                        2.8248e-02, -7.9477e-02,  1.8559e-02, -3.7287e-02, -3.5807e-02,\n                        5.5289e-02,  5.2829e-02,  2.2582e-02, -2.4748e-03, -2.4153e-02,\n                        7.1724e-02, -8.8336e-02, -7.0547e-02, -1.5929e-01, -3.2248e-02,\n                       -1.3291e-01, -4.6312e-02,  5.4491e-03, -6.7990e-02,  3.9180e-03,\n                       -3.2108e-02,  7.1652e-02,  4.2806e-02, -5.3463e-02, -1.1766e-01,\n                       -7.9059e-02,  8.1651e-02,  1.9708e-02, -9.1718e-02, -1.5072e-02,\n                        6.2099e-02, -5.6094e-02, -6.2571e-02, -1.0802e-01,  3.0480e-02,\n                        1.3232e-02,  3.3678e-02,  1.2926e-02,  2.6960e-02, -4.8258e-02,\n                        3.3259e-02, -2.4517e-02, -4.8093e-02,  4.3585e-02,  3.6943e-02,\n                       -1.0937e-01, -1.6671e-01, -9.6428e-03,  3.9505e-02, -9.0545e-02,\n                       -1.3657e-01, -3.2921e-02, -5.2867e-02, -4.9076e-02, -7.4129e-02,\n                       -1.8409e-02, -5.2550e-02, -3.5770e-02, -3.1743e-02, -9.7337e-02,\n                       -8.2844e-02, -1.2958e-02, -2.2722e-02, -8.3489e-02, -3.5596e-02,\n                       -1.5481e-01, -8.3241e-02,  2.5185e-02, -5.4820e-02,  4.1084e-02,\n                       -2.2041e-02,  2.0685e-02, -1.3193e-02, -1.0111e-01, -9.6320e-02,\n                       -1.0120e-01, -2.1151e-02, -7.5160e-02, -1.0961e-01,  8.7435e-03,\n                        3.7609e-04, -1.3875e-01, -4.9366e-02, -5.8266e-02, -4.0557e-02,\n                       -1.1647e-01,  2.1246e-03, -1.3850e-01, -5.0973e-02, -2.2449e-02,\n                       -7.4587e-02, -5.3319e-02, -3.8857e-02, -9.7173e-02, -1.7405e-01,\n                       -9.3251e-02, -3.1628e-03,  3.9436e-02, -9.2878e-02,  7.1549e-02,\n                       -5.2441e-02, -3.4799e-03, -1.2109e-01, -2.1862e-02,  3.1806e-03,\n                       -5.8682e-02, -7.2578e-02,  5.4645e-02, -3.4306e-02, -5.4044e-02,\n                        2.7802e-03,  9.3483e-02,  3.4178e-02,  1.9187e-02,  4.5891e-02,\n                       -1.0114e-01, -1.1117e-01, -1.6116e-01, -9.5689e-02, -1.2705e-02,\n                        6.2561e-02, -4.7540e-02,  2.3092e-04, -7.4579e-02, -4.8427e-02,\n                       -9.1225e-02, -9.4668e-02, -1.3902e-01,  3.4134e-02, -4.5591e-02,\n                       -1.7436e-01, -1.0831e-01, -7.1227e-02, -1.8028e-02, -9.0636e-02,\n                       -5.0656e-03,  4.1118e-02, -4.6368e-02, -1.0439e-01,  4.7750e-02,\n                        5.0863e-02, -1.1068e-01, -1.0097e-01, -1.5434e-02, -2.5675e-02,\n                        7.6670e-03,  2.6241e-02,  2.5147e-02, -1.6018e-02, -7.9260e-02,\n                       -6.3161e-02,  9.2728e-03, -1.2963e-03,  1.6054e-02,  1.3844e-03,\n                       -2.5224e-02,  6.7930e-02, -1.4085e-01, -2.2844e-02,  1.3767e-02,\n                       -2.9552e-02,  4.1390e-03,  3.2613e-02, -1.3473e-01,  5.5237e-04,\n                       -1.6858e-01, -1.0752e-01, -6.9349e-02, -7.6772e-02,  3.2411e-02,\n                       -3.4677e-02,  8.5620e-03,  6.2923e-02, -1.5150e-02,  3.3839e-02,\n                       -7.2213e-02, -1.1140e-01,  5.9175e-02, -2.0761e-02, -1.7793e-02,\n                        7.2285e-02,  7.4997e-03, -5.4687e-02, -8.7352e-02, -8.1926e-02,\n                       -9.8987e-02, -2.9315e-02, -1.1269e-01,  1.6973e-02, -7.9334e-02,\n                        1.2128e-02, -4.3824e-02,  2.2264e-02,  3.7472e-02, -7.0679e-02,\n                        5.3300e-03,  1.2527e-03, -1.2225e-02,  1.9416e-02,  2.3628e-02,\n                       -9.1411e-02, -1.8395e-02, -1.0935e-02, -9.6591e-02,  7.2956e-05,\n                       -4.0554e-02, -3.7034e-02,  2.4613e-02, -5.9841e-02,  7.1257e-02,\n                       -1.3607e-02, -8.3876e-02, -1.9931e-02,  2.3003e-02,  6.5709e-03,\n                       -1.3858e-02, -1.0110e-01, -3.4350e-02,  2.6870e-02, -1.3842e-02,\n                       -4.1175e-03, -1.1621e-01,  5.4820e-02, -4.2667e-02, -2.7439e-02,\n                       -7.8329e-02, -2.4778e-02, -8.2292e-02,  3.4098e-02, -1.4118e-01,\n                       -1.1727e-01, -3.7080e-02,  2.7895e-02, -3.1911e-02, -1.3241e-01,\n                       -3.5180e-02, -3.6762e-02,  1.9254e-02,  3.0608e-02,  2.0043e-02,\n                        3.0750e-02, -9.6087e-02, -1.9009e-02,  2.8519e-02, -2.6602e-02,\n                       -3.4184e-02,  1.9904e-02,  3.6632e-02, -7.4809e-03, -8.7395e-02,\n                       -6.9771e-03, -2.3451e-01, -7.1015e-02, -1.4130e-01, -1.9423e-02,\n                       -2.9337e-02,  4.6578e-02, -7.0898e-02,  4.8621e-02, -1.2047e-02,\n                       -1.0126e-01, -8.7647e-02, -7.3943e-02,  8.3590e-03,  2.5720e-02,\n                       -1.0788e-01, -4.6843e-02,  1.5011e-02, -7.4500e-02, -2.1216e-02,\n                        1.1565e-03,  1.2013e-02, -2.8500e-02, -3.5045e-02,  4.2535e-02,\n                       -1.1986e-01, -2.0755e-02,  8.2262e-03,  5.8527e-02, -1.6871e-02,\n                        2.7810e-02, -1.5214e-02,  3.9050e-02, -8.0509e-02, -9.6113e-02,\n                       -5.5825e-02, -1.0651e-01, -2.8707e-03, -7.1394e-02, -1.4014e-01,\n                       -7.8764e-02,  3.9012e-02,  7.4558e-02, -1.4553e-01, -3.6153e-02,\n                       -6.9101e-02, -6.4611e-04, -3.9913e-02,  4.5886e-02,  3.1696e-02,\n                       -1.0602e-01, -1.3986e-01, -9.3405e-03, -7.8246e-02, -7.7097e-02,\n                        3.8148e-02,  2.6094e-02,  8.8170e-03, -8.5509e-02, -2.1771e-02,\n                        3.0142e-02, -8.0031e-02, -7.2004e-02, -9.4140e-02,  1.2542e-02,\n                       -2.8026e-02, -6.3642e-02, -1.0509e-01,  1.8642e-02, -1.4687e-02,\n                       -1.3822e-01,  8.5211e-02,  2.5767e-02, -1.4901e-02, -8.0968e-02,\n                       -2.2296e-02,  1.6495e-02,  1.6832e-02, -4.2860e-02,  3.8836e-02,\n                        4.4062e-02, -9.5766e-02, -2.1241e-03, -1.4591e-01,  4.1173e-02,\n                       -1.5199e-01, -9.7097e-02,  3.8564e-02, -7.5349e-02, -1.3540e-01,\n                        2.3783e-02,  8.2730e-02,  3.3966e-02,  9.2262e-03, -2.8897e-02,\n                       -4.5393e-02, -8.1169e-02,  3.9813e-02, -8.8550e-03, -5.4672e-02,\n                       -1.2986e-04,  2.1607e-02, -1.5516e-01,  4.1045e-02,  3.0762e-02,\n                       -6.9798e-02,  1.7491e-02,  1.1828e-01, -9.4103e-02, -1.1677e-01,\n                       -1.7218e-02, -1.4900e-01, -8.6619e-02, -1.7683e-02, -1.5819e-01,\n                       -7.5421e-03, -8.1806e-02,  1.1907e-01, -6.5701e-02, -8.2256e-02,\n                        7.6612e-03, -1.0113e-01, -1.0111e-01,  4.0740e-04,  5.8037e-02,\n                        3.7931e-02,  2.1504e-02, -8.5633e-02, -3.8110e-02,  6.3805e-02,\n                       -9.5223e-02, -1.1002e-01])),\n              ('layer4.0.bn2.running_mean',\n               tensor([-0.4684, -0.3896, -0.0895, -0.1738,  0.0813, -0.3695, -0.8408, -0.6063,\n                       -0.2713, -0.3538, -0.5910, -0.1708, -0.2599, -0.2142, -0.1147, -0.4543,\n                       -0.4406,  0.4612, -0.3618, -0.1413, -0.9422,  0.0599, -0.6139,  0.2214,\n                        0.5916, -0.1578, -0.1167, -0.7371, -0.0528, -1.3595, -1.1473,  0.1420,\n                       -0.9460,  0.0363, -0.0306,  0.0887, -0.3706, -0.3288, -0.1843, -0.1547,\n                       -0.9268, -0.7920, -0.2077,  0.3383, -0.2009, -0.6543, -1.1122, -0.8491,\n                       -0.3443, -0.1262, -0.4149, -0.2484,  0.5000, -0.0805, -0.1457,  0.1214,\n                       -0.1133,  0.1586, -0.4267, -0.5774, -0.0873, -0.4261,  0.3885, -0.6096,\n                        0.2546, -0.5599, -0.2830, -0.5074, -0.7890,  0.1190, -0.2859, -0.7839,\n                        0.3433, -0.1857, -0.9977, -0.3238, -0.7256, -0.1388, -0.7102, -0.3816,\n                       -0.0052,  0.0438, -0.2646, -0.2266, -0.2809,  0.1462,  0.2399, -0.4451,\n                       -0.3367, -0.2147, -0.2635, -0.3584, -0.0648,  0.4315, -0.3297, -0.8858,\n                       -0.3738,  0.8366,  0.7044, -0.5684, -0.1731,  0.0337, -0.3041, -0.0249,\n                       -0.9679, -0.3794, -0.6661,  0.0732, -0.0046,  0.6141,  0.1738,  0.7423,\n                        0.0247, -0.2051, -0.4191, -0.4029, -0.5941, -0.7192, -0.9661,  0.5432,\n                       -0.0291, -0.0239, -0.1044, -0.4386, -0.1864, -0.1532, -0.2901, -0.0963,\n                       -0.5274, -0.4386, -0.2860, -0.6381, -0.2712,  0.1529,  0.5136, -0.6929,\n                       -0.2139, -0.4586, -0.4095, -0.7062, -0.4921, -0.6356, -0.5170, -0.0688,\n                       -0.3841, -0.1299, -0.3540, -0.0074, -0.0895, -0.0790, -0.7472, -0.2307,\n                       -0.8550, -0.7438, -0.3023,  0.8907, -0.2321,  0.0549, -0.1482, -0.1410,\n                       -0.4505, -0.2300, -0.6507, -0.4985, -0.8479, -0.6875, -0.4110, -0.3561,\n                       -1.2985, -0.4212, -0.1413, -0.2510,  0.1384,  0.3539, -0.8429, -0.3118,\n                       -0.1726, -0.2903, -0.3243,  0.2027, -0.0512,  0.1800, -0.5450,  0.4939,\n                       -0.9744,  0.3895, -0.0395,  0.2608, -0.4593,  0.2047, -0.0524, -0.7866,\n                       -0.1153,  0.1391, -0.5072,  0.4860, -0.9872, -0.1875, -0.1279, -0.5166,\n                        0.0070, -0.9085, -0.6873,  0.7120, -0.2500, -0.3157, -0.7923, -0.3177,\n                       -0.0084, -0.2786, -0.3072,  0.2640,  0.4822, -0.1905,  0.3584, -0.4444,\n                        0.1909, -0.6597, -0.2420, -0.1780,  0.2755, -0.1593, -0.4634, -0.2694,\n                       -0.2905, -0.7643, -0.1983, -0.0325, -0.5263, -0.2178, -0.2945,  0.0945,\n                       -0.4966, -0.6411, -0.1832, -0.5866,  0.1411, -0.4176,  0.5890, -0.3915,\n                       -0.6409, -0.0130, -0.5603, -0.9409, -0.0407, -0.5994,  0.1604, -0.4377,\n                       -0.1202,  0.2712, -0.8035,  0.0585, -0.9641, -0.2879, -0.3681, -0.6533,\n                        0.7488, -0.2196,  0.0878, -0.5793, -0.9263, -0.1570, -0.2097, -0.4458,\n                       -0.9144, -0.6896, -0.6097, -0.0732, -0.3709, -1.2270,  0.7170,  0.0075,\n                       -0.4872, -0.0831,  0.0041,  0.3830, -0.3045, -0.3664,  0.2769,  0.1568,\n                       -0.0827, -0.0615, -0.1794, -0.4848, -0.3332, -0.8426, -0.6276, -0.7658,\n                       -0.2363, -0.2065, -0.4605, -0.0284, -0.2358,  0.1381, -0.8545, -0.4185,\n                        0.2595,  0.1501, -0.0361, -0.6555, -0.3127, -0.0141, -0.0326, -0.6824,\n                       -0.3638,  0.6361, -0.1470, -0.0067, -0.0033, -0.4171, -0.2056, -0.7545,\n                       -0.3135,  0.0765, -0.6311, -0.2013,  0.0651, -0.3695, -0.0322, -0.5748,\n                       -0.4190, -1.1339,  0.3813,  0.4530, -0.4016, -0.3777,  0.1342, -0.4978,\n                       -0.3465, -0.8115, -0.9035,  0.3744, -0.2835, -0.1557, -0.4569, -0.0845,\n                       -0.1010,  0.0687,  0.2617, -0.4298,  0.1258, -0.1993, -0.2521,  0.2451,\n                       -0.2438, -0.1894, -0.6389, -0.0784,  0.5453, -0.6841, -0.6884, -0.3354,\n                        0.2549, -0.2161,  0.2219, -0.9409, -0.4659, -0.3317,  0.3804, -0.3867,\n                        0.2121,  0.3637, -0.5431, -0.3316, -0.5704, -0.6879,  0.2281, -0.3844,\n                       -0.2129, -0.2833, -0.2175, -0.5187, -0.6800, -0.5005, -0.1887, -0.7451,\n                       -0.2350, -0.8133, -0.4916, -0.1884, -0.2792, -0.1453, -0.6427,  0.1891,\n                       -0.1307, -0.0666,  0.3964,  0.1109,  0.5094, -0.0356, -0.2932, -0.4426,\n                       -1.1771, -0.4216, -0.3449, -0.2364, -0.3264, -0.4892, -0.4700,  0.0594,\n                       -0.2712, -0.1081, -0.0659, -0.5412, -0.0142, -0.5574, -0.1303,  0.0688,\n                        0.1955,  0.4493, -0.2404, -0.6394, -0.1000, -0.1385,  0.0721, -0.1726,\n                       -0.5765, -0.4169,  0.1430, -0.0821, -0.6796,  0.1627, -0.9920, -0.2202,\n                       -0.1369, -0.4573, -0.8653, -0.3980,  0.1118,  0.0564,  0.2993, -0.3937,\n                        0.5102, -0.1381, -0.3692, -0.4590,  0.2509, -0.1048, -0.2381, -0.5693,\n                        0.4011, -0.7755, -0.3405, -0.5711, -0.1124, -0.1696, -0.4289,  0.1936,\n                       -0.0090, -0.8368,  0.1388, -0.5344,  0.0117, -0.0269, -0.2234, -0.1501,\n                       -0.8337, -0.5560, -0.1590, -0.7416, -0.4470,  0.0998,  0.0402,  0.2651,\n                       -0.5076, -0.4993, -0.5672, -0.0335, -0.2992, -0.1381, -0.4148, -0.4783,\n                       -0.6001,  0.0277, -0.3855, -1.1761, -0.1523, -0.3945, -0.0830, -1.2349,\n                       -0.1543, -0.3688, -0.2638, -0.2355, -0.9098, -0.7802, -0.8234, -0.6942,\n                       -0.0844, -0.7959, -0.5183, -0.0546,  0.3201, -0.2412, -0.1577, -0.5136,\n                        0.0273, -1.4418, -1.3295,  0.3638, -0.6795, -0.4986, -0.4969, -0.6171,\n                       -0.2681, -0.3273, -0.2905, -0.1058,  0.0178, -0.0092,  0.4725, -0.1720])),\n              ('layer4.0.bn2.running_var',\n               tensor([0.6034, 0.5674, 0.7396, 0.5233, 0.7377, 0.6588, 0.7642, 0.7081, 0.7206,\n                       0.5795, 0.7278, 0.7188, 0.8428, 0.6254, 0.6586, 0.5838, 0.6713, 0.7624,\n                       0.7068, 0.7328, 0.7917, 0.6092, 0.6269, 0.7051, 0.8587, 0.8841, 0.5959,\n                       0.7718, 0.7333, 0.7799, 0.9407, 0.7720, 0.8087, 0.6928, 0.6678, 0.6750,\n                       0.6032, 0.5931, 0.6190, 0.5444, 0.9549, 0.9694, 0.7718, 0.5358, 0.8298,\n                       0.7430, 0.9624, 0.7352, 0.8436, 0.8360, 0.7092, 0.8563, 0.6403, 0.5347,\n                       0.7140, 0.8524, 0.6323, 0.8327, 0.8545, 0.5555, 0.5774, 0.7648, 0.5404,\n                       0.7170, 0.7905, 0.6627, 0.6112, 0.7811, 0.8402, 0.7816, 0.6464, 0.5379,\n                       0.6816, 0.6111, 0.7841, 0.8430, 0.7668, 0.6816, 0.8411, 0.7810, 0.7266,\n                       0.6417, 0.6264, 0.7610, 0.7782, 0.6255, 0.8055, 0.6680, 0.7261, 0.6943,\n                       0.7450, 0.6632, 0.7967, 0.6167, 0.9129, 0.6198, 0.6167, 0.6501, 1.0021,\n                       0.7236, 0.6195, 0.7319, 0.6650, 0.6261, 0.5627, 0.7065, 0.8997, 0.6869,\n                       0.8319, 0.6726, 0.8227, 0.9801, 0.6274, 0.6586, 0.8024, 0.5547, 0.6629,\n                       0.6984, 0.6953, 0.6989, 0.8358, 0.7085, 0.7911, 0.6719, 0.6557, 0.4900,\n                       0.7980, 0.6682, 0.6966, 0.7890, 0.7706, 0.5689, 0.7762, 0.7386, 0.6181,\n                       0.6529, 0.6849, 0.7340, 0.9643, 0.5744, 0.7442, 0.5710, 0.7707, 0.6896,\n                       0.7321, 0.5970, 0.6209, 0.7344, 0.7406, 0.6918, 0.5963, 0.7789, 0.7718,\n                       0.6959, 0.5543, 0.7257, 0.9644, 0.6527, 0.6073, 0.6253, 0.8154, 0.7584,\n                       0.5964, 0.7297, 0.7208, 0.7795, 0.6714, 0.7331, 0.8846, 0.9248, 0.8221,\n                       0.5576, 0.5754, 0.6828, 0.7422, 0.6787, 0.7166, 0.6665, 0.7673, 0.7189,\n                       0.6274, 0.6857, 0.8090, 0.7846, 0.6258, 0.8215, 0.6897, 0.5821, 0.8176,\n                       0.6298, 0.6906, 0.6898, 0.7329, 0.5913, 0.6513, 0.7335, 0.8220, 0.7788,\n                       1.0249, 0.7452, 0.7546, 0.7839, 0.6776, 0.7252, 0.6635, 0.6350, 0.7857,\n                       0.6755, 0.5915, 0.7007, 0.7991, 0.5739, 0.5636, 0.8113, 0.6645, 0.7837,\n                       0.6715, 0.5749, 0.5804, 0.7826, 0.7075, 0.7089, 0.6440, 0.6197, 0.6757,\n                       0.7102, 0.6305, 0.6953, 0.6469, 0.8201, 0.7808, 0.8162, 0.5521, 0.8875,\n                       0.7338, 0.6564, 0.6278, 0.6284, 0.6890, 0.6115, 0.8697, 0.8394, 0.8205,\n                       0.7297, 0.6570, 0.6277, 0.7859, 0.6402, 0.8910, 0.6869, 0.8338, 0.8421,\n                       0.7958, 0.6594, 0.6692, 0.6866, 0.6519, 0.5976, 0.5383, 0.7134, 0.7112,\n                       0.6207, 0.6155, 0.7956, 0.6227, 0.8638, 0.9196, 0.6279, 0.6440, 0.7487,\n                       0.7999, 0.7600, 0.7819, 0.6826, 0.7003, 0.8556, 0.6879, 0.7788, 0.5895,\n                       0.6304, 0.7979, 0.6566, 0.7302, 0.7821, 0.6173, 1.0131, 0.8249, 0.6544,\n                       0.6431, 0.6976, 0.6754, 0.8416, 0.7209, 0.6648, 0.8599, 0.7339, 0.6208,\n                       0.7162, 0.6496, 0.7971, 0.6579, 0.6495, 0.6868, 1.0607, 0.7425, 0.6080,\n                       0.7380, 0.6200, 0.7053, 0.6004, 0.7314, 0.7954, 0.8077, 0.7587, 0.6287,\n                       0.5711, 0.7121, 0.5521, 0.7568, 0.5849, 0.6471, 0.8455, 0.7059, 0.8589,\n                       0.5851, 0.8099, 0.7491, 0.7613, 0.7863, 0.6864, 0.7222, 0.5473, 0.6433,\n                       0.5719, 0.6366, 0.8765, 0.5844, 0.9355, 0.9310, 0.9729, 0.6175, 0.5203,\n                       0.5758, 0.7719, 0.9144, 0.6886, 0.7799, 0.6622, 0.8720, 0.9086, 0.6917,\n                       0.6896, 1.1093, 0.7097, 0.8356, 0.7451, 0.7562, 0.5976, 0.8283, 0.5863,\n                       0.6565, 0.7523, 0.8140, 0.6572, 0.6384, 0.7407, 0.6302, 0.8538, 0.7023,\n                       0.8538, 0.8419, 0.6088, 0.6301, 0.7484, 0.7431, 0.7118, 0.8090, 0.8539,\n                       0.6425, 0.5567, 0.7517, 0.7258, 0.5493, 0.7483, 0.5787, 0.6713, 0.7259,\n                       0.6752, 0.6846, 0.6687, 0.5951, 0.6283, 0.5716, 0.7085, 0.9770, 0.6927,\n                       0.5902, 0.6706, 0.5082, 0.7741, 0.7427, 0.6549, 0.7395, 0.7923, 0.7192,\n                       0.5542, 0.8048, 0.7467, 0.6524, 0.8515, 0.6885, 0.7565, 0.6939, 0.7090,\n                       0.6022, 0.6448, 0.7382, 0.6916, 0.6674, 0.6896, 0.6264, 0.6802, 0.8165,\n                       0.6885, 0.5917, 0.6543, 0.7502, 0.5954, 0.7282, 0.9077, 0.5283, 0.5895,\n                       0.7127, 0.6989, 0.6568, 0.6405, 0.6505, 0.9977, 0.5548, 0.8306, 0.6739,\n                       0.6641, 0.5164, 0.6099, 0.8178, 0.6424, 0.6469, 0.5629, 0.8277, 0.6712,\n                       0.6366, 0.7474, 0.7999, 0.7268, 0.6259, 0.8205, 0.9225, 0.9410, 0.4995,\n                       0.6944, 1.0354, 0.6757, 0.7637, 0.6846, 0.7559, 0.6725, 0.6357, 0.7727,\n                       0.5933, 0.5955, 0.6678, 0.7340, 0.8223, 0.6938, 0.7305, 0.6485, 0.7104,\n                       0.6562, 0.7604, 0.7308, 0.9580, 0.8295, 0.7354, 0.8373, 0.6759, 0.6270,\n                       0.7285, 0.8520, 0.5892, 0.6790, 0.9115, 0.5855, 0.7336, 0.7140, 0.5973,\n                       0.7410, 0.7161, 0.7651, 0.6478, 0.7299, 0.6879, 0.5670, 0.6051, 0.7215,\n                       0.7714, 0.8000, 0.6745, 0.8182, 0.6566, 0.9603, 0.7336, 1.0853])),\n              ('layer4.0.bn2.num_batches_tracked', tensor(13572)),\n              ('layer4.0.conv3.weight',\n               tensor([[[[ 0.0016]],\n               \n                        [[-0.0006]],\n               \n                        [[-0.0296]],\n               \n                        ...,\n               \n                        [[-0.0032]],\n               \n                        [[ 0.0159]],\n               \n                        [[ 0.0420]]],\n               \n               \n                       [[[-0.0074]],\n               \n                        [[-0.0235]],\n               \n                        [[ 0.0048]],\n               \n                        ...,\n               \n                        [[ 0.0260]],\n               \n                        [[-0.0122]],\n               \n                        [[-0.0243]]],\n               \n               \n                       [[[ 0.0217]],\n               \n                        [[-0.0008]],\n               \n                        [[-0.0092]],\n               \n                        ...,\n               \n                        [[-0.0244]],\n               \n                        [[-0.0175]],\n               \n                        [[ 0.0171]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0110]],\n               \n                        [[ 0.0102]],\n               \n                        [[ 0.0005]],\n               \n                        ...,\n               \n                        [[-0.0054]],\n               \n                        [[ 0.0198]],\n               \n                        [[ 0.0037]]],\n               \n               \n                       [[[-0.0320]],\n               \n                        [[-0.0012]],\n               \n                        [[-0.0058]],\n               \n                        ...,\n               \n                        [[-0.0025]],\n               \n                        [[ 0.0044]],\n               \n                        [[ 0.0162]]],\n               \n               \n                       [[[-0.0391]],\n               \n                        [[-0.0214]],\n               \n                        [[-0.0064]],\n               \n                        ...,\n               \n                        [[-0.0241]],\n               \n                        [[-0.0090]],\n               \n                        [[-0.0184]]]])),\n              ('layer4.0.bn3.weight',\n               tensor([-0.5130, -0.4336, -0.3311,  ...,  0.1812,  0.5220,  0.3542])),\n              ('layer4.0.bn3.bias',\n               tensor([ 0.1399,  0.1309,  0.1234,  ..., -0.0366,  0.1251,  0.0883])),\n              ('layer4.0.bn3.running_mean',\n               tensor([ 0.4507,  0.1312,  0.1505,  ...,  0.0181,  0.4026, -0.2054])),\n              ('layer4.0.bn3.running_var',\n               tensor([0.1147, 0.0624, 0.0631,  ..., 0.0456, 0.1040, 0.0929])),\n              ('layer4.0.bn3.num_batches_tracked', tensor(13572)),\n              ('layer4.0.downsample.0.weight',\n               tensor([[[[-0.0449]],\n               \n                        [[ 0.0308]],\n               \n                        [[ 0.0163]],\n               \n                        ...,\n               \n                        [[ 0.0309]],\n               \n                        [[ 0.0096]],\n               \n                        [[-0.0080]]],\n               \n               \n                       [[[-0.0386]],\n               \n                        [[ 0.0130]],\n               \n                        [[-0.0242]],\n               \n                        ...,\n               \n                        [[ 0.0771]],\n               \n                        [[ 0.0369]],\n               \n                        [[-0.0127]]],\n               \n               \n                       [[[ 0.0263]],\n               \n                        [[-0.0150]],\n               \n                        [[-0.0139]],\n               \n                        ...,\n               \n                        [[-0.0282]],\n               \n                        [[-0.0017]],\n               \n                        [[ 0.0296]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0309]],\n               \n                        [[ 0.0453]],\n               \n                        [[-0.0628]],\n               \n                        ...,\n               \n                        [[-0.0234]],\n               \n                        [[-0.0228]],\n               \n                        [[ 0.0104]]],\n               \n               \n                       [[[ 0.0030]],\n               \n                        [[-0.0266]],\n               \n                        [[-0.0031]],\n               \n                        ...,\n               \n                        [[-0.0012]],\n               \n                        [[ 0.0165]],\n               \n                        [[ 0.0297]]],\n               \n               \n                       [[[-0.0258]],\n               \n                        [[-0.0041]],\n               \n                        [[ 0.0101]],\n               \n                        ...,\n               \n                        [[ 0.0186]],\n               \n                        [[ 0.0149]],\n               \n                        [[-0.0051]]]])),\n              ('layer4.0.downsample.1.weight',\n               tensor([1.2134, 1.1840, 1.1481,  ..., 1.0081, 1.1948, 1.1379])),\n              ('layer4.0.downsample.1.bias',\n               tensor([ 0.1399,  0.1309,  0.1234,  ..., -0.0366,  0.1251,  0.0883])),\n              ('layer4.0.downsample.1.running_mean',\n               tensor([ 0.0990, -0.5518, -0.3815,  ..., -0.1655, -0.1616, -0.0921])),\n              ('layer4.0.downsample.1.running_var',\n               tensor([0.3765, 0.3135, 0.2636,  ..., 0.1612, 0.3420, 0.3002])),\n              ('layer4.0.downsample.1.num_batches_tracked', tensor(13572)),\n              ('layer4.1.conv1.weight',\n               tensor([[[[-0.0020]],\n               \n                        [[-0.0017]],\n               \n                        [[ 0.0327]],\n               \n                        ...,\n               \n                        [[-0.0252]],\n               \n                        [[-0.0327]],\n               \n                        [[ 0.0123]]],\n               \n               \n                       [[[ 0.0435]],\n               \n                        [[-0.0369]],\n               \n                        [[ 0.0087]],\n               \n                        ...,\n               \n                        [[-0.0201]],\n               \n                        [[ 0.0045]],\n               \n                        [[ 0.0227]]],\n               \n               \n                       [[[-0.0164]],\n               \n                        [[ 0.0130]],\n               \n                        [[ 0.0308]],\n               \n                        ...,\n               \n                        [[ 0.0268]],\n               \n                        [[ 0.0303]],\n               \n                        [[-0.0143]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0337]],\n               \n                        [[-0.0086]],\n               \n                        [[-0.0123]],\n               \n                        ...,\n               \n                        [[-0.0230]],\n               \n                        [[ 0.0168]],\n               \n                        [[-0.0273]]],\n               \n               \n                       [[[-0.0507]],\n               \n                        [[ 0.0099]],\n               \n                        [[ 0.0076]],\n               \n                        ...,\n               \n                        [[-0.0320]],\n               \n                        [[ 0.0334]],\n               \n                        [[-0.0005]]],\n               \n               \n                       [[[-0.0186]],\n               \n                        [[ 0.0123]],\n               \n                        [[-0.0636]],\n               \n                        ...,\n               \n                        [[-0.0042]],\n               \n                        [[ 0.0056]],\n               \n                        [[-0.0170]]]])),\n              ('layer4.1.bn1.weight',\n               tensor([1.0122, 1.0332, 1.0249, 0.9867, 1.0126, 1.0154, 0.9577, 0.9699, 0.9926,\n                       0.9937, 0.9808, 1.0107, 0.9646, 0.9791, 1.0338, 1.0023, 1.0141, 0.9952,\n                       0.9843, 0.9702, 0.9895, 0.9804, 1.0247, 1.0027, 0.9888, 1.0327, 0.9743,\n                       0.9973, 1.0467, 0.9976, 0.9838, 0.9650, 0.9854, 1.0060, 0.9555, 1.0350,\n                       0.9976, 0.9763, 0.9948, 0.9805, 1.0176, 1.0318, 1.0019, 0.9972, 0.9892,\n                       1.0075, 1.0036, 0.9782, 0.9765, 0.9720, 0.9707, 0.9737, 0.9940, 1.0026,\n                       0.9854, 1.0299, 0.9958, 0.9948, 1.0331, 0.9808, 0.9952, 0.9678, 1.0039,\n                       1.0171, 0.9591, 1.0199, 1.0057, 0.9950, 0.9983, 1.0333, 0.9934, 1.0191,\n                       0.9765, 1.0104, 0.9739, 1.0005, 0.9768, 0.9666, 0.9669, 0.9926, 1.0240,\n                       0.9787, 0.9704, 0.9901, 0.9943, 0.9653, 1.0120, 0.9917, 1.0368, 0.9880,\n                       0.9908, 1.0099, 0.9691, 0.9754, 1.0356, 0.9932, 1.0153, 0.9663, 1.0038,\n                       1.0109, 1.0132, 1.0136, 0.9730, 0.9936, 0.9681, 0.9758, 1.0010, 0.9675,\n                       1.0207, 1.0024, 0.9935, 0.9944, 0.9916, 1.0032, 1.0030, 0.9895, 1.0033,\n                       1.0006, 0.9494, 1.0039, 1.0011, 0.9727, 0.9878, 0.9985, 0.9655, 1.0018,\n                       0.9965, 0.9730, 1.0027, 0.9534, 0.9824, 0.9586, 0.9737, 0.9844, 0.9719,\n                       1.0247, 1.0548, 0.9901, 0.9917, 0.9775, 0.9795, 0.9869, 0.9823, 0.9787,\n                       0.9733, 0.9702, 0.9893, 0.9817, 0.9951, 0.9637, 0.9945, 0.9579, 0.9823,\n                       0.9847, 1.0155, 0.9853, 0.9855, 0.9654, 1.0014, 0.9837, 1.0047, 0.9586,\n                       1.0190, 0.9762, 1.0064, 1.0249, 1.0203, 0.9620, 1.0132, 0.9920, 0.9694,\n                       0.9908, 1.0442, 1.0299, 0.9585, 1.0151, 0.9609, 0.9713, 1.0007, 0.9991,\n                       0.9688, 0.9891, 1.0331, 0.9827, 1.0150, 0.9707, 1.0008, 0.9722, 1.0087,\n                       0.9906, 0.9605, 0.9998, 0.9982, 0.9977, 0.9861, 0.9597, 1.0350, 1.0363,\n                       0.9594, 0.9980, 0.9857, 1.0289, 1.0418, 0.9696, 1.0024, 1.0056, 1.0077,\n                       0.9646, 0.9960, 1.0075, 0.9936, 1.0042, 1.0411, 1.0479, 0.9767, 0.9492,\n                       1.0376, 0.9954, 0.9987, 1.0464, 0.9964, 0.9893, 0.9653, 0.9886, 0.9977,\n                       0.9671, 0.9928, 1.0022, 1.0053, 0.9965, 0.9820, 0.9479, 0.9783, 1.0548,\n                       0.9789, 0.9648, 0.9680, 0.9911, 1.0084, 0.9850, 0.9965, 0.9689, 0.9848,\n                       0.9808, 0.9905, 0.9889, 0.9496, 0.9885, 1.0032, 1.0153, 1.0061, 1.0045,\n                       1.0135, 0.9946, 0.9967, 0.9904, 0.9740, 0.9898, 0.9734, 0.9756, 0.9632,\n                       0.9859, 0.9674, 0.9694, 0.9988, 1.0352, 1.0135, 0.9597, 0.9803, 0.9858,\n                       1.0162, 1.0164, 1.0180, 0.9401, 0.9967, 1.0083, 0.9769, 0.9868, 0.9726,\n                       1.0016, 0.9610, 1.0173, 0.9872, 0.9591, 1.0017, 0.9849, 1.0211, 0.9664,\n                       0.9856, 1.0305, 0.9923, 1.0132, 0.9787, 0.9703, 0.9847, 0.9678, 1.0379,\n                       0.9758, 1.0231, 0.9894, 1.0195, 0.9865, 0.9904, 0.9553, 0.9830, 1.0436,\n                       1.0110, 0.9786, 0.9943, 0.9930, 0.9454, 0.9785, 1.0062, 0.9644, 1.0065,\n                       0.9885, 0.9890, 0.9713, 1.0008, 0.9763, 1.0012, 0.9770, 1.0267, 0.9805,\n                       0.9759, 0.9916, 0.9823, 1.0446, 0.9862, 1.0193, 0.9591, 0.9943, 0.9948,\n                       1.0105, 0.9797, 0.9801, 0.9959, 0.9911, 1.0069, 0.9949, 0.9628, 1.0092,\n                       1.0081, 0.9757, 0.9957, 0.9561, 0.9642, 1.0145, 0.9886, 1.0166, 0.9950,\n                       0.9681, 0.9660, 0.9857, 1.0359, 0.9814, 0.9990, 0.9867, 1.0059, 1.0273,\n                       0.9958, 1.0384, 0.9973, 1.0047, 0.9774, 0.9898, 1.0197, 0.9701, 1.0091,\n                       1.0136, 0.9790, 1.0439, 0.9968, 0.9792, 1.0013, 1.0255, 1.0289, 1.0269,\n                       0.9895, 1.0149, 0.9626, 1.0317, 0.9811, 0.9820, 0.9539, 0.9809, 1.0019,\n                       0.9852, 0.9666, 0.9762, 0.9949, 0.9878, 0.9790, 0.9519, 0.9750, 0.9497,\n                       1.0239, 1.0201, 0.9947, 1.0447, 0.9679, 0.9937, 0.9667, 0.9880, 0.9583,\n                       0.9854, 0.9740, 0.9964, 0.9813, 0.9525, 0.9883, 0.9964, 0.9801, 1.0340,\n                       0.9758, 0.9927, 0.9546, 0.9986, 0.9511, 1.0052, 1.0095, 0.9519, 1.0047,\n                       0.9503, 0.9916, 0.9983, 0.9883, 0.9838, 0.9823, 1.0076, 0.9763, 1.0042,\n                       0.9667, 0.9795, 0.9786, 0.9982, 0.9946, 0.9889, 0.9465, 1.0021, 1.0142,\n                       1.0251, 1.0141, 0.9911, 0.9775, 1.0100, 0.9912, 1.0241, 0.9647, 1.0040,\n                       1.0267, 0.9500, 0.9910, 0.9821, 0.9852, 0.9754, 1.0168, 1.0153, 1.0277,\n                       0.9846, 0.9442, 0.9742, 0.9926, 0.9709, 0.9693, 0.9481, 1.0077, 0.9956,\n                       0.9638, 0.9680, 0.9912, 0.9614, 1.0234, 0.9955, 0.9875, 0.9933, 0.9810,\n                       0.9941, 0.9857, 0.9748, 0.9709, 1.0042, 0.9561, 1.0211, 0.9469, 1.0056,\n                       0.9837, 1.0420, 0.9847, 0.9986, 1.0073, 1.0416, 0.9733, 1.0034, 0.9471,\n                       0.9947, 1.0111, 0.9903, 0.9471, 0.9993, 1.0080, 0.9964, 0.9797, 1.0056,\n                       1.0040, 0.9806, 0.9866, 0.9944, 0.9826, 0.9852, 0.9824, 1.0112])),\n              ('layer4.1.bn1.bias',\n               tensor([-0.1550, -0.1133, -0.1237, -0.2309, -0.1878, -0.1125, -0.0633, -0.1645,\n                       -0.0679, -0.1127, -0.1118, -0.1346, -0.1080, -0.1319, -0.1242, -0.0743,\n                       -0.0876, -0.1090, -0.1369, -0.1331, -0.1422, -0.1137, -0.1554, -0.1199,\n                       -0.1443, -0.0737, -0.1305, -0.0983, -0.1412, -0.1439, -0.1358, -0.1387,\n                       -0.0706, -0.0905, -0.1516, -0.2186, -0.1046, -0.0880, -0.1494, -0.1796,\n                       -0.1087, -0.1180, -0.0660, -0.1520, -0.1482, -0.0930, -0.1145, -0.1534,\n                       -0.1055, -0.1329, -0.1317, -0.0717, -0.1307, -0.0691, -0.1618, -0.2370,\n                       -0.1004, -0.1366, -0.2096, -0.1390, -0.1249, -0.1122, -0.1441, -0.1015,\n                       -0.1522, -0.1363, -0.1042, -0.0695, -0.1259, -0.1025, -0.0858, -0.1434,\n                       -0.0936, -0.1400, -0.0998, -0.0870, -0.0855, -0.1078, -0.1061, -0.1646,\n                       -0.0877, -0.1240, -0.1496, -0.1010, -0.1356, -0.1002, -0.1716, -0.0731,\n                       -0.1343, -0.1671, -0.1295, -0.0560, -0.1354, -0.0863, -0.0928, -0.1201,\n                       -0.1318, -0.1341, -0.0951, -0.1453, -0.1665, -0.1520, -0.1471, -0.0917,\n                       -0.1098, -0.0998, -0.0948, -0.1059, -0.0910, -0.1500, -0.1898, -0.0987,\n                       -0.0887, -0.1038, -0.0930, -0.1032, -0.1198, -0.1526, -0.1158, -0.1565,\n                       -0.0719, -0.1057, -0.1276, -0.0733, -0.1007, -0.0759, -0.0943, -0.1225,\n                       -0.1263, -0.2663, -0.1483, -0.1064, -0.1077, -0.1551, -0.0947, -0.0921,\n                       -0.0836, -0.1003, -0.0949, -0.1229, -0.0737, -0.1327, -0.0737, -0.0524,\n                       -0.1081, -0.0833, -0.1069, -0.1413, -0.1252, -0.1161, -0.0738, -0.1766,\n                       -0.1202, -0.2008, -0.1361, -0.0891, -0.1391, -0.0697, -0.1716, -0.1344,\n                       -0.0660, -0.1254, -0.1524, -0.1617, -0.1527, -0.1148, -0.1993, -0.1111,\n                       -0.1558, -0.1243, -0.1651, -0.1299, -0.0993, -0.2320, -0.1265, -0.1158,\n                       -0.1746, -0.1375, -0.2158, -0.1726, -0.1292, -0.1008, -0.1062, -0.1027,\n                       -0.0769, -0.1438, -0.1088, -0.0816, -0.1579, -0.0993, -0.1781, -0.1214,\n                       -0.0758, -0.2019, -0.1542, -0.0645, -0.0942, -0.2169, -0.1033, -0.1443,\n                       -0.1719, -0.1502, -0.0875, -0.1115, -0.0803, -0.0965, -0.0985, -0.0845,\n                       -0.0948, -0.0790, -0.1689, -0.1154, -0.0937, -0.1824, -0.1258, -0.1388,\n                       -0.0807, -0.1537, -0.0931, -0.1285, -0.1214, -0.1478, -0.0829, -0.1222,\n                       -0.1472, -0.0700, -0.0697, -0.1026, -0.0698, -0.0404, -0.1235, -0.0944,\n                       -0.1265, -0.0881, -0.0964, -0.0611, -0.1924, -0.0912, -0.0954, -0.1448,\n                       -0.1372, -0.1205, -0.1405, -0.1612, -0.1321, -0.2437, -0.0964, -0.0969,\n                       -0.1520, -0.1936, -0.1294, -0.1574, -0.0973, -0.1093, -0.1204, -0.1469,\n                       -0.1252, -0.1511, -0.1062, -0.1075, -0.1043, -0.0721, -0.0888, -0.1244,\n                       -0.1228, -0.1177, -0.1487, -0.1322, -0.1161, -0.0703, -0.1428, -0.1098,\n                       -0.0711, -0.0629, -0.1023, -0.0849, -0.1421, -0.1569, -0.1312, -0.1159,\n                       -0.1112, -0.0867, -0.0620, -0.1283, -0.0927, -0.1102, -0.1527, -0.0877,\n                       -0.1228, -0.1151, -0.0971, -0.0890, -0.1220, -0.0809, -0.1140, -0.1946,\n                       -0.1176, -0.0916, -0.0842, -0.1112, -0.0879, -0.1016, -0.0612, -0.0418,\n                       -0.0970, -0.0984, -0.1217, -0.1248, -0.2478, -0.0925, -0.1185, -0.1020,\n                       -0.1493, -0.1340, -0.2361, -0.0817, -0.0746, -0.1189, -0.1721, -0.1869,\n                       -0.1002, -0.1489, -0.2091, -0.0886, -0.1644, -0.1164, -0.1251, -0.0627,\n                       -0.1197, -0.1581, -0.1071, -0.0892, -0.1194, -0.1476, -0.1758, -0.1539,\n                       -0.1399, -0.1675, -0.1197, -0.1617, -0.1064, -0.1321, -0.1330, -0.1115,\n                       -0.1183, -0.1109, -0.0765, -0.0818, -0.1423, -0.1358, -0.1202, -0.0992,\n                       -0.1012, -0.1068, -0.0818, -0.0991, -0.0731, -0.1562, -0.1257, -0.0924,\n                       -0.1075, -0.1501, -0.0824, -0.1435, -0.0637, -0.1675, -0.1973, -0.1314,\n                       -0.0928, -0.1303, -0.1171, -0.1220, -0.1434, -0.1754, -0.0827, -0.1493,\n                       -0.0620, -0.0667, -0.1014, -0.1235, -0.1144, -0.1005, -0.1101, -0.1133,\n                       -0.1390, -0.1208, -0.1449, -0.1184, -0.1118, -0.1359, -0.1212, -0.0563,\n                       -0.1471, -0.1167, -0.1096, -0.1188, -0.1395, -0.1250, -0.1057, -0.2136,\n                       -0.1755, -0.1231, -0.1266, -0.1042, -0.1226, -0.1172, -0.1037, -0.1181,\n                       -0.0644, -0.1588, -0.1217, -0.1521, -0.0820, -0.0662, -0.1295, -0.1049,\n                       -0.0918, -0.1319, -0.1790, -0.1085, -0.1153, -0.0791, -0.1003, -0.1086,\n                       -0.1091, -0.1187, -0.1715, -0.1171, -0.0797, -0.1601, -0.1317, -0.1183,\n                       -0.1061, -0.0974, -0.1049, -0.0646, -0.0748, -0.1489, -0.1577, -0.1137,\n                       -0.1229, -0.0978, -0.2020, -0.0779, -0.0914, -0.0748, -0.1230, -0.1393,\n                       -0.0966, -0.1040, -0.0807, -0.1374, -0.0455, -0.1183, -0.0975, -0.1219,\n                       -0.1076, -0.1314, -0.1504, -0.0738, -0.1133, -0.1320, -0.1274, -0.1279,\n                       -0.1258, -0.1247, -0.1364, -0.0816, -0.1673, -0.1062, -0.1120, -0.0944,\n                       -0.0904, -0.0956, -0.1716, -0.1773, -0.1027, -0.1263, -0.1463, -0.1424,\n                       -0.1392, -0.1318, -0.1442, -0.0533, -0.0868, -0.1363, -0.2080, -0.0977,\n                       -0.0978, -0.1220, -0.0604, -0.2164, -0.1060, -0.0825, -0.0728, -0.1645,\n                       -0.0933, -0.1160, -0.0476, -0.1195, -0.1325, -0.1261, -0.0687, -0.0772,\n                       -0.1426, -0.1242, -0.1384, -0.1285, -0.1177, -0.0778, -0.1316, -0.0794])),\n              ('layer4.1.bn1.running_mean',\n               tensor([ 2.8818e+00,  1.7277e+00,  4.5258e+00, -1.3894e+00, -1.1246e+00,\n                        2.1978e+00, -5.2861e+00,  1.5618e+00,  2.0745e+00, -1.4199e+00,\n                        9.7302e-01,  2.6489e-01,  1.2721e+00,  1.5658e+00,  5.1907e+00,\n                       -2.7764e+00,  3.8211e+00,  4.4649e+00,  6.0077e-01,  3.2695e-01,\n                       -2.6284e+00,  5.0748e+00,  3.2894e+00,  3.4636e+00,  1.3814e+00,\n                        1.3880e+00,  1.5896e+00,  1.1528e+00,  3.6005e+00,  2.3913e+00,\n                       -1.1122e+00, -6.5539e-01,  2.5101e+00,  2.7701e+00,  3.2795e+00,\n                       -1.9074e+00, -9.6621e-01,  6.1020e+00, -9.8672e-01, -1.2339e+00,\n                        3.4464e+00, -7.1410e-01, -4.0494e+00,  2.1502e+00,  1.7333e+00,\n                       -4.5001e+00,  7.9197e-01,  4.6114e+00,  1.3086e+00, -1.7532e+00,\n                       -1.4797e-01, -3.2930e+00, -1.1949e-01,  7.6614e-01, -1.2058e+00,\n                        3.2223e+00,  3.6947e+00,  1.8189e+00,  8.9711e-01,  2.2533e+00,\n                        3.0685e+00, -3.1304e+00,  1.3481e+00,  6.5398e-02,  1.1368e-01,\n                        1.3500e+00,  3.1324e+00,  1.1529e+00, -4.7850e-02,  6.9860e-01,\n                       -2.3673e-01,  3.9034e+00,  3.6451e+00,  3.6883e+00,  9.7886e-01,\n                        1.5691e+00, -2.7789e+00, -2.3181e+00,  4.0412e+00, -1.1320e-01,\n                        2.6915e+00,  7.3242e-01, -9.6931e-01,  1.6769e+00,  8.1236e-01,\n                       -7.3010e-01,  3.0297e+00,  1.0995e+00, -1.0141e-02,  2.6812e+00,\n                        3.4991e+00,  5.2964e+00, -4.2576e-01, -1.4074e+00, -3.3974e+00,\n                       -1.3614e+00,  3.3166e+00,  4.5390e+00,  1.4222e+00,  1.5900e+00,\n                        9.7611e-01,  3.6609e+00,  3.9711e-01, -8.9804e-01,  9.3646e-01,\n                        2.0817e+00,  3.2683e+00, -1.4755e+00, -3.0301e-01,  1.2677e+00,\n                       -1.8079e-03,  2.6067e+00,  3.0950e+00,  9.8196e-01,  3.7822e+00,\n                        9.9467e-01,  3.6143e-01,  9.0529e-01,  2.4315e+00,  1.4872e+00,\n                        7.3112e+00,  1.2163e+00, -1.1898e+00,  2.5411e+00, -7.3092e-01,\n                        1.5156e+00, -5.8796e-01,  2.3795e+00,  1.3041e+00, -1.5532e+00,\n                        3.5214e-01,  4.6207e+00,  1.9835e-04,  2.8516e+00,  5.6284e+00,\n                       -6.1308e-02,  9.7937e-02, -1.1642e+00,  9.7913e-01,  4.7211e+00,\n                       -2.3599e+00,  2.6201e+00,  2.4291e+00, -1.0355e-02, -2.0113e+00,\n                       -9.0233e-01,  9.6909e-01,  2.4652e+00,  2.5914e+00, -2.3650e-01,\n                        4.0591e+00,  1.5981e+00,  6.8740e-02,  3.9908e+00, -4.0897e-02,\n                       -4.9690e+00,  9.6125e-02,  5.9537e-01, -9.0721e-02, -1.4044e+00,\n                        2.1835e+00,  3.1948e+00,  5.2604e-02,  2.4843e-01,  3.7526e-01,\n                       -3.8972e+00,  1.4725e+00, -3.9551e-02,  5.1740e+00,  7.0930e-01,\n                       -1.5719e+00, -6.4681e-01,  1.3108e-01, -1.1761e+00, -4.9227e-01,\n                        7.5459e+00,  2.0579e+00,  1.5615e+00,  1.6616e-01,  6.0462e-01,\n                        3.0173e+00, -9.2410e-01,  3.2884e+00,  4.3782e+00,  4.1728e+00,\n                        2.9840e+00,  2.4194e+00,  4.6090e-01,  1.0321e+00,  5.1964e-01,\n                       -6.3142e-01, -5.1162e+00,  3.6954e+00, -1.2989e+00,  5.2203e-01,\n                       -7.1283e+00,  1.8030e+00, -8.1395e-01,  1.9019e+00,  1.1071e+00,\n                        2.3072e+00,  5.0408e-02, -1.5450e+00,  2.6728e+00,  2.3182e+00,\n                        1.4374e-01, -6.9988e-01, -6.0850e+00,  1.7435e+00,  4.9599e+00,\n                       -3.4691e-01,  1.9396e-02, -1.8907e+00, -3.3904e+00,  4.0326e+00,\n                        9.4577e-01, -1.6433e+00,  1.9497e+00, -4.0348e-01, -8.8728e-02,\n                        6.9270e-01,  9.3424e-01, -5.1038e+00,  1.3278e+00,  1.9258e-01,\n                       -1.4628e+00, -6.1752e-01,  3.0122e+00,  1.7055e+00,  1.9968e+00,\n                        1.7986e+00, -4.1094e+00,  3.8721e+00,  1.0686e+00, -1.1376e+00,\n                        1.0231e+00, -3.3094e-01, -1.2304e+00,  1.2748e+00, -1.4338e+00,\n                        2.6636e+00,  3.8818e+00, -2.4735e-01,  4.8484e+00, -1.1722e+00,\n                        8.6315e-01,  4.4454e+00,  3.7505e+00,  2.7154e+00, -6.9107e-02,\n                        3.0884e+00,  1.1558e+00,  1.4276e+00,  2.4881e+00, -4.4871e-01,\n                       -1.0779e+00, -2.3327e+00,  2.6752e+00,  2.4885e+00, -1.6521e+00,\n                       -1.3637e+00,  5.1695e-01,  2.9286e+00,  2.3644e-01,  7.7789e-01,\n                        2.0275e+00,  5.3936e+00,  1.8501e+00,  3.4704e-01,  7.4705e+00,\n                        2.3235e+00,  5.7985e+00, -1.4942e+00, -4.8053e+00, -3.4483e+00,\n                        1.9728e+00, -1.1297e+00,  8.5345e-01, -5.6481e-01,  5.0812e-01,\n                       -2.1730e+00,  1.7518e-01,  3.2398e+00, -5.3915e-01,  2.3326e+00,\n                       -9.6270e-01, -1.9965e+00, -3.0821e+00,  4.0629e+00,  1.0205e+00,\n                       -8.9264e-01,  4.5743e-01,  3.4524e+00,  2.5316e+00,  3.9402e+00,\n                        1.4049e+00, -8.5858e-01,  1.1917e+00,  1.1404e+00,  6.6518e+00,\n                        3.4854e+00,  1.7380e+00, -1.1303e+00, -8.2550e+00,  4.8627e+00,\n                        6.9505e-01,  1.2189e+00,  8.2078e-01, -8.6576e-01, -2.1093e+00,\n                        1.8248e+00,  8.0733e-01,  1.1007e+00,  3.0104e+00, -4.1222e+00,\n                        1.4483e+00,  3.3607e+00, -2.1725e+00, -2.0472e-02,  2.1779e+00,\n                       -6.9754e-01, -8.3924e-01, -1.8235e+00,  2.9493e+00,  2.7160e-01,\n                       -1.8865e+00,  2.1209e+00, -1.3923e+00,  1.6807e+00,  1.7226e+00,\n                        2.6403e+00, -1.0003e+00,  3.1792e+00,  2.1604e+00,  2.6752e+00,\n                        2.3018e+00,  3.8437e+00,  1.9683e+00,  1.5880e+00,  2.6324e+00,\n                        2.9152e+00,  3.2207e+00,  3.2633e+00,  1.0590e+00,  2.6371e+00,\n                        1.2461e+00,  2.9521e+00, -1.1444e+00, -1.7820e+00,  2.1935e+00,\n                        8.5417e-01,  4.1762e+00,  4.4830e+00,  5.4462e+00, -1.2780e+00,\n                       -1.1948e+00, -2.6835e-01,  1.1339e+00,  2.0452e+00,  1.3205e+00,\n                        1.1548e+00,  1.9157e+00, -2.2267e+00,  2.6175e+00, -4.8470e+00,\n                       -6.9345e-01, -6.8612e-01,  4.2857e-01, -1.4165e+00,  3.6970e+00,\n                        1.8005e+00,  3.6932e+00, -9.0449e-01,  1.6399e-01, -1.8994e+00,\n                       -9.8818e-01,  5.2106e+00, -3.7102e+00,  4.2519e+00,  2.7274e+00,\n                        1.8557e+00,  7.4464e-02, -2.7283e+00,  1.7233e-01,  1.8176e+00,\n                        2.6717e+00,  1.9499e-01, -1.6566e+00,  3.1329e+00, -1.2777e+00,\n                       -1.0357e+00, -2.4462e+00, -1.6926e+00,  1.4297e+00, -2.3461e+00,\n                        1.0480e+00,  1.6648e+00,  1.9347e+00, -8.5025e-01,  1.3384e+00,\n                       -5.4414e-01, -1.1852e+00, -9.0447e-01,  3.1876e+00,  1.0331e+00,\n                        4.5195e-01,  5.2870e+00,  2.7542e+00,  6.4755e+00, -5.2279e-01,\n                        1.3523e+00,  3.3756e+00,  6.3852e-01,  1.0637e+00,  9.1320e-01,\n                        3.8054e+00,  6.7967e-01, -2.4316e-01, -8.9715e-01,  2.8858e+00,\n                        2.2513e-01,  2.4604e+00, -1.2165e-01, -5.6758e-01,  1.5452e+00,\n                        2.3966e+00,  2.6103e+00,  1.4122e+00,  5.9477e-01, -1.5874e+00,\n                       -2.8538e-01,  1.8892e+00, -2.2253e+00,  1.8901e+00,  1.6856e+00,\n                        3.6778e+00, -3.9255e-01,  4.6182e-01,  2.6063e+00,  1.1747e-01,\n                        2.7567e+00,  1.0458e+00,  8.4757e-01,  4.5545e+00,  1.1959e+00,\n                        4.3450e+00,  2.3746e+00,  6.9679e-01,  3.4090e+00,  3.4710e+00,\n                       -1.4298e+00,  1.5051e+00, -7.2985e+00,  2.1963e+00,  4.0863e-01,\n                       -1.9566e+00,  2.3951e+00,  7.2973e-01,  2.3031e+00, -1.2612e+00,\n                       -4.4985e-01,  3.1629e+00,  2.5566e+00,  4.1165e+00, -6.7183e-01,\n                        1.6440e+00,  3.9279e-02, -1.3090e+00, -4.1020e+00,  2.2253e-01,\n                        1.8705e+00,  2.4259e-01, -2.3643e+00,  3.9214e+00, -2.7285e-01,\n                       -4.2416e-01,  3.7646e+00,  4.9353e-01,  1.3071e+00,  8.9490e-01,\n                       -4.9491e-01,  1.8894e+00, -2.4963e+00, -1.0530e+00,  3.0521e+00,\n                        4.0818e+00,  4.2344e+00,  2.2093e+00,  3.9701e+00,  1.7040e+00,\n                       -9.1679e-02, -1.0605e+00,  8.9822e+00, -3.6221e-01, -7.0491e+00,\n                        2.6000e+00,  5.9206e+00, -4.8880e+00, -2.3251e+00,  1.4602e+00,\n                        1.5491e+00,  2.8135e+00, -1.8144e+00,  4.9669e+00,  3.8428e+00,\n                        3.0684e+00, -4.8017e-01,  2.2691e+00,  2.9885e+00,  5.4732e+00,\n                       -3.2533e+00,  3.4484e+00])),\n              ('layer4.1.bn1.running_var',\n               tensor([2.3281, 2.7142, 2.3528, 3.9813, 4.6469, 2.0636, 2.3869, 2.0031, 2.3903,\n                       2.6038, 2.3390, 2.6669, 2.6233, 2.8687, 2.3947, 3.3925, 3.5600, 2.4921,\n                       3.0850, 2.5308, 3.3118, 2.3980, 2.3337, 2.2988, 2.4463, 2.2661, 2.0323,\n                       2.4192, 2.4913, 3.1674, 3.4621, 2.3173, 2.4441, 2.1601, 2.4432, 2.6042,\n                       2.7006, 2.3528, 2.4125, 2.8051, 1.8900, 2.0140, 2.1113, 2.6251, 2.3582,\n                       3.0560, 1.9668, 2.9607, 2.3436, 2.3702, 2.2543, 2.0332, 2.7952, 2.6285,\n                       2.8670, 2.8687, 2.2488, 2.7085, 3.3494, 2.2573, 2.4445, 2.5088, 2.1657,\n                       2.2682, 2.3318, 2.3472, 2.8413, 2.2762, 2.6872, 2.4722, 2.7564, 2.3540,\n                       2.2854, 2.0296, 2.3784, 2.5295, 2.6885, 1.8730, 3.3206, 2.7070, 2.5460,\n                       1.9366, 2.3413, 2.2519, 2.4330, 2.1319, 2.8190, 2.0813, 2.5326, 2.4039,\n                       2.4911, 3.0785, 2.5278, 2.6173, 2.5926, 2.4432, 2.3325, 2.2599, 2.4323,\n                       2.4491, 2.5069, 2.1558, 3.7032, 2.1671, 2.2233, 2.2264, 2.9362, 2.9627,\n                       2.7420, 1.8449, 2.7645, 2.4755, 2.6809, 2.1893, 2.9058, 2.5345, 2.5894,\n                       2.6536, 2.3887, 2.0920, 2.9289, 2.3320, 2.0898, 2.6070, 2.5934, 2.5705,\n                       2.3672, 2.2846, 2.6531, 2.9770, 2.6241, 2.5362, 2.3382, 2.2600, 2.1722,\n                       2.6301, 1.9407, 2.2740, 2.3415, 2.4978, 2.7671, 2.8928, 2.2512, 2.3867,\n                       2.3728, 2.5594, 1.8985, 2.6256, 2.3949, 2.3611, 2.4752, 2.6659, 2.4589,\n                       2.0625, 2.8357, 2.8854, 2.2370, 2.7496, 2.0586, 3.0615, 2.1808, 2.4095,\n                       2.3190, 2.6509, 2.4275, 3.5540, 2.6969, 2.3519, 2.5863, 2.3667, 2.9903,\n                       2.4265, 2.3155, 3.1131, 2.7829, 4.0888, 2.5829, 2.1749, 2.5988, 2.6104,\n                       2.2938, 2.7211, 2.7846, 2.5892, 2.1653, 2.7961, 1.8199, 2.7357, 2.3675,\n                       2.4449, 2.8657, 3.0386, 3.3568, 2.7833, 2.0813, 3.3246, 2.3233, 2.7939,\n                       1.8036, 2.3280, 2.5139, 2.5599, 2.2577, 2.7392, 2.3321, 2.6316, 2.5881,\n                       3.1547, 2.2804, 2.1178, 2.6116, 3.5458, 2.6288, 4.2870, 2.7753, 2.2186,\n                       2.8406, 3.0801, 2.1371, 2.4607, 2.6695, 2.4363, 2.9660, 2.9904, 2.3339,\n                       2.5208, 2.2238, 2.9207, 2.2338, 2.3960, 2.7901, 3.0246, 2.0535, 3.3535,\n                       2.5826, 2.7205, 1.9692, 2.3736, 2.1957, 1.8923, 3.0946, 2.8080, 1.9217,\n                       2.4260, 2.6269, 2.0897, 2.5351, 2.4993, 2.5625, 2.6970, 2.4422, 2.2861,\n                       2.8335, 2.4819, 2.4044, 2.0149, 2.5346, 1.9795, 2.5798, 2.6509, 1.8877,\n                       2.2214, 3.0263, 2.7791, 2.4662, 2.5534, 2.5421, 2.9058, 2.1514, 2.8590,\n                       2.2052, 2.6187, 2.2882, 2.6360, 2.8888, 2.7347, 2.1894, 2.1385, 2.4443,\n                       3.2207, 1.9954, 2.5059, 2.4265, 2.4197, 2.4879, 3.2383, 2.4378, 2.2672,\n                       2.0196, 2.2556, 2.5834, 3.1732, 2.2342, 2.3355, 2.0802, 2.3069, 2.4719,\n                       2.2931, 2.5062, 2.6754, 2.6095, 2.9608, 2.2119, 3.3583, 1.9670, 2.9524,\n                       2.7938, 2.4088, 3.6766, 2.8930, 2.4555, 2.1414, 2.4546, 2.4616, 4.0467,\n                       2.5628, 2.0382, 2.9440, 2.4476, 3.2325, 2.0967, 2.7413, 2.7113, 2.6737,\n                       2.5520, 2.9343, 2.4705, 3.4124, 2.6355, 2.2823, 2.2507, 2.4615, 2.1152,\n                       2.5546, 2.4406, 2.5008, 2.3885, 2.2885, 2.1941, 2.4197, 1.8898, 2.5324,\n                       2.3849, 2.2140, 2.6052, 2.5802, 2.9749, 2.4033, 2.2315, 2.6619, 2.3216,\n                       2.6462, 2.5527, 2.2487, 2.9223, 2.0648, 2.4715, 2.2121, 2.6347, 2.2775,\n                       2.2335, 2.8451, 2.5827, 2.4262, 2.6248, 2.6588, 2.4740, 2.2918, 2.4942,\n                       2.2037, 2.2999, 2.8812, 2.1250, 2.5147, 2.4075, 2.6155, 2.3819, 2.9319,\n                       2.6234, 2.1078, 2.6821, 2.4216, 2.5172, 2.5259, 2.0130, 2.5456, 2.7155,\n                       1.9545, 2.2695, 2.3972, 2.6920, 2.6336, 2.9851, 2.5996, 2.3098, 2.7030,\n                       2.5818, 2.0168, 2.7884, 2.1837, 2.1212, 2.9232, 2.5890, 2.1259, 2.7115,\n                       2.2906, 2.5556, 1.9887, 2.4283, 3.9513, 2.4343, 2.6501, 2.3703, 3.2515,\n                       2.2744, 2.2348, 2.3422, 2.0469, 3.0282, 2.2311, 1.9694, 2.5037, 2.2808,\n                       2.3134, 2.2067, 1.7918, 2.7537, 2.8282, 2.5063, 2.1256, 2.2920, 2.3582,\n                       2.0580, 2.4584, 2.2356, 2.8091, 2.0682, 2.4331, 2.1019, 1.8470, 3.2010,\n                       2.1622, 2.7202, 2.3315, 2.5248, 2.7712, 2.4992, 2.3740, 1.8668, 2.5171,\n                       2.5774, 2.7773, 3.0767, 2.2766, 2.5715, 2.4465, 2.4535, 2.1862, 2.4304,\n                       2.3981, 2.1898, 2.3265, 2.1772, 2.4131, 2.4259, 2.1417, 2.7416, 2.3586,\n                       2.3127, 2.5556, 2.4283, 2.2869, 2.8859, 2.4501, 2.8298, 2.4811, 2.5685,\n                       1.9463, 2.3711, 2.3031, 2.5903, 2.9496, 2.4580, 2.8837, 2.4822, 2.7821,\n                       2.1829, 2.6941, 2.6083, 2.2936, 2.5860, 4.2789, 2.3138, 1.8944, 3.1063,\n                       2.8009, 3.0393, 2.2222, 2.1337, 2.1978, 2.8300, 3.0900, 2.3131, 2.4893,\n                       2.6352, 2.5277, 3.1731, 2.1858, 2.7894, 2.5153, 3.0055, 2.1714])),\n              ('layer4.1.bn1.num_batches_tracked', tensor(13572)),\n              ('layer4.1.conv2.weight',\n               tensor([[[[-8.6641e-03, -3.0760e-02, -2.7535e-03],\n                         [-1.7818e-02,  1.5246e-02,  7.7734e-03],\n                         [-1.1466e-03, -6.6623e-03, -1.2010e-02]],\n               \n                        [[-3.2395e-03,  3.8822e-03, -6.3345e-03],\n                         [ 8.3596e-03,  1.2532e-02,  2.5546e-02],\n                         [ 1.9443e-02,  4.0508e-03,  3.7187e-03]],\n               \n                        [[-1.3311e-02,  2.2335e-02,  1.1183e-02],\n                         [-1.4827e-02, -4.3332e-03, -1.0563e-02],\n                         [-4.9310e-03, -8.7871e-05, -1.2482e-02]],\n               \n                        ...,\n               \n                        [[ 6.4220e-03, -1.1531e-02,  2.6331e-02],\n                         [ 1.1562e-03, -1.1599e-02, -6.2010e-03],\n                         [-6.6036e-03, -1.7735e-03, -3.1796e-02]],\n               \n                        [[ 2.4403e-03, -6.4411e-03,  3.4992e-02],\n                         [-1.4369e-02, -1.1987e-03,  1.2451e-02],\n                         [ 8.0319e-03,  8.6587e-03, -3.1500e-03]],\n               \n                        [[ 8.8303e-03,  3.1171e-02,  2.2665e-02],\n                         [ 9.6520e-03,  1.7879e-02,  2.1719e-02],\n                         [ 2.0849e-02, -2.1167e-03,  5.0619e-03]]],\n               \n               \n                       [[[-7.8344e-03,  2.3073e-02,  1.2189e-02],\n                         [ 1.9577e-02,  1.9622e-02, -7.2428e-03],\n                         [-2.7116e-05, -3.3943e-03,  3.1369e-03]],\n               \n                        [[-3.2585e-02, -1.3543e-03, -8.5692e-03],\n                         [-2.1557e-02, -1.5110e-02, -1.4542e-02],\n                         [-1.9004e-02, -3.0628e-02, -1.2601e-02]],\n               \n                        [[ 2.5767e-02,  1.5068e-02,  8.5740e-03],\n                         [ 1.2727e-02,  3.1382e-02,  1.7968e-02],\n                         [-4.5400e-03,  3.3844e-02,  1.0895e-02]],\n               \n                        ...,\n               \n                        [[-1.0667e-02, -9.2948e-03,  6.8641e-03],\n                         [ 2.4554e-02,  1.2217e-02, -1.8761e-02],\n                         [ 1.2182e-02,  1.8859e-02, -1.1814e-02]],\n               \n                        [[-1.2884e-02, -1.5606e-02, -1.1922e-02],\n                         [ 2.2534e-02,  2.4589e-02, -1.0782e-02],\n                         [ 1.4336e-02,  1.6311e-02, -1.0745e-02]],\n               \n                        [[-1.0656e-02, -4.3073e-03, -2.7738e-03],\n                         [-2.1258e-02, -3.4258e-03, -4.3013e-04],\n                         [ 6.4585e-03,  1.0889e-02, -1.0574e-02]]],\n               \n               \n                       [[[-4.3062e-03, -8.9835e-03, -1.3291e-04],\n                         [-1.2850e-02, -1.5123e-02, -7.9006e-03],\n                         [ 1.4175e-02,  2.1987e-02,  9.5879e-03]],\n               \n                        [[ 2.0478e-02, -7.5529e-03, -2.9996e-03],\n                         [-1.0556e-02, -5.8190e-03, -9.8239e-03],\n                         [-1.1194e-02,  6.7265e-03, -1.3159e-02]],\n               \n                        [[-2.0422e-02,  1.7223e-03, -4.1393e-03],\n                         [-2.3332e-02, -2.5472e-02,  5.0756e-03],\n                         [-4.3084e-03,  2.6988e-02,  8.4533e-03]],\n               \n                        ...,\n               \n                        [[ 1.8935e-03,  2.2416e-02,  2.6104e-02],\n                         [-1.2297e-03,  2.0631e-02,  1.2402e-02],\n                         [-1.8501e-02, -1.2540e-02,  1.4793e-03]],\n               \n                        [[-8.2841e-03, -2.4356e-02, -1.6434e-02],\n                         [-2.2966e-02, -4.8761e-03,  1.1240e-02],\n                         [-1.1555e-02, -1.0798e-02, -6.1818e-03]],\n               \n                        [[ 1.1907e-03, -1.4412e-02, -3.9302e-02],\n                         [-9.7500e-03, -2.1746e-02, -1.3419e-02],\n                         [-1.0080e-02, -1.1418e-02, -1.9348e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-1.1367e-03,  2.6394e-03, -1.1453e-03],\n                         [ 1.3953e-02,  4.4587e-03,  1.2906e-02],\n                         [ 6.4410e-04,  2.1210e-02,  1.6523e-02]],\n               \n                        [[-5.1321e-03,  1.4017e-03, -6.9859e-04],\n                         [ 9.4640e-03, -1.3204e-02, -8.9654e-03],\n                         [ 3.7548e-03, -1.2418e-03,  3.5361e-03]],\n               \n                        [[ 4.5076e-03,  1.0845e-02,  4.6937e-03],\n                         [ 2.1489e-02,  3.5071e-02,  1.2895e-02],\n                         [ 1.7084e-02,  7.1932e-03, -1.6964e-03]],\n               \n                        ...,\n               \n                        [[-9.9365e-03, -3.2145e-02,  4.6431e-03],\n                         [-6.6013e-03, -9.7115e-03,  1.8671e-02],\n                         [ 1.1405e-02,  4.5668e-03,  2.1182e-02]],\n               \n                        [[-9.1077e-03, -4.2521e-03, -2.8897e-02],\n                         [ 3.7045e-03, -8.2821e-03, -1.5415e-02],\n                         [-1.2946e-02, -2.4450e-02, -3.1099e-02]],\n               \n                        [[ 1.3862e-02, -1.7443e-02, -1.2696e-02],\n                         [-2.4693e-03,  1.5790e-02,  1.3920e-02],\n                         [ 2.3013e-03,  8.3484e-03,  9.1087e-05]]],\n               \n               \n                       [[[ 2.3845e-04,  2.8568e-02,  4.0773e-04],\n                         [ 5.1799e-03,  1.6584e-02, -3.2408e-02],\n                         [-3.0755e-02, -2.0209e-02,  5.1122e-04]],\n               \n                        [[-9.1800e-03, -1.3927e-03, -3.3769e-03],\n                         [-1.9733e-02, -4.6974e-03, -1.5633e-02],\n                         [-1.9000e-02, -7.2865e-03, -9.2111e-03]],\n               \n                        [[-1.1907e-02,  1.0166e-02,  2.1589e-02],\n                         [ 5.3434e-03,  1.7877e-02,  1.6087e-02],\n                         [ 2.7111e-02,  2.9789e-03, -2.0553e-03]],\n               \n                        ...,\n               \n                        [[ 7.6567e-03,  1.3334e-02,  1.0482e-02],\n                         [-2.3253e-02,  2.7027e-03, -1.6511e-03],\n                         [ 1.2360e-02, -7.5091e-03, -2.0157e-03]],\n               \n                        [[ 5.9217e-03, -1.0961e-02, -7.1269e-03],\n                         [ 1.4428e-02,  2.2760e-03,  2.3221e-02],\n                         [-2.3239e-02, -2.3101e-02,  2.5244e-04]],\n               \n                        [[ 4.6204e-03, -9.0638e-03,  3.5907e-03],\n                         [ 9.8552e-03,  1.1168e-02, -3.1919e-03],\n                         [-2.1112e-04,  1.4536e-03, -5.9381e-03]]],\n               \n               \n                       [[[-2.5450e-02, -3.4706e-02, -1.8488e-02],\n                         [-6.4039e-03, -2.1232e-02,  4.1964e-03],\n                         [-9.0640e-03,  4.5415e-03, -1.4082e-02]],\n               \n                        [[-4.5586e-03,  2.3827e-02, -8.7764e-03],\n                         [-8.6503e-03, -7.8852e-03,  1.6908e-02],\n                         [-2.4315e-03,  2.2422e-02, -7.6245e-03]],\n               \n                        [[-8.6588e-03, -1.7525e-02, -3.5230e-02],\n                         [-3.9111e-03, -4.4025e-02, -2.3050e-03],\n                         [-2.6247e-03, -9.9693e-03,  2.7333e-02]],\n               \n                        ...,\n               \n                        [[ 6.5603e-03,  2.0541e-02, -8.5676e-03],\n                         [ 4.5296e-03, -4.0519e-03, -1.2110e-02],\n                         [-2.1421e-02, -1.6794e-02, -3.7477e-02]],\n               \n                        [[ 1.1073e-02, -1.9191e-02, -1.1987e-02],\n                         [-1.4139e-03, -5.2150e-03,  1.4318e-02],\n                         [ 3.0096e-02,  1.0459e-02, -3.7670e-03]],\n               \n                        [[-1.0138e-02,  9.3345e-03,  4.3869e-03],\n                         [-2.2925e-03, -6.6206e-03,  1.1365e-02],\n                         [-4.2795e-03, -3.4981e-03,  1.4182e-02]]]])),\n              ('layer4.1.bn2.weight',\n               tensor([0.9935, 1.0787, 1.0155, 1.0084, 1.0638, 1.0000, 0.9394, 1.0299, 1.0037,\n                       1.0074, 0.9651, 1.0637, 0.8789, 0.9874, 0.9711, 0.9330, 1.0265, 0.9410,\n                       0.9337, 0.9453, 1.0547, 0.9602, 0.9415, 1.0356, 1.0278, 1.0063, 0.9968,\n                       1.0322, 1.0495, 1.0515, 1.0304, 0.9552, 1.0174, 1.0280, 1.0517, 0.9918,\n                       1.0292, 1.0349, 0.9532, 0.9457, 1.0053, 0.9232, 0.9902, 0.9971, 0.9942,\n                       0.9580, 1.0158, 1.0238, 1.0559, 1.0024, 0.9850, 1.0216, 0.9318, 1.0077,\n                       0.9938, 0.9450, 1.0147, 1.0309, 0.9828, 1.0316, 0.9613, 1.0209, 1.0039,\n                       0.9429, 0.9607, 0.9917, 0.9813, 1.0463, 1.0013, 0.9950, 0.9704, 0.9959,\n                       1.0391, 0.9253, 0.9830, 0.9893, 0.9260, 0.9889, 0.9830, 0.9748, 0.9792,\n                       1.0174, 1.0592, 0.9595, 0.9584, 1.0334, 0.9563, 1.0296, 0.9283, 1.0674,\n                       0.9884, 0.9927, 1.0002, 1.0502, 0.9328, 0.9295, 0.9334, 0.9339, 1.0116,\n                       0.9323, 1.0002, 0.9556, 0.9854, 1.0839, 1.0527, 0.9566, 0.9412, 1.0676,\n                       0.9120, 0.9778, 0.9425, 1.0046, 0.9558, 0.9991, 0.9559, 1.0182, 0.9610,\n                       0.9550, 0.9745, 0.9847, 1.0285, 0.9825, 1.0176, 0.9605, 1.0584, 0.9551,\n                       0.9574, 0.9606, 1.0604, 1.0199, 1.0285, 1.0296, 0.9393, 1.0874, 1.0451,\n                       1.0190, 0.9861, 0.9526, 0.9209, 0.9487, 0.9541, 0.9410, 1.0337, 0.9523,\n                       0.9978, 1.0123, 1.0236, 1.0093, 0.9651, 1.0355, 0.9337, 1.0220, 0.9457,\n                       0.9607, 1.0683, 0.9853, 1.0832, 0.9390, 1.0460, 1.0503, 0.9485, 1.0165,\n                       1.0073, 0.9451, 1.1306, 1.0391, 1.0392, 0.9770, 1.0213, 0.9666, 0.9922,\n                       1.0161, 1.0038, 0.9574, 1.0498, 1.0545, 1.0302, 1.0310, 0.9363, 0.9676,\n                       0.9981, 0.9509, 1.0187, 1.0128, 1.0351, 1.0105, 0.9763, 0.9159, 0.9667,\n                       1.0704, 1.0680, 0.9665, 0.9373, 1.0843, 0.9499, 0.9839, 0.9912, 1.0309,\n                       0.9280, 0.9919, 0.9385, 0.9154, 0.9845, 0.9999, 0.9289, 1.0109, 0.9961,\n                       0.9395, 0.9327, 0.9374, 1.0341, 1.0147, 0.9875, 1.0227, 0.9637, 1.0382,\n                       0.9768, 0.9626, 1.0000, 1.0081, 0.9930, 1.0063, 0.9292, 1.0358, 0.9239,\n                       0.9434, 1.0179, 1.0246, 0.9538, 1.0461, 0.9710, 1.0056, 0.9519, 1.0289,\n                       0.9561, 0.9287, 0.9448, 0.9532, 0.9936, 1.0289, 1.0749, 0.9756, 0.9341,\n                       0.9759, 1.0241, 0.9632, 0.9922, 0.9716, 0.9819, 1.0154, 0.9310, 1.0415,\n                       0.9544, 1.0309, 1.0241, 0.9535, 0.9533, 0.9421, 0.9118, 0.9676, 0.9264,\n                       0.9673, 0.9967, 0.9412, 1.0025, 1.0307, 0.9440, 1.0645, 1.0059, 1.0287,\n                       0.9682, 1.0449, 0.9728, 1.0208, 0.9448, 0.9824, 0.9951, 0.9914, 1.0914,\n                       0.9866, 1.0293, 0.9691, 1.0679, 0.9858, 1.0410, 0.9785, 1.0353, 0.9786,\n                       1.0142, 0.9824, 1.0193, 0.9764, 0.9908, 0.9893, 0.9681, 1.0353, 1.0265,\n                       0.9871, 1.0235, 0.9343, 1.0307, 1.0283, 0.9771, 1.0350, 1.0170, 1.0148,\n                       0.9288, 0.9639, 1.0494, 1.0231, 0.9412, 0.9757, 1.0444, 1.0315, 0.9999,\n                       0.9945, 0.9930, 1.0042, 0.9926, 0.9740, 0.9599, 0.9376, 1.0193, 0.9466,\n                       0.9852, 0.9540, 0.9311, 0.9696, 0.9749, 0.9431, 1.0668, 0.9604, 0.9715,\n                       0.9953, 0.9133, 0.9851, 0.9418, 0.9347, 0.9900, 1.0088, 1.0608, 0.9745,\n                       1.0379, 1.0151, 1.0123, 1.0202, 1.0075, 0.9654, 0.9388, 0.9770, 0.9773,\n                       0.9753, 0.9600, 0.9757, 0.9446, 0.9782, 0.9511, 1.0034, 0.9513, 0.9470,\n                       1.0353, 0.9530, 0.9485, 0.9448, 0.9932, 0.9885, 1.0305, 0.9825, 1.0135,\n                       1.0019, 1.1443, 0.9662, 0.9781, 1.0610, 0.9992, 0.9433, 0.9864, 0.9675,\n                       0.9718, 0.9804, 0.9727, 1.0075, 0.9784, 1.0254, 0.9563, 0.9672, 0.9277,\n                       0.9954, 1.0401, 0.9387, 1.0492, 1.0566, 0.9600, 0.9591, 0.9777, 0.9699,\n                       0.9638, 1.0170, 0.9460, 0.9517, 1.0646, 0.9999, 0.9780, 1.0593, 1.0297,\n                       0.9639, 1.0312, 1.0350, 0.9466, 0.9901, 1.0042, 0.9220, 0.9158, 0.9600,\n                       0.9498, 1.0380, 0.9025, 0.9627, 1.0293, 0.9666, 1.0580, 1.0260, 0.9954,\n                       0.9813, 0.9719, 0.9672, 0.9403, 1.0209, 1.0175, 0.9628, 0.9259, 1.0626,\n                       1.0374, 1.0319, 0.9866, 1.0365, 1.0187, 0.9589, 0.9508, 0.9817, 1.0294,\n                       0.9917, 1.0297, 1.0272, 0.9443, 0.9435, 0.9901, 0.9617, 1.1105, 0.9972,\n                       1.0388, 0.9838, 0.9382, 0.9468, 1.0169, 0.9863, 1.0497, 0.9611, 0.9620,\n                       0.9385, 0.9119, 0.9687, 0.9876, 1.0035, 0.9510, 1.0148, 0.9271, 0.9547,\n                       0.9523, 0.9853, 0.9564, 0.9734, 0.9522, 1.0222, 0.9582, 1.0464, 0.9356,\n                       1.0464, 0.9693, 1.0368, 1.0440, 1.0278, 1.0656, 1.0223, 0.9901, 0.9570,\n                       0.9971, 1.0881, 0.9469, 1.0579, 0.9760, 1.0460, 0.9375, 0.9421, 1.0173,\n                       0.9909, 0.9874, 0.9608, 1.0222, 1.0143, 1.0080, 0.9892, 0.9379, 0.9995,\n                       0.9706, 0.9965, 0.9983, 0.9359, 1.0193, 0.9856, 1.0014, 0.9080])),\n              ('layer4.1.bn2.bias',\n               tensor([-0.1462, -0.1510, -0.0541, -0.0618, -0.0482, -0.1825, -0.1493, -0.1412,\n                       -0.1523, -0.0341, -0.1279, -0.0648, -0.1123, -0.1175, -0.1624, -0.1041,\n                       -0.0015, -0.1352, -0.1732, -0.0958, -0.0845, -0.1100, -0.0627, -0.0594,\n                       -0.0937, -0.0166, -0.1141, -0.1811, -0.0893, -0.0047, -0.0989, -0.1431,\n                       -0.0365, -0.1113, -0.0412, -0.1197, -0.1713, -0.0927, -0.0895, -0.1632,\n                       -0.1499, -0.1409, -0.0803, -0.1208, -0.0827, -0.1007, -0.1093, -0.0861,\n                       -0.0887, -0.0673, -0.1219, -0.1012, -0.1168, -0.0398, -0.0974, -0.1238,\n                       -0.0953, -0.1434, -0.0441, -0.0797, -0.1284, -0.1238, -0.1188, -0.1621,\n                       -0.1052, -0.1967, -0.1439, -0.1193, -0.1372, -0.0909, -0.0932, -0.0842,\n                       -0.0556, -0.1596, -0.1315, -0.1394, -0.1770, -0.1136, -0.1331, -0.1270,\n                       -0.0970, -0.1107, -0.0779, -0.1136, -0.1023, -0.0388, -0.1390, -0.0527,\n                       -0.1649, -0.0257, -0.0981, -0.0432, -0.1436, -0.0814, -0.0550, -0.1776,\n                       -0.1324, -0.1576, -0.0350, -0.1324, -0.1349, -0.1529, -0.2784, -0.0052,\n                       -0.1342, -0.0811, -0.1657, -0.0157, -0.0461, -0.1689, -0.1811, -0.0647,\n                       -0.1030, -0.1461, -0.1192, -0.0888, -0.1307, -0.1629, -0.1237, -0.0999,\n                       -0.1019, -0.0857, -0.0968, -0.1941, -0.0958, -0.1152, -0.1003, -0.1100,\n                       -0.0761, -0.1173, -0.0955, -0.0869, -0.1666, -0.0564, -0.0170, -0.1040,\n                       -0.0204, -0.1416, -0.1344, -0.0992, -0.2066, -0.0731, -0.1061, -0.1272,\n                       -0.0545, -0.0951, -0.0711, -0.1405, -0.1386, -0.0199, -0.0883, -0.0998,\n                       -0.0640, -0.0714, -0.0212, -0.0727, -0.0658, -0.1726, -0.0821, -0.1064,\n                       -0.0781, -0.0976, -0.0893, -0.1627, -0.0399, -0.0644, -0.0738, -0.1472,\n                       -0.0938, -0.1121, -0.0799, -0.0955, -0.1490, -0.2081, -0.0924, -0.0664,\n                       -0.0822, -0.0622, -0.1513, -0.0848, -0.0590, -0.0661, -0.0923, -0.0658,\n                       -0.0561, -0.1415, -0.1513, -0.1839, -0.1427, -0.0986, -0.1013, -0.1033,\n                       -0.1625, -0.0233, -0.1174, -0.1037, -0.0397, -0.0918, -0.0862, -0.1046,\n                       -0.1521, -0.1613, -0.1443, -0.0762, -0.1317, -0.0502, -0.1525, -0.1461,\n                       -0.1319, -0.1621, -0.1369, -0.0176, -0.0831, -0.1076, -0.1627, -0.0740,\n                       -0.1282, -0.1016, -0.0752, -0.0367, -0.1553, -0.0515, -0.1374, -0.0253,\n                       -0.1600, -0.1078, -0.0911, -0.0885, -0.1230, -0.0640, -0.0563, -0.0880,\n                       -0.1345, -0.0992, -0.1282, -0.1135, -0.1207, -0.1382, -0.1233, -0.0749,\n                       -0.0246, -0.1153, -0.1672, -0.1332, -0.1185, -0.1280, -0.0759, -0.1067,\n                       -0.1399, -0.1247, -0.1793, -0.1102, -0.1153, -0.1350, -0.0791, -0.1102,\n                       -0.1466, -0.2346, -0.1031, -0.1186, -0.1020, -0.1591, -0.0721, -0.1098,\n                       -0.0740, -0.1116, -0.1481, -0.0360, -0.1078, -0.1463, -0.1404, -0.1225,\n                       -0.1158, -0.0598, -0.1880, -0.1059, -0.1257, -0.1718, -0.0584, -0.1192,\n                       -0.1302, -0.0837,  0.0300, -0.1101, -0.0219, -0.1651, -0.1332, -0.0897,\n                       -0.0968, -0.0937, -0.0535, -0.0942, -0.1126, -0.1175, -0.1590, -0.1648,\n                       -0.0936, -0.1340, -0.1060, -0.1224, -0.0679, -0.0345, -0.1427, -0.0150,\n                       -0.0292, -0.0636, -0.1383, -0.0987, -0.1376, -0.0958, -0.1081, -0.1063,\n                       -0.0556, -0.0878, -0.1361, -0.1211, -0.1282, -0.1545, -0.1129, -0.0717,\n                       -0.1914, -0.1203, -0.1255, -0.1013, -0.0814, -0.1374, -0.1361, -0.1071,\n                       -0.1367, -0.1236, -0.0658, -0.1040, -0.0993, -0.0538, -0.0940, -0.0100,\n                       -0.0923, -0.1335, -0.0668, -0.1643, -0.0475, -0.1615, -0.1106, -0.1482,\n                       -0.1372, -0.0619, -0.1135, -0.1107, -0.1431, -0.1723, -0.0758, -0.1453,\n                       -0.1436, -0.1168, -0.0929, -0.1469, -0.1422, -0.1379, -0.1418, -0.1570,\n                       -0.0575, -0.0897, -0.1436, -0.1541, -0.1331, -0.0449, -0.0100, -0.0190,\n                       -0.0124, -0.0779, -0.0441, -0.1529, -0.1353, -0.1391, -0.1044, -0.1037,\n                       -0.0922, -0.1365, -0.0872, -0.0849, -0.1391, -0.0734, -0.1478, -0.0815,\n                       -0.0793, -0.0925, -0.1839, -0.1584, -0.0805, -0.2190, -0.1118, -0.1064,\n                       -0.0813, -0.1529, -0.0848, -0.1467, -0.0790, -0.0494, -0.1044, -0.1515,\n                       -0.0729, -0.1267, -0.1043, -0.0740, -0.1427, -0.1219, -0.0377, -0.0391,\n                       -0.1360, -0.1389, -0.1340, -0.1281, -0.1622, -0.1271, -0.1370,  0.0252,\n                       -0.0869, -0.1154, -0.0412, -0.1740, -0.0558, -0.0735, -0.1052, -0.0636,\n                       -0.1352, -0.1330, -0.1297, -0.1302, -0.1135, -0.1310, -0.0655, -0.1112,\n                       -0.0941, -0.1365, -0.0879, -0.1259, -0.0577, -0.0526, -0.1578, -0.1175,\n                       -0.0341, -0.1103, -0.1152, -0.0175, -0.1601, -0.1487, -0.1538, -0.1000,\n                       -0.1324, -0.1345, -0.1452, -0.1046, -0.2055, -0.1573, -0.1341, -0.0803,\n                       -0.0363, -0.1082, -0.1672, -0.1378, -0.1007, -0.0671, -0.0688, -0.0960,\n                       -0.1397, -0.0680, -0.1741, -0.1353, -0.1013, -0.1813, -0.1488, -0.1139,\n                       -0.1512, -0.0712, -0.1693, -0.0955, -0.1618, -0.0922, -0.1361, -0.1235,\n                       -0.1149,  0.0119, -0.0806, -0.0690, -0.0842, -0.0442, -0.0726, -0.0751,\n                       -0.1640, -0.0570, -0.1018, -0.0846, -0.1426, -0.1310, -0.0579, -0.1009,\n                       -0.0689, -0.1621, -0.0715, -0.0659, -0.0722, -0.0983, -0.1254, -0.1172,\n                       -0.0238, -0.1070, -0.0936, -0.1325, -0.0632, -0.1339, -0.1131, -0.1741])),\n              ('layer4.1.bn2.running_mean',\n               tensor([-8.0066e-01, -6.6131e-01, -8.4899e-01, -2.0718e-01, -1.0561e+00,\n                       -5.2130e-01,  5.9148e-02, -7.7064e-01, -6.2354e-01,  2.5433e-01,\n                        1.3564e-01, -8.1181e-01, -5.8261e-02, -7.9778e-01, -6.6950e-01,\n                       -1.2780e+00, -3.1458e-01, -4.8919e-01, -8.3222e-01, -1.0761e+00,\n                       -1.5758e-01, -1.5243e-01, -8.8553e-01, -9.6601e-01, -4.5571e-01,\n                       -3.8965e-01, -5.4920e-01, -5.2649e-01, -3.6333e-01, -3.7200e-01,\n                       -2.7525e-01,  4.6583e-02, -1.0206e+00,  9.4579e-01, -3.2146e-01,\n                       -1.4765e+00, -6.3846e-01, -5.8714e-01, -3.3179e-01, -6.6741e-01,\n                       -4.9831e-01, -7.5695e-01, -4.3638e-01, -2.9433e-01,  5.4239e-03,\n                       -9.5918e-01, -3.0305e-01,  2.5228e-01, -6.6812e-01, -1.5039e-01,\n                       -2.5951e-01, -3.4963e-01, -4.1647e-01, -2.4683e-01, -1.3517e-01,\n                        2.9565e-02, -5.4810e-01, -3.8025e-01, -4.6703e-03,  1.5837e+00,\n                       -6.0383e-01, -7.3625e-01, -3.3498e-01, -8.3028e-01, -1.0281e+00,\n                       -1.7519e-02, -1.0558e+00, -1.3151e+00, -8.1204e-01, -4.1786e-01,\n                       -4.7373e-01,  4.3974e-02, -1.3555e-01, -1.2129e+00, -8.2393e-01,\n                       -5.6825e-01,  8.3595e-02, -7.3067e-01, -7.7190e-01, -2.0999e-01,\n                        3.5085e-01, -3.9947e-01, -4.1735e-01, -5.1569e-01, -4.8950e-01,\n                        8.5714e-02, -3.6886e-01, -9.5028e-01, -5.0350e-01, -7.4539e-01,\n                       -1.1711e+00, -3.1100e-01, -7.0174e-01, -1.5659e-01, -1.3151e-01,\n                       -4.1792e-01, -7.2200e-01, -6.4009e-01,  8.6611e-01, -1.0567e-01,\n                       -5.9478e-01, -6.7907e-01, -4.6681e-01, -6.7552e-01, -1.4554e-01,\n                       -1.0087e-01, -8.2239e-01,  1.5967e-01, -6.8729e-02, -1.1423e+00,\n                       -5.1849e-01, -4.0745e-01, -2.6632e-01, -1.2325e+00, -6.4469e-01,\n                       -9.8489e-01,  9.3967e-03, -1.1842e-01, -3.1248e-01, -9.0358e-02,\n                        1.7397e-01, -7.2998e-01, -4.9976e-01, -1.2333e+00,  8.5019e-01,\n                       -5.7773e-02,  4.1169e-01, -2.9069e-01, -6.4250e-01, -1.2814e+00,\n                       -9.1735e-01, -5.0415e-01, -9.9428e-01, -7.7540e-01, -1.0188e+00,\n                       -3.1567e-01,  7.9934e-01,  8.0983e-02, -4.4903e-01, -4.5674e-01,\n                       -3.6531e-01,  7.6417e-01, -8.3471e-01, -3.2498e-01, -1.0378e-01,\n                       -3.4102e-01, -6.7167e-01, -3.2540e-01, -5.6455e-01, -1.4403e-01,\n                        2.8394e-01, -4.6838e-01,  3.9757e-01,  3.4964e-01, -5.4305e-01,\n                       -5.6666e-02, -3.8779e-01, -9.7268e-01, -1.0977e-01,  1.2650e-01,\n                        2.0480e-01, -4.9022e-01, -6.2920e-01, -5.1321e-01,  1.2938e-01,\n                       -7.1595e-01, -4.2658e-01,  1.7520e-01, -6.5876e-01, -7.1429e-01,\n                       -5.8149e-01, -6.0631e-01, -1.2839e+00, -6.7480e-01, -3.9661e-01,\n                       -7.8488e-02,  3.4306e-01, -5.2100e-01, -2.1605e-01, -5.3332e-01,\n                       -1.3248e+00,  1.8356e-02, -7.4959e-01, -4.7625e-01, -3.4649e-02,\n                       -7.2095e-01, -2.5223e-01, -1.0992e-01, -1.2818e-01, -1.0922e+00,\n                       -1.1046e+00, -6.3800e-01, -7.4223e-01, -8.3653e-01, -2.0827e-01,\n                        2.5973e-01, -6.8837e-01, -4.0170e-01, -1.2308e-01, -4.5817e-01,\n                       -5.5882e-01, -6.8963e-01,  2.6826e-01, -7.9539e-01, -1.9554e-01,\n                       -3.2150e-01, -6.7894e-01, -3.6110e-01, -9.9612e-02,  5.6335e-02,\n                       -5.0676e-01, -9.8366e-02,  1.6456e-01, -4.4186e-01, -3.5328e-01,\n                       -1.2100e-01,  1.3174e-01, -2.1904e-01, -3.5398e-01, -4.0033e-01,\n                       -7.9148e-01, -8.4018e-01, -1.0740e-01, -6.0577e-01, -2.4561e-01,\n                       -8.5074e-01,  8.8932e-02, -2.4529e-01, -2.2203e-01,  1.7255e-01,\n                        6.8553e-02, -2.9110e-01, -2.8099e-01,  2.8523e-01, -4.8861e-01,\n                       -6.7042e-01, -5.4119e-01, -2.9535e-01, -4.2021e-01, -1.1947e-01,\n                        3.2075e-01, -1.0905e+00, -3.1361e-01, -1.5507e-01, -5.7330e-02,\n                       -5.8947e-01,  5.6891e-01, -7.4679e-01, -2.5790e-01, -2.1038e-01,\n                       -1.1355e+00, -4.1643e-01, -4.3854e-02, -5.7370e-01, -8.4696e-01,\n                       -3.2866e-01, -8.0525e-02,  2.0816e-01,  6.6426e-01, -9.2679e-01,\n                       -6.8580e-01, -3.5069e-01, -3.9179e-01, -1.9738e-01, -4.0623e-01,\n                       -9.0243e-01, -9.4470e-01,  3.9668e-01, -3.0321e-01, -2.1884e-01,\n                       -1.1123e+00, -9.8458e-01,  6.3342e-02, -3.6013e-01, -6.6840e-01,\n                       -1.4529e-01, -3.6659e-02, -5.5521e-01, -1.8620e-01, -6.6454e-01,\n                       -6.3269e-01, -4.7095e-02, -1.2463e-01, -3.7087e-01, -8.3292e-01,\n                       -5.8310e-01, -3.5164e-01, -2.9312e-01, -2.6493e-01, -9.2909e-01,\n                       -8.2692e-01, -4.1597e-01, -4.9710e-01, -1.7614e-01, -1.0793e+00,\n                        3.1368e-01, -6.7961e-02, -4.6673e-01,  6.8018e-03, -3.7132e-01,\n                        4.7428e-01,  1.7669e-01, -4.7754e-01, -3.3781e-01, -3.5543e-01,\n                        6.3083e-01, -1.7211e-01,  2.6584e-01, -8.2687e-01, -7.0477e-01,\n                       -5.0902e-01, -8.3585e-01, -5.6931e-01, -3.9345e-01, -2.8752e-01,\n                       -5.7532e-01, -8.0822e-01, -4.8611e-01, -3.7360e-01, -4.0302e-02,\n                       -1.0058e+00, -7.2591e-01, -1.3030e+00, -1.3118e-01, -8.6616e-01,\n                       -1.2331e+00, -4.0143e-02, -6.4478e-01, -5.9161e-01,  1.0950e-01,\n                       -7.1651e-01, -3.3877e-01, -8.9419e-01,  6.6748e-01, -2.9834e-01,\n                        2.1838e-01,  1.6076e-01, -1.1322e+00, -3.0395e-01, -4.6473e-01,\n                       -5.1021e-01, -6.9014e-01, -8.4383e-01, -3.3147e-01, -1.2731e+00,\n                       -9.1392e-01, -2.6753e-01, -8.0435e-01, -3.1680e-01, -3.8225e-01,\n                       -6.8475e-01, -1.7418e+00, -8.5846e-01, -7.8325e-01, -9.4804e-01,\n                       -7.4187e-02, -4.0489e-01, -5.9795e-01, -7.1933e-01, -1.0494e-01,\n                       -4.9544e-01, -8.6649e-01, -5.4812e-02,  2.8390e-01, -3.8050e-01,\n                        6.5366e-01,  3.0357e-01, -4.4074e-01,  4.7164e-01, -1.2744e-01,\n                        4.9992e-01, -2.5802e-01, -5.8711e-01, -2.4335e-01, -4.0590e-01,\n                       -5.7452e-01, -5.1208e-01, -5.4573e-01, -1.1406e-01, -9.0422e-01,\n                       -9.1891e-01, -3.1482e-01, -7.6770e-01,  1.9539e-01, -5.5573e-01,\n                       -9.7733e-01, -2.9880e-01, -7.1774e-01,  3.2392e-01, -8.6021e-01,\n                       -9.7310e-01, -9.4672e-01, -1.2501e+00, -5.3001e-01, -6.6556e-01,\n                       -3.8009e-01, -7.7122e-01,  1.2981e-02, -1.6311e-01, -3.2611e-01,\n                       -4.1466e-01, -4.3806e-01, -1.9315e-01, -4.4069e-01, -1.1709e+00,\n                       -6.6592e-01,  1.0112e-01, -7.0135e-01, -6.3292e-01, -8.2116e-01,\n                        2.0772e-01, -5.1308e-01, -1.0260e+00, -2.8309e-01, -7.6072e-01,\n                       -1.8574e-01,  1.2108e-02, -1.3287e-01, -3.1288e-01, -9.8200e-01,\n                       -1.2197e-01, -3.2443e-01, -5.9547e-01, -9.1827e-02, -6.4600e-01,\n                       -5.0506e-01, -1.1285e+00, -4.9512e-01, -1.1564e-01, -1.5402e-01,\n                        1.2530e-01, -4.1872e-01, -1.1376e-01, -3.9613e-01, -4.4916e-01,\n                       -2.3933e-01, -6.7525e-01, -6.9971e-01, -2.8551e-01, -7.7143e-01,\n                        6.7499e-02, -1.1447e-01, -3.5469e-02,  8.4056e-01, -7.9619e-01,\n                       -2.6172e-01, -9.8681e-01, -3.6236e-01,  1.2133e+00, -5.1013e-01,\n                       -7.2496e-01, -4.8782e-02, -3.4467e-01, -8.6238e-01, -4.9936e-01,\n                       -8.3131e-01, -4.5343e-01, -3.2361e-01, -6.6910e-01, -3.7861e-01,\n                       -3.5009e-01,  5.7055e-01, -5.6823e-01, -1.0760e+00,  3.0221e-01,\n                       -9.5888e-01, -4.1039e-01, -1.6594e-01, -9.5311e-01,  1.9376e-02,\n                       -6.1178e-01, -5.3545e-01, -1.7422e-01, -7.2350e-01, -6.0196e-02,\n                       -4.4798e-01, -8.0883e-01, -7.6661e-01, -2.2894e-01, -5.6164e-01,\n                       -1.2603e+00,  1.4225e+00, -9.8525e-01, -5.2032e-01, -4.1184e-01,\n                        9.8540e-02, -3.1387e-01,  7.0072e-01, -3.6577e-01, -1.4609e-01,\n                       -1.7754e+00,  5.7345e-01, -9.1088e-01, -5.0635e-01,  3.2869e-01,\n                       -6.7792e-01,  3.2199e-01, -4.8786e-01,  2.1374e-01, -4.8424e-02,\n                       -6.2683e-01, -1.0802e+00, -4.0507e-01, -1.2876e+00,  7.0032e-01,\n                       -9.0776e-01,  9.6231e-04, -2.7056e-01,  3.9349e-01, -3.9898e-01,\n                       -1.1683e+00, -1.9570e-01])),\n              ('layer4.1.bn2.running_var',\n               tensor([0.4778, 1.1802, 1.0607, 0.4672, 0.4130, 0.4323, 0.5943, 0.5463, 0.6081,\n                       0.4057, 0.3753, 0.6451, 0.4589, 0.4722, 0.4814, 0.6093, 0.4100, 0.7219,\n                       0.5705, 0.7400, 2.0076, 0.4608, 0.6110, 0.4972, 0.5690, 0.3038, 0.5090,\n                       0.4775, 0.4884, 0.5814, 0.4855, 0.5035, 0.9528, 0.6144, 0.5339, 0.5568,\n                       0.5321, 0.5210, 0.4039, 0.5782, 0.5280, 0.5476, 0.5780, 0.6750, 0.4354,\n                       0.5894, 0.4343, 0.4603, 0.6654, 0.4276, 0.4930, 0.4505, 0.4371, 0.2926,\n                       0.6501, 0.3614, 0.6111, 0.5251, 0.3149, 0.8007, 0.5772, 0.8996, 0.7879,\n                       0.4475, 0.6114, 0.5366, 0.4839, 1.1437, 0.5454, 0.7302, 0.3800, 0.3613,\n                       0.5094, 0.8338, 0.4745, 0.5892, 0.4984, 0.6650, 0.6200, 0.5568, 0.4813,\n                       0.6065, 0.4716, 0.4395, 0.5551, 0.4843, 0.4630, 0.5602, 0.4567, 0.5516,\n                       0.5866, 0.3745, 0.4045, 0.5463, 0.2520, 0.4769, 0.4881, 0.5582, 0.5254,\n                       0.4701, 0.5504, 0.5375, 0.5558, 1.3521, 0.6503, 0.4706, 0.4851, 0.5585,\n                       0.3719, 0.5610, 0.4939, 0.6931, 0.3408, 0.5788, 0.4966, 0.5564, 0.4443,\n                       0.5510, 0.4173, 0.7483, 0.5435, 0.6411, 0.4971, 0.5056, 0.8006, 0.4191,\n                       0.3955, 0.3718, 1.8314, 0.6646, 0.5579, 0.5474, 0.5369, 0.9832, 0.5558,\n                       0.4682, 0.3986, 0.3833, 0.3851, 0.4911, 0.4653, 0.3808, 0.4513, 0.4848,\n                       0.4639, 0.3819, 0.4997, 0.6615, 0.5581, 0.3963, 0.4055, 0.5956, 0.4494,\n                       0.4848, 0.4563, 0.5743, 0.8030, 0.6702, 1.1657, 0.4632, 0.4038, 0.4699,\n                       0.4314, 0.4481, 0.9743, 0.4838, 0.5101, 0.5968, 0.5122, 0.5754, 0.5337,\n                       0.5178, 0.9635, 0.5769, 0.5158, 0.4339, 0.4944, 0.5174, 0.4625, 0.4386,\n                       0.5609, 0.3584, 0.6455, 0.6388, 0.4783, 0.5368, 0.4515, 0.8100, 0.4061,\n                       0.6058, 0.6807, 0.4272, 0.4960, 0.6528, 0.3122, 0.3579, 0.4435, 0.4462,\n                       0.3739, 0.3873, 0.4284, 0.6245, 0.7770, 0.6576, 0.5415, 0.3675, 0.4883,\n                       0.3914, 0.5406, 0.3979, 0.5680, 0.4975, 0.3461, 0.5642, 0.6105, 0.5932,\n                       0.4501, 0.4644, 0.3569, 0.4302, 0.5252, 0.6265, 0.3949, 0.4440, 0.4124,\n                       0.4539, 0.4008, 0.4974, 0.5532, 0.4790, 0.3251, 0.4140, 0.3987, 0.5752,\n                       0.5144, 0.3899, 0.4746, 0.3851, 0.4323, 0.4412, 0.5095, 0.5279, 0.5934,\n                       0.4857, 0.6352, 0.4974, 0.4148, 0.5045, 0.4735, 0.5163, 0.4991, 0.5059,\n                       0.4003, 0.5180, 1.4220, 0.6492, 0.5917, 0.5635, 0.5079, 0.5366, 0.5789,\n                       0.4431, 0.5709, 0.3353, 0.4942, 0.4699, 0.5554, 0.5117, 0.4609, 0.5328,\n                       0.4932, 0.6690, 1.0811, 0.4668, 0.4526, 0.4837, 0.5562, 0.4811, 0.4980,\n                       0.4920, 0.6477, 0.3440, 0.4279, 0.4832, 0.6410, 0.6874, 0.9899, 0.4420,\n                       0.9252, 0.8556, 0.6898, 0.5062, 0.5957, 0.4006, 0.7129, 0.5360, 0.6052,\n                       0.4342, 0.5427, 0.5610, 0.4307, 0.3457, 0.4759, 0.6841, 0.3835, 0.5876,\n                       0.4629, 0.4034, 0.5576, 0.4629, 0.5652, 1.0431, 0.5121, 0.5440, 0.7764,\n                       0.5414, 1.6059, 0.5108, 1.3961, 0.3330, 0.5065, 0.5961, 0.8020, 0.4638,\n                       0.6268, 0.6585, 0.5442, 0.5054, 0.5451, 0.3225, 0.5285, 0.5203, 0.5392,\n                       0.5542, 0.3128, 0.4432, 0.3893, 0.7916, 0.5169, 0.6360, 0.4284, 0.4897,\n                       0.6012, 0.6006, 0.9036, 0.6581, 0.5583, 0.9188, 0.3751, 0.5809, 0.4827,\n                       0.7715, 0.5314, 0.5441, 0.6625, 0.4982, 0.6817, 0.7716, 0.4209, 0.5252,\n                       0.5545, 0.4365, 0.3738, 0.5795, 0.5287, 0.5217, 0.4099, 0.3681, 0.4072,\n                       0.4836, 0.8533, 0.5587, 0.4844, 0.6305, 0.3842, 0.5479, 0.4651, 0.4883,\n                       0.5215, 0.6344, 0.7429, 0.4564, 0.7836, 0.7994, 0.3556, 0.5093, 0.3639,\n                       0.4461, 0.5432, 0.4990, 0.5770, 0.5812, 0.4802, 0.4741, 0.7249, 0.5515,\n                       0.5571, 0.7748, 0.3747, 0.7033, 0.5729, 0.4656, 0.4415, 0.4736, 0.6589,\n                       0.4615, 0.5920, 0.8935, 0.4933, 0.5530, 0.5047, 0.4486, 0.8360, 0.5276,\n                       0.4515, 0.4467, 0.3040, 0.3643, 0.5939, 1.3708, 0.4920, 0.4992, 0.7965,\n                       0.5191, 0.4229, 0.6981, 0.6026, 0.5198, 0.5769, 0.5546, 0.2468, 0.5512,\n                       0.4750, 0.4231, 0.3804, 0.4883, 0.5337, 0.4353, 0.3879, 0.5610, 0.4008,\n                       0.6808, 1.1113, 0.6544, 0.4916, 0.9402, 0.7073, 0.3483, 0.7905, 0.4941,\n                       0.4429, 0.5718, 0.4618, 0.4543, 0.4053, 0.4932, 0.4124, 0.8597, 0.5214,\n                       0.3699, 0.2960, 0.3997, 0.4028, 0.6284, 0.6664, 0.5175, 0.4883, 0.4292,\n                       0.6129, 0.3627, 0.5100, 1.3062, 0.5229, 0.4875, 0.3844, 0.6333, 0.7493,\n                       0.5968, 0.4175, 0.4834, 0.6104, 0.9011, 0.4763, 0.4511, 0.4017, 0.3978,\n                       0.4338, 0.7361, 0.4839, 0.5907, 0.7015, 0.4738, 0.9034, 0.5973, 0.3462,\n                       0.6354, 0.5533, 0.6551, 0.5298, 0.4859, 0.5676, 0.4872, 0.5863, 0.6646,\n                       0.4392, 0.5772, 0.4965, 0.4728, 0.4612, 0.5272, 0.5785, 0.4328])),\n              ('layer4.1.bn2.num_batches_tracked', tensor(13572)),\n              ('layer4.1.conv3.weight',\n               tensor([[[[-0.0174]],\n               \n                        [[ 0.0062]],\n               \n                        [[ 0.0001]],\n               \n                        ...,\n               \n                        [[-0.0473]],\n               \n                        [[ 0.0116]],\n               \n                        [[ 0.0009]]],\n               \n               \n                       [[[-0.0500]],\n               \n                        [[-0.0112]],\n               \n                        [[-0.0174]],\n               \n                        ...,\n               \n                        [[-0.0090]],\n               \n                        [[ 0.0042]],\n               \n                        [[-0.0025]]],\n               \n               \n                       [[[-0.0244]],\n               \n                        [[-0.0313]],\n               \n                        [[-0.0248]],\n               \n                        ...,\n               \n                        [[ 0.0046]],\n               \n                        [[ 0.0284]],\n               \n                        [[-0.0070]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0102]],\n               \n                        [[-0.0040]],\n               \n                        [[-0.0166]],\n               \n                        ...,\n               \n                        [[ 0.0122]],\n               \n                        [[-0.0010]],\n               \n                        [[ 0.0133]]],\n               \n               \n                       [[[-0.0070]],\n               \n                        [[ 0.0033]],\n               \n                        [[-0.0021]],\n               \n                        ...,\n               \n                        [[ 0.0142]],\n               \n                        [[-0.0062]],\n               \n                        [[ 0.0079]]],\n               \n               \n                       [[[-0.0169]],\n               \n                        [[ 0.0013]],\n               \n                        [[-0.0022]],\n               \n                        ...,\n               \n                        [[ 0.0293]],\n               \n                        [[ 0.0033]],\n               \n                        [[-0.0146]]]])),\n              ('layer4.1.bn3.weight',\n               tensor([-0.4164,  0.3352,  0.3033,  ..., -0.0951, -0.3909, -0.2409])),\n              ('layer4.1.bn3.bias',\n               tensor([ 0.1512,  0.1370,  0.1110,  ..., -0.0325,  0.1400,  0.1030])),\n              ('layer4.1.bn3.running_mean',\n               tensor([-0.0932,  0.4550, -0.0505,  ..., -0.0808, -0.3848, -0.3258])),\n              ('layer4.1.bn3.running_var',\n               tensor([0.0559, 0.0444, 0.0482,  ..., 0.0444, 0.0551, 0.0547])),\n              ('layer4.1.bn3.num_batches_tracked', tensor(13572)),\n              ('layer4.2.conv1.weight',\n               tensor([[[[ 0.0159]],\n               \n                        [[ 0.0369]],\n               \n                        [[ 0.0104]],\n               \n                        ...,\n               \n                        [[ 0.0215]],\n               \n                        [[ 0.0257]],\n               \n                        [[ 0.0107]]],\n               \n               \n                       [[[-0.0441]],\n               \n                        [[ 0.0231]],\n               \n                        [[ 0.0267]],\n               \n                        ...,\n               \n                        [[-0.0099]],\n               \n                        [[ 0.0267]],\n               \n                        [[-0.0058]]],\n               \n               \n                       [[[ 0.0196]],\n               \n                        [[-0.0097]],\n               \n                        [[ 0.0101]],\n               \n                        ...,\n               \n                        [[ 0.0321]],\n               \n                        [[-0.0445]],\n               \n                        [[ 0.0273]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0118]],\n               \n                        [[-0.0345]],\n               \n                        [[ 0.0024]],\n               \n                        ...,\n               \n                        [[-0.0284]],\n               \n                        [[-0.0117]],\n               \n                        [[-0.0178]]],\n               \n               \n                       [[[-0.0309]],\n               \n                        [[ 0.0036]],\n               \n                        [[-0.0160]],\n               \n                        ...,\n               \n                        [[-0.0053]],\n               \n                        [[ 0.0034]],\n               \n                        [[ 0.0031]]],\n               \n               \n                       [[[ 0.0343]],\n               \n                        [[-0.0080]],\n               \n                        [[-0.0389]],\n               \n                        ...,\n               \n                        [[ 0.0111]],\n               \n                        [[-0.0145]],\n               \n                        [[ 0.0023]]]])),\n              ('layer4.2.bn1.weight',\n               tensor([0.9662, 0.9403, 0.9415, 1.0301, 0.9714, 0.9854, 0.9925, 0.9981, 0.9972,\n                       0.9975, 0.9877, 0.9848, 1.0019, 1.0004, 0.9854, 0.9980, 0.9240, 0.9919,\n                       0.9731, 0.9795, 0.9806, 0.9829, 0.9962, 1.0172, 1.0607, 1.1303, 0.9730,\n                       1.0055, 1.0307, 0.9512, 1.0338, 0.9987, 0.9568, 0.9727, 0.9889, 0.9518,\n                       1.0151, 0.9493, 1.0173, 0.9868, 1.0161, 0.9868, 1.0161, 0.9750, 0.9971,\n                       0.9406, 0.9863, 0.9982, 0.9688, 1.0058, 1.0081, 0.9378, 0.9608, 0.9748,\n                       0.9993, 0.9547, 1.0056, 0.9800, 1.0044, 0.9964, 0.9757, 0.9552, 0.9952,\n                       0.9802, 0.9841, 0.9558, 0.9958, 1.0385, 1.0071, 0.9871, 0.9648, 1.0067,\n                       0.9822, 1.0416, 0.9423, 0.9902, 0.9552, 0.9981, 0.9861, 1.0024, 0.9841,\n                       1.0259, 0.9961, 0.9426, 0.9708, 1.0238, 1.0097, 0.9975, 0.9812, 0.9658,\n                       0.9805, 0.9862, 0.9536, 0.9859, 0.9758, 1.0102, 0.9956, 0.9850, 0.9808,\n                       0.9989, 0.9634, 0.9719, 1.0010, 0.9720, 1.0067, 1.0254, 0.9673, 0.9769,\n                       1.0047, 1.0065, 0.9988, 0.9600, 0.9656, 0.9735, 0.9797, 1.0191, 1.0098,\n                       0.9739, 0.9682, 0.9843, 0.9639, 1.0079, 0.9640, 0.9786, 0.9926, 0.9734,\n                       0.9787, 0.9785, 0.9777, 0.9716, 0.9681, 1.0498, 0.9654, 0.9521, 1.0051,\n                       0.9786, 0.9680, 0.9870, 0.9989, 0.9664, 0.9908, 1.0127, 1.0007, 1.0107,\n                       1.0281, 0.9796, 1.0278, 0.9711, 0.9946, 0.9764, 1.0099, 0.9544, 0.9743,\n                       1.0068, 0.9936, 1.0040, 0.9879, 1.0000, 0.9990, 0.9763, 0.9767, 0.9923,\n                       1.0088, 1.0096, 1.0036, 0.9730, 0.9951, 1.0111, 0.9939, 1.0897, 1.0305,\n                       0.9923, 0.9658, 1.0115, 0.9921, 0.9848, 0.9517, 0.9805, 0.9850, 1.0051,\n                       0.9686, 0.9933, 0.9989, 1.0059, 0.9541, 0.9889, 1.0063, 1.0040, 0.9902,\n                       0.9862, 1.0033, 0.9851, 0.9644, 1.0001, 0.9857, 0.9996, 0.9880, 0.9673,\n                       0.9790, 0.9951, 0.9726, 1.0091, 0.9698, 0.9762, 0.9766, 1.0088, 0.9725,\n                       0.9500, 0.9824, 0.9746, 1.0187, 0.9662, 0.9521, 0.9708, 0.9584, 1.0195,\n                       0.9996, 0.9644, 0.9684, 0.9814, 0.9590, 1.0022, 0.9977, 0.9814, 1.0079,\n                       1.0134, 0.9412, 0.9870, 0.9941, 1.0009, 1.0212, 0.9528, 0.9948, 0.9951,\n                       1.0052, 0.9797, 0.9557, 1.0054, 0.9971, 0.9950, 0.9917, 0.9999, 0.9564,\n                       0.9891, 1.0010, 0.9979, 1.0188, 0.9644, 0.9658, 0.9897, 0.9932, 0.9833,\n                       0.9739, 1.0050, 0.9600, 1.0107, 1.0401, 0.9814, 1.0025, 1.0158, 1.0227,\n                       0.9596, 0.9922, 0.9811, 1.0062, 1.0003, 0.9831, 0.9894, 0.9952, 0.9930,\n                       0.9755, 0.9846, 1.0024, 0.9620, 0.9900, 0.9700, 0.9945, 0.9736, 0.9853,\n                       0.9829, 0.9846, 0.9953, 0.9716, 1.0429, 0.9698, 0.9859, 0.9793, 0.9994,\n                       0.9796, 0.9758, 0.9700, 0.9876, 0.9843, 0.9887, 0.9917, 1.0095, 0.9531,\n                       0.9983, 0.9954, 0.9625, 1.0072, 0.9909, 1.0048, 1.0064, 0.9511, 0.9972,\n                       0.9865, 0.9967, 0.9740, 0.9814, 1.0020, 1.0158, 0.9710, 0.9919, 0.9699,\n                       0.9827, 0.9636, 0.9919, 0.9858, 1.0333, 0.9506, 1.0002, 0.9662, 0.9934,\n                       1.0045, 1.0620, 1.0200, 0.9915, 1.0087, 0.9886, 0.9514, 0.9592, 0.9849,\n                       0.9879, 0.9659, 0.9963, 0.9996, 0.9434, 0.9702, 1.0224, 1.0026, 0.9980,\n                       1.0499, 0.9765, 1.0251, 0.9184, 0.9950, 1.0076, 0.9522, 1.0084, 0.9892,\n                       0.9805, 0.9380, 1.0180, 1.0083, 0.9944, 1.0247, 0.9867, 1.0016, 0.9811,\n                       1.0040, 1.0030, 1.0017, 0.9744, 0.9907, 0.9927, 0.9816, 1.0231, 0.9973,\n                       1.0146, 0.9689, 0.9588, 0.9822, 1.0011, 0.9585, 1.0013, 0.9655, 0.9791,\n                       0.9664, 0.9862, 0.9500, 0.9975, 0.9382, 0.9819, 0.9894, 0.9453, 0.9977,\n                       0.9716, 0.9906, 0.9955, 0.9546, 0.9538, 0.9786, 0.9801, 0.9976, 1.0255,\n                       0.9919, 0.9664, 0.9671, 0.9708, 0.9673, 0.9806, 0.9937, 0.9918, 1.0439,\n                       1.0356, 0.9868, 1.0356, 0.9927, 1.0187, 1.0032, 1.0148, 1.0121, 1.0274,\n                       1.0074, 1.0019, 0.9992, 0.9947, 0.9912, 0.9711, 0.9954, 1.0004, 0.9810,\n                       0.9958, 1.0015, 0.9445, 0.9664, 0.9659, 0.9970, 0.9951, 1.0164, 0.9770,\n                       0.9654, 1.0502, 1.0039, 0.9986, 0.9735, 0.9442, 0.9933, 0.9882, 1.0013,\n                       0.9826, 0.9799, 0.9938, 0.9492, 0.9709, 0.9611, 0.9821, 0.9947, 0.9844,\n                       0.9760, 0.9714, 0.9927, 0.9874, 1.0115, 1.0095, 0.9944, 0.9940, 1.0000,\n                       1.0052, 0.9690, 0.9926, 0.9979, 0.9877, 1.0194, 1.0073, 0.9848, 0.9856,\n                       0.9757, 1.0014, 0.9734, 0.9819, 1.0109, 0.9835, 1.0131, 0.9700, 1.0243,\n                       0.9829, 0.9491, 0.9946, 0.9639, 0.9757, 0.9553, 1.0084, 1.0119, 1.0067,\n                       0.9554, 0.9670, 1.0105, 0.9759, 0.9732, 0.9923, 0.9878, 0.9728, 0.9763,\n                       0.9769, 1.0122, 0.9680, 1.0081, 0.9875, 1.0020, 0.9377, 0.9869, 0.9727,\n                       0.9691, 0.9794, 0.9875, 0.9630, 0.9495, 0.9695, 1.0049, 0.9559])),\n              ('layer4.2.bn1.bias',\n               tensor([-0.1325, -0.1578, -0.1297, -0.1377, -0.1706, -0.1849, -0.1024, -0.1881,\n                       -0.1486, -0.1363, -0.1287, -0.1638, -0.1504, -0.1181, -0.1354, -0.1296,\n                       -0.1168, -0.1248, -0.1570, -0.1364, -0.2167, -0.2168, -0.1307, -0.1687,\n                       -0.0815, -0.0909, -0.1037, -0.1456, -0.0807, -0.0872, -0.2266, -0.1530,\n                       -0.1398, -0.1639, -0.3725, -0.1745, -0.1107, -0.1684, -0.1462, -0.1186,\n                       -0.1398, -0.1507, -0.1556, -0.1568, -0.1158, -0.0249, -0.1191, -0.1593,\n                       -0.1482, -0.1598, -0.1381, -0.1935, -0.1196, -0.1141, -0.1898, -0.1284,\n                       -0.1555, -0.1797, -0.2403, -0.1361, -0.1910, -0.1153, -0.1750, -0.1524,\n                       -0.1688, -0.0268, -0.1776, -0.1846, -0.1409, -0.0979, -0.1701, -0.0963,\n                       -0.1655, -0.2505, -0.3004, -0.1251, -0.0925, -0.1406, -0.1317, -0.1316,\n                       -0.1134, -0.0991, -0.1141, -0.1670, -0.1488, -0.1350, -0.1002, -0.0952,\n                       -0.1409, -0.1441, -0.1980, -0.1056, -0.1636, -0.1408, -0.1733, -0.1106,\n                       -0.1581, -0.1245, -0.1299, -0.0950, -0.1020, -0.1553, -0.1393, -0.1277,\n                       -0.1136, -0.3002, -0.1038, -0.0936, -0.2103, -0.1807, -0.1618, -0.1643,\n                       -0.1820, -0.1396, -0.1839, -0.2738, -0.1285, -0.1120, -0.2275, -0.1540,\n                       -0.2079, -0.2180, -0.1642, -0.1409, -0.0887, -0.2210, -0.1109, -0.1357,\n                       -0.2967, -0.1225, -0.1578, -0.1990, -0.1016, -0.1539, -0.2896, -0.1371,\n                       -0.1741, -0.1064, -0.1713, -0.1849, -0.1173, -0.1180, -0.1885, -0.1406,\n                       -0.1459, -0.0934, -0.0842, -0.1356, -0.1946, -0.1170, -0.1377, -0.0858,\n                       -0.1274, -0.1493, -0.1111, -0.1184, -0.1615, -0.1647, -0.1461, -0.1520,\n                       -0.1057, -0.1619, -0.1446, -0.2284, -0.2183, -0.1753, -0.1745, -0.0880,\n                       -0.1579, -0.0757, -0.1154, -0.1549, -0.1494, -0.1945, -0.1547, -0.1232,\n                       -0.1303, -0.1203, -0.1378, -0.1667, -0.1180, -0.0803, -0.1956, -0.1838,\n                       -0.0982, -0.2010, -0.2114, -0.1251, -0.1418, -0.1466, -0.2013, -0.1424,\n                       -0.1838, -0.1572, -0.1341, -0.1559, -0.1015, -0.2288, -0.1344, -0.1298,\n                       -0.1706, -0.1425, -0.1386, -0.1335, -0.1001, -0.1541, -0.0835, -0.0443,\n                       -0.1383, -0.1722, -0.2113, -0.1698, -0.1736, -0.1087, -0.1105, -0.0634,\n                       -0.2100, -0.1195, -0.1355, -0.2017, -0.1351, -0.1756, -0.1646, -0.1767,\n                       -0.1574, -0.1299, -0.0512, -0.0526, -0.1219, -0.1146, -0.0520, -0.1194,\n                       -0.1335, -0.1701, -0.1631, -0.1985, -0.1725, -0.2184, -0.1568, -0.1372,\n                       -0.2711, -0.1468, -0.0879, -0.1219, -0.1507, -0.1126, -0.1676, -0.1642,\n                       -0.1441, -0.1224, -0.0880, -0.1344, -0.1685, -0.1405, -0.1858, -0.2085,\n                       -0.0706, -0.1428, -0.1679, -0.1408, -0.0998, -0.1421, -0.2042, -0.2252,\n                       -0.1414, -0.1029, -0.0835, -0.1605, -0.1619, -0.2080, -0.1329, -0.2409,\n                       -0.0897, -0.1420, -0.0358, -0.1618, -0.1487, -0.1432, -0.1994, -0.1284,\n                       -0.1723, -0.1699, -0.2143, -0.1655, -0.1366, -0.1065, -0.1412, -0.1379,\n                       -0.1720, -0.1297, -0.1700, -0.0974, -0.1161, -0.1857, -0.1258, -0.2020,\n                       -0.1921, -0.1337, -0.1747, -0.1720, -0.0767, -0.2170, -0.1785, -0.1845,\n                       -0.0640, -0.0919, -0.1367, -0.1863, -0.2471, -0.1541, -0.1438, -0.1634,\n                       -0.1658, -0.0933, -0.1273, -0.1462, -0.0946, -0.1084, -0.1891, -0.2999,\n                       -0.1781, -0.0715, -0.2290, -0.1229, -0.1100, -0.0478, -0.1050, -0.0803,\n                       -0.1822, -0.1894, -0.1664, -0.0730, -0.1330, -0.1433, -0.1412, -0.1300,\n                       -0.0857,  0.0083, -0.1446, -0.3181, -0.1379, -0.1432, -0.0896, -0.1280,\n                       -0.1225, -0.1869, -0.1617, -0.0759, -0.1354, -0.2257, -0.1660, -0.1533,\n                       -0.0718, -0.2244, -0.0748, -0.1581, -0.0917, -0.1728, -0.0907, -0.1275,\n                       -0.1273, -0.0799, -0.1494, -0.1098, -0.1165, -0.1291, -0.1540, -0.0835,\n                       -0.1458, -0.2178, -0.2143, -0.1243, -0.1630, -0.2316, -0.1602, -0.1496,\n                       -0.1323, -0.1356, -0.1365, -0.1821, -0.1461, -0.1521, -0.1932, -0.1964,\n                       -0.1205, -0.1642, -0.1264, -0.1787, -0.1134, -0.1800, -0.0758, -0.1539,\n                       -0.1678, -0.0961, -0.1256, -0.0902, -0.1394, -0.1841, -0.0854, -0.1390,\n                       -0.1477, -0.1359, -0.1705, -0.1142, -0.2447, -0.1036, -0.2075, -0.1931,\n                       -0.1986, -0.1618, -0.1688, -0.1981, -0.1513, -0.1103, -0.0901, -0.1439,\n                       -0.0999, -0.1961, -0.2572, -0.1257, -0.1300, -0.1378, -0.0881, -0.1865,\n                       -0.2015, -0.2241, -0.1726, -0.1186, -0.1189, -0.1477, -0.0951, -0.1849,\n                       -0.1040, -0.0450, -0.1519, -0.1365, -0.1556, -0.1368, -0.0967, -0.1626,\n                       -0.2683, -0.1961, -0.1320, -0.1064, -0.0946, -0.2111, -0.1788, -0.1195,\n                       -0.0998, -0.1051, -0.1542, -0.0970, -0.1391, -0.0672, -0.3001, -0.1852,\n                       -0.1429, -0.1085, -0.1875, -0.1358, -0.1558, -0.1869, -0.1513, -0.2098,\n                       -0.1185, -0.1288, -0.1030, -0.2137, -0.1635, -0.1055, -0.1729, -0.1291,\n                       -0.1112, -0.1604, -0.1721, -0.1633, -0.1012, -0.0880, -0.2553, -0.1252,\n                       -0.1612, -0.1020, -0.1499, -0.0806, -0.1273, -0.1983, -0.1643, -0.1469,\n                       -0.0807, -0.2072, -0.2225, -0.0853, -0.1292, -0.1706, -0.1720, -0.1994,\n                       -0.1127, -0.1589, -0.2188, -0.0752, -0.0610, -0.1414, -0.1510, -0.1040,\n                       -0.1429, -0.1340, -0.1447, -0.2008, -0.1561, -0.1519, -0.1067, -0.1932])),\n              ('layer4.2.bn1.running_mean',\n               tensor([-1.8462e+00,  1.9188e+00, -1.2828e+00,  4.1242e+00,  1.1955e+00,\n                       -3.2292e+00, -2.1979e+00,  3.9472e+00,  3.1145e+00,  6.3659e-01,\n                        2.2427e+00,  6.0725e+00,  4.0638e+00,  4.2409e+00, -2.3772e+00,\n                        4.9325e-01, -9.8278e+00, -1.5078e+00, -2.6726e+00, -3.3938e+00,\n                        6.8078e-01, -1.7993e-01,  2.3158e+00, -2.5404e+00,  1.0679e+01,\n                        1.2752e+01, -4.5529e+00,  2.2932e+00,  9.9250e+00, -1.0849e+01,\n                       -1.1985e-01, -2.5235e+00, -2.7471e+00, -2.2011e+00, -1.5184e+00,\n                        1.6149e+00,  2.4384e+00, -1.0094e+00, -1.0837e+00, -9.5933e+00,\n                       -2.1727e+00,  1.0365e+00, -4.3391e+00,  4.0204e-01,  3.9500e+00,\n                       -1.0566e+01, -7.9940e-01,  2.0919e+00, -2.3844e+00, -1.4309e+00,\n                       -1.0689e+00, -2.1874e+00, -4.8741e+00,  8.1573e-01,  5.6459e-01,\n                        5.4090e+00, -1.0734e-01,  4.3574e-01, -1.4475e+00,  7.7708e-01,\n                        2.9408e+00,  1.6768e+00,  1.1885e+00,  1.4652e+00, -7.2693e-01,\n                       -1.4407e+01, -6.1653e-01,  2.4017e+00,  2.4520e+00, -3.4245e+00,\n                        3.2139e+00, -5.4716e-01,  1.8490e+00,  1.2295e+00, -3.8177e+00,\n                       -8.9547e-01, -4.1349e+00, -5.1644e-01,  2.8165e+00,  4.1581e-01,\n                        6.5708e-01,  5.4668e+00,  6.3642e+00, -4.9411e+00,  3.7985e+00,\n                       -2.0515e-01,  4.0868e+00,  1.6979e+00,  3.2683e+00, -1.8120e+00,\n                        5.5311e-01,  1.6457e+00,  4.1575e-02,  3.6912e+00,  1.2063e+00,\n                       -6.6034e+00,  2.4805e-01,  3.1843e+00, -6.4827e-01, -7.0107e+00,\n                        3.1832e+00, -1.0201e+00,  3.0983e+00, -1.3305e+00, -2.0632e+00,\n                       -3.8667e+00,  3.5308e+00,  5.3645e+00, -3.3613e+00,  1.4185e+00,\n                       -2.0606e-01, -8.6371e-01,  1.4520e+00,  6.6787e-01, -1.0039e+00,\n                       -1.8928e+00,  4.5958e+00,  1.0983e+00,  6.5759e-01,  2.3983e-01,\n                       -2.9896e+00, -1.6791e+00, -4.0412e-01, -4.3700e+00,  6.9736e+00,\n                        4.0111e+00,  2.3892e+00, -3.8562e-01,  1.3087e+00,  1.4979e+00,\n                       -9.4732e-01,  3.0395e+00, -9.0788e-01,  1.0509e+00,  1.4042e+00,\n                        5.7057e+00, -3.9076e+00,  2.8047e+00,  1.8183e+00, -1.1569e+00,\n                       -2.3340e+00,  3.3572e+00,  2.2477e+00, -9.2448e+00, -2.0526e+00,\n                        1.3375e+00,  9.3122e+00,  1.7097e+00, -2.9498e+00,  3.0870e+00,\n                        8.1625e+00,  3.7887e+00,  3.6037e+00, -2.1422e+00, -5.6970e+00,\n                        5.4510e+00, -3.6532e+00,  9.8003e-01, -1.8187e+00,  7.0180e-01,\n                       -2.5691e+00, -1.2215e+00, -3.4327e+00, -2.1336e+00, -1.6346e+00,\n                        8.7320e-01,  2.4740e-01,  8.1411e+00, -1.0795e+00,  1.0388e+01,\n                        5.9150e+00,  4.5520e-01, -3.9243e+00, -4.1931e-01,  7.7903e+00,\n                        6.3172e+00, -2.5406e+00,  2.5241e+00, -2.2475e+00, -3.3592e+00,\n                        3.7293e-01,  2.2917e+00,  1.2558e+00, -8.5512e-01,  1.6110e+00,\n                        3.3332e-01,  1.1408e+00,  7.4379e+00,  2.0240e+00, -1.6672e+00,\n                        1.7780e+00,  3.8875e+00,  9.2770e-01,  2.0639e-01, -1.1264e+00,\n                        2.4209e+00,  3.6129e+00, -6.9315e-01,  6.4110e-01, -7.5747e-02,\n                        3.5821e-01,  1.2975e+00, -4.2026e+00,  2.8309e+00,  3.2176e+00,\n                       -8.1081e+00, -3.7152e-01, -1.3625e+01, -1.1221e-01,  4.3993e+00,\n                       -4.2086e-01, -3.7974e-01, -1.1920e+00,  2.9282e+00, -7.0938e+00,\n                        5.2800e+00, -1.4583e+00,  3.0088e+00,  5.6442e+00, -5.3912e-02,\n                       -3.7779e+00,  2.4753e+00, -1.1045e+00, -6.7020e-01, -4.6113e+00,\n                        4.1455e+00, -6.8390e+00, -5.2837e+00,  2.0187e+00,  1.4282e+00,\n                        1.0368e+01,  2.4861e+00, -9.4488e+00,  7.7570e-03,  4.9407e+00,\n                       -1.5478e+00, -3.5611e-02, -1.7368e+00,  3.1200e+00,  5.6620e-01,\n                        1.1156e+00, -1.4891e+00, -8.9448e-01,  2.0489e+00,  6.2859e+00,\n                        4.3343e+00,  2.3088e+00,  7.1583e-01, -1.3074e+00, -3.9736e-01,\n                       -8.7074e+00,  3.8245e+00, -2.0988e+00,  7.7656e-01, -2.3970e+00,\n                        3.6188e+00,  1.3496e+01,  8.1550e-01, -2.2183e+00, -5.9362e+00,\n                        9.1185e+00,  2.2991e+00,  2.6717e-01, -2.9920e+00,  1.2942e+00,\n                        4.7846e+00,  4.8971e+00, -2.7379e+00,  3.4551e-01, -3.8009e+00,\n                       -4.1875e+00, -7.7665e-01,  8.3912e+00, -5.0639e+00, -7.5446e+00,\n                        2.2431e+00,  2.2901e+00,  2.5242e+00,  9.4004e-01,  9.6035e-01,\n                        1.2069e+00,  3.4281e-01,  2.6695e+00, -3.0204e+00,  2.2841e+00,\n                        1.8653e+00, -2.6209e+00,  3.5193e+00,  4.3373e-02,  4.0553e+00,\n                        8.7078e-01,  7.3316e-02,  5.7722e+00,  1.3520e+00,  1.2062e+00,\n                        8.1163e-02, -2.2597e+00,  2.9467e+00, -9.6181e-01, -2.8677e+00,\n                        8.4100e+00, -4.0454e-01, -1.0283e+00, -3.4330e+00, -7.2012e+00,\n                        6.8269e+00,  7.7001e-01, -1.9784e+00, -3.1666e+00, -5.2414e+00,\n                        6.6285e+00,  4.6451e+00,  2.2603e+00,  3.4362e+00,  7.4423e+00,\n                       -3.0001e+00,  2.7002e+00,  6.6697e+00, -9.2906e-01, -2.2998e+00,\n                        9.5211e-01,  2.7023e+00, -2.2524e+00,  5.7264e+00,  2.4447e+00,\n                        1.2679e+01,  4.4938e+00,  5.9026e+00, -1.1671e+00,  2.7766e-01,\n                       -6.5696e-01, -5.7499e+00, -1.1105e+00,  4.3320e-01, -7.1990e-01,\n                        1.9505e+00, -3.1663e+00, -1.7249e+01,  3.7375e+00, -1.2757e+00,\n                       -3.6227e+00,  1.9119e+00,  1.1644e+01, -3.4017e+00,  4.0930e-01,\n                        1.8313e+00,  2.7935e+00,  7.1123e+00, -1.2528e+00, -2.1188e+00,\n                       -5.3605e-01, -1.9415e-01, -7.0863e+00,  1.4608e+00, -1.3254e+00,\n                       -3.8967e-01, -5.7695e+00, -5.6197e-02,  4.0936e+00, -7.3033e-01,\n                        1.0760e+00,  1.9934e+00,  4.0428e+00,  4.2073e+00, -5.8246e+00,\n                        1.3670e+00,  2.2502e+00,  2.8918e+00,  1.6958e+00,  6.3913e-01,\n                       -1.1010e-01, -1.7698e+00, -3.9755e+00, -9.8264e-01, -5.6551e-03,\n                        2.0876e+00,  2.7410e+00,  1.1316e+00, -1.1588e+00, -3.3695e+00,\n                       -4.9717e+00,  4.2134e+00, -2.2402e+00, -1.1199e+00,  6.5583e-01,\n                        1.3866e+00,  2.3993e+00, -1.5131e+00,  1.1061e-01, -4.4351e+00,\n                       -2.7862e+00,  4.5318e+00, -3.0850e+00, -2.8647e+00,  1.0950e+00,\n                        3.7384e+00, -2.7248e-01,  8.5393e-01, -5.1182e+00, -1.7567e+00,\n                        1.9201e+00,  4.2624e+00,  2.2676e+00,  6.6399e+00, -1.8147e+00,\n                        8.1365e+00,  7.7375e-02, -3.4344e+00,  3.2682e-01,  1.2849e+00,\n                       -2.1663e-01, -1.4904e+00,  1.1479e+00,  7.4064e+00,  7.5477e+00,\n                        3.8204e+00,  5.4689e+00,  9.1144e-01,  9.1018e-01,  2.2816e+00,\n                       -1.4128e+00,  4.4878e+00,  1.4513e+00,  4.9841e-01, -1.7722e+00,\n                       -7.7576e-01, -8.9065e-03,  1.5249e+00,  4.9028e-01, -1.0526e+00,\n                       -2.3154e+00,  2.5430e+00,  5.2495e+00,  1.3357e+01, -5.8356e+00,\n                        2.5230e+00,  7.6370e+00, -1.3821e+00, -8.4759e+00, -4.3109e+00,\n                        4.4498e-01,  4.7015e+00,  3.2316e+00,  5.8001e+00, -1.9023e-01,\n                       -1.9863e+00,  1.5769e-01, -1.8808e+00, -8.3062e-02,  3.8396e+00,\n                        9.5196e-01,  6.1969e+00, -3.6335e+00, -7.0396e-02, -1.9078e+00,\n                        1.6849e+00,  5.6244e+00, -1.2272e+00,  6.5013e-01, -1.1395e+00,\n                       -3.9091e+00,  2.0602e+00,  4.9243e+00, -3.4369e+00,  2.4224e+00,\n                        8.3156e-01, -2.6874e-01, -8.4357e-02,  4.4103e-01,  2.3441e+00,\n                       -9.4897e-01,  1.6481e+00,  4.3769e+00,  5.9994e-01,  6.9579e-01,\n                       -4.1876e-01,  3.4209e-01,  6.1510e+00,  9.1949e-01,  3.6138e-01,\n                       -9.3671e-01,  1.6642e-01,  4.4948e+00,  1.3376e+01,  7.1462e+00,\n                        2.4673e+00, -3.7039e-01, -3.5368e+00, -7.5654e+00,  2.8541e+00,\n                        9.2516e-01, -1.3898e+00,  5.5051e+00,  3.9162e-01,  3.0735e+00,\n                       -3.9105e+00,  8.7603e+00,  3.7541e+00, -7.8930e-01,  3.2092e+00,\n                       -7.4624e+00,  2.4494e+00, -1.1514e+00,  4.8881e+00,  1.5329e+00,\n                       -2.5386e+00,  5.9887e-01, -4.4534e+00, -2.3370e-01, -2.3905e+00,\n                       -5.3899e-01, -2.7737e-01])),\n              ('layer4.2.bn1.running_var',\n               tensor([2.9457, 2.6880, 2.7992, 2.2999, 2.7966, 3.4504, 2.6561, 2.2968, 2.7779,\n                       2.6385, 2.7470, 2.8374, 2.5182, 2.5171, 3.4092, 2.8358, 4.0167, 3.1411,\n                       2.5009, 3.4172, 2.8676, 2.6785, 2.7075, 3.2523, 3.3085, 5.0549, 2.9589,\n                       2.7235, 3.5726, 5.5759, 4.1199, 3.0536, 2.6630, 2.4992, 5.2341, 3.3886,\n                       2.5598, 2.9719, 2.7644, 5.5910, 3.2206, 2.6459, 3.3956, 2.8655, 2.2442,\n                       5.3580, 2.5555, 2.5528, 3.2773, 2.8383, 2.3562, 3.1153, 3.3791, 2.5528,\n                       2.8409, 2.3979, 2.7255, 3.2776, 5.2696, 3.5428, 3.6525, 2.5367, 2.6763,\n                       2.5731, 2.3837, 5.5608, 2.7829, 2.5018, 2.8210, 3.3766, 2.6953, 2.9592,\n                       2.4377, 3.1146, 3.7925, 3.1679, 2.7987, 2.8873, 2.1694, 2.8928, 2.4616,\n                       2.9497, 2.5307, 3.3241, 3.0018, 3.2021, 3.9737, 2.9286, 2.9230, 2.7657,\n                       2.8421, 2.8252, 2.4466, 2.3045, 3.0133, 3.1449, 2.5291, 2.4198, 2.8478,\n                       4.1467, 2.5180, 2.9972, 2.9667, 3.1207, 3.1286, 4.8759, 2.9947, 2.6705,\n                       3.8907, 2.8103, 2.9901, 3.3451, 2.4055, 3.3848, 2.5703, 2.8655, 2.8600,\n                       2.5240, 2.5906, 2.8497, 4.0248, 3.1109, 2.8786, 3.3737, 3.6240, 2.7102,\n                       2.3682, 2.4684, 2.4647, 2.8014, 3.2614, 4.1644, 3.8290, 2.6624, 2.6555,\n                       2.6848, 3.0376, 2.5366, 2.8785, 2.5271, 3.2365, 2.5304, 3.5199, 6.3381,\n                       3.6001, 2.7408, 2.8608, 2.3969, 3.3069, 2.9268, 3.1484, 2.8805, 2.6517,\n                       2.6934, 2.7584, 2.6852, 3.1511, 2.8762, 2.9343, 2.6998, 3.5093, 2.8329,\n                       3.3051, 3.3155, 2.7516, 2.6117, 2.9399, 3.5940, 3.5089, 5.5967, 2.8461,\n                       2.9965, 3.4046, 3.0355, 2.7877, 2.7747, 3.6647, 2.7359, 2.9006, 3.3779,\n                       2.5589, 2.7567, 3.0818, 3.0190, 3.3075, 2.9823, 2.9910, 3.8401, 2.6720,\n                       3.0876, 3.0886, 3.0987, 2.9992, 2.9210, 3.0189, 2.7083, 2.9247, 2.3931,\n                       2.2879, 2.9590, 2.6110, 3.5610, 3.5903, 2.3578, 2.5359, 3.5319, 2.2867,\n                       6.8989, 2.4809, 3.0173, 3.0506, 2.9307, 2.8304, 2.9591, 4.1815, 2.7282,\n                       3.3678, 2.7727, 2.6778, 2.8133, 3.0395, 2.8100, 3.0463, 2.8856, 3.6749,\n                       3.4756, 3.7221, 3.0804, 2.3927, 3.2463, 3.2212, 3.7676, 4.3254, 2.1990,\n                       2.4678, 3.4446, 2.4691, 2.8356, 2.7615, 4.3200, 2.9329, 2.9212, 3.3043,\n                       2.6683, 3.1344, 2.3931, 2.6200, 3.2264, 2.4276, 2.4929, 3.7420, 2.6097,\n                       2.2879, 2.4663, 2.8689, 2.6531, 4.1112, 2.8333, 3.1912, 3.6722, 3.0396,\n                       2.5070, 2.3734, 3.5619, 2.9024, 4.1813, 2.4480, 2.5549, 2.8888, 3.2285,\n                       3.5727, 2.2241, 2.5028, 2.5169, 6.0611, 2.5997, 2.1673, 2.6536, 3.0368,\n                       2.5470, 3.3421, 2.5210, 3.1648, 2.8084, 2.4014, 2.4305, 2.6020, 3.0314,\n                       3.0456, 2.6640, 2.7635, 2.8849, 2.7348, 2.4319, 3.3855, 2.7829, 2.4252,\n                       2.7572, 3.9877, 2.8089, 3.2682, 2.4529, 2.8488, 2.7018, 3.2347, 3.4758,\n                       2.7422, 2.7645, 4.6444, 2.9664, 3.1817, 2.6361, 2.4892, 2.4998, 3.6789,\n                       2.7538, 2.8738, 2.5801, 3.2247, 3.9227, 2.1171, 2.7541, 3.1421, 2.5526,\n                       2.7147, 4.5190, 2.4778, 2.8232, 3.4109, 2.4339, 3.2916, 3.3365, 2.3314,\n                       2.8819, 3.3926, 2.4824, 3.4196, 8.8778, 2.5956, 3.9479, 4.1728, 3.2223,\n                       3.8207, 3.3132, 2.4973, 2.8014, 2.9311, 2.9786, 3.0495, 3.4170, 2.7869,\n                       2.7463, 4.4373, 2.9461, 3.4436, 3.6690, 3.5022, 3.1767, 2.6621, 2.7879,\n                       2.7635, 2.5768, 3.1263, 3.1618, 3.9569, 2.7416, 2.7169, 2.8291, 2.6819,\n                       2.8829, 2.6264, 2.9658, 3.1189, 2.6307, 2.4570, 2.6099, 2.4546, 2.7764,\n                       3.3783, 2.7923, 2.9735, 2.4319, 2.7964, 2.3717, 2.3637, 2.5131, 2.1857,\n                       2.3847, 2.9194, 3.2682, 2.6264, 2.7029, 3.2907, 2.7756, 2.5803, 2.6733,\n                       2.5398, 2.9215, 2.8689, 2.6041, 2.6618, 2.3500, 2.3278, 2.7882, 3.3765,\n                       3.5136, 3.1949, 4.3068, 3.3566, 2.5504, 3.0240, 3.2656, 2.9423, 3.1883,\n                       2.9605, 2.4095, 2.7982, 2.5925, 2.6567, 2.6376, 2.8967, 2.8119, 3.0886,\n                       3.0995, 2.7266, 2.2493, 3.2039, 2.8422, 2.5720, 2.6561, 3.1872, 3.2812,\n                       2.5038, 3.4017, 2.9673, 2.4052, 2.7648, 2.9501, 4.6705, 2.9360, 3.7407,\n                       2.7946, 2.8478, 3.9692, 2.6001, 2.9134, 2.5961, 2.5001, 2.8808, 2.4517,\n                       2.3154, 3.0140, 3.3527, 3.0987, 3.7671, 2.8905, 2.3666, 2.6975, 2.4409,\n                       3.1705, 3.5387, 3.1747, 3.2917, 2.9914, 2.5717, 3.1703, 3.0299, 3.1149,\n                       3.1326, 2.7029, 3.0675, 2.8335, 2.8371, 2.5727, 3.1418, 3.4540, 3.5055,\n                       2.7692, 2.9767, 3.5722, 2.5060, 2.5794, 2.7233, 3.8803, 2.8820, 2.6185,\n                       2.2461, 2.5870, 4.3656, 2.9886, 2.5309, 2.9377, 2.6082, 2.3838, 2.6848,\n                       3.0751, 3.1519, 2.8720, 2.8759, 2.8383, 3.2239, 2.9387, 2.2654, 2.6853,\n                       2.8284, 3.5976, 2.6708, 3.8073, 2.3514, 2.4167, 2.3595, 2.5709])),\n              ('layer4.2.bn1.num_batches_tracked', tensor(13572)),\n              ('layer4.2.conv2.weight',\n               tensor([[[[-5.4313e-03, -6.1212e-03, -5.9463e-03],\n                         [-1.3813e-02,  6.8097e-03, -3.6475e-03],\n                         [ 1.1884e-02,  1.2626e-02,  2.5088e-02]],\n               \n                        [[-6.0596e-03, -5.0874e-03,  2.3577e-02],\n                         [-4.6939e-03, -3.5857e-02,  5.1242e-03],\n                         [ 2.6471e-03, -2.0945e-03,  5.7878e-03]],\n               \n                        [[ 5.4481e-03, -1.6601e-02, -2.2032e-02],\n                         [-5.1409e-03, -1.4619e-02, -7.5598e-03],\n                         [ 1.0366e-02, -6.9306e-03, -2.2434e-02]],\n               \n                        ...,\n               \n                        [[-1.6628e-02, -6.9355e-03, -3.8977e-02],\n                         [-1.8178e-02, -1.1833e-02, -9.1024e-04],\n                         [-2.2077e-03, -2.5337e-02, -9.2663e-03]],\n               \n                        [[-1.3622e-02, -3.3937e-03,  1.2224e-02],\n                         [ 1.1831e-02,  1.4324e-02, -7.0219e-03],\n                         [ 7.3073e-03,  4.5922e-03, -1.4338e-02]],\n               \n                        [[-1.5212e-02, -7.0712e-03,  6.4126e-03],\n                         [-2.0908e-03,  6.5496e-06, -9.1736e-03],\n                         [ 7.9628e-03, -1.2917e-02,  7.5000e-03]]],\n               \n               \n                       [[[-1.1313e-02,  8.7336e-03,  1.1766e-02],\n                         [ 1.0913e-02,  2.0692e-02, -1.0071e-02],\n                         [ 7.2105e-04,  4.0588e-03,  3.4466e-03]],\n               \n                        [[ 3.7382e-03, -1.6288e-02, -5.0445e-03],\n                         [ 1.3956e-02,  1.2841e-02, -1.2720e-02],\n                         [ 1.8322e-02,  7.0590e-03,  1.5569e-03]],\n               \n                        [[ 9.3194e-03,  2.0071e-02, -5.2004e-03],\n                         [-1.0445e-02,  2.2615e-03,  1.6937e-02],\n                         [ 1.8544e-02,  5.2886e-03, -2.1268e-02]],\n               \n                        ...,\n               \n                        [[ 8.8684e-04, -1.8960e-02,  5.6588e-04],\n                         [-3.8270e-02, -5.0401e-02, -3.8719e-02],\n                         [-2.0155e-02, -2.4402e-02, -3.6199e-02]],\n               \n                        [[-1.9440e-02, -1.3711e-02, -1.3848e-02],\n                         [ 1.4073e-03, -1.7589e-02, -1.1543e-02],\n                         [-2.4848e-02,  1.4455e-02,  2.5170e-03]],\n               \n                        [[-3.7067e-03,  2.1567e-02, -1.4167e-03],\n                         [ 1.9965e-02,  4.0859e-02,  7.3107e-03],\n                         [ 1.5593e-02, -1.8571e-03,  8.5488e-03]]],\n               \n               \n                       [[[-8.2136e-03, -9.2013e-03, -1.2828e-02],\n                         [-3.2742e-03, -4.5831e-03, -2.5345e-03],\n                         [ 4.5231e-02, -6.0064e-03,  9.7275e-03]],\n               \n                        [[ 2.0721e-03, -1.7613e-02, -2.2579e-02],\n                         [-9.0657e-03, -1.7596e-02, -1.5345e-02],\n                         [ 1.1892e-03,  4.6185e-03, -1.3376e-02]],\n               \n                        [[-7.0413e-03,  3.4257e-03,  8.6493e-03],\n                         [-6.6419e-03, -1.4148e-02,  9.0629e-03],\n                         [ 2.6104e-03, -1.3856e-03, -9.0957e-03]],\n               \n                        ...,\n               \n                        [[-1.6304e-03,  2.2292e-02,  3.0810e-04],\n                         [ 2.7023e-02,  2.8900e-02,  2.0203e-02],\n                         [ 1.0574e-02, -7.0783e-03, -2.9547e-03]],\n               \n                        [[-4.3899e-03,  2.8481e-03,  2.2529e-02],\n                         [ 6.2458e-03,  2.5318e-02,  4.7105e-03],\n                         [ 2.1632e-02,  1.8353e-02,  1.1486e-02]],\n               \n                        [[-1.2317e-05,  4.8571e-03, -2.3052e-02],\n                         [-1.0582e-02, -2.7651e-02, -1.8776e-02],\n                         [ 6.8374e-04, -1.0729e-02,  4.4788e-03]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 1.0997e-02,  1.0336e-02,  2.8882e-03],\n                         [ 2.0397e-02,  1.9750e-02,  2.0567e-02],\n                         [ 2.2801e-02, -3.5276e-03,  2.3686e-02]],\n               \n                        [[-3.5811e-03,  8.3554e-04, -9.5043e-03],\n                         [-1.1444e-02,  7.0398e-03,  7.5855e-03],\n                         [-1.8793e-03,  4.0214e-03, -6.1461e-03]],\n               \n                        [[-3.2397e-03,  9.5338e-03, -1.1852e-03],\n                         [-6.5121e-03,  7.8852e-03, -1.1296e-02],\n                         [-6.0556e-03, -9.3063e-03, -6.4863e-03]],\n               \n                        ...,\n               \n                        [[-1.1780e-02,  2.4558e-02, -1.7188e-02],\n                         [ 6.0177e-04, -1.3364e-02, -2.2926e-02],\n                         [ 1.2001e-03, -5.8016e-03,  2.5975e-03]],\n               \n                        [[-8.8645e-03,  3.2920e-02, -2.1420e-02],\n                         [-2.4402e-02, -2.2066e-02, -3.9039e-03],\n                         [-1.6061e-02, -2.8620e-02, -1.6496e-02]],\n               \n                        [[-3.2796e-03,  1.3677e-02,  1.3856e-02],\n                         [ 2.7362e-02,  1.5658e-02,  1.5017e-02],\n                         [-6.5204e-03,  6.7173e-03,  6.3419e-03]]],\n               \n               \n                       [[[-1.3269e-02, -1.7341e-02, -3.3362e-02],\n                         [-1.5329e-02, -1.9136e-02, -4.6294e-03],\n                         [-7.6446e-03,  7.4016e-03, -1.7877e-02]],\n               \n                        [[ 2.0611e-02,  7.1623e-03, -4.0553e-03],\n                         [-1.4318e-02,  1.5246e-02, -2.6170e-03],\n                         [ 2.1481e-02,  9.1479e-03, -1.2052e-02]],\n               \n                        [[-1.5053e-02, -2.6383e-03, -6.6435e-03],\n                         [-3.0384e-03, -1.0636e-02, -2.5561e-02],\n                         [-2.3138e-02, -2.4678e-02,  1.5182e-03]],\n               \n                        ...,\n               \n                        [[ 3.0587e-02,  3.1213e-02,  1.1336e-02],\n                         [ 1.8796e-02,  2.4415e-02,  1.2766e-03],\n                         [-2.5430e-02, -1.0391e-02,  1.3085e-02]],\n               \n                        [[ 9.5703e-04,  2.6097e-02,  3.3993e-03],\n                         [ 8.3160e-03, -1.8174e-02,  2.0135e-03],\n                         [-1.3185e-02, -3.3672e-02, -1.4892e-02]],\n               \n                        [[ 1.0474e-02, -8.4881e-03, -6.2807e-03],\n                         [ 1.1206e-02,  5.4336e-03,  1.4586e-02],\n                         [ 1.2764e-02,  2.7992e-02,  3.5695e-02]]],\n               \n               \n                       [[[-9.1790e-04,  1.2695e-02, -8.1860e-03],\n                         [-6.7983e-03,  1.5761e-03, -4.8524e-03],\n                         [-6.9307e-03, -2.5506e-02, -1.7371e-02]],\n               \n                        [[ 1.7233e-02, -2.7652e-03, -9.0823e-03],\n                         [ 1.4421e-03, -6.6938e-03,  1.4396e-03],\n                         [-1.6522e-03,  1.6333e-02,  8.8315e-03]],\n               \n                        [[-6.7753e-03, -7.9061e-04, -2.9821e-03],\n                         [ 1.5468e-02,  2.9504e-02,  9.9357e-03],\n                         [-1.9976e-03, -9.0674e-03, -1.2300e-02]],\n               \n                        ...,\n               \n                        [[ 1.7617e-02, -9.0603e-04,  1.2133e-02],\n                         [ 1.0240e-02,  7.9234e-03,  2.1591e-02],\n                         [ 8.6403e-03,  2.6178e-02,  6.7421e-03]],\n               \n                        [[-1.9234e-03,  3.7185e-02, -2.7649e-03],\n                         [ 4.5390e-02,  2.0412e-02,  9.6751e-03],\n                         [-5.6593e-03,  2.1535e-03,  2.9243e-02]],\n               \n                        [[ 1.7517e-02,  1.3447e-02, -1.9149e-02],\n                         [ 7.5392e-03, -4.5065e-03, -2.6918e-03],\n                         [ 2.4592e-02, -6.5382e-03, -5.1444e-03]]]])),\n              ('layer4.2.bn2.weight',\n               tensor([0.9946, 0.9973, 1.0163, 0.9937, 1.0354, 1.1072, 0.9602, 1.0166, 1.0162,\n                       0.9992, 1.0238, 1.0511, 0.9634, 1.0662, 1.0457, 0.9873, 0.9674, 1.0152,\n                       1.0131, 0.9580, 1.0190, 1.0443, 0.9989, 0.9746, 0.9355, 1.0105, 0.9714,\n                       1.0357, 0.9898, 1.0004, 0.9971, 0.9991, 1.0148, 0.9993, 0.9906, 0.9627,\n                       0.9807, 1.0375, 0.9414, 0.9595, 1.0150, 0.9852, 0.9593, 0.9875, 0.9706,\n                       1.0343, 1.0232, 0.9782, 0.9480, 1.0261, 1.0436, 1.0538, 0.9973, 1.0209,\n                       1.0164, 0.9941, 1.0299, 1.0055, 1.0044, 0.9794, 0.9921, 0.9272, 0.9816,\n                       0.9597, 1.0603, 0.9331, 0.9689, 1.0429, 0.9901, 1.0790, 0.9397, 0.9421,\n                       0.9675, 0.9278, 0.9519, 0.9948, 0.9709, 0.9932, 1.0345, 0.9849, 1.0842,\n                       0.9504, 1.0201, 1.0163, 1.0223, 0.9860, 1.0986, 1.0264, 0.9527, 0.9402,\n                       1.0189, 0.9880, 1.0156, 1.0273, 0.9637, 1.0254, 0.9631, 0.9688, 1.0333,\n                       1.0195, 0.9711, 0.9689, 0.9890, 0.9598, 0.9611, 1.0083, 0.9653, 1.1354,\n                       1.0226, 1.0153, 1.0279, 0.9625, 0.9207, 0.9796, 1.0124, 1.0458, 0.9873,\n                       1.0896, 0.9762, 1.0073, 0.9724, 0.9437, 1.0139, 0.9967, 1.0223, 0.9673,\n                       0.9369, 0.9612, 0.9836, 1.0015, 0.9657, 1.0409, 0.9576, 0.9304, 0.9965,\n                       1.0008, 0.9885, 0.9740, 0.9925, 1.0158, 0.9670, 1.0332, 0.9421, 0.9797,\n                       1.0007, 0.9996, 0.9539, 0.9783, 0.9960, 0.9478, 0.9946, 0.9651, 0.9629,\n                       0.9731, 0.9702, 0.9722, 0.9547, 0.9591, 1.0231, 0.9657, 0.9723, 0.9420,\n                       0.9976, 0.9085, 0.9265, 0.9745, 0.9659, 0.9870, 0.9984, 1.0200, 1.0087,\n                       0.9837, 0.9548, 1.0040, 0.9635, 0.9870, 0.9600, 0.9742, 1.0534, 1.0169,\n                       1.0023, 0.9740, 1.0386, 1.0080, 1.0330, 1.0431, 0.9470, 1.0673, 1.0570,\n                       0.9962, 0.9583, 1.0378, 1.0265, 0.9900, 0.9636, 0.9939, 1.0324, 0.9887,\n                       1.0152, 1.0176, 1.0313, 0.9956, 0.9886, 0.9835, 0.9986, 1.0230, 0.9652,\n                       1.0078, 0.9785, 0.9413, 0.9577, 0.9940, 1.0124, 0.9879, 1.0204, 1.0440,\n                       1.0278, 0.9765, 0.9887, 0.9952, 1.0464, 1.0004, 0.9936, 0.9734, 0.9940,\n                       1.0248, 1.0506, 1.0000, 0.9905, 1.0280, 0.9652, 0.9642, 0.9285, 1.0288,\n                       0.9441, 0.9982, 0.9262, 1.0301, 1.0267, 1.0137, 1.0491, 0.9438, 0.9898,\n                       0.9833, 1.0620, 1.0525, 1.0116, 0.9916, 0.9923, 1.0171, 1.0696, 0.9615,\n                       1.0096, 0.9160, 1.0207, 0.9818, 1.0604, 0.9529, 1.0301, 0.9339, 0.9463,\n                       0.9541, 0.9815, 1.0240, 0.9684, 0.9553, 0.9570, 0.9496, 0.9647, 0.9769,\n                       1.0530, 1.0741, 1.0343, 0.9860, 1.0198, 1.0137, 1.0367, 0.9993, 0.9941,\n                       0.9529, 1.0449, 0.9609, 0.9648, 0.9353, 0.9824, 1.0074, 0.9636, 0.9761,\n                       0.9734, 1.0344, 1.0329, 0.9390, 1.0080, 0.9704, 0.9590, 1.0310, 0.9615,\n                       0.9743, 1.0540, 1.0352, 0.9858, 1.0027, 0.9829, 1.0051, 1.1553, 1.0265,\n                       0.9729, 1.0326, 0.9732, 0.9997, 0.9495, 0.9605, 0.9333, 0.9756, 1.0282,\n                       0.9885, 1.0428, 0.9942, 1.0208, 1.0004, 0.9285, 1.0223, 1.0231, 1.0103,\n                       1.0108, 0.9534, 0.9994, 1.0142, 1.0152, 0.9185, 0.9724, 0.9761, 0.9275,\n                       1.0569, 0.9540, 1.0385, 1.0179, 1.0087, 1.0112, 0.9663, 1.0345, 1.0001,\n                       1.0011, 1.0599, 0.9858, 0.9666, 0.9790, 1.0001, 0.9856, 0.9608, 0.9722,\n                       0.9983, 0.9491, 0.9530, 0.9885, 1.0528, 0.9774, 0.9823, 1.0311, 1.0263,\n                       0.9967, 0.9737, 1.0052, 0.9819, 1.0034, 1.0450, 0.9752, 0.9746, 1.0346,\n                       0.9691, 1.0259, 0.9434, 0.9839, 0.9290, 0.9755, 0.9876, 1.0102, 1.0036,\n                       0.9306, 0.9566, 1.0079, 0.9925, 0.9523, 1.0621, 1.0177, 0.9443, 0.9951,\n                       0.9955, 1.0016, 1.0279, 1.0527, 0.9933, 0.9481, 1.0071, 0.9440, 0.9864,\n                       1.0656, 1.0191, 0.9841, 1.0296, 1.0018, 1.0240, 0.9656, 0.9739, 0.9637,\n                       1.0388, 0.9122, 0.9646, 0.9967, 0.9718, 0.9371, 0.9795, 1.0100, 0.9701,\n                       0.9882, 0.9410, 0.9873, 0.9965, 1.0660, 1.0440, 1.0280, 0.9547, 0.9608,\n                       1.0165, 0.9672, 0.9521, 0.9830, 1.0106, 0.9465, 0.9970, 0.9727, 0.9883,\n                       1.0035, 0.9624, 1.0083, 0.9481, 0.9243, 0.9837, 0.9449, 1.0012, 0.9940,\n                       1.0015, 0.9682, 1.0196, 0.9687, 0.9645, 0.9986, 0.9846, 0.9894, 0.9996,\n                       1.0493, 0.9974, 0.9810, 0.9728, 0.9392, 0.9815, 1.0330, 0.9699, 0.9677,\n                       0.9719, 1.0110, 0.9471, 1.0298, 0.9664, 0.9493, 0.9645, 0.9713, 0.9857,\n                       0.9622, 0.9736, 0.9412, 1.0169, 0.9969, 0.9812, 1.0160, 0.9367, 0.9862,\n                       0.9928, 1.0770, 1.0234, 0.9784, 0.9872, 0.9578, 1.0076, 1.0244, 0.9315,\n                       1.0019, 1.0102, 0.9188, 0.9911, 0.9435, 1.0982, 0.9545, 0.9899, 0.9300,\n                       0.9654, 1.0075, 0.9985, 1.0043, 0.9676, 1.0003, 1.0007, 0.9637, 0.9246,\n                       0.9429, 0.9609, 0.9619, 0.9641, 1.0148, 0.9423, 0.9736, 1.0184])),\n              ('layer4.2.bn2.bias',\n               tensor([-0.1600, -0.1662, -0.1292, -0.0927, -0.1077,  0.0329, -0.1385, -0.0791,\n                       -0.0462, -0.1592, -0.1251, -0.0139, -0.0792,  0.0125, -0.0701, -0.0642,\n                       -0.1618, -0.1152, -0.0961, -0.1128, -0.0701, -0.0822, -0.1289, -0.1595,\n                       -0.1154, -0.1760, -0.1320,  0.0101, -0.1125, -0.0934, -0.0211, -0.0059,\n                       -0.1021, -0.0037, -0.1008, -0.0761, -0.1569, -0.0194, -0.1171, -0.1729,\n                       -0.1146, -0.1051, -0.1581, -0.0948, -0.0992, -0.0418, -0.1393, -0.1563,\n                       -0.1478, -0.0846, -0.0976, -0.0216, -0.0329, -0.1356, -0.1044, -0.0342,\n                       -0.0552, -0.0977, -0.1148, -0.1527, -0.0482, -0.0614, -0.1351, -0.1447,\n                       -0.1189, -0.2034, -0.0809, -0.0400, -0.1453, -0.0673, -0.1523, -0.1249,\n                       -0.1905, -0.2073, -0.1901, -0.1249, -0.1324, -0.1341, -0.1589, -0.2029,\n                       -0.0323, -0.0297, -0.1292,  0.0260, -0.1021, -0.1722, -0.0076, -0.1369,\n                       -0.1565, -0.1005, -0.0773, -0.1462, -0.0822, -0.0517, -0.1837, -0.1265,\n                       -0.0515, -0.1482, -0.0417, -0.0522, -0.0863, -0.1142, -0.0789, -0.1319,\n                       -0.1632, -0.1202, -0.0543,  0.0216, -0.0829, -0.1798, -0.0829, -0.1135,\n                       -0.1495, -0.1312, -0.1159, -0.0417, -0.1898,  0.0311, -0.1235, -0.0431,\n                       -0.0911, -0.1830, -0.0608, -0.1006, -0.1129, -0.1267, -0.1949, -0.1315,\n                       -0.0526, -0.0814, -0.1191, -0.2090, -0.0623, -0.1221, -0.0690, -0.0902,\n                       -0.1928, -0.0896, -0.1050, -0.0298, -0.1476, -0.1039, -0.1290, -0.1022,\n                       -0.1248, -0.1350, -0.1080, -0.1848, -0.1351, -0.0225, -0.1477, -0.1331,\n                       -0.1044, -0.1286, -0.1474, -0.1413, -0.1002, -0.1383, -0.0757, -0.0974,\n                       -0.1216, -0.1404, -0.0945, -0.1763, -0.0739, -0.1201, -0.1497, -0.1230,\n                       -0.1179, -0.0930, -0.1513, -0.0855, -0.1333, -0.0695, -0.1338, -0.1541,\n                       -0.1127, -0.1233, -0.0952, -0.1386, -0.1246, -0.0901, -0.2012, -0.0855,\n                       -0.1319, -0.1289, -0.1437, -0.0604, -0.1017, -0.0342, -0.1113, -0.0318,\n                       -0.1530, -0.0957, -0.0877, -0.1013, -0.0750, -0.1350, -0.0746, -0.0305,\n                       -0.1167, -0.1247, -0.0953, -0.1097, -0.1119, -0.1155, -0.0763, -0.1192,\n                       -0.0421, -0.0720, -0.0868, -0.1031, -0.0858, -0.1155,  0.0123, -0.0118,\n                       -0.0923, -0.1047, -0.1021, -0.1142, -0.0409, -0.1266, -0.1355, -0.0550,\n                       -0.0957, -0.0512, -0.0454, -0.1110, -0.1033, -0.0332, -0.0392, -0.1352,\n                       -0.1343, -0.1008, -0.1661, -0.0960, -0.1291, -0.0295, -0.0426, -0.0557,\n                        0.0069, -0.1269, -0.1461, -0.1432, -0.1100, -0.0415, -0.0457, -0.1693,\n                       -0.0761, -0.0338,  0.0087, -0.0915, -0.0693, -0.1677, -0.1182, -0.0587,\n                       -0.0529, -0.2045, -0.1127, -0.0759, -0.1938, -0.1294, -0.1399, -0.0715,\n                       -0.1482, -0.2063, -0.1395, -0.2166, -0.1477, -0.1390, -0.0736, -0.1094,\n                        0.0128, -0.0917, -0.1128, -0.0579, -0.0471, -0.1168, -0.1062, -0.1628,\n                       -0.1377, -0.0817, -0.0853, -0.0739, -0.1282, -0.1259, -0.1804, -0.0408,\n                       -0.1839, -0.0760, -0.1182, -0.1541, -0.1091, -0.1142, -0.1024, -0.1001,\n                       -0.0906, -0.0833, -0.0512, -0.1990, -0.0508, -0.0932, -0.0885, -0.0758,\n                       -0.1717, -0.1418, -0.0714, -0.0836, -0.1361, -0.1321, -0.0926, -0.1335,\n                       -0.1102, -0.0963, -0.0954, -0.0979, -0.1011, -0.0981, -0.0529, -0.1143,\n                       -0.1089,  0.0151,  0.0215, -0.0694, -0.0860, -0.1305, -0.0681, -0.1352,\n                       -0.1034, -0.1295, -0.1518, -0.1629, -0.1401, -0.0277, -0.1057, -0.0615,\n                       -0.0302, -0.1606, -0.0979, -0.0954, -0.0845, -0.0754, -0.0621, -0.0913,\n                       -0.0802, -0.1481, -0.1103, -0.0807, -0.1036, -0.1012, -0.1400, -0.1268,\n                       -0.1141, -0.1366, -0.1045, -0.0536, -0.1032, -0.1110, -0.1109, -0.0610,\n                       -0.1095, -0.1003, -0.0463, -0.0964, -0.0538, -0.0755, -0.1534, -0.1511,\n                       -0.1156, -0.0884, -0.1334, -0.1319, -0.1172, -0.1546, -0.0583, -0.1568,\n                       -0.1182, -0.0291, -0.1943, -0.1205, -0.0404, -0.1211, -0.1064, -0.0924,\n                       -0.0765, -0.1414, -0.1571, -0.0174, -0.1247, -0.0892, -0.1138, -0.1122,\n                       -0.1420, -0.0565, -0.1489, -0.1245, -0.0148, -0.0881, -0.1093, -0.0596,\n                       -0.1620, -0.1063, -0.1278, -0.1561, -0.2479, -0.0331, -0.0509, -0.0587,\n                       -0.0976, -0.1002, -0.1472, -0.0644, -0.0976, -0.0908, -0.0804, -0.1917,\n                       -0.2118, -0.2250, -0.0992, -0.0326, -0.0767, -0.0803, -0.0967, -0.1266,\n                       -0.1015, -0.1660, -0.0815, -0.0957, -0.1053, -0.1017, -0.1907, -0.0767,\n                       -0.1445, -0.0900, -0.0412, -0.1598, -0.1735, -0.0264, -0.1892, -0.1451,\n                       -0.0631, -0.1456, -0.1190,  0.0277, -0.1691, -0.1480, -0.1000, -0.0694,\n                       -0.1153, -0.1316, -0.0781, -0.1081, -0.1559, -0.0715, -0.0987, -0.1034,\n                       -0.1187, -0.1617, -0.1425, -0.1324, -0.0994, -0.1123, -0.0742, -0.1977,\n                       -0.0992, -0.1568, -0.2013, -0.0796, -0.1680, -0.0782, -0.0912, -0.0954,\n                       -0.0899, -0.0620, -0.0728, -0.0944, -0.0984, -0.1468,  0.0649, -0.1038,\n                       -0.0762, -0.1288, -0.0825, -0.1219, -0.0640, -0.1159, -0.1029, -0.1435,\n                       -0.1789, -0.1667, -0.1211,  0.0042, -0.1073, -0.1000, -0.2074, -0.0875,\n                       -0.1353, -0.0811, -0.0444, -0.0878, -0.1674, -0.1692, -0.1164, -0.1829,\n                       -0.1094, -0.1414, -0.2121, -0.1394, -0.1269, -0.1246, -0.1040, -0.1802])),\n              ('layer4.2.bn2.running_mean',\n               tensor([ 9.8496e-02, -6.5720e-01, -7.9776e-01, -6.0611e-01, -8.5745e-01,\n                       -8.9712e-01, -2.4073e-01, -1.1361e+00, -9.1848e-01, -5.8746e-01,\n                       -2.9786e-01, -1.7516e-02, -8.7135e-01, -7.2115e-01, -1.0699e+00,\n                        4.6551e-01, -3.7652e-01, -1.8340e-01, -3.8283e-01,  2.8111e-01,\n                       -1.0523e+00, -6.4255e-01,  4.3504e-01,  8.0393e-01, -7.3167e-01,\n                       -6.5740e-01, -2.9577e-01, -6.2913e-01, -6.3241e-01, -3.1821e-01,\n                       -2.2891e-01,  3.6788e-02, -7.3206e-01, -1.0187e+00, -1.7744e-01,\n                       -5.9399e-01, -2.2326e-01, -5.0737e-01, -9.5260e-01, -9.2082e-02,\n                       -4.8057e-01, -4.1920e-01, -4.0721e-01,  2.0620e-01, -3.4321e-01,\n                       -7.7209e-01, -5.1251e-01,  3.5662e-02, -3.3990e-02, -2.8443e-01,\n                       -7.4313e-01, -4.7507e-01, -6.2073e-01, -2.9971e-01,  1.6063e-01,\n                       -9.7756e-01, -5.5495e-01, -7.6276e-01, -5.8364e-01, -4.4749e-01,\n                       -9.4257e-01,  3.6378e-01,  2.0276e-01, -4.0470e-01, -1.0607e-01,\n                       -2.6643e-01, -9.8487e-01, -4.2454e-01,  5.3001e-01, -3.5908e-01,\n                       -6.7888e-01, -7.8834e-01,  7.9916e-01,  3.5048e-01, -1.2825e-02,\n                       -3.6644e-01, -5.5087e-01, -8.1517e-01, -4.9572e-02,  2.0017e-01,\n                       -6.2787e-01, -1.0256e+00, -3.7924e-01, -1.4426e+00, -1.5641e-02,\n                       -6.2471e-01, -9.0868e-01, -5.2086e-01, -2.4645e-01, -3.3153e-01,\n                       -4.0547e-01, -7.6839e-01, -4.3132e-01,  1.9953e-02, -5.3108e-01,\n                       -5.6262e-01, -5.0131e-01, -6.0417e-01, -4.1150e-01, -1.5277e-01,\n                       -1.4987e-01, -8.1143e-01, -1.1737e+00, -1.9762e-01,  1.5098e-01,\n                       -3.1151e-01, -7.3901e-01, -1.3830e+00, -2.2319e-01,  1.2094e-01,\n                       -8.7010e-01, -3.7642e-01, -6.6127e-01, -4.5589e-01, -5.1494e-01,\n                       -8.6839e-01, -3.4910e-01, -9.0947e-01, -3.2115e-01, -2.2842e-01,\n                       -1.1467e-01, -2.5167e-01, -4.6488e-01, -4.7725e-01, -1.8472e-01,\n                       -1.2600e+00, -4.6418e-01,  1.9354e-01, -8.7890e-01, -9.2754e-01,\n                        9.8475e-02, -2.1414e-01, -3.6251e-02, -5.1648e-01, -1.3522e+00,\n                       -2.9812e-01,  1.5475e+00, -8.4547e-02, -7.0290e-01, -7.3878e-01,\n                       -4.6045e-01, -9.3648e-01, -5.1506e-01, -1.0765e+00,  9.3085e-01,\n                       -2.5436e-01, -7.7982e-01, -4.8920e-01, -5.1820e-01, -3.1748e-01,\n                       -1.4689e-01,  4.9398e-01,  9.3071e-01,  4.1570e-02, -2.7712e-01,\n                        1.1789e-01, -5.8526e-01, -6.7074e-01, -8.2356e-01,  4.8713e-01,\n                       -7.5824e-01, -1.5856e-01, -9.9186e-01, -1.5398e-01, -2.3219e-01,\n                       -2.7221e-01, -1.9485e-01, -5.5346e-01, -3.0398e-01, -4.5643e-01,\n                        7.4766e-02, -4.5427e-02, -5.5394e-01, -3.1376e-01, -1.5525e-01,\n                       -1.7077e-02, -5.1843e-01, -4.4003e-02,  1.6696e-02, -2.8107e-01,\n                       -3.8692e-01,  6.4515e-01,  1.6707e+00,  3.2707e-01, -4.9458e-01,\n                       -4.0657e-01, -2.3288e-01, -5.6138e-01, -4.1419e-01, -5.4526e-01,\n                       -6.9004e-01, -1.0272e+00, -2.3755e-01, -6.6375e-01,  3.1599e-01,\n                       -3.7418e-01,  2.8134e-01, -7.0960e-01, -6.8668e-01, -4.4453e-01,\n                       -4.3971e-01,  3.2370e-01, -8.8560e-01,  5.3901e-01, -3.8286e-01,\n                       -1.6726e-01, -4.8635e-01, -2.4510e-01, -9.6873e-02,  8.5899e-02,\n                       -6.4885e-01, -6.9659e-01, -4.1007e-01, -5.1572e-01, -5.5613e-01,\n                       -6.5983e-01, -4.0782e-01,  7.7719e-01, -8.9342e-01,  4.3767e-01,\n                       -6.8319e-01, -3.7194e-01, -7.5398e-01, -2.0109e-01, -3.2576e-01,\n                       -1.4251e-01, -5.4930e-01, -6.5789e-01, -6.9875e-01, -8.4430e-01,\n                       -4.4818e-01, -9.1855e-01, -3.4240e-01, -8.5521e-01,  4.6036e-01,\n                       -1.8493e-01,  3.0352e-01,  1.0961e-01, -1.0672e+00, -7.6057e-01,\n                       -8.3472e-01, -8.6790e-01, -5.2946e-01, -9.9617e-01, -4.7134e-01,\n                        8.5859e-01, -3.4053e-01, -2.1024e-01,  2.5575e-01,  4.8119e-02,\n                       -1.0136e+00, -8.3730e-01,  2.9901e-01,  3.9253e-01,  3.6324e-01,\n                        4.3945e-02, -9.9885e-01, -2.9137e-01, -1.6152e-01,  2.5914e-01,\n                       -6.2297e-01, -7.7253e-01, -1.2596e+00,  6.1426e-01, -7.0174e-01,\n                       -7.0795e-01, -2.9571e-01,  2.0594e-01, -1.4568e-01,  9.2073e-01,\n                        9.9936e-01,  1.3957e-01, -7.6456e-01, -3.9289e-01, -2.6555e-01,\n                       -7.0145e-01, -1.0776e+00, -4.2642e-01, -6.2471e-01, -5.2938e-01,\n                       -2.6548e-01, -1.1777e-01,  1.3550e-01, -6.9053e-01, -1.6477e-01,\n                       -7.0682e-01, -3.2848e-01, -1.1582e-01, -1.8491e-01,  2.8308e-01,\n                        9.8321e-02, -5.8559e-01, -5.4843e-01, -2.2207e-01, -6.0361e-01,\n                       -3.2054e-01, -6.8174e-02, -9.2135e-02, -9.6598e-01,  3.3686e-01,\n                        1.3726e-01, -4.3773e-01, -2.4363e-02, -1.0241e+00,  1.2624e+00,\n                        4.0791e-02, -4.8333e-01, -7.0008e-01,  1.2388e+00, -6.7150e-01,\n                       -5.0897e-01, -3.9003e-01, -5.6422e-02, -1.2642e+00, -5.2775e-01,\n                       -1.0259e+00,  2.7354e-01, -8.2666e-01, -2.6863e-01, -3.9439e-02,\n                       -1.4485e-01, -7.3876e-01, -8.8431e-01, -6.5890e-01, -5.8137e-01,\n                       -2.1491e-01, -1.1964e+00,  4.9249e-02, -3.2059e-03, -1.8562e-01,\n                       -1.6020e-01, -1.3501e-01, -1.8060e-01, -4.1967e-01,  1.4079e-01,\n                       -5.4822e-01, -2.3215e-01, -5.5382e-02, -4.7456e-01, -2.0191e-01,\n                       -6.3250e-02, -2.1918e-01,  3.0740e-01, -3.2993e-01, -3.3294e-01,\n                       -1.5125e-02, -5.3186e-01, -5.9546e-01, -4.1124e-01,  9.5868e-02,\n                        3.0690e-01,  4.2954e-01, -5.7404e-02, -3.4412e-01, -9.0478e-01,\n                       -8.5019e-01, -6.2552e-01, -4.6265e-01, -3.9788e-01, -4.7386e-02,\n                       -7.8834e-01, -2.9415e-01, -6.7031e-01, -2.6346e-01, -8.0495e-01,\n                       -3.3577e-01, -3.2086e-01, -4.2615e-01,  4.0871e-01,  7.0981e-02,\n                       -8.2061e-01, -6.3223e-01, -8.0787e-01, -4.8133e-01,  2.3724e-01,\n                       -2.8456e-01, -3.5028e-01, -4.2243e-01,  2.3622e-02,  1.8335e-01,\n                       -7.2589e-01, -6.7218e-01, -2.9270e-01,  4.6578e-01, -7.0746e-01,\n                       -2.6648e-01, -3.6251e-01, -1.0642e+00, -4.8413e-01, -5.0685e-01,\n                        7.3925e-01, -7.8588e-01, -1.2760e-01, -9.6393e-01, -4.1611e-01,\n                       -4.4134e-01, -7.2794e-01, -2.8687e-01, -6.5887e-02,  1.5294e-01,\n                       -8.0429e-01, -1.9638e-01, -1.2179e-01, -4.4250e-01,  3.7717e-01,\n                       -3.9631e-01, -2.7181e-01, -1.7274e-01, -5.9030e-01, -1.1130e+00,\n                       -5.9333e-01, -6.1853e-01, -7.7939e-02, -7.7770e-01,  2.7839e-01,\n                        2.0371e-01, -5.1739e-01,  1.6925e+00, -1.4278e-01, -9.2114e-01,\n                       -9.2635e-01, -1.1026e+00,  3.6091e-01,  4.3761e-01, -5.4615e-01,\n                        3.5366e-01, -2.0413e-01, -7.3139e-01, -3.7884e-01, -2.1486e-01,\n                       -5.3196e-01, -7.9079e-01, -4.1045e-01, -4.1478e-01, -4.3269e-01,\n                        2.0260e-01,  7.8473e-01, -7.3197e-01,  1.9557e-01, -4.3451e-01,\n                       -4.9442e-01, -2.3466e-01, -1.6643e-01, -8.3574e-01,  3.2352e-01,\n                       -4.3098e-01,  6.5261e-04, -3.4124e-01,  6.9033e-01, -8.1300e-01,\n                       -1.2184e+00, -3.6721e-01, -2.6103e-01,  1.3930e-01, -4.6939e-01,\n                        2.7405e-01, -4.5313e-01, -2.2013e-01, -4.8753e-01,  4.8564e-02,\n                       -6.3878e-01, -7.3072e-01, -3.7509e-01,  5.4388e-02, -5.2045e-02,\n                        4.0354e-01, -2.3302e-01, -1.7749e-01, -7.1086e-01, -1.7788e-01,\n                       -5.1737e-01, -2.0386e-01, -1.6040e-01, -9.2417e-01, -8.5276e-01,\n                       -2.4661e-01, -7.3871e-01, -1.7456e-01, -1.6493e+00, -2.9276e-01,\n                       -1.2945e-01, -7.8470e-02, -6.4068e-01, -3.7072e-01, -6.3659e-01,\n                       -1.1981e+00, -4.6360e-01, -1.4168e-01, -1.8291e-01, -1.2721e-01,\n                       -1.0265e+00, -1.4633e+00, -6.1856e-01, -3.0478e-01, -4.3786e-01,\n                       -8.9703e-01, -1.0795e+00, -1.3680e-02, -5.6061e-01, -5.6048e-01,\n                        7.7633e-01, -5.5297e-01,  2.5995e-01, -2.1107e-01,  1.5633e-01,\n                       -5.9435e-01,  5.6424e-01, -3.5106e-01,  8.9463e-01, -8.6727e-01,\n                        1.5714e-01,  2.5640e-02])),\n              ('layer4.2.bn2.running_var',\n               tensor([0.5238, 0.7484, 0.5287, 0.4949, 0.5968, 0.9549, 0.4984, 0.7501, 0.5432,\n                       0.5142, 0.5101, 0.5016, 0.6955, 0.9023, 0.7667, 0.4092, 0.5497, 0.4546,\n                       0.4535, 0.4582, 0.6066, 0.5816, 0.4627, 0.4492, 0.4824, 0.4438, 0.4546,\n                       0.4717, 0.4381, 0.5099, 0.3374, 0.3338, 0.5684, 0.6311, 0.3475, 0.4996,\n                       0.4107, 0.4173, 0.4433, 0.3881, 0.6892, 0.5497, 0.3755, 0.3305, 0.3697,\n                       0.8321, 0.3765, 0.3618, 0.3841, 0.4778, 0.5181, 0.7869, 0.4094, 0.3906,\n                       0.3923, 0.5907, 0.8558, 0.5684, 0.5070, 0.5155, 0.5322, 0.3118, 0.3824,\n                       0.4637, 0.5092, 0.5566, 0.7965, 0.5726, 0.4196, 0.4780, 0.4903, 0.4754,\n                       0.4515, 0.4221, 0.5046, 0.5167, 0.7621, 0.5138, 0.4080, 0.4883, 0.8194,\n                       0.6228, 0.5137, 0.6185, 0.4136, 0.5164, 1.1784, 0.4235, 0.4659, 0.4944,\n                       0.8601, 0.5116, 0.5975, 0.4624, 0.4977, 0.4746, 0.6077, 0.4273, 0.4950,\n                       0.4123, 0.6795, 0.5025, 0.5556, 0.3854, 0.3738, 0.3914, 0.4706, 1.3727,\n                       0.4379, 0.4380, 0.6499, 0.3649, 0.5823, 0.4280, 0.5104, 0.5399, 0.4418,\n                       1.1474, 0.5998, 0.6306, 0.3373, 0.4199, 0.4782, 0.4435, 0.5949, 0.7385,\n                       0.6098, 0.3875, 0.5915, 0.6318, 0.3188, 0.4146, 0.3329, 0.5881, 0.4886,\n                       0.4238, 0.5053, 0.3001, 0.4201, 0.8758, 0.3942, 0.5676, 0.3869, 0.5789,\n                       0.4971, 0.4187, 0.5495, 0.5441, 0.6006, 0.4628, 0.3595, 0.3344, 0.5029,\n                       0.2899, 0.4940, 0.3979, 0.3922, 0.7303, 0.5062, 0.3663, 0.5603, 0.4749,\n                       0.4937, 0.4720, 0.4429, 0.4187, 0.3953, 0.4817, 0.5209, 0.6306, 0.3982,\n                       0.4823, 0.5068, 0.4463, 0.3794, 0.4278, 0.4965, 0.7094, 0.4834, 0.4499,\n                       0.4057, 0.6013, 0.5928, 0.4973, 0.6519, 0.6664, 0.4944, 0.6694, 1.1099,\n                       0.4764, 0.5769, 0.6744, 0.5403, 0.5300, 0.4802, 0.6481, 0.4832, 0.5441,\n                       0.6338, 0.3889, 0.5098, 0.5469, 0.4966, 0.3504, 0.3776, 0.4053, 0.5756,\n                       0.5188, 0.3672, 0.3106, 0.4642, 0.4808, 0.5828, 0.6215, 0.7631, 0.5889,\n                       0.4737, 0.5305, 0.4431, 0.4192, 0.5959, 0.5427, 0.4352, 0.3156, 0.5295,\n                       0.4717, 0.7312, 0.6401, 0.4479, 0.5962, 0.3329, 0.4013, 0.4071, 0.5499,\n                       0.6264, 0.5078, 0.5230, 0.3831, 0.5502, 0.6158, 0.7898, 0.5263, 0.5572,\n                       0.5841, 0.4548, 0.6488, 0.4776, 0.3970, 0.4619, 0.3439, 1.1527, 0.4951,\n                       0.3601, 0.3383, 0.4581, 0.3215, 0.5533, 0.4482, 0.4747, 0.3132, 0.4180,\n                       0.4808, 0.5675, 0.4685, 0.4087, 0.4692, 1.1991, 0.3568, 0.3538, 0.5384,\n                       0.5089, 0.4875, 0.7125, 0.4179, 0.4798, 0.5687, 0.9913, 0.5784, 0.4452,\n                       0.4233, 0.5874, 0.2600, 0.4394, 0.4310, 0.5462, 0.6491, 0.5920, 0.5504,\n                       0.4550, 0.4583, 0.5100, 0.4218, 0.5673, 0.5032, 0.3514, 0.4766, 0.4635,\n                       0.5040, 0.7783, 0.4001, 0.2981, 0.4747, 0.4763, 0.5721, 0.9821, 0.5106,\n                       0.4939, 0.5080, 0.5730, 0.4944, 0.2965, 0.5656, 0.3336, 0.4873, 0.6151,\n                       0.5509, 0.6577, 0.5336, 0.4440, 0.3502, 0.4332, 0.4302, 0.6537, 0.7882,\n                       0.4225, 0.4868, 0.6036, 0.4961, 0.5102, 0.6639, 0.3732, 0.4351, 0.4019,\n                       0.9031, 0.3696, 0.7255, 0.5066, 0.4243, 0.6153, 0.3694, 0.3951, 0.5756,\n                       0.3557, 0.5732, 0.4129, 0.4888, 0.4937, 0.4330, 0.6243, 0.3479, 0.3819,\n                       0.5477, 0.2921, 0.3545, 0.6812, 0.6510, 0.5675, 0.3858, 0.6676, 0.5187,\n                       0.6116, 0.3988, 0.7066, 0.5468, 0.7427, 0.4995, 0.3866, 0.4157, 0.4473,\n                       0.4602, 0.4869, 0.3936, 0.4387, 0.4861, 0.3874, 0.4810, 0.3549, 0.5326,\n                       0.4870, 0.3081, 0.5050, 0.7013, 0.3584, 0.4062, 0.5628, 0.3812, 0.4385,\n                       0.6095, 0.5691, 0.5262, 0.6700, 0.4807, 0.5572, 0.6906, 0.4924, 0.5014,\n                       0.9633, 0.5245, 0.4626, 0.4478, 0.4227, 0.4217, 0.3652, 0.5309, 0.4366,\n                       0.4968, 0.5114, 0.3142, 0.5127, 0.5299, 0.4392, 0.6010, 0.4917, 0.5720,\n                       0.4617, 0.4565, 0.4580, 1.1482, 0.4476, 0.5830, 0.6590, 0.6394, 0.3319,\n                       0.4519, 0.4897, 0.4213, 0.4142, 0.5893, 0.8511, 0.5515, 0.5155, 0.5912,\n                       0.5726, 0.2855, 0.7224, 0.4157, 0.4887, 0.8265, 0.4304, 0.4511, 0.4443,\n                       0.4673, 0.3390, 1.3004, 0.3550, 0.4194, 0.5888, 0.3791, 0.5478, 0.4599,\n                       0.5799, 0.5442, 0.4243, 0.2593, 0.4884, 0.4044, 0.6478, 0.4160, 0.4639,\n                       0.5455, 0.5687, 0.4857, 0.6410, 0.6832, 0.5264, 0.5954, 0.4672, 0.3487,\n                       0.4628, 0.4294, 0.4934, 0.3558, 0.4646, 0.6644, 0.5259, 0.4698, 0.5861,\n                       0.5013, 1.3587, 0.4693, 0.5593, 0.5860, 0.3561, 0.4497, 0.5789, 0.4985,\n                       0.5498, 0.4311, 0.4712, 0.6181, 0.5437, 1.1076, 0.4141, 0.5005, 0.4729,\n                       0.7063, 0.5615, 0.4450, 0.4165, 0.5460, 0.4413, 0.4138, 0.4073, 0.5114,\n                       0.4750, 0.4753, 0.4003, 0.4622, 0.5345, 0.5787, 0.4220, 0.5398])),\n              ('layer4.2.bn2.num_batches_tracked', tensor(13572)),\n              ('layer4.2.conv3.weight',\n               tensor([[[[-0.0144]],\n               \n                        [[-0.0668]],\n               \n                        [[ 0.0229]],\n               \n                        ...,\n               \n                        [[ 0.0140]],\n               \n                        [[-0.0148]],\n               \n                        [[-0.0055]]],\n               \n               \n                       [[[-0.0173]],\n               \n                        [[ 0.0167]],\n               \n                        [[-0.0088]],\n               \n                        ...,\n               \n                        [[ 0.0165]],\n               \n                        [[ 0.0115]],\n               \n                        [[-0.0280]]],\n               \n               \n                       [[[ 0.0291]],\n               \n                        [[ 0.0071]],\n               \n                        [[ 0.0144]],\n               \n                        ...,\n               \n                        [[-0.0037]],\n               \n                        [[ 0.0020]],\n               \n                        [[-0.0021]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0021]],\n               \n                        [[-0.0518]],\n               \n                        [[-0.0129]],\n               \n                        ...,\n               \n                        [[ 0.0066]],\n               \n                        [[-0.0050]],\n               \n                        [[ 0.0015]]],\n               \n               \n                       [[[-0.0022]],\n               \n                        [[-0.0112]],\n               \n                        [[ 0.0200]],\n               \n                        ...,\n               \n                        [[-0.0055]],\n               \n                        [[ 0.0054]],\n               \n                        [[-0.0193]]],\n               \n               \n                       [[[ 0.0033]],\n               \n                        [[-0.0304]],\n               \n                        [[ 0.0198]],\n               \n                        ...,\n               \n                        [[-0.0033]],\n               \n                        [[-0.0186]],\n               \n                        [[ 0.0051]]]])),\n              ('layer4.2.bn3.weight',\n               tensor([-0.4964, -0.4108,  0.4425,  ...,  0.0287, -0.5083, -0.3546])),\n              ('layer4.2.bn3.bias',\n               tensor([ 0.1533,  0.1305,  0.1102,  ..., -0.0328,  0.1325,  0.1013])),\n              ('layer4.2.bn3.running_mean',\n               tensor([-0.4701, -0.2115,  0.2449,  ...,  0.1508, -0.3820, -0.3823])),\n              ('layer4.2.bn3.running_var',\n               tensor([0.0550, 0.0461, 0.0472,  ..., 0.0448, 0.0507, 0.0420])),\n              ('layer4.2.bn3.num_batches_tracked', tensor(13572)),\n              ('fc.weight',\n               tensor([[-0.0081, -0.0097,  0.0011,  ..., -0.0133, -0.0127,  0.0085],\n                       [-0.0019,  0.0140, -0.0250,  ..., -0.0080, -0.0202, -0.0104],\n                       [ 0.0090, -0.0086, -0.0173,  ...,  0.0043, -0.0041,  0.0032],\n                       ...,\n                       [-0.0156,  0.0012,  0.0091,  ..., -0.0050, -0.0256, -0.0050],\n                       [-0.0131,  0.0065, -0.0048,  ..., -0.0041,  0.0036,  0.0081],\n                       [ 0.0165,  0.0112, -0.0049,  ...,  0.0074,  0.0196, -0.0051]])),\n              ('fc.bias',\n               tensor([-0.0557, -0.0782, -0.0657, -0.0716, -0.0525, -0.0768, -0.0741, -0.0646,\n                       -0.0459, -0.0810, -0.0817, -0.0462, -0.0600, -0.0845, -0.0783, -0.0715,\n                       -0.0512, -0.0739, -0.0899, -0.0521, -0.0815, -0.0887, -0.0703, -0.0844,\n                       -0.0561, -0.0752, -0.0639, -0.0627, -0.0888, -0.0901, -0.0652, -0.0880,\n                       -0.0677, -0.0704, -0.0661, -0.0772, -0.0674, -0.0773, -0.0738, -0.0786,\n                       -0.0696, -0.0852, -0.0877, -0.0406, -0.1019, -0.0664, -0.0783, -0.0853,\n                       -0.0663, -0.0724, -0.0539, -0.0532, -0.1051, -0.0752, -0.0822, -0.0855,\n                       -0.0898, -0.0676, -0.0571, -0.0767, -0.0558, -0.0749, -0.0712, -0.0539,\n                       -0.0537, -0.0647, -0.0971, -0.0558, -0.0649, -0.0909, -0.0740, -0.0768,\n                       -0.0427, -0.0595, -0.0834, -0.0895, -0.0818, -0.0442, -0.0837, -0.0622,\n                       -0.0700, -0.0773, -0.0831, -0.0869, -0.0852, -0.0834, -0.0621, -0.0549,\n                       -0.0654, -0.0869, -0.0540, -0.0664, -0.0806, -0.0487, -0.0703, -0.0511,\n                       -0.0818, -0.0744, -0.0799, -0.0694, -0.0433, -0.0399, -0.0798, -0.0674,\n                       -0.0808, -0.0764, -0.0597, -0.0637, -0.0658, -0.0542, -0.0643, -0.0808,\n                       -0.0627, -0.0417, -0.0857, -0.0714, -0.0682, -0.0788, -0.0487, -0.0565,\n                       -0.0652, -0.0902, -0.0818, -0.0949, -0.0472, -0.0800, -0.0539, -0.0922,\n                       -0.0679, -0.0822, -0.0578, -0.0643, -0.0827, -0.0643, -0.0875, -0.0600,\n                       -0.0755, -0.0865, -0.0815, -0.0906, -0.0723, -0.0619, -0.0594, -0.0680,\n                       -0.0633, -0.0860, -0.0628, -0.0426, -0.0646, -0.0635, -0.0631, -0.0903,\n                       -0.0989, -0.0625, -0.0907, -0.0590, -0.0653, -0.0539, -0.0782, -0.0958,\n                       -0.0576, -0.0634, -0.0895, -0.0910, -0.0883, -0.0863, -0.0700, -0.0808,\n                       -0.0825, -0.0639, -0.0555, -0.0962, -0.0709, -0.0761, -0.0434, -0.0739,\n                       -0.0557, -0.0443, -0.0760, -0.0533, -0.0679, -0.0917, -0.0723, -0.0547,\n                       -0.0654, -0.0779, -0.0428, -0.0682, -0.0836, -0.0827, -0.0837, -0.0472,\n                       -0.0539, -0.0649, -0.0827, -0.0810, -0.0808, -0.0736, -0.0757, -0.0781,\n                       -0.0627, -0.0790, -0.0660, -0.0542, -0.0630, -0.0564, -0.0902, -0.0922,\n                       -0.0653, -0.0855, -0.0514, -0.0905, -0.0886, -0.0706, -0.0684, -0.0468,\n                       -0.0633, -0.0541, -0.0601, -0.0673, -0.0854, -0.0496, -0.0764, -0.0662,\n                       -0.0512, -0.0667, -0.0942, -0.0570, -0.0751, -0.0586, -0.0427, -0.0825,\n                       -0.0848, -0.0630, -0.0811, -0.0836, -0.0813, -0.0805, -0.0604, -0.0562,\n                       -0.0753, -0.0901, -0.0736, -0.0857, -0.0705, -0.0586, -0.0868, -0.0883,\n                       -0.0817, -0.0846, -0.0612, -0.0600, -0.0543, -0.0481, -0.0672, -0.0741,\n                       -0.0551, -0.0916, -0.0830, -0.0757, -0.0498, -0.0688, -0.0788, -0.0644,\n                       -0.0722, -0.0798, -0.0755, -0.0435, -0.0592, -0.0753, -0.0824, -0.0572,\n                       -0.0878, -0.0833, -0.0674, -0.0804, -0.0911, -0.0481, -0.0938, -0.0672,\n                       -0.0855, -0.0473, -0.0852, -0.0823, -0.0707, -0.0636, -0.0670, -0.0916,\n                       -0.0954, -0.0924, -0.0599, -0.0677, -0.0894, -0.0898, -0.0727, -0.0763,\n                       -0.1070, -0.0888, -0.0895, -0.0688, -0.0550, -0.0949, -0.0501, -0.0700,\n                       -0.0604, -0.0457, -0.0557, -0.0662, -0.0494, -0.0691, -0.0759, -0.0714,\n                       -0.0534, -0.0962, -0.0713, -0.0566, -0.0879, -0.0679, -0.0968, -0.0792,\n                       -0.0495, -0.0851, -0.0532, -0.0855, -0.0660, -0.0689, -0.0652, -0.0530,\n                       -0.0825, -0.0614, -0.0838, -0.0852, -0.0697, -0.0963, -0.0567, -0.0686,\n                       -0.0443, -0.0872, -0.0559, -0.0792, -0.0560, -0.0791, -0.0720, -0.0893,\n                       -0.0871, -0.0611, -0.0741, -0.0614, -0.0789, -0.0734, -0.0833, -0.0501,\n                       -0.0647, -0.0444, -0.0829, -0.0719, -0.0525, -0.0921, -0.0492, -0.0634,\n                       -0.0600, -0.0778, -0.0793, -0.0811, -0.0558, -0.0800, -0.0972, -0.0814,\n                       -0.0837, -0.0510, -0.0639, -0.0932, -0.0699, -0.0850, -0.0849, -0.0748,\n                       -0.0609, -0.0838, -0.0799, -0.0815, -0.0656, -0.0635, -0.0570, -0.0641,\n                       -0.0739, -0.0812, -0.0860, -0.0706, -0.0843, -0.0469, -0.0496, -0.0838,\n                       -0.0683, -0.0629, -0.0717, -0.0465, -0.0536, -0.0596, -0.0739, -0.0746,\n                       -0.0638, -0.0819, -0.0631, -0.0633, -0.0700, -0.0685, -0.0848, -0.0530,\n                       -0.0475, -0.0927, -0.0684, -0.0628, -0.0520, -0.0596, -0.0659, -0.0610,\n                       -0.0853, -0.0731, -0.0664, -0.0860, -0.0652, -0.0365, -0.0508, -0.0540,\n                       -0.0751, -0.0869, -0.0690, -0.0820, -0.0684, -0.0594, -0.0762, -0.0885,\n                       -0.0821, -0.0831, -0.0738, -0.0650, -0.0696, -0.0605, -0.0901, -0.0781,\n                       -0.0624, -0.0908, -0.0665, -0.0590, -0.0683, -0.0825, -0.0565, -0.0702,\n                       -0.0620, -0.0690, -0.0786, -0.0835, -0.0883, -0.0742, -0.0771, -0.0598,\n                       -0.0807, -0.0579, -0.0708, -0.0856, -0.0512, -0.0529, -0.0711, -0.0850,\n                       -0.0623, -0.0908, -0.0773, -0.0706, -0.0782, -0.0631, -0.0707, -0.0607,\n                       -0.0521, -0.0767, -0.0506, -0.0676, -0.0760, -0.0482, -0.0676, -0.1010,\n                       -0.0466, -0.0799, -0.0784, -0.0866, -0.0933, -0.0584, -0.0966, -0.0563,\n                       -0.0647, -0.0829, -0.0737, -0.0913, -0.0867, -0.0889, -0.0618, -0.0512,\n                       -0.0855, -0.0823, -0.0604, -0.0684, -0.0671, -0.0811, -0.0827, -0.0718,\n                       -0.0651, -0.0577, -0.0842, -0.0544, -0.0700, -0.0692, -0.0811, -0.0708,\n                       -0.0759, -0.0711, -0.0913, -0.0533, -0.0581, -0.0582, -0.0465, -0.0531,\n                       -0.0783, -0.0787, -0.0667, -0.0976, -0.0816, -0.0611, -0.0586, -0.0826,\n                       -0.0614, -0.0753, -0.0511, -0.0716, -0.0519, -0.0732, -0.0840, -0.0494,\n                       -0.0702, -0.0520, -0.0915, -0.0506, -0.0570, -0.0561, -0.0755, -0.0606,\n                       -0.0506, -0.0799, -0.0794, -0.0553, -0.0846, -0.0565, -0.0862, -0.0452,\n                       -0.0642, -0.0787, -0.0794, -0.0606, -0.0689, -0.0533, -0.0822, -0.0525,\n                       -0.0655, -0.0531, -0.0595, -0.0582, -0.0802, -0.0663, -0.0453, -0.0854,\n                       -0.0706, -0.0866, -0.0972, -0.0643, -0.0534, -0.0643, -0.0535, -0.0966,\n                       -0.0818, -0.0719, -0.0674, -0.0794, -0.0421, -0.0573, -0.0798, -0.0592,\n                       -0.0946, -0.0793, -0.0786, -0.0879, -0.0972, -0.0840, -0.0739, -0.0885,\n                       -0.0777, -0.0690, -0.0918, -0.0680, -0.0762, -0.0867, -0.0495, -0.0491,\n                       -0.0627, -0.0566, -0.0900, -0.0592, -0.0574, -0.0549, -0.0927, -0.0655,\n                       -0.0714, -0.0585, -0.0810, -0.0851, -0.0511, -0.0665, -0.0797, -0.0532,\n                       -0.0544, -0.0764, -0.0716, -0.0567, -0.0469, -0.0765, -0.0649, -0.0887,\n                       -0.0888, -0.0754, -0.0699, -0.0885, -0.0561, -0.0850, -0.0691, -0.0885,\n                       -0.0723, -0.0930, -0.0804, -0.0623, -0.0734, -0.0844, -0.0834, -0.0820,\n                       -0.0791, -0.0801, -0.0817, -0.0728, -0.0901, -0.0774, -0.0481, -0.0561,\n                       -0.0486, -0.0885, -0.0457, -0.0629, -0.0818, -0.0498, -0.0553, -0.0856,\n                       -0.0389, -0.0854, -0.0744, -0.0755, -0.0624, -0.0811, -0.0706, -0.0786,\n                       -0.0914, -0.0476, -0.0799, -0.0454, -0.0829, -0.0926, -0.0852, -0.0509,\n                       -0.0488, -0.0724, -0.0963, -0.0723, -0.0722, -0.0700, -0.0707, -0.0515,\n                       -0.0613, -0.0715, -0.0789, -0.0893, -0.0654, -0.0814, -0.0500, -0.0896,\n                       -0.0503, -0.0601, -0.0655, -0.0859, -0.0860, -0.0765, -0.0740, -0.0536,\n                       -0.0493, -0.0595, -0.0690, -0.0796, -0.0601, -0.0538, -0.0768, -0.1001,\n                       -0.0548, -0.0728, -0.0416, -0.0677, -0.0626, -0.0712, -0.0676, -0.0738,\n                       -0.0555, -0.0707, -0.0709, -0.0571, -0.0768, -0.0983, -0.0933, -0.0541,\n                       -0.0651, -0.0803, -0.0744, -0.0595, -0.0784, -0.0855, -0.0704, -0.0594,\n                       -0.0622, -0.0588, -0.0808, -0.0677, -0.0940, -0.0721, -0.0759, -0.0651,\n                       -0.0632, -0.0459, -0.0631, -0.0914, -0.0598, -0.0906, -0.0539, -0.0996,\n                       -0.0774, -0.0768, -0.0610, -0.0420, -0.0699, -0.0463, -0.0583, -0.0405,\n                       -0.0671, -0.0632, -0.0851, -0.0869, -0.0449, -0.0440, -0.0853, -0.0650,\n                       -0.0867, -0.0751, -0.0521, -0.0625, -0.0783, -0.0670, -0.0577, -0.0652,\n                       -0.0914, -0.0715, -0.0759, -0.0702, -0.0499, -0.0720, -0.0765, -0.0532,\n                       -0.0512, -0.0576, -0.0569, -0.0764, -0.0754, -0.0918, -0.0669, -0.0579,\n                       -0.0924, -0.0720, -0.0731, -0.0580, -0.0872, -0.0738, -0.0826, -0.0865,\n                       -0.0936, -0.0572, -0.0832, -0.0845, -0.0618, -0.0546, -0.0842, -0.0602,\n                       -0.0784, -0.0572, -0.0871, -0.0948, -0.0826, -0.0670, -0.0860, -0.0761,\n                       -0.0843, -0.0646, -0.0684, -0.0618, -0.0805, -0.0947, -0.0672, -0.0659,\n                       -0.0751, -0.0459, -0.0468, -0.0793, -0.0390, -0.0496, -0.0640, -0.0585,\n                       -0.0771, -0.0641, -0.0546, -0.0560, -0.0608, -0.0815, -0.0538, -0.0451,\n                       -0.0766, -0.0835, -0.0641, -0.0830, -0.0864, -0.0856, -0.0889, -0.0877,\n                       -0.0582, -0.0927, -0.0533, -0.0717, -0.0544, -0.0705, -0.0556, -0.0546,\n                       -0.0873, -0.0456, -0.0735, -0.0559, -0.0596, -0.0625, -0.0671, -0.0748,\n                       -0.0756, -0.0812, -0.0673, -0.0518, -0.0749, -0.0666, -0.0787, -0.0909,\n                       -0.0705, -0.0777, -0.0795, -0.0700, -0.0579, -0.0566, -0.0511, -0.0534,\n                       -0.0490, -0.0648, -0.0669, -0.0943, -0.0955, -0.0981, -0.0702, -0.0811,\n                       -0.0810, -0.0646, -0.0735, -0.0648, -0.0625, -0.0716, -0.0488, -0.0863,\n                       -0.0604, -0.0761, -0.0563, -0.0549, -0.0668, -0.0791, -0.0610, -0.0729,\n                       -0.0704, -0.0623, -0.0721, -0.0511, -0.0514, -0.0838, -0.0957, -0.0610,\n                       -0.0606, -0.0752, -0.0799, -0.0495, -0.0440, -0.0677, -0.0884, -0.0443,\n                       -0.0660, -0.0888, -0.0599, -0.0750, -0.0704, -0.0812, -0.0495, -0.0671,\n                       -0.0885, -0.0676, -0.0847, -0.0659, -0.0594, -0.0738, -0.0694, -0.0586,\n                       -0.0841, -0.0640, -0.0750, -0.0682, -0.0881, -0.0681, -0.0867, -0.0591,\n                       -0.0542, -0.0609, -0.0857, -0.0530, -0.0572, -0.0519, -0.1008, -0.0565,\n                       -0.0816, -0.0816, -0.0804, -0.0558, -0.0672, -0.0815, -0.0894, -0.0586,\n                       -0.0938, -0.0484, -0.0594, -0.0874, -0.0634, -0.0595, -0.0624, -0.0732,\n                       -0.0908, -0.0580, -0.0582, -0.0646, -0.0630, -0.0609, -0.0441, -0.0867,\n                       -0.0624, -0.0786, -0.0673, -0.0818, -0.0772, -0.0546, -0.0702, -0.0581,\n                       -0.0703, -0.0554, -0.0799, -0.0591, -0.0955, -0.0746, -0.0732, -0.0837,\n                       -0.0698, -0.0676, -0.0951, -0.0579, -0.0733, -0.0575, -0.0840, -0.0491,\n                       -0.0634, -0.0853, -0.0590, -0.0418, -0.0476, -0.0601, -0.0451, -0.0627]))]),\n 'optimizer': {'state': {0: {'exp_avg': tensor([-1.3861e-07, -9.9390e-07, -3.9214e-07, -4.7554e-07, -1.0174e-06,\n             2.7522e-07,  6.9101e-07,  8.5545e-07,  6.0965e-07, -1.6145e-07,\n             5.7934e-07,  4.9682e-07,  5.6749e-07,  4.9102e-07, -2.1833e-07,\n            -8.8731e-08, -1.1429e-06,  4.3873e-08,  1.9991e-06, -1.8914e-08,\n            -1.4081e-06,  2.3085e-06,  5.6092e-08, -1.3577e-06,  1.8306e-06,\n            -1.9578e-06, -5.6474e-07,  5.5171e-07, -4.1558e-07,  8.7424e-07,\n            -7.7609e-08, -1.0108e-07,  4.9484e-07,  1.9053e-06, -4.1705e-07,\n             2.3355e-07, -1.0722e-06, -1.4432e-06, -2.3248e-06, -4.0184e-08,\n            -1.1399e-06, -1.1114e-07, -1.9396e-06, -1.1436e-06,  9.6298e-07,\n             1.5532e-06,  1.1161e-06, -9.1222e-07,  1.2694e-06, -3.4552e-07,\n             2.1998e-07,  6.2773e-07,  5.1539e-07, -2.2744e-07, -1.6146e-06,\n             1.2311e-06, -4.0270e-08, -4.2613e-08, -1.3430e-06,  8.2066e-07,\n             1.5654e-06, -6.1641e-07,  5.5431e-07,  8.8286e-07]),\n    'exp_avg_sq': tensor([2.2019e-11, 1.7590e-11, 4.0253e-11, 2.0069e-11, 6.0498e-11, 9.3066e-12,\n            2.7430e-11, 1.4887e-11, 4.0092e-11, 1.7615e-11, 1.2754e-11, 3.6682e-11,\n            2.3112e-11, 1.2977e-11, 2.5767e-11, 2.5715e-11, 4.4557e-11, 3.0927e-11,\n            3.7788e-11, 3.3713e-11, 3.0219e-11, 5.5397e-11, 7.3881e-11, 2.9787e-11,\n            3.5512e-11, 1.2546e-10, 1.5599e-11, 2.7252e-11, 2.3614e-11, 1.7142e-11,\n            2.7553e-11, 1.5187e-11, 1.6377e-11, 4.3125e-11, 1.6274e-11, 6.5160e-11,\n            2.5037e-11, 1.9316e-11, 8.2656e-11, 4.7842e-11, 4.7779e-11, 3.5563e-11,\n            2.6338e-11, 2.2363e-11, 2.2558e-11, 3.3271e-11, 1.5321e-11, 5.4101e-11,\n            3.6220e-11, 3.1582e-11, 3.0832e-11, 4.7728e-11, 3.8710e-11, 5.9236e-11,\n            2.4391e-11, 3.5531e-11, 2.2592e-11, 1.0803e-11, 2.4061e-11, 1.2669e-11,\n            2.1418e-11, 1.8856e-11, 4.7296e-11, 3.4049e-11])},\n   1: {'exp_avg': tensor([-5.1086e-08, -2.4826e-09,  1.0018e-07, -3.0753e-07, -8.8383e-09,\n             9.3275e-07,  1.3415e-08,  5.9063e-08, -2.3272e-07, -7.9906e-07,\n             6.6844e-07,  6.7296e-08,  5.8787e-08, -3.5176e-07,  1.0263e-06,\n             4.2242e-08, -1.7275e-08, -1.2305e-07,  9.8904e-09, -5.7971e-08,\n            -2.9125e-08, -9.0696e-08,  1.0220e-06, -6.5166e-07, -5.0605e-07,\n            -7.0171e-07,  3.9782e-08,  1.3813e-07,  1.0908e-08,  3.0607e-07,\n            -3.2479e-07, -1.6081e-07,  1.7407e-08,  3.6303e-08,  7.2311e-07,\n             2.2443e-07, -4.8429e-07, -4.3114e-07, -1.9912e-07,  7.9576e-07,\n             1.0030e-07,  1.7959e-08, -1.6990e-07, -1.1068e-06,  3.4463e-07,\n             3.5661e-08,  2.2675e-07, -2.3260e-09,  6.0444e-08, -1.0214e-07,\n             5.4926e-07,  1.4456e-07, -7.3269e-07, -1.4844e-07, -4.1701e-07,\n             3.8415e-07, -8.5209e-09, -5.0898e-07,  5.5939e-07, -1.5695e-07,\n             8.6024e-08,  6.8228e-08,  1.3126e-07,  2.8614e-07]),\n    'exp_avg_sq': tensor([3.0536e-12, 1.1989e-12, 5.5115e-13, 5.3007e-12, 6.9899e-14, 4.2049e-12,\n            2.0517e-13, 1.4140e-12, 3.2577e-12, 9.3332e-12, 5.7660e-12, 7.4947e-13,\n            6.9480e-13, 1.2137e-12, 4.9863e-12, 7.6448e-12, 3.7009e-15, 6.5746e-12,\n            1.9305e-12, 1.0043e-11, 8.7579e-13, 6.6410e-13, 6.2088e-12, 3.6182e-12,\n            9.2519e-12, 6.9791e-12, 6.5522e-13, 2.8003e-13, 3.5276e-14, 5.5152e-12,\n            1.2134e-12, 3.8730e-12, 1.9687e-12, 2.6013e-12, 4.9475e-12, 2.4411e-12,\n            9.0123e-12, 4.2549e-12, 2.4928e-12, 3.3318e-12, 1.3987e-12, 2.0929e-13,\n            9.0140e-12, 4.3419e-12, 2.2187e-12, 3.6336e-13, 4.9257e-12, 1.3471e-14,\n            9.4355e-14, 5.2608e-13, 2.8711e-12, 2.2341e-13, 6.3688e-12, 2.1620e-12,\n            2.6718e-12, 1.6269e-12, 5.5442e-12, 3.8012e-12, 4.1199e-12, 4.3059e-12,\n            1.1360e-12, 2.9546e-13, 3.8094e-13, 2.0536e-12])},\n   2: {'exp_avg': tensor([-3.4662e-08,  2.9207e-07, -7.1005e-09,  1.5942e-07, -1.3304e-07,\n            -1.2859e-07,  3.4267e-07,  2.5964e-07,  3.0319e-07,  1.1311e-07,\n             3.8489e-07,  3.2863e-07,  1.5743e-07,  1.0515e-07, -1.1359e-07,\n            -6.3936e-08, -6.1279e-08,  2.2140e-07,  2.6408e-09,  2.3690e-07,\n            -2.9342e-07,  1.4309e-07, -7.2795e-08,  9.0273e-08,  3.4306e-07,\n             1.5310e-07, -1.2954e-07, -3.6584e-07,  2.6612e-07,  6.3521e-08,\n             1.8129e-07, -1.3337e-07, -4.2191e-08, -2.6254e-07, -1.6550e-07,\n             2.1017e-07,  1.2472e-07, -4.0174e-08,  1.2327e-07,  3.2181e-07,\n            -5.8432e-07,  5.0163e-08, -1.2553e-07, -3.0945e-07, -5.5980e-07,\n            -5.6158e-07,  1.6486e-07, -3.5041e-07,  5.2386e-07, -3.7844e-07,\n            -4.2105e-07, -1.4727e-07,  3.2164e-08,  1.4735e-07,  1.3450e-07,\n            -1.9988e-07, -2.1825e-07, -2.3164e-07,  3.2301e-07,  1.3244e-07,\n            -6.1156e-08,  2.5151e-07,  3.0905e-07, -6.2121e-09]),\n    'exp_avg_sq': tensor([1.0187e-12, 8.9537e-13, 1.5030e-12, 1.0208e-12, 8.1783e-13, 1.1367e-12,\n            2.6675e-12, 1.6130e-12, 1.9847e-12, 1.2354e-12, 8.0302e-13, 1.5844e-12,\n            1.2115e-12, 1.0634e-12, 9.6928e-13, 1.5755e-12, 6.7587e-13, 1.4299e-12,\n            3.9363e-12, 9.2188e-13, 1.2778e-12, 1.1013e-12, 1.3317e-12, 9.0419e-13,\n            6.3856e-12, 2.0789e-12, 9.6135e-13, 9.1799e-13, 5.4736e-13, 2.2877e-12,\n            9.9011e-13, 4.3899e-12, 1.1120e-12, 1.9260e-12, 1.0950e-12, 1.7152e-12,\n            3.4912e-12, 1.2110e-12, 2.6814e-12, 9.9262e-13, 3.0819e-12, 7.3364e-13,\n            1.0376e-12, 1.8490e-12, 1.3195e-12, 1.5784e-12, 1.2937e-12, 1.1544e-12,\n            1.8971e-12, 1.4415e-12, 1.3521e-12, 9.6088e-13, 2.2506e-12, 1.0171e-12,\n            2.8005e-12, 9.9011e-13, 2.1351e-12, 1.8198e-12, 2.1791e-12, 1.0506e-12,\n            1.6313e-12, 1.2953e-12, 1.6808e-12, 8.7153e-13])},\n   3: {'exp_avg': tensor([ 2.3570e-07, -1.0082e-07, -2.6187e-07,  1.9790e-07, -3.3459e-07,\n             1.8952e-07,  2.5950e-07,  1.6784e-07,  3.4737e-07,  7.8880e-08,\n             2.6615e-07,  4.4735e-07, -1.3902e-07, -7.1989e-08, -1.8184e-07,\n             6.0952e-08, -1.6141e-07,  2.4412e-07, -1.0491e-07,  6.4449e-08,\n            -3.3384e-07, -4.0716e-08, -7.4353e-08,  2.7352e-08,  2.3936e-07,\n             3.4070e-07, -1.4426e-07,  9.6464e-08,  1.6047e-07,  1.6714e-08,\n             3.5193e-08,  8.3626e-08, -1.7064e-07, -3.6738e-08, -5.8261e-08,\n             3.3832e-07,  1.6809e-07, -2.9947e-08,  3.1950e-07, -5.0542e-09,\n            -6.6435e-07,  8.6123e-08, -1.8051e-07, -5.4546e-07, -5.2550e-07,\n            -1.3286e-09, -4.4806e-08,  1.2533e-07, -1.2099e-07,  2.2377e-07,\n            -3.7254e-07, -2.8640e-08, -5.2736e-07,  2.2871e-07,  2.6294e-07,\n            -2.4091e-07,  4.5572e-08, -8.4653e-08, -4.0462e-07,  1.2502e-07,\n            -9.0153e-09, -2.1378e-07, -3.9020e-08, -1.2759e-07]),\n    'exp_avg_sq': tensor([1.1405e-12, 1.2357e-12, 1.3051e-12, 1.0059e-12, 8.3746e-13, 1.3344e-12,\n            4.0556e-12, 1.6246e-12, 1.6246e-12, 2.2036e-12, 9.0366e-13, 2.0457e-12,\n            1.9401e-12, 1.1292e-12, 1.5732e-12, 2.4865e-12, 1.0824e-12, 1.0600e-12,\n            4.0588e-12, 1.1672e-12, 1.4510e-12, 1.0248e-12, 1.1780e-12, 1.0966e-12,\n            9.2147e-12, 2.2583e-12, 1.0162e-12, 8.7751e-13, 8.4872e-13, 2.6108e-12,\n            8.5827e-13, 2.0836e-12, 1.0708e-12, 2.1579e-12, 1.0427e-12, 1.7647e-12,\n            5.1531e-12, 1.3698e-12, 4.2430e-12, 1.1242e-12, 3.1064e-12, 1.0277e-12,\n            1.2113e-12, 1.7421e-12, 1.3938e-12, 1.4217e-12, 1.4916e-12, 1.7143e-12,\n            1.2879e-12, 1.7864e-12, 1.3077e-12, 1.1315e-12, 1.5251e-12, 1.3985e-12,\n            3.1847e-12, 1.1830e-12, 1.9319e-12, 1.5891e-12, 1.4325e-12, 1.1956e-12,\n            2.0201e-12, 1.0528e-12, 1.5102e-12, 1.0231e-12])},\n   4: {'exp_avg': tensor([ 1.7239e-07, -7.6602e-08, -3.3265e-07,  3.7402e-08,  2.4538e-07,\n            -1.5972e-07,  2.1427e-07,  3.3776e-08,  5.4994e-08, -4.5390e-08,\n            -5.7833e-10,  1.0893e-07, -7.2838e-07, -7.0274e-08, -6.5506e-08,\n            -1.1720e-07, -1.1816e-07, -2.4448e-07, -9.9507e-08,  4.1945e-09,\n             6.1563e-08, -1.8426e-07, -1.4683e-07, -2.2138e-07,  5.1068e-08,\n            -2.0623e-07,  2.9669e-07, -7.6460e-08, -5.5672e-08,  3.7606e-07,\n            -1.4231e-07, -1.4230e-07, -1.3762e-07, -3.0203e-08,  2.1851e-07,\n             1.9474e-08,  1.9536e-07,  3.2939e-07,  1.6361e-07,  3.1849e-07,\n             3.9745e-07, -2.8600e-08, -1.5069e-09, -2.5543e-07, -1.3925e-07,\n             4.9794e-07,  2.3809e-07,  6.6997e-08,  1.5320e-07,  9.6973e-08,\n            -2.2511e-07, -1.1391e-07,  3.0496e-07,  2.1165e-07,  8.3019e-08,\n            -4.4475e-07,  1.4350e-07,  3.1452e-07,  6.8079e-08, -2.6125e-08,\n            -2.0358e-07,  3.2893e-07, -2.9304e-07,  1.5654e-07]),\n    'exp_avg_sq': tensor([9.9823e-13, 2.8591e-12, 1.2100e-12, 1.5999e-12, 1.8135e-12, 1.4028e-12,\n            1.0626e-12, 9.1417e-13, 6.5680e-13, 6.0613e-13, 3.7425e-12, 1.8989e-12,\n            4.4139e-12, 9.7633e-13, 1.4176e-12, 2.8902e-12, 1.0730e-12, 1.7452e-12,\n            1.4313e-12, 5.4373e-12, 1.3535e-12, 1.1552e-12, 5.4846e-13, 1.9091e-12,\n            1.0584e-12, 2.5357e-12, 1.1098e-12, 1.2285e-12, 1.3274e-12, 1.8269e-12,\n            1.0893e-12, 1.0189e-12, 2.4886e-12, 5.4148e-13, 1.0207e-12, 1.0022e-12,\n            7.0782e-13, 7.1688e-13, 1.1862e-12, 1.2932e-12, 3.3253e-12, 3.1835e-12,\n            1.3018e-12, 1.2810e-12, 1.7667e-12, 9.6724e-13, 1.0519e-12, 8.8274e-13,\n            7.5753e-13, 1.2463e-12, 9.0791e-13, 1.5993e-12, 1.4235e-12, 8.8221e-13,\n            9.3463e-13, 1.6400e-12, 1.0579e-12, 1.0532e-12, 7.3089e-13, 8.6983e-13,\n            2.2636e-12, 9.0131e-13, 1.0438e-12, 8.4673e-13])},\n   5: {'exp_avg': tensor([ 3.0984e-07, -3.6334e-07, -1.6666e-07, -3.0442e-07, -1.3294e-08,\n            -9.5973e-08,  1.7127e-07,  2.0911e-07,  1.2522e-07, -2.9976e-07,\n            -1.4778e-07,  1.0540e-07, -3.0506e-07, -3.6231e-08,  1.5987e-07,\n            -9.0065e-07,  1.3476e-07, -3.0594e-07, -3.8351e-08,  2.1206e-07,\n             1.1711e-07,  4.1027e-08, -5.4770e-08, -5.2626e-07,  2.2194e-07,\n            -2.4272e-07,  3.0073e-07, -1.4993e-07,  1.9648e-07,  2.5776e-07,\n            -3.6737e-07, -1.2792e-07,  2.8093e-08, -1.9075e-07,  5.8506e-08,\n             9.9396e-08, -2.0221e-07,  2.8284e-09, -2.7549e-07,  2.1199e-07,\n             2.2821e-07, -2.9892e-07, -1.5910e-07, -2.2819e-07, -6.2367e-07,\n             2.0296e-07, -1.2609e-07,  3.0885e-07, -1.0483e-07, -9.5099e-08,\n            -2.3616e-07,  5.9364e-08, -2.6187e-08, -7.9447e-08, -1.6055e-07,\n            -2.5109e-07, -1.0705e-07,  1.3555e-07, -1.3449e-07, -4.4544e-08,\n            -1.7904e-07,  1.4862e-07, -2.7283e-07, -1.3322e-07]),\n    'exp_avg_sq': tensor([9.4448e-13, 1.8673e-12, 8.3612e-13, 1.3755e-12, 1.0400e-12, 1.0421e-12,\n            6.8663e-13, 7.4557e-13, 5.5425e-13, 5.7547e-13, 1.5028e-12, 1.8881e-12,\n            1.6037e-12, 5.9391e-13, 8.2084e-13, 3.0851e-12, 7.7199e-13, 1.0202e-12,\n            1.1808e-12, 1.2035e-12, 9.1964e-13, 9.1219e-13, 4.4822e-13, 1.4712e-12,\n            8.6035e-13, 1.5227e-12, 8.1367e-13, 7.8884e-13, 1.0083e-12, 1.0322e-12,\n            7.1593e-13, 8.3506e-13, 1.0095e-12, 5.6873e-13, 8.3785e-13, 9.4140e-13,\n            6.4430e-13, 7.1395e-13, 8.5920e-13, 1.1876e-12, 2.1006e-12, 4.0260e-12,\n            1.7726e-12, 8.6975e-13, 2.0976e-12, 6.8307e-13, 1.0097e-12, 5.3923e-13,\n            7.4162e-13, 9.4818e-13, 5.3097e-13, 6.1970e-13, 9.1298e-13, 8.3404e-13,\n            7.1448e-13, 1.3217e-12, 1.0818e-12, 6.4745e-13, 6.8246e-13, 6.3784e-13,\n            9.5943e-13, 5.3547e-13, 9.8956e-13, 7.7351e-13])},\n   6: {'exp_avg': tensor([-2.7733e-07,  9.3271e-07, -2.7991e-07,  7.4442e-08,  6.1524e-07,\n            -3.0307e-07,  7.2576e-07, -6.3889e-07, -4.9678e-08,  9.1356e-08,\n            -1.3739e-06, -9.6480e-07, -6.4834e-07, -7.1867e-07, -7.9470e-07,\n             7.7634e-07,  6.7095e-07, -3.6888e-07, -3.8246e-07,  1.1769e-08,\n            -5.3405e-07, -3.6828e-07, -1.3772e-06, -6.5621e-07,  1.7067e-07,\n            -3.2918e-08, -5.8621e-07,  1.1103e-06,  2.8776e-07, -6.6738e-07,\n            -2.1411e-07,  8.4763e-07,  7.9109e-07, -1.5886e-07,  6.8548e-07,\n             6.2014e-07,  3.3180e-07, -9.1542e-08,  5.6144e-07, -4.0667e-08,\n             1.9927e-08,  3.8698e-07, -1.0032e-07,  4.0224e-07,  7.4998e-07,\n            -1.7601e-06,  7.3145e-07, -7.1926e-07,  1.2448e-06, -5.8014e-07,\n            -1.5518e-07, -3.8656e-07, -5.3879e-07, -1.1097e-06,  6.1041e-07,\n             6.1919e-07,  9.0320e-07, -1.1846e-06, -1.2936e-06, -1.9885e-07,\n            -9.9550e-08, -1.6637e-07, -5.8906e-07, -4.8417e-07,  3.0722e-07,\n            -2.7613e-07,  1.3756e-06,  2.7580e-07,  2.3298e-09,  4.2914e-07,\n            -1.6994e-06, -8.2706e-07,  5.6718e-07, -5.0449e-07, -3.4123e-07,\n            -1.2424e-07,  5.6977e-07, -1.7411e-07, -1.8661e-07, -7.9363e-09,\n             4.6295e-07,  5.3911e-07, -1.0962e-07, -3.9246e-08, -1.7620e-07,\n             3.6847e-07,  2.1210e-06,  1.3976e-07,  5.2700e-07,  7.7063e-07,\n            -1.4237e-07, -6.0190e-07,  2.8558e-07, -1.3058e-07,  1.1231e-06,\n            -1.0675e-07, -3.6174e-07, -9.8501e-07,  8.1967e-07,  3.5204e-07,\n             1.4597e-09, -1.1393e-06,  1.6665e-06, -6.0219e-07, -4.0585e-07,\n             8.7001e-07, -1.6999e-06, -1.0288e-06,  3.1518e-08,  5.0295e-07,\n             2.1961e-07,  3.6078e-07,  8.7551e-07,  6.1575e-07, -3.1682e-07,\n             4.6038e-07, -1.4086e-07,  2.1723e-07,  3.2209e-07, -1.0669e-07,\n            -4.5665e-07, -4.7110e-07, -2.7426e-07,  1.6854e-07, -5.5371e-07,\n            -7.9291e-08, -2.6099e-07, -3.4365e-08,  6.2354e-08,  7.6670e-08,\n            -5.0268e-07,  5.2811e-07,  3.8327e-07, -2.9470e-07,  1.0901e-07,\n             2.8868e-07,  1.0153e-07, -1.0180e-06, -2.1409e-07,  6.2526e-07,\n            -4.5661e-07,  2.4901e-06,  1.2919e-07, -1.7683e-06,  3.2606e-07,\n             6.3449e-08, -9.7047e-08, -1.8743e-07, -3.2763e-07,  1.4068e-06,\n            -2.3308e-07, -1.4053e-06,  3.3561e-07,  2.0155e-07, -6.4852e-07,\n             9.8353e-07, -2.4503e-06,  3.9091e-07,  3.8548e-07, -3.9539e-07,\n            -6.5697e-07, -4.3754e-07,  7.1063e-07, -1.3264e-06,  3.9833e-07,\n            -2.1631e-07,  3.3909e-07, -1.0987e-06,  1.2255e-07, -8.3945e-07,\n             2.0802e-08, -2.4885e-07,  6.3381e-07, -9.3354e-08,  7.2874e-07,\n             1.0348e-06,  7.9907e-07,  1.6576e-07,  1.9177e-08, -5.5328e-07,\n            -8.6692e-07,  1.2757e-06, -6.4646e-07, -7.2484e-07, -2.7972e-07,\n             2.5303e-07, -1.1511e-07, -1.6519e-07, -5.2003e-07, -7.8452e-08,\n             6.9564e-08, -4.9196e-09,  1.3805e-08, -1.7245e-07, -8.7019e-07,\n             4.9665e-07,  8.9161e-08,  1.8831e-07,  5.5828e-07, -5.8849e-07,\n            -3.9987e-08,  2.0280e-07, -1.1710e-06, -3.4936e-07,  1.7110e-07,\n            -2.1684e-07,  8.6634e-08,  6.7225e-07, -1.9593e-07,  3.2536e-07,\n            -6.6718e-07,  7.9464e-08,  3.6847e-07,  3.1001e-07,  1.3848e-07,\n             6.3757e-07, -1.7546e-08,  2.0521e-07,  3.2434e-07, -8.0909e-07,\n            -4.3065e-07,  9.1143e-09, -7.6708e-07, -2.9569e-07,  5.6182e-07,\n            -3.2096e-08,  3.8933e-07,  3.4499e-07, -4.1391e-07,  8.6954e-07,\n             2.1590e-08, -1.2340e-07,  1.0944e-08, -6.2856e-07, -6.9574e-08,\n            -5.2226e-08, -1.8402e-07,  8.6712e-08,  4.9321e-07,  5.1866e-07,\n            -9.5832e-07, -1.4400e-07,  5.4742e-08, -1.3294e-06,  8.4230e-07,\n             9.3032e-07, -1.5278e-06, -1.6201e-06,  2.6924e-07,  1.1540e-07,\n            -4.7632e-07, -8.4674e-07, -7.4219e-07, -7.1347e-09, -3.5717e-07,\n            -6.1923e-07]),\n    'exp_avg_sq': tensor([5.8557e-12, 1.2867e-11, 1.5383e-12, 9.9947e-12, 6.2639e-12, 6.1202e-12,\n            3.8450e-12, 3.5095e-11, 3.1589e-12, 9.1415e-12, 1.4169e-11, 8.0716e-12,\n            5.6113e-12, 1.2943e-11, 1.0650e-11, 1.3822e-11, 1.8991e-11, 2.1530e-11,\n            4.3258e-12, 5.4434e-12, 1.2003e-11, 7.6024e-12, 1.5315e-11, 1.0260e-11,\n            9.2171e-12, 3.0191e-12, 1.4717e-11, 5.3311e-12, 9.0646e-12, 5.6720e-12,\n            7.2255e-12, 2.3406e-11, 2.1204e-11, 1.3575e-11, 1.8338e-11, 3.9027e-12,\n            5.7013e-12, 4.1728e-12, 1.4090e-11, 6.6557e-12, 1.4371e-12, 4.8528e-11,\n            3.1804e-12, 3.6809e-12, 1.8478e-11, 1.4792e-11, 6.3212e-12, 2.3809e-11,\n            8.2193e-12, 1.2228e-11, 9.3030e-12, 1.5497e-11, 5.3345e-12, 2.9389e-11,\n            8.3234e-12, 2.6234e-11, 2.0901e-11, 3.3099e-12, 1.3261e-11, 3.3852e-12,\n            1.4074e-11, 5.4963e-12, 1.5788e-11, 3.0792e-11, 1.3709e-11, 4.2521e-12,\n            2.0790e-11, 3.5245e-12, 2.5051e-12, 9.2782e-12, 2.4828e-11, 7.3171e-12,\n            4.0119e-12, 3.4371e-12, 4.1862e-12, 1.7222e-11, 1.3835e-11, 1.0432e-11,\n            2.0432e-11, 6.8869e-12, 4.3149e-12, 3.1618e-12, 4.8497e-12, 1.8119e-11,\n            6.0146e-12, 5.9648e-12, 3.9227e-11, 7.8312e-12, 2.7047e-12, 1.3476e-11,\n            4.2969e-12, 2.1014e-11, 3.4573e-12, 7.9197e-12, 1.5719e-11, 2.6150e-12,\n            5.8679e-12, 9.4885e-12, 1.1451e-11, 6.8939e-12, 3.0398e-11, 8.2061e-12,\n            1.0423e-11, 7.1817e-12, 7.1813e-12, 1.2750e-11, 2.2612e-11, 5.2783e-12,\n            8.9566e-12, 8.2393e-12, 1.4231e-11, 1.5173e-11, 8.7106e-12, 7.8371e-12,\n            4.0050e-12, 2.7446e-12, 3.6167e-12, 9.5577e-12, 1.1675e-11, 8.1080e-12,\n            5.3371e-12, 8.1362e-12, 1.6842e-11, 7.7524e-12, 6.9180e-12, 1.2940e-11,\n            2.2568e-12, 8.4937e-12, 1.5142e-11, 8.4325e-12, 9.1600e-12, 1.6890e-11,\n            3.9266e-12, 1.0776e-11, 8.2926e-12, 4.6240e-12, 2.3457e-12, 1.4983e-11,\n            3.7073e-11, 1.0639e-11, 1.0478e-11, 7.6644e-11, 3.7790e-12, 1.3493e-11,\n            3.7210e-12, 1.4682e-11, 2.0808e-11, 1.6661e-11, 5.6624e-12, 3.4509e-11,\n            1.5538e-12, 2.3057e-11, 8.3855e-12, 8.0331e-12, 1.0029e-11, 1.1419e-11,\n            1.9797e-11, 1.3079e-11, 2.5504e-12, 4.0906e-12, 1.8301e-11, 9.0580e-12,\n            7.0459e-12, 9.4209e-12, 2.5210e-12, 8.7329e-12, 2.8026e-12, 1.2223e-11,\n            2.6778e-11, 1.4267e-11, 5.0226e-12, 5.0571e-12, 1.7859e-11, 1.1778e-11,\n            1.1676e-11, 8.8994e-12, 8.4407e-12, 1.7108e-11, 1.2661e-11, 5.3806e-12,\n            8.8383e-12, 2.3490e-11, 9.9303e-12, 1.7016e-11, 2.2980e-11, 3.4339e-12,\n            7.4933e-12, 3.4731e-12, 2.8378e-11, 1.6213e-12, 3.7859e-12, 5.8540e-12,\n            9.1574e-12, 7.8636e-12, 1.1054e-11, 1.9468e-11, 4.2712e-12, 6.6154e-12,\n            2.0441e-11, 9.5258e-12, 3.2765e-12, 1.8359e-11, 3.4732e-11, 5.4491e-12,\n            6.5507e-12, 6.5523e-12, 9.2868e-12, 7.7212e-12, 1.0088e-11, 9.7039e-12,\n            9.4328e-12, 5.7207e-12, 8.9396e-12, 7.7840e-12, 3.2021e-12, 3.0383e-11,\n            5.3635e-12, 5.4390e-12, 4.2886e-12, 1.7507e-11, 5.1230e-12, 2.2485e-11,\n            1.2883e-11, 4.7117e-12, 8.9350e-12, 7.9005e-12, 1.0488e-11, 5.9935e-12,\n            8.2541e-12, 1.4238e-11, 2.9317e-11, 5.1645e-12, 4.4325e-12, 6.9931e-12,\n            2.9417e-12, 2.5929e-12, 1.0050e-11, 4.4522e-12, 2.9542e-12, 2.7227e-12,\n            1.3132e-11, 1.8071e-12, 1.1097e-11, 8.3741e-12, 1.7856e-11, 6.0944e-12,\n            2.2909e-11, 4.3518e-11, 2.7493e-12, 1.2663e-11, 8.8587e-12, 1.4703e-11,\n            1.1570e-11, 9.9536e-12, 6.2077e-12, 6.6937e-12])},\n   7: {'exp_avg': tensor([-1.0074e-07, -2.4376e-07, -6.8585e-08, -4.9754e-07,  6.6091e-07,\n             2.2655e-07,  1.3989e-07, -5.1868e-07, -8.6464e-07,  1.7408e-07,\n            -2.5491e-07,  2.1702e-07, -6.4686e-07,  4.6835e-07, -1.3779e-07,\n            -5.4853e-07,  1.6952e-07, -1.9538e-07,  1.3404e-07, -9.2529e-08,\n            -3.5769e-07,  4.4878e-07, -2.9985e-07, -2.8972e-07,  4.3293e-07,\n             4.2881e-08, -1.5015e-07,  2.1526e-07,  7.0044e-08, -6.6855e-07,\n            -4.4854e-07,  2.1281e-07, -1.3240e-07,  3.9739e-07, -1.0599e-07,\n             8.7817e-08, -3.8625e-08,  1.7009e-07, -2.6322e-07,  3.5151e-07,\n            -2.9831e-07,  3.0499e-07,  9.7511e-08, -1.8990e-07,  6.1206e-07,\n            -3.0046e-08,  1.2425e-07,  2.0128e-07,  1.3225e-07, -5.1110e-07,\n            -4.0527e-08,  2.4780e-07, -1.4172e-07, -3.1909e-07, -4.6816e-08,\n             2.5175e-07,  9.6719e-08,  1.0316e-07, -2.5579e-07, -1.0281e-07,\n            -1.8018e-07,  1.7950e-09, -2.6262e-07,  5.2900e-07, -3.8213e-07,\n            -5.1971e-07,  5.1061e-08, -3.6596e-09, -2.2588e-07, -3.9776e-07,\n            -1.2555e-07, -6.5284e-08, -4.4453e-08,  2.9350e-07, -1.8828e-07,\n             8.2075e-09, -9.1327e-07,  4.8975e-07, -7.0764e-08,  3.4199e-07,\n            -1.7055e-07,  1.4239e-07,  1.8229e-07, -8.4347e-08, -1.3178e-07,\n             1.9148e-07,  4.7631e-07,  2.8982e-07, -5.8661e-07,  5.3591e-07,\n             3.3812e-07, -6.5688e-08, -1.6364e-07, -4.3109e-08,  3.7961e-07,\n            -1.2408e-08,  1.7464e-07, -3.3643e-07,  8.3392e-08,  4.7595e-07,\n            -4.5253e-07, -6.5717e-08, -6.1715e-07, -4.5247e-07, -3.9031e-07,\n             2.2533e-07, -1.1362e-07,  7.2318e-07, -1.5260e-08,  4.1085e-08,\n            -9.9550e-08, -7.3408e-07,  2.7531e-07,  5.5846e-07,  5.0182e-07,\n             8.5147e-08,  6.6771e-07, -5.0192e-08, -1.2061e-07,  3.1737e-07,\n            -9.3023e-08, -3.0041e-07, -1.0229e-07,  1.2292e-08, -2.8510e-07,\n             2.4794e-07, -6.8125e-07, -1.1925e-08,  7.6568e-08, -8.6208e-07,\n             2.1695e-07, -6.2638e-07,  7.2063e-08, -7.6205e-08, -5.8645e-08,\n            -1.3934e-07,  5.6882e-08,  3.3353e-08, -1.9594e-07, -2.0600e-07,\n            -4.4639e-07, -4.7012e-07, -3.8787e-07, -1.3263e-07, -2.0369e-07,\n            -5.5657e-07, -2.5852e-07,  7.7147e-09,  5.4196e-07, -2.8328e-07,\n             1.1178e-07,  7.6027e-08,  1.5609e-08,  1.0577e-07, -3.1447e-07,\n             4.1075e-07, -1.3926e-07,  3.2812e-08,  2.7912e-07, -3.6558e-07,\n             6.7760e-08, -1.9716e-09,  2.6130e-07, -6.0777e-07, -1.4562e-07,\n            -1.0373e-07,  3.8748e-07, -1.3181e-06, -2.9176e-07,  9.8510e-08,\n            -1.7520e-07,  2.0371e-07, -8.4160e-08,  3.1804e-07,  1.2487e-07,\n            -3.4496e-07, -1.5432e-07, -7.4321e-07, -4.5538e-07, -2.9549e-07,\n             3.4772e-07, -3.8594e-07, -4.4566e-08,  4.8290e-08, -3.9260e-07,\n            -4.4908e-07,  3.6770e-07,  8.1651e-08, -2.0355e-07,  2.7377e-07,\n             1.9895e-07,  5.2283e-07,  4.7575e-09, -2.8047e-07, -1.7077e-07,\n            -8.9755e-08, -8.9368e-07, -2.1134e-08,  2.5372e-07, -8.8069e-08,\n            -9.5833e-10,  2.1909e-07,  1.7991e-07, -7.5619e-08,  2.6986e-07,\n             5.8630e-08, -2.2436e-07,  2.4470e-07,  4.0017e-07, -2.1810e-07,\n             4.4618e-08,  2.2278e-07, -3.2217e-07, -1.0347e-07,  6.4501e-07,\n            -7.1202e-08, -1.7567e-07,  1.5563e-08, -4.4266e-07, -4.8841e-07,\n            -6.5584e-07, -2.3080e-08, -3.6145e-07, -1.7645e-07,  3.2160e-07,\n             8.2005e-07,  2.0368e-07, -2.8386e-07, -6.1755e-08, -3.3226e-08,\n            -3.2216e-07,  1.7708e-07,  2.5097e-07, -5.1825e-07,  1.3913e-07,\n            -6.6693e-07,  1.7420e-07, -8.6324e-08,  2.1058e-07,  2.6690e-07,\n            -3.0464e-07, -3.4737e-08,  1.1700e-06,  5.4391e-07, -1.6474e-08,\n            -2.9787e-07, -1.7884e-07, -6.3870e-07, -1.3120e-08,  4.5256e-07,\n            -7.7975e-08, -2.2927e-07, -2.6694e-07,  3.7139e-07, -2.7146e-07,\n            -9.6129e-08]),\n    'exp_avg_sq': tensor([1.8813e-12, 1.4978e-12, 1.2983e-12, 3.4532e-12, 2.1719e-12, 2.1793e-12,\n            1.9063e-12, 1.5436e-11, 2.1930e-12, 3.4390e-12, 2.4432e-12, 2.0039e-12,\n            2.3540e-12, 3.9021e-12, 2.8633e-12, 1.9406e-12, 2.3878e-12, 8.7061e-12,\n            1.9095e-12, 3.0028e-12, 1.7723e-12, 2.4540e-12, 2.6801e-12, 2.4810e-12,\n            3.5056e-12, 1.7465e-12, 5.0116e-12, 2.9249e-12, 2.5699e-12, 2.8931e-12,\n            1.5640e-12, 6.9694e-12, 1.6702e-12, 2.7799e-12, 2.5450e-12, 3.2943e-12,\n            2.6500e-12, 1.6146e-12, 1.5112e-12, 2.1649e-12, 1.5362e-12, 5.8424e-12,\n            3.8614e-12, 1.2756e-12, 5.2598e-12, 3.2110e-12, 2.5877e-12, 6.3781e-12,\n            3.3915e-12, 3.3278e-12, 2.9877e-12, 2.9731e-12, 2.3838e-12, 3.3312e-12,\n            2.5064e-12, 2.9880e-12, 1.3906e-12, 1.7280e-12, 2.3712e-12, 1.7118e-12,\n            2.5856e-12, 2.7595e-12, 4.1711e-12, 2.1476e-12, 5.4472e-12, 2.6904e-12,\n            2.0326e-12, 1.4046e-12, 2.8896e-12, 1.9970e-12, 5.6801e-12, 2.5962e-12,\n            2.6319e-12, 2.3546e-12, 2.0744e-12, 4.4801e-12, 5.3492e-12, 2.9020e-12,\n            2.8192e-12, 3.8445e-12, 3.8031e-12, 1.4746e-12, 2.3676e-12, 4.2507e-12,\n            3.3313e-12, 2.6990e-12, 9.1287e-12, 3.2244e-12, 2.3961e-12, 2.3552e-12,\n            2.9957e-12, 4.1848e-12, 2.1236e-12, 3.0708e-12, 4.7099e-12, 2.5151e-12,\n            2.8689e-12, 2.4378e-12, 3.3004e-12, 3.9214e-12, 3.9478e-12, 1.9431e-12,\n            4.1197e-12, 1.9477e-12, 3.8525e-12, 3.7767e-12, 4.0029e-12, 2.3801e-12,\n            2.8706e-12, 2.4627e-12, 2.3547e-12, 2.9268e-12, 3.5282e-12, 2.5944e-12,\n            1.5168e-12, 1.6935e-12, 1.9447e-12, 1.8976e-12, 3.6843e-12, 2.9094e-12,\n            1.3569e-12, 3.5546e-12, 4.3686e-12, 1.4419e-12, 2.0315e-12, 2.9910e-12,\n            1.5049e-12, 2.2769e-12, 1.2684e-12, 2.7893e-12, 3.8250e-12, 5.4856e-12,\n            2.5497e-12, 2.4840e-12, 1.6970e-12, 2.6357e-12, 1.5015e-12, 2.9676e-12,\n            8.8676e-12, 3.0060e-12, 4.3446e-12, 3.6887e-12, 1.5699e-12, 3.5702e-12,\n            1.7114e-12, 1.5445e-12, 5.4208e-12, 2.2311e-12, 2.3918e-12, 1.8372e-12,\n            2.0492e-12, 3.6726e-12, 2.0455e-12, 2.0451e-12, 2.4490e-12, 2.3318e-12,\n            2.0954e-12, 5.9463e-12, 1.5115e-12, 1.6043e-12, 2.2505e-12, 1.9894e-12,\n            1.9329e-12, 2.6772e-12, 1.5758e-12, 3.0697e-12, 2.4921e-12, 7.4680e-12,\n            8.6742e-13, 2.5874e-12, 2.4042e-12, 2.3927e-12, 3.0836e-12, 2.8263e-12,\n            2.1800e-12, 1.7348e-12, 1.8774e-12, 2.7829e-12, 3.5341e-12, 2.0438e-12,\n            2.2905e-12, 6.1856e-12, 2.1358e-12, 3.6304e-12, 3.4251e-12, 1.9457e-12,\n            2.5425e-12, 1.7126e-12, 3.2180e-12, 1.5025e-12, 1.5568e-12, 2.3363e-12,\n            1.8063e-12, 1.5760e-12, 1.6228e-12, 7.1876e-12, 2.7931e-12, 2.1879e-12,\n            3.2564e-12, 2.6136e-12, 1.4215e-12, 4.5691e-12, 4.6825e-12, 2.8861e-12,\n            1.8621e-12, 2.7372e-12, 2.0198e-12, 1.9817e-12, 2.3752e-12, 1.8105e-12,\n            2.4583e-12, 4.5889e-12, 2.5421e-12, 2.2292e-12, 2.1931e-12, 4.8783e-12,\n            1.6500e-12, 2.3709e-12, 2.2212e-12, 4.3991e-12, 3.0665e-12, 5.0153e-12,\n            2.9604e-12, 1.3395e-12, 2.0582e-12, 2.5611e-12, 2.3263e-12, 2.4972e-12,\n            2.3869e-12, 2.9317e-12, 4.6431e-12, 2.7809e-12, 2.0331e-12, 2.7609e-12,\n            2.3250e-12, 1.9073e-12, 2.7945e-12, 2.1021e-12, 1.7297e-12, 2.7590e-12,\n            3.0253e-12, 1.1820e-12, 3.3337e-12, 2.0194e-12, 2.1985e-12, 1.7905e-12,\n            4.0989e-12, 9.4724e-12, 1.9210e-12, 3.0852e-12, 1.5860e-12, 3.1542e-12,\n            5.4080e-12, 1.7974e-12, 2.1923e-12, 3.6088e-12])},\n   8: {'exp_avg': tensor([-3.6039e-08, -2.2515e-07, -6.3376e-08, -2.8893e-07, -7.3192e-08,\n             6.0202e-08, -1.2641e-07, -7.3765e-07, -9.7652e-07,  1.5698e-07,\n            -8.1445e-07,  1.2861e-06, -3.2135e-07,  4.7392e-07,  2.4224e-08,\n            -2.5394e-07, -8.1359e-08, -3.2214e-07,  3.3512e-07, -1.0222e-07,\n             3.9381e-07,  9.1725e-07, -8.2202e-07, -1.6096e-07,  2.0553e-07,\n             3.1552e-07, -2.3219e-07,  4.5103e-07,  1.9522e-07, -3.0726e-07,\n            -1.8962e-08,  1.3957e-07, -4.1467e-07,  3.6416e-07, -6.2880e-07,\n             8.9498e-07,  2.6508e-07, -6.6198e-08,  6.1315e-07,  1.4636e-07,\n            -1.1634e-07,  1.0054e-07,  2.3624e-07, -2.4107e-07,  3.0973e-07,\n             4.2229e-07, -4.3396e-09,  3.2258e-07,  5.0765e-07, -4.1916e-07,\n            -4.9658e-07, -3.7552e-08, -2.6280e-07,  1.1198e-07,  4.3388e-07,\n            -4.2442e-07,  1.0275e-06, -2.1568e-08, -3.8297e-07, -8.6741e-09,\n             7.4683e-08, -1.2398e-07, -2.6540e-07, -1.6640e-07, -6.8446e-07,\n            -6.2074e-07,  8.4558e-07,  6.5576e-08, -8.5149e-08, -3.4662e-07,\n            -1.3287e-07, -4.8216e-07,  4.4814e-07,  1.0185e-07, -1.4447e-07,\n            -3.0604e-07, -9.9848e-07,  2.6645e-07, -3.4167e-07, -5.4317e-08,\n             5.2582e-07,  3.6073e-07,  1.1763e-07, -5.8016e-07,  1.6290e-07,\n             4.4105e-08,  9.2797e-07,  4.0861e-07, -1.1855e-07,  7.6797e-07,\n             5.7522e-07,  2.5143e-07,  4.3921e-08, -6.3311e-08,  3.8512e-07,\n            -1.7758e-07,  1.7709e-07, -5.7296e-07, -1.3896e-07, -2.0436e-08,\n            -5.5289e-08,  4.0871e-07, -9.9711e-07, -2.8643e-07, -4.8462e-07,\n            -1.8082e-07,  3.9661e-07, -8.5590e-08,  2.2673e-07, -9.6271e-08,\n             4.9768e-07, -8.3839e-07,  3.3622e-07,  2.6375e-07,  3.6008e-07,\n            -1.5702e-08, -1.1230e-08,  1.5809e-07, -1.9340e-07,  4.3903e-07,\n             1.7507e-08, -1.5361e-07,  2.9252e-07,  3.0820e-07, -2.3399e-07,\n             2.9752e-07, -3.8504e-07,  2.3247e-07,  3.7429e-07, -2.4507e-07,\n             4.6091e-07, -1.1829e-06,  4.8796e-07,  3.0065e-07, -1.8706e-07,\n             2.3589e-07,  5.7354e-08, -2.7774e-07, -1.5604e-07, -1.9830e-07,\n             1.6359e-07,  9.2106e-07,  8.1207e-08, -8.8982e-07,  1.7793e-07,\n            -4.0168e-07, -2.9304e-07, -2.6883e-07,  7.8439e-07, -2.9207e-07,\n             3.7352e-07,  2.0836e-07,  2.6138e-07,  4.6261e-07,  4.3255e-07,\n             4.4004e-07,  1.0943e-06, -8.0157e-08,  3.3728e-07,  9.5057e-08,\n             2.0883e-07,  6.4574e-08,  3.1025e-07,  3.2851e-08, -2.2002e-07,\n             2.6659e-08,  3.3937e-07, -1.1378e-06,  6.3197e-07, -1.7703e-07,\n            -1.4503e-07, -1.1236e-08,  5.0185e-07,  3.5614e-07,  2.1345e-07,\n            -4.1219e-07, -9.8942e-07, -8.6027e-07, -3.7882e-07, -3.9716e-07,\n            -3.2789e-07,  7.9045e-07,  4.2701e-07,  1.3219e-08, -6.8569e-07,\n            -6.2034e-07,  4.2428e-07,  2.2485e-07,  2.5572e-07,  1.0686e-07,\n            -2.0560e-08, -4.7385e-09,  1.4141e-07, -5.0644e-07,  7.4984e-08,\n            -1.0061e-08, -6.4621e-07,  2.2117e-07,  3.5555e-07,  3.8534e-07,\n             5.4939e-09,  6.3600e-07,  4.3476e-07,  2.6732e-07,  2.2056e-07,\n             2.1176e-07,  4.7266e-08,  4.8429e-07,  5.3289e-07,  5.3909e-07,\n            -1.1718e-07,  2.6577e-07, -1.1689e-07, -4.9281e-08,  6.0576e-07,\n            -6.8754e-08, -1.6011e-07, -3.1728e-07, -2.5803e-07, -1.1037e-06,\n            -5.8378e-07,  3.5487e-07,  3.7128e-07, -1.6751e-07,  8.8801e-08,\n             4.3160e-07,  5.0575e-09, -1.7583e-07,  1.9871e-07,  5.5612e-07,\n            -1.4885e-07,  7.7360e-08,  5.6830e-07, -1.5875e-07,  1.7076e-07,\n            -4.3059e-07,  3.0704e-08, -2.6024e-07, -4.1520e-08,  3.6037e-07,\n            -3.5136e-07,  1.3220e-07,  6.6496e-07,  1.1708e-06, -5.1753e-07,\n             1.4495e-07,  5.0477e-07, -5.4869e-07, -3.1472e-08,  2.4966e-07,\n             1.4177e-07, -2.9972e-07, -7.0654e-07,  1.1802e-06,  5.6597e-08,\n             2.1828e-07]),\n    'exp_avg_sq': tensor([2.3485e-12, 7.0304e-12, 1.9518e-12, 2.9860e-12, 5.5056e-12, 3.8267e-12,\n            2.7442e-12, 1.2991e-11, 2.3735e-12, 3.3496e-12, 5.2211e-12, 5.5368e-12,\n            2.9851e-12, 4.1504e-12, 3.4080e-12, 4.5684e-12, 5.7926e-12, 7.4780e-12,\n            2.5719e-12, 2.4042e-12, 6.7721e-12, 8.1576e-12, 6.1416e-12, 3.4270e-12,\n            5.9576e-12, 1.7677e-12, 5.8723e-12, 1.5949e-12, 2.0898e-12, 2.2585e-12,\n            3.0009e-12, 4.8342e-12, 7.6594e-12, 2.7867e-12, 4.2028e-12, 1.4511e-11,\n            3.2229e-12, 2.6998e-12, 6.5927e-12, 3.3714e-12, 2.3010e-12, 1.8141e-11,\n            6.6619e-12, 1.9094e-12, 2.8234e-12, 9.7108e-12, 3.0643e-12, 5.5963e-12,\n            5.3710e-12, 2.4579e-12, 4.2245e-12, 1.1427e-11, 1.8611e-12, 4.8759e-12,\n            7.1574e-12, 1.2296e-11, 1.2611e-11, 1.7287e-12, 2.0633e-12, 2.6484e-12,\n            7.7006e-12, 3.2747e-12, 1.0164e-11, 1.1320e-11, 8.0687e-12, 3.8422e-12,\n            1.1178e-11, 1.7498e-12, 5.8276e-12, 5.1756e-12, 5.7694e-12, 5.2758e-12,\n            4.1813e-12, 3.5765e-12, 2.3097e-12, 5.7924e-12, 1.2954e-11, 3.3002e-12,\n            8.7591e-12, 3.9471e-12, 4.5771e-12, 3.3446e-12, 3.0061e-12, 2.8082e-12,\n            4.7908e-12, 5.1119e-12, 7.4481e-12, 2.6349e-12, 2.7520e-12, 6.2703e-12,\n            2.5275e-12, 7.2457e-12, 1.8242e-12, 5.0514e-12, 9.7256e-12, 3.1428e-12,\n            4.8304e-12, 6.5326e-12, 2.3965e-12, 7.2827e-12, 1.0732e-11, 3.6946e-12,\n            7.5058e-12, 7.1828e-12, 4.5172e-12, 5.1380e-12, 8.4446e-12, 2.9982e-12,\n            3.4273e-12, 2.3923e-12, 2.4611e-12, 5.4457e-12, 2.8980e-12, 3.5461e-12,\n            2.0305e-12, 2.1293e-12, 3.1273e-12, 1.8671e-12, 4.8951e-12, 5.1284e-12,\n            1.7030e-12, 4.5744e-12, 5.0961e-12, 5.2006e-12, 2.3313e-12, 2.0174e-12,\n            2.0295e-12, 3.3588e-12, 5.3041e-12, 3.7949e-12, 3.6027e-12, 1.2625e-11,\n            5.6904e-12, 4.2431e-12, 3.9498e-12, 4.8084e-12, 1.3643e-12, 4.0972e-12,\n            6.5264e-12, 2.7435e-12, 2.7291e-12, 3.3620e-11, 2.0992e-12, 6.1517e-12,\n            1.6897e-12, 1.0054e-11, 6.1173e-12, 5.6230e-12, 4.5061e-12, 1.4552e-11,\n            3.4316e-12, 2.8323e-12, 2.1906e-12, 4.2835e-12, 3.5634e-12, 4.2383e-12,\n            9.4467e-12, 6.9365e-12, 2.2400e-12, 2.4341e-12, 5.4973e-12, 5.1071e-12,\n            3.1173e-12, 4.5411e-12, 1.2961e-12, 3.4559e-12, 4.7652e-12, 5.6212e-12,\n            9.9502e-12, 4.4900e-12, 4.7667e-12, 3.0049e-12, 8.0828e-12, 6.8983e-12,\n            9.6345e-12, 4.1176e-12, 4.0306e-12, 7.1279e-12, 4.7256e-12, 1.2129e-12,\n            4.8687e-12, 9.4712e-12, 2.8720e-12, 4.4137e-12, 8.8518e-12, 3.4223e-12,\n            4.9475e-12, 2.2069e-12, 1.6216e-11, 4.0896e-12, 2.2456e-12, 3.5529e-12,\n            4.5219e-12, 3.8022e-12, 4.6825e-12, 9.8630e-12, 2.7714e-12, 2.9332e-12,\n            4.9521e-12, 4.8408e-12, 2.6235e-12, 6.6241e-12, 1.4202e-11, 2.7916e-12,\n            3.6432e-12, 4.2574e-12, 2.6458e-12, 3.6116e-12, 5.1233e-12, 6.0364e-12,\n            2.7129e-12, 7.6115e-12, 4.0009e-12, 2.2826e-12, 5.4753e-12, 1.0262e-11,\n            2.6991e-12, 6.1417e-12, 1.9239e-12, 1.2787e-11, 3.8143e-12, 9.2866e-12,\n            4.6212e-12, 1.2272e-12, 3.6720e-12, 3.9313e-12, 6.4438e-12, 4.9854e-12,\n            2.6418e-12, 6.6152e-12, 1.0886e-11, 4.2916e-12, 7.3437e-12, 2.3158e-12,\n            4.2141e-12, 2.2920e-12, 6.3171e-12, 2.0427e-12, 1.7873e-12, 5.9230e-12,\n            4.0765e-12, 2.4471e-12, 1.6618e-11, 9.3738e-12, 1.1981e-11, 2.2908e-12,\n            6.9176e-12, 9.5518e-12, 3.8875e-12, 7.6338e-12, 3.2883e-12, 5.9478e-12,\n            4.1666e-12, 6.0568e-12, 2.6915e-12, 4.0147e-12])},\n   9: {'exp_avg': tensor([-1.0074e-07, -2.4376e-07, -6.8585e-08, -4.9754e-07,  6.6091e-07,\n             2.2655e-07,  1.3989e-07, -5.1868e-07, -8.6464e-07,  1.7408e-07,\n            -2.5491e-07,  2.1702e-07, -6.4686e-07,  4.6835e-07, -1.3779e-07,\n            -5.4853e-07,  1.6952e-07, -1.9538e-07,  1.3404e-07, -9.2529e-08,\n            -3.5769e-07,  4.4878e-07, -2.9985e-07, -2.8972e-07,  4.3293e-07,\n             4.2881e-08, -1.5015e-07,  2.1526e-07,  7.0044e-08, -6.6855e-07,\n            -4.4854e-07,  2.1281e-07, -1.3240e-07,  3.9739e-07, -1.0599e-07,\n             8.7817e-08, -3.8625e-08,  1.7009e-07, -2.6322e-07,  3.5151e-07,\n            -2.9831e-07,  3.0499e-07,  9.7511e-08, -1.8990e-07,  6.1206e-07,\n            -3.0046e-08,  1.2425e-07,  2.0128e-07,  1.3225e-07, -5.1110e-07,\n            -4.0527e-08,  2.4780e-07, -1.4172e-07, -3.1909e-07, -4.6816e-08,\n             2.5175e-07,  9.6719e-08,  1.0316e-07, -2.5579e-07, -1.0281e-07,\n            -1.8018e-07,  1.7950e-09, -2.6262e-07,  5.2900e-07, -3.8213e-07,\n            -5.1971e-07,  5.1061e-08, -3.6596e-09, -2.2588e-07, -3.9776e-07,\n            -1.2555e-07, -6.5284e-08, -4.4453e-08,  2.9350e-07, -1.8828e-07,\n             8.2075e-09, -9.1327e-07,  4.8975e-07, -7.0764e-08,  3.4199e-07,\n            -1.7055e-07,  1.4239e-07,  1.8229e-07, -8.4347e-08, -1.3178e-07,\n             1.9148e-07,  4.7631e-07,  2.8982e-07, -5.8661e-07,  5.3591e-07,\n             3.3812e-07, -6.5688e-08, -1.6364e-07, -4.3109e-08,  3.7961e-07,\n            -1.2408e-08,  1.7464e-07, -3.3643e-07,  8.3392e-08,  4.7595e-07,\n            -4.5253e-07, -6.5717e-08, -6.1715e-07, -4.5247e-07, -3.9031e-07,\n             2.2533e-07, -1.1362e-07,  7.2318e-07, -1.5260e-08,  4.1085e-08,\n            -9.9550e-08, -7.3408e-07,  2.7531e-07,  5.5846e-07,  5.0182e-07,\n             8.5147e-08,  6.6771e-07, -5.0192e-08, -1.2061e-07,  3.1737e-07,\n            -9.3023e-08, -3.0041e-07, -1.0229e-07,  1.2292e-08, -2.8510e-07,\n             2.4794e-07, -6.8125e-07, -1.1925e-08,  7.6568e-08, -8.6208e-07,\n             2.1695e-07, -6.2638e-07,  7.2063e-08, -7.6205e-08, -5.8645e-08,\n            -1.3934e-07,  5.6882e-08,  3.3353e-08, -1.9594e-07, -2.0600e-07,\n            -4.4639e-07, -4.7012e-07, -3.8787e-07, -1.3263e-07, -2.0369e-07,\n            -5.5657e-07, -2.5852e-07,  7.7147e-09,  5.4196e-07, -2.8328e-07,\n             1.1178e-07,  7.6027e-08,  1.5609e-08,  1.0577e-07, -3.1447e-07,\n             4.1075e-07, -1.3926e-07,  3.2812e-08,  2.7912e-07, -3.6558e-07,\n             6.7760e-08, -1.9716e-09,  2.6130e-07, -6.0777e-07, -1.4562e-07,\n            -1.0373e-07,  3.8748e-07, -1.3181e-06, -2.9176e-07,  9.8510e-08,\n            -1.7520e-07,  2.0371e-07, -8.4160e-08,  3.1804e-07,  1.2487e-07,\n            -3.4496e-07, -1.5432e-07, -7.4321e-07, -4.5538e-07, -2.9549e-07,\n             3.4772e-07, -3.8594e-07, -4.4566e-08,  4.8290e-08, -3.9260e-07,\n            -4.4908e-07,  3.6770e-07,  8.1651e-08, -2.0355e-07,  2.7377e-07,\n             1.9895e-07,  5.2283e-07,  4.7575e-09, -2.8047e-07, -1.7077e-07,\n            -8.9755e-08, -8.9368e-07, -2.1134e-08,  2.5372e-07, -8.8069e-08,\n            -9.5833e-10,  2.1909e-07,  1.7991e-07, -7.5619e-08,  2.6986e-07,\n             5.8630e-08, -2.2436e-07,  2.4470e-07,  4.0017e-07, -2.1810e-07,\n             4.4618e-08,  2.2278e-07, -3.2217e-07, -1.0347e-07,  6.4501e-07,\n            -7.1202e-08, -1.7567e-07,  1.5563e-08, -4.4266e-07, -4.8841e-07,\n            -6.5584e-07, -2.3080e-08, -3.6145e-07, -1.7645e-07,  3.2160e-07,\n             8.2005e-07,  2.0368e-07, -2.8386e-07, -6.1755e-08, -3.3226e-08,\n            -3.2216e-07,  1.7708e-07,  2.5097e-07, -5.1825e-07,  1.3913e-07,\n            -6.6693e-07,  1.7420e-07, -8.6324e-08,  2.1058e-07,  2.6690e-07,\n            -3.0464e-07, -3.4737e-08,  1.1700e-06,  5.4391e-07, -1.6474e-08,\n            -2.9787e-07, -1.7884e-07, -6.3870e-07, -1.3120e-08,  4.5256e-07,\n            -7.7975e-08, -2.2927e-07, -2.6694e-07,  3.7139e-07, -2.7146e-07,\n            -9.6129e-08]),\n    'exp_avg_sq': tensor([1.8813e-12, 1.4978e-12, 1.2983e-12, 3.4532e-12, 2.1719e-12, 2.1793e-12,\n            1.9063e-12, 1.5436e-11, 2.1930e-12, 3.4390e-12, 2.4432e-12, 2.0039e-12,\n            2.3540e-12, 3.9021e-12, 2.8633e-12, 1.9406e-12, 2.3878e-12, 8.7061e-12,\n            1.9095e-12, 3.0028e-12, 1.7723e-12, 2.4540e-12, 2.6801e-12, 2.4810e-12,\n            3.5056e-12, 1.7465e-12, 5.0116e-12, 2.9249e-12, 2.5699e-12, 2.8931e-12,\n            1.5640e-12, 6.9694e-12, 1.6702e-12, 2.7799e-12, 2.5450e-12, 3.2943e-12,\n            2.6500e-12, 1.6146e-12, 1.5112e-12, 2.1649e-12, 1.5362e-12, 5.8424e-12,\n            3.8614e-12, 1.2756e-12, 5.2598e-12, 3.2110e-12, 2.5877e-12, 6.3781e-12,\n            3.3915e-12, 3.3278e-12, 2.9877e-12, 2.9731e-12, 2.3838e-12, 3.3312e-12,\n            2.5064e-12, 2.9880e-12, 1.3906e-12, 1.7280e-12, 2.3712e-12, 1.7118e-12,\n            2.5856e-12, 2.7595e-12, 4.1711e-12, 2.1476e-12, 5.4472e-12, 2.6904e-12,\n            2.0326e-12, 1.4046e-12, 2.8896e-12, 1.9970e-12, 5.6801e-12, 2.5962e-12,\n            2.6319e-12, 2.3546e-12, 2.0744e-12, 4.4801e-12, 5.3492e-12, 2.9020e-12,\n            2.8192e-12, 3.8445e-12, 3.8031e-12, 1.4746e-12, 2.3676e-12, 4.2507e-12,\n            3.3313e-12, 2.6990e-12, 9.1287e-12, 3.2244e-12, 2.3961e-12, 2.3552e-12,\n            2.9957e-12, 4.1848e-12, 2.1236e-12, 3.0708e-12, 4.7099e-12, 2.5151e-12,\n            2.8689e-12, 2.4378e-12, 3.3004e-12, 3.9214e-12, 3.9478e-12, 1.9431e-12,\n            4.1197e-12, 1.9477e-12, 3.8525e-12, 3.7767e-12, 4.0029e-12, 2.3801e-12,\n            2.8706e-12, 2.4627e-12, 2.3547e-12, 2.9268e-12, 3.5282e-12, 2.5944e-12,\n            1.5168e-12, 1.6935e-12, 1.9447e-12, 1.8976e-12, 3.6843e-12, 2.9094e-12,\n            1.3569e-12, 3.5546e-12, 4.3686e-12, 1.4419e-12, 2.0315e-12, 2.9910e-12,\n            1.5049e-12, 2.2769e-12, 1.2684e-12, 2.7893e-12, 3.8250e-12, 5.4856e-12,\n            2.5497e-12, 2.4840e-12, 1.6970e-12, 2.6357e-12, 1.5015e-12, 2.9676e-12,\n            8.8676e-12, 3.0060e-12, 4.3446e-12, 3.6887e-12, 1.5699e-12, 3.5702e-12,\n            1.7114e-12, 1.5445e-12, 5.4208e-12, 2.2311e-12, 2.3918e-12, 1.8372e-12,\n            2.0492e-12, 3.6726e-12, 2.0455e-12, 2.0451e-12, 2.4490e-12, 2.3318e-12,\n            2.0954e-12, 5.9463e-12, 1.5115e-12, 1.6043e-12, 2.2505e-12, 1.9894e-12,\n            1.9329e-12, 2.6772e-12, 1.5758e-12, 3.0697e-12, 2.4921e-12, 7.4680e-12,\n            8.6742e-13, 2.5874e-12, 2.4042e-12, 2.3927e-12, 3.0836e-12, 2.8263e-12,\n            2.1800e-12, 1.7348e-12, 1.8774e-12, 2.7829e-12, 3.5341e-12, 2.0438e-12,\n            2.2905e-12, 6.1856e-12, 2.1358e-12, 3.6304e-12, 3.4251e-12, 1.9457e-12,\n            2.5425e-12, 1.7126e-12, 3.2180e-12, 1.5025e-12, 1.5568e-12, 2.3363e-12,\n            1.8063e-12, 1.5760e-12, 1.6228e-12, 7.1876e-12, 2.7931e-12, 2.1879e-12,\n            3.2564e-12, 2.6136e-12, 1.4215e-12, 4.5691e-12, 4.6825e-12, 2.8861e-12,\n            1.8621e-12, 2.7372e-12, 2.0198e-12, 1.9817e-12, 2.3752e-12, 1.8105e-12,\n            2.4583e-12, 4.5889e-12, 2.5421e-12, 2.2292e-12, 2.1931e-12, 4.8783e-12,\n            1.6500e-12, 2.3709e-12, 2.2212e-12, 4.3991e-12, 3.0665e-12, 5.0153e-12,\n            2.9604e-12, 1.3395e-12, 2.0582e-12, 2.5611e-12, 2.3263e-12, 2.4972e-12,\n            2.3869e-12, 2.9317e-12, 4.6431e-12, 2.7809e-12, 2.0331e-12, 2.7609e-12,\n            2.3250e-12, 1.9073e-12, 2.7945e-12, 2.1021e-12, 1.7297e-12, 2.7590e-12,\n            3.0253e-12, 1.1820e-12, 3.3337e-12, 2.0194e-12, 2.1985e-12, 1.7905e-12,\n            4.0989e-12, 9.4724e-12, 1.9210e-12, 3.0852e-12, 1.5860e-12, 3.1542e-12,\n            5.4080e-12, 1.7974e-12, 2.1923e-12, 3.6088e-12])},\n   10: {'exp_avg': tensor([ 5.7910e-08,  2.3645e-08,  2.1878e-07,  8.6928e-08,  7.2598e-07,\n             3.4199e-07,  1.7035e-07,  3.3394e-07, -3.5838e-07,  4.3229e-08,\n            -7.2767e-08, -4.6370e-07,  7.7886e-08, -1.4153e-07, -3.3616e-07,\n            -2.9792e-07,  3.9988e-07,  2.4557e-07, -2.2041e-07,  2.3852e-07,\n             2.6156e-07,  5.0423e-07, -1.5162e-07, -3.3655e-07, -4.4280e-07,\n            -2.4751e-07, -8.3329e-07, -9.2133e-09, -1.2086e-07, -3.4413e-07,\n             5.9950e-08,  2.0737e-07,  1.8476e-07, -1.9439e-07,  2.3100e-07,\n            -2.9239e-07,  8.1355e-07, -6.4498e-08, -2.7105e-07,  4.1892e-08,\n            -1.3659e-07, -3.6447e-07, -4.2587e-07,  2.5977e-07, -4.2652e-07,\n            -2.0013e-07,  1.4022e-07, -3.3585e-07,  3.6995e-07,  4.3627e-07,\n             2.0543e-07,  1.7528e-07,  2.1210e-07, -2.6174e-07, -3.1192e-07,\n            -9.7528e-08, -2.5077e-08, -1.2430e-07, -7.7052e-08, -1.9287e-07,\n             5.8446e-07,  5.7086e-07,  2.1682e-07, -3.1099e-08]),\n    'exp_avg_sq': tensor([1.2650e-12, 1.1114e-12, 1.2452e-12, 1.8736e-12, 4.0613e-12, 1.4230e-12,\n            1.5044e-12, 2.5131e-12, 1.1753e-12, 3.0167e-12, 1.4554e-12, 2.2800e-12,\n            2.3228e-12, 1.2111e-12, 1.7817e-12, 3.5537e-12, 1.8992e-12, 4.2755e-12,\n            8.5408e-13, 1.5868e-12, 2.8904e-12, 6.8806e-12, 1.1110e-12, 1.7624e-12,\n            1.2116e-12, 1.1399e-12, 2.6031e-12, 3.0745e-12, 8.0338e-13, 1.1975e-12,\n            2.3228e-12, 2.3340e-12, 1.6747e-12, 1.3081e-12, 1.7625e-12, 5.6749e-12,\n            1.1980e-12, 1.0260e-11, 2.5722e-12, 1.8908e-12, 2.2370e-12, 1.5716e-12,\n            1.7228e-12, 1.1985e-12, 4.0898e-12, 1.4858e-12, 1.3652e-12, 7.4190e-12,\n            1.6971e-12, 2.1471e-12, 1.8688e-12, 2.1040e-12, 1.6675e-12, 2.1568e-12,\n            1.0332e-12, 7.1883e-13, 1.4717e-12, 2.1623e-12, 2.5403e-12, 1.1434e-12,\n            1.3827e-12, 4.2719e-11, 1.1501e-12, 1.8624e-12])},\n   11: {'exp_avg': tensor([ 4.5908e-08, -9.2650e-09,  3.2306e-07,  1.2225e-07,  4.6521e-07,\n             1.9348e-07,  1.9153e-07,  1.7958e-07, -8.4965e-08,  3.5682e-08,\n            -1.7369e-07, -2.2778e-07,  1.3877e-07,  1.9109e-07, -2.3895e-07,\n             2.0582e-07,  7.8898e-08,  1.9567e-07, -4.3822e-07,  4.4514e-07,\n             6.3402e-08,  4.4661e-07, -2.8435e-07, -4.7962e-07, -2.1784e-07,\n            -2.9404e-07, -4.5182e-07, -1.6709e-07, -1.6040e-07, -7.1448e-08,\n             4.0405e-07, -3.3230e-07, -1.7570e-07, -6.2596e-08,  4.7892e-08,\n            -2.8697e-07,  3.4131e-07, -2.7571e-08, -4.6076e-07,  1.5306e-07,\n             1.7657e-07, -3.8412e-07, -1.8414e-07,  1.3686e-07, -5.7807e-07,\n            -1.8435e-07,  1.5188e-07,  9.8614e-08, -2.3797e-07,  1.9167e-07,\n             5.3679e-08,  3.9893e-07,  2.3053e-07, -2.6958e-07, -2.6135e-07,\n            -1.6326e-07, -1.3884e-07,  3.8644e-09, -2.3888e-07, -3.8305e-07,\n             1.9015e-07, -2.6269e-07,  3.9657e-08, -1.5507e-09]),\n    'exp_avg_sq': tensor([9.8976e-13, 1.0197e-12, 1.2476e-12, 1.1866e-12, 1.5882e-12, 1.4041e-12,\n            1.4244e-12, 8.9723e-13, 1.1564e-12, 2.5592e-12, 1.3814e-12, 1.4594e-12,\n            1.3304e-12, 9.8526e-13, 2.1145e-12, 2.4031e-12, 1.3950e-12, 1.6617e-12,\n            9.5848e-13, 1.4607e-12, 1.6079e-12, 1.0328e-12, 1.0268e-12, 1.0815e-12,\n            7.6496e-13, 1.2955e-12, 2.1048e-12, 2.0034e-12, 6.4647e-13, 1.8491e-12,\n            1.8413e-12, 2.0015e-12, 1.6443e-12, 1.1172e-12, 1.5430e-12, 4.0880e-12,\n            1.0038e-12, 2.0025e-12, 1.8974e-12, 1.6106e-12, 2.1026e-12, 1.0567e-12,\n            1.6437e-12, 7.2935e-13, 2.7905e-12, 1.1197e-12, 1.0732e-12, 2.0973e-12,\n            1.2036e-12, 1.8808e-12, 1.5163e-12, 1.5926e-12, 1.6060e-12, 1.9497e-12,\n            1.0290e-12, 7.8661e-13, 1.6552e-12, 1.6311e-12, 1.5844e-12, 1.0604e-12,\n            1.0969e-12, 4.6807e-12, 9.4348e-13, 1.1476e-12])},\n   12: {'exp_avg': tensor([-8.5086e-08, -2.6306e-07, -1.7905e-07,  5.0511e-08, -9.9701e-08,\n             9.8395e-08, -4.3642e-07, -4.7396e-07,  5.9741e-07, -3.5939e-07,\n             2.3341e-07, -3.6685e-07,  2.9381e-07,  3.5615e-07,  6.0514e-08,\n            -1.7336e-07,  1.2241e-07,  2.4202e-07,  2.6661e-07,  1.8679e-07,\n            -2.2274e-07,  1.3162e-07, -4.7672e-07, -3.0141e-07, -1.5061e-07,\n            -1.5891e-07,  4.4206e-07,  2.8524e-07, -2.9486e-08, -2.4830e-08,\n             4.7312e-08,  2.9059e-07, -3.7229e-08, -1.2617e-08,  2.9086e-07,\n            -2.7510e-07,  3.5954e-07, -1.7286e-07, -1.2006e-07, -1.7728e-07,\n             2.5690e-07,  2.5366e-07, -2.3099e-07,  1.5056e-07,  6.5010e-07,\n            -2.1094e-07, -3.4308e-07,  1.6480e-07, -2.6151e-08,  2.6494e-08,\n            -2.5562e-07,  3.7787e-07, -3.7431e-08,  2.1095e-07,  1.1475e-07,\n            -4.4004e-07,  1.5043e-07, -1.4087e-09,  3.5522e-07, -6.8561e-08,\n            -1.5368e-07, -1.8798e-08, -2.1824e-07, -3.1491e-07]),\n    'exp_avg_sq': tensor([2.2684e-12, 9.0489e-13, 1.0874e-12, 8.6430e-13, 1.4033e-12, 1.6416e-12,\n            2.3130e-12, 8.1669e-13, 1.0620e-12, 9.8045e-13, 1.5745e-12, 1.4507e-12,\n            1.2087e-12, 1.1949e-12, 8.1359e-13, 1.7469e-12, 1.3310e-12, 1.0295e-12,\n            7.7591e-13, 2.1390e-12, 2.4851e-12, 1.8888e-12, 1.0523e-12, 1.5051e-12,\n            2.9332e-12, 1.3484e-12, 1.4399e-12, 1.9788e-12, 1.2916e-12, 1.7208e-12,\n            3.4370e-12, 1.6048e-12, 1.1955e-12, 9.4217e-13, 2.8754e-12, 1.7807e-12,\n            3.2053e-12, 2.3033e-12, 8.6593e-13, 2.1429e-12, 1.0286e-11, 1.2779e-12,\n            7.4960e-12, 1.0093e-12, 1.3263e-12, 1.0044e-12, 2.9101e-12, 8.6712e-13,\n            1.8250e-12, 1.6710e-12, 3.4694e-12, 1.2678e-11, 1.4009e-12, 1.2244e-12,\n            1.7987e-12, 1.3285e-12, 1.0856e-12, 1.0481e-12, 2.7311e-12, 1.8435e-12,\n            1.4472e-12, 1.2941e-12, 7.9615e-13, 2.7870e-12])},\n   13: {'exp_avg': tensor([ 1.1882e-07, -1.8758e-08, -3.0756e-07, -1.1883e-07, -1.1592e-07,\n            -2.9416e-07, -1.9555e-07, -5.9341e-07,  2.3142e-07, -2.5258e-07,\n            -9.3074e-08, -1.7256e-07,  2.4677e-07, -1.2433e-07,  4.5369e-09,\n            -9.4725e-08,  3.0426e-08,  3.9694e-08,  1.3190e-07, -2.9184e-07,\n            -3.9907e-07,  4.1726e-08, -3.4034e-07, -1.9622e-07, -1.4364e-07,\n            -3.0029e-07, -9.4582e-08, -2.7233e-08, -2.7279e-07, -1.8443e-07,\n            -8.6085e-08, -2.8840e-07, -2.2225e-07, -1.1376e-07,  3.0226e-07,\n            -2.3186e-07,  5.3680e-08, -3.1264e-07, -1.7924e-07, -1.3720e-07,\n             2.2643e-07,  1.7192e-07,  5.6249e-08, -6.7974e-09,  1.8441e-07,\n            -7.3445e-08, -1.8891e-07, -1.7412e-07,  4.1300e-08,  1.1497e-07,\n             1.1909e-07,  2.9411e-07, -7.1019e-08,  1.3971e-07, -2.0549e-08,\n            -3.1129e-07, -1.0346e-07,  1.6617e-07,  2.0691e-07, -2.1000e-07,\n            -1.2414e-07, -6.3803e-08,  1.2027e-08, -3.3077e-07]),\n    'exp_avg_sq': tensor([1.5902e-12, 5.6559e-13, 7.3787e-13, 6.4323e-13, 7.1814e-13, 1.5281e-12,\n            1.6626e-12, 8.6663e-13, 1.0735e-12, 5.8860e-13, 9.3739e-13, 1.1387e-12,\n            1.0354e-12, 7.5949e-13, 5.4610e-13, 8.8258e-13, 1.1603e-12, 7.6117e-13,\n            6.1412e-13, 1.4625e-12, 1.4982e-12, 1.1753e-12, 5.8553e-13, 1.1471e-12,\n            2.1311e-12, 7.7742e-13, 1.2697e-12, 1.0275e-12, 9.2755e-13, 1.7496e-12,\n            1.9194e-12, 1.0679e-12, 8.0406e-13, 7.7102e-13, 1.0066e-12, 1.4387e-12,\n            1.4877e-12, 1.6156e-12, 6.5943e-13, 1.8351e-12, 1.3993e-12, 8.1237e-13,\n            1.3760e-12, 8.3521e-13, 9.2073e-13, 6.7224e-13, 1.2284e-12, 6.1154e-13,\n            1.5027e-12, 1.0383e-12, 2.7738e-12, 1.0195e-12, 1.2563e-12, 1.1227e-12,\n            1.6177e-12, 9.9057e-13, 7.9152e-13, 6.0223e-13, 1.7225e-12, 1.7450e-12,\n            9.9974e-13, 1.0211e-12, 5.8196e-13, 1.6678e-12])},\n   14: {'exp_avg': tensor([-1.4585e-08,  8.2038e-07, -1.7898e-07,  7.5810e-08, -8.2872e-08,\n             4.0222e-07,  2.7886e-07, -4.2841e-07,  7.6176e-08, -1.3091e-07,\n            -7.7022e-07, -8.4743e-07,  6.8814e-07,  6.5340e-07,  6.9332e-08,\n             5.5735e-07, -1.3880e-07, -8.0401e-07, -4.0956e-07, -3.9178e-07,\n             2.2534e-07,  6.3210e-07, -2.0261e-07,  6.6066e-07,  5.8047e-07,\n             2.1383e-07,  7.1313e-07, -2.6520e-07, -5.2699e-07, -2.1063e-07,\n             6.2068e-07,  2.0366e-07,  2.6580e-07, -6.0246e-07,  5.8245e-07,\n            -2.0411e-07, -1.3366e-06, -2.7369e-07,  2.2976e-07,  3.7788e-07,\n            -4.0057e-07,  1.8072e-06,  3.3651e-07, -1.5805e-08, -1.3716e-06,\n             2.0408e-06,  4.6652e-07, -5.2668e-07,  2.2416e-07,  7.0233e-07,\n            -9.6474e-07, -7.2335e-07, -6.3491e-08, -2.4421e-08,  5.9701e-07,\n             3.6796e-07,  7.8795e-07, -3.8143e-07,  7.1313e-07, -5.9422e-08,\n            -5.7345e-07,  2.2917e-07, -1.7579e-07, -9.8087e-08,  2.5039e-06,\n            -5.3277e-07, -9.5489e-08,  2.0462e-07,  8.5167e-08,  3.9955e-07,\n             1.2814e-06, -8.0025e-07,  9.2839e-07,  1.8047e-07,  2.1250e-07,\n            -2.3717e-07,  5.7290e-07, -1.7810e-07, -4.9819e-07, -6.7049e-07,\n            -1.2299e-06, -2.7645e-07,  3.8834e-07,  7.7341e-08,  1.7184e-07,\n            -1.1547e-07, -2.0465e-06, -1.0428e-07, -1.4102e-07, -9.0195e-07,\n            -1.0881e-07, -1.0395e-06,  3.6935e-07,  2.2358e-07, -1.6058e-07,\n            -5.7757e-07, -5.1567e-07,  1.4852e-07,  3.5730e-08, -9.1598e-07,\n             3.9980e-07, -4.3358e-07,  2.7193e-07, -2.1423e-07,  3.2066e-07,\n             7.9594e-07, -2.0908e-06,  3.3669e-07,  5.5347e-07,  2.4245e-07,\n             6.8974e-07,  5.5387e-07,  1.9106e-07, -6.4063e-07, -2.0730e-07,\n            -5.5819e-07, -9.5331e-07, -1.3149e-07, -4.2584e-07, -7.9319e-07,\n             6.7597e-07,  5.6140e-07,  1.0433e-06, -4.6677e-08,  1.4085e-07,\n             7.5528e-07, -1.9491e-08, -2.6717e-07,  8.9846e-08, -2.4506e-07,\n            -2.0396e-07, -3.0202e-07,  2.8253e-07, -1.2211e-07, -2.3645e-07,\n             4.4593e-07, -1.4001e-07, -1.3752e-08, -7.0396e-08,  8.5542e-07,\n            -9.5151e-07, -1.3374e-06,  2.8197e-07, -1.8691e-06,  1.2814e-07,\n            -3.0544e-07, -2.1518e-07, -7.2825e-07,  1.9462e-07, -1.5513e-07,\n            -4.0450e-07, -7.1945e-07, -1.2013e-07,  8.9215e-08,  1.4461e-06,\n            -8.2261e-07,  8.0401e-07,  4.4998e-07, -5.0197e-07, -3.2163e-07,\n             4.9329e-07,  1.6113e-07,  7.6384e-07, -1.8281e-07,  4.0136e-07,\n             8.9692e-07,  7.0469e-07,  4.9802e-07,  1.0454e-06,  4.8959e-07,\n             3.0219e-07,  2.1109e-07, -6.5980e-07, -2.5121e-07, -3.6256e-07,\n            -3.3186e-07,  6.5261e-07, -1.0690e-07,  2.8391e-07,  2.1040e-09,\n            -2.3879e-08,  4.9901e-07,  4.8116e-07, -5.1009e-08,  5.3531e-07,\n             6.8456e-07, -8.3480e-07, -5.5168e-08,  6.0701e-07,  2.2057e-07,\n             1.7015e-07,  2.7305e-07,  1.3534e-07, -2.0373e-07,  6.9096e-07,\n             9.5200e-07,  9.0375e-07, -1.4300e-07,  2.0047e-07,  1.3169e-07,\n            -1.6823e-07, -4.9254e-08, -6.4140e-07, -1.8032e-07,  1.6534e-07,\n             4.7100e-07,  1.2015e-07,  1.1218e-06,  6.0599e-07, -1.4539e-06,\n             2.7034e-07, -5.5136e-08,  5.6063e-07,  2.6086e-07, -2.0861e-07,\n             1.3254e-06,  2.1030e-07,  1.2173e-07,  3.0080e-07,  1.0054e-06,\n            -6.4249e-07,  1.7649e-07, -1.5235e-06,  3.5256e-07, -4.0433e-07,\n             3.3014e-07,  3.3002e-07, -3.5260e-07, -3.5897e-07, -9.3308e-07,\n            -3.2981e-07, -9.2529e-08, -5.8633e-07, -1.0631e-06, -9.9563e-07,\n            -3.6474e-07, -2.7031e-07,  1.9272e-06, -3.2898e-07,  5.0036e-07,\n            -5.9597e-07, -2.7508e-08,  8.3335e-07, -5.5301e-07, -9.8734e-07,\n             2.0793e-07,  1.1918e-06,  2.8172e-07, -3.9039e-07,  1.0352e-06,\n            -3.9097e-07,  1.1314e-07, -1.6499e-07, -2.1679e-07,  6.0590e-08,\n             3.7628e-07]),\n    'exp_avg_sq': tensor([4.3492e-12, 6.3438e-12, 1.8960e-12, 1.0812e-11, 4.7544e-12, 3.1910e-12,\n            5.9387e-12, 2.7334e-11, 2.3915e-12, 7.8754e-12, 1.1493e-11, 5.4016e-12,\n            4.9528e-12, 1.4275e-11, 5.5042e-12, 1.2092e-11, 5.9831e-12, 7.8215e-12,\n            3.9700e-12, 3.4700e-12, 9.3204e-12, 6.7178e-12, 1.0937e-11, 9.6752e-12,\n            1.0095e-11, 4.3915e-12, 1.9702e-11, 4.4773e-12, 4.9271e-12, 5.6053e-12,\n            5.2204e-12, 1.2259e-11, 6.3619e-12, 1.3201e-11, 7.2686e-12, 2.0173e-11,\n            9.5459e-12, 3.7658e-12, 1.4424e-11, 7.0809e-12, 2.1231e-12, 1.9951e-11,\n            6.3885e-12, 1.4693e-12, 9.1703e-12, 1.6079e-11, 4.4885e-12, 7.3050e-12,\n            1.0284e-11, 8.1670e-12, 1.0551e-11, 1.1923e-11, 2.0768e-12, 1.2309e-11,\n            8.9988e-12, 1.3975e-11, 1.1116e-11, 3.6087e-12, 6.0920e-12, 2.4954e-12,\n            1.1280e-11, 7.0161e-12, 1.6457e-11, 6.1720e-12, 2.3802e-11, 3.0297e-12,\n            9.6629e-12, 2.3799e-12, 5.8956e-12, 4.2898e-12, 1.3791e-11, 6.2238e-12,\n            6.6197e-12, 2.0040e-12, 5.4060e-12, 9.0271e-12, 5.5089e-12, 5.5148e-12,\n            8.7086e-12, 7.7998e-12, 6.7936e-12, 1.9074e-12, 6.1033e-12, 8.9276e-12,\n            1.8789e-12, 1.2671e-11, 1.2130e-11, 7.9700e-12, 4.7938e-12, 8.1379e-12,\n            4.4570e-12, 9.1268e-12, 5.0479e-12, 9.4198e-12, 2.5359e-11, 2.6113e-12,\n            1.4316e-12, 4.0146e-12, 2.0167e-11, 1.3653e-11, 1.1490e-11, 5.7397e-12,\n            9.3416e-12, 5.4672e-12, 4.5094e-12, 7.8325e-12, 2.5909e-11, 4.5841e-12,\n            4.8820e-12, 3.8588e-12, 1.6688e-11, 1.0945e-11, 7.2334e-12, 8.1396e-12,\n            4.9821e-12, 4.5502e-12, 3.7413e-12, 5.9896e-12, 1.0116e-11, 1.2351e-11,\n            4.6767e-12, 6.5517e-12, 1.3408e-11, 6.5655e-12, 3.3753e-12, 4.5966e-12,\n            3.9597e-12, 4.4078e-12, 9.8211e-12, 6.8514e-12, 6.2207e-12, 1.2430e-11,\n            3.5805e-12, 4.8156e-12, 8.8401e-12, 7.7960e-12, 3.3187e-12, 6.9141e-12,\n            2.2838e-11, 7.7711e-12, 7.8596e-12, 4.7268e-11, 4.1293e-12, 9.2433e-12,\n            4.2924e-12, 1.1749e-11, 7.1946e-12, 6.8454e-12, 4.4459e-12, 2.2940e-11,\n            3.6302e-12, 8.7792e-12, 3.9931e-12, 5.9906e-12, 1.1351e-11, 6.5630e-12,\n            1.7301e-11, 1.3367e-11, 2.7170e-12, 6.3294e-12, 5.5058e-12, 7.5802e-12,\n            6.1033e-12, 7.7699e-12, 3.5121e-12, 6.3770e-12, 4.1834e-12, 5.7029e-12,\n            1.0262e-11, 8.4604e-12, 6.0586e-12, 6.7855e-12, 1.8931e-11, 1.3831e-11,\n            7.4497e-12, 6.0718e-12, 3.9669e-12, 8.8362e-12, 7.9266e-12, 5.1781e-12,\n            6.8193e-12, 1.5714e-11, 5.3764e-12, 8.1698e-12, 1.3093e-11, 3.3790e-12,\n            5.7900e-12, 2.7081e-12, 2.5015e-11, 8.0871e-12, 1.0652e-12, 5.1293e-12,\n            7.7310e-12, 9.7940e-12, 3.4543e-12, 1.0251e-11, 4.8385e-12, 3.7546e-12,\n            1.5373e-11, 6.7717e-12, 1.7204e-12, 1.0694e-11, 2.1378e-11, 8.9638e-12,\n            7.7643e-12, 7.2371e-12, 6.1326e-12, 5.2342e-12, 7.9075e-12, 8.8802e-12,\n            7.6082e-12, 8.4089e-12, 9.8485e-12, 4.9233e-12, 2.6369e-12, 1.5507e-11,\n            6.4910e-12, 6.4412e-12, 2.4114e-12, 7.4328e-12, 5.8865e-12, 1.9149e-11,\n            9.4031e-12, 3.6218e-12, 6.4020e-12, 6.0129e-12, 5.7900e-12, 9.9071e-12,\n            5.5562e-12, 1.3237e-11, 1.6905e-11, 4.7497e-12, 3.5021e-12, 7.8877e-12,\n            4.8242e-12, 4.0546e-12, 4.1243e-12, 8.1491e-12, 4.2733e-12, 4.1655e-12,\n            8.6249e-12, 2.1161e-12, 1.1538e-11, 4.2923e-12, 1.4553e-11, 3.9313e-12,\n            1.5227e-11, 2.8070e-11, 3.1427e-12, 1.3866e-11, 7.5585e-12, 1.1979e-11,\n            6.5856e-12, 5.4687e-12, 6.8169e-12, 5.5874e-12])},\n   15: {'exp_avg': tensor([ 3.9319e-08, -2.1885e-08,  1.0666e-07, -2.4823e-07,  5.5590e-07,\n             6.9819e-08, -2.5395e-07, -1.2478e-07, -6.0226e-07, -2.8968e-07,\n            -3.2999e-07,  8.0276e-08, -6.8210e-07, -3.1599e-07, -6.9286e-08,\n             3.1801e-08,  3.1854e-07,  1.4953e-07, -1.2888e-07, -9.8604e-08,\n             3.0528e-08, -1.5167e-07, -2.4390e-07,  1.4294e-07, -1.0981e-08,\n            -9.6870e-08, -6.5148e-08,  1.7998e-07, -5.4520e-08, -1.9816e-08,\n             5.9455e-08,  1.7039e-07, -1.3565e-07,  4.8478e-07, -5.6735e-08,\n            -9.1820e-08, -5.8329e-08,  7.9354e-08,  9.7303e-08,  8.9863e-08,\n            -2.1637e-07,  2.3720e-07,  3.8049e-07, -6.5097e-08,  3.1153e-07,\n            -5.2566e-08,  2.1974e-07, -6.5575e-07,  2.9586e-07, -2.2175e-07,\n             9.7573e-09, -1.1558e-07, -1.8474e-07, -2.4071e-07, -2.4476e-07,\n             2.0199e-07, -1.6016e-07, -2.5994e-07, -2.7123e-07, -1.7600e-08,\n             1.4153e-07,  8.3616e-08,  8.2824e-08,  3.8143e-07,  2.9317e-07,\n            -2.1024e-07, -3.8056e-08, -2.0859e-07,  1.3522e-07, -1.8989e-07,\n            -7.2615e-08, -1.3677e-08,  2.2122e-07,  8.8028e-08, -1.8951e-07,\n            -1.2717e-07, -8.1493e-07, -1.5031e-08,  6.5908e-08,  2.6187e-07,\n             7.9669e-08,  1.5156e-07, -2.2797e-08, -2.4471e-07, -1.8612e-07,\n             7.8943e-08, -3.6513e-07,  4.6802e-07, -1.5413e-07,  4.6018e-07,\n             1.8468e-07,  2.2631e-07, -2.2683e-07, -3.0223e-07,  2.3275e-07,\n            -2.1508e-07,  2.4674e-07, -1.5618e-07,  1.7556e-08, -2.6092e-07,\n            -6.2764e-08,  5.8606e-08, -6.1848e-07, -1.6122e-07,  4.2496e-08,\n            -7.3666e-09, -8.2161e-08,  1.1015e-07,  1.0047e-07, -2.7198e-07,\n            -6.1879e-08,  3.4731e-08,  3.4878e-08,  1.2178e-07,  1.1842e-07,\n             1.7021e-07,  3.6085e-07, -3.6568e-07, -1.4571e-07, -9.0310e-09,\n             3.3022e-08,  5.8937e-08, -1.3153e-07, -1.0293e-07, -1.4049e-07,\n             4.2665e-08, -2.4186e-08,  3.2665e-07,  8.2226e-09, -2.7715e-07,\n             7.6266e-07,  8.7457e-08, -2.4958e-07,  6.6853e-08, -4.4765e-08,\n             2.3913e-07,  3.5118e-08,  6.3113e-09, -3.1614e-07,  7.0565e-08,\n            -3.7044e-07, -2.5576e-07, -1.0565e-08, -7.7353e-08, -1.4172e-07,\n            -2.9734e-08, -4.8299e-07, -7.5742e-09,  1.8756e-07, -2.5496e-07,\n            -1.8202e-07,  1.8668e-07,  3.4092e-07,  3.4072e-09, -1.1740e-07,\n             3.9404e-08, -1.6533e-07, -5.5077e-08,  5.4271e-07,  3.9722e-08,\n             1.3941e-07, -1.2870e-07, -1.3736e-07, -3.0602e-07,  1.0506e-07,\n            -3.0657e-07, -4.4649e-07, -1.0716e-06, -1.1384e-07, -1.4373e-08,\n            -1.6409e-08,  9.3857e-08,  7.2314e-08, -1.4099e-07, -4.9023e-08,\n            -9.6288e-09, -1.9351e-08, -8.2652e-07,  4.1243e-08, -1.6980e-07,\n            -2.4959e-09, -1.3600e-07, -3.6732e-07,  1.1175e-07, -9.7708e-09,\n            -2.6969e-07, -8.2357e-08,  3.2385e-07,  3.8881e-08, -5.4650e-08,\n             2.4538e-07,  1.3495e-07,  5.0444e-08, -2.6409e-07,  4.9048e-08,\n             1.3723e-08, -7.5279e-08, -1.3672e-07,  7.9157e-08,  3.8449e-08,\n            -1.6767e-07,  1.4061e-07, -3.6833e-07, -3.2650e-08,  1.0371e-07,\n             2.4027e-07,  1.0022e-07, -2.7887e-08,  7.1892e-08, -4.0649e-08,\n            -2.5340e-07, -1.3549e-07, -1.1448e-07, -1.7233e-07,  4.0714e-07,\n            -1.2631e-07, -1.1794e-07, -1.8334e-08, -4.9093e-07, -3.8621e-07,\n            -1.1083e-07, -2.5427e-07, -2.2303e-07, -2.6126e-07, -6.3102e-08,\n             6.0457e-08,  4.0033e-08, -4.9403e-08, -5.0747e-08,  8.4708e-08,\n            -3.9116e-07, -2.8055e-08,  2.1131e-08,  5.5242e-08,  3.0447e-08,\n            -3.0176e-08,  1.0956e-07,  6.2341e-08,  9.1482e-08,  2.1010e-07,\n            -3.4763e-07, -2.4633e-07,  8.6192e-07,  3.8409e-08, -8.3844e-08,\n            -4.2011e-07, -3.2610e-07, -6.4235e-07,  1.5561e-07, -3.5559e-08,\n             1.1744e-07, -2.8059e-07, -7.3849e-07, -5.0884e-09, -1.1767e-07,\n            -2.3269e-08]),\n    'exp_avg_sq': tensor([9.1106e-13, 1.7014e-13, 8.2530e-13, 1.2073e-12, 1.0766e-12, 5.3229e-13,\n            3.7624e-13, 3.4977e-12, 1.1734e-12, 1.8315e-12, 7.0804e-13, 3.3088e-13,\n            1.7216e-12, 2.5339e-12, 1.3892e-12, 1.6263e-13, 1.4005e-12, 4.2127e-12,\n            1.3557e-12, 1.1579e-12, 3.5460e-13, 6.9055e-13, 2.7787e-13, 4.6669e-13,\n            2.0846e-12, 3.7061e-13, 3.7192e-12, 2.0987e-12, 4.2236e-13, 1.3341e-13,\n            1.1688e-13, 5.0892e-12, 2.7127e-13, 2.1999e-12, 2.5713e-14, 1.8034e-12,\n            1.5624e-13, 6.3719e-13, 8.2681e-14, 4.3334e-13, 1.1778e-12, 1.8695e-12,\n            2.3693e-12, 1.0728e-12, 3.7497e-12, 1.5611e-13, 8.8184e-13, 3.4850e-12,\n            1.8147e-12, 3.5135e-13, 8.4609e-13, 3.1072e-13, 1.5029e-12, 1.8235e-12,\n            8.3436e-13, 1.1120e-12, 5.9807e-13, 2.6140e-13, 1.5131e-12, 9.2885e-13,\n            9.3967e-13, 2.7862e-13, 1.7315e-12, 1.0963e-12, 2.0387e-12, 1.5369e-12,\n            7.5565e-14, 9.5554e-13, 1.0226e-12, 7.7458e-13, 3.6244e-12, 3.4482e-13,\n            1.4666e-12, 1.3344e-12, 1.3375e-12, 1.4277e-12, 3.2284e-12, 2.0370e-13,\n            4.7600e-13, 1.9527e-12, 3.1824e-13, 1.0649e-12, 8.3877e-14, 3.4565e-12,\n            2.2336e-12, 8.3688e-13, 4.0335e-12, 2.4270e-12, 1.1751e-12, 1.2522e-12,\n            7.7584e-13, 1.9197e-12, 5.9689e-13, 7.6547e-13, 1.9063e-12, 1.6797e-12,\n            2.0901e-12, 7.1999e-13, 4.0664e-14, 2.3378e-12, 1.3738e-12, 7.4269e-13,\n            2.2065e-12, 7.4529e-13, 2.0195e-12, 1.8790e-12, 1.8753e-13, 2.7644e-13,\n            5.8353e-14, 9.0153e-13, 3.5214e-14, 1.7833e-13, 1.8818e-12, 9.7033e-13,\n            3.5304e-13, 3.4068e-13, 4.1262e-13, 4.7009e-13, 6.8899e-13, 1.0767e-13,\n            1.2424e-13, 6.9704e-13, 2.7998e-12, 2.5546e-13, 1.2032e-12, 1.8322e-12,\n            1.8342e-13, 1.5349e-12, 1.6493e-13, 5.5905e-13, 3.1325e-12, 3.2847e-14,\n            1.2341e-12, 9.7029e-13, 1.6798e-13, 7.4868e-13, 1.0012e-12, 5.3667e-13,\n            4.5803e-12, 1.0852e-12, 3.2306e-12, 2.9806e-13, 1.0226e-12, 1.0128e-12,\n            3.5452e-13, 2.2048e-13, 1.8271e-12, 8.6504e-14, 1.0161e-12, 2.1734e-13,\n            1.1099e-12, 7.1279e-13, 8.7663e-13, 2.4951e-13, 1.7087e-13, 2.7270e-14,\n            2.5162e-13, 3.9415e-12, 1.1970e-12, 3.7956e-13, 2.2523e-13, 3.1631e-13,\n            3.8756e-13, 1.5946e-12, 1.0417e-12, 1.1385e-12, 1.0491e-12, 4.6245e-12,\n            1.4858e-13, 3.5432e-13, 4.8923e-13, 1.7666e-13, 1.3892e-12, 4.6040e-13,\n            1.4514e-12, 2.7961e-13, 4.1398e-13, 1.6053e-12, 1.9818e-12, 1.1402e-12,\n            2.6246e-14, 9.9447e-13, 5.8245e-13, 1.7626e-12, 5.5012e-13, 1.7380e-12,\n            9.2782e-14, 7.4044e-13, 8.2573e-13, 1.1563e-12, 1.0537e-12, 5.7502e-13,\n            3.7142e-13, 6.1808e-13, 4.6246e-13, 1.7258e-12, 3.7523e-13, 4.6198e-13,\n            1.8818e-12, 1.3103e-13, 1.0934e-12, 3.0699e-12, 4.5160e-13, 9.9529e-13,\n            1.4705e-12, 2.2692e-12, 1.2909e-13, 4.4999e-14, 1.0162e-12, 3.3886e-13,\n            9.1655e-13, 2.5644e-12, 7.6241e-13, 1.1283e-12, 1.4780e-12, 1.1705e-12,\n            3.7932e-13, 8.2312e-13, 1.6349e-12, 2.1570e-12, 1.3219e-12, 2.4958e-12,\n            1.1557e-12, 6.1035e-13, 9.4941e-14, 2.5490e-13, 1.1351e-12, 9.1696e-13,\n            2.1607e-13, 7.4897e-13, 1.5924e-12, 1.0999e-12, 1.6982e-12, 1.1955e-12,\n            1.9773e-12, 2.9294e-13, 1.0428e-12, 2.2824e-13, 7.8754e-13, 1.1806e-12,\n            9.6597e-13, 7.9905e-13, 1.9244e-12, 4.6656e-13, 1.5401e-13, 6.5422e-13,\n            8.3554e-13, 5.5466e-12, 1.3929e-12, 4.3373e-13, 4.3795e-13, 1.1124e-12,\n            2.1254e-12, 3.1993e-13, 1.4845e-12, 1.1802e-12])},\n   16: {'exp_avg': tensor([ 9.2414e-08,  3.1758e-07, -1.9205e-07,  7.4025e-08, -9.1101e-07,\n             1.6526e-07,  2.2431e-07,  2.6453e-07, -4.3479e-07,  1.1294e-07,\n             2.7005e-07,  2.4737e-07, -1.0729e-07, -3.9527e-07, -1.5812e-07,\n             2.0590e-07,  1.2569e-08, -3.5142e-07, -6.6715e-08, -1.1681e-07,\n            -2.0710e-07,  5.5217e-07, -8.7989e-08, -5.3417e-08, -4.9874e-08,\n            -1.9151e-07, -1.5106e-07, -2.0895e-07,  5.4241e-08,  2.5277e-07,\n             3.2724e-07,  3.7692e-07,  1.8909e-07,  4.0090e-07,  5.1046e-07,\n             1.5081e-08,  6.0421e-07, -1.3895e-07,  1.7546e-07, -4.1405e-07,\n            -2.7716e-07,  1.1377e-07, -3.0662e-07,  2.9555e-07,  5.2223e-07,\n            -2.0348e-07, -1.1417e-07, -7.5224e-09,  3.5234e-07, -4.5860e-07,\n            -2.7733e-07,  5.6523e-08, -2.6601e-07, -2.4964e-07,  2.9950e-08,\n             1.0244e-07,  3.4960e-07, -2.2762e-07, -6.9435e-07,  6.1653e-07,\n             3.7791e-08, -2.5332e-07, -4.2893e-08,  3.0202e-07]),\n    'exp_avg_sq': tensor([1.3192e-12, 7.9785e-12, 1.2362e-12, 1.3288e-12, 3.1132e-12, 3.9938e-12,\n            4.7184e-12, 2.6158e-12, 1.3941e-12, 1.4343e-12, 4.7872e-12, 1.3584e-12,\n            1.2296e-12, 1.4364e-12, 1.0974e-12, 1.6076e-12, 9.5517e-13, 1.7718e-12,\n            1.8677e-12, 1.3706e-12, 2.5427e-12, 1.2821e-12, 1.4411e-12, 1.2084e-12,\n            1.4046e-12, 1.7258e-12, 2.0382e-12, 1.0453e-12, 1.7613e-12, 2.5219e-12,\n            1.0813e-12, 7.7379e-13, 1.3639e-12, 3.8898e-12, 3.9922e-12, 1.4874e-12,\n            2.1873e-11, 1.2842e-12, 1.0634e-12, 1.0406e-12, 1.7797e-12, 1.5855e-12,\n            1.9418e-12, 1.7751e-12, 1.6666e-12, 2.0089e-12, 2.0476e-12, 9.9386e-13,\n            2.3072e-12, 9.4496e-13, 2.0099e-12, 1.8505e-12, 2.5016e-12, 1.4058e-12,\n            4.5016e-12, 1.0113e-12, 1.7587e-12, 2.1880e-12, 1.5315e-12, 1.9947e-12,\n            1.6694e-12, 1.0951e-12, 1.7300e-12, 9.9220e-13])},\n   17: {'exp_avg': tensor([-1.3499e-07,  1.2417e-07, -1.5311e-07,  1.0139e-07, -4.3596e-07,\n             1.2964e-07, -4.4309e-08,  1.4428e-07, -2.9410e-07,  8.4405e-08,\n             2.7662e-07,  1.7237e-07, -1.2434e-07, -4.1632e-07, -9.2373e-08,\n             3.5916e-07,  1.3952e-08, -5.7332e-08, -7.0459e-08, -2.0468e-07,\n            -2.9705e-07, -2.2985e-07, -2.3369e-07, -2.3747e-07,  1.0765e-07,\n            -3.6754e-08, -2.7526e-07, -3.0318e-07,  3.0192e-07,  1.7180e-07,\n             2.8979e-07,  1.2993e-07, -1.1819e-07, -2.2055e-07,  2.1446e-07,\n             4.6567e-07,  6.6366e-07,  4.7678e-08,  3.0186e-07, -5.1244e-08,\n             3.7526e-08, -2.2293e-07, -3.2861e-07,  1.0976e-07,  5.8349e-07,\n             1.1865e-08, -1.2538e-07,  1.4888e-07,  9.4985e-08, -3.4487e-07,\n            -5.1983e-07,  1.3405e-07, -8.5149e-08, -4.9390e-07,  4.0643e-09,\n            -1.2891e-07,  2.8786e-07, -2.7786e-07, -3.9870e-07,  1.2453e-07,\n            -1.8030e-07, -8.1943e-08,  1.0825e-07,  2.9720e-07]),\n    'exp_avg_sq': tensor([1.1839e-12, 9.1688e-13, 1.0367e-12, 1.0667e-12, 2.3377e-12, 2.3564e-12,\n            1.0939e-12, 1.5273e-12, 9.6703e-13, 1.3411e-12, 1.0994e-12, 1.0115e-12,\n            8.8268e-13, 1.5221e-12, 9.2334e-13, 1.6145e-12, 1.4223e-12, 1.3222e-12,\n            1.1556e-12, 1.5450e-12, 1.8975e-12, 1.0104e-12, 1.3138e-12, 1.0763e-12,\n            1.4009e-12, 1.2902e-12, 2.0328e-12, 9.3410e-13, 1.2147e-12, 1.2008e-12,\n            9.9145e-13, 7.6551e-13, 1.1204e-12, 2.8920e-12, 2.8604e-12, 1.2794e-12,\n            3.1143e-12, 1.3587e-12, 7.9093e-13, 9.5958e-13, 1.7102e-12, 9.5411e-13,\n            1.5822e-12, 1.2750e-12, 1.5851e-12, 1.4088e-12, 1.7764e-12, 1.0551e-12,\n            1.7865e-12, 1.3397e-12, 9.2285e-13, 1.2767e-12, 2.1356e-12, 1.0759e-12,\n            3.4483e-12, 1.0452e-12, 1.7249e-12, 1.5358e-12, 8.1721e-13, 1.4903e-12,\n            1.5612e-12, 1.1910e-12, 1.1093e-12, 7.9319e-13])},\n   18: {'exp_avg': tensor([-1.9409e-07, -1.1242e-07,  2.2536e-07, -3.4697e-07, -3.4590e-07,\n            -2.1892e-07,  1.1770e-07,  4.0971e-08, -2.6174e-07, -4.8190e-07,\n            -1.0943e-07, -9.4267e-08, -5.6509e-07,  1.3215e-07, -1.4821e-07,\n             4.7075e-08,  2.3569e-07,  5.6259e-07,  4.7628e-07, -4.3809e-08,\n            -3.6341e-07, -4.7491e-07, -4.2290e-07,  2.6202e-07,  1.1546e-07,\n             3.0624e-08,  1.9038e-07,  1.7726e-07, -1.1078e-07,  1.7579e-07,\n            -1.5427e-07, -3.1292e-07,  1.3615e-08, -1.2914e-07,  6.0331e-07,\n            -2.3708e-07, -1.9481e-07,  1.9354e-07, -8.5966e-08,  3.8552e-07,\n            -1.5544e-07,  1.1572e-07,  3.3054e-07,  8.9432e-08,  2.9770e-07,\n             2.8693e-07,  2.6796e-08,  4.3706e-07,  3.8630e-07, -4.5019e-08,\n             4.1646e-07, -3.1826e-07, -3.1116e-08, -2.0580e-07,  1.8719e-07,\n            -3.8792e-07, -1.2338e-07,  4.6167e-09,  3.6631e-08, -2.8421e-07,\n             2.1389e-07, -3.4280e-07,  1.9170e-07,  3.8244e-07]),\n    'exp_avg_sq': tensor([2.2094e-12, 1.0373e-12, 2.5623e-12, 7.9280e-13, 1.3033e-12, 3.3250e-12,\n            1.8982e-12, 2.0052e-12, 1.0326e-12, 1.2791e-12, 1.5880e-12, 1.0909e-12,\n            3.4653e-12, 1.5405e-12, 4.6653e-12, 1.2628e-12, 4.2287e-12, 1.7732e-12,\n            6.3435e-12, 1.7633e-12, 1.1752e-12, 1.4870e-12, 1.0766e-12, 1.4047e-12,\n            1.2722e-12, 1.9303e-12, 1.4075e-12, 1.8237e-12, 2.1895e-12, 9.5494e-13,\n            1.8044e-12, 1.2600e-12, 1.3206e-12, 7.9196e-13, 1.6908e-12, 2.0240e-12,\n            3.3836e-12, 1.1566e-12, 1.5449e-12, 1.1955e-12, 1.7321e-12, 9.6988e-13,\n            1.7906e-12, 1.3580e-12, 1.2209e-12, 1.4758e-12, 1.0484e-12, 2.8631e-12,\n            2.6152e-12, 1.0567e-12, 1.9946e-12, 1.5265e-12, 2.1758e-12, 1.7855e-12,\n            1.5628e-12, 7.2959e-13, 1.0273e-12, 7.7183e-13, 3.5124e-12, 2.1613e-12,\n            1.6271e-12, 1.5402e-12, 1.1362e-12, 4.3264e-12])},\n   19: {'exp_avg': tensor([-3.3407e-07, -2.9182e-07,  4.5463e-07, -3.1661e-07,  2.6740e-08,\n             1.8821e-07, -1.2248e-07,  1.4569e-07, -2.2167e-07, -5.1952e-07,\n            -3.0881e-07, -1.7684e-07, -8.9776e-08,  1.5332e-07,  2.8017e-08,\n            -7.0083e-08,  2.4050e-07,  1.7470e-07,  3.7808e-07, -1.0302e-07,\n            -1.4272e-07, -1.2478e-07, -2.6954e-07,  1.1287e-07, -7.6445e-08,\n            -1.1738e-07,  1.1853e-07,  1.2807e-07, -9.7651e-08, -2.0302e-07,\n            -1.9720e-07, -2.0590e-07, -4.2191e-08, -6.6650e-08,  1.5168e-07,\n            -2.5066e-07, -1.3079e-07,  6.8648e-08, -2.6228e-07,  1.0210e-07,\n            -1.8105e-07, -8.0224e-08,  2.3634e-07,  3.0821e-07,  3.0740e-07,\n            -8.6131e-08, -2.5287e-07,  1.1480e-07,  5.1375e-07, -3.3504e-07,\n             2.2493e-07, -2.5260e-07,  1.7196e-07, -1.6468e-07,  1.1893e-07,\n            -1.3959e-07, -1.2719e-07, -4.8492e-09, -1.8851e-07, -1.9119e-07,\n             9.8596e-08,  3.7991e-08, -9.1277e-08,  2.2522e-08]),\n    'exp_avg_sq': tensor([1.6092e-12, 7.2304e-13, 1.7975e-12, 6.1393e-13, 7.7038e-13, 8.9511e-13,\n            1.0145e-12, 1.0530e-12, 6.9747e-13, 9.3552e-13, 1.4312e-12, 8.3405e-13,\n            2.0238e-12, 7.4405e-13, 1.3016e-12, 1.1005e-12, 4.5906e-12, 1.0977e-12,\n            2.0470e-12, 9.9792e-13, 7.8456e-13, 6.1896e-13, 6.3107e-13, 8.6132e-13,\n            7.3680e-13, 1.2527e-12, 6.0196e-13, 1.0086e-12, 1.3678e-12, 5.6690e-13,\n            1.0581e-12, 7.8501e-13, 9.1019e-13, 4.6179e-13, 8.7409e-13, 9.2564e-13,\n            8.8038e-13, 5.8131e-13, 8.9647e-13, 7.4627e-13, 1.2981e-12, 6.8064e-13,\n            1.6221e-12, 7.8324e-13, 8.1651e-13, 9.0926e-13, 8.4825e-13, 2.3915e-12,\n            7.7891e-13, 7.1074e-13, 1.2921e-12, 8.5938e-13, 1.5641e-12, 1.1038e-12,\n            8.6127e-13, 6.2058e-13, 7.0926e-13, 7.0184e-13, 2.8441e-12, 1.1652e-12,\n            5.7697e-13, 7.7633e-13, 8.5366e-13, 1.6744e-12])},\n   20: {'exp_avg': tensor([-1.8537e-07, -4.2494e-07,  1.7969e-07, -9.2049e-07, -7.5571e-07,\n             3.7326e-08, -8.0768e-07, -5.7026e-08, -3.0987e-07,  3.9948e-07,\n             1.9702e-07, -3.2510e-07,  4.2104e-07, -3.0878e-07,  1.3445e-07,\n             5.5866e-07, -3.9555e-07,  3.8150e-07, -2.5365e-07,  3.0300e-07,\n            -1.5525e-07,  6.7299e-07,  2.2088e-07,  8.2367e-07, -3.3081e-07,\n             6.7107e-07, -5.1290e-07,  1.2386e-07, -1.8630e-07, -5.3557e-08,\n            -3.1774e-07,  1.1525e-06,  2.5697e-07, -5.4610e-07, -8.5489e-07,\n            -2.5840e-07,  6.5793e-07,  1.8009e-07,  7.7261e-08,  2.0569e-07,\n             1.5113e-07,  4.2367e-07,  1.5437e-07, -9.3437e-10, -6.9437e-07,\n             2.3409e-07, -3.7407e-08, -3.2446e-07,  8.6273e-08,  1.0069e-06,\n            -1.0118e-06, -2.5259e-07, -1.4594e-07,  6.7900e-07,  6.8348e-07,\n            -7.5092e-07, -1.4516e-07,  1.0583e-07, -8.5192e-08,  5.8493e-08,\n             3.6800e-07,  1.0354e-06, -7.9002e-07,  3.1935e-07, -5.7544e-07,\n             2.5248e-07, -4.8688e-07,  5.6593e-08,  1.1064e-08, -5.9310e-09,\n            -4.4375e-07,  3.0148e-07,  1.9064e-07, -4.5599e-08,  2.1811e-07,\n             5.6361e-07,  2.0090e-07, -9.2648e-07, -2.0899e-08,  1.9915e-07,\n             6.3965e-07,  2.3900e-07,  4.2398e-07, -2.4791e-07,  2.6716e-07,\n            -9.7604e-07, -8.5793e-07,  4.0254e-08,  3.1637e-07,  5.2931e-07,\n             4.7894e-07,  3.8404e-09, -6.5123e-07,  1.0125e-06, -1.3448e-06,\n             1.6191e-07, -7.3204e-07,  4.5064e-07,  7.1090e-07, -1.7649e-07,\n             8.6839e-09, -7.0180e-07, -3.8183e-07,  4.3191e-08, -3.2502e-07,\n             9.3129e-07,  1.1793e-07, -4.1143e-07, -2.8984e-07,  2.5253e-07,\n            -6.7083e-08,  5.2519e-07,  8.0148e-08, -4.2350e-07,  7.4925e-07,\n            -9.5904e-07,  4.8582e-08, -2.3106e-07, -1.8802e-07,  4.2751e-07,\n             2.1736e-07,  4.1162e-08, -7.0790e-07,  3.5289e-07,  2.1120e-09,\n            -1.3446e-07, -3.6163e-07,  4.7538e-07,  8.2443e-07, -4.8364e-08,\n            -6.1831e-07,  9.0279e-07,  4.0406e-08,  5.3001e-08, -5.3149e-07,\n             1.4787e-07,  2.4792e-07, -3.4026e-07, -3.6954e-07, -3.0574e-07,\n             9.4946e-08, -1.0392e-06,  7.7264e-09, -1.8955e-07, -6.4998e-08,\n             5.1643e-07, -6.1742e-07, -3.6524e-07,  2.2369e-07,  3.9281e-07,\n             4.2679e-07, -2.0481e-07,  6.9785e-08,  4.3318e-07,  1.1382e-07,\n             5.3004e-08, -5.3973e-07,  4.9177e-07,  3.2783e-07, -7.1275e-07,\n            -1.1076e-06, -7.6861e-07,  5.8210e-07, -6.7703e-07,  4.7968e-07,\n             1.5881e-07,  3.0711e-07, -1.0939e-07,  4.7451e-08,  8.4081e-07,\n             2.5414e-07, -2.3192e-08, -8.9493e-07,  2.5854e-08,  3.9339e-08,\n            -6.2302e-07, -3.5532e-07,  1.6659e-08,  3.7174e-07, -6.4390e-07,\n            -5.6520e-07,  1.6783e-07, -1.8003e-07,  3.5106e-07, -4.9794e-07,\n             1.6489e-07,  3.8264e-07, -1.7752e-07, -1.6825e-07, -4.3340e-08,\n             4.5412e-07, -4.5907e-07,  2.2956e-07, -3.2952e-07, -2.4374e-07,\n            -8.1359e-07,  5.6890e-08,  4.3351e-07, -3.0500e-07,  2.4719e-09,\n             4.3324e-07, -3.1198e-07, -1.0406e-06,  4.1717e-07, -1.6257e-07,\n             4.4510e-07,  6.5918e-08,  8.6726e-08, -4.3044e-07, -2.5151e-07,\n            -2.1305e-07,  6.4460e-08, -2.3228e-07,  7.4916e-08, -4.3638e-08,\n            -6.8847e-08,  3.0342e-07,  6.9462e-07,  3.6020e-07,  8.8311e-07,\n            -9.2649e-07,  1.1546e-07,  1.6577e-07, -5.2973e-08, -2.4137e-07,\n             6.5722e-07, -1.3481e-07,  5.6837e-07, -7.1448e-08, -2.7213e-07,\n             6.3120e-08,  4.7415e-07, -2.1867e-07, -6.1914e-07,  1.4982e-07,\n            -2.1568e-07,  2.1870e-07,  7.8232e-07,  1.9518e-07, -7.2224e-08,\n             3.5724e-07, -3.0175e-07, -1.9486e-07, -8.7168e-07,  2.5287e-07,\n             2.7973e-07,  2.8912e-07,  4.1932e-08, -1.5433e-08, -3.4180e-07,\n            -1.1912e-06, -1.3972e-07, -3.9158e-07,  9.1052e-08,  7.4483e-07,\n             4.3335e-07]),\n    'exp_avg_sq': tensor([1.2085e-12, 3.5279e-12, 1.0606e-12, 4.7394e-12, 1.7416e-12, 2.1752e-12,\n            2.8924e-12, 1.9274e-11, 2.1613e-12, 4.1596e-12, 5.2184e-12, 4.2087e-12,\n            2.2867e-12, 6.3437e-12, 1.9941e-12, 8.5970e-12, 6.7074e-12, 8.2481e-12,\n            1.8911e-12, 1.5651e-12, 3.7424e-12, 9.6466e-12, 7.5285e-12, 4.1901e-12,\n            2.5770e-12, 1.9308e-12, 5.6557e-12, 2.8233e-12, 4.0444e-12, 3.0168e-12,\n            5.0112e-12, 1.3463e-11, 4.5253e-12, 3.9186e-12, 7.0081e-12, 4.8310e-12,\n            5.0844e-12, 4.0225e-12, 4.3464e-12, 3.4455e-12, 1.5584e-12, 1.0684e-11,\n            2.2592e-12, 1.1914e-12, 4.9630e-12, 8.3363e-12, 3.1942e-12, 7.0975e-12,\n            5.3522e-12, 5.1528e-12, 4.7907e-12, 4.0872e-12, 2.8199e-12, 8.0791e-12,\n            3.7182e-12, 1.7448e-11, 9.3567e-12, 3.2130e-12, 3.1598e-12, 2.4385e-12,\n            4.6840e-12, 3.6311e-12, 1.3187e-11, 7.2499e-12, 1.0228e-11, 3.4117e-12,\n            5.5953e-12, 2.7248e-12, 2.8767e-12, 4.7712e-12, 6.0745e-12, 4.2867e-12,\n            2.1077e-12, 2.8776e-12, 1.5654e-12, 4.5745e-12, 3.1908e-12, 2.4904e-12,\n            5.0468e-12, 4.3371e-12, 4.0499e-12, 1.4130e-12, 3.1609e-12, 8.6708e-12,\n            2.3162e-12, 3.4545e-12, 1.0132e-11, 4.0931e-12, 2.1767e-12, 4.9270e-12,\n            5.8424e-12, 3.4296e-12, 3.0978e-12, 3.7341e-12, 1.0239e-11, 3.2505e-12,\n            1.7471e-12, 3.1357e-12, 6.4836e-12, 3.4668e-12, 5.7404e-12, 3.2107e-12,\n            4.1385e-12, 5.7292e-12, 1.4882e-12, 6.1327e-12, 1.0589e-11, 3.5153e-12,\n            4.4198e-12, 4.7296e-12, 4.7148e-12, 6.6500e-12, 4.5205e-12, 3.1286e-12,\n            2.6339e-12, 3.4976e-12, 3.2040e-12, 2.0735e-12, 4.0013e-12, 4.7912e-12,\n            2.6202e-12, 4.8016e-12, 2.8940e-12, 3.0145e-12, 1.0856e-12, 2.6269e-12,\n            3.7377e-12, 2.2447e-12, 5.7735e-12, 3.0100e-12, 2.9650e-12, 1.5750e-11,\n            3.5698e-12, 1.7907e-12, 5.7955e-12, 3.2292e-12, 1.8190e-12, 4.5765e-12,\n            7.4249e-12, 3.9338e-12, 4.9258e-12, 2.2394e-11, 2.4823e-12, 4.3520e-12,\n            3.9726e-12, 6.4132e-12, 5.8809e-12, 6.8395e-12, 2.6712e-12, 1.1787e-11,\n            2.2413e-12, 4.2081e-12, 3.9008e-12, 2.2516e-12, 5.2670e-12, 3.5271e-12,\n            6.4387e-12, 5.7487e-12, 1.5898e-12, 5.2412e-12, 3.4961e-12, 4.3766e-12,\n            2.6565e-12, 3.2292e-12, 2.3446e-12, 4.7840e-12, 2.7865e-12, 2.0554e-12,\n            9.6413e-12, 5.6260e-12, 4.7775e-12, 4.5946e-12, 6.2365e-12, 6.9115e-12,\n            4.4424e-12, 3.6446e-12, 3.5324e-12, 5.8345e-12, 2.8322e-12, 3.8124e-12,\n            6.2935e-12, 5.0226e-12, 2.3961e-12, 3.4657e-12, 5.1844e-12, 2.1794e-12,\n            3.7944e-12, 1.8282e-12, 4.2848e-12, 5.3600e-12, 2.1217e-12, 5.3328e-12,\n            3.9256e-12, 4.9969e-12, 4.0595e-12, 4.9099e-12, 3.3858e-12, 4.3286e-12,\n            5.0960e-12, 3.2580e-12, 1.2450e-12, 1.4670e-11, 4.9856e-12, 3.9206e-12,\n            2.0310e-12, 5.8550e-12, 4.1913e-12, 4.7724e-12, 4.5797e-12, 4.0626e-12,\n            4.8282e-12, 2.9777e-12, 3.2569e-12, 1.6062e-12, 2.0316e-12, 5.2080e-12,\n            3.1981e-12, 2.8750e-12, 2.1277e-12, 8.7384e-12, 4.0859e-12, 5.1560e-12,\n            2.3706e-12, 2.6325e-12, 5.1524e-12, 3.3414e-12, 3.6358e-12, 7.2179e-12,\n            3.2266e-12, 1.0020e-11, 5.8196e-12, 5.0718e-12, 2.2454e-12, 3.9509e-12,\n            4.3308e-12, 3.5861e-12, 4.6579e-12, 3.2896e-12, 3.9665e-12, 2.5863e-12,\n            3.7730e-12, 2.3277e-12, 3.6994e-12, 3.5695e-12, 6.5557e-12, 2.1642e-12,\n            6.4112e-12, 1.0139e-11, 1.9526e-12, 6.4334e-12, 3.6378e-12, 2.9506e-12,\n            3.2606e-12, 4.6207e-12, 4.7182e-12, 3.3273e-12])},\n   21: {'exp_avg': tensor([ 1.3696e-07, -2.2439e-08,  7.9755e-08, -2.0821e-08,  1.5653e-07,\n             7.6513e-08,  9.3943e-10, -4.7205e-08, -2.8644e-07, -2.5756e-08,\n            -1.9870e-07,  1.7223e-07, -8.9348e-07, -4.2441e-07, -1.1552e-07,\n             4.1913e-08,  1.4293e-07, -3.3034e-07,  1.1623e-08, -1.9747e-08,\n             1.5681e-07, -1.4409e-07, -9.4869e-08, -1.3487e-08, -7.3874e-09,\n            -7.1415e-08,  2.5445e-07,  2.4611e-07,  2.9522e-08, -1.9936e-08,\n            -2.1250e-08, -2.3867e-07, -4.9497e-08,  4.6227e-07, -4.7905e-08,\n            -3.1624e-07,  1.6284e-08,  1.2320e-07, -1.4951e-08,  9.0349e-08,\n            -2.7447e-07,  2.2752e-08,  1.1535e-07, -1.2340e-07,  1.5254e-07,\n             1.4148e-08,  1.9324e-07, -3.8743e-07,  9.4433e-08, -1.5071e-07,\n            -1.4847e-07, -6.0270e-10, -2.0467e-07,  1.7097e-07, -2.6715e-07,\n             4.9289e-08, -1.0360e-07, -1.1494e-08, -2.3652e-07,  9.9432e-08,\n            -1.0321e-07,  2.2982e-08, -5.5155e-08,  1.9825e-07,  5.9170e-08,\n             5.8635e-09, -2.0838e-08, -2.8208e-07, -1.2627e-07,  1.5792e-07,\n             2.0940e-07, -4.9286e-08,  1.3715e-07,  1.0561e-07, -8.6763e-08,\n             8.9336e-08, -2.3372e-07, -1.3437e-08,  5.4409e-09,  4.1421e-08,\n            -5.7098e-08,  7.1857e-08,  3.0311e-08,  1.6315e-07, -1.6770e-07,\n            -2.1940e-09,  1.0436e-07,  1.9582e-07, -3.1045e-07,  3.7702e-07,\n             1.6992e-08,  2.2700e-07, -1.7650e-08, -2.6001e-07,  7.0317e-08,\n            -2.3753e-07,  5.8462e-07, -1.1914e-07,  2.0635e-08, -1.7677e-07,\n            -2.0737e-07, -8.8445e-08, -1.7367e-07, -1.2942e-07, -3.9289e-08,\n            -1.1129e-07, -3.4429e-08, -1.3719e-08,  7.3064e-08, -1.6536e-08,\n            -5.1584e-08,  3.6452e-08,  1.3031e-07,  2.9127e-08, -2.2205e-08,\n             3.6779e-08,  2.4289e-07, -3.8349e-07, -7.9416e-08, -4.1759e-09,\n             4.6414e-08,  7.3523e-08, -9.3436e-08, -5.3191e-08,  3.5898e-08,\n             5.1410e-08, -7.6117e-08,  8.6738e-08,  1.6802e-08, -5.4593e-08,\n             3.7809e-07,  9.2856e-08, -1.9907e-07,  3.7388e-08, -5.3867e-08,\n             2.1794e-07,  6.3502e-09, -8.0891e-09, -1.1241e-07,  1.1194e-07,\n            -2.2760e-07, -1.2695e-07,  2.2205e-07, -5.4958e-09, -1.8384e-08,\n            -1.4347e-08, -3.8982e-07, -7.5111e-09,  2.8370e-07, -1.1212e-07,\n            -1.0956e-07, -2.5556e-09, -8.0727e-11, -4.2756e-08,  3.3341e-08,\n             2.8145e-08, -1.3330e-07,  1.0998e-08,  4.5695e-07,  4.4071e-08,\n            -3.7410e-08, -2.0009e-08, -1.1219e-07, -1.2832e-07,  3.1168e-07,\n            -1.3155e-07, -3.3137e-07, -3.2497e-07,  2.5019e-08,  4.9783e-08,\n            -1.0030e-07,  8.9354e-08,  1.0494e-07, -1.2302e-07,  8.0397e-08,\n            -3.4712e-08,  9.9257e-09, -5.7364e-07,  1.0729e-07, -1.7002e-08,\n            -5.9317e-09, -8.4910e-08, -3.4241e-07, -1.0724e-08, -4.5299e-08,\n            -2.5308e-07, -7.1998e-08,  1.3867e-07,  1.8248e-07, -1.6061e-07,\n             1.4458e-07,  6.9153e-08, -4.9017e-09, -7.5457e-08,  2.9629e-07,\n             1.4241e-07, -6.0273e-08, -4.8234e-08,  1.5688e-07,  2.1640e-08,\n            -2.4681e-07,  1.5925e-07, -4.3623e-08, -1.0373e-07,  1.5990e-07,\n             2.3734e-07, -3.5370e-09, -2.5664e-08,  7.9767e-08, -2.9167e-08,\n            -1.3602e-07, -1.6655e-07, -5.5660e-08,  4.5163e-08,  1.6937e-07,\n            -1.5213e-07, -1.3179e-07, -3.6488e-08, -4.7391e-07, -6.7228e-08,\n            -7.9019e-08, -6.4946e-08,  7.1917e-08, -1.3125e-07, -6.3219e-08,\n            -1.1323e-07, -6.2214e-09, -1.8057e-07,  4.9660e-08, -5.8145e-08,\n            -7.9052e-08,  3.3141e-08,  1.5092e-07,  5.4599e-08,  1.3283e-07,\n            -4.1550e-08, -2.9091e-08,  1.3821e-08,  1.0183e-10,  2.8799e-08,\n            -5.5390e-07, -6.2565e-08,  4.6008e-07,  5.5754e-08,  9.8411e-10,\n            -1.8202e-07, -2.5739e-07, -1.7973e-07,  2.9182e-07,  1.3751e-08,\n             6.3856e-08,  7.9668e-08, -1.8635e-07,  6.3438e-08, -4.9387e-08,\n             1.1998e-07]),\n    'exp_avg_sq': tensor([3.4576e-13, 1.0720e-13, 6.0609e-13, 4.7890e-13, 4.2211e-13, 4.7932e-13,\n            1.9174e-15, 1.0389e-13, 8.1964e-13, 3.4812e-13, 5.0147e-13, 2.5925e-13,\n            1.1556e-12, 2.1881e-12, 5.8614e-13, 1.0055e-13, 8.7119e-13, 2.1020e-12,\n            6.7822e-13, 1.7810e-13, 5.4346e-14, 2.0598e-13, 1.5083e-13, 9.9733e-14,\n            4.2464e-13, 3.2394e-13, 2.7264e-12, 1.9742e-12, 1.1393e-13, 2.9875e-14,\n            5.7300e-14, 3.0200e-12, 1.4780e-13, 1.4978e-12, 1.5493e-14, 1.4652e-12,\n            4.6204e-14, 4.4145e-13, 2.3581e-14, 1.2776e-13, 9.3588e-13, 3.1335e-13,\n            9.7359e-13, 4.9793e-13, 3.4271e-12, 4.2296e-14, 4.3755e-13, 1.2572e-12,\n            4.2337e-13, 2.5280e-13, 6.1823e-13, 8.4038e-14, 1.0760e-12, 5.2381e-13,\n            7.9775e-13, 3.5339e-13, 1.4268e-13, 3.4025e-14, 8.0750e-13, 5.2240e-13,\n            4.6722e-13, 2.9430e-14, 1.8813e-13, 8.6520e-13, 8.5337e-13, 9.0300e-13,\n            1.9630e-14, 7.8162e-13, 3.4106e-13, 1.4555e-13, 2.2775e-12, 2.6083e-13,\n            6.7703e-13, 2.9976e-13, 7.7302e-13, 7.5636e-13, 6.8335e-13, 2.0343e-13,\n            3.5244e-14, 2.7123e-13, 6.1489e-14, 8.0950e-13, 1.3048e-14, 2.4626e-13,\n            6.9431e-13, 6.8203e-14, 1.5595e-12, 1.1232e-12, 4.9303e-13, 7.0512e-13,\n            3.3940e-13, 1.3326e-12, 3.4964e-14, 4.4685e-13, 1.0567e-12, 9.1874e-13,\n            1.1680e-12, 2.3560e-13, 2.7447e-14, 1.2801e-12, 8.3903e-13, 4.2456e-13,\n            1.3590e-12, 4.1057e-13, 1.5200e-12, 8.2972e-13, 1.6295e-14, 5.4852e-14,\n            3.8796e-14, 4.6011e-13, 1.7914e-14, 1.7715e-13, 1.2259e-13, 6.0703e-13,\n            9.9961e-14, 5.7238e-14, 2.9049e-13, 3.8823e-13, 2.4808e-13, 1.0205e-13,\n            4.2930e-14, 2.3669e-13, 1.5294e-12, 1.0754e-13, 6.8616e-13, 8.6696e-13,\n            8.3217e-14, 3.2957e-13, 4.1797e-14, 1.8226e-13, 1.2538e-12, 2.7174e-14,\n            9.7375e-13, 5.2220e-13, 1.0228e-13, 5.2502e-13, 1.0212e-15, 3.6219e-14,\n            2.2656e-12, 3.4748e-13, 2.6616e-12, 1.3679e-13, 7.2957e-13, 6.2285e-13,\n            8.5151e-15, 5.7996e-14, 9.5674e-13, 8.6499e-14, 3.2210e-13, 1.0590e-13,\n            8.8629e-13, 4.1898e-15, 2.9617e-17, 5.5579e-14, 5.1052e-14, 1.9170e-14,\n            1.0605e-13, 2.2686e-12, 8.3601e-13, 9.4586e-14, 3.0761e-14, 7.7485e-14,\n            1.8020e-13, 9.1605e-13, 6.5426e-13, 7.8414e-13, 6.5476e-13, 8.1199e-13,\n            4.0614e-14, 1.4222e-13, 1.2687e-13, 1.0073e-13, 5.4992e-13, 2.5802e-13,\n            1.0936e-12, 2.3740e-13, 9.2243e-14, 1.2646e-12, 1.2529e-12, 4.9949e-13,\n            3.8279e-15, 1.7804e-13, 3.6309e-13, 8.9362e-13, 1.7046e-13, 1.1246e-12,\n            6.9087e-14, 4.0430e-13, 4.7617e-13, 8.7146e-13, 6.9612e-13, 1.1382e-13,\n            2.2279e-13, 1.2987e-13, 2.8861e-13, 2.0197e-13, 6.1477e-14, 2.0011e-13,\n            5.3662e-13, 9.0917e-14, 7.9740e-13, 2.1392e-12, 1.1717e-13, 7.3741e-13,\n            8.4340e-13, 4.5521e-13, 1.5818e-16, 2.4940e-14, 4.6897e-13, 1.1447e-13,\n            4.3342e-13, 1.5155e-12, 5.9595e-13, 6.1805e-13, 1.2281e-12, 5.9759e-13,\n            1.3710e-13, 1.1137e-13, 1.0385e-12, 1.3151e-12, 1.4309e-13, 1.2650e-12,\n            5.6804e-13, 2.5357e-13, 9.4900e-14, 7.4814e-14, 3.7809e-13, 3.5541e-13,\n            1.8106e-14, 3.8203e-13, 5.3968e-13, 2.7066e-13, 8.4727e-13, 4.0976e-13,\n            4.9181e-13, 5.3457e-14, 2.9077e-13, 3.3388e-14, 1.7492e-13, 5.5212e-13,\n            4.2065e-13, 6.8277e-14, 8.8584e-13, 3.0258e-13, 1.6523e-14, 4.0975e-13,\n            3.5319e-13, 2.0006e-12, 4.7514e-13, 1.1655e-13, 1.6003e-13, 4.4625e-13,\n            6.8201e-13, 6.8357e-14, 1.1682e-12, 8.6847e-13])},\n   22: {'exp_avg': tensor([-3.8877e-07, -4.8414e-07, -6.2443e-08,  1.3132e-07,  1.8225e-07,\n             3.0636e-07,  1.7259e-07,  2.8420e-07, -2.8912e-09,  8.7706e-08,\n             2.0278e-07, -1.5596e-07,  7.4465e-07,  1.9968e-07,  1.1748e-07,\n            -8.6482e-08,  1.4788e-07,  2.1798e-07, -1.9549e-08,  2.5614e-07,\n            -6.0906e-08, -3.7127e-07, -1.6768e-07,  3.9985e-07,  1.7538e-07,\n             8.2524e-08, -1.7499e-07, -3.6044e-07, -2.9127e-07, -4.1251e-07,\n            -9.0385e-07,  1.5965e-07, -4.2315e-08,  3.6698e-08,  1.0844e-07,\n             8.8350e-07,  1.8209e-07, -6.1241e-08, -3.0801e-07, -2.2499e-07,\n            -6.9366e-08, -3.9867e-07,  5.8337e-08, -2.3698e-07, -4.4824e-07,\n             2.0012e-08,  7.9972e-08, -5.5584e-07,  7.2991e-08, -4.3853e-07,\n             1.6772e-08,  1.5296e-07,  1.8801e-07, -3.9904e-07,  1.5596e-07,\n             3.3058e-07, -8.2737e-07, -3.4364e-07,  1.1099e-07, -4.3081e-07,\n             1.8335e-07, -1.2993e-08, -3.0357e-07, -1.4943e-07, -1.3135e-07,\n             1.2387e-07,  1.2633e-07,  6.7137e-07,  4.6975e-07,  1.9962e-07,\n             1.8774e-07, -1.3385e-07, -4.7484e-07,  2.1740e-07, -6.1213e-07,\n            -1.2977e-07,  1.8402e-07,  1.2943e-07,  3.1373e-07, -5.5929e-08,\n             1.4242e-07,  3.5076e-08, -2.7768e-08,  1.7638e-07,  1.6314e-08,\n             2.9091e-07,  2.6247e-07, -3.8109e-07, -2.0306e-07,  1.7455e-07,\n             3.6045e-07,  1.2874e-08, -3.6211e-07, -8.5009e-08, -2.9563e-08,\n            -3.7257e-07,  2.6680e-07,  2.1266e-07,  3.2522e-07,  2.5102e-07,\n            -6.1311e-07,  1.8790e-07,  1.8742e-07, -2.4969e-07, -6.3541e-07,\n             2.3041e-07,  1.8041e-07, -3.9512e-08, -3.7105e-07,  2.6879e-08,\n             1.2563e-07,  3.7341e-07, -3.4045e-07, -2.5201e-07,  1.4364e-07,\n             1.4147e-07,  3.4916e-08, -1.9632e-07,  4.2191e-07, -8.3080e-07,\n             6.4864e-07, -7.4483e-07,  4.6153e-07, -2.3413e-07,  4.5751e-07,\n             4.1443e-07,  3.8419e-07,  2.5395e-08]),\n    'exp_avg_sq': tensor([2.2371e-12, 1.7889e-12, 1.2437e-12, 1.4519e-12, 8.5401e-13, 8.8262e-13,\n            8.2243e-13, 1.3169e-12, 1.8270e-12, 1.2459e-12, 1.0136e-12, 2.3036e-12,\n            1.5593e-12, 1.0301e-12, 6.8555e-13, 1.5780e-12, 9.0367e-13, 1.0510e-12,\n            1.3809e-12, 1.6345e-12, 1.2224e-12, 4.6528e-12, 1.0911e-12, 1.0759e-12,\n            1.3856e-12, 1.2332e-12, 1.7201e-12, 2.7459e-12, 3.7641e-12, 9.8275e-13,\n            1.8772e-12, 1.5773e-12, 1.2345e-12, 9.6730e-13, 5.9351e-13, 1.9940e-12,\n            1.0250e-12, 9.7980e-13, 1.4712e-12, 1.9152e-12, 2.0721e-12, 1.1033e-12,\n            1.0430e-12, 1.5437e-12, 1.5760e-12, 1.8007e-12, 2.5734e-12, 3.1293e-12,\n            9.9962e-13, 1.4341e-12, 9.9731e-13, 9.8466e-13, 1.2742e-12, 2.1057e-12,\n            3.5797e-12, 9.2731e-13, 2.6806e-12, 1.7283e-12, 7.1778e-13, 1.6685e-12,\n            1.0328e-12, 1.1442e-12, 1.1489e-12, 1.8211e-12, 1.9380e-12, 1.2270e-12,\n            1.9103e-12, 1.6852e-12, 2.3871e-12, 1.3399e-12, 1.0838e-12, 1.5501e-12,\n            2.5125e-12, 2.6323e-12, 1.6059e-12, 8.5907e-13, 1.6807e-12, 1.9902e-12,\n            1.7983e-12, 2.2134e-12, 8.9872e-13, 6.7824e-13, 1.4804e-12, 1.9540e-12,\n            8.0947e-13, 4.2911e-12, 1.2958e-12, 2.0913e-12, 8.8391e-13, 7.3467e-13,\n            1.9981e-12, 9.8369e-13, 1.4404e-12, 6.1121e-13, 1.0431e-12, 8.0656e-13,\n            7.7088e-13, 1.3729e-12, 1.0361e-12, 2.1721e-12, 3.3189e-12, 9.7858e-13,\n            7.7634e-13, 2.3470e-12, 2.4699e-12, 1.6668e-12, 1.0575e-12, 1.7882e-12,\n            1.0729e-12, 1.2369e-12, 4.2463e-12, 1.9310e-12, 2.0437e-12, 1.1148e-12,\n            1.9903e-12, 1.7407e-12, 1.3391e-12, 1.6459e-12, 1.2478e-12, 3.5014e-12,\n            1.3883e-12, 2.1320e-12, 3.0773e-12, 2.0399e-12, 1.4222e-12, 5.5468e-12,\n            1.2128e-12, 1.5995e-12])},\n   23: {'exp_avg': tensor([ 2.6010e-07, -3.1951e-08,  1.9312e-07, -1.5478e-07, -8.7331e-08,\n             8.4269e-08,  1.3836e-07,  1.8014e-07, -1.4839e-07, -1.3446e-08,\n             2.1793e-07, -1.5967e-07,  3.3036e-07, -1.0068e-07,  3.1146e-07,\n            -4.8570e-08,  1.8510e-07, -1.5219e-08,  3.1237e-08,  3.3721e-07,\n            -1.4415e-07, -1.2929e-07, -4.1396e-07,  3.2315e-07,  2.2336e-07,\n             5.9587e-08, -3.1829e-07, -3.4797e-07, -3.0167e-07, -4.2988e-07,\n            -7.0888e-07,  2.2170e-07, -9.6607e-08, -1.2828e-07,  2.4733e-07,\n             9.9788e-07,  1.9487e-07, -2.1494e-07, -3.4132e-07, -2.3977e-07,\n            -2.6255e-07, -5.9608e-07,  2.4369e-07, -2.0228e-07, -3.8163e-07,\n             3.9689e-08,  2.7056e-07, -6.7357e-07, -7.0258e-08, -3.7902e-07,\n             5.2220e-09,  4.8885e-08,  7.3130e-08, -1.3414e-07, -1.4004e-07,\n             1.9211e-07, -5.8843e-07, -4.5849e-07, -8.8150e-08, -2.7360e-07,\n             3.6117e-07, -7.8946e-08, -3.6487e-07, -3.2076e-07,  1.3294e-07,\n             3.1955e-07,  2.8296e-07,  4.2853e-07,  5.6541e-07, -1.0872e-07,\n             3.8935e-08,  6.7888e-08, -1.9768e-07,  9.1045e-08, -2.7411e-07,\n            -2.4787e-07, -8.8920e-09,  1.6849e-07,  4.6826e-07, -1.2605e-07,\n            -2.9733e-08, -1.7545e-07,  3.9918e-08,  6.0249e-08, -1.8782e-07,\n            -1.7573e-07,  1.6982e-07, -3.8247e-07, -3.2780e-07,  1.1648e-07,\n             2.5353e-07,  1.7458e-08, -9.9842e-08,  1.4242e-07,  2.0808e-07,\n            -3.6947e-07,  2.7311e-07,  1.6925e-07,  2.1193e-07,  9.9451e-08,\n            -7.5568e-07, -2.8903e-08,  1.4147e-07, -5.3989e-08, -2.7104e-07,\n             1.5526e-07,  1.6414e-07,  7.8709e-08, -3.1542e-07, -6.3444e-09,\n             3.4038e-08,  1.5222e-07, -1.9634e-07, -1.9108e-07,  2.1026e-07,\n             1.0443e-07, -1.3858e-07, -6.1144e-07,  4.8785e-08, -6.9492e-07,\n             2.8318e-07, -2.8947e-07,  2.7663e-07, -3.1857e-07,  2.2771e-07,\n             1.3755e-07,  5.2887e-07, -2.2945e-07]),\n    'exp_avg_sq': tensor([1.3815e-12, 1.3105e-12, 1.0154e-12, 1.4002e-12, 7.7346e-13, 9.4336e-13,\n            1.1313e-12, 1.2552e-12, 1.3083e-12, 9.1147e-13, 9.0651e-13, 2.2281e-12,\n            1.0351e-12, 9.9479e-13, 6.8956e-13, 1.1263e-12, 1.0145e-12, 7.5439e-13,\n            9.5938e-13, 1.5085e-12, 8.4618e-13, 2.5520e-12, 1.0470e-12, 1.1318e-12,\n            1.3806e-12, 9.4843e-13, 2.1435e-12, 1.7162e-12, 3.8873e-12, 1.1819e-12,\n            1.3245e-12, 1.0613e-12, 8.3869e-13, 1.0989e-12, 6.9189e-13, 1.6859e-12,\n            7.6013e-13, 6.9431e-13, 1.3682e-12, 2.0885e-12, 1.3446e-12, 1.0614e-12,\n            8.9279e-13, 9.6658e-13, 1.0851e-12, 1.4500e-12, 1.9119e-12, 4.8652e-12,\n            1.2526e-12, 1.3179e-12, 9.7552e-13, 1.1352e-12, 6.4741e-13, 1.9899e-12,\n            3.0098e-12, 7.6824e-13, 1.5980e-12, 1.4171e-12, 8.3616e-13, 1.0910e-12,\n            1.0054e-12, 9.0896e-13, 1.2350e-12, 1.1819e-12, 1.3358e-12, 1.1291e-12,\n            1.3467e-12, 1.0503e-12, 1.4938e-12, 1.0831e-12, 1.0856e-12, 1.0638e-12,\n            1.6569e-12, 1.5565e-12, 1.2469e-12, 1.0093e-12, 1.8086e-12, 1.3045e-12,\n            1.7458e-12, 1.0474e-12, 9.8814e-13, 8.6333e-13, 1.1906e-12, 1.3750e-12,\n            6.3482e-13, 3.5314e-12, 1.0823e-12, 1.6650e-12, 8.0401e-13, 7.4988e-13,\n            1.4267e-12, 8.6144e-13, 8.0475e-13, 4.7167e-13, 1.0113e-12, 8.5235e-13,\n            6.7035e-13, 1.0898e-12, 1.0028e-12, 1.5435e-12, 2.4788e-12, 1.0080e-12,\n            8.3974e-13, 1.4747e-12, 1.9019e-12, 1.4483e-12, 1.3384e-12, 1.2428e-12,\n            1.2292e-12, 1.0603e-12, 1.4644e-12, 1.6226e-12, 1.6793e-12, 8.2451e-13,\n            1.7192e-12, 1.8275e-12, 8.4404e-13, 9.7002e-13, 1.0743e-12, 2.0861e-12,\n            9.3678e-13, 1.7375e-12, 2.7259e-12, 9.8828e-13, 1.1025e-12, 3.6522e-12,\n            1.0694e-12, 1.2263e-12])},\n   24: {'exp_avg': tensor([-1.4330e-07, -2.8532e-07,  2.2731e-07,  9.7216e-08, -1.1757e-07,\n            -2.2730e-07, -1.3956e-07, -1.0286e-07, -2.9304e-07, -2.9236e-07,\n            -1.3402e-07,  2.1223e-07,  4.6756e-07,  4.6810e-07, -3.5167e-07,\n             1.3239e-07, -1.5923e-07,  1.1968e-07,  7.0194e-08, -2.3276e-07,\n             1.7839e-07, -1.8598e-07, -2.8710e-08, -2.0371e-08,  1.7723e-07,\n             8.5042e-08,  1.5170e-07,  3.0113e-07,  1.4209e-07,  2.6619e-07,\n            -1.0690e-07, -1.2162e-07, -2.1533e-07,  9.5430e-08, -2.7529e-07,\n             2.1854e-07, -3.5449e-07, -2.6999e-08, -7.8260e-08, -2.6663e-07,\n             2.1756e-07,  6.2700e-07, -2.0632e-07,  1.5027e-07,  2.9277e-07,\n            -2.8743e-08,  5.4447e-09, -5.3596e-08, -2.1977e-08,  3.0484e-07,\n            -5.5308e-07,  7.6759e-08,  4.3718e-07,  4.0846e-07, -4.7915e-07,\n            -3.3866e-07, -5.8729e-08,  1.0390e-07,  2.4561e-07,  1.7774e-07,\n            -7.5215e-08,  2.3688e-07, -4.5131e-07, -2.0857e-08,  4.0065e-08,\n            -7.5124e-08,  1.0498e-07,  2.1027e-07,  1.7020e-07,  3.5584e-07,\n            -1.4334e-07, -2.0253e-07, -1.1971e-07,  1.5359e-07, -7.1209e-08,\n             6.6512e-08, -4.9178e-07, -4.6798e-08, -2.4312e-07,  1.4391e-07,\n            -2.2660e-07,  3.0154e-07,  3.1314e-07, -1.6478e-07,  8.2080e-08,\n            -7.6935e-08,  3.7551e-07,  1.5257e-07, -1.1803e-08,  1.4600e-07,\n             3.9448e-07, -4.2261e-08,  4.1858e-07, -1.2923e-07,  2.5874e-08,\n             5.1605e-07,  1.1575e-07,  2.1857e-07,  1.1049e-07, -1.1415e-07,\n            -2.1242e-07, -5.4612e-07,  2.2045e-07,  5.0408e-08, -2.5031e-08,\n             6.7014e-07, -4.9350e-07, -2.0618e-07,  2.6497e-07, -1.0820e-07,\n             4.7455e-09, -4.5584e-07, -9.7558e-08, -1.7330e-07, -1.1489e-07,\n             1.1526e-07, -2.5809e-08,  3.9537e-07, -1.4661e-07, -4.5800e-08,\n             2.0140e-07, -6.2877e-08, -2.0742e-07, -2.6156e-08, -2.5232e-07,\n             1.9439e-07, -1.3046e-07,  1.1490e-07]),\n    'exp_avg_sq': tensor([9.7360e-13, 1.4614e-12, 1.3418e-12, 6.2165e-13, 1.1068e-12, 6.6799e-13,\n            1.3484e-12, 1.1795e-12, 1.3673e-12, 1.1491e-12, 1.2308e-12, 1.1319e-12,\n            1.0297e-12, 2.2354e-12, 5.7523e-13, 1.2918e-12, 6.8808e-13, 8.8199e-13,\n            8.8782e-13, 9.3753e-13, 8.0708e-13, 9.1488e-13, 1.0765e-12, 8.7226e-13,\n            8.5459e-13, 1.2981e-12, 1.7065e-12, 9.1662e-13, 6.6055e-13, 8.0988e-13,\n            1.0211e-12, 8.1848e-13, 1.1270e-12, 1.0543e-12, 8.5902e-13, 9.5063e-13,\n            9.3259e-13, 8.0764e-13, 1.1762e-12, 9.4036e-13, 1.2684e-12, 9.3093e-13,\n            1.3365e-12, 9.0485e-13, 1.7206e-12, 6.4046e-13, 1.2539e-12, 1.0873e-12,\n            1.4767e-12, 1.0597e-12, 4.2463e-12, 6.3373e-13, 1.8732e-12, 1.3515e-12,\n            1.7068e-12, 8.0931e-13, 8.0640e-13, 1.4917e-12, 1.2641e-12, 1.5350e-12,\n            1.4781e-12, 7.4234e-13, 8.5290e-13, 9.5324e-13, 9.2674e-13, 8.5237e-13,\n            1.0096e-12, 1.4320e-12, 1.6639e-12, 2.3304e-12, 1.0526e-12, 7.9671e-13,\n            9.5701e-13, 6.7398e-13, 9.5941e-13, 8.6284e-13, 2.6477e-12, 8.9955e-13,\n            2.1198e-12, 1.2759e-12, 1.6107e-12, 9.8651e-13, 1.7000e-12, 1.1474e-12,\n            7.4454e-13, 1.2129e-12, 9.8080e-13, 6.0718e-13, 1.3577e-12, 9.8861e-13,\n            7.7723e-13, 7.2852e-13, 7.7698e-13, 1.0205e-12, 7.5169e-13, 1.5869e-12,\n            1.0523e-12, 1.3376e-12, 1.2792e-12, 1.1030e-12, 1.3338e-12, 1.3914e-12,\n            1.3357e-12, 8.1984e-13, 7.0871e-13, 1.4740e-12, 1.2269e-12, 1.2012e-12,\n            1.4562e-12, 1.0052e-12, 2.4461e-12, 9.5109e-13, 1.3722e-12, 9.3013e-13,\n            8.9073e-13, 1.0693e-12, 8.9922e-13, 8.6391e-13, 1.4132e-12, 1.1166e-12,\n            1.5772e-12, 9.4222e-13, 9.4681e-13, 9.3068e-13, 8.3025e-13, 1.1660e-12,\n            8.2601e-13, 1.0816e-12])},\n   25: {'exp_avg': tensor([ 6.5689e-08, -7.8538e-07,  7.3648e-08,  6.7872e-09, -2.7741e-07,\n            -6.5443e-08, -7.0937e-08, -2.1963e-07, -4.9652e-08, -2.7908e-07,\n            -7.5591e-08,  1.2738e-07,  2.4983e-07,  1.0491e-07, -2.9132e-07,\n            -1.0627e-07, -9.0693e-08, -8.7294e-08,  2.4613e-08, -1.6832e-07,\n            -4.7202e-08, -2.8436e-07, -2.2448e-07, -6.0641e-08,  8.5622e-08,\n             1.0023e-07,  1.5381e-07,  3.6631e-07, -3.1265e-09,  6.9640e-08,\n            -2.2740e-07,  1.1511e-07, -3.9150e-08,  2.2756e-08, -2.5948e-07,\n             2.6126e-07, -9.7495e-08,  1.3204e-08, -7.9554e-08, -7.0318e-07,\n            -1.6292e-07,  4.3148e-07, -1.2658e-07, -4.6994e-09,  2.0309e-07,\n            -1.4377e-07,  1.4765e-07, -4.9289e-08, -8.6850e-08,  1.4042e-07,\n            -4.5234e-07,  1.2028e-07,  2.0996e-07, -2.1353e-07, -3.9919e-07,\n            -4.0377e-07, -1.1459e-07,  1.1613e-07,  1.6366e-07, -4.5572e-07,\n             3.5057e-08, -1.4563e-07, -3.1147e-07, -1.6580e-07, -3.9677e-07,\n            -3.3994e-08,  5.9316e-08,  3.4081e-07, -2.0657e-08,  1.2394e-07,\n            -6.6499e-08,  5.2361e-08, -1.2801e-07,  4.5545e-08,  6.2172e-08,\n            -9.3395e-08, -5.2196e-07, -2.1532e-07, -4.5502e-07,  1.0920e-07,\n            -2.2157e-07, -1.4026e-07,  7.6304e-08, -2.3377e-07,  4.5942e-08,\n             2.3778e-08,  4.4516e-07,  1.7326e-07, -4.9625e-09, -1.3095e-07,\n             3.9303e-07, -2.1731e-07, -1.6670e-07, -1.7488e-07,  7.6652e-08,\n             3.4911e-07, -3.1582e-08, -1.5797e-07, -6.1714e-08, -4.7394e-08,\n            -2.4284e-07,  2.0929e-08,  4.2305e-08,  4.8400e-10, -3.4373e-08,\n             3.4620e-07, -2.5837e-07, -2.4019e-07, -1.2307e-07, -3.3010e-07,\n            -4.9656e-07, -4.6304e-07, -1.8378e-07, -2.3818e-07, -2.7298e-07,\n             1.2832e-07, -6.1611e-08,  2.6726e-07, -4.6058e-07, -8.8273e-08,\n            -1.6612e-07, -1.6268e-07, -4.0500e-07, -1.0495e-07, -1.9423e-07,\n             1.0301e-07, -3.7816e-07, -2.7374e-08]),\n    'exp_avg_sq': tensor([5.5744e-13, 1.1038e-12, 6.5229e-13, 4.6452e-13, 6.2623e-13, 5.6213e-13,\n            8.6480e-13, 5.8777e-13, 7.0096e-13, 8.8475e-13, 5.1944e-13, 5.2290e-13,\n            6.6378e-13, 1.2255e-12, 3.9147e-13, 8.8767e-13, 4.5194e-13, 5.8781e-13,\n            5.7830e-13, 5.4220e-13, 4.6474e-13, 5.5208e-13, 6.1460e-13, 5.2780e-13,\n            6.2960e-13, 7.7820e-13, 9.2048e-13, 5.9009e-13, 5.2380e-13, 4.2873e-13,\n            6.0120e-13, 5.5435e-13, 7.7401e-13, 5.6344e-13, 6.5684e-13, 5.2519e-13,\n            5.2611e-13, 5.4840e-13, 7.3547e-13, 6.8041e-13, 8.4926e-13, 7.0068e-13,\n            6.2751e-13, 6.9819e-13, 1.1823e-12, 5.2822e-13, 6.2780e-13, 6.0904e-13,\n            6.5160e-13, 5.8738e-13, 2.7421e-12, 4.1882e-13, 1.2055e-12, 6.9745e-13,\n            8.2578e-13, 5.2063e-13, 5.1559e-13, 7.9577e-13, 6.8819e-13, 9.8502e-13,\n            7.2358e-13, 3.8205e-13, 4.9604e-13, 5.9995e-13, 6.1950e-13, 5.6216e-13,\n            4.8226e-13, 8.4283e-13, 7.9532e-13, 1.7482e-12, 5.4016e-13, 5.4209e-13,\n            5.2931e-13, 5.4134e-13, 6.8698e-13, 5.5566e-13, 1.2200e-12, 5.6647e-13,\n            1.0704e-12, 1.0535e-12, 9.6004e-13, 6.4684e-13, 8.6237e-13, 5.4396e-13,\n            4.4295e-13, 1.0372e-12, 5.5962e-13, 4.1600e-13, 6.9673e-13, 8.4385e-13,\n            5.3357e-13, 4.3865e-13, 4.6679e-13, 4.9651e-13, 6.4591e-13, 9.8801e-13,\n            1.0699e-12, 7.1856e-13, 7.5983e-13, 6.6501e-13, 7.2096e-13, 7.9818e-13,\n            6.7577e-13, 4.3839e-13, 4.4392e-13, 7.3531e-13, 7.0852e-13, 8.4697e-13,\n            9.0968e-13, 5.9484e-13, 9.2005e-13, 5.6360e-13, 7.2883e-13, 5.6861e-13,\n            5.7493e-13, 6.5224e-13, 5.9468e-13, 5.4543e-13, 7.5308e-13, 8.0383e-13,\n            6.7775e-13, 1.1342e-12, 6.4355e-13, 5.8957e-13, 6.2805e-13, 6.7473e-13,\n            5.2619e-13, 6.0717e-13])},\n   26: {'exp_avg': tensor([-3.4720e-07,  1.3786e-08, -8.9057e-09, -5.6384e-07,  9.1304e-08,\n            -2.7707e-07,  1.8035e-07, -3.4509e-07, -3.1892e-07,  3.6471e-07,\n            -9.5500e-08, -1.5500e-07,  2.1741e-07,  3.5161e-08,  2.2618e-07,\n             1.1731e-08, -1.0515e-07,  2.3126e-07, -2.1616e-07,  8.7820e-08,\n            -1.7526e-07,  1.3992e-07,  2.2416e-08, -1.6405e-07, -1.4931e-07,\n             7.0887e-07,  2.5588e-07, -2.8760e-07,  5.4688e-07, -1.1249e-07,\n             3.3300e-07, -2.8610e-07, -2.0816e-07,  9.2032e-08,  3.6558e-08,\n            -3.1785e-07, -2.5854e-07,  1.5188e-07,  1.5022e-07, -2.8307e-07,\n            -3.6672e-07,  5.0868e-08, -1.5842e-07,  1.1427e-07, -6.2579e-08,\n             4.4279e-07, -2.3322e-07, -3.5807e-07,  2.8808e-07,  1.3243e-07,\n            -1.9851e-08,  1.8755e-08, -1.5449e-07, -1.2335e-07,  8.3497e-08,\n            -1.9809e-07,  8.1047e-08, -3.7766e-08,  1.6495e-07, -1.1352e-07,\n            -1.5926e-07,  8.0769e-08,  1.3866e-08,  7.4837e-08, -1.4859e-07,\n             1.4849e-07,  4.3948e-07, -1.6888e-08, -2.3423e-07, -1.2559e-08,\n            -1.9187e-07, -1.2238e-07,  1.3285e-07, -1.2205e-07,  5.3229e-07,\n            -5.5128e-08, -4.2648e-07, -3.4456e-08, -2.4610e-07, -2.5354e-07,\n            -1.0008e-07,  1.3100e-07, -2.9629e-07,  2.2172e-07,  3.8956e-07,\n             6.8550e-07,  1.9894e-07, -4.5185e-08,  3.3966e-07, -8.6014e-08,\n             1.6175e-07,  1.0264e-07,  1.0537e-07,  1.2655e-07, -4.0981e-08,\n            -9.7106e-08,  4.1387e-08, -2.3462e-07,  1.2546e-07,  1.7815e-07,\n            -2.1192e-08, -1.4485e-07,  2.8627e-08, -5.2817e-07, -3.0149e-07,\n            -8.0643e-09,  1.0361e-07,  7.8364e-08, -6.0428e-08,  6.9431e-08,\n             5.0915e-07, -6.7675e-09, -4.2591e-07, -1.0818e-07,  5.3524e-07,\n             1.6136e-07, -3.2756e-08,  2.6716e-07, -1.5732e-07,  4.0518e-08,\n            -2.3042e-07, -1.2698e-07, -3.3155e-07,  2.3184e-07, -3.7614e-08,\n             3.2220e-07,  3.7841e-07,  1.1577e-08,  4.1972e-08,  1.2057e-07,\n             1.5973e-07,  4.6251e-07, -9.7199e-08,  3.5662e-08, -1.0291e-07,\n             3.3989e-07,  6.6924e-08, -1.5815e-07, -3.2337e-07, -2.6249e-08,\n            -8.6277e-07,  3.1208e-09, -3.7324e-07, -1.0721e-07,  2.0403e-07,\n             1.1048e-09,  4.0141e-07,  2.4986e-08, -1.8104e-07,  3.3049e-07,\n             8.8597e-08, -7.1115e-08, -3.6100e-07, -2.7876e-07, -1.4490e-07,\n             3.1772e-07,  2.8265e-08, -3.6898e-08,  1.4194e-07,  1.1317e-07,\n             1.5148e-07, -6.9690e-08,  1.7820e-07, -3.0141e-07,  1.0758e-07,\n             5.8827e-08,  1.3956e-07, -1.2447e-07, -3.7916e-07,  6.1725e-07,\n             6.6644e-08, -2.6887e-07, -2.5296e-07,  1.8316e-07,  2.5444e-07,\n            -2.7363e-07,  2.4347e-09, -2.8899e-08, -7.1796e-08,  2.7748e-07,\n            -5.4273e-08, -2.0995e-08,  4.9316e-07, -8.6268e-08,  1.4962e-07,\n            -1.7308e-07,  5.1129e-07, -1.6874e-07, -1.2260e-07,  1.9712e-07,\n            -4.6223e-07, -4.5988e-07,  9.4402e-08,  4.4462e-07,  1.5297e-07,\n             2.4212e-07, -5.9090e-08, -5.3901e-08, -6.0987e-08,  3.8343e-07,\n            -3.4333e-07,  3.7096e-07,  2.1645e-07, -1.4478e-08,  4.8754e-08,\n            -2.6029e-07,  1.4787e-07,  3.7425e-07, -5.7531e-07, -1.4343e-07,\n             3.5997e-07, -3.9410e-07, -2.0922e-09, -2.2634e-07,  7.7567e-08,\n            -6.3297e-07, -1.0631e-07,  1.5500e-07, -5.8807e-08, -6.9444e-08,\n             8.7096e-08,  8.4628e-08, -2.2303e-08, -3.1664e-08,  6.8485e-08,\n            -1.6704e-08, -1.3321e-07,  3.5321e-07,  2.0707e-07, -2.1017e-07,\n            -5.2982e-07,  4.1501e-07, -1.5285e-07, -2.9420e-07,  6.3649e-09,\n            -1.3661e-07,  1.8395e-07,  8.7606e-08,  1.4388e-07, -2.5436e-07,\n            -1.7861e-07, -3.6017e-07,  1.1939e-07,  3.8778e-07, -8.8315e-08,\n             9.2454e-08,  4.8319e-07, -3.4991e-07, -2.0883e-07,  4.3320e-07,\n            -1.7382e-07, -4.4634e-07, -4.5859e-07,  1.8769e-07, -1.8952e-07,\n            -4.4335e-07,  4.1236e-07,  4.9328e-07, -2.6904e-07,  2.2946e-07,\n            -1.5161e-07,  2.0534e-07, -2.7011e-08,  1.4820e-07, -5.7468e-07,\n             9.0673e-09, -6.6461e-08,  7.7111e-08,  1.7326e-07,  4.3838e-08,\n             2.2640e-07, -1.8618e-07,  1.8044e-07, -1.5094e-07, -1.9527e-08,\n            -2.5372e-07,  3.5860e-07, -5.0636e-08,  7.5358e-08,  2.8701e-07,\n            -1.1737e-07,  1.3252e-07, -7.1819e-08,  1.9966e-07,  4.3551e-07,\n            -3.8370e-08,  4.0043e-08, -1.5028e-08,  3.3644e-07,  3.8164e-07,\n            -1.3425e-07,  3.7216e-07,  1.0953e-07,  5.2238e-07,  3.4079e-08,\n            -2.3590e-07,  1.4255e-07,  1.1372e-07,  1.1559e-07,  4.4179e-07,\n             3.9455e-07,  3.9356e-07,  2.6684e-07, -2.0615e-08,  3.4989e-07,\n            -7.9436e-08, -1.2248e-07, -9.4062e-08, -2.0359e-07, -4.2378e-07,\n             1.3722e-08,  1.3795e-07,  2.8068e-07,  4.5900e-08,  1.2428e-07,\n            -2.2562e-07,  2.7907e-07,  5.8413e-08, -2.0663e-07,  5.2490e-07,\n             1.5532e-07, -3.7587e-07,  2.0214e-07,  4.4794e-08,  1.4343e-07,\n             2.4703e-07, -3.2290e-07, -1.3331e-07, -2.5896e-07, -5.2862e-07,\n            -5.7864e-07,  2.2585e-07, -1.4540e-07, -3.2423e-08, -1.2823e-07,\n            -3.4589e-07, -1.2049e-07, -2.2319e-07, -1.7876e-07,  2.6847e-07,\n            -1.7101e-07, -2.1324e-07, -2.3285e-07, -1.0950e-07, -1.3620e-07,\n             2.6486e-07, -7.4287e-08, -1.7057e-07,  8.1076e-08,  3.4779e-07,\n             1.7798e-07, -7.6159e-08,  1.1297e-08,  2.4667e-08,  1.3820e-07,\n             1.0644e-06, -1.0864e-07,  4.4596e-07,  2.6587e-07,  1.1503e-07,\n             1.1085e-07, -1.9925e-08,  2.6457e-07, -7.4582e-08, -2.3838e-07,\n             1.1677e-07, -1.6027e-07, -5.6061e-10,  1.6193e-07, -1.0519e-07,\n             2.6063e-07,  1.2952e-07, -6.9823e-08, -2.2280e-07, -2.8408e-07,\n            -6.4213e-08, -2.4961e-07, -2.7657e-07, -1.4672e-08,  2.0762e-07,\n            -2.4135e-07, -4.0928e-08, -1.9250e-07, -1.0783e-08,  3.3524e-07,\n             3.0955e-07, -1.4233e-07, -4.9826e-08, -6.7856e-08, -8.3757e-08,\n             3.5557e-07, -1.0386e-07, -8.0172e-08, -3.1644e-07, -4.3597e-08,\n             9.6231e-08, -2.3927e-07, -9.5008e-08, -3.1400e-07, -1.7526e-07,\n            -4.4081e-08, -2.5335e-07,  4.3133e-08,  3.4693e-07,  3.7888e-07,\n            -1.2745e-08,  1.0979e-07, -8.0066e-08, -2.1294e-08, -1.9027e-08,\n            -1.8386e-07,  4.6133e-07, -8.0870e-08,  6.7544e-08,  9.1664e-08,\n             6.6659e-08,  4.0799e-07,  1.2316e-07,  8.1775e-08, -7.2640e-08,\n             1.6848e-07,  3.0191e-07, -1.6894e-07, -1.0517e-07,  1.9437e-07,\n             1.8111e-07,  1.4307e-07,  1.8719e-07,  8.1766e-08,  1.3695e-07,\n             1.3486e-08, -3.9645e-07,  3.6198e-08, -2.5231e-07, -2.9364e-07,\n             4.6194e-07, -2.0751e-07, -6.0149e-07, -7.0440e-07, -2.7189e-07,\n            -4.3601e-07, -3.2860e-07, -5.1682e-07,  3.0553e-08, -9.3731e-08,\n            -2.4286e-07, -1.5815e-07, -1.1148e-07, -3.3619e-07, -6.1800e-08,\n             9.0077e-08,  4.5518e-07, -2.5519e-07, -3.6481e-07, -8.3087e-08,\n            -6.1943e-08, -1.6548e-07, -1.8532e-07, -8.4248e-08,  2.4567e-07,\n             1.4739e-07, -3.4792e-08, -5.4522e-07,  1.2995e-08,  2.8018e-08,\n            -1.8438e-07, -8.3043e-09,  7.0042e-07,  1.0071e-07,  1.3891e-07,\n             3.5208e-07,  1.0290e-07,  2.0081e-07,  4.1977e-09,  2.1859e-07,\n            -2.1782e-07,  2.1669e-09, -3.5597e-09, -1.9910e-07,  3.1075e-07,\n            -7.6919e-08,  5.4500e-07, -2.4553e-07, -1.6059e-07, -5.4410e-08,\n             1.2581e-07, -2.2698e-07,  1.3864e-07,  5.1799e-07, -2.9417e-07,\n             1.5450e-07, -7.9610e-08, -2.4073e-07, -3.5906e-07, -4.9385e-08,\n             1.9264e-07, -8.8929e-08,  2.1970e-07,  3.9593e-08,  1.2297e-07,\n            -1.3730e-07, -2.1474e-07,  3.4505e-07, -3.6245e-08,  1.4901e-07,\n             3.1069e-07,  2.0515e-07,  1.5889e-07,  1.9019e-07,  1.0871e-07,\n             8.4888e-07, -3.0557e-08]),\n    'exp_avg_sq': tensor([1.3775e-12, 1.0429e-12, 9.6604e-13, 6.8625e-12, 6.8623e-13, 1.4181e-12,\n            8.4918e-13, 8.1374e-13, 1.0694e-12, 2.2668e-12, 5.8919e-13, 1.4486e-12,\n            4.5230e-13, 1.2733e-12, 9.0836e-13, 1.6632e-12, 1.0631e-12, 2.4019e-12,\n            2.5344e-12, 5.3581e-13, 1.0243e-12, 1.2291e-12, 5.1194e-13, 7.8641e-13,\n            8.1179e-13, 2.0390e-12, 5.4153e-13, 1.6069e-12, 3.5497e-12, 1.9279e-12,\n            2.0734e-12, 2.0557e-12, 6.7010e-13, 1.5947e-12, 2.0075e-12, 2.1165e-12,\n            1.1629e-12, 1.0403e-12, 5.8614e-13, 2.2643e-12, 1.3096e-12, 1.5745e-12,\n            1.0293e-12, 7.4432e-13, 1.9926e-12, 2.1253e-12, 6.5445e-13, 1.5349e-12,\n            3.6190e-13, 1.7983e-13, 7.1373e-13, 5.6021e-13, 9.4233e-13, 6.6918e-13,\n            1.5198e-12, 6.1899e-13, 1.9046e-12, 8.6719e-13, 3.2670e-12, 8.9775e-13,\n            2.8367e-13, 1.7914e-12, 1.2180e-12, 9.5317e-13, 1.5701e-12, 1.4602e-12,\n            6.7757e-13, 1.2777e-12, 6.5723e-13, 4.2121e-12, 9.9209e-13, 7.5391e-13,\n            5.9386e-13, 1.3006e-12, 2.0696e-12, 4.9162e-13, 2.3584e-12, 1.3855e-12,\n            1.5874e-12, 1.8515e-12, 1.9376e-12, 6.1201e-13, 7.5672e-13, 1.8531e-12,\n            1.4169e-12, 1.1888e-12, 1.5430e-12, 4.6929e-13, 1.7147e-12, 2.7252e-12,\n            4.6073e-13, 1.0856e-12, 1.6257e-12, 1.7490e-12, 1.4579e-12, 1.1163e-12,\n            1.1831e-12, 1.0805e-12, 5.4570e-13, 1.6280e-12, 4.2377e-13, 5.3071e-13,\n            4.3031e-13, 6.1484e-13, 1.3998e-12, 1.1134e-12, 7.5050e-13, 1.0648e-12,\n            5.7879e-13, 7.6648e-13, 2.6510e-12, 5.0651e-13, 1.5360e-12, 6.2696e-13,\n            8.1977e-13, 9.0287e-13, 5.9804e-13, 4.7324e-13, 2.7004e-12, 1.2711e-12,\n            9.5840e-13, 5.7617e-13, 1.3148e-12, 7.2390e-13, 6.6146e-13, 1.3680e-12,\n            2.3264e-12, 5.1557e-13, 1.9044e-12, 1.4468e-12, 1.2011e-12, 1.7035e-12,\n            4.8403e-13, 1.3525e-12, 1.0351e-12, 1.4798e-12, 4.8660e-13, 5.0981e-13,\n            1.6950e-12, 9.2238e-13, 2.3480e-12, 1.0562e-12, 9.1656e-13, 7.2269e-13,\n            8.5407e-13, 1.8904e-12, 3.5597e-13, 1.9684e-12, 1.2400e-12, 4.0181e-12,\n            3.2212e-13, 4.3234e-13, 9.5761e-13, 4.4412e-13, 1.1222e-12, 3.0833e-12,\n            5.6558e-13, 9.1963e-13, 1.1115e-12, 7.5885e-13, 1.2843e-12, 6.7649e-13,\n            1.0963e-12, 6.4946e-13, 5.4108e-13, 1.2899e-12, 1.1988e-12, 2.3708e-13,\n            8.8673e-13, 2.3576e-12, 9.6879e-13, 6.0492e-13, 2.0164e-12, 2.8660e-12,\n            6.0160e-13, 5.0908e-13, 1.1960e-12, 1.0395e-12, 7.6685e-13, 8.2341e-13,\n            2.2714e-12, 2.1771e-12, 7.3328e-13, 2.3894e-12, 2.5789e-13, 6.0610e-13,\n            1.1039e-12, 2.4884e-13, 1.4802e-12, 4.3477e-13, 2.5090e-12, 2.4777e-12,\n            7.3208e-13, 1.6044e-12, 3.5368e-13, 5.1636e-13, 9.4438e-13, 1.4069e-12,\n            5.1792e-13, 1.6737e-12, 8.1960e-13, 9.7433e-13, 7.4877e-13, 1.1409e-12,\n            1.1765e-12, 7.6638e-13, 7.1850e-13, 1.1670e-12, 1.8763e-12, 8.1055e-13,\n            9.9264e-13, 1.9097e-12, 1.2263e-12, 1.5373e-12, 8.5300e-13, 1.0751e-12,\n            9.4091e-13, 1.2964e-12, 7.4418e-13, 3.4357e-13, 3.6459e-13, 6.3257e-13,\n            7.3914e-13, 3.8682e-13, 1.2470e-12, 8.2791e-13, 1.8775e-12, 6.0762e-13,\n            5.9397e-13, 6.4336e-13, 2.8689e-12, 9.3555e-13, 8.9992e-13, 7.9176e-13,\n            4.9277e-13, 3.7277e-13, 2.0638e-12, 2.6051e-13, 2.0001e-12, 1.9831e-12,\n            9.5249e-13, 1.1531e-12, 9.4598e-13, 2.6135e-12, 1.4100e-12, 1.4190e-12,\n            1.6016e-12, 1.5613e-12, 1.4382e-12, 4.3735e-12, 1.4382e-12, 1.6663e-12,\n            1.6456e-12, 1.0679e-12, 8.6506e-13, 1.9795e-12, 1.1123e-12, 1.4712e-12,\n            8.4438e-13, 1.0737e-12, 1.5849e-12, 1.0420e-12, 6.5354e-13, 8.0074e-13,\n            4.0202e-12, 9.0205e-13, 4.1624e-13, 1.1097e-12, 1.3449e-12, 5.5489e-13,\n            4.7435e-13, 9.2657e-13, 2.8177e-13, 2.0265e-12, 9.5058e-13, 2.0049e-12,\n            1.4650e-12, 1.5806e-12, 3.2094e-13, 2.1877e-13, 5.1649e-13, 8.7824e-13,\n            1.3992e-12, 1.6476e-12, 1.4699e-12, 1.9903e-13, 1.5308e-12, 1.7328e-12,\n            7.6686e-13, 9.0057e-13, 2.5759e-12, 7.3247e-13, 4.8521e-13, 2.0168e-12,\n            1.2925e-12, 4.2369e-12, 7.0038e-13, 1.9786e-12, 6.4559e-13, 1.4929e-12,\n            1.0737e-12, 1.6462e-12, 7.4635e-13, 1.3392e-12, 6.6878e-13, 5.7992e-13,\n            6.2410e-13, 9.6764e-13, 3.2458e-13, 1.1127e-12, 1.5404e-12, 7.9280e-13,\n            1.3431e-12, 4.4712e-13, 1.0653e-12, 2.4265e-12, 4.5552e-13, 1.4200e-12,\n            5.9559e-13, 2.3211e-12, 2.5923e-12, 1.4474e-12, 5.8314e-13, 1.0878e-12,\n            4.4640e-13, 1.0487e-12, 1.0186e-12, 6.8304e-13, 7.6257e-13, 2.8967e-12,\n            1.5084e-12, 9.0671e-13, 3.1603e-12, 6.0820e-13, 1.7612e-12, 1.0555e-12,\n            4.9065e-13, 2.0012e-12, 2.9461e-12, 1.2202e-12, 1.5779e-12, 9.2077e-13,\n            1.1406e-12, 2.3097e-12, 3.7068e-13, 8.3828e-13, 3.9125e-12, 7.4403e-13,\n            2.6374e-12, 6.3088e-13, 1.2070e-12, 6.1907e-13, 2.6675e-13, 2.2212e-12,\n            1.2076e-12, 1.6646e-12, 3.3762e-13, 2.2982e-12, 4.7945e-13, 2.3230e-13,\n            1.6789e-12, 1.8435e-12, 2.7260e-12, 8.6417e-13, 1.1675e-12, 8.8335e-13,\n            6.5801e-13, 4.6846e-13, 2.8836e-13, 2.1656e-12, 1.3874e-12, 1.0400e-12,\n            1.5853e-12, 6.0334e-13, 7.9389e-13, 3.0668e-13, 7.2744e-13, 4.5879e-12,\n            1.1480e-12, 8.8125e-13, 2.6773e-12, 2.3677e-13, 6.3844e-13, 1.0905e-12,\n            1.1928e-12, 1.9487e-12, 5.6922e-13, 3.5212e-13, 7.6260e-13, 1.2051e-12,\n            1.2115e-12, 1.1845e-12, 1.0087e-12, 8.3889e-13, 9.2654e-13, 4.8801e-13,\n            6.8138e-13, 1.8495e-13, 1.2845e-12, 3.2685e-13, 8.0301e-13, 1.0653e-12,\n            1.1066e-12, 3.2302e-12, 2.8418e-12, 1.1675e-12, 5.8429e-13, 9.7270e-13,\n            1.0999e-12, 1.2193e-12, 7.8851e-13, 2.8609e-12, 6.3581e-13, 1.0928e-12,\n            2.2376e-12, 6.8379e-13, 1.3659e-12, 5.3604e-13, 1.0085e-12, 1.5208e-12,\n            8.0310e-13, 6.8911e-13, 3.4065e-12, 1.1537e-12, 8.2676e-13, 6.1248e-13,\n            4.2996e-12, 7.7634e-13, 9.3786e-13, 4.8661e-13, 1.5361e-12, 6.6005e-13,\n            1.4383e-12, 1.6704e-12, 5.2446e-13, 5.6369e-13, 1.4318e-12, 1.6267e-12,\n            1.9129e-12, 1.5616e-12, 1.7660e-12, 7.9920e-13, 2.5726e-12, 1.7720e-12,\n            5.8802e-13, 1.1022e-12, 1.7500e-12, 9.1797e-13, 2.1305e-12, 1.0279e-12,\n            6.7419e-13, 5.3119e-13, 1.5549e-12, 1.4043e-12, 3.9142e-12, 7.9777e-13,\n            6.8696e-13, 1.2461e-12, 8.7898e-13, 1.0711e-12, 2.7671e-12, 9.4353e-13,\n            8.7042e-13, 1.4771e-12, 9.8890e-13, 1.1491e-12, 4.7870e-13, 1.9287e-12,\n            3.6195e-13, 7.3370e-13, 1.4035e-12, 1.0985e-12, 2.1929e-12, 5.1869e-13,\n            2.0972e-13, 7.9245e-13, 7.3274e-13, 1.8317e-12, 2.1177e-12, 3.2127e-12,\n            1.0442e-12, 1.9084e-12, 1.0897e-12, 2.5355e-12, 1.3107e-12, 1.7716e-12,\n            8.2280e-13, 1.4889e-12, 1.4316e-12, 3.0976e-12, 3.8527e-12, 1.7301e-12,\n            1.8433e-12, 1.1653e-12, 1.0197e-12, 9.2996e-13, 3.3493e-13, 1.0834e-12,\n            1.0858e-12, 3.5538e-13, 3.3566e-13, 2.0327e-13, 9.6596e-13, 9.0492e-13,\n            1.8274e-12, 1.2921e-12, 1.0688e-12, 1.1226e-12, 6.5354e-13, 1.1152e-12,\n            2.9662e-12, 9.8223e-13])},\n   27: {'exp_avg': tensor([-2.5042e-07, -5.0125e-08,  9.0141e-08, -3.6941e-07,  1.6147e-07,\n            -3.2190e-07,  4.9386e-08, -2.4550e-07,  2.2177e-08,  9.6421e-08,\n            -5.2465e-08, -4.6125e-08,  2.4819e-07,  7.6804e-08,  1.0067e-07,\n            -1.8258e-07, -7.7005e-08, -2.6018e-07, -2.9895e-07,  1.6492e-07,\n             3.1429e-07,  2.4361e-07, -1.7716e-07, -1.4709e-07, -8.8981e-09,\n            -1.1877e-07, -2.2607e-08, -3.4473e-08, -2.3625e-07, -2.8570e-07,\n            -8.1292e-08,  2.3718e-07, -2.6681e-07, -8.8050e-08,  1.4080e-07,\n            -3.5246e-07,  2.8545e-08, -2.5365e-07, -1.8064e-07,  4.2581e-07,\n             1.9135e-07,  3.5951e-08,  4.7034e-08, -2.9763e-07, -5.2212e-08,\n            -9.4878e-08, -1.6461e-07, -3.2114e-08, -1.1499e-07,  1.4119e-07,\n             2.0129e-07,  1.4723e-07, -4.7543e-08, -7.1981e-08,  9.2683e-08,\n             3.5206e-08,  8.5244e-08, -3.0327e-08,  1.7257e-07, -7.5148e-08,\n            -2.3036e-07,  1.4738e-07,  1.8789e-07,  2.1200e-08, -6.6421e-08,\n            -4.7746e-08,  2.5497e-07, -9.1386e-08, -2.3056e-07,  1.1409e-07,\n             1.1613e-07, -3.5656e-07,  1.2361e-07,  1.3762e-07,  1.7054e-07,\n             2.3859e-07, -2.8080e-07,  5.6093e-08, -1.4343e-07,  2.1404e-07,\n            -6.1457e-08, -2.3157e-07, -1.4725e-08,  9.1458e-08,  2.4052e-08,\n            -5.5329e-07, -2.5602e-07, -7.6841e-08, -1.9489e-07,  1.9505e-07,\n            -7.7949e-08,  1.6197e-07, -1.7638e-07,  1.1647e-08, -2.5380e-08,\n            -8.4546e-08, -1.4143e-08,  1.7990e-07,  3.4913e-08, -9.6136e-08,\n            -7.4313e-08, -1.0204e-07, -3.9873e-08, -2.6366e-07, -2.5689e-07,\n            -3.7304e-09, -2.8484e-07,  1.7114e-07, -2.7098e-07, -1.2767e-07,\n            -3.2320e-07,  5.3882e-08,  2.8366e-07,  5.8482e-08, -2.0857e-07,\n             5.8353e-08,  2.2244e-08,  3.8509e-08, -3.4206e-08,  1.8571e-09,\n             7.8028e-10, -2.0912e-07,  1.8584e-07,  3.8103e-07,  1.4261e-07,\n            -2.4216e-07, -7.2456e-08,  1.0293e-07, -1.8679e-07, -5.7546e-08,\n            -8.8051e-09, -3.4194e-08, -1.9919e-07,  1.6745e-07, -1.3765e-07,\n             3.5780e-07, -1.4104e-07,  5.1986e-09,  2.2255e-07,  3.1773e-07,\n            -3.3967e-07, -1.7860e-07, -6.4185e-08, -1.0809e-07,  9.9215e-08,\n            -1.0037e-07, -6.9467e-08, -2.0726e-07, -2.2705e-07, -3.4473e-08,\n             1.9755e-07, -8.3857e-08, -4.8405e-08,  5.8217e-08, -9.3614e-08,\n            -4.4832e-07, -2.4434e-07,  7.8500e-08, -7.6601e-08, -6.0502e-08,\n            -2.3307e-07, -1.0808e-07, -3.0973e-07, -2.0627e-07,  6.0036e-08,\n            -3.0147e-08,  6.7928e-08, -1.0436e-07,  1.0057e-07,  1.4866e-07,\n             1.7462e-07,  2.4118e-07, -1.1284e-07,  4.2681e-07, -3.8042e-08,\n             1.7773e-07,  1.6666e-07, -4.6317e-08,  1.0303e-07, -1.1992e-07,\n             3.2191e-08, -3.5427e-07,  4.8580e-08, -1.5990e-07, -2.1558e-08,\n            -6.2352e-08, -3.3398e-07, -1.0520e-07,  3.4671e-07, -2.0281e-08,\n             1.3643e-07, -6.7862e-08,  1.6299e-07, -6.5584e-08, -5.3141e-08,\n             2.0620e-07,  6.1298e-09, -1.0674e-07, -2.4585e-07,  7.6394e-08,\n             2.0085e-07,  4.8189e-07,  5.0171e-08, -1.5649e-07,  1.6966e-07,\n             9.5274e-08,  3.6581e-07,  5.2202e-08,  3.4264e-07,  1.7536e-07,\n            -4.7982e-07, -4.1200e-07,  2.8931e-07,  3.7282e-07, -1.9893e-07,\n            -3.7300e-07, -8.8565e-08,  2.4244e-07,  3.1152e-08, -2.1554e-08,\n            -1.7116e-07, -3.3057e-08, -2.2068e-07,  4.8391e-08, -1.8265e-07,\n            -2.7906e-08, -5.7289e-07,  3.4676e-07, -1.5265e-08,  1.6181e-07,\n            -1.3021e-07, -1.8190e-07, -8.3591e-08,  8.2733e-08, -1.7532e-07,\n            -1.1290e-07, -5.3702e-08, -1.4530e-07, -9.6682e-08, -5.8527e-07,\n            -1.5295e-07, -1.5063e-07,  2.2363e-07,  1.6022e-07,  3.0230e-09,\n            -8.6845e-08, -3.2350e-08, -2.5696e-07,  6.7542e-08,  2.8243e-07,\n            -7.4429e-08, -2.8039e-07,  1.7437e-08,  3.2537e-07,  8.6976e-08,\n            -1.6076e-07, -2.3824e-07,  1.4317e-07,  2.0286e-07, -6.5167e-08,\n            -2.3501e-07,  1.6929e-08, -9.3931e-08,  3.6175e-07, -1.4568e-08,\n             3.5313e-07, -6.4089e-08,  5.8946e-08,  6.1059e-08,  3.0734e-08,\n            -2.8667e-08,  1.3995e-07,  7.7699e-08, -4.7251e-07, -2.6598e-07,\n             4.5583e-08, -1.0107e-07, -2.8330e-08,  4.9776e-08,  2.2216e-07,\n             9.0970e-08, -3.0448e-08,  1.4848e-07,  6.0701e-08, -1.6465e-07,\n             2.6095e-08, -2.8132e-07, -3.1493e-08, -3.3943e-07, -3.9542e-07,\n             2.6399e-08,  2.1396e-07, -5.1953e-08, -2.0341e-07,  6.7918e-08,\n            -3.9863e-07, -3.3153e-07,  8.3732e-09,  1.1998e-07,  2.6603e-07,\n             3.0577e-07, -1.6106e-07,  3.3417e-07,  1.2049e-07,  9.0182e-08,\n             9.0485e-08,  8.6921e-08,  2.1262e-07,  1.5643e-07, -2.6775e-08,\n            -5.9009e-07, -2.1659e-09, -7.2553e-09,  1.2911e-07,  3.5243e-08,\n            -1.3315e-07, -3.8851e-08,  8.9950e-08, -1.8282e-07,  2.3912e-08,\n             7.4616e-09,  2.7683e-07, -2.6211e-07,  6.0783e-08, -1.5893e-07,\n             2.9668e-07, -1.6600e-07,  4.1311e-08,  3.3738e-07,  3.9248e-07,\n            -5.5965e-08,  4.8690e-08, -1.4476e-07, -1.1029e-07, -2.3414e-09,\n             1.0728e-07, -3.8150e-09,  1.1638e-07,  2.5772e-08, -3.2235e-07,\n             9.0826e-08,  4.0023e-08,  1.2346e-07, -2.0533e-08, -2.1172e-08,\n            -1.5809e-08, -1.8727e-07,  1.9169e-07, -2.0834e-07, -1.3482e-07,\n            -1.7891e-07,  2.2261e-07, -9.0771e-09, -1.9411e-07,  7.2022e-08,\n             2.8554e-07,  1.8668e-07, -2.7318e-07, -2.2023e-07,  3.7661e-07,\n             2.7159e-07,  5.9451e-08, -3.7966e-07,  9.8297e-08,  2.1989e-07,\n             2.7933e-08, -2.2311e-08, -1.6398e-08,  4.4237e-08, -1.2999e-07,\n            -2.1396e-07,  1.4390e-07,  4.8003e-08, -4.8951e-07, -3.3339e-07,\n             7.6537e-08,  3.7355e-08, -5.2248e-07,  2.0216e-07,  1.8398e-08,\n            -6.6842e-08,  8.9623e-08,  1.5596e-07, -1.2824e-07, -1.0274e-07,\n            -4.7517e-07, -2.4007e-07,  3.9593e-11, -2.9526e-08,  1.3096e-07,\n             8.2681e-08, -1.0552e-07,  4.8811e-08, -6.5026e-08, -9.0440e-08,\n             1.2989e-07, -1.8817e-07,  3.6723e-08, -1.2129e-07, -8.7907e-08,\n            -1.5412e-07, -1.3953e-07,  4.7083e-08, -1.3702e-07,  9.1943e-08,\n            -9.7465e-08,  1.1287e-07,  3.7635e-07, -2.4175e-07, -2.7658e-07,\n             1.9697e-08, -1.0641e-07,  1.2291e-07,  1.9013e-07,  4.0833e-07,\n             4.8478e-09, -1.7839e-08, -1.0024e-07,  2.5823e-07, -1.6111e-08,\n             3.0477e-08,  1.0553e-07,  9.7129e-08,  9.3022e-08, -4.7138e-08,\n            -9.2177e-09, -3.3709e-08, -4.6940e-08,  4.2810e-08,  5.2001e-08,\n             9.1766e-08, -5.2283e-08, -2.1430e-07,  1.8953e-07,  9.1366e-09,\n            -2.2580e-07, -5.4246e-08,  1.8884e-07, -2.5339e-07,  1.4226e-07,\n             8.1099e-08,  6.3082e-08, -2.3594e-07, -7.3804e-08, -1.0346e-07,\n            -4.2378e-08, -2.1638e-07,  1.1492e-07, -2.7418e-07, -1.1090e-07,\n            -2.3882e-08, -1.9592e-07, -3.1281e-07, -6.7149e-08,  2.5273e-08,\n            -1.2867e-07,  3.1165e-07,  1.5237e-07,  2.6421e-08,  8.7956e-08,\n            -2.5895e-07,  1.1938e-07,  1.9600e-08, -6.3447e-08, -8.0992e-08,\n             4.4345e-07, -7.7466e-08, -4.6748e-08, -1.8563e-08,  7.9588e-08,\n             2.6279e-07, -2.6270e-07,  2.2040e-07, -3.0956e-08, -1.5297e-07,\n             2.3025e-07, -4.3782e-07, -1.6507e-07, -3.2697e-07, -2.3122e-07,\n             2.3977e-07,  2.8765e-07,  1.5059e-07, -5.6362e-08,  1.8473e-07,\n            -2.7171e-07, -2.0847e-08, -2.7128e-08,  2.0454e-07, -9.6860e-09,\n            -2.7855e-08, -6.9347e-08,  3.3525e-07, -4.1318e-07, -3.0546e-07,\n            -2.0478e-08, -1.0537e-07, -8.4917e-08, -3.4604e-07,  1.3951e-07,\n             9.9209e-08, -7.3638e-11, -5.1688e-08, -1.3443e-07,  1.0427e-08,\n             1.9041e-07,  4.0851e-08,  6.8975e-08, -2.0018e-07,  2.8252e-07,\n             3.5154e-08,  1.7175e-07]),\n    'exp_avg_sq': tensor([7.7877e-13, 8.5993e-13, 6.9060e-13, 2.0755e-12, 5.2246e-13, 5.4108e-13,\n            5.5003e-13, 4.1981e-13, 8.3026e-13, 6.1805e-13, 4.9713e-13, 6.7285e-13,\n            3.2573e-13, 7.3744e-13, 6.7504e-13, 7.2681e-13, 2.0681e-12, 8.3963e-13,\n            1.0144e-12, 4.6334e-13, 9.8163e-13, 8.3696e-13, 4.5358e-13, 6.9059e-13,\n            7.0415e-13, 9.8080e-13, 4.2937e-13, 7.4379e-13, 8.2007e-13, 8.0345e-13,\n            8.9248e-13, 8.0736e-13, 5.4589e-13, 1.0201e-12, 9.9001e-13, 4.7114e-13,\n            6.1134e-13, 5.0301e-13, 3.8816e-13, 9.8351e-13, 6.4801e-13, 9.1899e-13,\n            5.3141e-13, 5.2875e-13, 5.9158e-13, 8.2363e-13, 5.4685e-13, 6.8151e-13,\n            3.2833e-13, 4.0178e-13, 6.8363e-13, 4.2658e-13, 7.8718e-13, 5.0085e-13,\n            8.4860e-13, 4.3364e-13, 4.0578e-13, 4.6412e-13, 1.2222e-12, 4.6018e-13,\n            3.2049e-13, 7.6195e-13, 5.8108e-13, 5.4389e-13, 6.6486e-13, 9.8336e-13,\n            4.8815e-13, 6.4587e-13, 5.6015e-13, 9.9953e-13, 5.3518e-13, 4.9100e-13,\n            4.4787e-13, 7.8126e-13, 4.6461e-13, 2.7211e-13, 9.8648e-13, 6.1939e-13,\n            7.3239e-13, 4.6546e-13, 1.0879e-12, 5.0399e-13, 5.2991e-13, 8.7442e-13,\n            6.0821e-13, 6.7667e-13, 8.1462e-13, 4.1627e-13, 7.4328e-13, 4.4326e-13,\n            5.1689e-13, 7.0882e-13, 7.2413e-13, 7.8772e-13, 6.1601e-13, 1.0364e-12,\n            7.3706e-13, 5.8224e-13, 4.9759e-13, 4.8941e-13, 5.3353e-13, 3.5734e-13,\n            2.6889e-13, 5.0412e-13, 9.0488e-13, 7.4089e-13, 5.4497e-13, 6.3755e-13,\n            5.3488e-13, 5.4374e-13, 1.8950e-12, 3.6936e-13, 8.2122e-13, 5.0192e-13,\n            5.9455e-13, 5.1031e-13, 5.6642e-13, 7.3878e-13, 1.2273e-12, 4.7492e-13,\n            5.3409e-13, 3.5951e-13, 5.5873e-13, 5.3123e-13, 3.7841e-13, 6.2671e-13,\n            4.9472e-13, 5.3417e-13, 8.7240e-13, 8.0435e-13, 8.5844e-13, 7.5277e-13,\n            3.4661e-13, 7.0159e-13, 3.7235e-13, 6.5066e-13, 3.2457e-13, 3.5875e-13,\n            8.7078e-13, 5.0789e-13, 8.0699e-13, 6.4916e-13, 4.3013e-13, 4.2242e-13,\n            6.5962e-13, 7.8784e-13, 3.3442e-13, 1.0311e-12, 5.5652e-13, 1.2718e-12,\n            3.2893e-13, 4.7934e-13, 5.3572e-13, 3.7818e-13, 6.0462e-13, 7.1053e-13,\n            4.5572e-13, 5.5874e-13, 7.9915e-13, 5.2273e-13, 7.9952e-13, 6.1546e-13,\n            4.8155e-13, 4.8586e-13, 3.9922e-13, 5.5814e-13, 7.9663e-13, 2.0334e-13,\n            5.8419e-13, 1.0366e-12, 5.5983e-13, 5.0640e-13, 9.7086e-13, 1.3415e-12,\n            4.2275e-13, 4.2753e-13, 5.0815e-13, 5.7101e-13, 6.1382e-13, 6.5532e-13,\n            7.6160e-13, 1.1241e-12, 5.1047e-13, 9.3750e-13, 2.8553e-13, 4.7503e-13,\n            7.7288e-13, 2.7814e-13, 5.3591e-13, 3.4552e-13, 9.0419e-13, 5.4338e-13,\n            4.9902e-13, 6.0805e-13, 3.7539e-13, 4.0115e-13, 6.2118e-13, 1.0075e-12,\n            4.2987e-13, 1.0415e-12, 4.7789e-13, 8.9088e-13, 6.7024e-13, 6.5496e-13,\n            1.0683e-12, 6.9296e-13, 5.7819e-13, 6.5764e-13, 7.4615e-13, 6.8304e-13,\n            7.4611e-13, 7.9080e-13, 8.9772e-13, 9.4576e-13, 6.3018e-13, 7.6323e-13,\n            4.9421e-13, 6.1199e-13, 5.7346e-13, 3.1313e-13, 3.2322e-13, 4.3460e-13,\n            5.4343e-13, 3.7771e-13, 1.0697e-12, 5.3189e-13, 9.9633e-13, 5.6417e-13,\n            5.9312e-13, 4.1712e-13, 5.4279e-13, 5.1701e-13, 4.5938e-13, 4.1406e-13,\n            3.5911e-13, 3.2325e-13, 1.0862e-12, 3.3014e-13, 1.0967e-12, 8.8247e-13,\n            6.6132e-13, 6.9279e-13, 5.1978e-13, 4.6090e-13, 6.7882e-13, 6.0066e-13,\n            6.1679e-13, 8.8098e-13, 5.9032e-13, 1.3235e-12, 5.6595e-13, 5.9718e-13,\n            5.5734e-13, 6.8339e-13, 6.5880e-13, 6.8419e-13, 5.5518e-13, 7.8562e-13,\n            6.7472e-13, 5.9521e-13, 9.1191e-13, 7.0891e-13, 5.2654e-13, 5.6078e-13,\n            7.5537e-13, 7.7046e-13, 3.9386e-13, 6.1249e-13, 6.3718e-13, 6.9325e-13,\n            5.3298e-13, 4.8665e-13, 3.3552e-13, 6.8648e-13, 6.4224e-13, 6.7148e-13,\n            4.9879e-13, 6.4811e-13, 2.4932e-13, 1.7147e-13, 4.1149e-13, 4.6304e-13,\n            7.0842e-13, 1.0721e-12, 6.8751e-13, 2.7291e-13, 8.2994e-13, 8.0419e-13,\n            4.6264e-13, 4.5834e-13, 9.7238e-13, 7.0053e-13, 5.5687e-13, 8.0644e-13,\n            7.1402e-13, 6.3665e-13, 5.2387e-13, 6.5640e-13, 5.1819e-13, 6.1993e-13,\n            5.8882e-13, 9.4744e-13, 6.3025e-13, 6.5751e-13, 5.1682e-13, 7.5843e-13,\n            4.6690e-13, 4.7826e-13, 3.4585e-13, 8.8217e-13, 1.0790e-12, 8.8967e-13,\n            7.6694e-13, 4.2514e-13, 6.6012e-13, 4.5345e-13, 3.5909e-13, 6.8435e-13,\n            4.8049e-13, 7.5899e-13, 8.7911e-13, 7.1646e-13, 5.7146e-13, 8.6973e-13,\n            5.0246e-13, 7.1431e-13, 4.9925e-13, 5.9475e-13, 6.2631e-13, 1.4310e-12,\n            3.5821e-13, 6.5121e-13, 1.1050e-12, 3.8136e-13, 5.3737e-13, 8.4047e-13,\n            5.3158e-13, 1.0068e-12, 1.8636e-12, 7.5208e-13, 5.4011e-13, 7.0580e-13,\n            7.3934e-13, 8.3315e-13, 2.6311e-13, 6.3077e-13, 5.5012e-13, 5.3153e-13,\n            1.1258e-12, 4.6254e-13, 7.4037e-13, 6.1857e-13, 3.4773e-13, 8.5468e-13,\n            8.0885e-13, 1.3243e-12, 4.0734e-13, 8.8185e-13, 4.0239e-13, 2.9529e-13,\n            4.8537e-13, 7.1515e-13, 1.4111e-12, 5.6686e-13, 9.5986e-13, 4.7116e-13,\n            4.5851e-13, 5.0510e-13, 2.5587e-13, 9.9642e-13, 7.7616e-13, 7.6965e-13,\n            8.7949e-13, 4.4635e-13, 7.1421e-13, 3.7026e-13, 4.3954e-13, 1.0092e-12,\n            6.2734e-13, 5.5799e-13, 5.8464e-13, 2.4771e-13, 5.3640e-13, 5.0191e-13,\n            6.1010e-13, 6.2020e-13, 4.4207e-13, 3.6388e-13, 4.3845e-13, 9.3042e-13,\n            9.4561e-13, 8.3593e-13, 7.2583e-13, 5.9689e-13, 5.8228e-13, 4.4878e-13,\n            6.1111e-13, 2.1006e-13, 6.7232e-13, 2.9012e-13, 8.1025e-13, 6.1896e-13,\n            5.2373e-13, 1.0819e-12, 8.9423e-13, 5.3872e-13, 5.2998e-13, 7.2683e-13,\n            7.9095e-13, 7.8817e-13, 7.5306e-13, 5.1107e-13, 5.4497e-13, 4.5328e-13,\n            8.4547e-13, 3.3287e-13, 4.5035e-13, 4.5580e-13, 5.0385e-13, 7.3082e-13,\n            6.1044e-13, 5.1065e-13, 1.5439e-12, 8.6667e-13, 5.0286e-13, 5.9952e-13,\n            1.9288e-12, 5.3562e-13, 5.4061e-13, 3.5167e-13, 9.2842e-13, 6.3404e-13,\n            7.1628e-13, 7.8150e-13, 4.5138e-13, 4.7597e-13, 5.8951e-13, 6.7177e-13,\n            8.0910e-13, 8.9006e-13, 5.6431e-13, 6.1677e-13, 8.5028e-13, 8.7549e-13,\n            4.8692e-13, 6.7744e-13, 8.8047e-13, 4.8334e-13, 5.9969e-13, 8.3046e-13,\n            4.9643e-13, 5.4054e-13, 5.8852e-13, 6.2682e-13, 1.3325e-12, 5.6919e-13,\n            4.7593e-13, 7.7247e-13, 3.7626e-13, 6.9666e-13, 7.3084e-13, 6.9274e-13,\n            4.8682e-13, 7.6720e-13, 5.7143e-13, 9.4460e-13, 5.1732e-13, 1.0911e-12,\n            4.5092e-13, 5.5726e-13, 6.2178e-13, 6.5155e-13, 1.0571e-12, 4.7885e-13,\n            2.5849e-13, 4.5503e-13, 4.6475e-13, 8.7756e-13, 7.4025e-13, 7.8597e-13,\n            7.4763e-13, 8.5682e-13, 7.3949e-13, 9.1767e-13, 6.6519e-13, 1.4380e-12,\n            4.6090e-13, 6.1504e-13, 7.2041e-13, 9.8549e-13, 1.5448e-12, 8.4811e-13,\n            8.5087e-13, 8.5989e-13, 6.3327e-13, 7.0111e-13, 3.1710e-13, 8.3251e-13,\n            6.7405e-13, 4.0272e-13, 4.5346e-13, 2.5233e-13, 6.7266e-13, 8.7226e-13,\n            6.5206e-13, 5.1140e-13, 6.6653e-13, 6.4743e-13, 5.2493e-13, 6.3427e-13,\n            1.0823e-12, 5.4224e-13])},\n   28: {'exp_avg': tensor([-1.2331e-07,  7.6662e-08,  3.5108e-07, -1.7023e-07,  2.2265e-07,\n            -2.4663e-07,  1.6458e-07, -5.0483e-08, -6.9146e-08, -1.4248e-08,\n            -1.4860e-07,  7.2246e-08,  2.0886e-07, -1.0728e-07, -4.4590e-08,\n             5.2571e-08, -6.1699e-08, -1.2980e-07, -1.8680e-07,  4.8372e-07,\n             1.3303e-07,  4.2529e-08, -1.5937e-07, -1.7028e-07, -9.3708e-08,\n            -1.7368e-07, -8.1826e-08,  1.1578e-07, -7.0418e-08, -4.2134e-07,\n            -1.5498e-07,  3.1501e-07, -1.9341e-07, -2.3087e-07,  2.7560e-07,\n            -4.3068e-07, -8.5822e-08, -1.7740e-07, -4.7251e-07,  9.2103e-08,\n            -1.4252e-07,  3.5875e-07, -2.6285e-08, -9.4391e-08,  3.8400e-08,\n            -3.2298e-07, -1.2879e-07,  7.0321e-08, -1.9630e-08,  1.3325e-07,\n             2.2337e-07, -3.0936e-08,  1.5569e-07, -2.2734e-07, -8.3626e-08,\n             7.1553e-08, -1.6503e-07,  8.6443e-09,  6.6833e-08,  1.1846e-07,\n            -3.3475e-07,  7.5450e-08,  1.5486e-07, -1.2024e-08,  8.7525e-08,\n             2.3070e-07,  7.1992e-08,  2.3323e-07, -5.2125e-07,  3.4745e-07,\n             1.5740e-07, -4.8159e-07,  1.4728e-07, -2.3919e-08,  2.3595e-07,\n             2.4801e-07,  5.6519e-08,  1.0286e-07,  6.2015e-08,  8.2247e-08,\n             1.2016e-07, -4.7608e-08,  2.3161e-07, -7.4176e-07, -4.7793e-08,\n            -2.4959e-07, -1.3971e-07, -2.6193e-07,  3.0087e-08,  3.2421e-07,\n             1.7752e-07, -1.1212e-07,  3.4013e-08,  6.3770e-08,  1.7513e-07,\n            -7.5668e-08, -1.0880e-07,  1.6863e-07,  2.6841e-07, -1.4736e-07,\n            -8.2777e-08, -1.4088e-07,  5.1778e-08, -2.0651e-07,  3.4722e-09,\n             2.1127e-07, -1.0187e-07,  2.7400e-07, -4.5000e-07, -7.6472e-08,\n            -3.6256e-07,  6.0564e-08,  3.7561e-07,  2.6020e-08,  2.5631e-08,\n            -3.5524e-08,  1.8570e-08,  3.2572e-07, -1.5793e-07,  1.7581e-07,\n             3.4208e-09, -3.0562e-07, -2.4104e-08,  3.4706e-07,  1.9758e-07,\n            -5.7256e-08,  1.2658e-07, -9.5163e-08, -2.1832e-07,  2.2937e-08,\n             4.6072e-08,  4.8488e-09, -1.3567e-07,  1.6516e-07, -1.6746e-07,\n             2.5164e-07, -2.7631e-07,  1.1504e-07,  7.9036e-08,  6.9800e-08,\n            -5.6746e-08, -1.1987e-07, -1.1582e-07, -2.0849e-07, -1.1216e-07,\n            -2.0115e-07, -4.3536e-08, -1.3700e-07, -8.1283e-08, -6.4425e-09,\n             2.5787e-07, -1.1526e-07, -2.2261e-07, -4.8144e-08,  5.5788e-08,\n             2.2161e-08, -1.8013e-07,  1.4635e-07, -2.0969e-07, -7.7701e-09,\n            -2.0927e-08,  1.5440e-08, -4.1187e-07, -2.4734e-07,  1.1592e-07,\n            -1.1221e-07,  1.5748e-08, -1.8034e-07, -2.3032e-07,  1.3002e-07,\n             1.7882e-07,  2.0376e-07, -2.4772e-07,  2.3328e-07, -9.3947e-08,\n             3.4662e-07, -1.3626e-07, -1.3235e-07,  6.7678e-08,  2.0427e-08,\n             5.0521e-08,  3.6693e-08,  5.5146e-08,  4.0068e-07,  1.2087e-08,\n            -2.1520e-07, -3.9161e-07, -2.0392e-07,  2.4704e-07,  6.6584e-09,\n            -8.9015e-08, -1.5892e-07,  1.1477e-07,  5.4706e-07,  3.0429e-08,\n             2.7277e-07,  2.7759e-08, -6.0251e-08, -2.1937e-07,  4.5801e-08,\n             1.3778e-07,  6.2800e-07,  2.5738e-07, -2.3348e-08,  1.4249e-07,\n             3.6270e-07,  5.6235e-07, -6.3067e-08,  4.3733e-08,  1.3723e-07,\n            -3.2698e-07, -5.1518e-07,  6.0394e-08,  6.6627e-07, -7.9327e-08,\n            -2.2108e-07,  5.3117e-08, -1.0055e-07, -5.3806e-09, -4.8997e-08,\n            -4.0287e-08, -9.8973e-08, -2.7468e-07, -2.4106e-07, -3.2342e-07,\n             7.7618e-09, -4.3595e-07,  4.0062e-07,  1.0168e-07,  5.1545e-08,\n            -6.9367e-08, -2.8867e-07, -9.5416e-09, -8.7298e-08, -2.0497e-07,\n            -1.4526e-07, -2.1122e-07, -7.5128e-08, -1.9474e-07, -4.9928e-07,\n            -1.4440e-07, -1.5333e-07,  3.2048e-07,  2.9634e-07,  7.4435e-09,\n            -1.3196e-07, -7.2703e-08, -1.2678e-07, -7.4514e-08,  5.0421e-07,\n            -5.9265e-08, -1.2066e-09,  3.1965e-08,  2.5345e-07,  1.0904e-07,\n             1.1807e-07, -2.1159e-07,  3.0119e-07,  1.3206e-07,  1.0970e-07,\n             5.2833e-07,  3.9284e-07,  6.4648e-08,  2.8966e-07, -2.8997e-07,\n             5.5513e-07, -4.6494e-09, -1.6959e-07,  2.1311e-08,  3.9895e-07,\n             1.0074e-07,  2.0551e-08,  5.6264e-08, -3.8184e-07, -2.3393e-07,\n             2.2363e-07, -1.5308e-08, -9.0217e-08,  1.6790e-07,  1.4023e-07,\n             1.6264e-08,  3.4693e-08, -1.0627e-07, -2.7555e-07, -2.1934e-07,\n             2.5360e-08,  1.5155e-07, -4.1235e-07, -1.8238e-07,  5.8180e-08,\n            -8.0157e-08,  2.7221e-07, -2.3316e-08, -2.7475e-07, -1.2885e-07,\n            -1.9142e-07, -3.0368e-07, -1.7571e-07, -3.2924e-08,  3.3295e-07,\n             1.8929e-07,  2.7795e-07,  2.8639e-07,  5.8004e-07, -2.8548e-07,\n             1.5426e-07,  2.9599e-07,  1.2609e-07,  3.2074e-07,  3.7272e-07,\n            -6.3109e-07, -2.3392e-07,  9.0681e-08,  4.4935e-08, -2.1369e-08,\n            -1.7098e-07, -2.0625e-08,  2.2175e-07, -1.3343e-07, -1.0511e-07,\n            -9.5819e-08,  1.5908e-07, -1.6500e-07,  1.3137e-08, -1.3092e-07,\n             2.3707e-07, -3.5190e-07, -2.2078e-07,  1.0855e-07,  3.8345e-07,\n            -1.3848e-07, -2.2883e-08, -2.1388e-07,  1.1431e-08,  1.9834e-08,\n            -3.6991e-08,  3.5253e-08,  3.3639e-07, -6.0033e-08, -3.7501e-07,\n            -1.2046e-07, -4.2589e-08, -3.1657e-08,  9.4766e-08,  1.2664e-08,\n             1.3794e-08, -2.0708e-07,  1.1460e-07, -9.9911e-08, -8.4319e-08,\n            -1.7076e-07,  1.3665e-07, -8.3605e-09, -4.0029e-07,  7.7263e-08,\n             9.2221e-08,  3.7247e-07, -1.4840e-07, -1.2946e-07,  5.9661e-07,\n             1.9619e-07,  4.0884e-08, -4.9694e-07,  1.2444e-07,  1.8798e-07,\n             3.8913e-08,  1.2760e-07,  1.8287e-09, -7.1442e-08, -2.1015e-07,\n            -1.5505e-07,  3.5020e-07,  9.0807e-09, -3.8252e-07, -2.2691e-07,\n             8.3789e-08,  1.5676e-08, -1.5484e-07,  1.4940e-07,  1.2746e-07,\n             1.5336e-07,  4.5053e-08,  3.4344e-07, -2.4536e-07, -2.4367e-07,\n             4.4506e-08, -2.5278e-07,  2.4534e-07, -3.4043e-08,  1.2166e-09,\n             9.8532e-10,  9.3830e-08,  1.4822e-07, -1.7483e-07, -4.1062e-09,\n            -7.4363e-08, -9.4094e-08, -7.7049e-08, -2.7433e-07, -9.5137e-09,\n            -1.6519e-08, -2.7856e-09,  1.5438e-07, -9.1391e-07,  2.8235e-08,\n            -1.6868e-07, -5.0282e-09,  5.5239e-07, -2.9148e-07, -5.4454e-07,\n            -1.0871e-07, -7.9544e-08,  1.6161e-07,  1.0886e-07, -2.4569e-08,\n             4.1599e-09, -2.6388e-07, -1.7366e-07,  3.7170e-07,  2.6467e-07,\n             2.4885e-07,  2.1407e-07,  7.8045e-07, -1.7368e-07,  6.4213e-08,\n            -1.4034e-07,  1.4009e-08, -1.5026e-07,  1.2346e-07,  9.0670e-08,\n             3.9822e-08, -1.8256e-07, -7.6339e-08,  2.2617e-07,  4.7993e-08,\n            -1.0583e-07, -4.8146e-08, -1.6890e-07, -3.1360e-07,  1.0533e-07,\n             9.5464e-09,  5.2464e-08, -3.8039e-08,  3.8126e-07,  7.0593e-08,\n            -2.9335e-08, -2.6143e-07,  1.2417e-07, -2.1915e-07, -1.4008e-07,\n             9.1580e-08, -3.4765e-07, -7.7534e-08,  2.4237e-07, -3.5197e-07,\n            -1.3177e-07,  3.5185e-07,  7.4661e-08,  1.6244e-07, -1.7867e-07,\n             8.6137e-09,  2.9646e-07,  1.1883e-07,  4.0642e-08,  5.6451e-09,\n             2.0717e-07, -9.3422e-08, -2.2785e-07,  2.3105e-08,  1.4318e-07,\n            -2.2148e-07, -4.9720e-07,  4.1442e-07, -1.5979e-07, -1.9608e-07,\n             1.0106e-07, -2.3372e-07,  2.6265e-08, -2.5752e-07, -2.4261e-07,\n             5.6834e-08,  4.9965e-07, -9.1030e-08,  9.2526e-08, -1.5336e-08,\n            -3.9284e-07,  7.9611e-08,  6.0212e-08,  9.8276e-08,  1.4059e-07,\n            -1.3478e-07,  9.8594e-08,  3.3763e-07, -8.7873e-07, -3.2493e-07,\n            -2.2027e-07, -1.4025e-07, -7.2423e-08, -3.4643e-07, -1.1057e-07,\n            -6.7467e-08, -8.0229e-10, -1.7827e-07, -3.5514e-07,  8.0156e-08,\n             1.9361e-10, -2.0565e-07, -1.5199e-07,  1.6276e-07,  2.8101e-07,\n            -1.2775e-07,  1.0724e-07]),\n    'exp_avg_sq': tensor([7.3930e-13, 1.0886e-12, 9.7436e-13, 7.5708e-12, 5.8660e-13, 1.9039e-12,\n            1.0642e-12, 6.0808e-13, 1.9149e-12, 4.9348e-13, 4.7421e-13, 1.3618e-12,\n            5.0363e-13, 7.4909e-13, 1.0511e-12, 8.6863e-13, 3.1571e-12, 2.0533e-12,\n            2.3383e-12, 1.6102e-12, 1.4012e-12, 1.2061e-12, 7.2885e-13, 1.0708e-12,\n            1.3777e-12, 2.6270e-12, 7.6327e-13, 1.0102e-12, 9.2317e-13, 1.6264e-12,\n            1.3551e-12, 1.5720e-12, 1.1076e-12, 1.6953e-12, 1.1615e-12, 7.4901e-13,\n            6.8415e-13, 6.4810e-13, 9.0075e-13, 7.0365e-13, 1.8432e-12, 3.4287e-12,\n            8.8978e-13, 6.3460e-13, 4.7258e-13, 2.0264e-12, 6.6774e-13, 1.6857e-12,\n            4.8971e-13, 1.3083e-12, 9.0949e-13, 5.3867e-13, 1.0512e-12, 1.2406e-12,\n            1.3366e-12, 3.9126e-13, 8.2551e-13, 2.8304e-13, 9.8091e-13, 8.4953e-13,\n            6.6351e-13, 1.0955e-12, 6.8188e-13, 7.0113e-13, 7.4370e-13, 7.0338e-13,\n            3.6964e-13, 8.6794e-13, 9.4860e-13, 1.4811e-12, 3.9643e-13, 4.9523e-13,\n            6.8115e-13, 7.8802e-13, 8.8149e-13, 5.0135e-13, 7.1459e-13, 6.2419e-13,\n            1.2748e-12, 5.5661e-13, 1.3126e-12, 5.5367e-13, 4.2310e-13, 2.1103e-12,\n            6.2581e-13, 1.1804e-12, 9.9540e-13, 7.9868e-13, 1.2332e-12, 7.8908e-13,\n            1.0065e-12, 9.1940e-13, 1.1470e-12, 8.3694e-13, 5.5762e-13, 1.9955e-12,\n            7.7169e-13, 7.2771e-13, 1.0589e-12, 6.4158e-13, 8.8273e-13, 6.7872e-13,\n            5.6094e-13, 7.4591e-13, 1.3103e-12, 1.6966e-12, 1.1911e-12, 9.2176e-13,\n            9.4150e-13, 6.3767e-13, 3.7421e-12, 6.2198e-13, 9.4335e-13, 6.5970e-13,\n            4.3349e-13, 5.8475e-13, 9.9571e-13, 1.7580e-12, 1.7732e-12, 4.0913e-13,\n            7.9748e-13, 6.7412e-13, 4.8394e-13, 5.5352e-13, 6.1433e-13, 8.2634e-13,\n            6.4117e-13, 7.1136e-13, 1.9006e-12, 6.8110e-13, 9.4354e-13, 1.3674e-12,\n            6.8080e-13, 7.7017e-13, 4.0074e-13, 6.2513e-13, 5.7996e-13, 4.6479e-13,\n            1.4064e-12, 5.0960e-13, 1.5550e-12, 7.1195e-13, 2.9154e-13, 5.1588e-13,\n            6.5408e-13, 1.3127e-12, 4.6977e-13, 1.7778e-12, 1.1064e-12, 1.1923e-12,\n            4.7705e-13, 6.4223e-13, 6.8842e-13, 5.3835e-13, 1.1604e-12, 1.0266e-12,\n            4.4925e-13, 6.0302e-13, 1.3501e-12, 6.7967e-13, 1.0966e-12, 1.0868e-12,\n            9.0669e-13, 6.8666e-13, 6.5134e-13, 5.1497e-13, 6.4737e-13, 5.2297e-13,\n            9.8346e-13, 1.9228e-12, 5.2571e-13, 5.3094e-13, 1.3446e-12, 2.0926e-12,\n            9.6377e-13, 7.3927e-13, 5.9415e-13, 7.7764e-13, 9.2202e-13, 9.5083e-13,\n            9.3256e-13, 1.8835e-12, 7.4498e-13, 1.9833e-12, 9.1335e-13, 8.9736e-13,\n            1.5543e-12, 5.5416e-13, 4.8946e-13, 4.9028e-13, 1.8022e-12, 1.5032e-12,\n            3.5804e-13, 8.7080e-13, 5.9037e-13, 4.2676e-13, 9.8486e-13, 1.8598e-12,\n            4.7839e-13, 1.2834e-12, 3.6835e-13, 1.7659e-12, 8.0837e-13, 5.1208e-13,\n            1.8206e-12, 9.6166e-13, 1.1627e-12, 9.7371e-13, 9.1277e-13, 8.2116e-13,\n            1.5505e-12, 1.5121e-12, 8.5928e-13, 1.8484e-12, 7.7604e-13, 1.3996e-12,\n            3.4156e-13, 6.5137e-13, 7.3016e-13, 4.1904e-13, 4.9188e-13, 4.3998e-13,\n            8.3314e-13, 1.4421e-12, 2.6030e-12, 4.4500e-13, 8.4113e-13, 1.0915e-12,\n            9.0959e-13, 4.6792e-13, 5.0063e-13, 9.0974e-13, 3.1500e-13, 5.9183e-13,\n            3.0077e-13, 5.2298e-13, 8.3013e-13, 6.2711e-13, 2.4179e-12, 1.9501e-12,\n            8.1037e-13, 5.5395e-13, 6.7707e-13, 6.3909e-13, 1.7138e-12, 7.5749e-13,\n            5.6768e-13, 2.0583e-12, 9.8485e-13, 3.1502e-12, 6.6592e-13, 6.5605e-13,\n            4.9262e-13, 1.2805e-12, 8.4439e-13, 1.3211e-12, 3.3863e-13, 8.9989e-13,\n            6.6061e-13, 7.6840e-13, 1.9760e-12, 1.0026e-12, 5.8132e-13, 1.3713e-12,\n            1.0777e-12, 1.4142e-12, 7.6997e-13, 4.8751e-13, 6.7492e-13, 2.4500e-12,\n            8.5628e-13, 7.3767e-13, 7.3697e-13, 1.7623e-12, 9.0021e-13, 7.1752e-13,\n            4.4766e-13, 7.5090e-13, 1.0467e-12, 4.5257e-13, 5.8358e-13, 6.8620e-13,\n            5.6015e-13, 1.6741e-12, 7.7582e-13, 5.5333e-13, 1.1781e-12, 2.0465e-12,\n            3.2740e-13, 5.3882e-13, 8.4259e-13, 1.0301e-12, 1.1984e-12, 1.5853e-12,\n            8.3817e-13, 1.4004e-12, 6.3998e-13, 1.2720e-12, 5.6800e-13, 5.4374e-13,\n            4.6943e-13, 1.4396e-12, 5.1479e-13, 7.0731e-13, 7.5472e-13, 5.9979e-13,\n            1.4554e-12, 3.9970e-13, 9.1002e-13, 1.4780e-12, 1.1620e-12, 1.8869e-12,\n            1.0842e-12, 5.6843e-13, 7.0985e-13, 9.4569e-13, 5.3856e-13, 7.5540e-13,\n            5.5112e-13, 8.1931e-13, 1.0126e-12, 5.3658e-13, 5.6294e-13, 1.0085e-12,\n            7.1676e-13, 8.0291e-13, 3.4918e-13, 7.9079e-13, 4.5162e-13, 2.0739e-12,\n            4.5656e-13, 1.2671e-12, 2.7789e-12, 5.5695e-13, 6.7129e-13, 1.3425e-12,\n            7.3031e-13, 1.7687e-12, 1.9136e-12, 1.5685e-12, 4.3066e-13, 1.0681e-12,\n            8.5454e-13, 8.8616e-13, 4.3671e-13, 7.3262e-13, 1.1626e-12, 6.8212e-13,\n            1.3170e-12, 5.3199e-13, 1.1391e-12, 6.0774e-13, 4.0978e-13, 2.2013e-12,\n            1.1680e-12, 8.7784e-13, 1.1144e-12, 1.4084e-12, 8.7489e-13, 8.8617e-13,\n            5.1854e-13, 6.1481e-13, 1.8293e-12, 7.6136e-13, 1.8171e-12, 6.8426e-13,\n            4.8149e-13, 8.2918e-13, 5.5268e-13, 2.5238e-12, 8.9423e-13, 1.4394e-12,\n            1.5260e-12, 6.1560e-13, 1.3257e-12, 8.1009e-13, 5.7576e-13, 1.9420e-12,\n            5.0976e-13, 8.0880e-13, 1.0891e-12, 3.0535e-13, 8.4348e-13, 4.5810e-13,\n            7.2327e-13, 7.8850e-13, 6.4709e-13, 6.9238e-13, 4.5096e-13, 1.1041e-12,\n            9.4452e-13, 5.9328e-13, 9.1838e-13, 1.2540e-12, 4.4425e-13, 9.5424e-13,\n            1.1787e-12, 5.4440e-13, 1.0604e-12, 6.5810e-13, 1.5915e-12, 5.4595e-13,\n            6.7502e-13, 3.2086e-12, 1.9284e-12, 4.8807e-13, 5.0465e-13, 1.3432e-12,\n            1.2090e-12, 1.8635e-12, 1.0937e-12, 7.0750e-13, 8.6050e-13, 3.2748e-13,\n            5.8223e-13, 1.9161e-13, 4.8691e-13, 5.1198e-13, 9.9529e-13, 9.8232e-13,\n            8.1549e-13, 5.2385e-13, 2.3909e-12, 1.4435e-12, 8.9956e-13, 5.3388e-13,\n            1.8150e-12, 5.2409e-13, 7.2842e-13, 4.6182e-13, 1.1089e-12, 1.6535e-12,\n            1.2598e-12, 8.3442e-13, 9.7222e-13, 7.7086e-13, 1.2027e-12, 9.5227e-13,\n            1.0417e-12, 1.3227e-12, 4.6851e-13, 7.6480e-13, 9.2302e-13, 1.6957e-12,\n            7.0128e-13, 1.3541e-12, 1.1994e-12, 5.3676e-13, 7.8031e-13, 7.1242e-13,\n            5.9258e-13, 1.0425e-12, 4.2033e-13, 9.1332e-13, 4.3875e-12, 5.6085e-13,\n            6.6382e-13, 1.2443e-12, 3.6960e-13, 1.2122e-12, 1.2894e-12, 7.5801e-13,\n            4.5268e-13, 1.1299e-12, 1.0708e-12, 1.0381e-12, 8.8757e-13, 1.2154e-12,\n            6.8600e-13, 8.8346e-13, 5.7487e-13, 1.1474e-12, 1.7318e-12, 9.1928e-13,\n            6.7131e-13, 7.9128e-13, 4.6457e-13, 5.8423e-13, 6.8491e-13, 1.5366e-12,\n            1.4170e-12, 1.8259e-12, 9.2281e-13, 1.1159e-12, 9.9653e-13, 2.3900e-12,\n            4.7558e-13, 4.5757e-13, 1.2037e-12, 1.0713e-12, 9.8698e-13, 1.0355e-12,\n            1.1750e-12, 1.6072e-12, 9.2412e-13, 1.8544e-12, 4.3212e-13, 9.3209e-13,\n            8.1297e-13, 7.0710e-13, 1.0782e-12, 4.8678e-13, 4.6218e-13, 1.3891e-12,\n            1.3042e-12, 7.2078e-13, 9.6098e-13, 1.6216e-12, 9.5424e-13, 6.0152e-13,\n            1.4734e-12, 4.9839e-13])},\n   29: {'exp_avg': tensor([-2.5042e-07, -5.0125e-08,  9.0141e-08, -3.6941e-07,  1.6147e-07,\n            -3.2190e-07,  4.9386e-08, -2.4550e-07,  2.2177e-08,  9.6421e-08,\n            -5.2465e-08, -4.6125e-08,  2.4819e-07,  7.6804e-08,  1.0067e-07,\n            -1.8258e-07, -7.7005e-08, -2.6018e-07, -2.9895e-07,  1.6492e-07,\n             3.1429e-07,  2.4361e-07, -1.7716e-07, -1.4709e-07, -8.8981e-09,\n            -1.1877e-07, -2.2607e-08, -3.4473e-08, -2.3625e-07, -2.8570e-07,\n            -8.1292e-08,  2.3718e-07, -2.6681e-07, -8.8050e-08,  1.4080e-07,\n            -3.5246e-07,  2.8545e-08, -2.5365e-07, -1.8064e-07,  4.2581e-07,\n             1.9135e-07,  3.5951e-08,  4.7034e-08, -2.9763e-07, -5.2212e-08,\n            -9.4878e-08, -1.6461e-07, -3.2114e-08, -1.1499e-07,  1.4119e-07,\n             2.0129e-07,  1.4723e-07, -4.7543e-08, -7.1981e-08,  9.2683e-08,\n             3.5206e-08,  8.5244e-08, -3.0327e-08,  1.7257e-07, -7.5148e-08,\n            -2.3036e-07,  1.4738e-07,  1.8789e-07,  2.1200e-08, -6.6421e-08,\n            -4.7746e-08,  2.5497e-07, -9.1386e-08, -2.3056e-07,  1.1409e-07,\n             1.1613e-07, -3.5656e-07,  1.2361e-07,  1.3762e-07,  1.7054e-07,\n             2.3859e-07, -2.8080e-07,  5.6093e-08, -1.4343e-07,  2.1404e-07,\n            -6.1457e-08, -2.3157e-07, -1.4725e-08,  9.1458e-08,  2.4052e-08,\n            -5.5329e-07, -2.5602e-07, -7.6841e-08, -1.9489e-07,  1.9505e-07,\n            -7.7949e-08,  1.6197e-07, -1.7638e-07,  1.1647e-08, -2.5380e-08,\n            -8.4546e-08, -1.4143e-08,  1.7990e-07,  3.4913e-08, -9.6136e-08,\n            -7.4313e-08, -1.0204e-07, -3.9873e-08, -2.6366e-07, -2.5689e-07,\n            -3.7304e-09, -2.8484e-07,  1.7114e-07, -2.7098e-07, -1.2767e-07,\n            -3.2320e-07,  5.3882e-08,  2.8366e-07,  5.8482e-08, -2.0857e-07,\n             5.8353e-08,  2.2244e-08,  3.8509e-08, -3.4206e-08,  1.8571e-09,\n             7.8028e-10, -2.0912e-07,  1.8584e-07,  3.8103e-07,  1.4261e-07,\n            -2.4216e-07, -7.2456e-08,  1.0293e-07, -1.8679e-07, -5.7546e-08,\n            -8.8051e-09, -3.4194e-08, -1.9919e-07,  1.6745e-07, -1.3765e-07,\n             3.5780e-07, -1.4104e-07,  5.1986e-09,  2.2255e-07,  3.1773e-07,\n            -3.3967e-07, -1.7860e-07, -6.4185e-08, -1.0809e-07,  9.9215e-08,\n            -1.0037e-07, -6.9467e-08, -2.0726e-07, -2.2705e-07, -3.4473e-08,\n             1.9755e-07, -8.3857e-08, -4.8405e-08,  5.8217e-08, -9.3614e-08,\n            -4.4832e-07, -2.4434e-07,  7.8500e-08, -7.6601e-08, -6.0502e-08,\n            -2.3307e-07, -1.0808e-07, -3.0973e-07, -2.0627e-07,  6.0036e-08,\n            -3.0147e-08,  6.7928e-08, -1.0436e-07,  1.0057e-07,  1.4866e-07,\n             1.7462e-07,  2.4118e-07, -1.1284e-07,  4.2681e-07, -3.8042e-08,\n             1.7773e-07,  1.6666e-07, -4.6317e-08,  1.0303e-07, -1.1992e-07,\n             3.2191e-08, -3.5427e-07,  4.8580e-08, -1.5990e-07, -2.1558e-08,\n            -6.2352e-08, -3.3398e-07, -1.0520e-07,  3.4671e-07, -2.0281e-08,\n             1.3643e-07, -6.7862e-08,  1.6299e-07, -6.5584e-08, -5.3141e-08,\n             2.0620e-07,  6.1298e-09, -1.0674e-07, -2.4585e-07,  7.6394e-08,\n             2.0085e-07,  4.8189e-07,  5.0171e-08, -1.5649e-07,  1.6966e-07,\n             9.5274e-08,  3.6581e-07,  5.2202e-08,  3.4264e-07,  1.7536e-07,\n            -4.7982e-07, -4.1200e-07,  2.8931e-07,  3.7282e-07, -1.9893e-07,\n            -3.7300e-07, -8.8565e-08,  2.4244e-07,  3.1152e-08, -2.1554e-08,\n            -1.7116e-07, -3.3057e-08, -2.2068e-07,  4.8391e-08, -1.8265e-07,\n            -2.7906e-08, -5.7289e-07,  3.4676e-07, -1.5265e-08,  1.6181e-07,\n            -1.3021e-07, -1.8190e-07, -8.3591e-08,  8.2733e-08, -1.7532e-07,\n            -1.1290e-07, -5.3702e-08, -1.4530e-07, -9.6682e-08, -5.8527e-07,\n            -1.5295e-07, -1.5063e-07,  2.2363e-07,  1.6022e-07,  3.0230e-09,\n            -8.6845e-08, -3.2350e-08, -2.5696e-07,  6.7542e-08,  2.8243e-07,\n            -7.4429e-08, -2.8039e-07,  1.7437e-08,  3.2537e-07,  8.6976e-08,\n            -1.6076e-07, -2.3824e-07,  1.4317e-07,  2.0286e-07, -6.5167e-08,\n            -2.3501e-07,  1.6929e-08, -9.3931e-08,  3.6175e-07, -1.4568e-08,\n             3.5313e-07, -6.4089e-08,  5.8946e-08,  6.1059e-08,  3.0734e-08,\n            -2.8667e-08,  1.3995e-07,  7.7699e-08, -4.7251e-07, -2.6598e-07,\n             4.5583e-08, -1.0107e-07, -2.8330e-08,  4.9776e-08,  2.2216e-07,\n             9.0970e-08, -3.0448e-08,  1.4848e-07,  6.0701e-08, -1.6465e-07,\n             2.6095e-08, -2.8132e-07, -3.1493e-08, -3.3943e-07, -3.9542e-07,\n             2.6399e-08,  2.1396e-07, -5.1953e-08, -2.0341e-07,  6.7918e-08,\n            -3.9863e-07, -3.3153e-07,  8.3732e-09,  1.1998e-07,  2.6603e-07,\n             3.0577e-07, -1.6106e-07,  3.3417e-07,  1.2049e-07,  9.0182e-08,\n             9.0485e-08,  8.6921e-08,  2.1262e-07,  1.5643e-07, -2.6775e-08,\n            -5.9009e-07, -2.1659e-09, -7.2553e-09,  1.2911e-07,  3.5243e-08,\n            -1.3315e-07, -3.8851e-08,  8.9950e-08, -1.8282e-07,  2.3912e-08,\n             7.4616e-09,  2.7683e-07, -2.6211e-07,  6.0783e-08, -1.5893e-07,\n             2.9668e-07, -1.6600e-07,  4.1311e-08,  3.3738e-07,  3.9248e-07,\n            -5.5965e-08,  4.8690e-08, -1.4476e-07, -1.1029e-07, -2.3414e-09,\n             1.0728e-07, -3.8150e-09,  1.1638e-07,  2.5772e-08, -3.2235e-07,\n             9.0826e-08,  4.0023e-08,  1.2346e-07, -2.0533e-08, -2.1172e-08,\n            -1.5809e-08, -1.8727e-07,  1.9169e-07, -2.0834e-07, -1.3482e-07,\n            -1.7891e-07,  2.2261e-07, -9.0771e-09, -1.9411e-07,  7.2022e-08,\n             2.8554e-07,  1.8668e-07, -2.7318e-07, -2.2023e-07,  3.7661e-07,\n             2.7159e-07,  5.9451e-08, -3.7966e-07,  9.8297e-08,  2.1989e-07,\n             2.7933e-08, -2.2311e-08, -1.6398e-08,  4.4237e-08, -1.2999e-07,\n            -2.1396e-07,  1.4390e-07,  4.8003e-08, -4.8951e-07, -3.3339e-07,\n             7.6537e-08,  3.7355e-08, -5.2248e-07,  2.0216e-07,  1.8398e-08,\n            -6.6842e-08,  8.9623e-08,  1.5596e-07, -1.2824e-07, -1.0274e-07,\n            -4.7517e-07, -2.4007e-07,  3.9593e-11, -2.9526e-08,  1.3096e-07,\n             8.2681e-08, -1.0552e-07,  4.8811e-08, -6.5026e-08, -9.0440e-08,\n             1.2989e-07, -1.8817e-07,  3.6723e-08, -1.2129e-07, -8.7907e-08,\n            -1.5412e-07, -1.3953e-07,  4.7083e-08, -1.3702e-07,  9.1943e-08,\n            -9.7465e-08,  1.1287e-07,  3.7635e-07, -2.4175e-07, -2.7658e-07,\n             1.9697e-08, -1.0641e-07,  1.2291e-07,  1.9013e-07,  4.0833e-07,\n             4.8478e-09, -1.7839e-08, -1.0024e-07,  2.5823e-07, -1.6111e-08,\n             3.0477e-08,  1.0553e-07,  9.7129e-08,  9.3022e-08, -4.7138e-08,\n            -9.2177e-09, -3.3709e-08, -4.6940e-08,  4.2810e-08,  5.2001e-08,\n             9.1766e-08, -5.2283e-08, -2.1430e-07,  1.8953e-07,  9.1366e-09,\n            -2.2580e-07, -5.4246e-08,  1.8884e-07, -2.5339e-07,  1.4226e-07,\n             8.1099e-08,  6.3082e-08, -2.3594e-07, -7.3804e-08, -1.0346e-07,\n            -4.2378e-08, -2.1638e-07,  1.1492e-07, -2.7418e-07, -1.1090e-07,\n            -2.3882e-08, -1.9592e-07, -3.1281e-07, -6.7149e-08,  2.5273e-08,\n            -1.2867e-07,  3.1165e-07,  1.5237e-07,  2.6421e-08,  8.7956e-08,\n            -2.5895e-07,  1.1938e-07,  1.9600e-08, -6.3447e-08, -8.0992e-08,\n             4.4345e-07, -7.7466e-08, -4.6748e-08, -1.8563e-08,  7.9588e-08,\n             2.6279e-07, -2.6270e-07,  2.2040e-07, -3.0956e-08, -1.5297e-07,\n             2.3025e-07, -4.3782e-07, -1.6507e-07, -3.2697e-07, -2.3122e-07,\n             2.3977e-07,  2.8765e-07,  1.5059e-07, -5.6362e-08,  1.8473e-07,\n            -2.7171e-07, -2.0847e-08, -2.7128e-08,  2.0454e-07, -9.6860e-09,\n            -2.7855e-08, -6.9347e-08,  3.3525e-07, -4.1318e-07, -3.0546e-07,\n            -2.0478e-08, -1.0537e-07, -8.4917e-08, -3.4604e-07,  1.3951e-07,\n             9.9209e-08, -7.3638e-11, -5.1688e-08, -1.3443e-07,  1.0427e-08,\n             1.9041e-07,  4.0851e-08,  6.8975e-08, -2.0018e-07,  2.8252e-07,\n             3.5154e-08,  1.7175e-07]),\n    'exp_avg_sq': tensor([7.7877e-13, 8.5993e-13, 6.9060e-13, 2.0755e-12, 5.2246e-13, 5.4108e-13,\n            5.5003e-13, 4.1981e-13, 8.3026e-13, 6.1805e-13, 4.9713e-13, 6.7285e-13,\n            3.2573e-13, 7.3744e-13, 6.7504e-13, 7.2681e-13, 2.0681e-12, 8.3963e-13,\n            1.0144e-12, 4.6334e-13, 9.8163e-13, 8.3696e-13, 4.5358e-13, 6.9059e-13,\n            7.0415e-13, 9.8080e-13, 4.2937e-13, 7.4379e-13, 8.2007e-13, 8.0345e-13,\n            8.9248e-13, 8.0736e-13, 5.4589e-13, 1.0201e-12, 9.9001e-13, 4.7114e-13,\n            6.1134e-13, 5.0301e-13, 3.8816e-13, 9.8351e-13, 6.4801e-13, 9.1899e-13,\n            5.3141e-13, 5.2875e-13, 5.9158e-13, 8.2363e-13, 5.4685e-13, 6.8151e-13,\n            3.2833e-13, 4.0178e-13, 6.8363e-13, 4.2658e-13, 7.8718e-13, 5.0085e-13,\n            8.4860e-13, 4.3364e-13, 4.0578e-13, 4.6412e-13, 1.2222e-12, 4.6018e-13,\n            3.2049e-13, 7.6195e-13, 5.8108e-13, 5.4389e-13, 6.6486e-13, 9.8336e-13,\n            4.8815e-13, 6.4587e-13, 5.6015e-13, 9.9953e-13, 5.3518e-13, 4.9100e-13,\n            4.4787e-13, 7.8126e-13, 4.6461e-13, 2.7211e-13, 9.8648e-13, 6.1939e-13,\n            7.3239e-13, 4.6546e-13, 1.0879e-12, 5.0399e-13, 5.2991e-13, 8.7442e-13,\n            6.0821e-13, 6.7667e-13, 8.1462e-13, 4.1627e-13, 7.4328e-13, 4.4326e-13,\n            5.1689e-13, 7.0882e-13, 7.2413e-13, 7.8772e-13, 6.1601e-13, 1.0364e-12,\n            7.3706e-13, 5.8224e-13, 4.9759e-13, 4.8941e-13, 5.3353e-13, 3.5734e-13,\n            2.6889e-13, 5.0412e-13, 9.0488e-13, 7.4089e-13, 5.4497e-13, 6.3755e-13,\n            5.3488e-13, 5.4374e-13, 1.8950e-12, 3.6936e-13, 8.2122e-13, 5.0192e-13,\n            5.9455e-13, 5.1031e-13, 5.6642e-13, 7.3878e-13, 1.2273e-12, 4.7492e-13,\n            5.3409e-13, 3.5951e-13, 5.5873e-13, 5.3123e-13, 3.7841e-13, 6.2671e-13,\n            4.9472e-13, 5.3417e-13, 8.7240e-13, 8.0435e-13, 8.5844e-13, 7.5277e-13,\n            3.4661e-13, 7.0159e-13, 3.7235e-13, 6.5066e-13, 3.2457e-13, 3.5875e-13,\n            8.7078e-13, 5.0789e-13, 8.0699e-13, 6.4916e-13, 4.3013e-13, 4.2242e-13,\n            6.5962e-13, 7.8784e-13, 3.3442e-13, 1.0311e-12, 5.5652e-13, 1.2718e-12,\n            3.2893e-13, 4.7934e-13, 5.3572e-13, 3.7818e-13, 6.0462e-13, 7.1053e-13,\n            4.5572e-13, 5.5874e-13, 7.9915e-13, 5.2273e-13, 7.9952e-13, 6.1546e-13,\n            4.8155e-13, 4.8586e-13, 3.9922e-13, 5.5814e-13, 7.9663e-13, 2.0334e-13,\n            5.8419e-13, 1.0366e-12, 5.5983e-13, 5.0640e-13, 9.7086e-13, 1.3415e-12,\n            4.2275e-13, 4.2753e-13, 5.0815e-13, 5.7101e-13, 6.1382e-13, 6.5532e-13,\n            7.6160e-13, 1.1241e-12, 5.1047e-13, 9.3750e-13, 2.8553e-13, 4.7503e-13,\n            7.7288e-13, 2.7814e-13, 5.3591e-13, 3.4552e-13, 9.0419e-13, 5.4338e-13,\n            4.9902e-13, 6.0805e-13, 3.7539e-13, 4.0115e-13, 6.2118e-13, 1.0075e-12,\n            4.2987e-13, 1.0415e-12, 4.7789e-13, 8.9088e-13, 6.7024e-13, 6.5496e-13,\n            1.0683e-12, 6.9296e-13, 5.7819e-13, 6.5764e-13, 7.4615e-13, 6.8304e-13,\n            7.4611e-13, 7.9080e-13, 8.9772e-13, 9.4576e-13, 6.3018e-13, 7.6323e-13,\n            4.9421e-13, 6.1199e-13, 5.7346e-13, 3.1313e-13, 3.2322e-13, 4.3460e-13,\n            5.4343e-13, 3.7771e-13, 1.0697e-12, 5.3189e-13, 9.9633e-13, 5.6417e-13,\n            5.9312e-13, 4.1712e-13, 5.4279e-13, 5.1701e-13, 4.5938e-13, 4.1406e-13,\n            3.5911e-13, 3.2325e-13, 1.0862e-12, 3.3014e-13, 1.0967e-12, 8.8247e-13,\n            6.6132e-13, 6.9279e-13, 5.1978e-13, 4.6090e-13, 6.7882e-13, 6.0066e-13,\n            6.1679e-13, 8.8098e-13, 5.9032e-13, 1.3235e-12, 5.6595e-13, 5.9718e-13,\n            5.5734e-13, 6.8339e-13, 6.5880e-13, 6.8419e-13, 5.5518e-13, 7.8562e-13,\n            6.7472e-13, 5.9521e-13, 9.1191e-13, 7.0891e-13, 5.2654e-13, 5.6078e-13,\n            7.5537e-13, 7.7046e-13, 3.9386e-13, 6.1249e-13, 6.3718e-13, 6.9325e-13,\n            5.3298e-13, 4.8665e-13, 3.3552e-13, 6.8648e-13, 6.4224e-13, 6.7148e-13,\n            4.9879e-13, 6.4811e-13, 2.4932e-13, 1.7147e-13, 4.1149e-13, 4.6304e-13,\n            7.0842e-13, 1.0721e-12, 6.8751e-13, 2.7291e-13, 8.2994e-13, 8.0419e-13,\n            4.6264e-13, 4.5834e-13, 9.7238e-13, 7.0053e-13, 5.5687e-13, 8.0644e-13,\n            7.1402e-13, 6.3665e-13, 5.2387e-13, 6.5640e-13, 5.1819e-13, 6.1993e-13,\n            5.8882e-13, 9.4744e-13, 6.3025e-13, 6.5751e-13, 5.1682e-13, 7.5843e-13,\n            4.6690e-13, 4.7826e-13, 3.4585e-13, 8.8217e-13, 1.0790e-12, 8.8967e-13,\n            7.6694e-13, 4.2514e-13, 6.6012e-13, 4.5345e-13, 3.5909e-13, 6.8435e-13,\n            4.8049e-13, 7.5899e-13, 8.7911e-13, 7.1646e-13, 5.7146e-13, 8.6973e-13,\n            5.0246e-13, 7.1431e-13, 4.9925e-13, 5.9475e-13, 6.2631e-13, 1.4310e-12,\n            3.5821e-13, 6.5121e-13, 1.1050e-12, 3.8136e-13, 5.3737e-13, 8.4047e-13,\n            5.3158e-13, 1.0068e-12, 1.8636e-12, 7.5208e-13, 5.4011e-13, 7.0580e-13,\n            7.3934e-13, 8.3315e-13, 2.6311e-13, 6.3077e-13, 5.5012e-13, 5.3153e-13,\n            1.1258e-12, 4.6254e-13, 7.4037e-13, 6.1857e-13, 3.4773e-13, 8.5468e-13,\n            8.0885e-13, 1.3243e-12, 4.0734e-13, 8.8185e-13, 4.0239e-13, 2.9529e-13,\n            4.8537e-13, 7.1515e-13, 1.4111e-12, 5.6686e-13, 9.5986e-13, 4.7116e-13,\n            4.5851e-13, 5.0510e-13, 2.5587e-13, 9.9642e-13, 7.7616e-13, 7.6965e-13,\n            8.7949e-13, 4.4635e-13, 7.1421e-13, 3.7026e-13, 4.3954e-13, 1.0092e-12,\n            6.2734e-13, 5.5799e-13, 5.8464e-13, 2.4771e-13, 5.3640e-13, 5.0191e-13,\n            6.1010e-13, 6.2020e-13, 4.4207e-13, 3.6388e-13, 4.3845e-13, 9.3042e-13,\n            9.4561e-13, 8.3593e-13, 7.2583e-13, 5.9689e-13, 5.8228e-13, 4.4878e-13,\n            6.1111e-13, 2.1006e-13, 6.7232e-13, 2.9012e-13, 8.1025e-13, 6.1896e-13,\n            5.2373e-13, 1.0819e-12, 8.9423e-13, 5.3872e-13, 5.2998e-13, 7.2683e-13,\n            7.9095e-13, 7.8817e-13, 7.5306e-13, 5.1107e-13, 5.4497e-13, 4.5328e-13,\n            8.4547e-13, 3.3287e-13, 4.5035e-13, 4.5580e-13, 5.0385e-13, 7.3082e-13,\n            6.1044e-13, 5.1065e-13, 1.5439e-12, 8.6667e-13, 5.0286e-13, 5.9952e-13,\n            1.9288e-12, 5.3562e-13, 5.4061e-13, 3.5167e-13, 9.2842e-13, 6.3404e-13,\n            7.1628e-13, 7.8150e-13, 4.5138e-13, 4.7597e-13, 5.8951e-13, 6.7177e-13,\n            8.0910e-13, 8.9006e-13, 5.6431e-13, 6.1677e-13, 8.5028e-13, 8.7549e-13,\n            4.8692e-13, 6.7744e-13, 8.8047e-13, 4.8334e-13, 5.9969e-13, 8.3046e-13,\n            4.9643e-13, 5.4054e-13, 5.8852e-13, 6.2682e-13, 1.3325e-12, 5.6919e-13,\n            4.7593e-13, 7.7247e-13, 3.7626e-13, 6.9666e-13, 7.3084e-13, 6.9274e-13,\n            4.8682e-13, 7.6720e-13, 5.7143e-13, 9.4460e-13, 5.1732e-13, 1.0911e-12,\n            4.5092e-13, 5.5726e-13, 6.2178e-13, 6.5155e-13, 1.0571e-12, 4.7885e-13,\n            2.5849e-13, 4.5503e-13, 4.6475e-13, 8.7756e-13, 7.4025e-13, 7.8597e-13,\n            7.4763e-13, 8.5682e-13, 7.3949e-13, 9.1767e-13, 6.6519e-13, 1.4380e-12,\n            4.6090e-13, 6.1504e-13, 7.2041e-13, 9.8549e-13, 1.5448e-12, 8.4811e-13,\n            8.5087e-13, 8.5989e-13, 6.3327e-13, 7.0111e-13, 3.1710e-13, 8.3251e-13,\n            6.7405e-13, 4.0272e-13, 4.5346e-13, 2.5233e-13, 6.7266e-13, 8.7226e-13,\n            6.5206e-13, 5.1140e-13, 6.6653e-13, 6.4743e-13, 5.2493e-13, 6.3427e-13,\n            1.0823e-12, 5.4224e-13])},\n   30: {'exp_avg': tensor([ 9.4586e-08, -1.8281e-07, -9.3088e-08,  1.6586e-07, -1.1863e-08,\n            -6.7448e-08, -9.7910e-08,  1.2944e-07,  5.3210e-08,  1.7486e-07,\n             2.4369e-08,  4.0583e-08, -3.0987e-07,  1.1380e-09, -9.2632e-08,\n            -1.3780e-07, -3.0665e-07,  1.0146e-07,  3.1176e-07,  1.0237e-07,\n             2.3044e-08, -7.6179e-08,  2.9499e-07, -1.2424e-07,  8.8354e-08,\n             2.6539e-08, -1.8070e-07,  1.0433e-07, -6.4957e-08, -6.5537e-08,\n             1.1237e-07, -7.9390e-09,  4.7108e-08, -1.0860e-07, -2.6825e-07,\n            -2.6326e-07,  1.3956e-07,  1.6970e-08, -3.5826e-08,  1.1649e-08,\n             7.5406e-08, -1.0182e-07, -7.4558e-08, -1.1009e-07,  5.0055e-08,\n            -6.1699e-08, -2.6117e-07,  1.9596e-08, -3.2480e-08, -5.9476e-08,\n            -4.3633e-09,  1.8091e-07, -9.6448e-08,  1.1771e-07, -3.8045e-09,\n            -6.0458e-08,  3.2032e-07,  2.7329e-07, -2.6520e-08, -3.7072e-07,\n            -1.1593e-07, -3.7771e-08,  4.9729e-08,  4.5309e-08, -5.0887e-08,\n             4.5195e-08,  6.1133e-08, -1.3381e-07, -3.6643e-07, -1.3730e-07,\n            -9.4236e-08,  1.7745e-07,  3.7673e-10,  2.3533e-07,  2.1994e-07,\n            -4.0621e-08, -5.7453e-08,  6.4046e-08,  9.8339e-08,  4.8126e-08,\n             1.8578e-07, -6.2441e-09,  4.3177e-08, -4.6737e-08, -3.8117e-07,\n             5.4447e-08, -5.7113e-08,  2.2760e-07, -1.4062e-07, -6.8403e-08,\n             9.1854e-08,  5.1173e-08, -1.0726e-08,  5.1224e-08,  8.6052e-08,\n             2.3943e-08, -7.1541e-08, -2.5649e-08, -6.0650e-08, -2.4577e-07,\n             1.1160e-07,  2.6897e-07, -9.2458e-08,  2.1998e-07, -7.2857e-08,\n             6.6770e-08, -2.7108e-07,  7.7600e-08,  8.5226e-10, -1.5784e-07,\n             1.8787e-07,  9.4090e-08,  1.9694e-08,  1.0093e-07, -2.6560e-08,\n            -3.4977e-08, -8.6279e-08,  1.9132e-07,  8.8570e-08, -5.5906e-09,\n            -4.2061e-08, -1.9758e-08,  2.1728e-07, -2.1456e-08,  1.1954e-09,\n             5.3669e-09, -5.6096e-09,  1.0444e-07]),\n    'exp_avg_sq': tensor([2.5384e-13, 7.6980e-13, 2.4600e-13, 3.3294e-13, 4.2567e-13, 4.3395e-13,\n            3.5114e-13, 8.4114e-13, 4.2722e-13, 7.4489e-13, 2.1625e-13, 5.2662e-13,\n            3.9989e-13, 3.9602e-13, 2.2968e-13, 4.3367e-13, 4.2862e-13, 1.9605e-13,\n            4.6689e-13, 4.4537e-13, 3.1703e-13, 2.8305e-13, 4.5067e-13, 2.8254e-13,\n            3.0136e-13, 4.9808e-13, 9.6864e-13, 2.2368e-13, 3.1197e-13, 3.1846e-13,\n            9.1573e-13, 4.3498e-13, 4.1138e-13, 7.5878e-13, 3.0805e-13, 4.2566e-13,\n            1.0827e-12, 4.4214e-13, 4.4786e-13, 5.9227e-13, 1.7089e-13, 4.9805e-13,\n            5.4926e-13, 3.1440e-13, 3.1346e-13, 4.5912e-13, 3.1944e-13, 4.7659e-13,\n            4.5008e-13, 2.5107e-13, 4.4391e-13, 4.9078e-13, 2.9656e-13, 3.3576e-13,\n            3.3286e-13, 2.6992e-13, 5.9228e-13, 4.3379e-13, 2.6367e-13, 7.0643e-13,\n            7.9195e-13, 1.4639e-13, 1.9992e-13, 3.0461e-13, 3.9091e-13, 2.9967e-13,\n            2.3969e-13, 4.2413e-13, 3.7103e-13, 4.9615e-13, 2.4049e-13, 4.0011e-13,\n            3.5368e-13, 5.8306e-13, 9.1048e-13, 2.1515e-13, 3.8710e-13, 4.4352e-13,\n            2.8585e-13, 2.2502e-13, 4.5328e-13, 2.3079e-13, 2.4928e-13, 4.2757e-13,\n            4.7236e-13, 2.9874e-13, 8.2535e-13, 4.3816e-13, 5.4239e-13, 2.4867e-13,\n            5.6542e-13, 2.9998e-13, 4.8553e-13, 1.2634e-12, 3.3949e-13, 4.6532e-13,\n            4.1296e-13, 3.7413e-13, 6.1596e-13, 4.9413e-13, 8.6038e-13, 3.1940e-13,\n            3.2790e-13, 4.8152e-13, 3.8535e-13, 3.1938e-13, 7.4142e-13, 6.3013e-13,\n            4.1172e-13, 5.5321e-13, 3.4836e-13, 4.5260e-13, 2.5530e-13, 4.3947e-13,\n            2.7241e-13, 3.9011e-13, 4.7406e-13, 3.1744e-13, 6.8030e-13, 4.5917e-13,\n            3.0237e-13, 2.1061e-13, 7.2605e-13, 2.6494e-13, 1.9686e-13, 5.2388e-13,\n            1.8423e-13, 2.1331e-13])},\n   31: {'exp_avg': tensor([-1.1581e-07, -1.1001e-07, -1.9088e-07,  2.4807e-07,  5.0029e-09,\n            -1.1432e-07, -9.5867e-08,  1.5649e-07,  2.1807e-07,  1.0905e-07,\n             3.1711e-08,  5.3508e-08, -1.9040e-07,  3.3617e-08, -1.3480e-07,\n             4.6779e-08, -2.3908e-07,  1.0872e-07,  2.5764e-07,  8.1243e-08,\n             1.7321e-07, -2.6274e-07,  1.4521e-07, -2.0215e-07, -1.0203e-07,\n            -7.8906e-08, -3.4691e-07,  8.2024e-08, -1.9225e-07, -1.8159e-08,\n             5.9977e-08,  7.8719e-08, -1.3419e-07,  4.0793e-08, -2.9342e-07,\n            -1.5289e-07,  6.3613e-08,  2.2617e-08, -9.1823e-08, -2.5591e-08,\n            -7.2061e-08, -1.6790e-07, -9.6497e-08, -6.2293e-08,  3.0637e-08,\n            -5.2152e-08, -3.6256e-07, -1.4142e-08, -2.1939e-07, -2.9233e-07,\n            -1.1528e-07,  2.2714e-07,  2.9023e-08, -2.0557e-08, -8.5610e-09,\n            -1.7096e-08,  1.2750e-07,  3.0978e-07, -1.3247e-07, -3.0673e-07,\n            -5.7000e-08, -3.2524e-08,  1.9396e-07,  5.9897e-08, -9.6325e-08,\n            -4.7348e-08, -1.5805e-08, -7.3653e-08, -3.2500e-07,  9.3319e-09,\n            -8.9128e-08,  1.1301e-07,  2.5684e-08,  1.4436e-07,  1.5739e-07,\n             5.6704e-08, -4.0840e-08, -1.4779e-07,  5.5348e-08,  1.1078e-08,\n             7.6021e-08, -1.2217e-07,  1.5561e-07,  6.8800e-08, -4.2727e-07,\n             1.4319e-07, -1.7226e-07, -4.4173e-09, -2.7141e-08, -3.3599e-08,\n             5.0064e-08,  1.6598e-07,  6.8826e-08,  2.5439e-08, -5.8177e-09,\n             8.2082e-10,  8.2679e-08, -1.1801e-07,  1.8127e-08, -2.1366e-07,\n            -4.1379e-09,  6.8738e-08, -9.2961e-08,  1.2405e-07, -7.8941e-08,\n             1.5725e-07, -1.4913e-07,  1.7512e-08, -1.9324e-08, -1.6498e-07,\n             7.8663e-08,  7.3726e-08, -6.1018e-08, -6.4229e-08,  1.0488e-07,\n            -1.4563e-07, -2.4563e-07,  1.3390e-07, -6.2392e-08,  6.9837e-08,\n             7.8361e-08,  9.1687e-08,  1.3291e-07,  4.0027e-08, -3.1513e-08,\n            -1.7842e-08,  1.1868e-07,  2.3978e-08]),\n    'exp_avg_sq': tensor([3.6244e-13, 4.0003e-13, 3.1475e-13, 3.5847e-13, 3.4920e-13, 4.2167e-13,\n            2.6669e-13, 6.1523e-13, 4.5458e-13, 5.5485e-13, 2.4463e-13, 3.7384e-13,\n            3.2410e-13, 2.9178e-13, 5.2429e-13, 3.9315e-13, 3.7268e-13, 2.8172e-13,\n            2.9825e-13, 4.8454e-13, 4.7739e-13, 2.9358e-13, 4.7832e-13, 3.6679e-13,\n            3.1005e-13, 5.1290e-13, 5.9941e-13, 2.7488e-13, 2.7871e-13, 3.0687e-13,\n            4.5594e-13, 3.2951e-13, 3.1144e-13, 5.2944e-13, 3.1349e-13, 3.9179e-13,\n            5.0676e-13, 2.9827e-13, 3.9196e-13, 3.9761e-13, 2.4037e-13, 3.2541e-13,\n            4.4742e-13, 3.6612e-13, 2.4760e-13, 3.2935e-13, 4.7379e-13, 4.2717e-13,\n            3.3606e-13, 3.2608e-13, 2.7101e-13, 5.5912e-13, 3.3712e-13, 3.0767e-13,\n            3.4399e-13, 2.1143e-13, 3.7246e-13, 4.3028e-13, 2.4126e-13, 4.4366e-13,\n            3.2894e-13, 2.1234e-13, 3.6737e-13, 2.8478e-13, 2.7822e-13, 3.9153e-13,\n            3.4124e-13, 2.9797e-13, 3.0241e-13, 2.4783e-13, 5.0177e-13, 3.8177e-13,\n            2.9971e-13, 4.2954e-13, 6.1761e-13, 1.7146e-13, 3.2736e-13, 3.4734e-13,\n            4.0153e-13, 2.9894e-13, 3.8067e-13, 2.6006e-13, 3.2850e-13, 3.6242e-13,\n            3.6342e-13, 3.8591e-13, 5.7222e-13, 3.4254e-13, 4.4000e-13, 3.7117e-13,\n            4.1840e-13, 2.9940e-13, 3.1363e-13, 6.0338e-13, 2.5485e-13, 3.1649e-13,\n            4.4382e-13, 7.1041e-13, 3.7693e-13, 4.8739e-13, 4.6177e-13, 3.8968e-13,\n            2.5137e-13, 4.0399e-13, 3.1368e-13, 5.7772e-13, 5.2925e-13, 5.0574e-13,\n            3.1170e-13, 3.3357e-13, 3.4629e-13, 3.9140e-13, 3.9704e-13, 4.0447e-13,\n            3.2738e-13, 3.0250e-13, 3.5647e-13, 4.1293e-13, 4.7401e-13, 3.6072e-13,\n            2.1751e-13, 4.4548e-13, 4.0984e-13, 2.9883e-13, 2.1999e-13, 3.1506e-13,\n            3.9205e-13, 2.3731e-13])},\n   32: {'exp_avg': tensor([ 1.6298e-07,  1.5981e-07, -8.0702e-08, -6.7491e-08,  1.1236e-07,\n            -1.2035e-07, -2.0145e-07, -2.6699e-07,  1.5501e-07, -1.2614e-07,\n             1.7852e-07, -1.6782e-08, -1.2711e-07,  1.4198e-07,  1.7865e-07,\n            -4.6383e-08,  1.4381e-07, -4.0873e-08, -3.3436e-08,  1.3044e-07,\n            -2.2268e-07, -1.4012e-08, -2.6767e-07, -7.8331e-08, -5.9391e-09,\n             3.3025e-07,  5.7578e-08, -9.8311e-08, -2.5543e-07, -6.4098e-08,\n             6.6837e-08, -2.2332e-07, -2.5940e-07, -8.7181e-08,  5.1462e-08,\n             1.1432e-07, -7.1508e-08, -1.7291e-07,  2.6788e-08, -7.4745e-08,\n             6.3454e-08,  6.1570e-08, -3.0639e-07,  2.2358e-07,  3.0857e-07,\n            -1.6796e-07, -1.9732e-07,  1.2912e-07,  9.7831e-08, -1.5355e-07,\n            -8.2614e-08, -1.7523e-07, -4.3541e-08,  2.0181e-07, -5.2035e-08,\n             3.1845e-08,  3.9202e-07,  3.0124e-07,  1.2683e-07, -3.8332e-08,\n             1.1226e-07,  6.0416e-08,  3.1727e-07,  3.3544e-07, -9.3752e-08,\n             2.3070e-07, -1.5072e-07, -1.8574e-07, -2.8414e-08,  3.6203e-08,\n            -4.7426e-08, -3.3373e-07, -1.7417e-07, -1.0635e-07, -1.0856e-07,\n            -1.6259e-08,  2.0559e-07,  2.6638e-07, -4.1561e-08, -4.8685e-08,\n             1.0850e-07,  2.3798e-07,  2.8967e-07,  1.4722e-07, -1.5695e-07,\n            -2.5626e-07, -5.5308e-08, -1.5576e-07,  2.7134e-07, -2.3073e-07,\n             9.4060e-08, -1.4227e-07, -3.0989e-07,  5.4870e-08,  1.9722e-08,\n             1.3444e-07,  2.9215e-08,  2.0311e-07,  3.5187e-08,  7.1731e-09,\n             3.3165e-07, -1.8442e-07,  2.3421e-08, -3.8796e-07, -1.5921e-07,\n             3.7800e-08,  1.2966e-07,  5.6621e-08,  2.5409e-08, -6.9078e-08,\n            -1.1654e-07,  8.8598e-08,  7.3931e-08, -3.5409e-07, -1.5228e-07,\n             1.4323e-08,  3.0838e-08, -6.8570e-08,  3.0712e-07, -7.2844e-08,\n            -3.2238e-07, -1.5946e-08,  1.0799e-07,  5.3187e-09, -9.2371e-08,\n             5.2333e-07, -1.6429e-08, -1.7137e-07]),\n    'exp_avg_sq': tensor([8.8620e-13, 3.6110e-13, 5.4821e-13, 3.5102e-13, 3.7943e-13, 6.8967e-13,\n            4.9349e-13, 6.4307e-13, 1.5113e-12, 3.8556e-13, 6.4225e-13, 4.5177e-13,\n            4.4569e-13, 4.1085e-13, 4.2702e-13, 9.3275e-13, 1.0190e-12, 6.3976e-13,\n            2.2300e-13, 6.1865e-13, 1.0609e-12, 6.3800e-13, 1.0453e-12, 1.0609e-12,\n            6.2419e-13, 1.7236e-12, 3.2990e-12, 9.7499e-13, 1.3547e-12, 9.5336e-13,\n            1.2398e-12, 5.5911e-13, 1.1029e-12, 9.7086e-13, 3.6492e-13, 6.2832e-13,\n            8.2424e-13, 4.7984e-13, 5.3730e-13, 3.9590e-13, 7.5416e-13, 9.8986e-13,\n            8.6559e-13, 3.3399e-13, 7.9942e-13, 1.4464e-12, 6.8260e-13, 5.6641e-13,\n            1.4745e-12, 5.0101e-13, 1.0273e-12, 5.1080e-13, 5.3008e-13, 4.5129e-13,\n            6.3308e-13, 6.1376e-13, 7.5581e-13, 4.0471e-13, 1.5193e-12, 9.0772e-13,\n            4.0229e-13, 4.1154e-13, 4.9919e-13, 1.1990e-12, 5.0171e-13, 4.6872e-13,\n            6.9307e-13, 5.3631e-13, 4.3051e-13, 3.0738e-13, 3.6133e-13, 4.4369e-13,\n            1.0869e-12, 5.0270e-13, 3.6071e-13, 5.6992e-13, 7.7288e-13, 8.0396e-13,\n            3.6908e-13, 1.4396e-12, 6.2507e-13, 7.3380e-13, 6.3555e-12, 7.8095e-13,\n            9.8336e-13, 6.5670e-13, 7.4954e-13, 4.2203e-13, 6.2940e-13, 3.6350e-13,\n            8.1365e-13, 5.8380e-13, 9.0787e-13, 1.1395e-12, 3.6628e-13, 6.3843e-13,\n            1.4055e-12, 1.0294e-12, 7.3639e-13, 3.8566e-13, 5.3924e-13, 6.3653e-13,\n            9.5677e-13, 8.2707e-13, 6.5774e-13, 4.2327e-13, 6.3579e-13, 6.0823e-13,\n            6.2411e-13, 3.0375e-13, 4.0268e-13, 4.2202e-13, 9.3950e-13, 4.0602e-13,\n            3.8640e-13, 4.3301e-13, 2.9407e-13, 5.6692e-13, 9.5545e-13, 6.3714e-13,\n            5.6624e-13, 1.0603e-12, 9.1915e-13, 6.2648e-13, 7.1062e-13, 2.2431e-12,\n            3.3514e-13, 4.6588e-13])},\n   33: {'exp_avg': tensor([ 2.6272e-07,  9.2569e-08,  2.1033e-07, -4.7561e-08, -7.3781e-08,\n            -2.3786e-09, -7.2707e-08, -1.5205e-07,  8.9639e-09, -1.0138e-07,\n             1.5534e-07,  5.1377e-08, -1.7016e-07,  2.7242e-08,  1.6760e-07,\n            -7.7240e-08,  2.1355e-09, -4.3821e-08,  3.3803e-09,  2.2116e-07,\n            -2.8588e-07, -1.4616e-07, -2.8178e-07, -2.9891e-08, -1.7424e-07,\n             3.4338e-07,  2.4673e-07, -1.7214e-07, -2.1270e-07,  8.6268e-08,\n            -2.4734e-08, -2.2821e-07, -1.6664e-07, -5.5460e-08, -5.9810e-08,\n            -1.3222e-07,  8.2742e-08, -1.2313e-07,  6.7628e-08, -7.7122e-08,\n             3.5323e-08, -1.1413e-08, -2.2844e-07,  4.8369e-08,  1.2221e-07,\n            -4.2884e-08, -1.1627e-07,  2.7372e-07,  5.1055e-08, -2.2899e-07,\n            -3.4784e-07,  2.8492e-09, -2.1578e-07,  2.1644e-07, -1.4219e-07,\n            -5.0562e-08,  3.7992e-07,  2.4094e-08,  1.5095e-07,  8.8038e-10,\n             9.8309e-08,  5.6613e-08,  2.2485e-07,  4.6173e-07, -2.7154e-08,\n             2.4179e-07, -1.1430e-07, -6.0282e-08, -7.0322e-08,  1.9849e-07,\n            -5.9331e-09, -4.7233e-08, -6.2416e-08, -1.4691e-08, -2.2124e-07,\n             1.7211e-07,  6.9800e-08,  3.1650e-07, -1.5264e-07, -1.7756e-07,\n             1.4317e-08,  2.5495e-07,  4.9792e-08, -3.9130e-09, -1.8091e-07,\n            -2.3660e-07, -1.1353e-09, -1.7696e-07,  1.6830e-07, -2.2303e-07,\n             1.4967e-07, -1.1096e-07, -2.3517e-07, -5.9333e-09, -1.1921e-07,\n             1.7141e-07, -1.9984e-07,  2.9611e-07, -1.6525e-07, -9.5537e-08,\n             1.6736e-07, -1.6729e-07, -1.9270e-07, -2.9639e-07,  1.0087e-08,\n             3.9146e-08,  1.1105e-07, -2.7619e-08,  4.9473e-08, -4.5615e-08,\n             8.1026e-08,  3.4973e-08,  6.0136e-08, -2.1581e-07, -2.3519e-07,\n            -1.0757e-07, -8.0370e-08, -3.3277e-08,  1.1309e-07, -2.8176e-07,\n            -2.3334e-07, -8.4058e-08,  5.7491e-08, -5.6508e-09, -1.5226e-07,\n             2.7914e-07,  1.8653e-08, -1.1389e-07]),\n    'exp_avg_sq': tensor([8.0211e-13, 2.9064e-13, 3.5244e-13, 2.5571e-13, 2.5640e-13, 4.5361e-13,\n            3.0004e-13, 3.6722e-13, 9.4359e-13, 2.5878e-13, 5.4267e-13, 3.6109e-13,\n            3.0067e-13, 2.5150e-13, 2.9411e-13, 5.9076e-13, 6.7471e-13, 4.0135e-13,\n            1.9379e-13, 4.3856e-13, 8.7345e-13, 3.2064e-13, 5.9819e-13, 7.2997e-13,\n            4.6661e-13, 1.6905e-12, 1.7700e-12, 5.3456e-13, 1.0242e-12, 5.0982e-13,\n            7.8063e-13, 3.6474e-13, 7.0183e-13, 5.2479e-13, 2.5379e-13, 3.5286e-13,\n            4.1945e-13, 3.2166e-13, 3.4939e-13, 2.8010e-13, 4.9229e-13, 6.7462e-13,\n            4.3382e-13, 2.9814e-13, 5.0806e-13, 8.6416e-13, 3.6705e-13, 3.6259e-13,\n            9.6171e-13, 3.4076e-13, 7.3245e-13, 3.3043e-13, 3.5213e-13, 3.2812e-13,\n            3.8623e-13, 3.8879e-13, 4.6624e-13, 2.5202e-13, 6.1525e-13, 6.2435e-13,\n            2.5691e-13, 3.2423e-13, 3.4750e-13, 9.6779e-13, 3.1150e-13, 3.7697e-13,\n            4.7284e-13, 3.5643e-13, 2.7560e-13, 2.4916e-13, 2.9381e-13, 2.7819e-13,\n            7.3801e-13, 3.0688e-13, 2.5390e-13, 4.1748e-13, 4.1089e-13, 6.5647e-13,\n            2.4699e-13, 6.5756e-13, 4.0848e-13, 5.2430e-13, 2.1628e-12, 5.1068e-13,\n            5.4811e-13, 4.1589e-13, 5.7695e-13, 3.7374e-13, 5.6794e-13, 2.9810e-13,\n            4.8470e-13, 3.8318e-13, 4.9125e-13, 6.3300e-13, 2.3124e-13, 3.9113e-13,\n            7.8470e-13, 6.2369e-13, 4.6002e-13, 2.4812e-13, 4.0405e-13, 3.3596e-13,\n            6.1525e-13, 6.2280e-13, 4.4863e-13, 3.4631e-13, 4.4176e-13, 4.1284e-13,\n            3.2301e-13, 2.4832e-13, 2.5235e-13, 2.9287e-13, 6.0672e-13, 3.2602e-13,\n            2.1774e-13, 4.2241e-13, 2.2320e-13, 3.4529e-13, 6.7592e-13, 4.9268e-13,\n            4.2893e-13, 6.4422e-13, 4.9224e-13, 3.7152e-13, 5.3546e-13, 1.2291e-12,\n            2.9275e-13, 2.7580e-13])},\n   34: {'exp_avg': tensor([ 5.2482e-08,  3.5377e-08, -8.7355e-07,  5.1506e-07,  3.2688e-07,\n            -3.0594e-07, -3.1952e-08,  1.5203e-07, -1.2511e-07, -8.2267e-08,\n             3.5692e-07,  3.5079e-07, -3.6731e-08,  2.4170e-07,  1.6534e-07,\n            -1.6525e-07, -2.6582e-07, -6.5735e-08,  5.2026e-07,  1.1080e-07,\n            -1.4417e-07,  6.2831e-07,  6.7647e-09,  3.2010e-07,  3.7341e-08,\n             4.4683e-07, -2.8527e-07, -1.0286e-07, -8.0199e-07, -3.0788e-07,\n             3.5411e-07,  3.1832e-07,  9.8988e-08, -3.0032e-07, -1.5751e-07,\n            -4.5726e-07, -1.9587e-07, -8.5803e-08,  3.4850e-07,  4.9252e-08,\n             3.8064e-07, -3.5818e-07,  4.9124e-07, -9.9888e-08, -1.2414e-07,\n             1.0000e-06,  3.1904e-10,  1.3312e-07, -1.6215e-07, -1.7867e-08,\n             4.5884e-07, -1.2216e-07,  2.1970e-07, -3.8172e-08,  3.2108e-07,\n            -2.3831e-07, -5.4070e-07,  2.0067e-07,  6.2831e-07,  2.0948e-07,\n             3.1164e-07, -3.6680e-07,  2.4597e-07, -4.2587e-08, -6.4192e-07,\n             5.5309e-07, -1.0151e-07, -3.1260e-08, -3.3301e-07, -1.2748e-07,\n             7.1887e-08, -7.1137e-08,  2.2730e-07, -7.9435e-08, -9.0660e-08,\n            -1.1603e-08, -4.9368e-07, -1.7907e-07,  2.0009e-07, -2.2773e-07,\n             2.5215e-07, -5.6944e-08,  1.9602e-07, -7.8300e-07, -2.0690e-07,\n            -2.2685e-07, -1.1069e-06,  2.6122e-08, -3.0209e-07,  7.3160e-07,\n            -3.3786e-08,  1.6708e-07,  5.6782e-07, -3.7320e-07,  5.5621e-07,\n            -3.5988e-07, -1.8074e-07, -1.9397e-07, -2.7658e-07, -1.8483e-07,\n            -7.1795e-08, -8.0281e-08, -2.2805e-07, -2.4750e-07, -6.6747e-08,\n             2.9657e-07, -4.6165e-08,  4.7675e-08, -4.4918e-07, -2.6720e-07,\n             1.6627e-07, -9.2123e-08, -1.5047e-07,  1.2222e-07,  1.0096e-07,\n             2.8925e-07,  7.4418e-08,  2.5895e-08,  1.2902e-07,  1.1636e-07,\n             4.1177e-08,  2.3822e-07,  3.8336e-07, -2.5239e-07, -5.5719e-08,\n             2.4435e-08,  2.1102e-07, -1.4095e-07,  3.2934e-07,  7.3281e-08,\n             3.4380e-08, -2.2487e-07,  2.8571e-07, -2.9289e-07, -6.2701e-09,\n            -1.5746e-07, -1.2057e-07, -1.9715e-07,  3.0619e-07,  1.4279e-07,\n             5.3630e-07, -3.8993e-07,  1.3179e-07,  4.3503e-07, -2.1124e-07,\n             2.7032e-08, -3.4877e-07,  2.2962e-07,  4.7832e-07,  3.0033e-07,\n             1.7176e-07,  2.3862e-07, -4.7877e-07,  1.0011e-07, -3.2423e-08,\n            -1.9781e-07,  1.0032e-07, -5.6723e-07, -1.1252e-07, -6.7436e-08,\n            -4.0716e-07, -1.9160e-07, -2.5666e-07, -2.2504e-07, -2.2272e-08,\n             1.4827e-08,  1.1563e-07, -1.4180e-07, -2.6179e-07, -2.8662e-07,\n            -4.7409e-08, -1.9852e-07,  3.5331e-07,  6.0573e-07, -4.3165e-07,\n             3.2198e-07, -1.4075e-07,  3.1345e-07,  4.7795e-08,  7.2953e-09,\n             1.3668e-07, -4.2031e-07,  5.9110e-08, -3.8420e-08, -1.4232e-08,\n            -1.4598e-07, -3.2684e-07, -1.1612e-07,  4.0217e-07,  2.7094e-07,\n             9.9030e-07, -2.0806e-07,  1.4588e-07, -4.4229e-07, -1.9127e-08,\n            -5.9881e-08, -8.8185e-08,  2.9459e-07,  5.1286e-08, -7.4081e-07,\n            -5.2931e-07, -2.1245e-07, -8.2474e-08, -9.8304e-08,  4.5677e-08,\n            -9.3184e-08,  4.2302e-07, -2.4686e-08, -3.8033e-07,  3.4432e-08,\n            -1.4738e-07, -2.8792e-07, -3.6174e-07,  3.7687e-07, -1.8437e-07,\n             1.0086e-06,  1.8760e-07,  2.7927e-07,  2.0439e-07, -2.1205e-07,\n             4.1407e-07,  4.2627e-08, -3.2866e-07, -2.6262e-07, -1.3927e-09,\n             3.5025e-07, -6.0277e-07,  1.3859e-07,  2.0355e-07,  3.2245e-08,\n            -1.7064e-07, -4.2924e-07, -1.5659e-07, -3.5519e-08,  1.0422e-07,\n             1.7537e-07, -6.3343e-08, -2.1840e-07, -2.3112e-07, -5.2568e-07,\n            -5.4424e-07,  5.8098e-07, -3.5074e-08,  7.7516e-07,  5.6806e-07,\n            -1.9813e-07, -7.5160e-07,  1.7626e-07,  1.4736e-07,  6.1069e-07,\n            -3.0771e-07,  2.5007e-08, -2.5043e-07,  1.4243e-07, -2.7279e-07,\n             1.7038e-07, -3.0577e-08,  3.1048e-07, -1.4542e-07,  1.5174e-07,\n            -7.4248e-07,  7.0579e-08,  5.6624e-08,  9.5211e-08,  1.6004e-07,\n            -4.7253e-07,  1.1580e-07, -3.7434e-07,  3.9784e-07, -3.1553e-07,\n            -5.8982e-08,  2.0548e-07,  2.4728e-07,  3.8164e-07, -4.8357e-07,\n             4.6130e-08,  1.3879e-07, -1.5240e-08,  9.0875e-08, -7.7096e-08,\n            -2.2275e-07,  2.0336e-07,  2.1857e-07, -1.8172e-08,  6.1120e-07,\n            -2.4471e-07, -2.0564e-09,  9.9862e-07,  1.7796e-07, -2.5810e-07,\n             3.8331e-07,  3.7260e-07, -6.9340e-08,  5.6777e-07,  1.5962e-07,\n             4.6640e-07,  4.0210e-07,  2.3201e-08, -5.7295e-09,  3.6021e-07,\n             2.0215e-07, -1.6128e-07,  1.6080e-07, -5.4160e-07,  5.5406e-08,\n            -1.5017e-08,  3.4510e-07, -1.8352e-07, -1.4520e-07,  8.9503e-08,\n             2.6117e-07, -2.5131e-07,  4.1670e-07,  8.8662e-08, -1.9708e-07,\n            -2.8664e-07,  1.4471e-07, -2.2552e-07,  3.1940e-07, -3.2566e-07,\n             4.9046e-07,  2.7822e-08,  2.1684e-07, -6.8726e-08, -2.5415e-07,\n            -7.5497e-07,  4.2096e-07, -6.9676e-08,  4.9950e-07,  5.5442e-07,\n            -1.4052e-07,  1.8590e-08, -6.4695e-07, -2.2979e-08, -3.5711e-07,\n            -4.7119e-07, -9.7803e-09,  6.4121e-10, -1.2189e-07, -2.2724e-07,\n            -2.5865e-07,  3.6580e-07, -3.5315e-07,  1.7559e-07, -2.5962e-07,\n             2.7869e-08,  2.9286e-07, -1.6188e-08,  3.6391e-07, -2.1321e-07,\n             1.1866e-07, -2.7597e-07, -4.5532e-07,  2.8673e-07,  5.3883e-08,\n            -1.8764e-07, -1.9091e-07, -2.1286e-07,  8.5294e-08,  1.6854e-07,\n            -1.5617e-07, -8.9163e-07, -7.9264e-08,  3.8774e-08, -1.0169e-07,\n             5.6529e-08,  4.7751e-07, -1.2470e-07,  3.6599e-07,  1.2378e-07,\n             3.9612e-07,  1.1882e-07,  1.0821e-07, -2.0303e-07,  5.8936e-07,\n            -2.2259e-08, -2.2584e-08,  2.4872e-07,  8.0304e-07,  6.0317e-08,\n            -3.1947e-07,  1.1707e-07, -1.0314e-08,  6.1783e-08,  2.5998e-08,\n            -7.6968e-08, -3.8347e-07, -3.2258e-08, -6.6976e-08, -3.1512e-07,\n            -8.6947e-08,  1.5464e-07, -4.1312e-07,  1.5633e-07, -7.1703e-07,\n             3.0221e-08,  1.8070e-07,  1.9494e-07,  4.6931e-07, -2.4149e-07,\n            -1.9809e-07, -1.5910e-08, -3.2263e-07, -5.6685e-07,  7.1655e-07,\n             2.7608e-07,  3.0794e-07, -2.8384e-08,  1.3182e-07, -5.6853e-08,\n            -4.6420e-07, -1.0501e-06, -2.0726e-07,  5.2707e-08, -4.1410e-07,\n             2.0425e-07, -2.0452e-07, -2.4312e-07,  9.9624e-08, -3.8305e-07,\n            -3.7458e-07, -4.1633e-08, -9.2133e-08,  1.6641e-08,  1.4819e-07,\n             1.3730e-07, -4.5605e-07,  3.9625e-07, -9.4450e-08, -3.6360e-07,\n             5.7726e-07,  2.4622e-07,  4.4591e-07, -3.5006e-08,  4.9841e-08,\n            -1.9436e-08,  3.3210e-08,  3.1383e-07, -1.2102e-07, -1.7016e-07,\n            -6.6211e-08,  2.1578e-07,  4.7570e-07, -3.2668e-07, -1.3630e-07,\n             1.8331e-08, -4.1157e-10, -1.3805e-07,  3.8616e-07, -4.2699e-07,\n             8.9351e-10,  1.6671e-07, -6.2449e-07,  1.8007e-07, -1.5993e-07,\n             1.2061e-07, -5.5715e-07, -4.2125e-08,  2.4333e-07,  2.2701e-07,\n            -2.2058e-07,  7.9265e-08, -5.2107e-07, -1.5981e-07,  6.2530e-07,\n             9.3746e-08,  1.7617e-07,  3.8137e-07, -3.4503e-07,  3.3959e-07,\n             1.1874e-07, -4.8070e-07, -2.0619e-07, -3.6708e-07, -4.8209e-07,\n             5.8744e-08,  2.2720e-09,  2.2449e-07,  2.3546e-08,  3.6380e-07,\n            -3.3735e-07, -2.7829e-07,  7.9062e-07, -2.0472e-07, -9.9150e-10,\n             6.9581e-07, -3.1181e-07,  3.0501e-07, -1.8750e-07, -1.0017e-07,\n            -7.0231e-07, -1.9278e-07,  1.0298e-07,  1.6273e-07,  1.0184e-08,\n            -4.2092e-07,  3.2201e-07, -2.2530e-07,  2.9125e-07,  1.0133e-07,\n            -3.0351e-07,  3.0765e-07, -3.3561e-07, -3.0075e-07,  3.3499e-07,\n            -7.9333e-08,  2.3808e-07,  8.2826e-08,  1.1901e-07,  5.7018e-08,\n            -8.7927e-08,  5.8180e-07]),\n    'exp_avg_sq': tensor([2.1930e-12, 1.6122e-12, 2.1156e-12, 6.8356e-12, 1.6053e-12, 1.1965e-12,\n            1.5054e-12, 1.4363e-12, 1.2551e-12, 2.3219e-12, 1.3692e-12, 2.3100e-12,\n            1.0707e-12, 2.3708e-12, 1.8221e-12, 3.9639e-12, 4.9207e-12, 2.7880e-12,\n            1.6430e-12, 1.4382e-12, 1.7620e-12, 2.7430e-12, 8.6459e-13, 2.2630e-12,\n            1.6684e-12, 3.0584e-12, 1.1610e-12, 2.3111e-12, 5.6114e-12, 3.7453e-12,\n            5.3321e-12, 4.0711e-12, 1.3404e-12, 3.4217e-12, 2.9420e-12, 2.7546e-12,\n            2.1172e-12, 1.0711e-12, 1.0055e-12, 3.5264e-12, 3.4616e-12, 3.6699e-12,\n            1.7493e-12, 1.5729e-12, 2.7362e-12, 4.0729e-12, 1.9896e-12, 2.2661e-12,\n            7.0023e-13, 3.1776e-13, 1.5549e-12, 1.3492e-12, 1.3347e-12, 4.9191e-13,\n            4.1602e-12, 1.0575e-12, 4.4103e-12, 1.3756e-12, 4.3982e-12, 1.3853e-12,\n            1.2896e-12, 3.1851e-12, 1.9501e-12, 1.0286e-12, 2.2593e-12, 1.6176e-12,\n            9.8185e-13, 1.1086e-12, 1.1904e-12, 4.0260e-12, 1.8465e-12, 1.3942e-12,\n            1.3406e-12, 1.7100e-12, 3.4224e-12, 2.1718e-13, 2.8034e-12, 1.6328e-12,\n            2.6823e-12, 3.9470e-12, 2.6270e-12, 9.0812e-13, 1.6519e-12, 3.8874e-12,\n            1.6436e-12, 1.4444e-12, 4.4783e-12, 3.3044e-13, 2.1320e-12, 5.7235e-12,\n            5.9745e-13, 2.0604e-12, 3.4821e-12, 3.2842e-12, 3.0269e-12, 2.9979e-12,\n            1.7753e-12, 2.0042e-12, 9.3281e-13, 4.5914e-12, 2.5370e-12, 4.7017e-13,\n            3.5855e-13, 1.3272e-12, 2.7111e-12, 2.9361e-12, 1.5409e-12, 1.4202e-12,\n            2.4659e-12, 7.4955e-13, 7.1637e-12, 3.4113e-13, 1.8497e-12, 1.6301e-12,\n            7.0947e-13, 1.9495e-12, 1.2885e-12, 4.2427e-13, 3.5623e-12, 2.6141e-12,\n            6.6755e-13, 1.5998e-12, 2.2227e-12, 1.2987e-12, 1.2245e-12, 2.2976e-12,\n            4.0677e-12, 1.6094e-12, 2.4937e-12, 2.7566e-12, 1.7134e-12, 1.6767e-12,\n            1.2061e-12, 2.3628e-12, 1.6706e-12, 2.8826e-12, 5.2200e-13, 1.2748e-12,\n            1.7455e-12, 1.8663e-12, 4.4921e-12, 2.2897e-12, 1.5607e-12, 1.2244e-12,\n            1.2274e-12, 1.5253e-12, 9.2539e-13, 3.2225e-12, 2.3280e-12, 3.8358e-12,\n            1.0565e-12, 1.0557e-12, 1.5894e-12, 4.0912e-13, 3.9242e-12, 4.6992e-12,\n            9.0808e-13, 1.6109e-12, 1.6097e-12, 7.6954e-13, 2.3675e-12, 1.3458e-12,\n            1.2336e-12, 1.2396e-12, 7.6143e-13, 2.2736e-12, 1.7108e-12, 4.4132e-13,\n            1.6961e-12, 2.2968e-12, 1.2084e-12, 1.7870e-12, 2.7305e-12, 3.7815e-12,\n            8.7652e-13, 1.2724e-12, 1.9116e-12, 1.5291e-12, 2.4396e-12, 5.2792e-13,\n            2.8464e-12, 4.4617e-12, 1.3000e-12, 1.7061e-12, 1.1446e-12, 1.7337e-12,\n            2.4917e-12, 2.1826e-13, 3.3550e-12, 6.9337e-13, 3.4103e-12, 4.5667e-12,\n            1.2181e-12, 2.0743e-12, 1.0979e-12, 1.5808e-12, 1.7411e-12, 2.2982e-12,\n            6.9554e-13, 3.5721e-12, 1.5212e-12, 1.8778e-12, 1.3419e-12, 1.2632e-12,\n            1.2680e-12, 1.4910e-12, 1.5037e-12, 1.5274e-12, 3.3067e-12, 1.4369e-12,\n            2.0759e-12, 3.8085e-12, 1.5431e-12, 2.4611e-12, 1.4007e-12, 3.1034e-12,\n            1.7267e-12, 2.1469e-12, 1.6305e-12, 1.3178e-12, 6.0731e-13, 8.5463e-13,\n            2.0642e-12, 1.0734e-12, 4.3680e-12, 1.0483e-12, 2.3885e-12, 9.7154e-13,\n            1.5537e-12, 1.4167e-12, 3.4448e-12, 8.3991e-13, 1.4706e-12, 1.2267e-12,\n            7.5029e-13, 1.0249e-12, 3.1768e-12, 8.6908e-13, 3.8833e-12, 6.5342e-12,\n            1.0663e-12, 2.5970e-12, 1.6521e-12, 4.6978e-12, 2.0316e-12, 2.7826e-12,\n            2.7978e-12, 1.9445e-12, 2.8992e-12, 4.8000e-12, 3.1115e-12, 1.8363e-12,\n            3.5912e-12, 2.2071e-12, 2.1302e-12, 2.9363e-12, 2.1198e-12, 1.3111e-12,\n            2.6318e-12, 1.0661e-12, 3.5850e-12, 1.8542e-12, 1.3100e-12, 1.8088e-12,\n            6.6336e-12, 2.2815e-12, 6.4039e-13, 2.2408e-12, 1.8732e-12, 2.5489e-12,\n            6.6193e-13, 1.6009e-12, 1.0609e-12, 3.4462e-12, 2.4449e-12, 3.7139e-12,\n            1.8996e-12, 2.4003e-12, 2.1415e-13, 6.2370e-13, 1.0156e-12, 2.1058e-12,\n            2.2345e-12, 1.4981e-12, 2.0330e-12, 7.7268e-13, 2.7453e-12, 3.6749e-12,\n            1.5396e-12, 1.5134e-12, 3.1119e-12, 1.2107e-12, 1.4176e-12, 4.5417e-12,\n            1.7902e-12, 3.3724e-12, 2.4037e-12, 3.3814e-12, 1.2382e-12, 2.7793e-12,\n            1.8959e-12, 2.0005e-12, 1.9037e-12, 3.5306e-12, 1.8959e-12, 8.5444e-13,\n            1.6340e-12, 1.5521e-12, 1.0904e-12, 2.2113e-12, 1.9188e-12, 2.5612e-12,\n            3.9038e-12, 7.6499e-13, 2.6690e-12, 2.7204e-12, 1.2202e-12, 1.5884e-12,\n            1.4614e-12, 2.3846e-12, 4.4018e-12, 2.4621e-12, 8.0111e-13, 2.5961e-12,\n            1.1808e-12, 1.8251e-12, 2.2355e-12, 1.0118e-12, 2.1657e-12, 4.9653e-12,\n            2.0457e-12, 1.3269e-12, 5.2771e-12, 1.0511e-12, 3.4024e-12, 1.1223e-12,\n            8.3672e-13, 2.2550e-12, 4.5554e-12, 3.4610e-12, 1.5678e-12, 1.4685e-12,\n            1.4903e-12, 2.7771e-12, 7.8641e-13, 1.6822e-12, 4.2549e-12, 1.7848e-12,\n            6.9523e-12, 1.4460e-12, 1.6188e-12, 1.2721e-12, 1.2414e-12, 2.0137e-12,\n            1.9661e-12, 2.1389e-12, 8.4255e-13, 4.2471e-12, 3.8206e-13, 1.9255e-13,\n            2.4303e-12, 3.0217e-12, 4.1211e-12, 1.3737e-12, 3.1388e-12, 8.8757e-13,\n            1.1105e-12, 9.4233e-13, 5.6167e-13, 3.3707e-12, 3.6218e-12, 1.2840e-12,\n            3.2650e-12, 7.2902e-13, 1.5231e-12, 7.7252e-13, 1.3998e-12, 8.9557e-12,\n            1.6197e-12, 8.2590e-13, 3.0137e-12, 4.8262e-13, 1.3062e-12, 1.1624e-12,\n            1.5890e-12, 2.6640e-12, 1.1777e-12, 8.1012e-13, 1.1854e-12, 2.1767e-12,\n            2.2748e-12, 1.3762e-12, 2.2182e-12, 1.3344e-12, 2.0580e-12, 6.7304e-13,\n            1.9717e-12, 6.4317e-13, 1.2133e-12, 6.8547e-13, 1.5779e-12, 2.4408e-12,\n            1.4293e-12, 7.0231e-12, 4.2447e-12, 1.6705e-12, 1.3397e-12, 1.0855e-12,\n            1.4314e-12, 1.0804e-12, 1.5965e-12, 4.6923e-12, 1.2769e-12, 1.3019e-12,\n            3.2751e-12, 8.3208e-13, 2.4391e-12, 1.0174e-12, 1.4385e-12, 2.9044e-12,\n            1.5069e-12, 7.8766e-13, 3.2064e-12, 2.0438e-12, 1.3430e-12, 7.5334e-13,\n            3.9286e-12, 1.3431e-12, 1.3627e-12, 7.1437e-13, 2.4231e-12, 1.4009e-12,\n            2.9986e-12, 3.9071e-12, 8.7287e-13, 1.3603e-12, 1.4173e-12, 1.8099e-12,\n            2.9927e-12, 1.4944e-12, 2.2032e-12, 1.6051e-12, 3.1970e-12, 1.6163e-12,\n            1.0502e-12, 6.8285e-13, 3.8757e-12, 9.0355e-13, 2.7737e-12, 2.0857e-12,\n            1.0927e-12, 1.4411e-12, 2.9843e-12, 1.9860e-12, 2.7026e-12, 8.0620e-13,\n            1.3165e-12, 1.9697e-12, 8.7502e-13, 1.3612e-12, 3.6247e-12, 1.7729e-12,\n            1.5888e-12, 1.8417e-12, 1.6978e-12, 3.6204e-12, 1.1710e-12, 3.5633e-12,\n            8.2970e-13, 1.0554e-12, 3.5972e-12, 1.2610e-12, 3.8015e-12, 1.3514e-12,\n            8.7067e-13, 1.2983e-12, 1.1246e-12, 1.7893e-12, 2.7684e-12, 5.0708e-12,\n            2.1034e-12, 2.5154e-12, 2.8002e-12, 4.8447e-12, 3.0927e-12, 2.2741e-12,\n            1.1216e-12, 2.0882e-12, 2.6345e-12, 4.0004e-12, 8.4972e-12, 3.0638e-12,\n            3.5889e-12, 2.8829e-12, 1.5395e-12, 1.8489e-12, 1.0293e-12, 1.7423e-12,\n            1.4967e-12, 1.0657e-12, 5.8535e-13, 3.8249e-13, 1.6119e-12, 1.1707e-12,\n            4.3224e-12, 2.5586e-12, 1.5143e-12, 3.1672e-12, 9.8506e-13, 1.8309e-12,\n            2.8538e-12, 1.8845e-12])},\n   35: {'exp_avg': tensor([-1.2143e-07,  2.1214e-07, -1.2854e-07, -3.1078e-07,  6.7389e-08,\n            -1.6777e-07,  3.9235e-08, -1.0692e-07, -1.1218e-07, -2.4548e-08,\n             2.2044e-08, -1.0888e-07,  1.5631e-07,  7.7705e-09,  1.8058e-07,\n            -1.2647e-07,  1.6521e-07, -1.7598e-07, -9.3472e-08,  1.0562e-07,\n             3.3779e-07,  5.7903e-08, -1.8997e-07, -7.3509e-08, -4.0250e-08,\n            -7.2465e-08, -6.2259e-08, -1.1715e-07,  1.2771e-08, -6.7060e-08,\n             6.0813e-08,  2.5734e-08, -2.1656e-07, -1.9336e-08, -1.1466e-07,\n            -2.0569e-08, -9.9813e-08,  7.3135e-08, -8.3442e-08,  2.9340e-07,\n             1.2625e-07, -2.4186e-08, -1.9174e-08, -4.7901e-08, -3.1561e-09,\n             4.4965e-08, -1.0945e-07, -1.0352e-07, -1.6599e-07,  5.7548e-08,\n            -3.3778e-08, -1.4092e-07, -5.9585e-08, -1.6000e-07,  1.4669e-07,\n             1.8133e-07,  6.2139e-08, -6.6556e-08,  5.0590e-08, -6.8838e-08,\n             6.6320e-08,  1.5019e-07,  2.0616e-07, -1.6179e-07,  1.9862e-07,\n            -2.6206e-08,  1.3467e-07, -1.1802e-07, -6.2400e-09,  1.9497e-07,\n             1.4329e-07, -2.2661e-07,  1.2853e-08, -6.4806e-08, -2.9269e-08,\n             1.2556e-07, -1.6194e-07,  5.3834e-08, -1.0025e-08,  1.4316e-07,\n             1.8209e-08, -2.5269e-07,  6.1902e-08,  1.6848e-07,  9.3393e-08,\n            -3.5319e-07,  3.2224e-08, -9.5522e-08,  1.5101e-07,  7.2908e-08,\n             1.5908e-08,  6.7773e-08, -7.4632e-08,  1.0709e-07, -1.3004e-07,\n            -9.5454e-08,  8.1867e-08,  1.6325e-07, -7.1326e-08,  5.0073e-08,\n            -2.2372e-07, -6.0858e-09, -6.4268e-08, -1.4090e-07, -2.2758e-07,\n             7.2416e-08, -8.7981e-08,  1.4118e-07, -3.2896e-08, -1.2415e-07,\n            -4.1959e-07,  1.5456e-08, -1.7014e-07,  6.8875e-08, -1.9418e-07,\n             9.7360e-08, -9.6069e-08,  1.3614e-08, -5.3140e-08, -1.1433e-07,\n            -4.6209e-09,  3.9427e-08,  2.1796e-07,  1.7767e-07,  5.5763e-08,\n            -1.4703e-07,  1.4342e-08,  1.8543e-07, -1.6782e-08, -3.5494e-08,\n            -1.0486e-07, -1.5199e-07, -8.3198e-08,  8.6408e-08, -1.1741e-07,\n             1.1106e-07, -1.1647e-07,  5.5880e-08,  1.2170e-07,  1.2065e-08,\n             1.5479e-07,  6.5771e-08, -1.2531e-07,  8.5525e-08,  2.8235e-08,\n            -9.4195e-08, -1.5245e-07, -1.7781e-07,  2.2792e-08, -1.0107e-07,\n             1.3760e-10, -6.4734e-08,  1.4750e-07,  1.3180e-07, -1.6000e-07,\n            -1.6069e-07, -2.4769e-07, -1.9517e-08,  2.4276e-08, -2.0221e-07,\n            -1.1932e-07, -2.3348e-07, -1.1429e-07, -6.2423e-08, -1.8865e-08,\n            -6.9615e-08,  2.0261e-08, -8.8080e-08,  6.0954e-08,  1.2968e-07,\n             9.8077e-08,  3.8987e-08, -1.0066e-07,  1.4512e-07, -4.0596e-08,\n             5.2855e-08, -2.8576e-08,  2.2810e-07, -5.0882e-08, -1.9201e-07,\n             1.0515e-07, -2.6277e-07,  5.8168e-08, -1.3585e-07,  8.4844e-08,\n            -2.3288e-07, -2.2075e-07, -1.7152e-07,  1.2076e-07,  1.9669e-07,\n             1.6216e-07, -6.8592e-08,  2.5076e-08, -7.2224e-08, -1.5684e-08,\n            -1.5875e-07,  7.9501e-08, -3.5435e-07, -2.6374e-07,  2.5519e-07,\n             2.6574e-08,  3.9125e-07, -1.6450e-07, -5.0726e-08,  1.5090e-07,\n            -3.1655e-08,  2.5520e-07, -5.9615e-08,  5.8103e-08, -5.9090e-08,\n            -4.2993e-07, -2.2969e-07,  1.1167e-07,  3.9273e-07, -2.1472e-07,\n             8.0637e-08,  1.6441e-07,  1.0423e-07, -1.4318e-07,  7.5456e-08,\n            -1.9316e-07,  5.9408e-08, -4.4073e-08,  1.8231e-07, -8.7371e-08,\n             1.1615e-10, -2.3921e-07,  3.2014e-07, -1.2740e-07,  1.3358e-07,\n            -1.1767e-07, -2.4511e-08, -8.4173e-08, -2.3180e-08, -6.1524e-08,\n            -4.6716e-08, -1.3130e-07,  8.9014e-08, -1.7862e-07, -2.2211e-07,\n            -1.3217e-07, -1.8597e-07,  1.3051e-07, -9.2419e-08, -1.5712e-07,\n            -1.2922e-08,  1.8694e-08, -1.4612e-07,  1.4087e-07,  1.4221e-07,\n            -8.3864e-08, -4.1297e-08,  8.6749e-08,  1.4262e-07,  2.1577e-07,\n             5.9770e-09, -1.2835e-08,  9.4524e-08,  8.7286e-08, -4.7970e-08,\n            -7.3085e-08,  5.7720e-08, -6.7848e-08,  8.1669e-08, -9.3388e-08,\n             8.8505e-08,  3.0078e-09,  7.9318e-09, -4.4873e-07,  8.9027e-09,\n             1.6027e-08,  2.9750e-07,  3.0482e-07, -2.4108e-07,  1.8258e-07,\n             6.8452e-08, -2.7080e-07,  9.0519e-08,  7.0507e-08,  1.5400e-07,\n            -2.6026e-08, -8.1344e-08, -5.7039e-08, -9.8680e-08, -2.0943e-07,\n             3.8348e-08, -1.5102e-07,  2.1032e-07, -2.5906e-07, -1.2616e-07,\n             4.4357e-08,  2.7407e-07, -4.8642e-08, -2.0873e-08,  2.7875e-08,\n            -2.7351e-07, -1.8336e-07, -1.2222e-07,  1.0017e-07,  3.8143e-08,\n             2.2811e-07, -3.7608e-08,  4.0364e-07,  1.3840e-07, -1.2377e-07,\n            -5.1869e-08, -1.0521e-07,  9.8158e-08,  2.4260e-09,  2.9089e-08,\n            -1.9486e-07,  3.4136e-08, -1.0280e-07,  2.0924e-08, -1.4133e-07,\n             1.6519e-08,  2.0271e-07,  4.1963e-11, -1.1499e-07,  8.2034e-08,\n             1.1768e-08,  2.5168e-07, -4.6190e-07,  2.1812e-07, -3.4691e-08,\n             4.7349e-07,  7.8119e-09, -3.2787e-08,  3.6664e-08,  1.3686e-07,\n             7.1554e-08,  1.5595e-07,  7.0118e-08, -1.4833e-08, -3.9824e-08,\n             4.1295e-08,  1.6764e-08, -4.2324e-08, -7.8506e-08,  5.4824e-08,\n             1.1836e-07, -8.0028e-09,  1.2371e-08, -1.3238e-07,  3.4621e-08,\n             1.9654e-08,  5.4586e-08,  2.2658e-07,  1.1110e-07, -3.1221e-07,\n            -7.6190e-08, -2.7623e-09, -2.2979e-07,  1.1153e-07, -7.0562e-08,\n             3.4636e-07,  1.0785e-07, -1.1113e-07, -1.3824e-07,  3.3332e-07,\n             1.1439e-07,  1.5829e-07, -2.2193e-07,  2.6785e-07,  4.1328e-08,\n             1.2363e-07,  3.1253e-08, -4.4824e-08,  1.7777e-07, -8.3972e-08,\n            -9.9524e-08,  1.6469e-07, -2.0332e-08, -4.7360e-07, -3.3438e-07,\n            -4.1974e-08,  1.0672e-07, -1.2425e-07, -1.5575e-07, -1.6275e-07,\n             4.3500e-08,  1.9434e-08,  9.2481e-08, -2.9118e-08,  8.3204e-08,\n            -2.5320e-07,  1.2341e-08,  7.7343e-08,  8.9372e-08,  3.6451e-07,\n             1.3747e-07, -1.4970e-07, -1.0898e-07, -1.3360e-07, -5.3922e-08,\n             2.5961e-08, -9.3339e-08, -6.4559e-08, -8.1114e-08, -1.5288e-07,\n             7.0291e-08, -1.0397e-07, -9.1806e-08, -1.9800e-07, -1.3112e-07,\n            -3.7664e-08, -2.1279e-08,  3.1113e-07, -2.1330e-07, -2.9609e-07,\n             1.2925e-09, -1.3865e-07, -1.8704e-07,  3.8081e-08, -3.6504e-08,\n             1.4567e-07, -5.9869e-08, -1.5702e-07,  1.6059e-07, -3.6134e-08,\n             3.8562e-08,  1.2943e-07, -9.1232e-08,  4.0835e-08,  2.3401e-08,\n             7.3880e-08, -1.5573e-07, -2.7325e-08,  3.8194e-08,  5.1864e-08,\n            -6.6010e-08,  6.1390e-09, -1.3026e-07,  9.1678e-08,  9.7533e-08,\n            -1.4596e-07, -5.8537e-08,  3.0485e-08,  2.6980e-08,  1.3837e-07,\n             1.0571e-07,  3.8969e-08, -1.2073e-07, -7.7410e-08, -1.5534e-07,\n            -3.6347e-08, -6.1888e-08,  1.3904e-07, -6.8561e-08,  4.7596e-08,\n             7.5752e-08, -1.5468e-07, -2.0477e-07,  1.5773e-07,  1.6347e-08,\n            -1.0482e-07,  1.5850e-07, -1.5645e-07, -4.6462e-08,  1.1114e-07,\n             1.4194e-09,  1.0414e-07, -1.0113e-07,  3.3500e-08,  1.1029e-07,\n             4.6067e-07,  8.9212e-09, -3.7408e-07,  3.5929e-08,  1.1768e-07,\n             1.4397e-07, -5.2874e-08,  1.3498e-07,  1.5796e-07, -3.3965e-07,\n            -7.2542e-09, -5.0456e-07, -2.1579e-07, -3.1244e-07, -8.5679e-09,\n             6.9728e-08,  1.4396e-07,  1.2166e-07, -1.0846e-07,  1.5244e-07,\n            -3.6548e-07, -9.6093e-08,  1.8374e-07,  7.4191e-08,  6.9759e-08,\n            -7.7690e-08, -1.7666e-07, -3.9789e-08, -9.4408e-08, -2.0151e-07,\n             7.5026e-08, -3.0205e-07, -1.3650e-07, -7.6027e-08, -3.1396e-08,\n            -6.7632e-08,  1.1945e-08,  7.1235e-08,  4.5832e-08, -8.4313e-08,\n             1.7491e-07, -1.1240e-07,  9.9340e-09, -1.2641e-07,  1.2669e-07,\n             1.0346e-07,  7.0751e-08]),\n    'exp_avg_sq': tensor([3.4212e-13, 6.9676e-13, 1.9452e-13, 1.3331e-12, 2.0574e-13, 5.0278e-13,\n            4.7169e-13, 3.3389e-13, 6.4288e-13, 2.8133e-13, 2.2712e-13, 4.9894e-13,\n            1.8466e-13, 3.1861e-13, 7.9493e-13, 3.9402e-13, 3.0872e-12, 4.2069e-13,\n            8.7001e-13, 4.9474e-13, 8.9921e-13, 5.0748e-13, 3.5123e-13, 4.8413e-13,\n            7.0351e-13, 4.6556e-13, 1.9173e-13, 2.1836e-13, 1.3320e-13, 4.4628e-13,\n            4.8049e-13, 5.0122e-13, 4.1853e-13, 6.2861e-13, 2.2672e-13, 4.2116e-14,\n            7.3848e-14, 3.2129e-13, 3.6534e-13, 8.1115e-13, 2.4166e-13, 7.6824e-13,\n            5.0011e-13, 3.5311e-13, 4.1074e-14, 5.0371e-13, 3.0036e-13, 5.1913e-13,\n            3.1043e-13, 3.3545e-13, 3.4197e-13, 2.7426e-13, 6.0645e-13, 4.4934e-13,\n            5.2058e-13, 4.1389e-13, 1.6607e-13, 2.7583e-13, 4.4584e-13, 4.5480e-13,\n            5.0113e-13, 3.9695e-13, 3.9905e-13, 5.0709e-13, 2.8975e-13, 6.5737e-13,\n            3.9877e-13, 4.2538e-13, 3.4754e-13, 4.3993e-13, 4.1970e-13, 3.6951e-13,\n            5.0681e-13, 1.9041e-13, 1.6497e-13, 1.8041e-13, 5.2379e-13, 3.7792e-13,\n            1.9791e-13, 2.3378e-13, 7.9315e-13, 4.1892e-13, 2.0608e-13, 4.0863e-13,\n            3.8704e-13, 3.3576e-13, 1.8221e-13, 3.8286e-13, 5.5369e-13, 4.4717e-14,\n            4.5271e-13, 3.6669e-13, 2.2480e-13, 1.6674e-13, 3.7412e-13, 5.8158e-13,\n            4.6267e-13, 3.6050e-13, 4.0602e-13, 1.1313e-13, 6.8768e-13, 3.3268e-13,\n            2.2205e-13, 3.4705e-13, 6.3310e-13, 1.6562e-13, 5.5436e-13, 4.0497e-13,\n            6.1836e-13, 4.4020e-13, 1.3518e-12, 2.8543e-13, 4.4353e-13, 2.5960e-13,\n            5.7234e-13, 2.7884e-13, 1.9849e-13, 6.8126e-13, 8.1068e-13, 2.4482e-13,\n            4.5286e-13, 7.9620e-13, 3.4448e-13, 3.6836e-13, 3.4180e-13, 5.2870e-13,\n            9.1878e-14, 3.8019e-13, 3.7061e-13, 3.7991e-13, 4.4939e-13, 6.2616e-13,\n            4.5894e-13, 2.0554e-13, 2.9892e-13, 1.5336e-13, 3.3050e-13, 3.2216e-13,\n            6.0137e-13, 2.2413e-13, 1.9063e-13, 4.5302e-13, 3.5174e-13, 2.3348e-13,\n            4.8718e-13, 6.3451e-13, 3.0725e-13, 2.0056e-13, 3.8955e-13, 8.6494e-13,\n            2.8965e-13, 3.0745e-13, 3.6430e-13, 3.0651e-13, 1.8268e-13, 1.5062e-13,\n            3.4749e-13, 2.2235e-13, 1.9356e-13, 4.3831e-13, 8.6119e-13, 5.8179e-13,\n            2.3406e-13, 2.7019e-13, 4.1662e-13, 3.4200e-13, 5.9864e-13, 2.1017e-13,\n            2.0386e-13, 7.2756e-13, 4.2274e-13, 2.5178e-13, 9.1171e-14, 6.9586e-13,\n            3.6627e-13, 3.2427e-13, 1.2184e-13, 2.5092e-13, 6.9307e-13, 5.6682e-13,\n            4.7947e-13, 6.9336e-13, 3.8940e-13, 7.8076e-13, 4.0924e-13, 2.0874e-13,\n            4.1586e-13, 2.2373e-13, 2.1652e-13, 5.4129e-13, 3.3780e-13, 3.8654e-14,\n            2.9518e-13, 1.9453e-13, 1.4567e-13, 2.7079e-13, 5.0070e-13, 7.7942e-13,\n            3.8036e-13, 6.2005e-13, 1.6569e-13, 7.7234e-13, 4.8282e-13, 4.2731e-13,\n            1.0040e-12, 5.8144e-13, 4.5627e-13, 1.3827e-13, 1.7886e-13, 2.9743e-13,\n            5.8078e-13, 5.2501e-13, 5.8602e-13, 3.0795e-13, 3.4098e-13, 3.3652e-13,\n            3.3670e-13, 3.4803e-13, 3.8972e-13, 3.6388e-13, 2.5819e-13, 1.7080e-13,\n            5.4512e-13, 4.2797e-13, 8.5711e-13, 3.2890e-13, 6.4387e-13, 4.4184e-13,\n            6.8114e-13, 2.8046e-13, 2.9492e-13, 3.7388e-13, 4.1840e-13, 4.8922e-13,\n            3.0622e-13, 4.2561e-13, 9.9112e-13, 3.5319e-13, 7.6619e-13, 5.8279e-13,\n            5.9468e-13, 3.9192e-13, 4.3012e-13, 1.5564e-13, 4.4974e-13, 1.1171e-13,\n            3.8110e-13, 6.3041e-13, 4.1952e-13, 8.7700e-13, 2.5323e-13, 2.5741e-13,\n            1.1997e-13, 5.3115e-13, 2.0012e-13, 8.1680e-14, 3.0704e-13, 5.9695e-13,\n            3.0244e-13, 2.8666e-13, 4.9387e-13, 2.7942e-13, 3.6441e-13, 1.3845e-13,\n            1.8321e-13, 5.7989e-13, 3.6898e-13, 5.0091e-13, 3.8707e-13, 5.9599e-13,\n            4.7137e-13, 4.6619e-13, 4.9674e-13, 2.6127e-13, 2.9056e-13, 1.1522e-13,\n            2.8910e-13, 2.0630e-13, 2.2624e-13, 2.9006e-13, 3.9543e-13, 1.1420e-13,\n            6.7231e-14, 7.6155e-13, 2.9944e-13, 3.8136e-13, 4.5635e-13, 5.3106e-13,\n            2.9002e-13, 1.2241e-13, 7.6366e-13, 5.2268e-13, 3.9032e-13, 4.4921e-13,\n            3.0316e-13, 3.0732e-13, 6.5258e-13, 2.3525e-13, 1.7180e-13, 2.9563e-13,\n            5.7004e-13, 7.0126e-13, 5.6608e-13, 2.5019e-13, 2.2921e-13, 6.4338e-13,\n            4.7476e-13, 3.2218e-13, 4.1777e-13, 3.0053e-13, 2.9139e-13, 8.3378e-13,\n            2.9592e-13, 3.9054e-13, 3.4244e-13, 1.3411e-13, 4.3296e-13, 2.8994e-13,\n            3.1714e-13, 3.9336e-13, 4.1657e-13, 4.2827e-13, 4.1289e-13, 4.8522e-13,\n            4.2599e-13, 5.6552e-13, 1.1312e-13, 3.4158e-13, 1.7148e-13, 9.6553e-14,\n            9.4571e-14, 5.4396e-13, 6.4468e-13, 1.2870e-13, 1.9344e-13, 5.9487e-13,\n            4.6034e-13, 8.2406e-13, 1.4835e-12, 1.5066e-13, 1.8223e-13, 5.2038e-13,\n            5.5637e-13, 4.1192e-13, 3.4100e-13, 2.5339e-13, 9.7798e-14, 5.6290e-13,\n            4.7288e-13, 5.1708e-13, 7.0645e-13, 3.3449e-13, 2.7691e-13, 3.1058e-13,\n            1.8987e-13, 9.5779e-13, 3.9245e-13, 5.8222e-13, 3.7184e-13, 2.4280e-13,\n            2.7378e-13, 5.2674e-13, 8.5390e-13, 5.5438e-13, 7.7188e-13, 3.5033e-13,\n            1.6291e-13, 4.9866e-13, 3.1513e-13, 6.8798e-13, 1.7913e-13, 5.1896e-13,\n            4.7308e-13, 3.8845e-13, 6.1342e-13, 3.0326e-13, 3.5334e-13, 3.8102e-13,\n            4.2873e-13, 2.9781e-13, 6.3757e-14, 2.2897e-13, 4.3873e-13, 3.0188e-13,\n            2.9470e-13, 2.8915e-13, 1.4572e-13, 3.6811e-13, 4.1117e-13, 7.9885e-13,\n            6.5372e-13, 3.6579e-13, 1.3036e-13, 5.2608e-13, 3.9032e-13, 4.1394e-13,\n            4.6786e-13, 3.0383e-13, 5.9538e-13, 2.7262e-13, 7.0071e-13, 4.5281e-13,\n            4.4294e-13, 7.5821e-13, 5.4146e-13, 4.2248e-13, 3.7026e-13, 5.2808e-13,\n            6.8972e-13, 6.8258e-13, 4.7863e-13, 2.7952e-13, 5.5164e-13, 2.7438e-13,\n            3.9517e-13, 1.6867e-13, 7.5285e-14, 5.1457e-13, 4.5772e-13, 4.5145e-13,\n            2.9202e-13, 2.9709e-13, 1.3862e-12, 6.3114e-13, 4.5467e-13, 4.5359e-13,\n            1.6120e-12, 4.2867e-13, 4.5893e-13, 3.0807e-13, 4.4901e-13, 5.0078e-13,\n            2.6639e-13, 2.4261e-13, 4.2787e-13, 2.7095e-13, 3.6474e-13, 4.6274e-13,\n            2.3088e-13, 7.5509e-13, 2.9133e-13, 4.2364e-13, 7.1737e-13, 2.3891e-13,\n            4.7460e-13, 6.0780e-13, 2.8692e-13, 3.6154e-13, 2.5387e-13, 5.7686e-13,\n            4.4947e-13, 3.9267e-13, 2.5201e-13, 4.4448e-13, 6.5004e-13, 5.0810e-13,\n            4.1229e-13, 5.6986e-13, 2.9032e-13, 5.3726e-13, 5.5171e-13, 5.0693e-13,\n            3.4735e-13, 5.5715e-13, 5.5477e-13, 6.5784e-13, 4.3148e-13, 5.6596e-13,\n            4.0591e-13, 4.5182e-13, 2.8169e-13, 2.2429e-13, 6.7872e-13, 3.4112e-13,\n            3.9700e-13, 3.0692e-13, 3.5001e-13, 6.6863e-13, 5.4194e-13, 1.9721e-13,\n            3.5223e-13, 6.2455e-13, 4.7961e-13, 3.2178e-13, 8.1590e-13, 1.1045e-12,\n            4.7203e-13, 4.0066e-13, 3.9232e-13, 6.0198e-13, 7.3298e-13, 3.2532e-13,\n            1.5881e-13, 5.9741e-13, 4.3487e-13, 4.7910e-13, 3.3406e-13, 7.3980e-13,\n            7.0006e-13, 3.5515e-13, 4.3092e-13, 2.7091e-13, 5.7444e-13, 7.2382e-13,\n            2.7498e-13, 3.6305e-13, 3.6186e-13, 5.1581e-13, 4.4531e-13, 3.2164e-13,\n            9.3007e-13, 1.2701e-13])},\n   36: {'exp_avg': tensor([-2.3413e-09,  1.0734e-07,  2.1960e-07, -1.8959e-07, -1.7380e-08,\n            -1.8965e-07,  1.1373e-07,  2.3564e-08, -3.2948e-07, -8.6579e-08,\n            -2.3306e-07, -5.0475e-08,  8.1413e-08,  1.1451e-07,  3.1460e-07,\n             3.2380e-07,  1.2230e-07, -4.4501e-07,  1.8836e-08,  1.5249e-07,\n            -4.8081e-09, -1.5828e-07,  2.1826e-07,  5.6095e-08,  7.9106e-08,\n             2.2697e-07, -3.3793e-08,  3.4131e-07,  2.7941e-07,  7.6185e-08,\n            -2.1865e-07,  7.5748e-08, -1.0798e-09,  8.2675e-08,  1.4912e-07,\n             1.8018e-08, -1.6664e-07, -1.1225e-07, -1.3406e-07, -6.7635e-08,\n            -1.0555e-07, -1.5552e-07, -1.5420e-07, -1.0431e-07,  2.4599e-07,\n            -6.2034e-08, -1.3050e-07,  1.8503e-07, -2.6688e-07,  8.1408e-08,\n            -5.2942e-08,  9.4697e-08, -1.3008e-07, -4.1895e-07, -2.4521e-07,\n             1.1340e-08, -6.8242e-08,  3.2410e-07, -1.8113e-07, -6.1388e-08,\n            -1.0535e-07, -7.5767e-08,  4.4579e-08,  6.8352e-08, -6.3206e-08,\n            -1.7021e-07,  4.6515e-07, -9.4833e-09,  1.9603e-07,  7.9404e-08,\n            -1.9733e-07,  6.2955e-08, -3.5312e-07,  1.0214e-07, -8.1061e-08,\n            -7.0394e-08,  9.0484e-08, -1.6614e-07,  1.2501e-07,  1.2071e-07,\n             3.4878e-07,  2.3610e-08,  2.4737e-07, -4.0048e-08,  1.5283e-08,\n             2.2166e-07,  1.0587e-07, -1.7980e-07, -1.2894e-07, -5.1461e-09,\n            -9.9661e-08, -6.3935e-08,  2.0486e-07,  2.3642e-07,  5.7824e-08,\n            -5.8859e-08, -4.7391e-08, -5.5829e-08, -2.9175e-08, -3.5058e-07,\n            -7.6247e-08,  4.3286e-08, -9.5795e-08, -2.0996e-08, -1.7524e-07,\n            -1.1794e-07, -1.2807e-07,  2.4220e-07, -5.9861e-09, -2.5280e-07,\n            -1.0646e-07, -1.3505e-07,  2.9122e-08, -4.0541e-08, -1.0353e-07,\n            -3.6207e-09, -1.2867e-08, -3.7926e-08, -1.2158e-07,  4.9066e-08,\n             2.6140e-07, -9.8890e-08,  1.4537e-07, -1.0725e-07,  1.3714e-07,\n             9.8804e-08,  1.9711e-07,  1.0323e-07]),\n    'exp_avg_sq': tensor([3.7595e-13, 7.1946e-13, 6.8783e-13, 3.9917e-13, 8.5260e-13, 5.5953e-13,\n            7.0206e-13, 3.3530e-13, 9.3788e-13, 3.4999e-13, 7.8231e-13, 4.7835e-13,\n            7.0064e-13, 1.7919e-13, 7.1355e-13, 5.8453e-13, 6.2375e-13, 1.3037e-12,\n            3.5617e-13, 2.2514e-13, 3.3685e-13, 6.7837e-13, 9.6441e-13, 4.1695e-13,\n            5.6516e-13, 7.2182e-13, 3.0634e-13, 7.9611e-13, 3.8982e-13, 6.8499e-13,\n            5.1467e-13, 3.7569e-13, 2.7470e-13, 8.3196e-13, 6.5865e-13, 4.8493e-13,\n            7.7886e-13, 3.3553e-13, 6.3509e-13, 7.6353e-13, 2.8049e-13, 3.6880e-13,\n            6.1193e-13, 4.3298e-13, 2.9221e-13, 5.5972e-13, 3.6245e-13, 4.2307e-13,\n            4.1258e-13, 2.7876e-13, 4.7666e-13, 2.7351e-13, 2.4498e-13, 5.6353e-13,\n            2.5711e-13, 4.5635e-13, 5.0158e-13, 7.6048e-13, 6.0783e-13, 7.4533e-13,\n            3.0512e-13, 5.1771e-13, 2.0828e-13, 3.5880e-13, 6.1288e-13, 3.1967e-13,\n            1.3784e-12, 9.6542e-13, 4.2152e-13, 5.2950e-13, 3.0173e-13, 1.6573e-13,\n            5.2201e-13, 7.6222e-13, 7.1106e-13, 3.1693e-13, 1.1538e-12, 3.2982e-13,\n            4.6191e-13, 6.1507e-13, 5.5634e-13, 3.1238e-13, 6.5929e-13, 1.6262e-13,\n            3.2321e-13, 1.1774e-12, 5.3864e-13, 3.7393e-13, 1.3362e-12, 7.5700e-13,\n            1.2070e-12, 1.0387e-12, 4.3048e-13, 4.5767e-13, 3.2933e-13, 7.5491e-13,\n            2.2796e-13, 2.7988e-13, 6.7668e-13, 3.9934e-13, 4.0260e-13, 4.1432e-13,\n            2.9369e-13, 4.3047e-13, 5.0012e-13, 1.3157e-12, 8.8169e-13, 2.1891e-13,\n            6.4061e-13, 1.1101e-12, 2.6329e-13, 4.5943e-13, 6.0004e-13, 6.0200e-13,\n            2.4889e-13, 2.2941e-13, 4.7226e-13, 3.0673e-13, 6.1723e-13, 3.8962e-13,\n            9.0634e-13, 6.1148e-13, 1.0886e-12, 2.5764e-13, 5.9885e-13, 2.7581e-13,\n            5.9329e-13, 4.8380e-13])},\n   37: {'exp_avg': tensor([ 4.9735e-08,  1.7041e-07,  1.8219e-07, -8.2796e-08, -3.1450e-08,\n            -6.1622e-08,  5.9311e-08,  1.7570e-07, -3.5224e-07, -1.3260e-07,\n            -1.4272e-07, -1.8945e-07,  1.3249e-08,  3.1751e-08,  1.9338e-07,\n             8.9154e-08,  2.3333e-07, -2.5249e-07, -1.2456e-07,  2.1644e-07,\n            -1.0131e-07, -6.2712e-08,  1.8832e-07,  1.6903e-07,  1.9976e-08,\n             2.4640e-07, -1.0576e-07,  1.1862e-07,  1.3356e-07, -2.5795e-08,\n            -1.8181e-07, -2.3886e-08, -5.8139e-08, -5.8584e-09,  1.1048e-07,\n            -1.2266e-09, -1.6202e-07, -1.1831e-07, -2.0794e-07, -2.0287e-07,\n            -9.4989e-08, -2.5171e-08, -1.6210e-07,  9.6840e-08,  2.0498e-07,\n            -2.7163e-08, -1.8234e-07,  2.9744e-07, -3.0030e-07, -1.6429e-08,\n            -6.8168e-08,  4.1385e-08, -2.5444e-07, -3.8078e-07, -2.0666e-07,\n            -1.3104e-07, -1.0709e-07,  2.6521e-07, -1.5527e-07, -6.0755e-08,\n            -8.0983e-08, -1.3777e-07,  6.6686e-08, -5.2081e-08, -1.3870e-07,\n            -3.0279e-07,  3.9923e-07, -1.5206e-09,  2.1877e-07,  4.3656e-08,\n            -1.9183e-07,  6.1678e-08, -2.3444e-07, -1.8935e-07, -1.1751e-07,\n            -2.5118e-08, -5.4734e-08, -1.7177e-07,  2.7660e-07,  1.2182e-07,\n             2.9269e-07, -1.6275e-07,  1.1438e-07, -4.7874e-08, -1.4078e-07,\n            -3.5168e-08,  3.8081e-08, -1.5199e-07, -1.9612e-07, -1.9979e-07,\n             1.3698e-08,  3.5373e-08,  2.0498e-08,  1.3071e-07, -4.9474e-08,\n            -1.2082e-07, -2.1201e-08, -1.2566e-07,  2.5107e-08, -7.9817e-08,\n             7.3888e-08,  8.6553e-09,  1.4123e-08, -2.0758e-07, -2.2656e-07,\n            -1.7480e-07,  1.6396e-07,  2.9751e-07,  4.7100e-08, -1.9967e-07,\n            -1.6792e-07,  5.4720e-09, -2.0317e-09, -1.0697e-08, -9.2499e-08,\n             8.2190e-08,  4.9700e-08, -1.2490e-07, -3.3084e-08,  1.3831e-07,\n             1.1382e-07, -1.3284e-07,  3.1168e-08, -1.0014e-07, -5.2197e-08,\n             9.4155e-08,  4.7453e-07,  4.9250e-08]),\n    'exp_avg_sq': tensor([3.1933e-13, 6.0500e-13, 4.8562e-13, 2.8973e-13, 1.4190e-12, 4.1642e-13,\n            4.5875e-13, 4.0543e-13, 5.0643e-13, 3.5270e-13, 5.1808e-13, 3.1054e-13,\n            5.7574e-13, 3.0489e-13, 4.3266e-13, 3.6915e-13, 6.4853e-13, 8.5253e-13,\n            3.5359e-13, 3.8991e-13, 6.2452e-13, 5.4612e-13, 4.1022e-13, 4.3092e-13,\n            4.0954e-13, 5.2539e-13, 2.7025e-13, 5.0441e-13, 2.8230e-13, 4.2826e-13,\n            4.1403e-13, 3.6595e-13, 2.3447e-13, 5.7596e-13, 3.4912e-13, 4.1217e-13,\n            5.7800e-13, 2.9617e-13, 4.4586e-13, 4.3553e-13, 3.7854e-13, 2.6777e-13,\n            4.1755e-13, 4.9041e-13, 3.2888e-13, 4.4925e-13, 4.2562e-13, 4.0988e-13,\n            4.2864e-13, 3.0033e-13, 4.2290e-13, 3.3566e-13, 4.7057e-13, 4.4121e-13,\n            3.1370e-13, 3.4596e-13, 3.9844e-13, 4.8148e-13, 4.8776e-13, 5.6569e-13,\n            3.0876e-13, 4.9087e-13, 4.3324e-13, 3.4740e-13, 3.9681e-13, 3.4435e-13,\n            7.3596e-13, 6.8790e-13, 4.4766e-13, 4.8247e-13, 4.5308e-13, 3.0609e-13,\n            3.2002e-13, 5.9630e-13, 4.8877e-13, 3.7972e-13, 4.9589e-13, 4.3065e-13,\n            2.9049e-13, 4.2730e-13, 4.2252e-13, 5.0007e-13, 3.9734e-13, 3.0110e-13,\n            2.8630e-13, 4.6509e-13, 3.6964e-13, 3.4791e-13, 9.4776e-13, 3.9552e-13,\n            7.6022e-13, 6.9005e-13, 4.1535e-13, 4.0928e-13, 3.3412e-13, 5.5959e-13,\n            3.9057e-13, 4.1458e-13, 4.2694e-13, 3.4402e-13, 3.9779e-13, 3.7185e-13,\n            4.4866e-13, 5.1523e-13, 3.8200e-13, 8.6509e-13, 5.3843e-13, 4.0758e-13,\n            4.0763e-13, 7.6268e-13, 2.5618e-13, 3.0793e-13, 4.5097e-13, 4.5461e-13,\n            3.5894e-13, 2.6702e-13, 4.5862e-13, 3.5254e-13, 4.4047e-13, 3.9541e-13,\n            6.5816e-13, 5.1047e-13, 5.1996e-13, 4.2177e-13, 3.8670e-13, 3.8421e-13,\n            1.0242e-12, 4.1862e-13])},\n   38: {'exp_avg': tensor([-1.2872e-07, -1.0679e-08,  1.3685e-07, -4.7860e-08, -1.2273e-07,\n            -2.2113e-08,  1.9040e-07,  1.8352e-07,  2.4667e-07, -2.7332e-07,\n             1.7967e-07,  7.1644e-08, -3.3007e-07,  4.5685e-08, -1.8488e-07,\n             2.7573e-07,  1.1494e-07, -1.3876e-07,  2.7393e-07, -4.7935e-08,\n            -2.0589e-08,  1.9359e-07, -3.8009e-08,  1.0188e-07,  4.1895e-09,\n             2.8409e-09,  6.2322e-08, -2.1530e-07, -5.0322e-08, -3.8770e-08,\n             2.0586e-07, -5.9469e-07, -4.3884e-08, -1.2572e-08,  1.2804e-07,\n            -6.8086e-08,  3.0533e-07, -1.0879e-07,  5.9579e-09,  8.9685e-08,\n            -1.9515e-07,  1.7227e-07,  1.8271e-07, -5.2301e-08,  3.6880e-08,\n             2.3609e-07, -2.0116e-07, -2.7463e-08,  3.6487e-08, -5.9908e-09,\n             2.5576e-08, -7.7777e-08,  4.7104e-08, -1.0538e-07,  1.3833e-07,\n            -9.5623e-09,  1.0461e-08, -5.2527e-08,  3.0764e-07, -4.0792e-08,\n            -2.3150e-07,  2.8825e-07,  9.6768e-08, -1.6389e-07, -6.3888e-08,\n            -4.9381e-08,  4.4226e-08,  2.4307e-07, -2.5785e-07, -5.6864e-08,\n             2.5015e-07,  4.7197e-09, -6.9620e-08, -1.6215e-07, -1.9584e-07,\n            -8.0214e-08,  5.2819e-08, -1.1613e-08, -3.7107e-07, -9.8260e-08,\n            -5.2436e-08,  1.3228e-07,  6.6299e-08, -1.7745e-07, -1.3998e-07,\n             4.7302e-07, -4.3481e-08, -1.9951e-07, -2.2639e-07,  2.5213e-07,\n             4.2319e-08, -3.1529e-08,  9.2757e-08,  3.1002e-07,  2.1470e-08,\n             1.4767e-08, -2.6238e-07, -4.1645e-07,  4.0446e-08, -1.2443e-08,\n             5.1293e-08, -1.1783e-07, -1.8764e-07, -1.0816e-07, -3.3525e-07,\n            -1.2334e-07,  1.8156e-07,  4.9465e-08, -3.7303e-08, -6.9039e-08,\n            -7.3422e-09,  1.2460e-07,  5.8278e-08,  1.0187e-07,  7.2710e-08,\n             1.3091e-07,  5.6301e-08,  1.4642e-07,  1.7078e-08, -2.2177e-07,\n             1.7905e-07,  4.2868e-08, -1.6136e-07,  1.0831e-07, -3.6570e-09,\n             1.7303e-08,  4.1737e-08, -1.8956e-08]),\n    'exp_avg_sq': tensor([4.3032e-13, 5.7765e-13, 2.4457e-13, 7.5903e-13, 4.9005e-13, 6.7068e-13,\n            5.1333e-13, 1.4053e-12, 5.9850e-13, 4.8232e-13, 6.8264e-13, 4.3759e-13,\n            6.3719e-13, 3.1510e-13, 5.0551e-13, 9.3679e-13, 3.2392e-13, 4.5618e-13,\n            5.3984e-13, 5.6944e-13, 4.6362e-13, 2.2915e-12, 7.0687e-13, 5.3757e-13,\n            7.7700e-13, 3.6838e-13, 5.9043e-13, 7.5180e-13, 2.9807e-13, 4.4879e-13,\n            8.0398e-13, 9.1095e-13, 4.0990e-13, 5.1496e-13, 7.4364e-13, 3.1092e-13,\n            5.4542e-13, 4.3242e-13, 6.8175e-13, 2.8761e-13, 4.1364e-13, 6.1882e-13,\n            4.0066e-13, 8.9508e-13, 5.2819e-13, 6.8830e-13, 6.7793e-13, 1.2558e-12,\n            5.3160e-13, 4.1702e-13, 5.0409e-13, 4.1333e-13, 6.2566e-13, 1.0965e-12,\n            2.3567e-12, 6.3846e-13, 7.2340e-13, 3.6056e-13, 4.3189e-13, 4.9174e-13,\n            5.8268e-13, 4.2619e-13, 2.7951e-13, 6.3515e-13, 6.3042e-13, 7.8244e-13,\n            3.8701e-13, 6.5552e-13, 6.9706e-13, 1.1036e-12, 2.7277e-13, 5.2936e-13,\n            2.7295e-13, 5.3700e-13, 5.2503e-13, 3.0924e-13, 7.2811e-13, 4.7823e-13,\n            7.0807e-13, 1.1547e-12, 3.7279e-13, 6.3762e-13, 3.1657e-13, 5.0254e-13,\n            5.4539e-13, 5.3044e-13, 6.2392e-13, 3.6859e-13, 4.8616e-13, 7.3823e-13,\n            3.3223e-13, 3.0047e-13, 4.2655e-13, 5.5917e-13, 3.6757e-13, 2.0771e-13,\n            5.1649e-13, 4.8432e-13, 6.7462e-13, 7.9400e-13, 5.2483e-13, 6.6553e-13,\n            3.8501e-13, 4.1477e-13, 1.8977e-12, 4.7142e-13, 1.4533e-12, 7.0613e-13,\n            3.8966e-13, 2.4995e-13, 7.0138e-13, 5.7903e-13, 4.0346e-13, 4.1524e-13,\n            3.3258e-13, 5.4926e-13, 3.7334e-13, 3.5286e-13, 5.3306e-13, 1.1253e-12,\n            9.1126e-13, 6.8506e-13, 6.3334e-13, 8.6139e-13, 2.1376e-13, 2.6420e-13,\n            5.5746e-13, 4.0893e-13])},\n   39: {'exp_avg': tensor([-6.8008e-08, -1.1623e-07,  2.8589e-08, -3.0306e-08, -1.3424e-07,\n            -2.3532e-08,  1.8771e-07,  2.4169e-07,  8.7479e-08, -3.9321e-08,\n             1.0457e-07, -1.2295e-07, -9.6143e-08,  3.9661e-08, -1.6627e-07,\n             7.4801e-08,  5.8710e-08, -7.0357e-08,  2.2845e-07, -3.0791e-07,\n             9.4141e-08, -1.1762e-08, -5.2900e-08,  1.9209e-09, -3.8836e-08,\n            -1.5588e-07,  1.1979e-07, -1.3299e-07, -9.3481e-08, -9.9201e-08,\n             1.2802e-07, -7.9451e-07, -1.2835e-07,  2.0180e-08,  8.8248e-08,\n            -2.0211e-07,  1.5473e-07, -1.4293e-07,  6.9812e-08,  1.3723e-07,\n            -8.4621e-08,  4.1594e-08,  1.1211e-07, -8.5057e-08, -1.4858e-07,\n             2.0099e-08, -1.0908e-07, -4.5742e-08,  1.5158e-08, -4.6755e-08,\n             9.1254e-08, -1.4875e-07,  2.0124e-08, -2.0506e-07, -1.1820e-07,\n             2.1572e-08,  3.8487e-08,  1.3691e-07,  2.4750e-07, -1.2593e-07,\n            -2.1219e-07,  1.5101e-07,  3.3810e-08, -2.0234e-07,  2.9624e-08,\n            -1.2209e-07, -1.4785e-09,  2.1244e-07, -1.5838e-07, -1.1536e-07,\n             1.9285e-07,  5.2324e-09, -9.9880e-08, -1.4846e-07, -3.1978e-07,\n             5.8795e-09,  1.2501e-07, -1.8431e-07, -4.5881e-08,  8.3186e-08,\n             1.2850e-07,  1.5814e-07,  6.9051e-08, -1.3588e-07, -8.8965e-08,\n             3.0426e-07,  1.3632e-07, -2.2342e-07, -1.6912e-07,  1.6672e-07,\n            -5.0470e-08, -6.7321e-08,  5.9878e-08,  1.2946e-07, -8.2634e-08,\n            -2.1684e-08, -2.0949e-07, -3.1387e-07, -2.4161e-08, -9.4479e-08,\n             5.1424e-08, -1.3202e-07, -1.8038e-07, -1.8697e-07, -2.0574e-07,\n            -1.0387e-07,  1.1554e-07,  1.2695e-07, -2.8255e-08, -1.3303e-07,\n            -4.8900e-08, -6.1940e-09,  5.6658e-08,  4.5564e-08,  8.2793e-08,\n             2.2141e-07,  8.5571e-08,  1.8073e-07, -8.5616e-08, -2.2356e-07,\n             1.1850e-07,  8.6316e-08, -7.4780e-08,  1.3575e-07, -8.5015e-08,\n             1.3707e-08,  1.0835e-07, -8.7063e-08]),\n    'exp_avg_sq': tensor([4.0377e-13, 3.2513e-13, 1.7766e-13, 4.1475e-13, 2.7765e-13, 4.6042e-13,\n            3.6304e-13, 6.5560e-13, 2.8827e-13, 2.7039e-13, 3.0889e-13, 2.7553e-13,\n            4.0900e-13, 2.4370e-13, 3.1898e-13, 5.6023e-13, 2.2852e-13, 2.8581e-13,\n            3.5920e-13, 3.9585e-13, 2.8262e-13, 1.7906e-12, 5.9451e-13, 4.2161e-13,\n            4.4945e-13, 2.5760e-13, 3.4347e-13, 5.9359e-13, 2.3805e-13, 2.6227e-13,\n            5.4458e-13, 5.8327e-13, 2.1628e-13, 3.7784e-13, 4.8275e-13, 2.4427e-13,\n            3.4681e-13, 3.1960e-13, 4.3709e-13, 1.9582e-13, 2.6476e-13, 4.1108e-13,\n            2.1884e-13, 5.5096e-13, 2.8592e-13, 3.1447e-13, 2.8505e-13, 1.0091e-12,\n            2.8432e-13, 2.6211e-13, 2.9493e-13, 3.1781e-13, 3.1394e-13, 6.7503e-13,\n            1.2722e-12, 3.5286e-13, 3.4416e-13, 2.7117e-13, 2.4594e-13, 2.5956e-13,\n            3.3955e-13, 2.3854e-13, 1.9836e-13, 4.4535e-13, 3.8818e-13, 4.2324e-13,\n            1.9071e-13, 5.3370e-13, 5.1692e-13, 6.9436e-13, 1.8089e-13, 3.4452e-13,\n            2.0807e-13, 3.1308e-13, 2.5613e-13, 2.3062e-13, 4.8555e-13, 2.2522e-13,\n            2.8494e-13, 6.5695e-13, 2.3427e-13, 4.8046e-13, 1.9665e-13, 4.0270e-13,\n            5.3008e-13, 4.5868e-13, 4.4994e-13, 1.9978e-13, 2.8494e-13, 5.9012e-13,\n            2.0059e-13, 2.0699e-13, 2.7940e-13, 3.3869e-13, 2.4384e-13, 1.5472e-13,\n            3.4812e-13, 2.8498e-13, 2.8550e-13, 4.9435e-13, 2.9974e-13, 4.3564e-13,\n            2.6865e-13, 3.7959e-13, 1.2538e-12, 4.2887e-13, 1.0850e-12, 4.6556e-13,\n            2.7914e-13, 2.6123e-13, 3.5631e-13, 4.2898e-13, 2.7123e-13, 2.3131e-13,\n            2.4772e-13, 4.0426e-13, 2.3307e-13, 2.5469e-13, 2.4511e-13, 5.8995e-13,\n            6.8627e-13, 5.1270e-13, 3.4903e-13, 6.2894e-13, 1.5565e-13, 1.6378e-13,\n            4.1647e-13, 2.8122e-13])},\n   40: {'exp_avg': tensor([ 5.2565e-07, -2.8525e-07,  5.0326e-07, -1.5010e-07, -1.1016e-08,\n             3.8086e-07,  1.5069e-07,  5.4312e-07,  8.5041e-08,  2.1294e-07,\n            -1.5233e-07,  2.6024e-07, -3.8367e-07, -3.7817e-08,  2.8644e-07,\n            -3.4452e-08, -3.7891e-07, -1.7210e-07,  4.1052e-07,  3.1943e-07,\n            -6.0935e-08,  3.4707e-07,  1.6556e-07,  2.0891e-07,  1.4029e-07,\n            -6.9944e-08,  6.6462e-08, -2.2989e-08,  1.7860e-07, -1.7099e-07,\n             3.7321e-07, -1.7875e-07, -6.2515e-08, -5.1492e-08,  2.6587e-07,\n             6.5829e-07,  4.0178e-07,  3.3446e-07,  1.7242e-08,  3.6097e-07,\n             2.2900e-07,  2.7550e-07,  1.8159e-07, -3.7437e-07, -3.1192e-07,\n            -1.6075e-09, -2.3103e-08, -1.0343e-08, -3.4095e-07, -1.1687e-07,\n            -3.7492e-08,  5.6566e-09, -5.6918e-07, -2.6821e-07,  3.7887e-08,\n            -3.9521e-07, -4.4436e-07, -1.4356e-08, -2.3768e-07, -2.6342e-07,\n             3.4195e-07,  2.6460e-07, -8.7485e-08, -2.3715e-07, -1.4145e-07,\n             1.9924e-07, -1.2223e-07, -4.1033e-07, -1.6920e-07, -2.4975e-09,\n             2.1480e-07, -1.8301e-08,  1.4996e-07,  9.7664e-08,  1.8963e-07,\n            -4.2863e-08, -1.0280e-07,  5.5952e-08,  3.0490e-07, -4.2229e-07,\n             1.8707e-07,  8.2145e-09, -1.3770e-07, -1.1391e-07,  1.4219e-07,\n             2.1250e-07,  4.9213e-07,  1.4292e-07,  6.5031e-07, -4.5503e-07,\n            -8.1868e-09, -3.8277e-08,  2.5192e-07, -2.7978e-08,  4.6340e-07,\n            -4.0736e-07, -8.0190e-08,  3.6578e-08, -3.3107e-07, -2.4505e-07,\n            -2.5942e-07, -3.6680e-08, -1.2428e-07, -1.4706e-08,  1.9094e-07,\n             3.2074e-07,  2.0909e-07,  5.0037e-08,  5.1191e-09, -6.2721e-08,\n             7.0963e-07, -1.1913e-07, -1.3545e-07, -4.0730e-07,  2.6129e-07,\n            -2.3788e-07, -2.5739e-07,  1.9587e-07,  2.0564e-08, -1.4110e-07,\n            -5.0389e-08,  5.1723e-07,  1.2555e-07, -1.4589e-07, -2.9176e-07,\n             6.2190e-08,  8.6040e-09, -1.2417e-07,  8.0708e-08, -1.7502e-07,\n            -1.7231e-07, -1.4414e-07, -3.2823e-08, -1.4943e-07, -1.9552e-07,\n            -3.0110e-07, -7.2335e-08, -1.9723e-07, -4.1294e-08,  3.6984e-07,\n            -1.6964e-07, -2.8506e-07,  6.3995e-08,  1.9632e-07,  3.2934e-07,\n             1.0382e-07, -7.6169e-08,  3.7248e-07, -2.9132e-07, -1.1215e-07,\n             4.5174e-08,  6.0395e-08,  1.2172e-07,  1.0687e-07,  4.2551e-08,\n            -1.1857e-07,  1.0726e-07,  1.3983e-07, -7.0187e-08, -3.7205e-07,\n             2.6781e-07, -4.1116e-08, -9.1760e-08, -2.6099e-07, -1.6001e-07,\n            -1.1656e-07,  7.3803e-08, -1.8941e-07, -2.4500e-07, -1.4624e-08,\n             4.2275e-08,  3.2357e-07, -2.6237e-08,  3.9911e-07, -4.3683e-07,\n            -1.0870e-07,  2.9350e-07,  9.4717e-08, -3.9335e-07, -3.6669e-07,\n            -4.0318e-07, -1.7681e-07, -2.3855e-07,  6.7669e-08,  1.9158e-07,\n             2.0426e-07,  1.2241e-07, -1.5835e-07,  5.2718e-07, -1.3381e-07,\n            -1.3288e-08, -4.0305e-07, -2.8059e-07, -2.6619e-07, -3.6580e-07,\n            -7.6740e-08,  1.9707e-07,  2.0647e-08,  1.6224e-07,  5.2535e-09,\n             1.8648e-07, -3.0726e-07,  1.5493e-07, -1.3959e-07, -9.7866e-08,\n             4.9335e-07, -1.5168e-07,  7.5413e-07, -2.1424e-07,  1.3224e-07,\n            -1.7624e-07, -3.2843e-07,  2.2693e-07,  1.6990e-07, -1.7683e-07,\n            -5.8749e-08, -4.1527e-07, -1.4269e-08,  2.9814e-07, -1.6803e-07,\n            -9.4508e-08, -2.5800e-07, -2.0491e-07,  1.9312e-07,  6.0708e-07,\n             4.9618e-08, -1.0851e-07,  5.1479e-07,  2.9121e-07,  2.4669e-07,\n             1.5119e-07, -5.0656e-07, -3.6116e-07, -4.4881e-08, -1.1032e-07,\n            -2.2708e-07,  3.7787e-08,  2.1292e-07, -3.4638e-07, -1.5244e-07,\n             3.7688e-07,  5.2956e-07,  5.5843e-09,  4.5845e-07, -9.6425e-09,\n            -2.6889e-07,  1.2365e-07, -3.8766e-07,  1.0124e-08, -1.0437e-07,\n            -7.0699e-07, -2.4899e-07, -1.7121e-07, -4.7710e-07, -1.2002e-07,\n            -4.1314e-07, -2.0199e-08,  1.5629e-07, -7.8273e-08, -1.3734e-07,\n            -1.0592e-07, -1.3595e-08, -1.3263e-07, -8.9405e-08,  1.2263e-07,\n            -3.1599e-07, -1.2617e-07,  2.4227e-07,  6.8926e-07,  1.0603e-07,\n             2.0230e-07,  2.4718e-07, -6.4341e-08,  4.1816e-08, -1.4914e-07,\n             7.5484e-08, -3.1086e-07, -6.5208e-07, -2.6360e-07,  3.8989e-07,\n            -1.6563e-07,  3.6200e-07, -8.3312e-08, -1.7082e-07,  1.4374e-07,\n             1.6428e-07,  3.4775e-07,  7.5533e-07,  1.6924e-07, -5.8616e-08,\n             6.1456e-07, -6.1688e-07,  2.7417e-07,  3.0318e-07, -1.2039e-07,\n             6.0410e-07,  2.4176e-07, -9.2904e-09,  2.3775e-08,  2.8730e-07,\n            -2.5039e-07, -2.1793e-07, -1.5587e-07, -2.2195e-07,  5.4436e-07,\n            -2.6636e-07,  2.1659e-07, -1.0164e-08,  3.5860e-07, -1.7170e-07,\n            -4.4232e-07, -2.1545e-07, -1.1985e-06, -4.8654e-08, -1.9287e-07,\n             3.9836e-07, -1.2965e-08,  2.2367e-07, -3.0014e-07,  3.3530e-07,\n             2.2246e-07,  1.0440e-07,  3.6506e-07,  3.9717e-07,  4.8724e-08,\n             7.1055e-07,  4.1659e-08,  1.1649e-07,  1.0604e-07, -8.1086e-07,\n             4.6455e-07,  1.9134e-07, -9.1674e-08, -8.7525e-08, -6.0924e-07,\n             4.6216e-08,  2.4326e-07, -1.0602e-06,  2.9351e-07,  2.4970e-07,\n            -2.1815e-07,  5.7749e-08,  1.4896e-07,  3.4028e-07,  1.9180e-07,\n            -5.8889e-08,  2.9267e-07,  2.7358e-07,  7.5158e-07, -2.4157e-07,\n            -6.5813e-08,  1.7489e-07, -2.6173e-07,  5.6261e-08,  2.4882e-07,\n            -6.1733e-07,  1.5000e-07,  5.4508e-07, -5.2483e-08, -9.7244e-08,\n             1.7338e-07,  4.3019e-07, -7.5609e-08, -2.6734e-07,  1.3664e-07,\n            -6.9163e-08,  6.1788e-08, -7.8443e-08,  9.7492e-08,  2.3959e-07,\n            -4.2203e-08,  4.4389e-07,  2.1423e-07, -1.8726e-07,  2.9589e-07,\n            -1.1765e-07, -2.1101e-07,  3.6719e-07,  1.1247e-07,  2.0180e-07,\n             2.9383e-07, -1.8105e-07,  2.0803e-07,  5.0729e-07,  1.0459e-07,\n             2.1052e-07, -3.6975e-07,  3.3754e-07,  2.5373e-07,  5.7275e-08,\n            -3.0608e-07,  4.8592e-07,  4.1517e-07, -7.6020e-08,  1.0246e-07,\n            -4.9209e-08,  3.3546e-07,  4.9551e-08, -6.1026e-08, -2.0026e-07,\n             9.1049e-08,  4.3952e-07, -1.4877e-08,  5.3419e-08,  2.4192e-08,\n            -8.3769e-08, -1.0115e-07, -6.6429e-08,  9.6129e-08,  2.5761e-07,\n            -1.5104e-07, -4.1020e-08,  1.8606e-07,  1.6887e-07, -3.5332e-07,\n             2.7415e-07, -1.5173e-07, -4.2497e-07,  2.1850e-07,  6.8820e-08,\n             4.1550e-07,  1.8271e-07, -5.7065e-07, -3.7340e-08,  6.2694e-07,\n            -6.9585e-08,  3.4958e-07,  1.5511e-07, -7.8580e-08,  1.6672e-07,\n            -9.5917e-09, -6.0672e-08,  9.7553e-08,  3.6561e-08,  3.3709e-07,\n             1.1521e-07,  8.6701e-07,  8.6941e-08,  3.6458e-08, -2.2189e-07,\n             3.4986e-07,  1.8881e-07,  1.1809e-07,  3.2386e-07,  2.5854e-07,\n            -1.0792e-07, -4.4751e-07, -7.5458e-08, -1.0238e-07,  3.5845e-07,\n             1.8545e-07,  3.1668e-07, -1.3171e-07, -1.9290e-07, -1.8104e-07,\n             6.0689e-09, -5.8832e-07, -1.1118e-07,  5.8117e-08, -3.8341e-07,\n            -2.7786e-07, -2.5270e-07,  1.5987e-07, -2.1067e-07, -3.0584e-08,\n            -2.0530e-07,  2.6724e-07,  4.8891e-07,  8.0320e-08, -8.0483e-08,\n             2.8677e-07,  5.8087e-08, -2.1622e-07, -4.1945e-07, -1.0289e-07,\n            -1.1559e-07, -4.3857e-07,  1.0205e-07, -2.6010e-07, -3.1071e-07,\n             2.8624e-07,  2.0284e-07, -1.7727e-07,  6.2545e-08,  5.7443e-07,\n            -1.1840e-08,  2.0861e-07, -1.4993e-07,  2.8710e-07, -2.5898e-07,\n            -1.9275e-07,  1.7100e-07, -2.5526e-07, -1.3498e-07, -1.5724e-07,\n             1.5248e-07, -3.4082e-07, -4.4250e-08,  1.6721e-07,  2.0912e-07,\n            -1.1062e-07,  3.8506e-08, -2.2716e-07,  1.2018e-07,  3.6207e-07,\n             1.7547e-07, -3.0811e-07,  3.2626e-07,  4.2114e-07,  1.6778e-07,\n            -3.2433e-07, -1.3302e-07]),\n    'exp_avg_sq': tensor([2.2774e-12, 1.4181e-12, 1.8153e-12, 1.9629e-12, 9.1467e-13, 1.0492e-12,\n            7.3495e-13, 1.1992e-12, 1.0547e-12, 1.9127e-12, 1.2443e-12, 8.4885e-13,\n            9.5379e-13, 2.2061e-12, 9.2438e-13, 3.7407e-12, 4.0163e-12, 3.4707e-12,\n            1.4804e-12, 7.1311e-13, 2.1344e-12, 1.4749e-12, 1.2835e-12, 8.3139e-13,\n            1.4385e-12, 1.7362e-12, 9.5690e-13, 1.8045e-12, 3.7413e-12, 1.9891e-12,\n            2.4523e-12, 2.3387e-12, 1.3363e-12, 2.5138e-12, 2.1702e-12, 2.1970e-12,\n            1.6785e-12, 7.2949e-13, 8.7681e-13, 2.8660e-12, 1.2537e-12, 1.9566e-12,\n            1.3664e-12, 1.2731e-12, 2.1843e-12, 2.3286e-12, 1.2023e-12, 1.5042e-12,\n            2.7354e-13, 5.3004e-13, 1.2311e-12, 9.1196e-13, 1.6100e-12, 9.4616e-13,\n            2.1783e-12, 1.0336e-12, 2.1698e-12, 9.9597e-13, 2.8097e-12, 9.8958e-13,\n            7.3723e-13, 3.4235e-12, 1.6860e-12, 7.9233e-13, 1.8868e-12, 1.4484e-12,\n            7.9717e-13, 1.1841e-12, 1.0490e-12, 3.1532e-12, 1.4789e-12, 1.1216e-12,\n            1.1337e-12, 1.4389e-12, 2.7592e-12, 2.6950e-13, 2.6630e-12, 1.4257e-12,\n            1.5247e-12, 2.2210e-12, 1.6714e-12, 1.0722e-12, 1.5020e-12, 2.6989e-12,\n            1.1194e-12, 7.9238e-13, 2.7458e-12, 2.7756e-13, 2.2529e-12, 3.4365e-12,\n            5.9583e-13, 1.5171e-12, 2.5248e-12, 2.7863e-12, 3.0336e-12, 2.1549e-12,\n            1.0103e-12, 1.1564e-12, 8.4371e-13, 2.9618e-12, 1.3861e-12, 5.1358e-13,\n            1.7572e-13, 8.4278e-13, 1.9058e-12, 1.1204e-12, 9.1075e-13, 1.1107e-12,\n            1.1566e-12, 6.8897e-13, 4.4465e-12, 6.0572e-13, 1.2490e-12, 1.7526e-12,\n            1.1844e-12, 1.2581e-12, 1.0912e-12, 6.1889e-13, 1.8988e-12, 1.3650e-12,\n            4.9228e-13, 9.6423e-13, 1.4144e-12, 1.1207e-12, 8.4224e-13, 2.2084e-12,\n            2.2399e-12, 6.9024e-13, 1.7114e-12, 2.2599e-12, 1.5398e-12, 1.1497e-12,\n            8.2151e-13, 1.4942e-12, 1.1806e-12, 2.3816e-12, 2.6739e-13, 8.4822e-13,\n            2.2129e-12, 1.3019e-12, 2.4323e-12, 1.8816e-12, 8.7868e-13, 1.1585e-12,\n            9.3494e-13, 1.8983e-12, 7.0457e-13, 2.5581e-12, 1.9081e-12, 3.2811e-12,\n            7.1583e-13, 8.1683e-13, 1.4998e-12, 5.8894e-13, 2.0987e-12, 2.8376e-12,\n            8.7015e-13, 2.6885e-12, 2.1262e-12, 8.9248e-13, 1.0296e-12, 8.9487e-13,\n            1.1665e-12, 9.0102e-13, 5.6034e-13, 1.9875e-12, 1.2387e-12, 4.8359e-13,\n            1.2680e-12, 2.1754e-12, 8.4468e-13, 9.6588e-13, 1.7427e-12, 2.5556e-12,\n            6.1440e-13, 6.9277e-13, 1.5036e-12, 1.3941e-12, 1.6571e-12, 8.2902e-13,\n            2.8467e-12, 2.4710e-12, 1.3283e-12, 2.2137e-12, 6.3198e-13, 1.5646e-12,\n            1.4972e-12, 2.0432e-13, 1.5437e-12, 7.3443e-13, 1.9203e-12, 2.6394e-12,\n            8.4381e-13, 2.0521e-12, 8.1299e-13, 1.1953e-12, 1.4138e-12, 1.6868e-12,\n            8.3636e-13, 2.2229e-12, 1.1859e-12, 1.2141e-12, 1.2647e-12, 9.0869e-13,\n            1.6003e-12, 1.0823e-12, 9.9988e-13, 1.8503e-12, 1.6786e-12, 1.0527e-12,\n            1.4741e-12, 1.7419e-12, 1.2245e-12, 1.8493e-12, 9.5326e-13, 2.0157e-12,\n            1.3368e-12, 1.8018e-12, 1.3367e-12, 9.2481e-13, 3.9188e-13, 7.9118e-13,\n            1.0269e-12, 4.6376e-13, 2.1929e-12, 1.1562e-12, 1.7060e-12, 8.5420e-13,\n            7.1720e-13, 1.3010e-12, 2.3176e-12, 5.7368e-13, 1.3627e-12, 1.0147e-12,\n            5.1560e-13, 4.6535e-13, 1.3947e-12, 6.9908e-13, 2.8248e-12, 2.4042e-12,\n            1.0281e-12, 1.2031e-12, 1.5682e-12, 2.5269e-12, 1.8563e-12, 3.0078e-12,\n            2.2914e-12, 1.4128e-12, 1.7756e-12, 5.3051e-12, 2.2688e-12, 1.8469e-12,\n            1.8936e-12, 1.2543e-12, 1.3988e-12, 3.2197e-12, 1.3515e-12, 1.1404e-12,\n            1.9292e-12, 1.2542e-12, 2.9162e-12, 1.6665e-12, 9.4824e-13, 1.9294e-12,\n            3.9188e-12, 1.2880e-12, 4.5777e-13, 1.5532e-12, 1.3909e-12, 8.5669e-13,\n            5.0536e-13, 6.2023e-13, 7.5276e-13, 1.8861e-12, 1.8265e-12, 2.8358e-12,\n            1.2698e-12, 2.7799e-12, 5.4020e-13, 1.1432e-12, 1.1815e-12, 1.5622e-12,\n            1.6939e-12, 1.4391e-12, 2.0370e-12, 4.3608e-13, 1.3856e-12, 2.1016e-12,\n            1.1363e-12, 1.3802e-12, 3.1384e-12, 1.0890e-12, 1.0240e-12, 3.5278e-12,\n            1.6847e-12, 4.1335e-12, 1.0227e-12, 2.9428e-12, 9.0176e-13, 2.1106e-12,\n            1.2490e-12, 1.6668e-12, 1.1178e-12, 2.1100e-12, 1.4543e-12, 1.0806e-12,\n            1.2429e-12, 1.0371e-12, 1.0170e-12, 1.8846e-12, 1.7796e-12, 2.1979e-12,\n            2.5961e-12, 6.1019e-13, 1.3432e-12, 1.3408e-12, 9.0983e-13, 1.4224e-12,\n            1.1068e-12, 2.8753e-12, 3.0257e-12, 2.4343e-12, 5.0487e-13, 1.6180e-12,\n            6.9707e-13, 1.7993e-12, 1.3047e-12, 9.0638e-13, 1.6324e-12, 3.7892e-12,\n            1.6762e-12, 9.7568e-13, 2.8122e-12, 8.7320e-13, 2.3839e-12, 9.6651e-13,\n            9.8814e-13, 1.8800e-12, 1.7342e-12, 2.4349e-12, 1.7601e-12, 1.1539e-12,\n            1.0694e-12, 2.5908e-12, 6.2074e-13, 1.0637e-12, 3.2790e-12, 1.1481e-12,\n            3.4528e-12, 9.8379e-13, 9.4161e-13, 1.4323e-12, 5.8015e-13, 2.1323e-12,\n            1.4592e-12, 1.6566e-12, 1.1771e-12, 3.6338e-12, 6.5426e-13, 1.1809e-13,\n            1.8650e-12, 2.1826e-12, 1.5416e-12, 1.0619e-12, 2.8170e-12, 8.8366e-13,\n            9.9127e-13, 7.2623e-13, 5.2341e-13, 1.4616e-12, 1.8921e-12, 1.5863e-12,\n            1.8448e-12, 7.9963e-13, 7.2687e-13, 9.0360e-13, 9.4450e-13, 4.6693e-12,\n            1.3437e-12, 8.8103e-13, 3.3172e-12, 3.0634e-13, 9.2305e-13, 1.2473e-12,\n            1.3763e-12, 2.2613e-12, 1.5297e-12, 9.1728e-13, 1.4589e-12, 1.4674e-12,\n            2.3591e-12, 1.5274e-12, 1.9787e-12, 9.9960e-13, 2.1284e-12, 4.6749e-13,\n            1.2146e-12, 1.0085e-12, 9.7805e-13, 4.0993e-13, 1.5055e-12, 1.4511e-12,\n            1.3227e-12, 2.1730e-12, 1.4535e-12, 1.2141e-12, 6.7402e-13, 6.8341e-13,\n            2.0261e-12, 1.2303e-12, 1.2364e-12, 2.8534e-12, 1.1361e-12, 1.0058e-12,\n            2.2081e-12, 8.0089e-13, 1.9862e-12, 6.8998e-13, 7.9175e-13, 1.6299e-12,\n            1.0814e-12, 7.9412e-13, 1.5812e-12, 1.6348e-12, 1.1656e-12, 8.4762e-13,\n            2.3538e-12, 1.2981e-12, 1.1095e-12, 6.5377e-13, 1.0397e-12, 9.7836e-13,\n            2.2112e-12, 2.3486e-12, 9.8858e-13, 8.8004e-13, 1.5254e-12, 9.9412e-13,\n            2.4712e-12, 9.5322e-13, 1.9839e-12, 1.1485e-12, 3.0320e-12, 2.0059e-12,\n            6.9897e-13, 1.1453e-12, 2.5116e-12, 8.5495e-13, 1.7025e-12, 1.2866e-12,\n            1.0176e-12, 1.6480e-12, 3.0400e-12, 1.6476e-12, 2.3158e-12, 4.5701e-13,\n            9.0612e-13, 1.4079e-12, 5.6981e-13, 1.6095e-12, 2.4211e-12, 1.0552e-12,\n            1.0817e-12, 1.1245e-12, 1.2187e-12, 1.3863e-12, 6.5616e-13, 2.3816e-12,\n            6.1748e-13, 6.4342e-13, 1.9300e-12, 1.1205e-12, 2.0393e-12, 1.2171e-12,\n            8.9183e-13, 1.0852e-12, 1.1418e-12, 1.3617e-12, 2.3277e-12, 3.9964e-12,\n            2.1106e-12, 9.6925e-13, 1.9435e-12, 2.5529e-12, 1.8416e-12, 1.4354e-12,\n            9.4491e-13, 1.0466e-12, 2.2893e-12, 3.2019e-12, 4.7858e-12, 3.7103e-12,\n            2.3142e-12, 1.2545e-12, 9.5600e-13, 1.1914e-12, 5.6131e-13, 1.4821e-12,\n            1.0079e-12, 5.7637e-13, 7.4362e-13, 3.5996e-13, 1.6950e-12, 1.0004e-12,\n            1.4880e-12, 1.6849e-12, 1.2392e-12, 1.9645e-12, 1.1680e-12, 1.5856e-12,\n            2.0393e-12, 1.6111e-12])},\n   41: {'exp_avg': tensor([-6.1519e-08,  2.3747e-07, -1.1333e-07, -1.4310e-07,  4.4875e-08,\n            -4.7880e-08,  8.7749e-08, -2.0097e-07,  5.9278e-09, -5.5461e-08,\n            -3.3113e-08, -1.2326e-07,  6.3235e-08,  8.3820e-09,  3.0345e-07,\n             8.7214e-09, -9.7490e-08, -1.7486e-07, -3.1450e-07,  7.7676e-08,\n             1.4946e-07,  1.4591e-08, -4.1910e-08,  3.8979e-08, -5.0678e-08,\n            -1.6383e-07, -8.1519e-08, -8.5405e-08,  1.1941e-08, -1.2605e-07,\n             5.6531e-08, -6.2312e-08, -2.7223e-07, -1.0082e-08, -8.8391e-08,\n            -7.8354e-09, -5.2392e-08,  1.0048e-07, -3.4384e-08, -1.5939e-08,\n             5.8964e-08,  8.1082e-08,  3.9993e-08,  8.5209e-09, -4.8787e-09,\n            -3.8866e-08, -6.3352e-08,  9.9790e-08, -2.8620e-08,  1.2626e-07,\n             8.2284e-08, -2.3272e-09, -2.7830e-07, -5.8830e-08, -2.7601e-08,\n             2.7037e-07, -2.4783e-08,  2.8785e-08,  2.0605e-09, -4.4886e-08,\n             1.4239e-07, -4.2575e-10,  2.6041e-08, -8.7188e-08, -4.8710e-08,\n            -1.2864e-07,  7.8634e-08,  3.5202e-08, -3.7641e-08,  1.6492e-07,\n             5.3520e-08, -1.4453e-07,  7.2907e-08, -1.1509e-08,  2.4641e-09,\n             1.4425e-07, -1.1801e-07,  7.7905e-08, -8.8515e-09,  6.9610e-08,\n             1.3969e-07, -3.1678e-07,  1.5001e-08,  1.3846e-08,  6.3744e-08,\n            -1.2594e-07,  9.3875e-09, -1.4647e-07,  1.9312e-07,  3.9117e-08,\n            -9.1441e-08, -4.6500e-09, -7.2082e-08,  9.1123e-08, -1.3867e-07,\n            -5.0837e-09, -1.8631e-08,  9.3541e-08, -8.3206e-08,  1.9915e-08,\n            -8.4149e-08, -1.3284e-08, -5.6596e-08,  7.9524e-08, -2.4474e-08,\n             6.1244e-08,  1.2158e-07,  1.5471e-07,  2.6866e-09, -1.9617e-07,\n            -4.6140e-07, -2.0407e-08, -4.7635e-08,  6.6013e-08, -3.8227e-08,\n             1.0343e-07, -5.8644e-08, -1.6707e-08, -7.8717e-08, -7.0032e-08,\n             1.2592e-08, -8.6053e-08,  1.0671e-07,  1.1559e-07,  4.5264e-08,\n            -3.0430e-08,  2.9404e-08,  1.9427e-07,  1.0625e-07,  6.5800e-08,\n            -1.1457e-07,  4.9517e-08, -1.0009e-08,  7.3604e-08, -4.0382e-08,\n            -1.4548e-09, -8.9462e-09, -3.1662e-08,  1.3183e-07,  8.5677e-08,\n             8.5253e-08, -5.3985e-08, -5.8095e-08,  5.8580e-08,  2.7053e-08,\n            -1.0972e-07, -1.1323e-07,  3.1244e-08, -4.4241e-08, -1.2032e-07,\n             1.4022e-07, -2.2496e-08,  3.8995e-08,  1.6221e-07, -8.2054e-08,\n            -8.6053e-08, -1.6957e-07,  1.0329e-08, -7.2116e-09, -2.8534e-07,\n            -1.4663e-07, -8.8820e-08, -1.7419e-07, -6.8509e-08, -4.7700e-08,\n            -8.6937e-08, -6.6359e-08, -9.9010e-08,  1.0980e-08,  9.9255e-08,\n             1.2545e-07, -1.3279e-07, -9.1012e-08,  4.7468e-08,  3.9363e-08,\n             3.6915e-08, -3.9556e-08,  2.8799e-08, -1.9017e-07, -9.6999e-08,\n             2.0883e-07, -1.4539e-07,  8.2697e-08, -1.2249e-07, -8.3204e-08,\n            -1.1697e-09,  1.6087e-09, -8.8550e-08, -6.6954e-09,  2.2181e-07,\n             1.1463e-07, -2.5934e-08, -1.6118e-07, -1.6254e-07, -9.5467e-09,\n            -6.2513e-08,  1.4364e-07, -2.0557e-07, -1.3070e-07,  6.3780e-08,\n             4.4466e-08,  3.3096e-07, -1.8856e-07, -1.1999e-07,  1.6926e-07,\n            -1.4390e-07,  1.9444e-07,  3.7166e-08,  5.8052e-08, -6.0695e-08,\n            -3.4689e-07, -1.3219e-07,  8.7315e-08,  5.6737e-08, -1.3368e-07,\n            -9.7973e-09,  1.6410e-07,  4.7057e-08, -9.7800e-08, -2.1560e-08,\n            -1.4739e-07,  2.3704e-08,  4.8674e-08,  7.8826e-08,  2.5919e-07,\n             6.0868e-09, -1.6337e-07,  2.2186e-07, -2.7458e-07,  6.8242e-08,\n            -4.8171e-08,  1.7774e-08, -4.9852e-08,  1.0141e-07, -7.8223e-08,\n            -3.6320e-08, -2.0315e-07,  2.6465e-08, -5.8377e-08, -1.5543e-07,\n            -3.0055e-08, -1.2318e-07,  1.1350e-07, -1.0010e-07, -5.5971e-08,\n             4.2478e-08,  9.9826e-08, -2.3351e-08,  1.3726e-07,  6.7744e-08,\n             2.0670e-08, -5.1411e-09,  5.3000e-08,  1.1613e-07,  2.4898e-07,\n             3.4648e-08, -1.4307e-08,  7.4572e-08,  4.9063e-08, -6.3120e-08,\n            -1.1200e-07, -3.6111e-08, -9.3033e-08, -2.8997e-10, -9.4943e-08,\n             1.5202e-08, -1.8905e-08,  1.3712e-07, -1.9087e-07,  1.1358e-07,\n             1.1528e-07,  1.5767e-07,  1.8972e-07, -2.0191e-07,  9.5819e-08,\n             1.1388e-07, -4.6843e-08,  1.6723e-07,  1.6200e-07,  2.5667e-08,\n             7.8134e-08, -8.2032e-08, -6.6006e-08, -1.6249e-07, -1.8279e-07,\n             2.8611e-09, -1.1528e-07,  3.1548e-07, -8.2577e-08, -8.3117e-08,\n            -7.8209e-08,  1.2976e-07, -1.5597e-07,  6.9910e-08,  7.1984e-08,\n            -2.5496e-07, -2.6571e-07, -2.2937e-08,  6.5413e-08, -2.5865e-08,\n             1.0338e-07, -2.5708e-08,  4.7615e-07,  1.1149e-07, -6.0859e-08,\n             1.8951e-07, -4.1050e-08,  1.7980e-07, -2.0048e-08,  9.0288e-08,\n            -1.3028e-07, -1.2909e-07, -6.1429e-08,  9.2122e-08, -1.3051e-07,\n            -3.6676e-08,  1.0479e-07, -4.4318e-08, -1.8057e-07,  9.7354e-08,\n            -8.2647e-08,  1.7362e-07, -4.6547e-07,  1.4970e-07, -9.0725e-08,\n             3.4659e-07, -4.0101e-08,  4.3363e-08, -3.0878e-08,  9.9185e-08,\n             1.8046e-09,  1.2761e-07,  9.7031e-08,  2.8004e-08, -3.5497e-09,\n             1.4350e-07,  4.3882e-09, -2.7123e-07, -2.5193e-07, -4.2144e-08,\n             2.5766e-08,  2.4251e-07, -7.1248e-09, -8.2718e-08,  6.9021e-08,\n            -8.7028e-08,  4.9269e-09,  6.1026e-08,  4.2674e-08, -2.6367e-07,\n            -4.0911e-08, -7.1411e-08, -2.4717e-07,  1.7506e-08, -3.8304e-08,\n             2.7441e-07, -1.3714e-08,  2.1608e-09, -8.1233e-08,  2.1701e-07,\n             4.2684e-08,  2.1318e-07, -2.0812e-07,  3.0824e-07,  1.3694e-08,\n             4.5135e-08, -2.1711e-08, -5.9589e-08,  9.6348e-08, -1.7078e-07,\n            -9.1976e-08,  6.7870e-08, -6.0655e-08, -3.5352e-07, -3.2937e-07,\n            -4.8909e-08,  4.0214e-09, -6.8112e-08, -2.4504e-08, -9.0454e-08,\n             4.1802e-08,  1.1459e-07, -1.9031e-08,  1.5614e-07,  1.3964e-08,\n            -1.1892e-07,  1.0424e-09, -2.0681e-08,  8.0772e-08,  1.8564e-07,\n             1.0163e-07, -1.3474e-07,  1.6211e-08, -8.7039e-08,  5.3564e-09,\n             6.0387e-08, -2.7813e-07, -8.9761e-08, -1.1456e-07, -1.1882e-07,\n            -1.8833e-08, -1.7001e-07, -5.4504e-08,  8.6575e-08, -1.4982e-07,\n            -1.8997e-08, -3.4109e-08,  4.4398e-07, -1.3452e-07, -9.8225e-08,\n             3.6700e-08, -6.9040e-08, -5.3568e-09, -5.4959e-08, -8.7766e-08,\n             6.1871e-08, -3.3785e-08, -1.3878e-07,  3.4717e-07, -1.4221e-08,\n             1.5944e-08,  9.2121e-08, -1.6363e-07,  3.4928e-08,  2.1241e-08,\n            -1.6947e-08, -9.4809e-08, -1.8265e-08,  1.0067e-07,  7.4290e-08,\n            -3.5647e-09,  3.9761e-08,  4.0907e-08,  1.8575e-08,  2.5714e-07,\n            -9.4339e-08,  1.3363e-07,  1.0789e-08, -1.9925e-08, -1.3022e-07,\n             6.0197e-08,  2.6825e-09,  5.3660e-08, -2.3252e-08, -3.1825e-07,\n             7.4492e-08, -1.1257e-07,  4.9350e-08,  1.1151e-08, -4.0786e-08,\n             1.6270e-07, -8.8056e-08, -1.1398e-07,  9.8724e-08,  1.1320e-07,\n            -7.0985e-08,  4.8700e-08, -1.0609e-07,  1.2337e-07,  1.2717e-07,\n            -2.2961e-08,  1.3238e-07,  2.7750e-08, -4.3491e-10,  5.1795e-08,\n             3.7910e-07,  5.3949e-08, -2.0016e-07,  1.9338e-08,  1.4838e-07,\n             3.0403e-08, -3.8171e-08,  1.4154e-07,  1.1686e-07, -1.2364e-07,\n            -5.5160e-08, -3.3405e-07, -2.4013e-07, -2.7199e-07, -3.1196e-08,\n            -1.8574e-09,  9.9699e-08,  8.6483e-08, -1.3955e-08,  6.5532e-08,\n            -2.7383e-07, -8.0342e-08,  6.5441e-08,  1.4719e-07,  5.2358e-08,\n            -1.0823e-07, -9.3188e-08, -4.1940e-08, -7.5878e-08, -1.3498e-07,\n             7.8741e-09, -2.2896e-07, -8.5559e-08,  1.8794e-10,  6.3410e-08,\n             9.9784e-09,  4.8943e-09,  1.3160e-07,  5.3444e-08, -4.9059e-08,\n             1.8308e-07, -5.2732e-08,  7.9365e-08, -9.7015e-08, -4.9200e-09,\n            -2.4389e-08,  3.5358e-08]),\n    'exp_avg_sq': tensor([2.7814e-13, 5.8168e-13, 8.2109e-14, 8.8264e-13, 1.1384e-13, 3.3029e-13,\n            3.6715e-13, 2.5049e-13, 4.8303e-13, 1.8998e-13, 7.5389e-14, 4.1173e-13,\n            1.0024e-13, 3.1863e-13, 5.2110e-13, 2.1426e-13, 2.6466e-12, 2.2823e-13,\n            6.6464e-13, 3.8615e-13, 7.3582e-13, 2.6259e-13, 2.8141e-14, 3.5301e-13,\n            5.2318e-13, 2.1352e-13, 1.3874e-13, 8.8835e-14, 4.7636e-14, 3.4325e-13,\n            4.1766e-13, 9.7431e-14, 2.4032e-13, 5.2793e-13, 6.4554e-14, 7.6958e-15,\n            3.4850e-14, 2.3806e-13, 3.0299e-13, 5.1993e-13, 1.6269e-13, 6.9807e-13,\n            1.4477e-13, 1.8270e-13, 3.6973e-14, 4.5426e-13, 1.8139e-13, 3.4363e-13,\n            2.3219e-13, 3.8261e-13, 1.0096e-13, 1.8859e-13, 4.8704e-13, 4.1776e-13,\n            3.9850e-13, 3.1503e-13, 4.6365e-14, 1.5584e-13, 2.4718e-13, 3.4409e-13,\n            3.9397e-13, 1.5136e-13, 1.9455e-13, 4.1016e-13, 1.2812e-13, 5.1812e-13,\n            3.3413e-13, 3.2492e-13, 2.2659e-13, 2.4560e-13, 2.9089e-13, 2.7675e-13,\n            3.1898e-13, 6.5872e-14, 8.3520e-14, 1.4129e-13, 3.9061e-13, 2.2314e-13,\n            1.2896e-13, 1.2272e-13, 6.3354e-13, 3.0696e-13, 7.2528e-14, 2.9254e-13,\n            2.9269e-13, 2.0726e-13, 4.4818e-14, 2.5009e-13, 4.9318e-13, 3.3837e-14,\n            3.7310e-13, 2.2644e-13, 1.3005e-13, 7.7376e-14, 2.1390e-13, 3.5887e-13,\n            1.3146e-13, 2.5089e-13, 3.6285e-13, 3.6220e-14, 6.1306e-13, 2.5273e-13,\n            1.4959e-13, 2.5344e-13, 2.8325e-13, 1.2451e-13, 3.9100e-13, 2.8847e-13,\n            4.8937e-13, 3.4596e-13, 1.2342e-12, 3.2355e-13, 2.6878e-13, 1.8037e-13,\n            4.7553e-13, 1.8198e-13, 1.3604e-14, 5.5017e-13, 6.1815e-13, 1.0673e-13,\n            3.6403e-13, 6.4496e-13, 2.6236e-13, 3.0039e-13, 1.9697e-13, 3.2080e-13,\n            5.4573e-14, 2.6401e-13, 3.0894e-13, 2.7005e-13, 2.7762e-13, 5.0831e-13,\n            3.9269e-13, 9.1090e-14, 1.1363e-13, 2.7223e-14, 2.1411e-13, 2.3007e-13,\n            2.3626e-13, 7.8437e-14, 9.7104e-14, 2.1893e-13, 2.7736e-13, 1.5562e-13,\n            4.2375e-13, 5.4248e-13, 2.7458e-13, 3.3976e-14, 2.1432e-13, 6.3244e-13,\n            1.6123e-13, 1.6047e-13, 1.4834e-13, 2.7052e-13, 8.2754e-14, 5.0805e-14,\n            2.1138e-13, 7.3690e-14, 1.3682e-14, 2.8135e-13, 6.7426e-13, 4.8696e-13,\n            1.8419e-13, 2.4832e-13, 3.4563e-13, 1.4636e-13, 4.2567e-13, 2.3013e-13,\n            1.1600e-13, 2.9302e-13, 3.2015e-13, 1.3533e-13, 7.4548e-14, 3.8811e-13,\n            2.7635e-13, 2.2151e-13, 5.4118e-14, 1.5737e-13, 6.2935e-13, 3.8833e-13,\n            3.0557e-13, 5.0745e-13, 3.2246e-13, 6.8757e-13, 3.0902e-13, 7.1636e-14,\n            3.3132e-14, 1.9840e-13, 8.5633e-14, 4.6750e-13, 1.4438e-13, 6.7232e-15,\n            1.3435e-13, 7.8053e-14, 2.7107e-14, 7.0108e-14, 4.1392e-13, 5.8492e-13,\n            2.0355e-13, 4.3600e-13, 1.5988e-13, 5.3098e-13, 2.5041e-13, 1.8205e-13,\n            8.2493e-13, 4.6442e-13, 4.0143e-13, 4.0501e-14, 1.7877e-13, 1.5832e-13,\n            3.8556e-13, 3.8756e-13, 4.4736e-13, 1.3584e-13, 2.3914e-13, 1.9891e-13,\n            2.0678e-13, 2.0034e-13, 2.3192e-13, 1.6081e-13, 2.0876e-13, 1.0757e-13,\n            3.5710e-13, 3.2023e-13, 7.1414e-13, 2.0136e-13, 3.5678e-13, 3.7266e-13,\n            3.0043e-13, 1.9772e-13, 2.2111e-13, 2.4965e-13, 3.1391e-13, 3.3986e-13,\n            2.4108e-13, 3.1450e-13, 8.4928e-13, 1.9360e-13, 6.6441e-13, 4.9518e-13,\n            5.2862e-13, 2.2405e-13, 2.8727e-13, 1.1671e-13, 2.3797e-13, 3.1272e-14,\n            3.0890e-13, 4.8145e-13, 3.5312e-13, 3.8221e-13, 8.9281e-14, 1.6723e-13,\n            6.5805e-14, 3.6404e-13, 1.9291e-13, 1.7131e-14, 1.8768e-13, 4.6306e-13,\n            2.5679e-14, 1.6231e-13, 4.1882e-13, 7.5373e-14, 2.1949e-13, 1.2992e-14,\n            1.8002e-13, 3.9878e-13, 2.8660e-13, 4.3027e-13, 2.4436e-13, 4.2706e-13,\n            4.2305e-13, 3.3306e-13, 4.0682e-13, 1.7977e-13, 1.9163e-13, 4.3151e-14,\n            1.3755e-13, 1.3549e-13, 2.8827e-13, 1.1157e-13, 3.2681e-13, 1.1413e-13,\n            4.0111e-14, 6.2891e-13, 1.7220e-13, 2.5740e-13, 2.7089e-13, 3.9730e-13,\n            1.5300e-13, 4.7742e-14, 6.6925e-13, 3.6431e-13, 3.2529e-13, 2.9892e-13,\n            1.8325e-13, 2.9341e-13, 4.0577e-13, 1.2920e-13, 8.3050e-14, 1.0619e-13,\n            4.6739e-13, 3.1798e-13, 4.4870e-13, 1.4851e-13, 8.9150e-14, 3.9318e-13,\n            2.6357e-13, 2.2019e-13, 2.4872e-13, 1.1999e-13, 1.6826e-13, 7.2970e-13,\n            1.4929e-13, 2.0683e-13, 1.7198e-13, 9.6986e-14, 3.6617e-13, 9.6940e-14,\n            2.0588e-13, 3.4854e-13, 3.0620e-13, 3.0276e-13, 3.0225e-13, 3.6028e-13,\n            2.5576e-13, 2.5940e-13, 7.1589e-14, 1.1070e-13, 8.7927e-14, 7.9967e-14,\n            5.8607e-14, 4.8101e-13, 2.6297e-13, 6.2823e-14, 1.1198e-13, 4.2905e-13,\n            3.8542e-13, 6.5765e-13, 9.8003e-13, 5.3675e-14, 2.9321e-14, 3.6179e-13,\n            3.8991e-13, 2.6749e-13, 2.5128e-13, 1.3271e-13, 6.4519e-14, 2.6694e-13,\n            3.5539e-13, 3.6170e-13, 4.7944e-13, 9.1590e-14, 2.4475e-13, 5.4481e-14,\n            1.0619e-13, 8.0962e-13, 2.5639e-13, 4.5115e-13, 2.8610e-13, 1.6944e-13,\n            9.7227e-14, 4.5299e-13, 5.4744e-13, 5.1224e-13, 6.9879e-13, 2.6563e-13,\n            7.4544e-14, 3.3517e-13, 3.3417e-13, 4.3016e-13, 1.4930e-13, 4.3568e-13,\n            3.5339e-13, 3.6223e-13, 5.2010e-13, 1.8782e-13, 1.5825e-13, 2.7914e-13,\n            1.9742e-13, 1.3359e-13, 6.0295e-14, 1.7628e-13, 3.2611e-13, 1.7621e-13,\n            1.5475e-13, 6.4112e-14, 4.8319e-14, 2.2686e-13, 3.8014e-13, 6.4412e-13,\n            5.9301e-13, 1.1546e-13, 5.4256e-14, 4.0662e-13, 2.8903e-13, 3.3394e-13,\n            2.9780e-13, 3.4455e-14, 4.3753e-13, 2.5401e-13, 2.5759e-13, 3.7110e-13,\n            3.8099e-13, 4.8553e-13, 3.9324e-13, 3.6696e-13, 2.5923e-13, 4.2795e-13,\n            4.7889e-13, 6.2269e-13, 1.5451e-13, 2.0350e-13, 2.7822e-13, 1.9298e-13,\n            2.0500e-13, 7.3576e-14, 3.4784e-14, 4.0215e-13, 3.6038e-13, 2.1745e-13,\n            1.9611e-13, 2.3716e-13, 9.3494e-13, 5.8593e-13, 2.9858e-13, 3.6813e-13,\n            1.2729e-12, 3.5711e-13, 3.8561e-13, 2.7876e-13, 3.2476e-13, 3.9162e-13,\n            1.0328e-13, 7.8028e-14, 3.9397e-13, 2.0936e-13, 1.2401e-13, 3.7756e-13,\n            5.9467e-14, 5.0753e-13, 2.4651e-13, 2.2718e-13, 6.5674e-13, 7.4657e-14,\n            3.8989e-13, 4.1685e-13, 1.1581e-13, 2.6474e-13, 1.3482e-13, 3.8548e-13,\n            3.4886e-13, 1.7525e-13, 1.2561e-13, 3.8146e-13, 5.6850e-13, 3.6347e-13,\n            3.3119e-13, 4.0204e-13, 2.0610e-13, 3.2997e-13, 4.2472e-13, 3.6900e-13,\n            2.8112e-13, 5.1394e-13, 4.4217e-13, 4.8746e-13, 3.6109e-13, 2.9941e-13,\n            3.3106e-13, 3.7914e-13, 1.5957e-13, 1.9551e-13, 4.1110e-13, 1.1054e-13,\n            2.7688e-13, 1.6175e-13, 2.8450e-13, 4.3170e-13, 3.9167e-13, 1.0768e-13,\n            3.8883e-14, 5.2888e-13, 3.9842e-13, 1.5174e-13, 5.7632e-13, 8.4541e-13,\n            4.4242e-13, 2.8874e-13, 3.1693e-13, 3.7164e-13, 6.0518e-13, 2.7195e-13,\n            7.6335e-14, 2.1387e-13, 2.8610e-13, 3.1276e-13, 2.6394e-13, 5.7557e-13,\n            5.6612e-13, 2.8168e-13, 2.6510e-13, 2.6118e-13, 6.0627e-13, 5.5136e-13,\n            1.6955e-13, 2.7606e-13, 2.9454e-13, 4.6653e-13, 2.5604e-13, 1.8088e-13,\n            6.8479e-13, 4.9890e-14])},\n   42: {'exp_avg': tensor([-2.1309e-07, -9.3797e-08,  2.4218e-08, -1.3535e-07, -4.1127e-07,\n            -8.2662e-09,  1.1323e-07,  2.6255e-07, -3.5598e-08,  1.5920e-07,\n             9.1564e-08, -2.4514e-08,  3.7415e-07, -8.9990e-08,  1.3873e-07,\n             6.1738e-07, -1.2460e-07,  2.7745e-07,  1.2411e-07, -2.1178e-07,\n             7.3204e-08, -4.9117e-07, -1.4122e-07, -1.0282e-07,  9.2727e-08,\n             3.6841e-08, -3.3882e-07, -1.1874e-07,  4.7324e-08, -2.4296e-07,\n            -3.2006e-08,  1.8583e-07, -1.3879e-07, -1.1994e-07, -2.1604e-09,\n            -4.4718e-08,  2.6453e-07,  9.4202e-08, -6.4356e-08,  4.7601e-08,\n            -5.4365e-07,  1.0204e-08, -1.6092e-08, -5.2666e-08, -1.7068e-07,\n             7.1797e-08,  1.2046e-07,  3.0724e-07, -3.9250e-08, -7.8910e-08,\n             1.1814e-07,  5.2986e-08,  2.1577e-07,  8.2616e-08, -1.2034e-07,\n             2.1540e-08, -2.8050e-08, -2.9470e-07, -3.1435e-07,  1.1883e-07,\n             1.0122e-07,  9.6796e-08,  3.5337e-07,  3.9065e-07,  3.7865e-07,\n            -2.9589e-07, -2.9905e-08,  4.5993e-07, -2.6029e-07,  8.7802e-08,\n             2.2806e-07, -2.1911e-07, -1.1229e-07, -1.8532e-07,  3.7077e-08,\n            -2.7854e-07,  1.2440e-07,  9.3959e-08,  1.6966e-08, -7.4683e-09,\n             1.8484e-08, -5.2918e-08, -1.5124e-07, -7.1867e-08,  3.5961e-07,\n             2.3285e-07, -1.1704e-07, -1.5957e-07,  2.1118e-08,  4.4915e-08,\n             6.0410e-08,  4.8974e-07, -1.2030e-07, -7.4280e-08,  2.2376e-08,\n            -5.6668e-08,  4.4203e-07, -1.6031e-07,  1.7149e-07, -1.9101e-07,\n             3.8571e-08,  8.7281e-08,  1.2592e-07, -5.8527e-08, -4.5651e-08,\n            -2.0864e-07, -4.9828e-08, -1.2987e-09, -3.8972e-07, -2.7865e-08,\n             1.1118e-07, -4.5033e-08,  6.3261e-08,  2.6989e-07, -1.8122e-07,\n            -3.3595e-07, -3.1466e-07, -2.2183e-07,  1.8301e-07,  2.7225e-07,\n            -6.5820e-08, -1.2828e-07, -6.3039e-08,  3.9752e-08, -1.3878e-07,\n             3.2436e-07, -2.1704e-07, -1.7942e-07]),\n    'exp_avg_sq': tensor([7.0615e-13, 1.1582e-12, 2.0719e-13, 4.8459e-13, 8.2030e-13, 8.0109e-13,\n            1.1772e-12, 4.5425e-13, 4.6050e-13, 4.7469e-13, 3.2639e-13, 2.9702e-13,\n            7.6130e-13, 7.2929e-13, 4.6160e-13, 9.2448e-13, 1.3833e-12, 9.6879e-13,\n            4.7184e-13, 4.0505e-13, 4.4094e-13, 5.0181e-13, 5.8567e-13, 5.7892e-13,\n            5.9282e-13, 3.8383e-13, 2.9668e-13, 3.9193e-13, 7.9936e-13, 9.9790e-13,\n            7.5823e-13, 2.8493e-13, 4.4304e-13, 7.7064e-13, 3.9054e-13, 5.7274e-13,\n            9.2540e-13, 7.5357e-13, 4.8197e-13, 3.7259e-13, 6.9680e-13, 4.6753e-13,\n            5.2313e-13, 7.9857e-13, 8.0687e-13, 7.1910e-13, 2.7251e-13, 5.8062e-13,\n            3.5113e-13, 7.7827e-13, 6.7065e-13, 2.0009e-12, 9.6238e-13, 6.0487e-13,\n            7.3158e-13, 4.0899e-13, 3.4415e-13, 1.8993e-12, 8.6956e-13, 9.0205e-13,\n            3.7388e-13, 1.9018e-13, 9.1116e-13, 1.4387e-12, 5.8119e-13, 6.3388e-13,\n            2.5842e-13, 6.5539e-13, 1.4952e-12, 5.6039e-13, 4.0458e-13, 6.7302e-13,\n            6.5034e-13, 1.5649e-12, 3.7471e-13, 8.7169e-13, 8.0953e-13, 4.2068e-13,\n            8.0153e-13, 7.8623e-13, 5.0762e-13, 5.5081e-13, 4.3544e-13, 2.4333e-12,\n            6.4521e-13, 5.6181e-13, 4.6085e-13, 3.9516e-13, 6.9566e-13, 8.9909e-13,\n            4.7379e-13, 6.9958e-13, 7.9589e-13, 6.9436e-13, 5.0189e-13, 3.8560e-13,\n            7.3072e-13, 7.2917e-13, 4.4487e-13, 2.5647e-13, 5.0649e-13, 3.6131e-13,\n            7.2877e-13, 2.1856e-13, 7.4376e-13, 9.3995e-13, 5.7929e-13, 4.4707e-13,\n            1.1577e-12, 4.1334e-13, 7.4424e-13, 3.6843e-13, 1.0339e-12, 1.1512e-12,\n            6.9085e-13, 4.8833e-13, 7.7835e-13, 6.1743e-13, 1.1232e-12, 3.8282e-13,\n            5.6653e-13, 5.5759e-13, 2.6867e-13, 5.1623e-13, 4.2485e-13, 9.0224e-13,\n            3.5344e-13, 7.0388e-13])},\n   43: {'exp_avg': tensor([-2.0774e-07, -1.1802e-07,  1.0414e-07, -2.0653e-07, -3.7713e-07,\n            -8.7851e-08, -2.9693e-08,  2.9708e-07,  1.5261e-07,  1.0438e-07,\n             1.0471e-07, -1.6870e-07,  1.4162e-07, -3.7900e-08,  6.0635e-08,\n             2.5577e-07, -1.8617e-07,  2.5964e-07,  2.2917e-08, -2.6334e-07,\n             6.6069e-08, -3.9316e-07,  1.1753e-07, -2.0569e-07,  1.0056e-07,\n             3.1924e-08, -4.1632e-07,  5.9259e-08,  5.1064e-08, -2.4554e-07,\n            -1.6095e-07, -9.3865e-08,  1.3719e-07,  7.0654e-09,  6.3216e-08,\n            -1.3005e-07,  3.2036e-07,  8.3460e-10, -5.6339e-09,  3.7968e-08,\n            -3.7307e-07, -2.3553e-09, -1.7391e-07, -3.4972e-08, -3.2376e-07,\n            -9.2702e-08,  1.0108e-08,  3.5085e-07, -1.2298e-07, -1.4197e-07,\n             2.6901e-07,  1.0653e-07,  3.4363e-07,  7.4413e-08, -2.0065e-07,\n             5.8065e-09, -5.9590e-08, -4.4636e-07, -2.3419e-07, -7.5784e-08,\n             2.3155e-07,  1.4794e-07,  1.2106e-07,  2.7470e-07,  4.7466e-07,\n            -1.7225e-07, -8.4445e-08,  2.7699e-07, -1.1511e-07,  3.3269e-07,\n             3.3668e-08, -1.1477e-07, -2.6713e-07, -3.2865e-07,  1.4300e-08,\n            -2.2559e-07, -1.4934e-08, -3.8759e-10,  7.8181e-08, -1.2759e-07,\n            -2.6137e-08, -1.0438e-07, -4.7751e-08, -6.2101e-08,  2.4741e-07,\n             1.9280e-07, -1.3746e-07, -2.0207e-07,  4.5633e-08,  1.8689e-07,\n            -6.6463e-08,  4.0957e-07, -8.1106e-09,  5.9539e-08,  2.9858e-08,\n            -1.4614e-07,  2.5862e-07, -1.0432e-07,  2.5211e-07, -3.6545e-07,\n            -2.2524e-08, -1.4309e-07,  6.7496e-08,  6.1396e-08, -1.6374e-07,\n            -3.3459e-08, -2.4487e-08, -5.8390e-09, -9.2761e-08, -1.1375e-07,\n            -1.0461e-07, -1.0525e-07,  1.5281e-07,  6.5922e-08, -1.3057e-07,\n            -3.8379e-07, -3.1535e-07, -1.9364e-07,  1.2778e-07,  5.0984e-08,\n            -3.3039e-08, -2.1310e-08,  7.5769e-08,  7.1323e-08, -6.0652e-08,\n             2.7422e-07, -2.4296e-07, -1.4367e-07]),\n    'exp_avg_sq': tensor([7.5707e-13, 8.0590e-13, 3.5044e-13, 6.3026e-13, 5.9579e-13, 5.3374e-13,\n            7.1138e-13, 4.0643e-13, 5.4890e-13, 4.3725e-13, 3.5561e-13, 4.7469e-13,\n            6.5019e-13, 4.4280e-13, 3.5878e-13, 5.3574e-13, 1.2098e-12, 5.6920e-13,\n            3.6043e-13, 5.7280e-13, 6.9742e-13, 3.3558e-13, 4.9468e-13, 3.9972e-13,\n            7.1889e-13, 2.9404e-13, 3.4695e-13, 5.4086e-13, 6.4224e-13, 6.2320e-13,\n            4.7871e-13, 3.7807e-13, 3.4580e-13, 4.1109e-13, 7.5123e-13, 4.3747e-13,\n            5.5073e-13, 4.9983e-13, 3.8997e-13, 4.1967e-13, 4.6186e-13, 3.9518e-13,\n            3.7345e-13, 1.6823e-12, 6.2568e-13, 6.6147e-13, 2.9196e-13, 8.0153e-13,\n            3.8854e-13, 5.5843e-13, 1.6876e-12, 5.7239e-13, 6.0514e-13, 5.5973e-13,\n            5.9789e-13, 4.8048e-13, 4.1406e-13, 1.7973e-12, 7.0937e-13, 4.6092e-13,\n            4.6190e-13, 3.4295e-13, 4.4871e-13, 8.7311e-13, 5.4805e-13, 7.0405e-13,\n            3.6528e-13, 6.0820e-13, 7.4803e-13, 1.5545e-12, 4.3006e-13, 6.9422e-13,\n            5.6943e-13, 7.1851e-13, 4.3640e-13, 5.5145e-13, 6.4135e-13, 2.9130e-13,\n            4.4340e-13, 5.0153e-13, 3.9834e-13, 6.8090e-13, 3.0634e-13, 1.2831e-12,\n            6.2727e-13, 5.6426e-13, 4.1300e-13, 4.9255e-13, 5.8874e-13, 5.4320e-13,\n            4.1444e-13, 5.2955e-13, 5.8124e-13, 4.7875e-13, 5.8402e-13, 4.4714e-13,\n            5.4492e-13, 6.5158e-13, 3.9284e-13, 3.5247e-13, 4.2317e-13, 4.3909e-13,\n            6.0528e-13, 4.8822e-13, 5.1036e-13, 7.3042e-13, 4.4832e-13, 5.8750e-13,\n            4.6374e-13, 3.4085e-13, 4.9946e-13, 6.9003e-13, 8.0460e-13, 5.2426e-13,\n            5.2626e-13, 1.1008e-12, 5.4033e-13, 4.1171e-13, 8.3330e-13, 3.3411e-13,\n            5.0884e-13, 7.9796e-13, 6.1635e-13, 1.0966e-12, 7.5627e-13, 5.5070e-13,\n            4.9543e-13, 5.0273e-13])},\n   44: {'exp_avg': tensor([ 2.1124e-07, -8.9828e-08,  5.1578e-08,  9.2606e-09,  1.6003e-07,\n             1.4366e-07,  1.0774e-07, -7.6814e-08,  1.2501e-07, -2.7130e-07,\n             1.2750e-07,  1.2580e-07,  1.8039e-07, -2.6535e-08, -4.4797e-07,\n            -7.8950e-09,  1.1759e-07,  8.1861e-08,  7.4888e-08,  1.8522e-07,\n             3.7303e-09, -1.6275e-08,  3.7216e-07, -3.3943e-07, -3.9959e-08,\n            -4.1736e-08,  9.8881e-08, -3.1148e-08, -1.9294e-07,  6.1990e-08,\n            -1.6254e-07, -2.1779e-07, -1.9858e-07,  3.1521e-08, -1.9321e-07,\n            -2.8471e-08,  1.0274e-07,  1.6275e-09, -7.0299e-08, -1.4349e-08,\n            -1.3680e-07, -8.8856e-09,  5.1291e-08,  4.7416e-09, -3.7522e-08,\n            -6.1609e-08,  6.0196e-08,  2.9932e-08,  3.5240e-07,  1.8952e-07,\n             6.9425e-08, -1.2698e-08,  1.0742e-07,  6.7866e-08, -1.0864e-07,\n            -1.5370e-08,  6.4808e-08, -9.7686e-08,  1.5650e-07,  3.4919e-07,\n             2.0833e-07,  5.8230e-08,  2.1779e-08,  7.1805e-08,  3.3427e-07,\n            -1.5576e-07, -2.2700e-07, -1.8159e-07,  1.1405e-07, -3.3657e-07,\n            -1.6969e-07,  1.4156e-07,  7.3861e-08,  6.0217e-08, -1.2895e-07,\n            -1.4815e-07,  8.2612e-09, -2.5955e-07,  2.0077e-07,  1.4254e-08,\n            -1.5623e-07, -1.6097e-07, -9.3469e-09, -3.1700e-07, -6.7571e-08,\n            -2.5473e-07,  5.5212e-09,  3.1781e-07,  3.8107e-09,  6.3372e-08,\n             1.1995e-07, -1.0748e-08,  1.1008e-07,  1.8229e-07,  3.6313e-08,\n             2.2766e-07, -3.9415e-07, -2.2653e-07,  5.9094e-08, -6.0763e-08,\n            -1.0323e-07,  3.6198e-07, -1.4427e-07,  1.3485e-07,  8.5176e-08,\n            -3.8580e-07, -1.5761e-07, -1.8609e-07, -7.7818e-09,  1.7257e-07,\n             8.3778e-08,  7.0849e-08, -3.8820e-08, -3.7188e-08,  8.9985e-08,\n            -4.0181e-07,  1.3482e-07,  4.7599e-09,  1.0002e-07,  7.8559e-08,\n            -5.5445e-09, -1.7892e-07,  1.4554e-08,  2.3768e-08,  1.1115e-07,\n             4.1096e-08,  2.2972e-08, -1.5998e-08]),\n    'exp_avg_sq': tensor([4.2386e-13, 3.6541e-13, 3.4742e-13, 5.3577e-13, 4.7094e-13, 4.4188e-13,\n            1.6168e-12, 4.2580e-13, 4.4482e-13, 4.1280e-13, 5.0949e-13, 6.1255e-13,\n            5.9827e-13, 2.6600e-13, 1.0196e-12, 3.1264e-13, 2.5332e-13, 3.0031e-13,\n            4.4884e-13, 6.8157e-13, 4.4016e-13, 2.5313e-13, 1.5926e-12, 7.8851e-13,\n            4.4457e-13, 5.8366e-13, 5.5784e-13, 4.2933e-13, 3.0039e-13, 4.0018e-13,\n            3.9311e-13, 9.8568e-13, 4.0299e-13, 1.2286e-12, 6.0219e-13, 5.6346e-13,\n            3.5480e-13, 8.2748e-13, 5.1440e-13, 3.5074e-13, 4.0555e-13, 2.3253e-13,\n            4.9972e-13, 5.7560e-13, 5.9574e-13, 3.3113e-13, 3.4712e-13, 3.3188e-13,\n            4.2432e-13, 1.2118e-12, 5.1034e-13, 4.7680e-13, 3.7112e-13, 6.1192e-13,\n            7.7709e-13, 4.7044e-13, 3.9466e-13, 4.9554e-13, 3.3682e-13, 8.9093e-13,\n            4.5344e-13, 2.8908e-13, 9.5202e-13, 2.4936e-13, 4.4469e-13, 2.2474e-13,\n            8.6451e-13, 5.1848e-13, 8.6334e-13, 1.3767e-12, 7.9018e-13, 3.8035e-13,\n            3.7004e-13, 3.2362e-13, 6.0438e-13, 3.4036e-13, 3.8307e-13, 2.9040e-13,\n            6.0167e-13, 3.6031e-13, 6.3972e-13, 7.0809e-13, 8.9333e-13, 1.0833e-12,\n            3.4664e-13, 2.4590e-13, 9.1664e-13, 3.3942e-13, 3.1830e-13, 2.3884e-13,\n            4.5742e-13, 7.3944e-13, 5.5896e-13, 4.3000e-13, 9.8867e-13, 1.2806e-12,\n            6.0128e-13, 1.4675e-12, 4.9987e-13, 2.4450e-13, 3.0737e-13, 2.0375e-12,\n            2.6809e-12, 1.1699e-12, 5.5241e-13, 3.0013e-13, 6.8445e-13, 3.5495e-13,\n            5.5053e-13, 9.0221e-13, 4.7078e-13, 3.4616e-13, 4.3711e-13, 3.2726e-13,\n            4.2041e-13, 2.2326e-12, 4.7746e-13, 3.3079e-13, 2.7893e-13, 1.9744e-13,\n            3.8497e-13, 5.8528e-13, 1.6388e-12, 6.0521e-13, 7.7779e-13, 1.3464e-12,\n            3.8769e-13, 4.7143e-13])},\n   45: {'exp_avg': tensor([ 3.6263e-08, -8.5513e-08, -4.3111e-08,  9.8661e-08,  4.7914e-08,\n             3.4689e-08,  2.1795e-07, -7.5556e-09,  1.1500e-07, -2.4131e-07,\n            -1.1858e-07,  1.1111e-07,  1.3349e-07,  1.0281e-08, -1.7171e-07,\n            -1.3358e-08,  1.1211e-07,  1.1381e-07,  9.1900e-08,  1.2151e-07,\n             6.7821e-08, -8.6632e-08,  3.4652e-07, -1.1941e-07, -7.4020e-09,\n             4.5381e-08,  3.5447e-08, -1.1634e-07, -1.9177e-07,  6.3322e-08,\n            -9.0258e-08, -4.6634e-08, -1.1499e-07, -4.6881e-08, -4.5475e-08,\n             5.1320e-09, -3.9307e-08, -8.7529e-08, -3.2488e-08, -1.7560e-08,\n            -1.9769e-07, -8.3794e-08,  7.4972e-08, -9.2864e-09, -8.6807e-08,\n            -4.5570e-08,  1.4008e-07, -1.1534e-07,  8.0524e-08,  8.7535e-08,\n            -1.2760e-07,  3.7771e-09,  2.8035e-07, -9.9526e-08, -3.8994e-08,\n             7.7483e-08,  5.5619e-09, -9.4511e-08,  2.0303e-07, -7.8895e-09,\n             1.1804e-07,  7.2694e-08,  1.6121e-07,  5.2866e-08,  1.5607e-07,\n            -6.8536e-08, -3.3132e-07, -4.5799e-08,  1.7114e-07, -2.3628e-07,\n            -9.2393e-08,  2.0740e-07, -1.0202e-07,  7.5377e-08, -1.5701e-07,\n             5.3288e-08, -9.0647e-09, -1.7329e-07,  2.9519e-08, -4.1373e-08,\n            -2.2573e-07, -1.5120e-07, -2.3504e-08, -2.2164e-07, -2.1888e-08,\n            -1.0506e-07, -2.0826e-07,  1.8725e-07, -9.2239e-08,  3.7951e-09,\n             9.7173e-08, -3.4728e-08, -5.9073e-09,  1.3362e-07,  5.2000e-08,\n             2.6145e-07, -2.8703e-07, -1.1269e-07, -3.7339e-08, -9.6387e-08,\n            -2.4380e-07,  2.5237e-07, -5.2356e-08,  2.3076e-07,  1.2091e-07,\n            -1.8861e-07, -2.6578e-07, -8.6293e-09,  1.3885e-07,  1.4286e-07,\n            -5.7582e-08,  8.9984e-09,  1.1290e-08, -2.6123e-08,  1.8054e-07,\n            -1.8999e-07,  7.2448e-08,  5.6216e-08,  6.9941e-08, -2.7920e-08,\n            -7.5317e-08, -1.6171e-07,  1.4573e-08,  1.1429e-09,  1.5595e-07,\n             1.1331e-07, -5.8808e-08, -2.4003e-07]),\n    'exp_avg_sq': tensor([3.1125e-13, 2.1460e-13, 2.7816e-13, 2.8003e-13, 3.0649e-13, 2.8623e-13,\n            1.4301e-12, 2.9486e-13, 2.9371e-13, 3.2761e-13, 2.9039e-13, 3.7323e-13,\n            5.4074e-13, 2.4275e-13, 4.7937e-13, 1.7497e-13, 1.7206e-13, 1.9402e-13,\n            1.9009e-13, 4.1544e-13, 3.6286e-13, 2.5699e-13, 1.0253e-12, 3.0430e-13,\n            2.1548e-13, 2.4579e-13, 3.3292e-13, 3.2227e-13, 1.7751e-13, 2.9742e-13,\n            2.5262e-13, 8.1705e-13, 2.4492e-13, 7.9435e-13, 4.0292e-13, 2.8900e-13,\n            2.2413e-13, 3.7689e-13, 2.8116e-13, 2.6026e-13, 3.5696e-13, 1.7472e-13,\n            3.5843e-13, 3.9501e-13, 3.7829e-13, 2.4962e-13, 3.4387e-13, 2.0318e-13,\n            2.9686e-13, 7.0244e-13, 2.5649e-13, 3.3704e-13, 2.9404e-13, 5.1567e-13,\n            5.8273e-13, 3.0082e-13, 3.3014e-13, 3.1773e-13, 2.5110e-13, 5.0551e-13,\n            2.6406e-13, 2.2056e-13, 7.4899e-13, 1.8427e-13, 3.5722e-13, 2.0429e-13,\n            6.8222e-13, 3.9432e-13, 5.6756e-13, 6.7135e-13, 4.9174e-13, 2.2978e-13,\n            2.5210e-13, 2.6872e-13, 4.5970e-13, 1.9832e-13, 3.3169e-13, 2.3519e-13,\n            3.9715e-13, 2.9275e-13, 4.1535e-13, 3.0316e-13, 4.3545e-13, 6.4224e-13,\n            2.2065e-13, 1.8804e-13, 4.0706e-13, 2.9881e-13, 2.7645e-13, 1.8143e-13,\n            2.2856e-13, 4.6238e-13, 3.2938e-13, 2.6026e-13, 6.5013e-13, 7.3318e-13,\n            3.6893e-13, 8.3679e-13, 3.1453e-13, 1.6028e-13, 2.1148e-13, 7.5706e-13,\n            1.3505e-12, 8.5004e-13, 3.0679e-13, 1.8490e-13, 5.0390e-13, 2.7891e-13,\n            3.9031e-13, 5.1964e-13, 3.3291e-13, 2.6843e-13, 3.4416e-13, 2.3376e-13,\n            3.1354e-13, 6.3731e-13, 2.1453e-13, 1.9430e-13, 2.5564e-13, 1.8202e-13,\n            2.3227e-13, 3.7737e-13, 7.5200e-13, 3.2557e-13, 4.6629e-13, 1.1479e-12,\n            2.4419e-13, 3.5006e-13])},\n   46: {'exp_avg': tensor([ 4.2250e-07,  1.8017e-08,  1.5182e-07, -1.0353e-07, -3.0433e-07,\n            -2.0322e-08,  1.1728e-08, -2.1075e-07,  5.2174e-08,  1.1054e-07,\n             1.8221e-07, -1.3610e-07, -1.3911e-07, -3.8517e-09, -1.1606e-07,\n            -1.9855e-07,  1.6207e-07, -3.8103e-08, -1.1859e-08, -2.9612e-07,\n            -4.9980e-08, -2.8767e-08,  2.9758e-07, -2.0030e-07, -2.1253e-07,\n            -2.5025e-07, -2.3348e-07, -3.0301e-07, -5.1350e-07, -2.0568e-07,\n            -2.9956e-07,  2.4158e-07, -2.0705e-08, -2.7366e-07,  7.8393e-08,\n            -1.0037e-07,  8.8180e-08,  2.1911e-07,  3.1830e-07, -9.1127e-08,\n            -4.7237e-08, -2.4967e-07, -4.1174e-09, -4.8655e-08,  1.2970e-07,\n             4.3918e-07, -4.1985e-09, -7.3140e-08, -9.8928e-09, -1.7382e-07,\n            -1.3851e-07, -8.4776e-08, -2.0944e-07,  9.7696e-08,  7.9682e-09,\n             7.6139e-08,  2.0462e-07, -3.0535e-07, -1.6782e-07,  1.2500e-07,\n             6.8173e-09, -5.0454e-07,  3.0799e-07, -3.0637e-07, -1.4279e-07,\n             1.9323e-07,  9.1051e-08, -1.7902e-07,  3.8959e-07,  2.5774e-07,\n            -6.8831e-08,  1.2198e-07, -6.7417e-08,  1.8045e-09,  2.0954e-07,\n             7.7730e-08,  1.1865e-07,  2.8631e-08, -2.8222e-07, -2.7897e-07,\n            -1.1396e-08,  1.5495e-07, -1.6003e-07,  4.9129e-10,  1.3309e-07,\n            -3.3261e-07,  1.1290e-08,  3.4283e-08,  2.1950e-07,  2.5768e-07,\n            -4.2147e-07, -9.6046e-09, -3.1924e-08,  1.2370e-07, -5.6531e-09,\n            -4.9766e-08, -1.5699e-08, -3.8049e-07,  1.4544e-07, -4.3599e-07,\n            -1.0124e-07,  2.6831e-09,  8.2625e-09, -9.2677e-08, -2.8265e-07,\n             2.7132e-08, -4.8007e-08, -2.2948e-07, -3.8092e-08, -2.7616e-07,\n            -8.2067e-08,  3.7541e-08, -3.9779e-08, -1.1922e-07,  3.5999e-08,\n            -5.8263e-08,  1.7247e-07,  1.7846e-07, -4.2721e-08,  1.0524e-07,\n            -7.2743e-08,  9.4494e-08,  3.6935e-07, -8.3717e-08,  8.4457e-08,\n            -1.1826e-07,  1.1254e-07,  1.3163e-07,  5.9948e-07,  1.3053e-07,\n             9.8768e-08,  4.0096e-08, -1.0526e-07,  6.2330e-09,  2.2853e-08,\n             2.2965e-07,  5.4327e-08, -2.8295e-07, -9.0894e-08,  2.5468e-07,\n             2.3482e-07,  2.2073e-07,  4.6709e-07,  2.2074e-07,  3.2090e-07,\n             2.7441e-07,  2.2549e-08, -2.1451e-08, -3.6498e-08,  3.8492e-08,\n            -2.7683e-07,  2.7820e-07,  1.0234e-08, -9.9889e-08, -2.3626e-07,\n            -2.8058e-08,  3.4635e-07, -2.4314e-07,  1.8437e-07,  1.8473e-07,\n            -2.9299e-08,  2.2595e-07, -1.2929e-07,  3.5308e-09, -1.6456e-07,\n            -1.3126e-07, -1.9607e-07,  4.7033e-08, -1.3987e-07, -3.1063e-07,\n            -7.5088e-08,  2.4169e-07,  3.0599e-07,  4.1951e-08, -6.7306e-09,\n             1.1573e-08, -1.3437e-07, -3.1062e-07,  8.5920e-08, -1.6575e-07,\n            -5.0675e-08, -8.4981e-08,  3.0382e-07, -2.3862e-07,  3.4629e-07,\n            -4.7733e-08, -1.5613e-07,  9.9151e-08,  4.8699e-08, -1.0608e-09,\n             6.5609e-08,  3.9494e-07, -1.7169e-07, -7.0489e-07, -9.2918e-08,\n            -1.8477e-07, -4.7006e-09, -3.6418e-07, -1.0969e-08,  1.5175e-07,\n            -6.4395e-07, -4.9546e-07,  6.6683e-08, -1.5121e-08,  2.8775e-07,\n             7.6224e-08,  3.0341e-07,  4.1916e-08,  5.8823e-07, -1.7067e-07,\n            -2.0788e-07,  3.4480e-07, -5.7395e-08,  1.2972e-07,  3.3727e-07,\n            -4.5535e-07, -2.6840e-07, -1.2838e-07, -1.9434e-07, -3.0248e-07,\n             2.0222e-07,  1.1399e-07, -2.0313e-07, -8.0633e-08,  7.4169e-08,\n             1.0256e-07,  5.3970e-07, -1.7842e-07, -2.7149e-08,  1.7454e-07,\n            -3.2387e-08, -1.4689e-07,  1.0593e-07, -2.8810e-07,  8.9902e-08,\n             4.3543e-08, -1.3463e-07,  3.3613e-07,  4.9452e-07, -7.1417e-07,\n            -3.3724e-07, -2.0492e-07, -9.5106e-08, -2.7080e-07,  1.4680e-07,\n            -1.1649e-07,  2.8938e-07, -3.1973e-08,  2.6131e-07,  7.2075e-07,\n             3.2197e-07,  1.6807e-07,  6.3328e-08,  1.6955e-07, -3.7235e-07,\n            -1.8651e-07,  5.6583e-07, -1.0145e-07,  4.7430e-07,  3.2827e-07,\n             6.5841e-08, -5.6951e-08,  7.2417e-08, -8.9072e-08, -4.0859e-07,\n             3.6836e-08,  1.6388e-07, -1.0451e-06, -2.3181e-08,  9.0631e-08,\n             1.0994e-07, -7.7600e-08, -2.2444e-08,  1.2539e-07,  3.8063e-08,\n            -1.6351e-07,  1.8721e-07, -5.3431e-07,  3.8866e-07,  2.8948e-07,\n            -4.3506e-07, -8.9445e-08, -2.3951e-08,  2.3354e-07, -1.0403e-06,\n            -2.8283e-08, -3.1279e-07,  3.7916e-07,  2.0985e-07, -1.8448e-07,\n            -1.3771e-07, -1.7143e-07, -2.3873e-07,  1.9614e-07, -3.8703e-07,\n            -3.5128e-07, -3.4840e-07, -9.6110e-08, -1.0654e-07, -1.7385e-08,\n             5.8266e-08, -1.3124e-08,  2.2494e-07,  3.1920e-07,  3.9314e-07,\n             5.4999e-07,  2.0440e-07,  2.6389e-07,  6.5007e-09,  8.3328e-08,\n            -4.9690e-07,  4.3403e-07, -4.0987e-07, -8.8654e-08, -1.5223e-07,\n            -1.6717e-07, -2.6416e-08, -1.3991e-07, -9.4778e-08,  3.0146e-07,\n            -1.5849e-07, -4.1073e-07,  2.2927e-07,  3.3369e-07,  1.5287e-08,\n            -4.1288e-07, -3.4331e-07,  3.2069e-07, -1.4899e-07, -1.6630e-07,\n            -1.7657e-07, -1.5839e-07,  9.0708e-08,  2.7488e-07, -3.9686e-07,\n            -1.7013e-07, -7.7558e-08, -9.3109e-08,  2.2887e-07,  3.3878e-07,\n             9.0095e-07, -3.3920e-07,  8.3036e-08,  3.4059e-07, -7.8774e-10,\n            -2.2459e-07, -2.5643e-07,  2.1044e-07,  1.3530e-07, -9.1353e-08,\n            -1.2833e-07,  4.5933e-07,  4.6371e-08, -8.0622e-08,  2.1668e-07,\n             4.2712e-07,  2.5361e-09, -6.6867e-07, -6.8386e-08,  2.6598e-08,\n            -5.4778e-07, -4.2720e-08,  7.0515e-08, -1.3306e-08, -1.8990e-07,\n            -2.2364e-08, -3.8156e-08, -6.8307e-08, -2.6158e-08,  3.3943e-07,\n            -3.6286e-07,  5.5919e-08, -2.1571e-07, -2.8641e-07,  2.2437e-07,\n             3.3175e-07, -5.6972e-08, -4.5040e-07,  2.3903e-07, -9.3271e-08,\n            -2.1605e-07,  9.6260e-08, -2.6585e-07,  3.3257e-07, -9.5394e-08,\n             3.8125e-07, -1.6686e-07,  1.2534e-07,  1.5500e-07, -2.0444e-07,\n            -5.7730e-07, -6.8830e-08, -3.0130e-07, -5.0282e-08, -2.1061e-08,\n             1.4722e-07, -5.8537e-07, -1.6137e-07,  1.2433e-07, -5.3156e-09,\n             8.0062e-08, -2.6107e-07, -2.4347e-07, -1.5072e-07,  2.1207e-07,\n            -1.4771e-07,  1.7096e-07, -6.9855e-09,  3.2336e-07,  2.8297e-07,\n            -3.8025e-08, -5.5963e-07, -4.0986e-07, -6.3720e-08,  3.3167e-07,\n             2.7185e-07,  5.7571e-08,  9.9641e-08, -2.7465e-07, -2.4970e-07,\n             2.0517e-07,  1.7036e-07,  5.6854e-09,  2.0356e-08, -2.1482e-07,\n            -4.0346e-08, -6.7692e-07,  6.9721e-08, -1.8801e-09,  2.0828e-07,\n            -7.7166e-08,  1.0541e-07, -5.3597e-07, -1.6930e-07,  4.7623e-08,\n             3.2500e-08, -3.1101e-07, -1.5419e-07, -4.5147e-08, -5.2306e-08,\n             2.3788e-07,  8.0467e-08,  3.4203e-07,  2.6456e-07, -1.5452e-07,\n            -2.9823e-07, -3.3813e-07,  1.3098e-07,  5.4704e-08, -4.1018e-07,\n             2.2657e-07, -9.2538e-08,  2.7479e-07, -6.0620e-07, -1.3637e-07,\n             2.0631e-07, -2.9899e-07,  8.8611e-08,  1.9479e-08, -1.7566e-07,\n             3.7442e-08,  2.1067e-07, -1.3968e-08,  8.3651e-07,  2.1577e-07,\n             9.3369e-09,  2.2355e-07,  8.1165e-07, -1.5926e-08, -3.3163e-07,\n             3.5405e-07,  4.0013e-07, -1.9032e-07,  1.1715e-07, -1.4407e-07,\n            -2.9867e-07,  2.3070e-07,  3.1773e-07, -3.1234e-08, -2.1571e-07,\n            -2.0234e-07, -1.1983e-07, -6.9901e-07, -2.4867e-07,  1.7644e-07,\n            -7.9784e-08, -1.5581e-07, -1.0468e-07,  3.2681e-07, -7.0787e-08,\n             1.1116e-07, -1.8884e-07,  2.2402e-08,  2.0877e-07,  2.9573e-08,\n             3.3072e-08,  2.0790e-07,  2.8661e-07, -1.3955e-07, -8.5275e-08,\n             1.3731e-07, -5.1478e-08,  1.5714e-07, -5.7750e-09, -3.6628e-07,\n            -6.4483e-09,  2.1501e-07,  6.2292e-08,  2.4262e-07, -2.8288e-08,\n            -4.7379e-08, -9.5439e-08]),\n    'exp_avg_sq': tensor([1.3215e-12, 8.0403e-13, 1.1435e-12, 1.6917e-12, 8.2191e-13, 4.0561e-13,\n            7.5842e-13, 1.2254e-12, 1.4764e-12, 1.2660e-12, 1.1771e-12, 8.7897e-13,\n            9.5275e-13, 1.2611e-12, 8.7159e-13, 2.4885e-12, 4.5799e-12, 1.4284e-12,\n            9.5030e-13, 1.2168e-12, 6.4853e-13, 1.2464e-12, 7.8536e-13, 9.3531e-13,\n            1.1111e-12, 1.1023e-12, 7.2424e-13, 1.0723e-12, 3.2722e-12, 1.1517e-12,\n            2.6651e-12, 1.3412e-12, 1.0261e-12, 1.4626e-12, 1.7387e-12, 1.7097e-12,\n            6.7216e-13, 4.2607e-13, 1.2253e-12, 2.0399e-12, 1.2554e-12, 1.2232e-12,\n            1.2916e-12, 9.5515e-13, 1.7871e-12, 2.2604e-12, 8.0133e-13, 1.2016e-12,\n            5.1896e-13, 4.5831e-13, 8.8026e-13, 6.7026e-13, 8.2356e-13, 6.1628e-13,\n            8.0763e-13, 5.5255e-13, 1.3427e-12, 7.1618e-13, 1.4757e-12, 7.7118e-13,\n            4.8966e-13, 2.7909e-12, 1.1404e-12, 5.7483e-13, 1.4579e-12, 8.1347e-13,\n            6.5353e-13, 9.4199e-13, 1.2285e-12, 2.4993e-12, 7.4760e-13, 9.4673e-13,\n            9.4370e-13, 1.4290e-12, 1.2788e-12, 1.8175e-13, 1.6262e-12, 9.5973e-13,\n            8.7081e-13, 1.5179e-12, 1.1505e-12, 8.8194e-13, 9.1048e-13, 2.2246e-12,\n            8.1192e-13, 7.3786e-13, 1.7773e-12, 2.8711e-13, 1.7016e-12, 2.8094e-12,\n            6.2721e-13, 1.0687e-12, 1.1612e-12, 1.6170e-12, 1.4877e-12, 1.9956e-12,\n            7.2597e-13, 7.4910e-13, 5.8199e-13, 2.2661e-12, 6.4681e-13, 2.6294e-13,\n            3.2063e-13, 7.6023e-13, 1.4003e-12, 1.6048e-12, 2.9465e-13, 1.0618e-12,\n            6.5871e-13, 6.8481e-13, 2.9267e-12, 6.2248e-13, 1.0040e-12, 1.3676e-12,\n            9.8588e-13, 1.0517e-12, 9.9268e-13, 6.8901e-13, 1.8150e-12, 1.1899e-12,\n            2.9913e-13, 9.1018e-13, 1.1483e-12, 6.8978e-13, 9.0664e-13, 1.0602e-12,\n            1.3151e-12, 6.2728e-13, 1.6163e-12, 1.4768e-12, 9.5267e-13, 8.3003e-13,\n            5.3878e-13, 1.1077e-12, 1.4555e-12, 1.2367e-12, 3.6578e-13, 5.9893e-13,\n            6.5899e-13, 1.1543e-12, 1.5424e-12, 1.4765e-12, 5.5842e-13, 7.2707e-13,\n            1.0206e-12, 1.2281e-12, 7.0686e-13, 2.2516e-12, 1.5473e-12, 1.9547e-12,\n            8.7995e-13, 8.2285e-13, 1.0582e-12, 4.3478e-13, 1.5404e-12, 1.7410e-12,\n            5.7737e-13, 1.4605e-12, 1.4898e-12, 7.7175e-13, 8.3465e-13, 1.0376e-12,\n            8.6758e-13, 6.4263e-13, 4.9550e-13, 1.2640e-12, 9.4716e-13, 5.8398e-13,\n            8.9711e-13, 9.3120e-13, 1.0331e-12, 9.5014e-13, 4.8925e-12, 2.2698e-12,\n            6.1799e-13, 5.5109e-13, 1.0667e-12, 9.5059e-13, 7.0971e-13, 6.9206e-13,\n            2.9647e-12, 1.5370e-12, 8.9715e-13, 1.3483e-12, 6.5139e-13, 1.2947e-12,\n            1.1531e-12, 2.5966e-13, 1.3008e-12, 7.5604e-13, 1.5128e-12, 1.8484e-12,\n            7.1550e-13, 1.2673e-12, 7.9258e-13, 6.9045e-13, 7.9360e-13, 1.0260e-12,\n            8.4491e-13, 8.6139e-13, 1.0014e-12, 9.3575e-13, 7.7854e-13, 1.0557e-12,\n            1.2461e-12, 1.0506e-12, 6.7933e-13, 1.4977e-12, 1.3271e-12, 1.1490e-12,\n            8.8347e-13, 1.2026e-12, 9.8723e-13, 1.1632e-12, 6.6014e-13, 1.5549e-12,\n            7.8270e-13, 9.9219e-13, 1.2347e-12, 5.8588e-13, 2.9278e-13, 6.1635e-13,\n            8.3878e-13, 4.6330e-13, 1.2585e-12, 8.2770e-13, 1.7739e-12, 5.8076e-13,\n            7.4966e-13, 9.1929e-13, 1.4247e-12, 5.3075e-13, 1.0166e-12, 7.2159e-13,\n            4.7545e-13, 3.6716e-13, 8.7716e-13, 5.0950e-13, 2.8352e-12, 2.0298e-12,\n            9.1336e-13, 9.8226e-13, 9.2321e-13, 1.4588e-12, 1.1037e-12, 1.7042e-12,\n            1.7154e-12, 1.2035e-12, 9.6710e-13, 3.2630e-12, 1.4290e-12, 1.1515e-12,\n            1.8329e-12, 1.1131e-12, 1.1668e-12, 1.8426e-12, 9.6968e-13, 6.9163e-13,\n            1.1231e-12, 1.3036e-12, 1.7742e-12, 1.6518e-12, 5.8359e-13, 1.0855e-12,\n            2.3182e-12, 1.5715e-12, 5.3523e-13, 1.5507e-12, 8.1650e-13, 9.3095e-13,\n            3.5127e-13, 5.9224e-13, 7.3393e-13, 1.1560e-12, 1.5218e-12, 2.5043e-12,\n            1.1995e-12, 1.5217e-12, 6.4193e-13, 5.5834e-13, 5.2276e-13, 8.3807e-13,\n            1.4050e-12, 6.9417e-13, 2.2572e-12, 4.5924e-13, 8.4949e-13, 1.9475e-12,\n            1.0151e-12, 8.8467e-13, 2.2672e-12, 7.8413e-13, 7.7527e-13, 1.9804e-12,\n            1.3373e-12, 2.4413e-12, 6.8810e-13, 1.7422e-12, 7.5819e-13, 1.2690e-12,\n            8.5805e-13, 1.0532e-12, 9.4777e-13, 1.5992e-12, 1.1470e-12, 1.0896e-12,\n            7.8073e-13, 8.2757e-13, 7.6763e-13, 1.3973e-12, 1.2687e-12, 8.8786e-13,\n            1.2652e-12, 6.5093e-13, 1.1154e-12, 1.1675e-12, 5.2689e-13, 1.1856e-12,\n            8.1497e-13, 1.5615e-12, 2.2257e-12, 1.3885e-12, 4.4817e-13, 1.0183e-12,\n            7.0903e-13, 1.3101e-12, 1.4160e-12, 8.8656e-13, 9.9525e-13, 2.5352e-12,\n            1.5763e-12, 7.1173e-13, 1.2535e-12, 8.8886e-13, 1.7393e-12, 7.5206e-13,\n            8.1231e-13, 9.6756e-13, 1.0748e-12, 1.8812e-12, 1.3722e-12, 1.0520e-12,\n            7.6954e-13, 1.6043e-12, 4.8501e-13, 7.8393e-13, 1.9554e-12, 1.0551e-12,\n            2.1131e-12, 6.4018e-13, 8.9007e-13, 1.0001e-12, 5.2045e-13, 1.2778e-12,\n            1.6500e-12, 1.5401e-12, 8.6324e-13, 2.1177e-12, 6.1018e-13, 8.3521e-14,\n            1.7337e-12, 9.6463e-13, 1.1216e-12, 6.4640e-13, 2.2614e-12, 6.3037e-13,\n            7.7938e-13, 4.8743e-13, 3.1110e-13, 1.1655e-12, 1.5648e-12, 9.1417e-13,\n            1.3460e-12, 1.0966e-12, 6.2520e-13, 9.6178e-13, 9.3923e-13, 5.1626e-12,\n            1.2214e-12, 9.7995e-13, 1.8695e-12, 1.6992e-13, 9.2474e-13, 1.0471e-12,\n            1.0549e-12, 1.8347e-12, 9.0068e-13, 4.1508e-13, 6.0536e-13, 8.2087e-13,\n            1.4955e-12, 1.2012e-12, 1.3386e-12, 4.4590e-13, 1.1123e-12, 3.8146e-13,\n            1.0285e-12, 8.0815e-13, 1.1346e-12, 3.1077e-13, 8.9942e-13, 1.0953e-12,\n            9.8850e-13, 2.0677e-12, 1.3353e-12, 8.8333e-13, 6.3362e-13, 5.9936e-13,\n            1.5668e-12, 1.2214e-12, 9.3423e-13, 2.6350e-12, 5.1611e-13, 9.0656e-13,\n            1.4876e-12, 5.6279e-13, 1.2998e-12, 5.8527e-13, 8.2095e-13, 1.2819e-12,\n            1.3042e-12, 5.1693e-13, 1.3717e-12, 1.5710e-12, 6.6711e-13, 8.6215e-13,\n            2.7580e-12, 8.7748e-13, 6.5330e-13, 6.6264e-13, 8.9726e-13, 4.5649e-13,\n            1.2987e-12, 1.8990e-12, 7.3037e-13, 5.8113e-13, 1.0446e-12, 1.1154e-12,\n            2.1059e-12, 1.0131e-12, 1.2148e-12, 8.4996e-13, 1.8732e-12, 1.4815e-12,\n            4.5288e-13, 9.9847e-13, 1.4623e-12, 6.8187e-13, 1.2261e-12, 8.0775e-13,\n            6.2671e-13, 9.3104e-13, 1.5080e-12, 1.4918e-12, 1.3986e-12, 6.4104e-13,\n            8.1850e-13, 1.6939e-12, 3.4907e-13, 1.1834e-12, 1.7268e-12, 1.0694e-12,\n            9.1633e-13, 1.0533e-12, 7.1911e-13, 1.4089e-12, 7.1953e-13, 1.8034e-12,\n            6.8526e-13, 5.4187e-13, 1.2405e-12, 1.5522e-12, 1.0038e-12, 9.7276e-13,\n            5.7129e-13, 6.6302e-13, 1.1483e-12, 9.4469e-13, 1.5530e-12, 2.4895e-12,\n            1.4535e-12, 8.6613e-13, 1.5858e-12, 2.1460e-12, 1.2855e-12, 1.4316e-12,\n            1.3394e-12, 9.2694e-13, 1.4132e-12, 1.7164e-12, 1.8511e-12, 2.0321e-12,\n            1.8024e-12, 1.1901e-12, 7.7020e-13, 9.9282e-13, 5.2854e-13, 1.2352e-12,\n            7.0842e-13, 6.1232e-13, 1.0233e-12, 3.4074e-13, 1.3142e-12, 5.5817e-13,\n            1.0042e-12, 1.0749e-12, 7.9244e-13, 1.5387e-12, 1.0748e-12, 1.4192e-12,\n            2.3613e-12, 8.5774e-13])},\n   47: {'exp_avg': tensor([ 9.7609e-08,  1.7639e-07, -3.6229e-08, -1.4239e-07, -5.3477e-08,\n            -3.3816e-08,  1.5353e-07, -2.4346e-07,  2.8327e-08,  1.2852e-08,\n            -4.8096e-08,  2.7483e-08,  2.3365e-08,  1.1736e-08,  1.6007e-07,\n            -1.6137e-08,  3.2154e-08, -6.0468e-08, -2.0723e-07,  2.8995e-09,\n             1.6130e-07, -2.9687e-08, -1.0399e-08,  1.0290e-07, -3.9025e-08,\n            -5.6371e-08,  9.8123e-09, -3.5729e-08,  1.1868e-08, -1.4444e-07,\n            -3.1119e-08, -6.2345e-08, -2.3047e-07,  1.6772e-07, -7.1994e-08,\n            -8.4232e-09,  2.1402e-08,  1.5162e-07,  6.1355e-08, -2.1339e-07,\n             1.0785e-07, -2.2242e-07,  7.2110e-08, -1.6232e-08,  4.9304e-08,\n             7.7291e-08, -2.6605e-08,  2.1788e-07, -8.8515e-08,  1.0332e-07,\n             1.1538e-07,  1.1970e-07, -1.2331e-07, -1.3835e-07, -4.9148e-08,\n             1.2301e-07, -2.0009e-08,  2.7364e-08, -9.3887e-08, -4.7313e-08,\n             9.6640e-08, -6.5220e-08,  9.0944e-08, -6.2207e-08, -6.0996e-08,\n            -3.8643e-08,  1.6360e-07,  2.6584e-08,  4.4531e-08,  7.2164e-08,\n             6.0420e-08, -1.2778e-07, -3.6352e-09, -6.0249e-08, -8.5611e-10,\n            -8.3804e-09, -1.9973e-08,  6.3029e-08, -2.5429e-08,  3.7527e-08,\n             2.4662e-07, -1.7018e-07, -4.5201e-09, -9.7711e-08,  8.5154e-08,\n             1.7229e-08,  5.3392e-09, -9.2337e-08,  1.3952e-07,  4.8576e-08,\n             5.5836e-08, -2.6809e-08, -4.2688e-08,  6.3083e-08, -7.7620e-08,\n             1.3104e-07, -6.6312e-08,  8.7643e-08, -4.3581e-08,  2.1633e-09,\n            -2.1307e-07, -5.8305e-08,  3.7667e-08, -3.0814e-08,  3.1695e-08,\n             4.8010e-09,  5.0321e-08,  1.0283e-07, -9.9347e-08, -1.2831e-07,\n            -1.2298e-07,  4.5803e-08,  4.4402e-08,  6.5035e-08,  4.1775e-08,\n            -1.7323e-10, -5.7284e-08,  2.4265e-07,  4.1587e-08, -9.7083e-08,\n             5.2317e-08, -5.3070e-08, -8.8842e-09,  1.3377e-07,  1.0682e-08,\n             8.9635e-10, -4.3480e-08,  1.7427e-07,  1.7832e-07,  9.0910e-08,\n            -1.1265e-08,  1.2624e-07, -5.9167e-08,  5.6375e-08,  4.4222e-08,\n             8.8681e-09, -5.0261e-08,  7.4882e-08,  1.3173e-07,  5.9139e-09,\n             1.3493e-08, -9.0125e-08, -7.9557e-09, -3.8927e-08,  8.2478e-08,\n            -9.7314e-08, -6.1199e-08,  1.0683e-08, -3.6289e-08, -2.2709e-07,\n             1.8387e-07, -6.3808e-09, -3.7559e-08, -2.1958e-08, -2.4333e-08,\n            -7.3407e-08, -9.9151e-08,  1.3340e-08, -7.5979e-09, -1.0671e-07,\n             4.0164e-08, -7.8610e-08, -1.1558e-07, -6.3539e-08,  3.4721e-08,\n            -7.2561e-08, -7.7389e-09, -5.5594e-09,  6.8065e-09,  1.0083e-07,\n             1.8040e-07, -1.6132e-07, -8.9478e-08,  8.1278e-08, -2.1069e-08,\n             7.6266e-08, -4.6650e-08,  2.0768e-08, -1.1335e-07, -1.5698e-07,\n             7.6867e-08, -1.5349e-07,  4.1862e-08,  1.3089e-08, -4.8971e-09,\n            -2.8096e-08,  1.6602e-09, -9.7037e-08, -2.0229e-08,  1.1833e-07,\n             2.0253e-08, -2.5993e-08, -1.1796e-07, -1.1543e-07, -1.5396e-08,\n            -7.0274e-08,  8.6162e-08, -1.3790e-07, -1.0405e-07,  1.1583e-07,\n            -5.2654e-09,  1.6202e-07, -2.1908e-07, -7.6868e-08,  3.4380e-08,\n            -8.6477e-08,  1.8435e-07,  1.1203e-08, -1.9957e-09, -1.2084e-07,\n            -1.8123e-07, -4.8883e-08,  1.9548e-07, -8.2816e-09, -1.3077e-07,\n             4.6338e-09,  8.1781e-08,  6.3140e-08,  7.3515e-09,  8.5512e-08,\n            -1.4025e-10,  3.9086e-08,  4.2211e-08, -1.0764e-07,  1.3690e-07,\n             2.8237e-08, -7.1700e-09,  2.8250e-07, -1.3069e-07,  4.6311e-08,\n            -2.6906e-08,  2.7737e-08,  6.1671e-08,  9.7756e-08, -1.0574e-07,\n            -3.6463e-08, -3.2282e-08,  1.3099e-08, -5.9384e-08, -2.1448e-07,\n            -5.3116e-09, -1.6229e-07, -2.6262e-08, -1.3520e-08,  6.0785e-08,\n             4.4341e-08,  1.5869e-07, -1.7094e-07,  1.0056e-07,  3.3592e-08,\n             7.9737e-08,  1.3627e-08,  2.8034e-08,  4.1800e-08,  1.5105e-07,\n             3.6375e-09,  5.0977e-08,  6.6008e-08,  4.6563e-08,  3.3093e-08,\n            -7.9740e-08, -7.3282e-08, -1.4054e-07, -4.8330e-09, -8.6663e-08,\n             5.4428e-08, -4.6865e-08,  1.0462e-07, -5.3200e-09,  2.9806e-08,\n             1.3783e-07,  1.3477e-07,  1.6005e-07, -6.9184e-08,  5.9924e-08,\n             6.6644e-08, -7.5241e-09,  1.1257e-07,  3.3917e-07,  2.5690e-08,\n             1.8939e-07, -1.9995e-08, -3.4083e-08, -7.2673e-08, -8.1408e-08,\n             2.2125e-08, -6.8399e-08,  2.8125e-07,  1.7999e-08, -7.8685e-08,\n            -8.7052e-08,  1.2157e-07, -3.1786e-09,  6.3254e-08, -6.6364e-08,\n            -2.3577e-07, -1.0136e-07, -1.1148e-08,  7.9815e-08,  2.9387e-08,\n             5.9721e-08,  1.0450e-08,  9.8794e-08,  8.8726e-08,  1.7263e-09,\n             3.2619e-08, -1.7044e-07,  1.6237e-07,  2.9639e-08, -1.7999e-08,\n            -5.2565e-08,  6.4282e-08,  8.4578e-08,  2.8784e-08, -6.7509e-08,\n            -6.4584e-08,  6.4910e-08, -3.1657e-08, -5.9577e-08,  8.9009e-08,\n             4.1744e-08,  1.1509e-07, -3.1427e-07,  5.5257e-08, -1.3178e-07,\n             1.4733e-07, -2.1218e-08, -3.9044e-09, -1.3822e-08,  5.9771e-08,\n            -9.3146e-09,  8.9462e-08,  1.2061e-07,  2.7908e-08,  1.4286e-08,\n             2.4922e-07, -2.3481e-08, -2.2132e-07, -7.9264e-08, -2.8893e-08,\n             2.6213e-08,  5.2535e-09, -4.4186e-08, -1.3182e-07,  3.5958e-08,\n            -2.4498e-10, -1.5652e-08,  7.7539e-09,  2.3234e-09, -1.4731e-07,\n            -1.1786e-07, -1.5607e-08, -9.2267e-08,  1.6747e-08, -4.6498e-08,\n             1.9092e-07,  3.4457e-08, -5.3418e-09, -9.7047e-08,  1.3301e-07,\n             2.3255e-08,  1.7925e-07, -8.4049e-08, -9.4107e-08,  6.5018e-08,\n             1.9948e-08, -1.2101e-08, -9.6997e-08,  1.3830e-07, -1.3291e-07,\n            -2.4554e-08,  9.2984e-08,  4.0834e-08, -2.8200e-07, -2.7572e-07,\n            -1.6844e-08,  3.9023e-08,  9.8980e-09, -1.5925e-08, -8.6462e-08,\n             2.8878e-08,  1.0735e-07,  6.5790e-08,  9.4151e-08,  6.3574e-08,\n            -1.1893e-07,  1.2999e-08,  3.9621e-08,  7.4675e-08,  2.0145e-07,\n            -1.1371e-07, -7.6086e-08,  1.2271e-08, -4.3417e-08, -5.6342e-08,\n             7.5439e-08, -4.9874e-08, -8.6558e-08, -1.9245e-08, -7.8472e-08,\n            -1.6997e-08, -1.3668e-07, -2.0357e-08, -1.6338e-08, -1.0338e-07,\n            -3.7270e-08,  6.0248e-08,  3.1742e-07,  2.2617e-08, -1.1958e-07,\n             7.4170e-08, -8.6881e-08,  6.3935e-08, -4.3093e-08,  2.6978e-09,\n             1.7493e-08,  8.2477e-09,  1.0055e-08,  2.3324e-07,  2.3525e-08,\n             3.6207e-08,  1.0697e-07, -2.5054e-08,  5.9461e-08,  5.9532e-08,\n            -1.4231e-08,  1.1238e-07, -2.1703e-08,  1.5822e-07,  1.8637e-07,\n            -1.2875e-07,  8.2797e-08,  1.9285e-08,  5.3894e-08,  1.6388e-07,\n            -9.6683e-08,  1.0048e-07,  1.6931e-08, -1.1335e-08, -1.0970e-07,\n             2.5138e-09, -4.5684e-08,  2.0570e-08, -2.9871e-09, -1.8146e-07,\n             4.0838e-08, -4.5078e-08,  2.6638e-08,  5.3234e-09,  6.4920e-08,\n            -3.9469e-08,  8.9323e-08, -5.7010e-08, -1.5073e-07,  1.4207e-08,\n            -8.6473e-08,  1.8218e-07, -1.3754e-07,  1.1000e-07,  8.2727e-08,\n            -1.0336e-07,  1.0852e-07,  4.7715e-08, -1.2771e-07,  4.9851e-08,\n             3.4639e-07, -9.7099e-08, -1.7561e-07, -1.5001e-07, -2.0681e-08,\n             1.3745e-09, -9.4771e-08,  6.9123e-08,  3.7657e-08, -1.3641e-07,\n            -2.4374e-08, -2.2978e-07, -2.1928e-07, -1.5590e-07, -1.1245e-08,\n            -6.1430e-10,  6.1523e-08,  1.7870e-07, -2.8447e-08,  1.4980e-08,\n            -2.3556e-07, -1.5280e-08, -7.8536e-09,  1.1683e-07,  1.2755e-07,\n             6.5287e-09, -5.2586e-08,  1.2423e-11, -2.1038e-08,  1.3268e-08,\n            -7.8112e-08, -1.4607e-07, -7.5869e-08,  1.2477e-07,  3.6210e-09,\n            -3.8955e-08,  5.8456e-08,  2.2886e-07,  7.9387e-08,  2.0682e-08,\n             5.7647e-08,  7.4128e-08,  1.1749e-07,  2.1818e-08, -1.6042e-08,\n             7.4453e-08,  2.6307e-08]),\n    'exp_avg_sq': tensor([1.4858e-13, 4.4320e-13, 1.4154e-14, 6.6101e-13, 4.8781e-14, 2.0219e-13,\n            3.2379e-13, 1.4877e-13, 2.9047e-13, 6.4500e-14, 4.6487e-14, 2.7240e-13,\n            3.4913e-14, 8.7359e-14, 3.9550e-13, 9.4026e-14, 1.2717e-12, 1.0434e-13,\n            4.6486e-13, 3.3427e-13, 4.0912e-13, 1.9607e-13, 8.9535e-15, 2.0334e-13,\n            4.5723e-13, 4.3609e-14, 5.6072e-14, 5.3100e-14, 4.7633e-14, 2.5618e-13,\n            2.8938e-13, 9.7431e-14, 1.7523e-13, 4.0088e-13, 4.5187e-14, 7.5981e-15,\n            2.3012e-14, 1.6348e-13, 1.5252e-14, 3.4401e-13, 9.3754e-14, 6.0056e-13,\n            7.4539e-14, 5.3319e-14, 1.6569e-14, 2.9655e-13, 9.2332e-14, 1.7213e-13,\n            2.1098e-13, 3.6554e-13, 8.7465e-14, 6.7026e-14, 3.6358e-13, 3.2423e-13,\n            1.8330e-13, 2.1092e-13, 4.6106e-14, 5.2855e-14, 1.6213e-13, 2.6058e-13,\n            2.5578e-13, 4.4137e-14, 1.2180e-13, 1.6982e-13, 7.3805e-14, 3.4874e-13,\n            2.5528e-13, 1.6155e-13, 5.2947e-14, 1.8723e-13, 1.6667e-13, 1.3193e-13,\n            1.3355e-13, 4.3172e-14, 3.3565e-14, 1.0841e-13, 1.2962e-13, 6.0300e-14,\n            1.1977e-13, 4.4226e-14, 4.1087e-13, 2.0332e-13, 6.8646e-14, 1.3009e-13,\n            2.3621e-13, 3.8603e-14, 9.0347e-15, 2.2677e-13, 3.2900e-13, 1.5355e-14,\n            1.7944e-13, 1.1206e-13, 9.5228e-14, 3.9785e-14, 9.0701e-14, 1.9218e-13,\n            8.5564e-14, 1.8617e-13, 1.9907e-13, 5.5557e-15, 3.4708e-13, 1.8881e-13,\n            1.4953e-13, 1.0969e-13, 1.9709e-13, 1.9905e-14, 2.3600e-13, 2.5969e-13,\n            3.0755e-13, 1.9056e-13, 8.0558e-13, 2.3180e-13, 1.8089e-13, 1.1870e-13,\n            3.5716e-13, 6.5198e-14, 1.1344e-14, 3.1096e-13, 4.7266e-13, 6.6468e-14,\n            2.3772e-13, 2.8611e-13, 8.3278e-14, 2.1491e-13, 2.7521e-14, 2.0385e-13,\n            2.2368e-14, 2.2917e-13, 2.4245e-13, 1.7976e-13, 1.7051e-13, 3.5033e-13,\n            2.7846e-13, 5.3156e-14, 4.7350e-14, 2.4010e-14, 1.7134e-13, 1.1210e-13,\n            2.3626e-13, 2.6883e-14, 2.9071e-14, 1.4216e-13, 1.8789e-13, 1.1944e-13,\n            3.2689e-13, 2.4437e-13, 2.4315e-13, 1.1042e-14, 6.4719e-14, 4.3502e-13,\n            8.5585e-14, 1.0649e-14, 9.4604e-14, 1.7812e-13, 2.3023e-14, 4.5586e-14,\n            1.0486e-13, 1.7304e-14, 1.3617e-14, 1.1801e-13, 3.8710e-13, 2.6503e-13,\n            7.3432e-14, 2.3434e-13, 2.4723e-13, 3.0292e-14, 2.9020e-13, 4.2698e-14,\n            3.5697e-14, 2.9354e-13, 2.2315e-13, 1.1705e-13, 5.4356e-14, 2.1402e-13,\n            2.4079e-13, 1.3306e-13, 3.3990e-14, 1.0222e-13, 2.6316e-13, 2.9300e-13,\n            7.7202e-14, 3.2291e-13, 1.8061e-13, 5.3554e-13, 1.6063e-13, 2.3167e-14,\n            3.2904e-14, 1.3761e-13, 8.2666e-14, 3.3718e-13, 6.5430e-14, 6.7225e-15,\n            6.3984e-14, 2.4201e-14, 1.1592e-14, 6.7828e-14, 2.5776e-13, 4.0834e-13,\n            6.0993e-14, 2.5435e-13, 3.8960e-14, 2.6277e-13, 2.0961e-13, 1.3170e-13,\n            4.9377e-13, 3.3728e-13, 2.5722e-13, 2.0803e-14, 7.3329e-14, 7.7554e-14,\n            2.5876e-13, 1.9448e-13, 3.4005e-13, 3.5437e-14, 1.7053e-13, 1.7214e-14,\n            6.9314e-14, 1.2844e-13, 1.2838e-13, 8.2498e-14, 1.3985e-13, 4.6311e-14,\n            4.5550e-14, 2.3215e-13, 5.3172e-13, 1.3609e-13, 1.1899e-14, 3.2945e-13,\n            1.5398e-13, 9.0445e-14, 1.5674e-13, 1.8631e-13, 1.9094e-13, 2.0692e-13,\n            1.7199e-13, 1.9703e-13, 5.6350e-13, 9.6952e-14, 5.2426e-13, 4.0963e-13,\n            4.3335e-13, 1.2466e-13, 1.9455e-13, 5.5185e-14, 1.0687e-13, 1.8043e-14,\n            2.1854e-13, 3.5040e-13, 2.1340e-13, 1.3996e-13, 5.6994e-14, 7.8526e-14,\n            4.3042e-14, 2.2662e-13, 1.1846e-13, 8.8634e-16, 1.1846e-13, 3.1310e-13,\n            2.0212e-14, 9.3346e-14, 2.9402e-13, 6.3126e-14, 1.3831e-13, 9.5326e-15,\n            1.5577e-13, 2.5260e-13, 2.4989e-13, 2.0704e-13, 2.5364e-14, 3.4246e-13,\n            3.1567e-13, 2.5893e-13, 3.3087e-13, 6.8998e-14, 1.0030e-13, 2.0405e-14,\n            8.0454e-14, 1.0973e-13, 3.8859e-13, 1.1158e-13, 1.8965e-13, 8.1325e-14,\n            1.1126e-14, 4.0952e-13, 1.2708e-13, 1.8554e-13, 1.9560e-13, 2.7700e-13,\n            6.0445e-14, 2.5498e-14, 3.3971e-13, 2.4416e-13, 8.6217e-14, 1.8752e-13,\n            1.5143e-14, 2.3712e-13, 2.3776e-13, 7.7209e-14, 6.8350e-14, 8.3431e-14,\n            3.6899e-13, 2.5951e-13, 2.7104e-13, 3.5716e-14, 8.1824e-16, 1.3656e-13,\n            1.5476e-13, 1.0111e-13, 1.4884e-13, 6.2039e-14, 1.0951e-13, 5.4219e-13,\n            2.9464e-14, 4.9339e-14, 7.0447e-14, 2.1627e-14, 2.6444e-13, 8.6727e-14,\n            6.8147e-14, 1.7139e-13, 1.7812e-13, 2.0148e-13, 1.9501e-13, 2.1890e-13,\n            2.1115e-13, 1.1576e-13, 3.2501e-14, 3.3058e-14, 5.7286e-14, 2.8340e-14,\n            2.8131e-14, 2.9683e-13, 1.3172e-13, 3.1552e-14, 5.3327e-14, 2.8289e-13,\n            2.2802e-13, 3.3101e-13, 6.3138e-13, 2.8449e-14, 2.9082e-14, 1.7204e-14,\n            2.5656e-13, 9.8512e-14, 1.2440e-13, 7.5161e-14, 3.7196e-14, 2.2462e-14,\n            1.0326e-13, 2.0139e-13, 3.5621e-13, 4.1786e-14, 1.2539e-13, 4.8510e-14,\n            8.7024e-14, 6.1238e-13, 1.8590e-13, 2.9614e-13, 2.0821e-13, 1.0109e-13,\n            5.4304e-14, 2.4591e-13, 3.8976e-13, 2.3180e-13, 5.5264e-13, 1.2770e-13,\n            4.4354e-14, 2.1083e-13, 2.0933e-13, 2.6405e-13, 3.9071e-14, 2.5941e-13,\n            1.8654e-13, 3.0946e-13, 3.4729e-13, 6.6180e-14, 5.5254e-14, 1.4844e-13,\n            1.0963e-13, 7.5769e-14, 3.3824e-14, 1.2345e-13, 2.4905e-13, 1.0498e-13,\n            9.4275e-14, 6.4108e-14, 1.4337e-14, 1.6136e-13, 2.7728e-13, 3.3728e-13,\n            2.7459e-13, 4.8042e-14, 2.5295e-14, 2.3336e-13, 7.7063e-14, 2.4985e-13,\n            6.1792e-14, 2.3404e-14, 3.0684e-13, 2.3277e-13, 6.8538e-14, 2.8044e-13,\n            2.5965e-13, 2.7945e-13, 2.8234e-13, 3.0250e-13, 1.5029e-13, 3.2480e-13,\n            2.4894e-13, 4.9345e-13, 5.8255e-14, 1.3153e-13, 2.0983e-13, 1.4097e-13,\n            1.6614e-15, 5.2564e-14, 1.3241e-14, 2.9167e-13, 2.7458e-13, 1.1366e-13,\n            5.4084e-14, 9.6215e-14, 4.2652e-13, 3.4683e-13, 2.2317e-13, 2.0660e-13,\n            8.4224e-13, 2.2696e-13, 2.9579e-13, 1.1600e-13, 2.0872e-13, 2.9178e-13,\n            7.9618e-14, 2.1188e-14, 2.8309e-13, 1.4951e-13, 7.8661e-14, 2.9885e-13,\n            1.7969e-14, 3.1919e-13, 1.7216e-13, 1.3205e-13, 4.7274e-13, 1.0585e-15,\n            2.7731e-13, 1.4025e-13, 4.3647e-14, 1.5804e-13, 7.0464e-14, 2.3653e-13,\n            1.7012e-13, 9.7394e-14, 3.8541e-14, 2.7237e-13, 3.7581e-13, 2.6352e-13,\n            2.9044e-13, 1.8295e-13, 1.3960e-13, 1.7963e-13, 2.3086e-13, 1.5105e-13,\n            1.6421e-13, 3.8387e-13, 2.1330e-13, 2.2927e-13, 2.8570e-13, 1.4941e-13,\n            2.6184e-13, 2.5764e-13, 1.0877e-13, 1.6691e-13, 2.6095e-13, 8.4644e-14,\n            1.8880e-13, 8.7629e-14, 1.9521e-13, 2.6538e-13, 2.5308e-13, 3.9847e-14,\n            3.8857e-14, 3.9313e-13, 1.9307e-13, 5.8284e-14, 3.5330e-13, 6.7353e-13,\n            4.1896e-15, 2.1396e-13, 1.9637e-13, 1.6574e-13, 3.6488e-13, 7.3008e-14,\n            9.6220e-19, 1.4673e-14, 1.9481e-13, 1.6801e-13, 1.9058e-13, 4.2058e-13,\n            4.2721e-13, 2.1915e-13, 8.0618e-14, 1.9812e-13, 3.5488e-13, 2.5213e-13,\n            1.1761e-13, 1.2465e-13, 2.2151e-13, 4.3240e-13, 9.2609e-14, 1.4883e-13,\n            4.9719e-13, 8.7060e-15])},\n   48: {'exp_avg': tensor([ 8.5054e-09,  2.1151e-07,  1.1728e-07,  1.2621e-07, -3.2813e-08,\n            -4.9695e-08,  1.4992e-07,  1.8911e-07,  5.4570e-08,  1.1420e-07,\n            -5.7553e-07, -5.2074e-08, -2.1750e-07,  8.6844e-08,  1.6796e-07,\n             3.1030e-07,  3.9919e-07,  6.0409e-09,  8.0653e-08,  6.6004e-08,\n            -6.8941e-08,  1.2353e-07,  6.5193e-09, -1.0095e-07, -6.0207e-07,\n            -2.1152e-07,  2.2948e-07,  3.9874e-07,  1.1189e-07, -5.7878e-08,\n             2.1186e-07, -4.5330e-10,  4.9024e-08,  1.4499e-07, -1.4716e-07,\n            -7.3364e-08, -5.0618e-10,  2.3083e-07, -1.4241e-07,  1.3683e-07,\n            -4.2270e-07,  5.5998e-08, -2.6881e-08,  6.2148e-08, -9.5648e-09,\n             1.0664e-07, -3.3743e-07,  1.6283e-07,  2.4459e-07, -1.5026e-07,\n             5.7560e-07, -1.2408e-07,  2.9198e-08, -7.4222e-08,  2.2616e-07,\n            -1.7472e-07,  1.3448e-07, -3.4661e-08,  2.0156e-08, -8.3422e-08,\n             1.4050e-07,  8.2232e-08, -3.4222e-07, -2.5381e-08, -5.5646e-08,\n             3.2534e-10, -2.0815e-07,  1.5831e-08,  3.1455e-08,  2.2825e-08,\n            -1.3475e-07, -1.6005e-07,  7.9711e-08, -1.1027e-07, -1.0167e-07,\n            -1.1405e-07, -4.1600e-08,  4.9237e-08,  1.4488e-07,  1.0618e-07,\n            -3.7363e-07,  1.0005e-07,  3.0529e-07,  4.9528e-08,  9.9984e-08,\n             1.1537e-07, -1.5127e-07,  2.1680e-07, -1.9349e-07, -3.2087e-08,\n            -1.8166e-08, -7.0407e-08,  4.5838e-08,  7.2275e-08,  2.7274e-07,\n             3.6418e-07, -7.0949e-08,  3.4745e-07,  2.6538e-07,  1.7896e-07,\n             6.0764e-08,  9.7615e-08, -2.1641e-07,  3.7934e-07,  1.1890e-07,\n            -2.1652e-07, -2.2312e-07, -2.4222e-07, -8.7575e-08,  9.9875e-08,\n            -1.2995e-07, -5.6035e-08, -3.0908e-07,  2.7278e-07, -1.8564e-07,\n             1.1882e-07, -4.2118e-08,  9.2292e-08, -1.9940e-07,  2.2585e-07,\n            -1.5250e-07,  7.7111e-08,  1.6750e-07,  2.7030e-07, -3.3497e-07,\n            -4.6400e-08, -3.1911e-07,  1.4240e-08,  1.5766e-07,  7.5952e-08,\n            -1.5206e-07, -1.8126e-07, -2.2320e-07,  1.5011e-07,  2.6491e-07,\n            -1.1918e-07,  1.3105e-07, -1.8597e-07,  2.2895e-07,  2.1465e-08,\n             7.3154e-08,  2.3630e-07, -2.9955e-07, -1.8027e-07,  1.0193e-07,\n            -1.1808e-07,  1.4636e-07,  1.2999e-07, -1.3256e-07,  2.3432e-07,\n             1.6990e-07, -2.9842e-07, -3.5632e-08, -4.5211e-07, -3.2402e-08,\n            -8.4973e-08,  8.9416e-08, -4.9090e-07,  5.5308e-08,  1.6733e-07,\n            -1.4725e-07,  2.7489e-09, -5.0684e-07,  1.9498e-07,  8.0097e-08,\n            -6.2734e-08,  1.4990e-07,  3.5885e-07,  4.2687e-07, -2.9834e-08,\n             1.0988e-07, -7.5091e-10, -2.6078e-07, -2.2643e-07, -5.6751e-09,\n             2.7681e-09, -1.3087e-07,  8.7016e-08,  1.0137e-07, -1.3072e-07,\n             1.0365e-07,  6.4127e-08, -2.1159e-07, -8.1711e-08, -1.0198e-07,\n            -8.2797e-08, -4.1617e-08,  1.4179e-09, -2.1281e-07, -1.0819e-08,\n            -1.2943e-07,  8.7919e-08, -6.3763e-08, -2.4725e-08,  7.6214e-07,\n            -3.3795e-07, -9.2907e-08,  2.9391e-09,  2.4302e-07,  1.6038e-07,\n             1.9275e-08, -3.7747e-08, -1.8957e-07, -6.9216e-08, -1.2990e-08,\n             6.5369e-08, -1.9247e-07,  1.1538e-08,  1.4634e-07,  5.5914e-08,\n             2.6331e-07, -3.4045e-07, -3.9440e-07, -4.8298e-08, -2.3309e-07,\n             2.0760e-07, -4.5924e-08, -3.8396e-08, -8.1579e-08,  1.2360e-07,\n             2.5480e-07,  1.2965e-07,  6.1978e-09,  1.2539e-07, -6.5616e-08,\n            -7.0728e-08,  4.6427e-08,  2.9944e-07, -3.7811e-08, -2.2011e-08,\n            -1.9305e-07, -1.4922e-07,  1.9260e-07, -2.4590e-08,  5.3063e-08,\n            -3.7535e-08, -3.9358e-07, -2.2280e-07,  2.1233e-07, -1.2998e-07,\n            -8.4277e-08, -3.2015e-07,  7.2774e-09, -6.6855e-09, -2.4940e-08,\n             8.6997e-08, -2.1206e-07, -1.3603e-07, -6.5989e-08,  4.4321e-09,\n             1.5875e-07, -5.7417e-08, -4.4815e-08, -6.0185e-08,  1.5117e-07,\n            -2.9473e-08]),\n    'exp_avg_sq': tensor([3.2715e-13, 5.8368e-13, 7.9492e-13, 8.4623e-13, 9.0197e-13, 4.4326e-13,\n            1.1539e-12, 4.9850e-13, 2.3280e-13, 7.1109e-13, 1.9440e-12, 6.2425e-13,\n            5.4773e-13, 9.7901e-13, 8.9628e-13, 4.6218e-13, 1.1330e-12, 2.9977e-13,\n            4.8361e-13, 5.3281e-13, 1.2606e-12, 7.7085e-13, 5.4964e-13, 1.3995e-13,\n            1.4142e-12, 5.0512e-13, 8.1906e-13, 1.2400e-12, 2.6075e-13, 2.0729e-13,\n            5.6840e-13, 2.3666e-13, 4.9027e-13, 2.6480e-13, 8.8698e-13, 5.2198e-13,\n            4.6022e-13, 5.5474e-13, 1.1657e-12, 1.1790e-12, 7.0522e-13, 4.7980e-13,\n            7.3391e-13, 7.3703e-13, 1.0466e-12, 4.7350e-13, 7.0314e-13, 5.6054e-13,\n            7.5192e-13, 1.0153e-12, 1.4302e-12, 9.6696e-13, 5.9292e-13, 7.8623e-13,\n            5.4262e-13, 7.8224e-13, 9.6344e-13, 4.1241e-13, 5.8233e-13, 6.8095e-13,\n            3.8131e-13, 8.4167e-13, 1.4959e-12, 3.7891e-13, 2.1373e-13, 1.8164e-13,\n            6.5421e-13, 1.9399e-13, 7.5008e-13, 8.2286e-13, 4.1321e-13, 1.3726e-12,\n            5.3556e-13, 4.0701e-13, 4.3557e-13, 9.3520e-13, 1.0891e-12, 6.2702e-13,\n            5.4431e-13, 7.1725e-13, 1.0053e-12, 8.1700e-13, 5.1922e-13, 4.3091e-13,\n            9.0687e-13, 5.3183e-13, 2.8379e-13, 4.5807e-13, 6.6979e-13, 1.9951e-13,\n            7.3151e-13, 6.9117e-13, 1.3628e-12, 4.7638e-13, 9.9043e-13, 1.1800e-12,\n            4.3918e-13, 1.0654e-12, 1.0062e-12, 9.4307e-13, 9.4783e-13, 1.1216e-12,\n            1.4502e-12, 4.8132e-13, 1.1707e-12, 4.1430e-13, 9.9783e-13, 1.1421e-12,\n            1.0374e-12, 1.1074e-12, 9.0834e-13, 5.1877e-13, 7.5986e-13, 8.5345e-13,\n            8.3330e-13, 8.0854e-13, 1.0566e-12, 1.2218e-12, 4.8715e-13, 6.5585e-13,\n            9.4229e-13, 8.8399e-13, 5.8826e-13, 1.2087e-12, 1.0615e-12, 3.4829e-13,\n            4.6171e-13, 1.0484e-12, 5.4057e-13, 6.7434e-13, 1.7816e-12, 8.1491e-13,\n            1.1929e-12, 8.3933e-13, 8.2471e-13, 8.4675e-13, 1.7473e-13, 3.5028e-13,\n            4.3269e-13, 2.5875e-12, 1.3488e-13, 7.9043e-13, 7.0337e-13, 1.2047e-12,\n            4.2486e-13, 7.0448e-13, 4.8666e-13, 1.8897e-13, 1.1376e-12, 9.1786e-13,\n            7.2030e-13, 3.5364e-13, 4.0996e-13, 1.2078e-12, 1.6969e-12, 7.0313e-13,\n            1.1614e-12, 1.6501e-12, 5.6789e-13, 3.6371e-13, 7.1092e-13, 1.6934e-13,\n            8.0509e-13, 1.1458e-12, 1.0690e-12, 6.9011e-13, 2.6067e-13, 1.1750e-12,\n            9.8272e-13, 7.6461e-13, 3.4707e-13, 7.3776e-13, 1.5457e-12, 4.3587e-13,\n            5.9400e-13, 1.1077e-12, 2.9917e-13, 7.1286e-13, 2.5949e-13, 1.2353e-12,\n            8.4061e-13, 7.0739e-13, 2.2398e-13, 3.5937e-13, 3.8657e-13, 5.4173e-13,\n            3.9204e-13, 2.9596e-13, 8.4281e-13, 1.3887e-12, 1.0563e-12, 2.8754e-13,\n            1.0898e-12, 3.5187e-13, 3.0522e-12, 6.6540e-13, 5.2459e-13, 4.8542e-13,\n            1.3519e-12, 8.0563e-13, 2.4201e-13, 3.0280e-13, 6.6829e-13, 4.7775e-13,\n            2.1642e-13, 3.3731e-13, 3.4579e-13, 2.3055e-13, 7.6340e-13, 4.4748e-13,\n            8.8679e-13, 2.1766e-12, 7.7597e-13, 3.0810e-13, 3.2518e-13, 8.2139e-13,\n            3.8479e-13, 7.0760e-13, 5.9845e-13, 7.3066e-13, 1.7025e-12, 3.7727e-13,\n            3.0069e-13, 1.3157e-12, 1.8418e-13, 4.9534e-13, 7.9827e-13, 9.2008e-13,\n            4.9350e-13, 1.0827e-12, 2.0732e-13, 9.4961e-13, 1.1687e-12, 1.1021e-12,\n            2.6208e-13, 4.9902e-13, 1.0023e-12, 1.7858e-12, 1.3707e-12, 4.7475e-13,\n            7.7275e-13, 1.1615e-12, 1.3914e-13, 5.6676e-13, 7.3450e-13, 4.2997e-13,\n            1.3113e-12, 2.4340e-13, 7.7598e-13, 3.3684e-13, 7.1580e-13, 7.4675e-13,\n            8.1370e-13, 2.7455e-13, 4.0386e-13, 3.1207e-13])},\n   49: {'exp_avg': tensor([-6.8651e-08,  2.6508e-07,  1.4006e-07, -1.2363e-07,  9.1962e-08,\n             2.8058e-08,  1.3148e-07, -8.5277e-09,  1.0081e-07,  2.4043e-08,\n            -3.6878e-07,  1.1097e-07, -2.9968e-07, -1.2075e-07,  8.5069e-08,\n             1.8757e-07,  1.3537e-07,  2.6065e-08,  1.5658e-07,  1.5328e-08,\n            -5.5910e-08,  4.8991e-08, -1.1881e-07, -9.9638e-08, -4.7294e-07,\n            -8.2560e-08,  2.1890e-07,  1.8578e-07,  2.0779e-07, -7.2160e-09,\n             1.9482e-07, -2.3074e-08, -1.5784e-07,  2.0245e-07, -3.7592e-07,\n             2.5180e-08, -4.6003e-08,  9.5522e-08, -5.9545e-08,  5.8088e-08,\n            -3.5200e-07,  5.3794e-08, -1.1379e-07, -2.0902e-10,  2.8880e-08,\n             6.2780e-08, -2.3387e-07,  1.8206e-07,  2.3528e-07, -5.9388e-08,\n             4.3122e-07,  3.9971e-08, -2.8620e-08,  9.7733e-08,  1.0100e-07,\n            -1.7623e-08,  7.2836e-08, -1.2164e-07, -4.6276e-08,  3.0179e-08,\n             1.1713e-07,  1.3589e-07, -3.1807e-07, -1.2890e-08,  9.0454e-08,\n            -9.9227e-08, -1.2371e-07, -9.1849e-08, -8.1266e-08,  6.8859e-08,\n            -9.5618e-08, -1.1807e-07,  2.1321e-07, -1.6873e-07, -1.0153e-07,\n             7.7408e-08,  1.2189e-07, -4.9850e-08,  3.3129e-08,  9.3691e-08,\n            -2.9660e-07, -4.5155e-08,  1.4230e-07,  4.4409e-08,  2.5211e-07,\n             1.3182e-07, -2.2344e-07,  3.1877e-07, -1.1820e-07, -2.3492e-07,\n            -6.3314e-08, -8.7428e-08,  2.0663e-08,  6.7205e-08,  1.3584e-07,\n             2.2458e-07, -1.6197e-07,  3.2985e-07,  2.7993e-07,  5.2293e-08,\n            -5.6302e-08, -1.2254e-07, -2.5057e-07,  3.9715e-07,  1.7195e-07,\n            -3.7248e-07, -1.3969e-07, -2.2493e-07, -1.9130e-07,  2.2504e-07,\n            -1.9217e-07,  1.0023e-07, -1.5868e-07,  2.2891e-07, -2.4778e-07,\n             1.0462e-07, -9.3739e-08,  2.5163e-07, -1.3518e-08,  1.0089e-07,\n            -1.8390e-07,  3.6163e-08,  1.0783e-07,  1.6318e-07, -3.3806e-07,\n            -4.0896e-08, -2.5859e-07,  2.0758e-07,  2.5899e-07,  1.0715e-07,\n            -6.4624e-08, -1.1399e-07, -1.8532e-07, -4.8335e-08,  1.0266e-07,\n             1.3231e-08,  2.0290e-07, -7.1090e-08,  1.1054e-07,  8.4382e-08,\n             6.1769e-08,  1.8119e-07, -2.4379e-07, -1.7924e-07,  1.2126e-09,\n            -1.1345e-07, -4.0589e-08,  1.9912e-07, -1.0637e-07,  1.6502e-07,\n             2.4138e-08, -2.7033e-07, -1.1095e-07, -1.7257e-07, -5.3653e-08,\n            -9.6461e-08,  1.7604e-07, -2.1444e-07, -1.3392e-07,  1.2716e-07,\n            -2.4690e-07, -1.0455e-07, -3.3757e-07,  1.0158e-07, -1.1311e-07,\n             1.0310e-07,  1.0262e-07,  3.6858e-07,  3.1226e-07, -9.4095e-08,\n             5.1544e-09, -2.0724e-07, -2.2225e-07, -2.6540e-08,  2.2944e-09,\n            -3.9020e-08, -1.6225e-07,  1.2759e-07,  1.4306e-07, -1.3084e-07,\n             4.1465e-08,  1.7182e-07, -2.7613e-07,  6.0302e-09, -1.1995e-07,\n             5.6623e-08, -2.0526e-07, -6.4340e-08, -1.8020e-07,  5.0131e-08,\n            -1.4921e-07,  1.9626e-08, -1.4752e-07,  1.2048e-07,  5.4875e-07,\n            -2.9403e-07, -9.2576e-08,  1.8099e-07, -4.5191e-08,  4.5739e-08,\n             2.7098e-08, -4.2729e-08, -7.5765e-08,  2.2721e-08, -9.6929e-08,\n             3.5844e-08, -2.9837e-07, -2.9044e-10,  1.1658e-07, -2.2616e-08,\n             5.8619e-08, -4.1089e-07, -4.2231e-07,  2.4162e-08, -2.4019e-07,\n             3.2598e-07,  6.9219e-08, -6.2174e-08, -8.6824e-09,  1.9260e-07,\n             3.5443e-07,  1.4455e-07, -2.1944e-08, -9.2139e-08,  9.1964e-09,\n            -7.9362e-08,  8.2145e-08,  1.7338e-07, -1.6065e-07,  1.4830e-08,\n            -2.0172e-07, -3.1566e-07,  5.0977e-08,  1.1872e-07, -3.4714e-08,\n            -5.9990e-08, -3.5951e-07, -1.3730e-07,  4.8194e-08, -1.2762e-07,\n             1.7056e-08, -2.0024e-07,  3.4095e-09, -3.4331e-08, -3.6474e-08,\n             8.6458e-08, -1.2094e-07, -1.2714e-07, -8.7525e-08,  2.1060e-07,\n             1.4637e-07, -1.8197e-07,  7.8932e-08, -9.5696e-08, -1.3849e-07,\n            -4.0077e-08]),\n    'exp_avg_sq': tensor([3.4263e-13, 5.4545e-13, 5.2057e-13, 6.8589e-13, 6.5827e-13, 5.3846e-13,\n            6.6421e-13, 5.3170e-13, 5.0791e-13, 5.3575e-13, 8.9129e-13, 5.0458e-13,\n            4.8016e-13, 5.7018e-13, 5.9623e-13, 4.3839e-13, 5.8095e-13, 3.5597e-13,\n            3.7950e-13, 5.4762e-13, 5.4190e-13, 5.0449e-13, 5.6213e-13, 2.3281e-13,\n            7.5174e-13, 3.5081e-13, 5.6070e-13, 7.9348e-13, 3.7169e-13, 3.0265e-13,\n            4.6824e-13, 3.3267e-13, 4.9653e-13, 4.1996e-13, 8.1333e-13, 4.1991e-13,\n            3.7327e-13, 4.6944e-13, 6.9697e-13, 7.1562e-13, 5.1862e-13, 4.0248e-13,\n            5.1250e-13, 4.8380e-13, 5.8244e-13, 5.2195e-13, 4.5700e-13, 5.1078e-13,\n            3.8077e-13, 6.7237e-13, 6.0099e-13, 7.3259e-13, 4.4737e-13, 5.0473e-13,\n            5.4854e-13, 5.5413e-13, 6.0503e-13, 6.1979e-13, 4.8591e-13, 5.1639e-13,\n            3.2996e-13, 5.5032e-13, 9.3923e-13, 4.3996e-13, 3.2813e-13, 3.1471e-13,\n            5.3149e-13, 3.9729e-13, 4.0735e-13, 5.4275e-13, 3.5467e-13, 1.0398e-12,\n            4.5798e-13, 4.4219e-13, 4.1631e-13, 7.2892e-13, 5.0744e-13, 6.3717e-13,\n            4.0058e-13, 4.0971e-13, 6.5448e-13, 5.9455e-13, 3.9357e-13, 2.9794e-13,\n            6.6661e-13, 4.8676e-13, 4.6625e-13, 5.1695e-13, 5.3293e-13, 5.4385e-13,\n            4.3940e-13, 4.0354e-13, 7.2097e-13, 3.9961e-13, 6.2307e-13, 8.2209e-13,\n            9.1962e-13, 6.0633e-13, 5.4473e-13, 5.0641e-13, 6.1641e-13, 6.4700e-13,\n            6.5347e-13, 5.0791e-13, 5.6735e-13, 4.3300e-13, 5.6975e-13, 7.0780e-13,\n            6.0708e-13, 6.4581e-13, 5.9985e-13, 5.0284e-13, 7.4942e-13, 4.1959e-13,\n            6.0964e-13, 6.5586e-13, 6.6601e-13, 6.1954e-13, 4.1339e-13, 5.8625e-13,\n            6.3507e-13, 5.5538e-13, 4.5400e-13, 4.3945e-13, 5.7877e-13, 3.2566e-13,\n            5.0215e-13, 5.9680e-13, 5.1559e-13, 4.3879e-13, 6.2816e-13, 5.1413e-13,\n            7.7069e-13, 6.3829e-13, 4.3586e-13, 5.6309e-13, 4.4990e-13, 3.5550e-13,\n            5.1727e-13, 1.1685e-12, 2.0114e-13, 4.8060e-13, 7.3467e-13, 5.4292e-13,\n            4.1987e-13, 7.4425e-13, 4.1131e-13, 3.4293e-13, 5.1456e-13, 5.3166e-13,\n            4.2309e-13, 4.0904e-13, 3.7478e-13, 6.3375e-13, 6.1715e-13, 4.9492e-13,\n            7.9553e-13, 7.2761e-13, 4.3120e-13, 4.1687e-13, 4.9802e-13, 3.1482e-13,\n            4.7526e-13, 6.7108e-13, 6.2497e-13, 6.4221e-13, 3.1699e-13, 5.6566e-13,\n            7.6462e-13, 6.8710e-13, 4.1116e-13, 5.2855e-13, 5.8733e-13, 4.6603e-13,\n            8.5715e-13, 5.3486e-13, 3.3583e-13, 5.0051e-13, 3.2573e-13, 6.5531e-13,\n            4.9291e-13, 7.9268e-13, 4.3729e-13, 3.6567e-13, 4.6635e-13, 4.4014e-13,\n            2.8965e-13, 3.4793e-13, 5.5200e-13, 7.8006e-13, 6.5899e-13, 4.2974e-13,\n            5.5442e-13, 4.6602e-13, 1.9064e-12, 7.1592e-13, 6.9215e-13, 4.7081e-13,\n            7.9180e-13, 5.0662e-13, 3.4623e-13, 3.6033e-13, 6.5852e-13, 5.6805e-13,\n            4.2808e-13, 4.2608e-13, 3.6090e-13, 3.5631e-13, 6.6102e-13, 4.1560e-13,\n            4.7368e-13, 7.9702e-13, 8.4479e-13, 3.3308e-13, 2.6441e-13, 6.1472e-13,\n            4.7067e-13, 5.6835e-13, 6.7939e-13, 6.5108e-13, 8.9304e-13, 5.1052e-13,\n            3.6980e-13, 5.7197e-13, 2.5066e-13, 6.4336e-13, 4.8247e-13, 5.9445e-13,\n            3.7906e-13, 8.3699e-13, 3.7644e-13, 6.1478e-13, 6.6218e-13, 4.7827e-13,\n            3.0922e-13, 3.8114e-13, 6.7225e-13, 8.1445e-13, 6.9777e-13, 4.3512e-13,\n            4.6426e-13, 6.0165e-13, 3.2764e-13, 4.7804e-13, 4.5230e-13, 2.8644e-13,\n            6.1190e-13, 3.4983e-13, 6.6496e-13, 3.5340e-13, 4.4799e-13, 4.4672e-13,\n            5.2169e-13, 3.2161e-13, 3.9206e-13, 4.2373e-13])},\n   50: {'exp_avg': tensor([ 1.0382e-07, -1.0324e-07,  6.0049e-08,  7.5579e-08,  2.6440e-07,\n             2.0245e-07,  6.0697e-08,  1.4187e-08,  1.7847e-07,  6.7018e-08,\n             6.6333e-08,  2.8102e-07, -2.9032e-07, -5.4949e-09, -4.0903e-08,\n            -7.8670e-08,  9.5923e-08, -9.6738e-08,  1.4167e-08,  3.1493e-07,\n             5.1621e-08,  2.9070e-08, -1.2666e-07, -5.0621e-08,  2.1933e-08,\n            -1.0051e-08,  1.9346e-07,  9.3092e-09, -5.0320e-08, -2.0873e-08,\n             5.1435e-08, -1.5885e-07, -7.6808e-08,  1.4809e-07, -1.0390e-07,\n            -4.2207e-08, -5.2613e-08,  6.5459e-08, -1.3790e-07, -2.3117e-07,\n             1.4123e-07, -7.4987e-09,  2.7637e-08,  1.6391e-07, -5.6618e-08,\n             3.9176e-09,  2.1274e-07,  2.1219e-07, -5.4401e-08,  8.0624e-08,\n            -1.4839e-07, -1.7027e-07,  7.3160e-08,  1.7397e-07,  4.2373e-08,\n            -1.4113e-08,  2.9584e-08, -3.0697e-07,  1.1383e-07, -4.5017e-07,\n            -2.2837e-07,  1.4573e-08, -7.8714e-08, -1.0617e-08, -1.0548e-07,\n            -2.2440e-07, -1.6627e-07, -2.8334e-08, -1.0244e-08, -2.5362e-07,\n             1.8524e-07, -1.1358e-07,  6.3599e-09,  2.7209e-08, -1.6216e-07,\n             1.2751e-07, -2.6551e-08, -9.8851e-08,  3.3620e-07,  3.3558e-07,\n             1.6225e-07, -2.6328e-08,  2.0512e-07,  1.3051e-07, -6.9519e-09,\n             1.0400e-07, -1.3359e-07, -8.2804e-08,  1.4630e-07, -1.2522e-07,\n             8.4954e-09, -1.2865e-08,  3.3572e-07,  8.2302e-08,  9.0475e-08,\n            -1.4503e-07, -1.2181e-07, -1.3566e-07, -9.5499e-08, -3.1328e-08,\n            -1.1582e-07,  9.9955e-08, -1.1858e-07,  7.3159e-08, -8.0539e-08,\n             1.6004e-07, -4.3464e-08, -6.4658e-08, -5.3670e-08, -4.7456e-08,\n            -4.9481e-07,  8.2994e-08, -1.4627e-07,  1.1576e-07,  1.7934e-07,\n            -2.4764e-07, -2.9415e-08,  1.3296e-07, -7.2235e-08,  8.4426e-08,\n            -2.2921e-08, -2.0650e-07, -1.8323e-08, -2.3170e-07, -5.9633e-08,\n             7.5203e-09, -1.3607e-07,  1.0836e-07, -1.6116e-07,  7.0989e-08,\n             1.1311e-07,  8.9457e-08,  1.3062e-07, -4.0738e-08,  1.7178e-07,\n            -1.4634e-07,  7.2343e-08,  3.5818e-08,  1.5607e-07, -4.9901e-08,\n            -3.7180e-08,  2.1783e-08, -1.3578e-07, -6.4888e-08,  3.5081e-10,\n             1.0388e-07, -1.7215e-07,  4.1089e-09, -6.6625e-08,  7.7829e-08,\n             8.2809e-08,  7.1877e-08,  2.6859e-08, -1.6889e-07,  8.9856e-08,\n            -1.3015e-07, -4.7721e-08,  1.0598e-07,  1.2509e-07,  1.4613e-07,\n             1.1075e-07, -1.8187e-07,  4.3031e-09, -3.7482e-09,  3.2718e-07,\n             9.5354e-08, -1.2208e-07, -4.1902e-08, -1.8514e-07,  3.1907e-08,\n             8.5271e-08, -4.0719e-08,  7.0682e-09, -2.7716e-07, -1.2610e-07,\n             1.0967e-07,  3.4046e-07, -1.4845e-07,  1.1525e-07, -2.0016e-08,\n            -2.6043e-08,  4.5985e-07,  1.8509e-07, -1.1415e-07, -4.1349e-07,\n            -1.1580e-07,  9.4841e-08, -7.0431e-08, -1.8712e-07, -2.0379e-07,\n             2.6418e-07, -3.8261e-07,  1.5160e-07, -5.8179e-08,  2.8632e-08,\n            -1.6158e-07, -3.0221e-09,  9.4382e-08, -7.3623e-08,  2.2509e-07,\n            -3.1099e-08,  1.4836e-07, -5.7710e-08, -1.0696e-07,  7.7082e-09,\n            -1.0854e-07,  8.4369e-08,  4.1538e-08,  8.6495e-08, -9.8482e-08,\n             9.5830e-08, -1.3155e-07,  3.1054e-08, -1.6472e-08,  3.2243e-08,\n            -1.2189e-08,  8.7174e-08,  2.3413e-07, -2.6814e-07,  8.0251e-08,\n            -2.6357e-07,  1.5182e-07,  4.6954e-07, -4.5440e-08,  1.6978e-07,\n            -1.9679e-07, -2.0971e-08,  1.3044e-07,  2.0193e-07, -1.1823e-07,\n            -1.2628e-07, -1.6092e-07,  3.4171e-07, -1.9463e-08,  9.2698e-08,\n            -2.2820e-07,  1.1574e-07,  5.3361e-08,  1.0134e-07, -4.5145e-08,\n            -1.6562e-07,  4.3245e-08,  7.3045e-08, -1.4458e-07,  9.5329e-08,\n            -2.6392e-08,  9.0437e-08,  9.2290e-08,  1.3422e-07,  5.6442e-09,\n             1.7780e-07, -1.2710e-07,  1.6184e-07, -3.9367e-08, -9.5923e-09,\n             1.5604e-07]),\n    'exp_avg_sq': tensor([2.3364e-13, 2.4026e-13, 4.4354e-13, 6.2087e-13, 4.2314e-13, 4.0101e-13,\n            3.5521e-13, 5.7114e-13, 4.2704e-13, 5.2727e-13, 6.8784e-13, 7.8566e-13,\n            2.9746e-13, 1.8791e-13, 2.7770e-13, 5.9161e-13, 2.3840e-13, 3.3288e-13,\n            3.9285e-13, 6.7469e-13, 1.5871e-13, 3.2180e-13, 3.5787e-13, 4.1300e-13,\n            1.5903e-13, 4.1743e-13, 1.8679e-13, 2.7203e-13, 4.5758e-13, 2.9585e-13,\n            2.1321e-13, 6.9189e-13, 2.2023e-13, 2.1924e-13, 5.1593e-13, 6.3313e-13,\n            2.7895e-13, 4.1703e-13, 2.6839e-13, 4.5152e-13, 5.1460e-13, 2.6473e-13,\n            2.8711e-13, 3.8158e-13, 2.3875e-13, 4.2545e-13, 4.6706e-13, 5.3462e-13,\n            4.7177e-13, 3.2467e-13, 2.8192e-13, 2.0334e-13, 2.7030e-13, 4.2685e-13,\n            4.6577e-13, 1.3055e-13, 4.2382e-13, 4.6786e-13, 1.5131e-13, 5.3396e-13,\n            4.3343e-13, 2.2672e-13, 3.0859e-13, 3.3512e-13, 3.4471e-13, 4.8863e-13,\n            4.0677e-13, 2.8950e-13, 2.4565e-13, 3.2798e-13, 2.5712e-13, 3.0195e-13,\n            2.1130e-13, 1.7379e-13, 5.0434e-13, 4.4651e-13, 2.5274e-13, 4.0481e-13,\n            4.4496e-13, 6.0150e-13, 5.3897e-13, 4.3158e-13, 6.4783e-13, 4.8553e-13,\n            5.7304e-13, 2.3493e-13, 4.6058e-13, 3.1946e-13, 3.4795e-13, 5.7639e-13,\n            2.1345e-13, 3.0919e-13, 5.7739e-13, 2.0260e-13, 3.6116e-13, 3.6580e-13,\n            5.2822e-13, 3.8053e-13, 4.0007e-13, 2.0295e-13, 3.8746e-13, 4.6888e-13,\n            1.8282e-13, 3.4683e-13, 1.9677e-13, 2.2403e-13, 2.6093e-13, 5.1183e-13,\n            3.7561e-13, 8.1071e-13, 9.1489e-13, 2.8690e-13, 5.1340e-13, 2.5984e-13,\n            3.1763e-13, 4.3158e-13, 3.0142e-13, 5.0832e-13, 5.6846e-13, 6.0209e-13,\n            3.3755e-13, 4.2221e-13, 4.3440e-13, 1.1492e-12, 2.5968e-13, 4.9176e-13,\n            4.4513e-13, 5.1589e-13, 5.5623e-13, 2.4429e-13, 3.3532e-13, 5.3976e-13,\n            7.0391e-13, 2.7950e-13, 2.9191e-13, 3.7597e-13, 3.5068e-13, 2.4367e-13,\n            2.7543e-13, 3.5885e-13, 2.5961e-13, 3.8299e-13, 6.5971e-13, 5.5101e-13,\n            3.4453e-13, 1.7698e-13, 5.6969e-13, 3.4474e-13, 2.9188e-13, 3.3048e-13,\n            2.6792e-13, 3.9186e-13, 2.0377e-13, 5.4385e-13, 2.9804e-13, 3.4640e-13,\n            3.6637e-13, 3.0004e-13, 2.5376e-13, 1.5020e-13, 3.8749e-13, 5.9847e-13,\n            6.9351e-13, 1.8589e-13, 9.4664e-13, 4.8488e-13, 2.1291e-13, 5.6368e-13,\n            4.1390e-13, 2.0444e-13, 3.9520e-13, 2.4078e-13, 2.6255e-13, 4.4970e-13,\n            2.9556e-13, 2.7525e-13, 4.0267e-13, 4.2119e-13, 2.2503e-13, 4.1823e-13,\n            2.7729e-13, 4.7175e-13, 3.2602e-13, 3.2958e-13, 7.5842e-13, 6.1976e-13,\n            3.3492e-13, 5.2209e-13, 2.3995e-13, 3.4285e-13, 4.2182e-13, 4.4609e-13,\n            5.3362e-13, 3.0835e-13, 5.9624e-13, 2.5485e-13, 1.7094e-13, 5.1839e-13,\n            3.1457e-13, 3.8360e-13, 2.6038e-13, 3.4251e-13, 1.6611e-13, 5.6966e-13,\n            4.2653e-13, 1.8698e-13, 5.5936e-13, 2.6860e-13, 5.0136e-13, 6.0356e-13,\n            6.1464e-13, 1.7849e-13, 1.9333e-13, 3.4807e-13, 3.9529e-13, 3.9701e-13,\n            1.6270e-13, 1.9061e-13, 3.0867e-13, 4.1224e-13, 8.1724e-13, 2.1783e-13,\n            6.6575e-13, 5.2678e-13, 2.1813e-13, 2.0384e-13, 2.9694e-13, 4.3689e-13,\n            2.7996e-13, 4.1879e-13, 2.7984e-13, 4.1958e-13, 4.2391e-13, 2.8815e-13,\n            4.9930e-13, 4.9399e-13, 1.1308e-12, 3.5383e-13, 3.3282e-13, 4.5875e-13,\n            2.5069e-13, 4.4795e-13, 2.6573e-13, 5.4497e-13, 2.3999e-13, 2.4902e-13,\n            2.6696e-13, 2.8227e-13, 1.7321e-13, 2.9696e-13, 3.8049e-13, 7.9393e-13,\n            5.5233e-13, 3.3924e-13, 4.1415e-13, 2.7142e-13])},\n   51: {'exp_avg': tensor([-2.7404e-08, -4.5643e-08, -1.0421e-07, -1.2118e-07,  4.3448e-08,\n             4.5563e-08, -6.5026e-08, -1.8709e-07,  2.1026e-09, -5.4289e-08,\n             6.7999e-08,  6.4459e-08, -9.5707e-08, -7.2463e-08, -5.6498e-08,\n            -1.2776e-07,  1.2773e-07,  2.9236e-08, -6.9296e-08,  5.1676e-08,\n            -2.2234e-08,  2.9279e-08, -1.8366e-07, -1.2761e-07, -6.5661e-08,\n            -5.8586e-09,  1.8727e-07,  2.3946e-08,  3.9609e-09, -1.7514e-08,\n             3.4757e-08, -1.3229e-07, -1.0193e-07,  9.1445e-08, -9.7042e-08,\n            -7.8886e-08,  4.2919e-09,  6.3509e-08, -8.3245e-08,  3.6356e-08,\n            -7.9820e-09, -8.4394e-09, -7.5242e-08, -2.0802e-08, -3.0771e-08,\n             6.0579e-08,  5.5569e-08,  1.0638e-07,  2.5974e-08,  1.3756e-08,\n            -9.1573e-08, -6.5245e-08,  1.5346e-07,  1.4480e-07, -2.4738e-08,\n            -5.0229e-09, -3.0756e-08,  1.3182e-07,  9.7274e-08, -3.1783e-07,\n            -2.0598e-07, -1.5339e-07, -1.7266e-07, -5.5896e-09, -2.1673e-07,\n            -1.8208e-07, -1.1240e-07, -1.7717e-08, -1.0924e-07, -6.4265e-08,\n             1.9651e-08,  3.4775e-08,  1.1805e-07,  3.1232e-08, -1.1678e-07,\n            -3.0521e-08, -1.0374e-07, -1.6471e-09, -2.8692e-09,  8.2806e-08,\n            -1.2206e-07, -5.7792e-08,  3.1999e-08,  5.0956e-08, -5.8397e-08,\n             1.8670e-08, -1.9411e-07,  4.6235e-08,  2.3346e-07, -2.6393e-08,\n             1.2411e-08, -1.2508e-07, -1.2503e-08,  1.0441e-07,  7.3328e-09,\n            -9.2738e-08, -9.3391e-08,  5.1592e-09, -1.1881e-07, -2.0354e-08,\n            -2.0268e-07, -1.0192e-08, -1.5756e-07,  2.0474e-07, -2.4718e-08,\n            -4.4572e-08,  3.7047e-08, -1.6413e-07, -1.9077e-08, -7.8487e-08,\n            -8.6250e-08, -2.0317e-08, -1.4790e-07,  1.3742e-07,  9.0084e-08,\n            -1.9688e-07, -5.2260e-08, -1.9935e-07, -4.6436e-08, -1.0598e-07,\n             3.9058e-08, -2.0092e-07,  1.8971e-07, -1.8658e-07,  8.2495e-09,\n             3.3266e-08,  2.9607e-08, -6.5687e-08, -1.1675e-08,  1.5055e-07,\n             1.4231e-07,  1.5920e-07,  1.5016e-07, -7.9917e-08,  2.3040e-08,\n            -8.6791e-08, -8.4958e-08, -1.2266e-08,  9.6914e-08, -9.5308e-08,\n            -8.7483e-08,  1.1383e-07, -1.6897e-07,  3.1784e-09,  1.3166e-07,\n             6.4299e-08, -1.3785e-07,  9.4499e-09,  3.2151e-08, -3.6893e-08,\n            -3.3827e-08, -7.4211e-09, -6.5161e-09, -1.7145e-07, -1.6964e-07,\n            -1.7138e-07, -4.2500e-08,  8.6563e-08,  2.8237e-08,  3.1098e-08,\n            -6.5647e-08, -4.4500e-08,  6.8966e-08,  9.3655e-09, -5.7514e-08,\n            -6.0749e-08,  1.5756e-08, -2.2961e-07, -1.1970e-07, -3.3541e-08,\n             3.0198e-08, -9.5398e-08, -1.3431e-09, -2.9412e-07, -6.6697e-08,\n             6.0747e-08,  1.0303e-07, -1.0586e-07,  9.0640e-08, -8.4162e-08,\n            -3.5920e-08,  1.6223e-07,  7.7463e-08, -1.3006e-07, -2.7249e-07,\n            -1.1857e-07,  5.8291e-08, -5.4687e-08,  1.8064e-08, -9.1027e-08,\n             9.5108e-08, -2.0722e-07,  2.3132e-08, -1.4621e-07, -1.0924e-07,\n            -1.8602e-07, -1.4366e-07, -8.8068e-08, -7.1849e-08,  1.2215e-07,\n            -6.8318e-08, -5.8576e-09,  2.2324e-08, -1.4931e-07,  8.3091e-09,\n            -1.1337e-07, -1.7064e-08, -1.3736e-07, -5.0424e-08, -4.0668e-08,\n            -1.3008e-08, -5.9730e-08,  8.8354e-08, -9.6879e-08,  5.1023e-08,\n            -3.0703e-08,  2.0439e-07,  9.5607e-08, -2.7161e-07, -5.4137e-08,\n            -1.2732e-07,  4.9800e-08,  1.9662e-07,  1.5810e-08,  1.5366e-07,\n            -2.0010e-07,  8.2846e-08,  1.2033e-07,  1.3486e-07, -1.9190e-07,\n            -7.7911e-08,  9.7841e-10,  2.8634e-08,  6.7272e-08, -1.2877e-07,\n            -1.1184e-07, -5.2827e-08, -6.2707e-08, -5.6979e-08, -4.7646e-08,\n            -1.7391e-07,  5.5568e-08,  1.3485e-07, -8.5172e-08,  9.8407e-08,\n            -5.7973e-08, -3.5462e-08,  8.4046e-08,  1.3301e-07, -4.2090e-08,\n             4.0329e-08, -3.9290e-07,  1.0982e-07, -1.2822e-07, -1.0491e-07,\n             4.2566e-08]),\n    'exp_avg_sq': tensor([1.8823e-13, 2.1172e-13, 2.2485e-13, 2.7191e-13, 2.0818e-13, 1.5646e-13,\n            1.3938e-13, 3.5108e-13, 2.7016e-13, 2.0501e-13, 2.6261e-13, 2.5292e-13,\n            1.5812e-13, 1.5522e-13, 1.3999e-13, 3.2799e-13, 1.8955e-13, 1.4196e-13,\n            1.8277e-13, 2.3562e-13, 1.2283e-13, 1.5116e-13, 1.8605e-13, 1.6294e-13,\n            1.7333e-13, 1.8112e-13, 1.4136e-13, 1.9279e-13, 3.8586e-13, 1.4846e-13,\n            1.1509e-13, 2.8402e-13, 1.6380e-13, 1.4639e-13, 3.0171e-13, 2.2899e-13,\n            1.3531e-13, 1.9588e-13, 1.4812e-13, 1.9541e-13, 2.0742e-13, 1.7814e-13,\n            1.8689e-13, 1.4473e-13, 1.4994e-13, 2.1216e-13, 2.4670e-13, 2.1373e-13,\n            2.1707e-13, 1.5541e-13, 1.6120e-13, 1.3760e-13, 2.0959e-13, 1.9131e-13,\n            3.1988e-13, 1.4044e-13, 1.9576e-13, 1.8255e-13, 1.2985e-13, 2.4373e-13,\n            1.9664e-13, 1.4686e-13, 2.0064e-13, 2.6916e-13, 1.4989e-13, 1.8482e-13,\n            1.9447e-13, 1.6138e-13, 1.5011e-13, 1.6198e-13, 1.4131e-13, 1.6040e-13,\n            1.7125e-13, 1.9912e-13, 2.0777e-13, 2.3928e-13, 1.8864e-13, 2.4921e-13,\n            2.8037e-13, 2.5202e-13, 2.0435e-13, 1.8288e-13, 2.8818e-13, 2.4560e-13,\n            3.0112e-13, 2.0922e-13, 2.2250e-13, 2.2117e-13, 2.0623e-13, 2.6756e-13,\n            1.6642e-13, 2.2288e-13, 2.6753e-13, 1.2992e-13, 2.1252e-13, 1.6916e-13,\n            2.3170e-13, 2.0935e-13, 2.3866e-13, 1.6869e-13, 1.8016e-13, 2.1468e-13,\n            1.4482e-13, 2.9103e-13, 1.3129e-13, 1.8512e-13, 1.8075e-13, 2.4198e-13,\n            1.7245e-13, 2.7879e-13, 2.9334e-13, 2.0734e-13, 2.4581e-13, 1.5689e-13,\n            1.5650e-13, 2.4838e-13, 1.3793e-13, 1.9604e-13, 2.3173e-13, 3.7007e-13,\n            1.6961e-13, 1.8946e-13, 1.9301e-13, 3.3806e-13, 2.0426e-13, 2.2270e-13,\n            1.7809e-13, 2.1201e-13, 2.2844e-13, 1.4440e-13, 1.8558e-13, 2.1264e-13,\n            2.6645e-13, 1.4240e-13, 1.2359e-13, 2.1370e-13, 1.8232e-13, 1.6480e-13,\n            1.3622e-13, 1.8408e-13, 1.3388e-13, 1.6691e-13, 2.7443e-13, 2.1449e-13,\n            2.7444e-13, 1.3684e-13, 1.9636e-13, 1.7533e-13, 1.5431e-13, 1.7264e-13,\n            1.4113e-13, 2.1863e-13, 1.5850e-13, 3.2757e-13, 1.6292e-13, 1.5474e-13,\n            2.2656e-13, 2.0447e-13, 1.5629e-13, 1.1483e-13, 1.5572e-13, 3.7928e-13,\n            2.2290e-13, 1.0685e-13, 2.9297e-13, 1.8516e-13, 1.7237e-13, 2.5132e-13,\n            2.1115e-13, 1.4055e-13, 2.3221e-13, 2.1847e-13, 1.6131e-13, 3.1345e-13,\n            1.9993e-13, 1.3533e-13, 1.9314e-13, 1.6656e-13, 1.3962e-13, 2.3879e-13,\n            1.2244e-13, 2.1323e-13, 1.5900e-13, 1.8730e-13, 2.3893e-13, 3.0876e-13,\n            1.5158e-13, 2.0193e-13, 1.3954e-13, 1.7032e-13, 1.6986e-13, 1.5800e-13,\n            2.3464e-13, 2.0111e-13, 2.5644e-13, 1.6312e-13, 1.2531e-13, 2.0591e-13,\n            1.7496e-13, 1.3843e-13, 1.3157e-13, 1.4197e-13, 1.4012e-13, 2.5649e-13,\n            2.6325e-13, 1.6543e-13, 2.2076e-13, 1.5821e-13, 1.9478e-13, 2.2153e-13,\n            2.4559e-13, 1.6504e-13, 1.3880e-13, 1.7652e-13, 1.6458e-13, 2.7930e-13,\n            1.4645e-13, 1.3551e-13, 2.3357e-13, 2.1712e-13, 3.0516e-13, 1.3276e-13,\n            3.1491e-13, 2.8623e-13, 1.2595e-13, 2.0186e-13, 1.7513e-13, 1.7084e-13,\n            1.5216e-13, 1.8769e-13, 1.6945e-13, 2.7369e-13, 1.6475e-13, 1.4806e-13,\n            1.9805e-13, 2.7988e-13, 3.3804e-13, 1.9162e-13, 1.8549e-13, 2.8199e-13,\n            1.7558e-13, 2.4238e-13, 1.7689e-13, 2.4278e-13, 1.7660e-13, 1.9943e-13,\n            1.6951e-13, 1.4113e-13, 1.0299e-13, 1.7631e-13, 1.6407e-13, 2.7563e-13,\n            1.9882e-13, 1.5381e-13, 1.9101e-13, 1.2082e-13])},\n   52: {'exp_avg': tensor([-6.6304e-08, -3.8885e-08, -7.1128e-08,  ..., -2.5439e-07,\n            -2.6528e-07, -6.1704e-08]),\n    'exp_avg_sq': tensor([8.0350e-13, 1.0828e-12, 8.8266e-13,  ..., 1.2479e-12, 1.7330e-12,\n            8.0825e-13])},\n   53: {'exp_avg': tensor([-1.3947e-07,  3.5381e-08,  7.7707e-08,  ..., -7.9249e-08,\n             1.3416e-07, -5.5919e-08]),\n    'exp_avg_sq': tensor([5.1905e-13, 4.5654e-13, 5.1709e-13,  ..., 5.4307e-13, 8.0573e-13,\n            7.7725e-13])},\n   54: {'exp_avg': tensor([-1.7963e-07, -1.0317e-08,  1.3021e-07,  ..., -2.9105e-08,\n             6.7233e-08, -1.1202e-07]),\n    'exp_avg_sq': tensor([3.8945e-13, 2.3605e-13, 9.0625e-13,  ..., 1.0934e-13, 4.2899e-13,\n            6.2287e-13])},\n   55: {'exp_avg': tensor([-1.3947e-07,  3.5381e-08,  7.7707e-08,  ..., -7.9249e-08,\n             1.3416e-07, -5.5919e-08]),\n    'exp_avg_sq': tensor([5.1905e-13, 4.5654e-13, 5.1709e-13,  ..., 5.4307e-13, 8.0573e-13,\n            7.7725e-13])},\n   56: {'exp_avg': tensor([-4.5029e-08, -7.5629e-09, -1.7163e-07,  5.6698e-09,  5.1617e-08,\n            -6.2046e-08, -1.1942e-07, -4.1861e-08, -3.1330e-08,  1.2227e-07,\n             6.6037e-08,  1.2961e-07, -1.4060e-07,  2.8657e-08,  1.2164e-07,\n             1.3722e-07, -2.6097e-08, -6.0225e-08, -7.3143e-08,  1.8038e-07,\n             6.8379e-08, -4.3697e-08,  1.3681e-07, -8.2867e-08,  2.2422e-08,\n             1.6834e-08, -2.3514e-08,  6.1918e-08,  1.0012e-08,  5.6318e-09,\n             1.9232e-07,  6.9046e-08, -9.3275e-08,  1.4376e-07, -2.2027e-07,\n            -2.6527e-07, -1.3422e-07,  6.3595e-08,  2.9135e-07,  1.7704e-07,\n            -4.3114e-08, -5.3789e-08,  2.6560e-08,  9.9169e-09, -1.1419e-08,\n             1.4343e-08, -2.6665e-07, -1.3578e-07, -6.5592e-08, -2.6605e-08,\n             1.8719e-07, -2.5507e-08, -4.3724e-08, -5.5112e-08,  4.7014e-08,\n             1.0479e-07, -9.5183e-08, -1.3329e-07,  1.5557e-07, -1.0104e-07,\n            -1.0341e-07, -1.2027e-08,  7.2255e-08, -8.1306e-08,  1.1820e-08,\n            -1.7823e-08, -9.8783e-08, -6.3977e-09,  2.2016e-08,  7.9978e-08,\n             1.3860e-07,  2.3400e-08, -4.0196e-08, -3.6381e-08, -8.7058e-08,\n             2.4831e-08, -1.2915e-08,  2.4541e-08, -4.2565e-08, -1.1127e-07,\n            -1.4528e-07, -3.7442e-08, -5.7640e-08,  5.6904e-08, -6.0757e-08,\n             4.1333e-08, -2.2950e-07,  1.4698e-07, -4.9739e-08,  2.4565e-08,\n            -3.3707e-08,  3.0909e-08,  6.6865e-09,  5.0481e-08, -1.3167e-07,\n            -2.6131e-08, -1.1869e-07,  6.8105e-08,  6.1163e-08,  1.0186e-07,\n             4.3043e-08, -7.9606e-08, -2.6317e-09, -5.4069e-08,  1.3848e-07,\n             5.2348e-08,  1.0361e-07,  1.4017e-07, -1.4714e-08, -7.0571e-08,\n            -2.0224e-07, -3.2449e-09,  8.8923e-08,  6.9779e-08,  2.2033e-07,\n            -2.6083e-08, -2.4836e-08, -3.4068e-08, -5.2036e-08,  1.4872e-08,\n             1.2561e-08,  1.7311e-08,  1.0196e-09, -1.2298e-08, -7.0968e-08,\n            -1.5280e-07, -4.8310e-08,  3.1622e-08, -8.3963e-08, -3.3576e-08,\n             4.4499e-08,  1.7192e-08,  5.7649e-09, -1.2198e-07, -5.7993e-08,\n            -1.2826e-07, -3.6098e-08, -8.3114e-08, -3.1925e-08,  6.2442e-08,\n            -8.3095e-08,  6.5866e-08,  1.8624e-07, -2.2417e-08,  2.7715e-08,\n             2.0392e-07,  1.2243e-07,  4.5107e-08, -2.0974e-08,  7.2893e-08,\n            -8.7691e-08,  3.4038e-08, -1.8040e-07,  1.3869e-07,  1.3461e-08,\n             7.0620e-08, -4.5687e-08, -8.3816e-09, -6.9762e-08,  1.1609e-07,\n             2.2204e-08,  8.0183e-08,  1.0177e-07,  3.4921e-08, -5.6503e-08,\n            -6.5292e-08, -3.1213e-09,  1.1561e-07, -6.8856e-08,  5.9726e-08,\n             4.1832e-08,  4.9962e-08,  2.7275e-09, -1.6758e-08,  1.4538e-08,\n            -9.0190e-08,  1.9490e-07,  4.1458e-08,  7.3811e-08, -2.6466e-08,\n             1.7672e-07, -1.1743e-07,  1.0153e-07,  5.7907e-08, -1.4556e-07,\n            -1.1064e-07,  5.1264e-08, -6.9417e-08,  2.8782e-08,  8.4194e-08,\n             4.9509e-08, -4.1793e-09, -2.4835e-08, -2.5612e-07, -2.6584e-08,\n             8.4349e-08,  1.1830e-07, -1.3300e-07,  2.4458e-08,  6.4253e-09,\n             2.5419e-07, -1.2976e-07, -1.0993e-07,  3.7122e-08,  7.3723e-08,\n             1.5476e-08, -1.3802e-07,  5.6575e-08,  7.2617e-08, -9.8145e-09,\n            -1.0449e-07,  6.7543e-08, -8.4178e-09,  4.2556e-08,  8.8204e-09,\n             5.0752e-08,  5.3434e-08, -8.9440e-08,  1.1244e-07, -3.3071e-08,\n             3.9900e-08,  1.1441e-07, -3.1781e-08, -1.2656e-07,  1.2911e-08,\n            -5.5285e-08, -3.1339e-07,  5.2493e-08,  6.2109e-08, -9.9865e-09,\n             4.3529e-08,  1.8780e-08, -1.4342e-08, -2.4686e-07,  9.3257e-09,\n             1.6212e-08,  7.5853e-09,  6.3512e-08, -2.9742e-08,  1.4271e-07,\n            -5.1631e-08,  7.4420e-09,  1.1404e-07,  1.2845e-07,  1.2814e-07,\n            -1.5308e-07, -5.6924e-09, -4.6829e-08,  7.0630e-08, -8.6379e-08,\n            -1.0679e-07, -6.7935e-08,  3.6457e-08,  1.8430e-07,  5.1190e-08,\n            -1.7173e-07]),\n    'exp_avg_sq': tensor([1.6165e-13, 1.7341e-13, 1.0745e-13, 1.7041e-13, 1.8804e-13, 2.0161e-13,\n            1.3176e-13, 2.1760e-13, 1.8646e-13, 1.4414e-13, 2.2670e-13, 1.6776e-13,\n            1.0879e-13, 1.2139e-13, 1.9192e-13, 1.3523e-13, 1.0145e-13, 2.2431e-13,\n            1.9778e-13, 1.9438e-13, 2.0569e-13, 1.6835e-13, 1.2591e-13, 2.2322e-13,\n            2.9244e-13, 1.8869e-13, 2.5979e-13, 1.1196e-13, 1.2624e-13, 1.4591e-13,\n            1.8560e-13, 1.6990e-13, 1.9225e-13, 1.6296e-13, 2.0120e-13, 3.0700e-13,\n            1.5615e-13, 1.3240e-13, 3.2489e-13, 2.4840e-13, 1.7967e-13, 1.0353e-13,\n            1.4006e-13, 1.9406e-13, 1.1904e-13, 2.0480e-13, 2.2806e-13, 2.3642e-13,\n            9.9672e-14, 1.2137e-13, 2.1010e-13, 2.3392e-13, 1.4048e-13, 2.3424e-13,\n            1.7566e-13, 2.6172e-13, 1.9654e-13, 2.4602e-13, 1.5152e-13, 3.0946e-13,\n            1.9880e-13, 3.2161e-13, 1.4578e-13, 1.3229e-13, 1.4027e-13, 1.6100e-13,\n            1.4555e-13, 1.8983e-13, 1.8308e-13, 2.1363e-13, 1.8144e-13, 1.6869e-13,\n            2.6699e-13, 1.3403e-13, 1.8857e-13, 1.8965e-13, 1.3694e-13, 1.9232e-13,\n            3.0449e-13, 2.3244e-13, 1.9123e-13, 1.2669e-13, 2.1085e-13, 2.2748e-13,\n            1.5819e-13, 2.0472e-13, 2.6912e-13, 2.2308e-13, 1.2717e-13, 3.8915e-13,\n            1.9995e-13, 1.5823e-13, 1.9413e-13, 1.1887e-13, 1.3179e-13, 1.2701e-13,\n            2.3814e-13, 1.1316e-13, 1.4855e-13, 1.5722e-13, 2.1463e-13, 1.8899e-13,\n            1.5498e-13, 1.4592e-13, 1.4532e-13, 2.4211e-13, 9.7906e-14, 1.5902e-13,\n            1.6064e-13, 1.9030e-13, 2.2350e-13, 3.3047e-13, 1.9670e-13, 1.3445e-13,\n            3.7178e-13, 1.8776e-13, 2.4171e-13, 2.7766e-13, 3.8810e-13, 1.2209e-13,\n            2.5592e-13, 1.9948e-13, 1.6923e-13, 2.0402e-13, 4.3423e-13, 1.6274e-13,\n            1.6974e-13, 1.7841e-13, 1.6879e-13, 2.5294e-13, 1.6897e-13, 1.4605e-13,\n            2.0924e-13, 2.4124e-13, 2.4531e-13, 1.8937e-13, 1.1919e-13, 1.3762e-13,\n            1.2506e-13, 1.9926e-13, 9.8124e-14, 1.7128e-13, 1.7331e-13, 1.3348e-13,\n            1.7254e-13, 2.2421e-13, 1.4506e-13, 1.5581e-13, 1.1539e-13, 1.9753e-13,\n            1.0605e-13, 1.3780e-13, 1.2326e-13, 2.0021e-13, 1.5263e-13, 1.2884e-13,\n            1.9116e-13, 1.0893e-13, 1.0886e-13, 1.1787e-13, 2.2223e-13, 1.9428e-13,\n            1.4331e-13, 1.6279e-13, 1.4863e-13, 1.7837e-13, 1.1988e-13, 1.1221e-13,\n            1.5868e-13, 2.1844e-13, 1.6325e-13, 1.3249e-13, 1.8758e-13, 2.2176e-13,\n            1.8239e-13, 1.6475e-13, 1.8265e-13, 1.2029e-13, 1.6821e-13, 1.7905e-13,\n            2.3785e-13, 1.7122e-13, 2.4050e-13, 2.1264e-13, 2.0094e-13, 1.6721e-13,\n            1.4447e-13, 1.7545e-13, 2.4878e-13, 1.7473e-13, 1.2088e-13, 2.5698e-13,\n            1.9129e-13, 3.5642e-13, 2.5139e-13, 1.6452e-13, 2.1674e-13, 1.8396e-13,\n            2.0214e-13, 1.5355e-13, 1.7066e-13, 3.0070e-13, 1.8791e-13, 2.3386e-13,\n            1.2331e-13, 2.0862e-13, 2.0419e-13, 3.1931e-13, 1.9804e-13, 1.8625e-13,\n            1.5973e-13, 1.6993e-13, 1.0432e-13, 1.1618e-13, 2.3644e-13, 2.1463e-13,\n            1.5331e-13, 1.4673e-13, 1.9485e-13, 1.1914e-13, 1.1017e-13, 1.6190e-13,\n            1.9304e-13, 1.7399e-13, 1.5737e-13, 2.2595e-13, 3.2669e-13, 1.6217e-13,\n            1.4385e-13, 1.7128e-13, 1.6150e-13, 1.2551e-13, 1.4894e-13, 1.9424e-13,\n            1.3663e-13, 1.3464e-13, 2.2575e-13, 2.5533e-13, 1.6792e-13, 2.0175e-13,\n            1.8147e-13, 2.2901e-13, 1.9561e-13, 3.7734e-13, 1.7099e-13, 2.1221e-13,\n            1.4374e-13, 1.6128e-13, 2.2248e-13, 2.7769e-13, 1.8918e-13, 1.5459e-13,\n            2.9867e-13, 3.2595e-13, 1.2605e-13, 1.6594e-13])},\n   57: {'exp_avg': tensor([-7.6735e-08, -1.7589e-08, -1.0927e-07, -3.5826e-08,  6.4685e-08,\n            -1.9407e-08, -7.5822e-08, -3.1585e-08, -8.5160e-08,  1.1502e-07,\n             1.5378e-08,  9.1957e-08, -9.4605e-08, -2.6394e-08,  7.0316e-08,\n             7.0491e-09,  1.0079e-07, -2.5057e-09, -1.0319e-07,  1.2815e-07,\n             7.4188e-08, -1.2551e-07,  4.1009e-08, -1.1891e-07, -4.9268e-08,\n             7.5251e-08, -2.9608e-08, -2.1264e-08,  7.1961e-08, -2.8625e-08,\n             1.1182e-07,  3.4462e-08, -5.8977e-08,  1.6570e-07, -1.4039e-07,\n            -1.3521e-07, -7.8036e-08, -4.9916e-08,  1.9105e-07,  5.5239e-08,\n            -4.6967e-08, -5.5027e-09, -3.0922e-08,  5.5948e-08, -5.3442e-08,\n            -2.9475e-08, -2.2853e-07, -2.1155e-07,  1.7617e-08,  3.4722e-08,\n             1.0589e-07, -2.5590e-08,  1.7626e-08, -9.7276e-09,  3.5326e-08,\n             8.6463e-08, -6.5096e-08, -9.3776e-08,  9.9500e-08, -9.5446e-08,\n            -8.0270e-08,  1.2410e-08, -4.1853e-08,  1.7666e-09,  7.2422e-08,\n            -2.2073e-08, -4.4415e-08, -1.8303e-08,  2.9621e-08,  5.9842e-08,\n             4.4329e-08, -1.9909e-08, -9.1770e-08,  4.2260e-08, -1.1159e-07,\n            -2.1646e-08,  5.9496e-08, -7.0869e-08, -4.5724e-08, -9.2323e-08,\n            -3.8978e-08,  1.9146e-08,  3.5119e-09, -7.0689e-08,  9.0781e-09,\n            -6.8237e-08, -1.4742e-07,  7.9044e-08, -5.2097e-08, -1.1412e-07,\n             2.4598e-08, -4.0571e-08, -3.5297e-08,  5.0597e-08, -4.6574e-08,\n            -4.5963e-08, -1.4716e-08,  5.8961e-08,  9.6899e-08,  3.1099e-08,\n            -1.0299e-07,  8.5295e-08, -2.3366e-08, -6.3987e-08,  1.8323e-07,\n            -1.5491e-08,  9.7552e-08,  6.4087e-08,  4.1387e-08, -2.5128e-08,\n            -1.3056e-07, -2.4670e-08,  3.0851e-08, -2.6401e-08,  1.1871e-07,\n             8.2843e-08, -4.9014e-08, -5.3047e-08,  1.5866e-08,  2.9096e-08,\n             4.4363e-08,  2.3391e-08, -5.6148e-08,  2.1494e-08, -8.9630e-08,\n            -8.3827e-08, -5.4625e-08,  5.1565e-08, -7.5094e-08, -8.4443e-08,\n             4.5171e-08,  2.8247e-08, -3.4440e-08, -1.1052e-07, -4.4788e-08,\n             2.1174e-09,  6.7266e-09, -4.6614e-08, -4.7871e-08,  2.8306e-08,\n            -1.2941e-07,  6.7364e-08,  1.1740e-07,  2.8718e-08,  1.2095e-08,\n             2.1944e-07,  1.1257e-07,  6.3290e-08,  1.8194e-08, -6.2898e-08,\n            -1.3231e-09,  2.9758e-08, -1.7669e-07,  1.0539e-07,  9.8412e-08,\n             1.0165e-07, -3.6221e-09, -5.7252e-08, -3.2181e-08,  7.6334e-08,\n             3.1157e-08,  8.5489e-08,  8.9224e-09,  7.2688e-09, -2.8404e-08,\n            -1.0256e-07, -3.8415e-08,  6.4202e-08,  4.1549e-08, -4.6469e-08,\n             2.9756e-08,  5.3976e-08,  1.2098e-08,  2.4907e-08, -6.3984e-08,\n            -6.0303e-08,  1.0996e-07, -8.2283e-09,  5.5383e-08,  4.8662e-08,\n             7.4311e-08, -7.3346e-08,  1.8042e-07, -2.4623e-08, -8.1501e-08,\n            -7.3395e-08,  2.9263e-08, -2.5649e-08,  5.0566e-08,  3.1528e-08,\n             6.7066e-08,  5.5318e-08, -8.4754e-09, -1.9852e-07,  4.2141e-09,\n             2.0600e-08,  8.4477e-08, -8.3336e-09,  5.8848e-09, -1.8112e-08,\n             2.4550e-07, -8.2186e-08, -1.0217e-07,  1.6066e-08, -9.8872e-09,\n            -2.0490e-08, -8.2740e-08,  1.4614e-07, -3.9931e-08, -3.1180e-08,\n            -2.1399e-08,  8.7390e-08,  2.3839e-08,  1.9594e-08,  3.6677e-08,\n             6.4125e-08,  2.2462e-08, -8.8563e-08,  1.1069e-07, -5.2432e-08,\n             5.2152e-09,  1.3535e-07, -5.4490e-08, -1.3162e-07, -1.7486e-08,\n             3.0881e-08, -2.4259e-07, -6.5082e-08,  2.9741e-08, -1.5822e-09,\n             2.0410e-08, -4.2550e-08, -1.4832e-08, -1.8606e-07,  3.8419e-09,\n             5.4286e-08,  9.6927e-08, -1.3751e-08, -6.1637e-08,  1.3498e-07,\n             6.8107e-08,  6.5531e-08, -3.0405e-08,  6.5393e-08,  5.5010e-09,\n            -1.4834e-07,  3.9619e-08, -1.1267e-08,  6.8917e-08, -1.1926e-07,\n            -6.6705e-08,  2.0353e-08, -3.4019e-09,  1.6016e-07,  1.1363e-07,\n            -1.4893e-07]),\n    'exp_avg_sq': tensor([1.1486e-13, 1.1158e-13, 8.9525e-14, 1.3355e-13, 1.2909e-13, 1.2947e-13,\n            1.0307e-13, 1.5016e-13, 1.4000e-13, 8.5364e-14, 1.4654e-13, 1.3077e-13,\n            1.1030e-13, 9.1952e-14, 1.4126e-13, 1.1082e-13, 9.4083e-14, 1.2976e-13,\n            1.3070e-13, 1.2882e-13, 1.0565e-13, 1.2392e-13, 9.6847e-14, 1.2065e-13,\n            1.5831e-13, 1.0098e-13, 1.4639e-13, 8.4016e-14, 9.6164e-14, 9.9162e-14,\n            1.2353e-13, 1.0395e-13, 1.2304e-13, 1.2455e-13, 1.2609e-13, 1.3310e-13,\n            1.1033e-13, 9.9841e-14, 1.7819e-13, 1.6574e-13, 1.1208e-13, 9.5966e-14,\n            1.0665e-13, 1.3556e-13, 9.3916e-14, 1.2501e-13, 1.3577e-13, 1.4673e-13,\n            8.0301e-14, 9.7017e-14, 1.5129e-13, 1.9613e-13, 1.0440e-13, 1.5028e-13,\n            1.0197e-13, 1.5984e-13, 1.6889e-13, 1.3538e-13, 1.1331e-13, 1.5048e-13,\n            1.3043e-13, 1.9635e-13, 1.0564e-13, 1.0701e-13, 1.0844e-13, 1.1130e-13,\n            1.0922e-13, 1.4874e-13, 1.2222e-13, 1.1238e-13, 1.1386e-13, 1.2889e-13,\n            1.6318e-13, 1.0571e-13, 1.2874e-13, 1.0622e-13, 1.2504e-13, 1.1402e-13,\n            1.8784e-13, 1.3041e-13, 1.1835e-13, 8.4636e-14, 1.6252e-13, 1.6455e-13,\n            9.8808e-14, 1.4076e-13, 1.4880e-13, 1.6783e-13, 1.0630e-13, 2.3108e-13,\n            1.3529e-13, 1.0177e-13, 1.2719e-13, 9.2767e-14, 9.9812e-14, 1.1094e-13,\n            1.3319e-13, 8.5261e-14, 9.2441e-14, 1.2157e-13, 1.6130e-13, 1.2827e-13,\n            1.1739e-13, 1.0666e-13, 1.1616e-13, 1.2285e-13, 9.2266e-14, 1.1865e-13,\n            9.8615e-14, 1.4058e-13, 1.4752e-13, 2.3741e-13, 1.3465e-13, 9.6345e-14,\n            1.6294e-13, 1.3117e-13, 9.8568e-14, 1.3400e-13, 2.5146e-13, 1.0475e-13,\n            1.4809e-13, 1.2470e-13, 1.0652e-13, 1.1488e-13, 1.6366e-13, 1.1670e-13,\n            1.0150e-13, 1.0478e-13, 1.1406e-13, 1.1939e-13, 1.1695e-13, 9.8488e-14,\n            1.4589e-13, 1.7380e-13, 1.5011e-13, 1.1609e-13, 9.1445e-14, 1.0492e-13,\n            8.5715e-14, 1.3356e-13, 9.0236e-14, 1.1498e-13, 1.1240e-13, 9.3960e-14,\n            1.1793e-13, 1.4313e-13, 9.4873e-14, 1.1297e-13, 9.6630e-14, 1.2588e-13,\n            9.8165e-14, 9.8322e-14, 8.9479e-14, 1.3834e-13, 1.1964e-13, 1.2883e-13,\n            1.2008e-13, 9.4493e-14, 1.1333e-13, 1.0490e-13, 1.5973e-13, 1.1430e-13,\n            1.2914e-13, 1.1011e-13, 1.2485e-13, 1.5736e-13, 9.7890e-14, 7.6808e-14,\n            1.0968e-13, 1.3217e-13, 1.2163e-13, 8.6567e-14, 1.2404e-13, 1.4567e-13,\n            1.2284e-13, 1.1728e-13, 1.2229e-13, 8.7538e-14, 1.1036e-13, 1.2896e-13,\n            1.6037e-13, 1.1329e-13, 1.7376e-13, 1.5050e-13, 1.1400e-13, 1.5564e-13,\n            1.1889e-13, 1.3452e-13, 1.4136e-13, 1.1393e-13, 1.2321e-13, 1.7829e-13,\n            1.2153e-13, 1.5071e-13, 1.8619e-13, 9.6736e-14, 1.4168e-13, 1.2207e-13,\n            1.1131e-13, 1.1785e-13, 1.5589e-13, 1.9338e-13, 1.3780e-13, 1.4057e-13,\n            1.1453e-13, 1.2981e-13, 1.3429e-13, 1.6971e-13, 1.2572e-13, 1.0821e-13,\n            1.8677e-13, 1.1522e-13, 9.0650e-14, 9.2198e-14, 1.3644e-13, 1.3780e-13,\n            1.0337e-13, 1.0972e-13, 1.3699e-13, 9.3677e-14, 8.1729e-14, 1.2050e-13,\n            1.2157e-13, 1.3060e-13, 1.0875e-13, 1.2717e-13, 1.7847e-13, 1.0212e-13,\n            9.5003e-14, 1.0428e-13, 1.0715e-13, 1.2162e-13, 1.1455e-13, 1.7036e-13,\n            1.0332e-13, 9.9752e-14, 1.3692e-13, 1.3461e-13, 1.2438e-13, 1.4219e-13,\n            1.3505e-13, 1.5225e-13, 1.2341e-13, 1.7923e-13, 1.3706e-13, 1.5358e-13,\n            1.2034e-13, 1.2458e-13, 1.1830e-13, 1.7252e-13, 1.0623e-13, 1.1799e-13,\n            1.4129e-13, 1.6399e-13, 1.0637e-13, 1.2002e-13])},\n   58: {'exp_avg': tensor([-8.6437e-08, -9.7561e-08,  9.6612e-08, -3.1665e-08, -1.1803e-07,\n            -2.1077e-07,  9.7761e-09, -2.6721e-08,  3.4890e-08, -3.6745e-08,\n             3.3054e-07,  4.6999e-08, -2.8260e-07, -6.5208e-08,  6.0049e-08,\n            -2.1780e-07, -1.1157e-07, -6.1124e-08,  3.1887e-08,  1.1899e-08,\n             2.1905e-08, -1.3612e-07,  5.1619e-09, -1.8394e-07,  4.9066e-08,\n             1.4293e-08, -5.4288e-08, -1.2010e-07,  2.9351e-09, -1.6151e-07,\n            -1.1286e-07,  2.8899e-08,  1.4548e-07, -1.4137e-08, -3.5582e-08,\n            -1.4959e-07,  9.1206e-08,  1.0676e-07,  2.7443e-08,  1.6159e-08,\n            -1.2456e-07,  1.5329e-07, -1.4101e-07,  1.2540e-07,  6.3678e-08,\n            -1.6743e-07, -1.9750e-07,  1.1930e-07,  1.4226e-08, -1.3607e-07,\n             1.0160e-07, -4.9805e-08,  2.9678e-08,  9.0799e-08,  5.7254e-08,\n            -1.8233e-07,  9.6933e-08, -7.5602e-08,  1.2761e-07, -1.6231e-07,\n             1.2669e-07,  2.8131e-08, -7.4928e-08,  8.2264e-09,  8.3238e-08,\n             4.1313e-08,  7.2684e-08,  7.8604e-08, -1.5196e-07,  2.1150e-07,\n            -1.6760e-08, -1.6708e-07,  8.6640e-08,  2.9927e-07, -1.2613e-07,\n             9.8538e-08,  1.7158e-07, -1.0318e-07, -5.6275e-08, -1.2387e-07,\n             4.9912e-08,  2.2220e-07, -1.0515e-07, -8.4838e-08, -1.5479e-07,\n             4.9783e-08,  1.6317e-07, -2.5333e-07, -2.9608e-07,  8.3737e-08,\n             1.2860e-07,  1.5824e-07,  2.8355e-07, -5.5288e-08,  1.0083e-07,\n             1.0673e-07,  1.3685e-07, -6.2425e-08,  7.8673e-08,  3.8573e-07,\n            -4.3563e-07,  2.0079e-07, -4.9977e-08, -1.7974e-07,  1.1221e-07,\n             1.1860e-07,  8.7676e-08,  2.6377e-09,  1.7693e-07,  4.0816e-08,\n             1.2710e-07, -5.8849e-08, -1.4362e-07,  1.0622e-07, -7.2602e-08,\n             8.9162e-08, -1.4642e-07, -8.1316e-08,  3.9742e-08, -2.5564e-08,\n            -2.4339e-07,  1.1882e-08,  1.5460e-08,  3.4098e-08, -2.1719e-08,\n             7.1250e-08,  2.4524e-07, -8.2163e-08, -1.3482e-07, -3.3602e-08,\n             2.2967e-08,  5.5504e-08, -1.4375e-07, -2.1462e-07, -1.8691e-07,\n             1.0617e-07,  3.6713e-08, -1.1003e-07, -6.1710e-08,  2.9070e-08,\n             3.2163e-08,  2.7113e-07,  7.4914e-08, -6.7821e-08, -6.4843e-08,\n            -5.1291e-08,  1.3238e-07,  1.1935e-08,  1.6709e-07, -1.4635e-08,\n            -2.3631e-07,  3.7181e-08,  3.5237e-08,  1.8668e-07, -1.9616e-07,\n             9.1008e-10, -3.3589e-07,  7.9008e-08,  9.0659e-08, -1.1303e-07,\n            -5.4358e-08,  1.3635e-07,  1.4227e-07,  1.4165e-07,  1.8785e-07,\n             9.2052e-08, -7.5429e-08,  6.2810e-08,  2.1877e-07,  3.3966e-08,\n             1.4708e-07, -4.9465e-09,  6.9639e-08, -5.8351e-08, -4.6571e-08,\n             1.6083e-07,  4.2277e-08, -8.7509e-08, -1.4856e-07,  7.1974e-08,\n             1.3608e-07, -2.0051e-07,  4.8318e-08, -1.4616e-07, -6.4208e-08,\n             1.1888e-07,  1.1924e-07, -1.0213e-07, -1.0107e-07,  2.1504e-08,\n             3.9923e-08, -7.2805e-08,  3.8216e-08,  5.6202e-08,  8.0356e-08,\n            -1.4705e-07,  1.7968e-08,  1.2862e-07, -1.1578e-07, -1.3120e-07,\n             2.3370e-07, -1.0754e-07, -1.1736e-07, -1.7597e-07, -1.2398e-07,\n            -1.1258e-07, -3.5808e-08,  4.5917e-08,  5.7716e-08, -2.9335e-08,\n             1.0203e-07, -7.3123e-09,  1.0500e-07, -8.5214e-08, -1.3017e-07,\n             4.2374e-08, -1.1158e-07,  2.5087e-07,  7.0655e-08,  2.5285e-07,\n            -8.2577e-09,  7.3517e-08, -4.9275e-08, -1.7363e-08,  1.0292e-07,\n            -1.8026e-07,  2.2913e-07,  1.7174e-07,  9.4711e-09, -1.1522e-08,\n            -1.2217e-07,  1.1870e-07, -1.1840e-07,  9.1244e-08, -5.0167e-08,\n             2.4040e-07, -1.7339e-07,  1.6563e-07, -1.7534e-07,  1.0791e-07,\n            -1.9038e-07,  1.1824e-07,  7.0093e-08,  1.2203e-07,  9.9540e-08,\n            -1.6275e-07, -2.3630e-07, -5.4773e-08, -2.9271e-08,  7.8301e-09,\n            -2.8914e-07, -8.0152e-08,  1.3386e-07, -9.2021e-08, -1.2483e-07,\n             7.3846e-08]),\n    'exp_avg_sq': tensor([3.4524e-13, 5.5548e-13, 2.3427e-13, 4.7052e-13, 1.8848e-13, 5.5762e-13,\n            2.3765e-13, 3.8882e-13, 1.3715e-13, 2.5150e-13, 1.4458e-12, 2.3102e-13,\n            4.3241e-13, 5.5357e-13, 2.2970e-13, 2.6535e-13, 5.0310e-13, 2.7407e-13,\n            1.5922e-13, 1.6380e-13, 5.3285e-13, 1.0247e-13, 3.8409e-13, 3.8892e-13,\n            4.2572e-13, 1.4568e-13, 6.3788e-13, 2.6152e-13, 7.6961e-13, 2.5709e-13,\n            1.8910e-13, 3.2386e-13, 4.0356e-13, 2.2556e-13, 3.3925e-13, 2.3043e-13,\n            1.5330e-13, 3.3745e-13, 3.3521e-13, 4.5456e-13, 2.9014e-13, 3.3696e-13,\n            3.9410e-13, 3.6213e-13, 1.6311e-13, 2.9982e-13, 2.8015e-13, 2.3478e-13,\n            4.9121e-13, 3.0948e-13, 5.7259e-13, 2.1882e-13, 4.5104e-13, 1.9419e-13,\n            1.9536e-13, 3.6257e-13, 2.7790e-13, 3.7315e-13, 3.7404e-13, 5.3118e-13,\n            2.6812e-13, 2.4797e-13, 2.4451e-13, 2.8699e-13, 2.0762e-13, 2.3966e-12,\n            2.6611e-13, 1.4260e-13, 2.1095e-13, 2.9021e-13, 1.7542e-13, 2.7973e-13,\n            5.8359e-13, 4.7990e-13, 2.7128e-13, 2.5246e-13, 3.4250e-13, 2.5010e-13,\n            1.1333e-13, 2.8351e-13, 2.6036e-13, 2.2842e-13, 2.3558e-13, 2.3593e-13,\n            5.1109e-13, 3.0916e-13, 2.2329e-13, 2.8188e-13, 3.6677e-13, 3.0368e-13,\n            2.2478e-13, 3.9330e-13, 4.1415e-13, 1.5405e-13, 1.5178e-13, 1.9972e-13,\n            2.7764e-13, 1.5123e-13, 2.6507e-13, 4.8645e-13, 4.0472e-11, 3.1399e-13,\n            4.3671e-13, 2.6501e-13, 1.9962e-13, 3.6835e-13, 5.2869e-13, 2.4705e-13,\n            3.6314e-13, 1.8473e-13, 2.9095e-13, 1.6348e-13, 3.0699e-13, 3.0284e-13,\n            3.4398e-13, 3.3921e-13, 1.3006e-12, 2.7645e-13, 1.9270e-13, 1.5683e-13,\n            2.1788e-13, 1.9136e-13, 3.0440e-13, 1.8909e-13, 2.2379e-13, 1.7507e-12,\n            5.3039e-13, 2.9704e-12, 3.6950e-13, 2.7901e-13, 3.8436e-13, 3.5035e-13,\n            3.0588e-13, 4.1392e-13, 6.3932e-13, 2.6590e-13, 4.8824e-13, 1.1422e-12,\n            3.6174e-13, 4.1500e-13, 2.0633e-13, 3.1868e-13, 1.6190e-13, 3.7434e-13,\n            3.2681e-13, 4.0808e-13, 3.4974e-13, 1.9224e-13, 3.4239e-13, 2.6993e-13,\n            3.2503e-13, 2.0393e-13, 1.5344e-13, 2.2488e-13, 2.7908e-13, 8.6637e-13,\n            2.4350e-13, 1.7853e-13, 1.7780e-13, 2.9858e-13, 1.5029e-13, 1.9710e-13,\n            3.4120e-13, 5.7464e-13, 2.7568e-13, 2.9945e-13, 2.3737e-13, 2.0911e-13,\n            3.5189e-13, 3.0402e-13, 8.3560e-13, 5.1739e-13, 2.9869e-13, 3.9269e-13,\n            1.1570e-13, 4.8141e-13, 2.8883e-13, 2.9683e-13, 4.7888e-13, 2.8571e-13,\n            2.5240e-13, 3.7080e-13, 6.5181e-13, 2.9391e-13, 5.1252e-13, 2.8028e-13,\n            2.5703e-13, 5.0920e-13, 3.3996e-13, 2.9975e-13, 2.6111e-13, 3.3372e-13,\n            3.2836e-13, 1.4383e-13, 2.9834e-13, 1.6694e-13, 2.4261e-13, 2.2310e-13,\n            3.8708e-13, 2.3430e-13, 2.1207e-13, 5.9355e-13, 4.3264e-13, 2.2062e-13,\n            2.6538e-13, 4.6667e-13, 1.9121e-13, 1.4000e-13, 1.9136e-13, 3.5955e-13,\n            2.4724e-13, 3.3197e-12, 2.4061e-13, 3.3243e-13, 1.0211e-13, 2.2798e-13,\n            2.3983e-13, 3.6567e-13, 3.1630e-13, 3.9453e-13, 2.9576e-13, 5.4238e-13,\n            2.3993e-13, 3.5944e-13, 6.5006e-13, 2.2148e-13, 1.7938e-13, 2.3631e-13,\n            1.9958e-13, 1.5793e-13, 2.9517e-13, 4.9891e-13, 2.1684e-13, 6.4986e-13,\n            2.6777e-13, 5.2019e-13, 1.6267e-13, 2.2917e-13, 3.4953e-13, 2.1725e-13,\n            5.5997e-13, 1.8185e-13, 2.8865e-13, 3.1589e-13, 2.7568e-13, 5.0583e-13,\n            3.2751e-13, 3.0866e-13, 3.4109e-13, 3.4794e-13, 1.9495e-13, 2.5129e-13,\n            2.1912e-13, 4.2817e-13, 6.1505e-13, 4.0279e-13])},\n   59: {'exp_avg': tensor([ 7.0790e-09, -6.4881e-08,  1.1248e-07, -6.7913e-08, -1.3100e-07,\n            -1.7532e-07, -2.9075e-09,  5.7904e-08,  5.0148e-08,  1.0893e-08,\n             1.1020e-07,  8.7521e-08, -1.1000e-07, -2.4418e-07,  2.2922e-08,\n            -4.7972e-08, -1.2169e-07,  1.9897e-08,  2.2132e-08,  1.1812e-08,\n             3.4597e-08, -5.3827e-08, -7.3533e-08, -7.2154e-08, -1.9061e-08,\n             3.4012e-08, -1.0000e-07, -3.3608e-08,  2.3877e-08, -1.4576e-07,\n            -9.8271e-08,  5.1637e-09,  3.1830e-08, -4.5028e-08,  8.2542e-08,\n            -3.1527e-08,  1.6026e-08,  1.0579e-07,  1.1296e-07, -9.8041e-08,\n            -1.4714e-07,  5.4607e-08, -2.6056e-08,  7.1943e-08,  1.2068e-07,\n            -6.1759e-08, -6.3008e-08,  1.4325e-07,  3.0822e-08, -1.8314e-07,\n             2.0655e-08, -9.1501e-08,  9.3603e-08,  1.6553e-07,  6.5327e-08,\n            -1.8021e-07,  5.2747e-08,  2.3123e-08, -8.8022e-09, -6.1085e-08,\n             3.0741e-08,  1.1309e-07, -4.1516e-08,  1.6166e-08,  2.9361e-08,\n            -6.5089e-08,  5.8736e-08,  3.7541e-08, -7.1894e-09,  1.3554e-08,\n             5.3138e-08, -3.8275e-08,  1.8171e-07,  1.3677e-07, -7.4041e-08,\n             4.5505e-08,  1.8402e-07, -6.6786e-08, -1.7646e-08, -1.2074e-07,\n             6.2156e-08,  1.5578e-07, -7.1920e-08, -1.3118e-07, -6.7210e-08,\n            -5.7594e-08,  1.1917e-07, -6.5002e-08, -2.6469e-07,  9.5520e-08,\n             8.8749e-08,  2.7821e-08,  1.2127e-07, -4.5278e-08,  1.5844e-07,\n             1.5182e-07,  8.6732e-08, -7.2390e-08, -9.0625e-09,  1.7118e-07,\n            -6.5688e-07,  1.3360e-07, -3.0968e-08, -4.8210e-08,  2.6869e-09,\n             9.4760e-08,  9.5453e-08, -5.8322e-08,  1.8953e-08,  3.4747e-08,\n             1.4303e-07, -5.7018e-09, -6.5977e-08, -3.7490e-08, -2.6505e-08,\n             6.3120e-10,  1.2492e-07, -6.6005e-08,  1.7430e-08,  4.9574e-08,\n            -1.4003e-07,  3.0548e-08,  3.6177e-08, -6.9403e-08,  4.2278e-08,\n             6.2852e-09,  1.1822e-07, -2.3860e-07, -2.1510e-07, -7.9098e-08,\n            -8.5996e-08,  1.1822e-07, -3.6438e-08, -5.1963e-08, -2.9430e-07,\n             5.4619e-08, -2.4658e-08, -1.4592e-07,  3.2577e-08,  2.0241e-07,\n            -2.9045e-08,  1.3628e-07, -2.0040e-08, -3.4911e-08, -3.8809e-08,\n            -8.5004e-08,  1.5389e-07,  7.9768e-08,  1.0775e-07,  3.4060e-08,\n            -2.4134e-07,  2.3336e-08, -3.8280e-08,  2.0265e-07, -2.0859e-07,\n            -1.8694e-08, -2.0338e-07,  9.0897e-08,  1.1469e-08, -5.4036e-08,\n            -8.7523e-08,  1.1987e-07, -2.5164e-08,  1.4678e-07,  3.6164e-08,\n             1.7565e-08,  1.0343e-08,  3.5401e-08,  1.2422e-07, -1.6221e-08,\n             3.8339e-08,  1.1396e-07, -4.7789e-08, -4.7827e-08, -3.6836e-08,\n             1.4353e-07,  5.4522e-08, -8.3641e-08, -3.7358e-08,  3.7456e-08,\n             1.9963e-07, -2.5368e-07, -4.2465e-08, -1.3676e-07,  3.7855e-08,\n             2.7879e-08,  5.1610e-08,  2.4952e-08, -7.9305e-08,  6.3550e-08,\n             6.2438e-09, -5.4286e-08,  6.1559e-08, -4.1523e-08,  3.5059e-08,\n             4.0522e-08, -2.8071e-08,  9.7649e-08,  1.9213e-08, -6.1453e-08,\n             2.3444e-07, -1.5042e-08, -1.2880e-07, -7.8893e-08, -1.3843e-07,\n             4.9160e-08,  2.4975e-08,  6.5013e-09,  4.9178e-08, -1.0029e-07,\n            -5.8953e-08, -2.2956e-07,  9.8382e-08, -4.6140e-08, -1.4205e-07,\n             1.1150e-07, -6.9856e-08,  1.9781e-07,  7.3460e-08,  1.7192e-07,\n            -2.0242e-08, -4.8470e-08, -2.7958e-08,  4.1663e-09,  7.8215e-08,\n            -1.3325e-07,  1.0841e-07, -6.2238e-09, -5.4596e-08, -2.2194e-08,\n            -1.2268e-07,  7.3851e-08, -6.3744e-08,  1.0316e-07, -4.4784e-08,\n             1.3583e-07, -8.6836e-08,  2.7185e-08, -2.3625e-07,  1.2848e-07,\n            -1.7248e-07,  1.1362e-07,  7.3524e-09,  2.3785e-08,  1.1139e-07,\n            -2.0828e-08, -5.7424e-08, -3.7780e-08,  2.5659e-08, -1.5658e-08,\n            -9.4580e-08, -2.8800e-08,  1.0638e-07, -1.2569e-07, -1.4112e-07,\n             9.1911e-08]),\n    'exp_avg_sq': tensor([2.1127e-13, 2.6014e-13, 1.6330e-13, 4.7222e-13, 1.7205e-13, 3.7440e-13,\n            1.9426e-13, 2.8508e-13, 1.2459e-13, 1.5392e-13, 5.1542e-13, 1.6479e-13,\n            2.6986e-13, 4.4569e-13, 1.7117e-13, 1.6337e-13, 2.5451e-13, 1.9477e-13,\n            1.3439e-13, 1.5276e-13, 3.6922e-13, 1.0172e-13, 2.0933e-13, 2.7404e-13,\n            2.4565e-13, 1.1358e-13, 4.3958e-13, 1.3636e-13, 4.4272e-13, 1.5705e-13,\n            1.5011e-13, 2.1562e-13, 2.2713e-13, 1.9908e-13, 1.9348e-13, 2.0108e-13,\n            1.0202e-13, 2.6654e-13, 2.2721e-13, 3.2882e-13, 1.5564e-13, 2.1841e-13,\n            3.1428e-13, 1.9164e-13, 1.3571e-13, 1.6696e-13, 2.1524e-13, 1.8220e-13,\n            3.0445e-13, 1.7955e-13, 6.3638e-13, 2.2529e-13, 2.4766e-13, 1.8290e-13,\n            1.1373e-13, 2.3470e-13, 1.7346e-13, 1.8972e-13, 3.0385e-13, 2.3009e-13,\n            1.9426e-13, 1.5125e-13, 2.1893e-13, 1.6685e-13, 1.3413e-13, 1.4175e-12,\n            1.3592e-13, 1.0085e-13, 1.3906e-13, 1.5440e-13, 1.2349e-13, 1.5702e-13,\n            2.6178e-13, 2.9599e-13, 1.4724e-13, 1.9756e-13, 1.9510e-13, 1.8614e-13,\n            9.7292e-14, 1.8730e-13, 1.3851e-13, 1.8191e-13, 1.7223e-13, 2.1965e-13,\n            2.6213e-13, 1.7534e-13, 1.5669e-13, 1.4026e-13, 2.0205e-13, 2.9340e-13,\n            1.3217e-13, 2.1186e-13, 1.9337e-13, 1.1163e-13, 9.5665e-14, 1.7314e-13,\n            2.6642e-13, 1.1213e-13, 1.7033e-13, 2.7405e-13, 1.5223e-11, 2.0041e-13,\n            1.9553e-13, 1.7990e-13, 1.4239e-13, 2.1507e-13, 3.5765e-13, 1.6152e-13,\n            2.1987e-13, 1.3218e-13, 1.8944e-13, 1.3243e-13, 2.1900e-13, 2.1195e-13,\n            1.8524e-13, 3.1401e-13, 4.5429e-13, 1.7243e-13, 1.5212e-13, 1.5281e-13,\n            1.3937e-13, 1.1300e-13, 1.5591e-13, 1.4492e-13, 1.6667e-13, 7.5738e-13,\n            4.3848e-13, 1.9938e-12, 2.4410e-13, 1.8980e-13, 2.4056e-13, 1.6683e-13,\n            1.6471e-13, 2.6435e-13, 3.9873e-13, 1.7346e-13, 3.1450e-13, 7.3179e-13,\n            2.8805e-13, 3.8432e-13, 1.6221e-13, 1.8220e-13, 1.5177e-13, 1.8468e-13,\n            1.9921e-13, 3.3984e-13, 2.2513e-13, 1.2036e-13, 2.2903e-13, 2.1290e-13,\n            2.5555e-13, 1.1903e-13, 1.4820e-13, 1.9948e-13, 1.8030e-13, 3.1694e-13,\n            1.4825e-13, 1.1894e-13, 1.1107e-13, 2.1423e-13, 1.2545e-13, 1.7597e-13,\n            2.5700e-13, 3.8129e-13, 2.1619e-13, 1.6410e-13, 1.5300e-13, 1.2737e-13,\n            2.1845e-13, 1.7404e-13, 3.6673e-13, 3.2235e-13, 1.5974e-13, 2.4921e-13,\n            9.2771e-14, 4.0538e-13, 1.7060e-13, 2.5036e-13, 2.0719e-13, 2.2152e-13,\n            2.4124e-13, 2.9489e-13, 3.8544e-13, 2.3305e-13, 4.8586e-13, 1.8222e-13,\n            1.9563e-13, 2.7820e-13, 1.7819e-13, 1.9797e-13, 1.6310e-13, 1.8450e-13,\n            2.4773e-13, 1.2367e-13, 1.7401e-13, 1.1062e-13, 1.2675e-13, 1.5271e-13,\n            1.9323e-13, 1.7363e-13, 1.0757e-13, 4.8399e-13, 2.5081e-13, 1.9691e-13,\n            1.2945e-13, 3.2089e-13, 1.4943e-13, 1.3339e-13, 1.6786e-13, 2.8409e-13,\n            1.7225e-13, 1.6595e-12, 1.9117e-13, 2.4284e-13, 1.0030e-13, 1.4824e-13,\n            1.8302e-13, 2.9464e-13, 1.5264e-13, 3.0585e-13, 2.1800e-13, 2.4173e-13,\n            1.7766e-13, 2.0090e-13, 2.7735e-13, 1.8803e-13, 1.3715e-13, 1.2078e-13,\n            2.0327e-13, 1.3555e-13, 1.7527e-13, 3.8865e-13, 1.7526e-13, 3.3070e-13,\n            1.5337e-13, 3.5234e-13, 1.1848e-13, 1.5458e-13, 2.1813e-13, 2.2148e-13,\n            4.5629e-13, 1.4493e-13, 2.4888e-13, 2.0651e-13, 1.3579e-13, 2.5796e-13,\n            2.8473e-13, 1.5261e-13, 2.1528e-13, 1.7646e-13, 1.3198e-13, 1.9415e-13,\n            1.4352e-13, 2.7829e-13, 3.6790e-13, 2.6062e-13])},\n   60: {'exp_avg': tensor([-1.6396e-07,  5.1618e-07, -3.9102e-08,  ...,  4.0907e-08,\n             2.7580e-07, -1.6793e-07]),\n    'exp_avg_sq': tensor([2.0321e-12, 1.4056e-12, 2.1591e-12,  ..., 2.2012e-12, 4.0641e-12,\n            2.7195e-12])},\n   61: {'exp_avg': tensor([-8.2734e-08, -1.0556e-07,  9.8208e-08,  ...,  2.1886e-08,\n            -3.2543e-08, -1.7660e-07]),\n    'exp_avg_sq': tensor([2.7568e-13, 2.8603e-13, 5.0565e-13,  ..., 1.5571e-13, 4.6069e-13,\n            2.2261e-13])},\n   62: {'exp_avg': tensor([ 7.4698e-10, -1.4439e-07, -1.5299e-08,  1.7596e-07,  7.3076e-08,\n            -8.4889e-08, -1.6847e-08, -2.3799e-08, -9.6716e-08, -2.3292e-07,\n            -5.9542e-08,  1.2719e-08,  1.8587e-08, -1.0929e-07, -6.1958e-08,\n            -1.3547e-07,  2.5462e-08, -3.2069e-10, -1.4010e-08,  4.7937e-08,\n             1.8890e-08, -7.7293e-08,  9.4498e-08, -9.4065e-08,  2.9957e-08,\n             8.3149e-08,  5.2410e-08,  1.2292e-07,  1.0497e-07,  9.3980e-08,\n             1.4871e-08,  2.3694e-07, -6.7329e-08,  5.0856e-09,  1.8201e-07,\n            -1.1963e-07,  8.1602e-08,  5.6282e-08, -2.5567e-08, -9.2685e-09,\n             8.7080e-08,  1.2055e-07,  7.3363e-08,  8.6453e-09,  1.9816e-07,\n            -3.1204e-08, -4.4429e-08,  3.7284e-08, -3.1493e-08,  6.6457e-09,\n            -1.4259e-07,  9.2078e-08,  9.5039e-08,  8.5521e-08, -5.7487e-08,\n             1.1843e-07,  1.3127e-07, -5.1339e-08,  1.1433e-08, -3.7516e-08,\n             5.7400e-09, -1.2334e-07,  6.0455e-08,  1.9141e-07, -1.1803e-07,\n            -4.1626e-08,  2.3549e-07,  3.9585e-08, -2.1889e-08, -1.6836e-07,\n            -6.0223e-08,  3.6598e-09, -2.5419e-08,  1.2707e-07, -6.6714e-08,\n            -1.2746e-07, -1.4036e-07, -2.2152e-07, -1.3968e-07, -6.8004e-08,\n             1.5067e-07,  4.1465e-08, -8.0475e-08, -2.8227e-08, -7.5968e-08,\n            -4.4958e-08,  2.9277e-08, -9.8337e-08, -5.7769e-08, -1.3895e-07,\n            -1.3875e-08,  9.3269e-08, -9.5988e-08,  6.2615e-09, -2.4743e-07,\n            -1.3240e-07, -1.4229e-07,  2.3237e-08, -3.7415e-08,  1.5890e-09,\n            -2.4017e-07, -2.1700e-09, -1.2143e-07,  3.7113e-07,  4.3120e-08,\n            -1.6486e-08,  1.5839e-07,  1.1208e-07, -1.6938e-07,  3.8031e-08,\n            -6.9710e-08,  3.2975e-08,  1.3726e-07,  2.2348e-08, -8.6105e-08,\n            -1.0100e-07,  1.9240e-08,  1.4663e-07, -2.8801e-09, -1.1223e-07,\n            -8.7228e-09, -9.4992e-08,  4.8367e-09, -2.3327e-07,  1.9144e-07,\n            -7.9394e-08,  4.1480e-08, -7.3404e-08,  4.3097e-08,  1.0194e-08,\n             1.7853e-07,  2.3928e-08, -3.6272e-08, -4.3039e-09,  3.5055e-08,\n            -3.1263e-08, -4.1978e-08, -7.2869e-08, -2.1772e-07, -4.9393e-08,\n            -5.6505e-08,  6.6943e-09,  1.9738e-07, -1.8050e-07, -8.0430e-08,\n            -1.6936e-07, -1.3105e-07,  4.5212e-08, -7.0451e-09, -1.3436e-08,\n             1.4534e-07, -1.2639e-07,  9.7287e-08, -2.5105e-08,  1.1260e-07,\n            -4.3661e-08,  7.9830e-08, -1.6334e-07, -1.7352e-07,  2.7565e-09,\n            -2.1813e-08,  8.3569e-08, -6.2379e-08, -5.4721e-08,  5.4873e-08,\n             2.6949e-07,  1.1659e-07,  1.0325e-07, -8.3348e-08,  2.1618e-07,\n             6.4657e-08, -3.6684e-08,  9.0774e-10, -1.1022e-07,  1.9986e-08,\n             1.8298e-07,  1.0348e-07,  3.6805e-08,  4.3821e-08, -1.9044e-08,\n             9.7074e-08,  6.2762e-08, -8.4738e-08,  1.7613e-07, -1.1861e-07,\n             5.0064e-08, -1.5628e-07, -7.5372e-08,  8.5227e-08,  5.9597e-08,\n            -6.9815e-08, -1.5606e-08, -4.7743e-08, -1.0569e-08, -7.6154e-08,\n             1.0586e-07,  5.9546e-08, -8.6093e-08,  1.8412e-07,  9.2394e-08,\n             4.3850e-08, -2.1238e-07,  5.4612e-08, -7.1867e-08, -3.4590e-07,\n            -2.7793e-07,  1.1944e-07, -9.4739e-08, -1.1173e-08,  3.8963e-08,\n             4.5141e-08,  1.4618e-07, -6.1543e-08,  3.8898e-08,  4.7822e-08,\n            -4.3696e-08,  1.6451e-07, -3.6546e-08,  1.7132e-07, -5.1037e-08,\n            -4.5022e-08,  1.4742e-07,  6.3746e-09,  3.6509e-09, -1.0643e-08,\n            -2.3698e-07,  5.6414e-08, -1.0884e-07,  2.6167e-07, -5.2614e-08,\n            -1.3123e-07,  3.1061e-07,  1.1527e-07, -1.0503e-08, -8.6408e-08,\n            -2.4456e-08, -9.8897e-08, -2.7205e-08,  1.1322e-07, -3.5430e-09,\n            -7.0049e-08,  5.1705e-08, -6.8057e-08, -5.0592e-08, -2.0621e-07,\n             1.9194e-08,  1.0254e-07,  1.1270e-08,  1.9252e-07,  1.2057e-07,\n            -1.5813e-07, -1.1267e-07,  1.4695e-07,  8.8302e-08, -2.5279e-08,\n             2.3115e-07]),\n    'exp_avg_sq': tensor([2.2650e-13, 1.2704e-13, 1.7267e-13, 2.9069e-13, 2.4523e-13, 1.9303e-13,\n            1.7351e-13, 1.2826e-13, 2.0297e-13, 2.0524e-13, 2.7079e-13, 2.4073e-13,\n            2.3222e-13, 2.3193e-13, 1.8885e-13, 1.9982e-13, 2.4931e-13, 2.0694e-13,\n            2.1016e-13, 3.6170e-13, 1.7223e-13, 5.4202e-13, 2.7263e-13, 2.3511e-13,\n            2.1245e-13, 2.0083e-13, 3.3843e-13, 1.9882e-13, 1.9555e-13, 3.1627e-13,\n            2.5410e-13, 2.8155e-13, 1.8888e-13, 2.9807e-13, 2.1767e-13, 2.3125e-13,\n            1.9694e-13, 2.0805e-13, 2.5566e-13, 1.6802e-13, 1.9121e-13, 2.1873e-13,\n            3.2202e-13, 1.9895e-13, 1.6255e-13, 1.7202e-13, 2.0678e-13, 2.7346e-13,\n            2.3718e-13, 2.6411e-13, 2.8002e-13, 2.3569e-13, 2.2660e-13, 1.8539e-13,\n            2.1523e-13, 4.4937e-13, 1.6099e-13, 3.1750e-13, 2.3861e-13, 2.0769e-13,\n            2.2623e-13, 2.6360e-13, 1.6338e-13, 2.6394e-13, 2.5357e-13, 3.8864e-13,\n            2.4343e-13, 1.3376e-13, 1.8975e-13, 1.4186e-13, 2.2272e-13, 2.9408e-13,\n            1.4687e-13, 2.0041e-13, 1.9224e-13, 1.7142e-13, 3.3257e-13, 2.0598e-13,\n            3.3596e-13, 2.4720e-13, 2.3311e-13, 1.8256e-13, 2.2119e-13, 2.3086e-13,\n            2.3701e-13, 3.1624e-13, 2.0695e-13, 2.3320e-13, 2.0759e-13, 2.4079e-13,\n            1.3624e-13, 2.9601e-13, 1.4114e-13, 3.5206e-13, 2.9417e-13, 2.0719e-13,\n            2.0325e-13, 1.7799e-13, 2.9949e-13, 3.5282e-13, 2.1545e-13, 2.4096e-13,\n            3.7008e-13, 2.0267e-13, 2.3185e-13, 2.7858e-13, 2.6547e-13, 2.7915e-13,\n            4.2134e-13, 2.2035e-13, 2.2018e-13, 1.7003e-13, 1.8104e-13, 2.7200e-13,\n            1.8860e-13, 2.5319e-13, 2.8750e-13, 1.8994e-13, 2.7579e-13, 2.6588e-13,\n            1.9324e-13, 2.8592e-13, 4.5723e-13, 3.4946e-13, 1.9141e-13, 1.8883e-13,\n            2.1358e-13, 2.0328e-13, 2.7228e-13, 2.0702e-13, 4.3707e-13, 2.1745e-13,\n            2.6074e-13, 2.2714e-13, 5.0244e-13, 2.5648e-13, 3.2263e-13, 2.9153e-13,\n            4.1634e-13, 2.1918e-13, 2.0886e-13, 3.0567e-13, 2.5219e-13, 5.6931e-13,\n            2.4169e-13, 1.7641e-13, 2.4210e-13, 2.0231e-13, 1.9963e-13, 2.7443e-13,\n            1.3769e-13, 1.4963e-13, 2.0629e-13, 1.7647e-13, 1.3413e-13, 2.5860e-13,\n            2.5063e-13, 2.6470e-13, 2.9976e-13, 2.4775e-13, 2.7758e-13, 2.6871e-13,\n            2.0088e-13, 1.3269e-13, 2.2293e-13, 3.4241e-13, 2.6604e-13, 2.6655e-13,\n            2.8594e-13, 2.2219e-13, 2.8385e-13, 1.9692e-13, 2.7687e-13, 2.5736e-13,\n            3.1045e-13, 2.7505e-13, 2.8424e-13, 1.5762e-13, 1.2955e-13, 2.2294e-13,\n            3.1974e-13, 4.3238e-13, 4.7684e-13, 4.2442e-13, 2.2918e-13, 2.6766e-13,\n            3.8022e-13, 3.0603e-13, 1.4651e-13, 1.7785e-13, 3.1867e-13, 1.6771e-13,\n            2.4854e-13, 2.1981e-13, 3.1564e-13, 2.6912e-13, 1.6527e-13, 2.3412e-13,\n            1.8223e-13, 2.7576e-13, 2.9667e-13, 2.6033e-13, 1.8529e-13, 1.7810e-13,\n            2.7361e-13, 2.3887e-13, 2.0533e-13, 2.3277e-13, 2.4651e-13, 2.2798e-13,\n            1.6742e-13, 1.8689e-13, 2.7478e-13, 2.4515e-13, 2.3710e-13, 1.8515e-13,\n            2.5441e-13, 2.2113e-13, 2.3047e-13, 1.9990e-13, 3.4450e-13, 2.6088e-13,\n            1.4458e-13, 2.3296e-13, 2.1570e-13, 2.8945e-13, 2.9004e-13, 2.2254e-13,\n            2.4269e-13, 2.3559e-13, 3.0923e-13, 2.5343e-13, 3.1264e-13, 2.2383e-13,\n            1.6374e-13, 2.9180e-13, 2.5837e-13, 2.5465e-13, 2.9280e-13, 3.3489e-13,\n            2.9506e-13, 2.3250e-13, 3.9575e-13, 2.2619e-13, 2.2616e-13, 1.8100e-13,\n            2.3256e-13, 2.0958e-13, 3.0192e-13, 2.6564e-13, 2.0213e-13, 1.4687e-13,\n            1.8949e-13, 2.1863e-13, 2.3162e-13, 2.0684e-13])},\n   63: {'exp_avg': tensor([-5.9039e-08, -8.9555e-08,  3.5722e-08,  1.3494e-07,  1.9813e-08,\n            -9.2287e-08, -9.9104e-08,  3.6512e-08, -1.0652e-08, -1.7920e-07,\n            -8.5196e-08,  2.0431e-08,  1.5349e-08,  7.5220e-09, -8.8977e-08,\n            -6.6491e-08,  2.8420e-08,  1.0705e-07, -3.5842e-08,  4.4328e-09,\n             2.6215e-08, -4.9220e-08,  3.0317e-08, -6.4413e-08, -1.1393e-08,\n             4.4885e-08,  2.8830e-08,  6.6307e-08,  3.5837e-08,  5.7640e-08,\n            -3.3330e-08,  1.4660e-07,  4.8870e-08, -3.7617e-08,  8.8115e-08,\n            -2.2339e-09,  1.2727e-07, -2.1950e-08, -1.8845e-08, -7.1716e-08,\n             8.4987e-09,  2.7468e-08,  3.3642e-08,  5.9631e-09, -1.5148e-08,\n            -5.4506e-08, -4.5633e-09, -2.1617e-08, -1.8051e-08, -4.8254e-09,\n            -1.8027e-07,  7.2276e-08,  1.0415e-07,  1.4628e-07, -6.3070e-08,\n             3.8664e-08,  1.8418e-07, -8.7804e-08, -2.6686e-08, -1.4976e-08,\n             4.1052e-08, -9.4478e-08,  6.3704e-08,  8.6349e-08, -5.2025e-08,\n            -9.5667e-08,  1.5977e-07,  6.4381e-08,  1.3329e-08, -1.6771e-07,\n            -1.3184e-07,  4.9613e-08, -3.6430e-08,  2.1429e-07, -5.1940e-08,\n            -4.8517e-08, -5.6124e-08, -1.2723e-07, -3.6106e-08, -4.7000e-08,\n             2.0252e-07, -6.6948e-08, -1.1374e-07, -8.7627e-08, -3.6862e-08,\n            -2.2278e-08, -4.9530e-08,  2.3023e-08, -6.9902e-08, -9.4321e-08,\n            -1.7843e-08, -9.4322e-08, -8.9566e-08, -6.0077e-08, -1.9337e-07,\n            -1.6434e-07, -1.2553e-07,  2.7680e-08,  4.6266e-09,  7.0393e-09,\n            -1.1314e-07, -1.4947e-08, -9.5005e-08,  2.8644e-07,  7.5798e-08,\n            -8.1385e-08,  7.7898e-08, -4.1932e-08, -1.5247e-07,  7.1863e-08,\n            -5.1779e-08,  1.7796e-09,  3.2895e-08,  3.2053e-08, -2.2626e-08,\n            -3.3237e-08, -4.8948e-08,  8.6007e-08, -2.4886e-08, -3.8171e-08,\n             1.7790e-08, -1.2170e-07,  1.7084e-08, -2.1179e-07,  1.9808e-07,\n            -1.4180e-07, -4.2877e-08, -5.2499e-08,  3.0151e-08, -5.1163e-08,\n             1.0931e-07, -2.0766e-08,  5.7038e-08, -4.0922e-08, -8.2394e-08,\n            -6.2201e-08, -1.3614e-07,  1.1667e-08, -2.1801e-07,  1.6648e-08,\n            -9.3156e-09,  1.5263e-08,  1.8485e-07, -1.5871e-07, -8.1706e-08,\n            -1.6887e-07, -3.3782e-08,  3.3390e-08,  7.3328e-09,  8.8846e-08,\n             7.8346e-08, -4.9930e-08,  3.8751e-08,  5.9244e-08,  9.2179e-08,\n             2.1616e-08,  1.0578e-07, -1.7323e-07, -1.5815e-07,  6.5734e-09,\n            -9.8095e-09,  1.4155e-07, -1.0338e-07, -4.0364e-08,  4.4940e-08,\n             1.5477e-07, -8.7049e-09,  4.4916e-08, -6.0930e-08,  8.9253e-08,\n            -3.7211e-08, -3.2209e-08,  4.4953e-09, -1.5730e-08,  5.9206e-08,\n             9.3151e-08,  4.5780e-08, -3.3781e-08, -3.0368e-08, -3.3762e-08,\n             6.1103e-08,  4.7819e-08, -7.3869e-08,  1.8691e-07, -1.6070e-07,\n             2.8332e-08, -3.7798e-08,  3.7376e-08,  6.8854e-08, -2.4727e-08,\n            -9.9763e-08, -7.8909e-08, -4.5086e-08, -5.0579e-08, -4.5031e-08,\n             2.9316e-08,  6.0249e-08,  1.2744e-07,  1.2698e-07, -1.7387e-09,\n             1.8641e-08, -1.0651e-07,  6.8707e-08, -1.0983e-07, -1.7561e-07,\n            -7.0308e-08,  1.9979e-09, -1.0147e-07, -1.5745e-08,  3.4946e-09,\n            -5.5569e-09,  1.6245e-07,  6.9081e-08, -1.8100e-08,  9.3053e-08,\n             2.6932e-08,  2.9489e-07, -4.0454e-08, -1.9379e-08,  2.2968e-08,\n            -4.3626e-08,  2.3709e-08, -3.8943e-08, -1.1432e-08,  1.3340e-08,\n            -1.4753e-07, -5.1223e-08, -1.2200e-07,  2.0119e-07, -4.6120e-08,\n            -4.7576e-08,  2.9738e-07, -2.6256e-08,  5.0311e-08, -3.5124e-09,\n             1.3546e-09,  4.8747e-09,  6.7705e-09, -3.6491e-08,  2.9395e-08,\n            -1.7490e-08,  1.5749e-07, -3.9158e-08, -2.4135e-08, -1.1725e-07,\n             6.7456e-09,  4.7009e-08,  1.2273e-07,  1.5559e-07,  6.7353e-08,\n            -1.3620e-07, -5.9002e-08,  1.0110e-08,  6.9921e-08, -4.1808e-08,\n             2.1967e-07]),\n    'exp_avg_sq': tensor([1.4971e-13, 9.5903e-14, 1.3183e-13, 1.9902e-13, 1.5960e-13, 1.4700e-13,\n            1.3256e-13, 1.1110e-13, 1.8087e-13, 1.6251e-13, 1.9509e-13, 1.6331e-13,\n            1.4774e-13, 1.5790e-13, 1.2209e-13, 1.3847e-13, 1.4799e-13, 1.6623e-13,\n            1.4342e-13, 2.0158e-13, 1.4056e-13, 3.5853e-13, 2.2271e-13, 1.2919e-13,\n            1.5518e-13, 1.2546e-13, 2.5941e-13, 1.4539e-13, 1.3769e-13, 1.8255e-13,\n            1.6571e-13, 3.1248e-13, 1.3353e-13, 1.5412e-13, 1.6712e-13, 1.6501e-13,\n            1.3409e-13, 1.4813e-13, 1.5733e-13, 1.2494e-13, 1.7327e-13, 1.5098e-13,\n            1.7775e-13, 1.8110e-13, 1.1502e-13, 1.3521e-13, 1.3372e-13, 1.6648e-13,\n            1.9840e-13, 1.5650e-13, 1.6256e-13, 1.5624e-13, 1.6996e-13, 1.4000e-13,\n            1.3124e-13, 2.6212e-13, 1.2525e-13, 1.7898e-13, 1.5293e-13, 1.9443e-13,\n            1.7358e-13, 1.9774e-13, 1.3148e-13, 1.7321e-13, 1.7641e-13, 2.3037e-13,\n            1.3505e-13, 1.2194e-13, 1.4213e-13, 1.1290e-13, 1.4273e-13, 1.9208e-13,\n            1.5189e-13, 1.5257e-13, 1.4687e-13, 1.2279e-13, 1.7659e-13, 1.5088e-13,\n            2.0115e-13, 1.6653e-13, 2.0845e-13, 1.6330e-13, 1.6649e-13, 1.7107e-13,\n            1.2915e-13, 1.7073e-13, 1.5385e-13, 1.3177e-13, 1.6472e-13, 1.9421e-13,\n            9.5362e-14, 1.6384e-13, 1.2397e-13, 1.8659e-13, 2.1401e-13, 1.4935e-13,\n            1.4229e-13, 1.5117e-13, 1.6654e-13, 2.4162e-13, 1.3714e-13, 1.3849e-13,\n            2.3594e-13, 1.8503e-13, 1.7659e-13, 1.9389e-13, 1.6136e-13, 1.8836e-13,\n            2.1043e-13, 1.3265e-13, 1.7202e-13, 1.2981e-13, 1.3705e-13, 2.0740e-13,\n            1.5388e-13, 1.8141e-13, 1.7268e-13, 1.4545e-13, 1.6504e-13, 1.6198e-13,\n            1.4766e-13, 1.7668e-13, 2.7357e-13, 1.8964e-13, 1.3607e-13, 1.3947e-13,\n            1.6187e-13, 1.5123e-13, 1.5919e-13, 1.5207e-13, 2.7142e-13, 1.4932e-13,\n            1.5686e-13, 1.6210e-13, 3.8406e-13, 1.9871e-13, 1.6627e-13, 1.6171e-13,\n            2.4009e-13, 1.6267e-13, 1.3542e-13, 2.1853e-13, 1.7522e-13, 2.8715e-13,\n            1.5299e-13, 1.4082e-13, 1.4558e-13, 1.3517e-13, 1.5148e-13, 1.6391e-13,\n            9.8459e-14, 1.3802e-13, 1.3217e-13, 1.2346e-13, 1.1629e-13, 1.7051e-13,\n            1.7113e-13, 1.6871e-13, 1.9163e-13, 1.4583e-13, 1.7532e-13, 1.7323e-13,\n            1.4588e-13, 1.2146e-13, 1.2789e-13, 2.3743e-13, 1.6063e-13, 1.6107e-13,\n            1.8711e-13, 1.6946e-13, 1.7810e-13, 1.2395e-13, 1.6714e-13, 1.4516e-13,\n            1.8378e-13, 2.3684e-13, 1.5790e-13, 1.2616e-13, 1.1331e-13, 1.3175e-13,\n            1.9944e-13, 3.2856e-13, 2.7320e-13, 2.3601e-13, 1.4826e-13, 1.7782e-13,\n            2.3647e-13, 1.4824e-13, 1.1781e-13, 1.5833e-13, 1.8831e-13, 1.2783e-13,\n            1.8840e-13, 1.5440e-13, 2.2324e-13, 2.2559e-13, 1.3771e-13, 1.8422e-13,\n            1.3806e-13, 1.5865e-13, 1.9148e-13, 1.3988e-13, 1.2586e-13, 1.2509e-13,\n            1.8450e-13, 1.4026e-13, 1.4066e-13, 1.7759e-13, 1.7577e-13, 1.6767e-13,\n            1.2552e-13, 1.6345e-13, 2.1600e-13, 1.6002e-13, 2.0119e-13, 1.2538e-13,\n            2.1776e-13, 1.7740e-13, 1.4400e-13, 1.4649e-13, 1.8433e-13, 1.4213e-13,\n            1.1603e-13, 1.4512e-13, 1.5853e-13, 1.8831e-13, 1.8122e-13, 1.5179e-13,\n            1.7578e-13, 1.4409e-13, 1.8878e-13, 1.6533e-13, 1.8443e-13, 1.4782e-13,\n            1.3726e-13, 1.6707e-13, 1.6345e-13, 1.7890e-13, 2.7110e-13, 2.5879e-13,\n            1.7471e-13, 1.5460e-13, 2.7444e-13, 1.4017e-13, 1.5914e-13, 1.2655e-13,\n            1.5860e-13, 1.3606e-13, 2.0701e-13, 1.7402e-13, 1.2262e-13, 1.3627e-13,\n            1.4258e-13, 1.5147e-13, 1.4015e-13, 1.2849e-13])},\n   64: {'exp_avg': tensor([ 2.2939e-07,  3.9609e-08,  6.6579e-08, -1.4907e-07,  2.5655e-07,\n             8.9441e-08, -1.2737e-07, -5.8346e-08,  1.6923e-07,  1.5632e-07,\n             1.0800e-07,  2.7650e-07, -1.8004e-07,  2.2727e-07, -8.8984e-08,\n            -5.7030e-08, -1.6336e-08, -2.7020e-07,  1.5498e-07, -1.1302e-09,\n            -2.3869e-08,  6.2997e-09, -5.9528e-08,  1.1813e-08, -1.3773e-07,\n            -4.5585e-08, -2.5624e-08, -1.2516e-07,  3.4418e-07, -3.0236e-08,\n            -4.9575e-08, -2.1173e-08,  2.5066e-07,  1.7659e-08, -3.7059e-08,\n            -1.4023e-07, -6.5342e-09,  1.2847e-07, -7.2007e-08,  1.4619e-08,\n            -4.8928e-08, -2.4379e-07,  1.1805e-09,  1.4753e-08, -1.6462e-07,\n            -1.3474e-08,  1.3191e-07, -1.0872e-07,  5.0848e-08, -2.8346e-08,\n             7.5876e-09,  3.9582e-07, -1.1418e-07,  1.3437e-07, -6.3327e-08,\n            -2.0075e-08,  9.6457e-08, -2.7540e-08,  1.6433e-07,  1.7876e-07,\n            -1.5851e-07, -8.5073e-08,  1.9102e-07, -1.3777e-07,  1.7929e-07,\n             4.0430e-07, -1.1692e-09,  1.9102e-07,  3.4680e-08, -1.0070e-07,\n             3.4214e-08,  1.6328e-07,  1.4800e-07,  1.0828e-07,  1.9050e-07,\n             9.4048e-08,  2.7140e-08, -4.4541e-08, -4.4740e-10,  7.6023e-08,\n             6.3577e-08, -2.3000e-07,  1.0918e-07,  8.8136e-08, -2.0035e-07,\n            -4.3264e-08,  9.6841e-08,  3.4776e-08, -1.5680e-07, -6.6181e-08,\n            -5.8373e-09,  1.8352e-07,  1.5526e-07, -1.9076e-07, -5.2360e-08,\n            -1.6855e-07,  3.9862e-08, -9.1672e-08, -2.1968e-08,  1.8472e-07,\n            -1.0557e-07, -1.0835e-07,  9.2952e-08,  8.0027e-08,  1.9294e-07,\n             1.2475e-07,  1.1228e-08, -7.0289e-08,  8.1020e-08, -8.6894e-09,\n            -4.3870e-08, -5.2264e-08, -5.2692e-08, -1.3092e-07,  1.9191e-07,\n             1.4016e-08, -2.3679e-07,  2.3012e-08, -1.1538e-07,  4.1440e-07,\n            -2.2405e-08,  4.6006e-08,  3.9855e-08,  1.0756e-08, -5.4525e-08,\n            -3.2139e-08, -2.6573e-08,  1.0203e-07, -1.7545e-07,  7.3880e-08,\n             1.4866e-07, -4.5829e-07, -2.1565e-07,  1.2558e-08, -2.8893e-08,\n            -1.9456e-08,  1.4252e-07, -1.3315e-08, -2.1257e-07,  2.0654e-08,\n            -3.3981e-07, -1.7389e-07,  1.7611e-08,  2.8076e-08,  5.4867e-08,\n            -2.2190e-08,  1.9527e-07, -3.7305e-08,  1.7519e-07, -7.0413e-08,\n            -1.1369e-08, -2.6027e-08, -1.6284e-07, -2.1556e-07, -1.2497e-07,\n             1.0872e-07, -7.7672e-08, -6.7624e-09, -1.3339e-07, -1.1328e-07,\n            -5.3866e-08, -2.4547e-09, -3.6608e-09, -1.2953e-07, -1.8549e-07,\n             5.7440e-08,  8.1586e-08, -4.4054e-08, -5.3062e-08, -1.8699e-07,\n            -8.3311e-08,  1.1834e-07, -7.5358e-08, -1.0554e-07, -2.6443e-07,\n            -1.1434e-07, -4.5808e-08,  1.0988e-07,  8.5088e-08,  5.6266e-08,\n            -9.0155e-09, -9.2237e-08,  9.8635e-08, -1.2287e-07, -4.5575e-08,\n            -7.0060e-08, -1.5406e-07,  2.2437e-09,  1.3886e-07,  7.7430e-08,\n            -4.1808e-08, -1.8343e-07,  6.0139e-08, -1.6993e-07, -1.0304e-08,\n             1.2328e-07, -2.3329e-07,  1.1851e-07,  1.8484e-07,  8.4530e-08,\n            -6.5755e-08,  1.8623e-08, -2.5736e-07, -1.3384e-07, -3.1962e-08,\n             5.4222e-09, -6.5803e-08,  1.7912e-07,  2.1312e-07,  1.6279e-08,\n            -5.0146e-08, -1.0186e-07, -3.8727e-08, -1.4828e-07, -8.8372e-08,\n            -1.6607e-07,  1.3541e-07, -9.7305e-08,  1.8047e-07, -2.5193e-07,\n             1.0982e-07,  2.0126e-07, -2.3173e-08, -2.5520e-08,  2.8809e-07,\n            -5.5763e-08,  1.5886e-07,  1.3110e-07,  1.3555e-07, -7.6818e-08,\n            -1.1232e-07,  2.5012e-08,  5.4786e-08,  9.3361e-08, -1.6120e-08,\n             1.5314e-07,  6.1155e-08, -8.7012e-08,  5.2479e-08,  5.0100e-08,\n            -1.2902e-07, -1.3741e-08,  9.4454e-08, -5.5357e-08, -1.1872e-07,\n             3.2568e-08,  1.6383e-07, -1.4327e-07, -8.1212e-08, -2.0103e-08,\n            -4.0796e-08, -9.2745e-08,  2.5533e-07,  2.3591e-09,  1.5728e-07,\n            -1.6184e-07]),\n    'exp_avg_sq': tensor([1.5202e-13, 2.4964e-13, 3.8175e-13, 3.2503e-13, 4.9134e-13, 1.3552e-13,\n            2.1561e-13, 1.5568e-13, 3.5911e-13, 2.7901e-13, 1.9031e-13, 1.9553e-13,\n            2.4894e-13, 2.1720e-13, 4.5408e-13, 3.6857e-13, 2.2475e-13, 3.1544e-13,\n            2.6236e-13, 3.6110e-13, 1.8433e-13, 1.9868e-13, 2.3643e-13, 1.3497e-13,\n            2.5612e-13, 5.4163e-13, 1.6938e-13, 3.6228e-13, 3.5606e-13, 2.2229e-13,\n            4.0059e-13, 2.0739e-13, 5.8900e-13, 2.9647e-13, 2.0908e-13, 2.1710e-13,\n            1.8525e-13, 1.8122e-13, 2.4770e-13, 1.8251e-13, 5.5674e-13, 1.9992e-13,\n            4.9791e-13, 2.1555e-13, 9.2637e-13, 3.1795e-13, 2.3214e-13, 2.9141e-13,\n            3.7965e-13, 2.7759e-13, 4.4685e-13, 3.0149e-13, 2.3796e-13, 1.8129e-13,\n            5.3087e-13, 3.1153e-13, 2.8346e-13, 2.9135e-13, 3.2806e-13, 4.5937e-13,\n            3.2073e-13, 3.7150e-13, 2.2120e-13, 3.2778e-13, 1.7592e-13, 4.4089e-13,\n            5.9500e-13, 2.2396e-13, 3.2835e-13, 2.3238e-13, 1.9575e-13, 2.2369e-13,\n            3.1493e-13, 2.1707e-13, 5.0523e-13, 2.2174e-13, 4.4690e-13, 3.1655e-13,\n            1.6436e-13, 4.3651e-13, 1.4384e-13, 2.9615e-13, 2.7120e-13, 2.0584e-12,\n            3.3566e-13, 2.6258e-13, 3.0372e-13, 3.7844e-13, 1.5887e-13, 2.7632e-13,\n            1.6477e-13, 3.5991e-13, 2.7050e-13, 5.0610e-13, 2.8221e-13, 3.1349e-13,\n            2.8806e-13, 3.4011e-13, 2.4312e-13, 2.9519e-13, 3.5208e-13, 1.7582e-13,\n            3.8737e-13, 2.7103e-13, 5.0332e-13, 2.4883e-13, 2.5136e-13, 4.2528e-13,\n            3.0071e-13, 5.3077e-13, 2.1330e-13, 1.7673e-13, 4.2626e-13, 2.1386e-13,\n            3.2880e-13, 2.6523e-13, 2.7320e-13, 2.3309e-13, 2.2746e-13, 1.7833e-12,\n            2.1498e-13, 1.6015e-13, 2.9768e-13, 2.5494e-13, 3.0410e-13, 2.7360e-13,\n            3.7035e-13, 3.0210e-13, 2.7712e-13, 1.9357e-13, 3.3848e-13, 1.2172e-11,\n            2.4311e-13, 2.7228e-13, 4.7293e-13, 2.5562e-13, 3.3995e-13, 1.6496e-13,\n            2.5523e-13, 3.3510e-13, 1.1627e-12, 3.0907e-13, 2.6436e-13, 2.3402e-13,\n            1.4524e-13, 2.6234e-13, 2.3025e-13, 4.4639e-13, 5.9499e-13, 1.6003e-13,\n            3.6299e-13, 2.5867e-13, 2.6397e-13, 2.5674e-13, 2.0764e-13, 2.5900e-13,\n            1.7507e-13, 1.6786e-13, 1.6433e-13, 1.8640e-13, 2.6011e-13, 2.9397e-13,\n            2.2116e-13, 2.7576e-13, 2.5485e-13, 3.7303e-13, 2.5934e-13, 5.1138e-13,\n            2.1716e-13, 4.8888e-13, 5.9544e-13, 2.1055e-13, 2.7268e-13, 2.5934e-13,\n            6.3365e-13, 1.0948e-13, 3.7857e-13, 2.7324e-13, 3.1233e-13, 1.8071e-13,\n            3.1832e-13, 2.4804e-13, 1.6878e-13, 2.2957e-13, 3.0502e-13, 4.0886e-13,\n            3.8481e-13, 2.5714e-13, 3.5667e-13, 1.5830e-13, 5.8742e-13, 5.7695e-13,\n            3.2469e-13, 3.4875e-13, 2.1361e-13, 3.5709e-13, 3.6948e-13, 7.6732e-13,\n            2.7965e-13, 3.3112e-13, 3.0724e-13, 2.7917e-13, 2.2831e-13, 3.5196e-13,\n            3.1994e-13, 2.8369e-13, 1.8374e-13, 3.0346e-13, 2.7545e-13, 1.6895e-13,\n            1.3593e-13, 2.1100e-13, 1.8056e-13, 3.6744e-13, 1.6546e-13, 2.4950e-13,\n            1.7082e-13, 3.7923e-13, 2.3618e-13, 2.4994e-13, 1.6430e-13, 5.5692e-13,\n            1.3285e-13, 1.4803e-13, 6.5275e-13, 4.4761e-13, 1.6686e-13, 3.7971e-13,\n            3.1814e-13, 3.2781e-13, 3.3121e-13, 3.1599e-13, 3.0037e-13, 1.7949e-13,\n            5.9584e-13, 3.5420e-13, 3.6383e-13, 2.4378e-13, 2.3046e-13, 2.6142e-13,\n            4.3982e-13, 2.2838e-13, 2.0886e-13, 2.7694e-13, 4.2486e-13, 2.5369e-13,\n            9.4247e-13, 3.6612e-13, 1.7902e-13, 2.2171e-13, 2.3453e-13, 1.6317e-13,\n            2.4853e-13, 3.6795e-13, 2.1617e-13, 2.3303e-13])},\n   65: {'exp_avg': tensor([ 2.4055e-07,  2.0481e-08, -2.6794e-08, -8.1599e-08,  2.5880e-07,\n             9.2933e-08, -1.3947e-07, -1.0923e-07, -5.1719e-08,  1.5522e-07,\n             4.0978e-08,  2.4880e-07, -1.0152e-07,  1.2704e-07, -1.2711e-07,\n            -9.2082e-08,  3.7115e-08, -2.5168e-07,  1.1263e-07,  3.0007e-08,\n            -2.7674e-09, -3.3921e-08, -7.1187e-09, -1.6385e-07, -7.8936e-08,\n            -8.4341e-08,  2.5304e-08, -3.2645e-08,  7.1360e-08, -1.4531e-07,\n            -3.8468e-08, -1.0792e-07,  1.0685e-08,  4.7481e-09,  8.5549e-08,\n            -8.4557e-08, -4.2812e-08,  2.8896e-08, -1.5228e-08,  5.5188e-08,\n            -6.9546e-08, -1.3315e-07, -8.2602e-10,  4.7135e-08, -1.0665e-07,\n            -2.5706e-08,  1.4179e-08, -4.3657e-08,  6.9861e-08,  1.1239e-08,\n             1.0472e-07,  2.7567e-07, -1.3545e-07, -4.5466e-08, -1.1614e-08,\n             6.5563e-08,  1.3020e-09, -4.4172e-08,  4.4203e-08,  1.3664e-07,\n            -2.9365e-08, -5.1902e-08,  7.9141e-08, -1.2886e-07,  8.1725e-08,\n             2.4738e-07, -3.6393e-08,  1.6768e-07,  1.0859e-08, -1.5567e-07,\n             8.4980e-08,  3.6716e-08,  1.3530e-08,  2.9213e-08,  1.9326e-07,\n             4.2594e-09,  7.8441e-08,  1.1905e-07,  4.3630e-08,  5.5518e-08,\n             1.8525e-08, -8.0960e-08,  5.4675e-08,  8.0923e-08, -1.6951e-08,\n            -3.0213e-08,  5.9182e-08,  7.5907e-08, -5.5825e-08, -4.9128e-08,\n             6.9902e-09,  1.3853e-07,  1.8125e-07, -2.3237e-07,  5.3910e-08,\n            -9.5575e-08,  2.6766e-08, -4.3315e-08, -8.0957e-08,  1.2675e-07,\n            -1.2706e-07, -8.6086e-08,  1.1775e-07, -3.0154e-09,  7.2258e-08,\n             2.3793e-08,  3.9590e-08, -4.4424e-08,  8.4810e-08,  3.4989e-09,\n            -1.1728e-07, -7.6018e-08, -1.2318e-07, -8.7842e-08,  1.6730e-07,\n             3.5728e-09, -3.9853e-08,  8.3900e-08, -4.8372e-08,  4.2160e-07,\n            -3.3682e-08,  5.4051e-09,  6.1104e-08,  3.1189e-08, -1.7295e-08,\n            -7.2118e-08, -3.4133e-09,  8.4023e-08, -1.3232e-07,  9.0046e-08,\n             7.0264e-08, -3.7611e-07, -8.9200e-08,  6.4096e-08,  3.5842e-08,\n            -7.3414e-08,  1.8094e-07, -2.8213e-08, -1.2352e-07, -4.7553e-08,\n            -5.6204e-08, -1.5495e-08, -3.7105e-08, -9.0334e-09,  1.3875e-07,\n             1.0322e-07,  1.4372e-07, -1.3996e-07,  3.7074e-08, -1.2389e-07,\n             6.8515e-08, -6.8821e-08, -1.8957e-07, -8.4301e-08, -1.4763e-07,\n             1.5878e-07, -8.2554e-08, -5.9854e-08, -7.3430e-08, -1.3203e-07,\n            -5.1032e-08,  3.7860e-08, -5.8472e-08, -1.3679e-07, -1.1057e-07,\n            -1.1540e-08,  1.7702e-09, -3.7212e-08, -1.1158e-07, -1.9495e-07,\n            -1.1486e-08, -7.8449e-08, -3.1443e-08, -1.4043e-07, -2.6842e-07,\n            -7.4396e-08,  9.8259e-08,  9.3398e-08,  1.9192e-08,  9.3988e-08,\n             2.9772e-08, -9.7874e-08,  2.6595e-08, -3.7557e-08,  3.8308e-09,\n            -7.7572e-08, -1.1401e-07,  1.2423e-08,  4.3681e-08, -1.0790e-07,\n             1.6840e-08, -1.7722e-07,  1.3800e-08, -5.9023e-08, -9.8547e-08,\n             7.4520e-08, -1.2928e-07,  7.0136e-08,  1.9439e-07,  2.8655e-08,\n            -7.6105e-08,  5.5959e-08, -1.7957e-07, -1.7292e-07, -7.7881e-08,\n             9.3044e-08, -8.3075e-08,  5.9833e-08,  6.9366e-08,  5.2353e-08,\n            -5.8959e-08, -9.2126e-08,  1.4802e-08, -7.0599e-08, -4.8623e-08,\n            -1.4545e-07,  4.9716e-09, -8.5235e-08,  9.2903e-08, -5.3664e-08,\n             6.4057e-08,  3.2270e-08, -2.4368e-08, -1.7101e-08,  1.7842e-07,\n            -1.0201e-07,  9.8272e-09,  3.6428e-08,  1.4315e-07, -6.6410e-08,\n            -6.4328e-08, -4.6360e-09,  6.4450e-08,  1.3724e-07,  4.5297e-08,\n             1.1304e-07, -3.3290e-08, -1.1075e-07,  6.3434e-09, -9.5509e-10,\n            -1.1024e-07, -8.3654e-08,  5.1554e-10, -2.0437e-09, -1.2453e-07,\n             2.0182e-08, -3.3655e-09, -1.3606e-07, -2.4790e-08, -5.7622e-08,\n             5.1848e-08, -9.6869e-08,  2.2823e-07,  5.1441e-08,  4.3113e-08,\n            -6.7829e-08]),\n    'exp_avg_sq': tensor([9.7611e-14, 1.3264e-13, 2.0157e-13, 1.9451e-13, 3.1164e-13, 1.0947e-13,\n            1.4554e-13, 1.6057e-13, 2.0200e-13, 2.1223e-13, 1.2754e-13, 1.5036e-13,\n            1.1311e-13, 1.6263e-13, 2.2334e-13, 2.2492e-13, 1.2379e-13, 1.8699e-13,\n            1.9837e-13, 2.1784e-13, 1.3864e-13, 1.2750e-13, 1.3630e-13, 1.0210e-13,\n            1.5415e-13, 2.6182e-13, 1.2881e-13, 2.1737e-13, 2.6116e-13, 1.4905e-13,\n            2.1118e-13, 1.3869e-13, 3.6217e-13, 1.6604e-13, 1.1995e-13, 1.3473e-13,\n            1.6162e-13, 1.4031e-13, 1.4581e-13, 1.3346e-13, 4.3331e-13, 1.2513e-13,\n            3.3496e-13, 1.4144e-13, 5.0900e-13, 1.8996e-13, 1.7129e-13, 1.4860e-13,\n            2.8272e-13, 1.9434e-13, 2.5594e-13, 2.3386e-13, 2.2583e-13, 1.6076e-13,\n            3.5525e-13, 2.9813e-13, 1.5329e-13, 1.7446e-13, 3.6895e-13, 2.6651e-13,\n            2.4386e-13, 2.1604e-13, 1.4959e-13, 1.5838e-13, 9.8159e-14, 2.0454e-13,\n            2.6190e-13, 1.6934e-13, 2.4454e-13, 2.1313e-13, 1.2613e-13, 1.1110e-13,\n            1.8755e-13, 1.3279e-13, 3.7649e-13, 1.6442e-13, 3.4645e-13, 1.6352e-13,\n            1.1504e-13, 1.8856e-13, 9.9450e-14, 1.9424e-13, 2.2263e-13, 9.7484e-13,\n            2.1587e-13, 1.4216e-13, 1.7497e-13, 2.6849e-13, 1.0587e-13, 1.9638e-13,\n            1.3939e-13, 1.7078e-13, 1.3460e-13, 2.8550e-13, 1.6723e-13, 2.2701e-13,\n            1.7365e-13, 1.7453e-13, 1.6623e-13, 1.5293e-13, 1.9385e-13, 1.2042e-13,\n            2.3261e-13, 2.5969e-13, 2.3680e-13, 1.5714e-13, 1.6876e-13, 2.0972e-13,\n            1.7955e-13, 2.5579e-13, 1.2563e-13, 1.2931e-13, 3.8963e-13, 1.4734e-13,\n            2.9150e-13, 1.5347e-13, 1.4074e-13, 1.4575e-13, 1.3039e-13, 1.0791e-12,\n            1.3452e-13, 1.1569e-13, 2.2663e-13, 1.3650e-13, 2.1651e-13, 1.2792e-13,\n            2.0465e-13, 1.5601e-13, 1.3690e-13, 1.6109e-13, 1.9145e-13, 7.5229e-12,\n            1.1931e-13, 1.4259e-13, 3.0456e-13, 1.2799e-13, 1.8037e-13, 1.3483e-13,\n            1.5133e-13, 2.1147e-13, 4.6515e-13, 1.8435e-13, 1.6204e-13, 2.3919e-13,\n            1.1312e-13, 1.6456e-13, 1.9676e-13, 3.4695e-13, 2.3077e-13, 1.1930e-13,\n            2.1239e-13, 1.6142e-13, 1.7384e-13, 1.9657e-13, 1.3910e-13, 1.7566e-13,\n            1.5071e-13, 1.4452e-13, 1.2892e-13, 1.3851e-13, 2.0989e-13, 1.7263e-13,\n            1.1257e-13, 1.7691e-13, 1.5314e-13, 1.8700e-13, 1.3433e-13, 4.2894e-13,\n            2.2739e-13, 2.2674e-13, 5.0363e-13, 1.3981e-13, 1.7064e-13, 1.7124e-13,\n            3.4406e-13, 8.3462e-14, 2.1121e-13, 1.6660e-13, 1.8595e-13, 1.7247e-13,\n            3.6631e-13, 1.7657e-13, 9.7370e-14, 1.2908e-13, 2.6340e-13, 2.4549e-13,\n            2.0923e-13, 3.0366e-13, 1.8560e-13, 1.0993e-13, 5.4105e-13, 4.4549e-13,\n            1.7971e-13, 1.8152e-13, 1.3166e-13, 2.8283e-13, 2.1978e-13, 4.3833e-13,\n            1.7108e-13, 2.5041e-13, 1.9690e-13, 1.3774e-13, 1.3192e-13, 1.7792e-13,\n            2.4682e-13, 3.5757e-13, 1.3391e-13, 1.7584e-13, 1.7567e-13, 1.0186e-13,\n            9.6508e-14, 1.9263e-13, 1.1458e-13, 3.0738e-13, 1.1164e-13, 1.3570e-13,\n            1.1490e-13, 2.5074e-13, 2.1090e-13, 1.3973e-13, 1.1282e-13, 3.8201e-13,\n            1.0200e-13, 9.1061e-14, 6.1231e-13, 2.3511e-13, 1.3071e-13, 2.3339e-13,\n            2.9056e-13, 2.1402e-13, 2.7786e-13, 2.0704e-13, 1.8278e-13, 1.2263e-13,\n            5.5781e-13, 1.9161e-13, 1.7147e-13, 1.2571e-13, 1.5120e-13, 1.3093e-13,\n            2.9951e-13, 1.2825e-13, 1.7624e-13, 1.3786e-13, 2.3861e-13, 1.3966e-13,\n            4.4487e-13, 1.8130e-13, 1.1017e-13, 1.5435e-13, 2.5917e-13, 1.4424e-13,\n            1.8997e-13, 1.8975e-13, 1.3492e-13, 1.5765e-13])},\n   66: {'exp_avg': tensor([ 2.9436e-07,  4.2055e-07, -3.0729e-08,  ...,  4.2805e-08,\n             4.2233e-08,  6.4986e-08]),\n    'exp_avg_sq': tensor([1.4554e-12, 1.3365e-12, 1.4473e-12,  ..., 1.7278e-12, 1.9352e-12,\n            2.7745e-12])},\n   67: {'exp_avg': tensor([-5.8858e-08, -1.3305e-07,  8.1480e-08,  ...,  5.5770e-09,\n            -1.0167e-07, -2.3096e-07]),\n    'exp_avg_sq': tensor([2.0767e-13, 2.3454e-13, 3.5097e-13,  ..., 1.3039e-13, 3.7352e-13,\n            1.4891e-13])},\n   68: {'exp_avg': tensor([ 8.7956e-08, -1.7590e-07,  5.2125e-08, -1.2098e-07,  1.6301e-08,\n            -1.0734e-07,  1.4340e-07,  1.5211e-07,  7.8081e-08, -3.0702e-07,\n             2.2847e-08, -1.1486e-07,  3.5515e-08,  2.2192e-07,  2.8023e-08,\n             7.9437e-08,  6.3337e-08, -1.8683e-07, -2.5543e-07, -8.1577e-08,\n            -1.3126e-07, -2.9151e-08,  2.0769e-08, -2.7329e-07,  6.3271e-08,\n            -1.5520e-07,  3.0084e-07,  1.2432e-07, -5.2844e-08,  1.5833e-07,\n             1.4924e-07,  8.5128e-08,  1.0094e-07,  6.6849e-09,  5.2769e-08,\n             8.3662e-08, -1.5256e-07, -9.8011e-08, -1.1080e-07, -1.0171e-07,\n            -8.7342e-08, -1.6135e-08, -2.6799e-07, -4.6714e-08,  7.1889e-08,\n             9.1484e-08,  5.7780e-08, -1.1904e-07, -2.0647e-07, -1.4259e-07,\n            -1.2359e-07,  1.0867e-07,  9.5120e-08, -6.7445e-08, -1.2110e-07,\n            -1.7303e-07, -2.1343e-07,  1.4317e-07, -1.0130e-07, -8.8436e-08,\n             2.4084e-08,  1.0616e-08, -1.5348e-07, -3.3248e-09, -2.4644e-08,\n            -1.4277e-07, -1.3000e-07,  1.0625e-08, -9.7029e-08,  3.5997e-08,\n            -8.3772e-08, -5.1944e-08, -3.2214e-08,  1.9958e-07, -2.9081e-08,\n            -9.3328e-08, -1.3509e-07,  7.5433e-08, -5.3396e-08, -9.4171e-08,\n             1.2128e-07,  1.1181e-07, -2.1033e-08, -4.1718e-08, -2.0514e-08,\n             2.0350e-07,  1.9638e-07,  9.7798e-08,  1.2381e-08,  2.8459e-08,\n             1.9243e-07, -1.9648e-08,  1.7119e-07, -3.2060e-07,  1.5585e-08,\n             3.8625e-08, -8.0470e-08, -3.6112e-08,  2.2114e-07, -2.8772e-08,\n             3.9641e-08,  1.5352e-07,  6.8852e-09,  4.8554e-09,  3.4719e-08,\n             1.9144e-07,  1.8812e-07, -1.6238e-07,  1.1272e-08,  1.3110e-07,\n            -1.0174e-07,  5.2818e-08,  3.3761e-08, -8.1621e-08,  2.3889e-07,\n             2.3858e-08,  2.6986e-07, -3.9222e-08,  1.7736e-07, -4.0086e-08,\n             1.1579e-07, -1.4737e-07,  5.5899e-08,  7.7870e-08,  9.7051e-08,\n            -3.5182e-08, -1.3882e-08,  2.9255e-08, -1.6079e-07, -1.7788e-07,\n            -1.5882e-07,  2.7739e-07,  2.5601e-07, -2.7023e-07,  1.7022e-07,\n            -1.0023e-07, -1.6294e-07,  1.9711e-08,  3.0880e-08,  1.1536e-07,\n            -4.6437e-09, -5.4228e-08,  6.1367e-08, -2.4035e-07,  1.8943e-07,\n             1.0259e-07,  6.2291e-08, -5.4956e-08, -1.7842e-07, -1.8245e-08,\n             9.6318e-08, -8.4799e-08, -4.3698e-09,  2.0259e-07, -7.0988e-08,\n             5.2505e-08, -2.1472e-07,  8.7770e-09, -1.5932e-08,  6.4905e-08,\n            -4.2605e-08, -1.3525e-07,  1.3048e-07,  9.8655e-08, -2.0823e-07,\n             2.6898e-08, -1.6383e-07, -1.4083e-08, -9.1591e-08, -1.2027e-07,\n             5.1897e-08,  1.4682e-07,  5.9546e-08, -6.7491e-08, -2.9943e-08,\n             4.2389e-08,  4.2434e-08, -1.4092e-07,  1.0758e-07,  1.1670e-07,\n            -1.4059e-07, -4.4358e-08,  7.6086e-08,  4.2167e-08,  4.3967e-08,\n            -8.2806e-08, -5.0255e-08, -1.1116e-07,  2.0884e-07,  1.1024e-08,\n            -3.8492e-08,  3.2346e-08,  3.7231e-07,  1.6474e-07,  1.4031e-07,\n            -1.6289e-08, -1.8275e-07,  1.0600e-07,  1.4251e-07,  7.9468e-08,\n            -1.2142e-08,  1.4668e-07, -3.7437e-07,  2.2768e-07, -4.5621e-08,\n             3.6592e-08,  6.7341e-08, -3.1351e-07, -5.8698e-08, -7.0283e-08,\n             1.4591e-07, -7.7931e-08,  1.5295e-07,  2.3809e-07, -1.0949e-07,\n            -9.1236e-08,  1.2667e-08, -5.6775e-08, -1.1153e-07, -6.4432e-08,\n             2.2534e-08,  2.0518e-07,  1.5099e-07,  1.3799e-08, -1.7238e-07,\n             7.0210e-08,  1.7754e-08, -5.2570e-08,  6.2592e-08, -1.0876e-07,\n            -1.6529e-07,  5.7236e-08,  2.0118e-07,  7.1163e-08, -1.6616e-07,\n            -8.1724e-08, -1.4932e-07,  3.1976e-07, -1.6046e-08, -2.7318e-08,\n             2.2243e-07,  6.9666e-08, -2.1761e-07,  1.1847e-07, -8.3622e-08,\n            -3.7563e-08, -2.7900e-08, -3.5592e-08, -2.2250e-08, -1.2791e-07,\n             1.1336e-07,  3.0795e-08, -2.0901e-08,  5.6197e-08, -7.5491e-08,\n             5.6720e-08]),\n    'exp_avg_sq': tensor([2.3807e-13, 2.6862e-13, 2.2092e-13, 2.8095e-13, 3.6978e-13, 2.3016e-13,\n            2.3246e-13, 2.5009e-13, 3.5533e-13, 2.5215e-13, 1.5048e-13, 3.5859e-13,\n            2.4533e-13, 3.0033e-13, 1.9945e-13, 3.4897e-13, 2.8669e-13, 5.1894e-13,\n            3.2633e-13, 3.6003e-13, 2.2586e-13, 4.5549e-13, 2.3291e-13, 2.9758e-13,\n            1.9634e-13, 3.0928e-13, 4.2535e-13, 2.1888e-13, 1.7305e-13, 4.4794e-13,\n            2.7836e-13, 2.8777e-13, 4.1461e-13, 2.5921e-13, 3.8581e-13, 2.3694e-13,\n            1.7053e-13, 2.7508e-13, 3.1350e-13, 1.9676e-13, 1.9391e-13, 3.3623e-13,\n            3.1167e-13, 3.2234e-13, 2.2414e-13, 3.2500e-13, 2.1478e-13, 4.2102e-13,\n            2.6355e-13, 2.1146e-13, 2.8980e-13, 2.0241e-13, 1.6104e-13, 3.0878e-13,\n            3.7221e-13, 2.8348e-13, 1.7802e-13, 4.1142e-13, 2.3824e-13, 2.0167e-13,\n            2.1653e-13, 1.8736e-13, 2.3025e-13, 3.4604e-13, 2.1654e-13, 2.7067e-13,\n            2.1296e-13, 1.8584e-13, 2.2003e-13, 5.1820e-13, 2.9765e-13, 2.5881e-13,\n            1.2327e-13, 3.5320e-13, 2.8609e-13, 2.0508e-12, 3.6669e-13, 2.6786e-13,\n            1.6577e-13, 2.9364e-13, 4.7491e-13, 2.7093e-13, 1.5152e-13, 2.5725e-13,\n            2.9628e-13, 4.0276e-13, 6.0542e-13, 2.8642e-13, 1.9050e-13, 2.3033e-13,\n            2.9203e-13, 2.6526e-13, 2.7206e-13, 3.1419e-13, 2.8753e-13, 2.4187e-13,\n            2.9417e-13, 3.2624e-13, 3.4115e-13, 3.0625e-13, 4.6667e-13, 2.9937e-13,\n            3.7612e-13, 2.3534e-13, 1.6353e-13, 2.4928e-13, 1.8139e-13, 3.2659e-13,\n            3.4381e-13, 3.8775e-13, 2.8535e-13, 1.3420e-13, 3.4763e-13, 4.0468e-13,\n            3.4506e-13, 1.7361e-13, 3.2465e-13, 2.9045e-13, 3.1196e-13, 3.2893e-13,\n            2.6589e-13, 1.8971e-13, 2.8622e-13, 2.6307e-13, 2.3871e-13, 3.6691e-13,\n            1.6193e-13, 2.9872e-13, 3.1646e-13, 1.7693e-13, 2.7004e-13, 3.2402e-13,\n            2.4982e-13, 2.0196e-13, 2.4297e-13, 2.5733e-13, 4.6370e-13, 2.8236e-13,\n            1.6658e-13, 2.7790e-13, 2.1491e-13, 2.8053e-13, 3.6931e-13, 3.1004e-13,\n            4.1975e-13, 2.7134e-13, 3.7842e-13, 2.9389e-13, 2.9764e-13, 2.9403e-13,\n            2.0858e-13, 2.5928e-13, 2.6731e-13, 3.3096e-13, 2.3657e-13, 6.3899e-13,\n            3.4364e-13, 2.8711e-13, 1.6978e-13, 3.8763e-13, 4.2605e-13, 2.5425e-13,\n            3.2208e-13, 4.5224e-13, 2.7343e-13, 1.6319e-13, 3.2851e-13, 3.2569e-13,\n            2.7685e-13, 1.9184e-13, 2.4872e-13, 4.4573e-13, 2.2751e-13, 2.8906e-13,\n            2.0191e-13, 2.2263e-13, 2.5339e-13, 3.4976e-13, 1.9247e-13, 3.0067e-13,\n            3.0718e-13, 2.8775e-13, 3.1081e-13, 5.8601e-13, 2.4159e-13, 2.1534e-13,\n            2.5539e-13, 3.7722e-13, 3.1669e-13, 2.1854e-13, 1.6639e-13, 3.1538e-13,\n            3.3944e-13, 1.9738e-13, 2.7781e-13, 1.9537e-13, 4.8742e-13, 2.0986e-13,\n            2.7956e-13, 4.4281e-13, 4.7582e-13, 3.0160e-13, 2.4034e-13, 4.7990e-13,\n            2.8440e-13, 3.1128e-13, 2.1292e-13, 6.3563e-13, 2.3166e-13, 3.2937e-13,\n            2.6578e-13, 1.7776e-13, 3.8697e-13, 4.6386e-13, 4.1684e-13, 3.5796e-13,\n            1.6954e-13, 3.9701e-13, 2.7614e-13, 3.2394e-13, 2.6513e-13, 3.0571e-13,\n            2.1010e-13, 2.5006e-13, 2.8866e-13, 2.7201e-13, 2.5895e-13, 3.8228e-13,\n            1.6843e-13, 2.7258e-13, 3.3899e-13, 3.2187e-13, 2.9009e-13, 2.7717e-13,\n            3.1652e-13, 3.1627e-13, 4.0624e-13, 4.6272e-13, 2.4520e-13, 3.5833e-13,\n            2.4314e-13, 2.6015e-13, 2.9866e-13, 2.4633e-13, 3.7805e-13, 2.5499e-13,\n            3.4725e-13, 2.4528e-13, 2.9191e-13, 2.6336e-13, 5.3481e-13, 2.2102e-13,\n            2.5741e-13, 2.2274e-13, 2.8243e-13, 2.7628e-13])},\n   69: {'exp_avg': tensor([ 7.4630e-08, -2.1545e-07,  6.6014e-08, -1.4849e-07,  1.0303e-07,\n            -3.8329e-08,  6.2507e-08,  1.1029e-07,  4.0900e-08, -1.0543e-07,\n             3.4127e-08,  8.1588e-09,  5.9942e-08,  2.1135e-07, -1.8521e-09,\n            -1.8312e-08,  9.4941e-08, -5.5148e-09, -1.4401e-07, -1.7363e-08,\n            -8.4410e-08, -1.8838e-09,  1.0939e-07, -1.6725e-07,  1.7838e-08,\n            -1.6757e-07,  1.6388e-07,  1.1465e-07, -3.8831e-08,  6.9426e-08,\n             1.5965e-07,  7.4064e-09,  6.6684e-08, -4.9097e-08, -3.0638e-08,\n             1.1921e-07, -1.4211e-07, -4.7186e-08, -7.3904e-08, -1.3619e-07,\n            -8.4257e-08, -2.7018e-08, -2.4461e-07,  1.4675e-07,  3.4875e-08,\n            -8.6747e-08,  6.1325e-08,  5.1398e-08, -1.8419e-07, -1.7096e-07,\n            -1.3200e-08,  1.2918e-07,  5.3671e-08, -4.3617e-08, -2.1532e-08,\n            -1.6397e-07, -1.3809e-07,  6.2870e-08, -1.0885e-07, -1.4265e-07,\n            -6.5199e-09, -2.7820e-09, -1.7304e-07, -3.6044e-08,  8.5125e-08,\n            -7.1032e-08, -1.2475e-07,  8.8206e-09, -2.2446e-08, -2.3106e-08,\n             3.2253e-08, -7.0572e-08, -6.2166e-08,  5.4608e-08,  9.4515e-09,\n            -1.2549e-07, -1.0079e-07,  7.7753e-08,  3.4431e-08, -2.0654e-07,\n             4.8968e-09, -4.1617e-08,  4.0565e-09, -4.7571e-08,  2.6905e-09,\n             1.9648e-07,  9.7767e-08,  6.8557e-08,  3.2265e-08,  1.2522e-07,\n             9.6233e-08, -2.9555e-08,  1.4751e-07, -1.5389e-07, -9.7025e-08,\n             1.1696e-07, -4.7004e-08,  8.4221e-08,  1.1552e-07,  2.1026e-09,\n             3.1388e-08,  2.0039e-07,  1.5798e-08, -3.7443e-08,  5.8999e-08,\n             7.6610e-08,  1.9994e-07, -1.8046e-08,  2.9136e-08,  1.6009e-07,\n            -6.7777e-08,  5.6977e-08,  1.9387e-08, -1.1084e-07,  1.9399e-07,\n            -8.9638e-08,  1.5976e-07, -5.6566e-08,  1.1581e-07, -2.4226e-08,\n             5.1009e-08, -2.1086e-07, -1.7301e-09, -3.1762e-08,  8.9990e-08,\n             1.7497e-08,  3.7668e-08, -5.3458e-08, -1.2305e-07, -6.9148e-08,\n            -1.3692e-07,  1.8404e-07,  2.1056e-07, -2.8390e-07,  1.5539e-07,\n            -1.6997e-07, -1.3219e-07, -2.1290e-08,  7.2203e-09,  1.2557e-07,\n            -4.4256e-08, -5.2177e-08,  8.5762e-08, -1.2950e-08,  6.9298e-08,\n             1.0968e-07,  9.8496e-09, -3.6537e-08, -1.7057e-07,  1.5166e-09,\n             5.4068e-08, -2.7869e-09, -5.3151e-08,  7.4990e-08, -4.1571e-08,\n            -5.1932e-09, -1.8709e-07,  1.4410e-07, -9.5682e-08,  9.5311e-08,\n             9.4805e-08, -8.0152e-08,  1.5957e-08,  5.8820e-08, -9.7322e-08,\n             7.7048e-08, -7.6750e-08, -2.3170e-08, -3.9264e-08, -1.6204e-08,\n             2.8784e-08,  1.0675e-07,  4.8002e-08, -3.5695e-08,  1.8643e-08,\n             5.3280e-08,  3.6434e-08, -1.0053e-07, -5.6401e-08,  1.4302e-07,\n            -2.5520e-08, -3.7703e-08,  9.6655e-08, -1.0036e-08, -1.0207e-08,\n            -1.0036e-08,  5.8127e-08, -1.8299e-09,  1.4636e-07,  3.4426e-08,\n            -5.0831e-08,  2.6864e-08,  1.2010e-07,  5.8167e-08,  2.0052e-08,\n            -1.3310e-08, -1.4078e-07,  7.2996e-08,  3.4099e-08,  6.5931e-08,\n            -1.8842e-08,  5.8462e-08, -3.4979e-07,  1.4631e-07, -6.3471e-08,\n             6.3497e-08,  7.1819e-08, -2.4716e-07, -2.3083e-08, -1.7506e-07,\n             7.2594e-08, -4.1046e-08,  1.7978e-07,  6.3604e-08, -4.8637e-08,\n            -1.0348e-07, -2.7113e-08, -7.9088e-08, -1.0702e-07,  1.8046e-08,\n            -7.3244e-08,  1.6796e-07,  1.1424e-07, -6.4112e-08, -1.7527e-07,\n            -8.9019e-09,  5.9253e-08, -1.0271e-07,  4.9814e-08,  2.9021e-09,\n            -8.7083e-08,  1.4799e-08, -2.9215e-08, -8.9569e-09, -5.0772e-08,\n             2.9510e-08, -9.6149e-08,  2.2904e-07, -7.8692e-08, -1.2190e-08,\n             1.3523e-07, -5.6143e-09, -1.1205e-07,  1.3486e-07, -2.4257e-08,\n            -5.4044e-08, -2.7250e-08, -4.2496e-08, -2.3438e-08, -2.1473e-07,\n            -2.2813e-08,  3.3816e-08, -1.9922e-08,  1.5272e-09, -1.2105e-07,\n             3.0019e-08]),\n    'exp_avg_sq': tensor([2.0551e-13, 1.7857e-13, 1.2444e-13, 1.8582e-13, 1.9844e-13, 1.4805e-13,\n            1.4455e-13, 1.8533e-13, 2.0955e-13, 1.6877e-13, 1.4220e-13, 2.1513e-13,\n            1.5632e-13, 2.0860e-13, 1.3245e-13, 1.8177e-13, 1.6524e-13, 2.3523e-13,\n            1.8369e-13, 1.9559e-13, 1.5531e-13, 2.1326e-13, 1.5626e-13, 1.8937e-13,\n            1.4357e-13, 1.8170e-13, 2.1498e-13, 1.3598e-13, 1.1466e-13, 2.0843e-13,\n            1.8185e-13, 1.5811e-13, 2.0810e-13, 1.6067e-13, 1.9479e-13, 1.6187e-13,\n            1.5969e-13, 1.5454e-13, 1.7531e-13, 1.6299e-13, 1.6465e-13, 1.7892e-13,\n            1.7204e-13, 1.9013e-13, 1.3095e-13, 1.6628e-13, 1.3470e-13, 2.1493e-13,\n            1.5703e-13, 1.4407e-13, 2.0511e-13, 1.5225e-13, 1.3339e-13, 1.9345e-13,\n            2.2670e-13, 2.1332e-13, 1.3137e-13, 2.3047e-13, 2.0015e-13, 1.6782e-13,\n            1.7641e-13, 1.4834e-13, 1.5554e-13, 1.7298e-13, 1.5340e-13, 1.7482e-13,\n            1.5800e-13, 1.2161e-13, 1.7020e-13, 2.4209e-13, 1.6872e-13, 1.7155e-13,\n            1.2971e-13, 1.8112e-13, 1.7208e-13, 9.2504e-13, 1.9438e-13, 1.4948e-13,\n            1.2088e-13, 1.4549e-13, 2.0504e-13, 1.7169e-13, 1.1188e-13, 1.6719e-13,\n            1.6447e-13, 2.3872e-13, 2.5895e-13, 1.6002e-13, 1.4027e-13, 1.4974e-13,\n            1.8222e-13, 2.2687e-13, 1.6231e-13, 1.6719e-13, 1.7985e-13, 2.0842e-13,\n            1.9023e-13, 1.7671e-13, 2.2011e-13, 1.8228e-13, 2.3012e-13, 1.6387e-13,\n            2.3286e-13, 1.4984e-13, 1.2805e-13, 1.6011e-13, 1.3378e-13, 1.8105e-13,\n            2.5246e-13, 1.8264e-13, 2.0973e-13, 1.1545e-13, 2.0823e-13, 2.0705e-13,\n            2.0230e-13, 1.0982e-13, 1.8386e-13, 1.6448e-13, 1.8004e-13, 1.9007e-13,\n            1.6604e-13, 1.6229e-13, 1.5637e-13, 1.9564e-13, 2.1215e-13, 1.9507e-13,\n            1.1114e-13, 1.6376e-13, 1.6811e-13, 1.0676e-13, 1.5281e-13, 1.8918e-13,\n            1.8216e-13, 1.6104e-13, 1.5651e-13, 1.6374e-13, 2.1303e-13, 1.6369e-13,\n            1.4704e-13, 1.7645e-13, 1.4108e-13, 1.7908e-13, 1.9432e-13, 1.9931e-13,\n            1.9825e-13, 1.6364e-13, 1.8936e-13, 2.1246e-13, 1.6867e-13, 1.8765e-13,\n            1.5225e-13, 1.3219e-13, 1.8248e-13, 1.8353e-13, 2.0306e-13, 2.7731e-13,\n            2.0853e-13, 1.7281e-13, 1.3790e-13, 1.8130e-13, 4.7392e-13, 1.9338e-13,\n            1.6824e-13, 1.9710e-13, 2.1070e-13, 1.2529e-13, 1.9880e-13, 1.7551e-13,\n            1.9110e-13, 1.4366e-13, 1.8459e-13, 2.5008e-13, 1.8540e-13, 1.5911e-13,\n            1.7012e-13, 1.8902e-13, 1.8006e-13, 1.9954e-13, 1.5030e-13, 2.4522e-13,\n            2.0238e-13, 1.6066e-13, 2.2677e-13, 2.5454e-13, 1.8370e-13, 1.4666e-13,\n            1.4436e-13, 2.0736e-13, 1.9341e-13, 1.7832e-13, 1.2671e-13, 1.8410e-13,\n            1.6022e-13, 1.7607e-13, 1.8210e-13, 1.4922e-13, 2.3719e-13, 1.4554e-13,\n            1.8593e-13, 2.1130e-13, 1.8827e-13, 1.9370e-13, 1.7088e-13, 2.1940e-13,\n            1.7843e-13, 1.5061e-13, 1.2560e-13, 2.4967e-13, 1.5989e-13, 2.5938e-13,\n            1.7196e-13, 1.3464e-13, 2.1470e-13, 2.1412e-13, 1.8721e-13, 1.9435e-13,\n            1.3390e-13, 2.3080e-13, 1.5218e-13, 1.8726e-13, 1.7196e-13, 2.0128e-13,\n            1.6366e-13, 2.1341e-13, 1.9297e-13, 1.8230e-13, 1.7745e-13, 2.0517e-13,\n            1.2600e-13, 1.7524e-13, 2.2856e-13, 1.7823e-13, 2.1566e-13, 1.5816e-13,\n            2.1206e-13, 2.0517e-13, 2.1435e-13, 2.5437e-13, 1.7656e-13, 2.2898e-13,\n            1.6207e-13, 1.6881e-13, 1.5239e-13, 1.9784e-13, 1.9705e-13, 1.6496e-13,\n            1.9553e-13, 1.7735e-13, 1.9664e-13, 1.9375e-13, 2.1599e-13, 1.5841e-13,\n            1.9377e-13, 1.4632e-13, 2.0160e-13, 1.6918e-13])},\n   70: {'exp_avg': tensor([-2.8212e-08,  3.3206e-08,  1.6920e-07, -1.6575e-07, -2.8214e-08,\n             1.2743e-07, -4.4899e-08,  2.3660e-07,  1.6135e-07, -7.1199e-08,\n             2.4664e-07, -5.9052e-09,  1.0470e-08,  1.0305e-07,  2.2395e-08,\n             1.4729e-07,  1.5593e-07, -3.3619e-07,  2.5027e-07,  9.6021e-08,\n            -9.0768e-08, -7.4181e-08, -1.5810e-08, -7.5298e-08, -2.9885e-07,\n            -4.2970e-08, -2.8976e-08,  4.0800e-08, -1.4460e-07,  2.0497e-07,\n             4.8957e-08, -8.3787e-08, -1.0127e-07,  7.3200e-08,  4.3674e-08,\n             4.4542e-07,  1.8835e-07,  3.0439e-07, -9.9649e-09,  1.1938e-08,\n             9.1253e-08, -1.1422e-07, -2.9192e-08, -2.2456e-08, -1.8513e-07,\n             4.4128e-08, -5.5610e-09, -1.0340e-07, -1.5971e-07,  1.2956e-07,\n            -9.7583e-08, -2.8067e-07,  4.0358e-08, -5.1818e-09,  3.9606e-08,\n             6.1080e-08, -5.2243e-08, -1.2336e-07, -5.2757e-08, -1.4029e-08,\n            -2.0398e-08,  1.3482e-07, -1.3119e-07,  9.2594e-08,  1.5692e-07,\n             1.4734e-07, -1.5053e-07,  1.2721e-09, -2.5919e-07, -6.2922e-08,\n             2.2843e-07, -1.7005e-08,  2.4479e-08, -2.3626e-07,  1.4294e-07,\n            -5.1642e-08,  1.8429e-07, -2.7939e-07,  2.9407e-07, -8.0871e-08,\n             3.6208e-07, -1.5410e-08, -1.0907e-07, -2.1380e-08, -2.2206e-09,\n             2.2953e-07,  1.5361e-07,  1.1957e-07, -2.1905e-07, -4.8463e-08,\n             1.7278e-08, -2.0755e-08,  6.3181e-08, -1.6689e-07,  3.0030e-08,\n            -2.1371e-08,  2.4862e-07, -1.6353e-07, -2.9583e-07, -2.1284e-07,\n             9.2081e-09, -1.1498e-07,  9.7166e-08, -4.5919e-08,  1.0845e-07,\n             1.6422e-07, -8.9891e-09, -1.3122e-07,  1.2836e-07,  6.7980e-08,\n             2.2631e-07, -1.4156e-07, -3.7934e-08, -1.1596e-08,  7.9442e-08,\n             1.0699e-07, -4.4290e-08, -3.7504e-08, -3.8142e-08, -1.2773e-07,\n            -5.9464e-09,  1.1929e-08, -2.6857e-08,  9.1322e-09, -1.4554e-07,\n             1.5370e-07,  7.4081e-08, -1.0143e-07, -2.8661e-08,  2.8904e-07,\n            -9.9215e-08, -4.2059e-08, -5.1212e-08,  1.6341e-07, -1.5919e-07,\n             8.8354e-09,  6.4325e-08, -1.8939e-07, -4.6930e-08,  2.1911e-07,\n             2.8803e-07, -9.2258e-08,  1.0116e-07,  1.9754e-07, -8.8678e-08,\n             3.6123e-08, -9.5161e-08, -1.2412e-07,  8.0875e-08, -9.1569e-08,\n            -3.4951e-07,  2.2729e-07,  4.2895e-08,  3.4806e-07,  8.3839e-08,\n            -3.1179e-07,  4.7814e-08,  3.7060e-08, -2.9902e-08, -4.1848e-08,\n            -1.8154e-08,  9.2682e-08,  5.5289e-08, -3.4901e-08, -4.0939e-08,\n            -6.0086e-08, -6.3614e-09, -9.0763e-08, -2.8051e-08, -8.0866e-08,\n             4.3914e-08,  1.7937e-09,  2.3102e-08, -2.3521e-08, -8.6025e-08,\n             7.1176e-09, -2.4853e-07,  1.8676e-07, -4.1739e-08,  9.8517e-08,\n            -1.3515e-07, -2.5465e-08,  4.5389e-08, -1.6661e-07,  8.6773e-08,\n            -1.8573e-07,  8.7132e-08,  3.4353e-08, -9.9547e-08, -1.2382e-07,\n            -1.1653e-07, -1.5618e-07, -4.3997e-08,  2.0697e-07, -5.6610e-08,\n             1.3755e-07, -7.0132e-08,  4.2316e-08,  1.1873e-07, -7.7492e-08,\n            -6.3532e-08,  1.9081e-08,  9.9829e-08,  1.6682e-07,  2.1962e-07,\n            -1.6745e-07, -2.4208e-07, -1.4732e-08, -7.5358e-08, -1.0393e-07,\n             4.1699e-09, -2.9816e-08, -1.3811e-07,  1.7649e-08,  5.6073e-08,\n            -1.3024e-07,  6.9033e-08, -8.8620e-08,  9.2580e-08, -4.8637e-09,\n            -1.5039e-07, -5.8108e-09, -1.9108e-08, -1.1705e-07, -1.5805e-07,\n             2.9353e-08,  1.5969e-07,  1.8755e-08,  3.5460e-08, -8.8850e-08,\n            -4.9103e-08,  1.7797e-07,  1.5107e-07, -1.1120e-07, -4.3188e-08,\n             3.0815e-07, -1.2916e-08, -6.3908e-08, -1.1057e-07,  5.3232e-08,\n             7.7211e-08, -2.6295e-09, -1.9653e-07, -1.2926e-07,  9.8917e-08,\n             4.7903e-08,  6.8527e-08, -1.1686e-07, -8.3257e-08,  9.1127e-08,\n             7.9637e-08,  1.7059e-07, -1.5838e-07, -1.3378e-07, -1.7682e-07,\n             1.5994e-07]),\n    'exp_avg_sq': tensor([2.1187e-13, 1.9315e-13, 1.8558e-13, 3.0044e-13, 4.6281e-13, 1.9778e-13,\n            2.2158e-13, 4.7913e-13, 2.8174e-13, 1.9460e-13, 2.4483e-13, 2.4368e-13,\n            3.7340e-13, 2.4706e-13, 2.6606e-13, 1.5575e-13, 3.3341e-13, 2.6967e-13,\n            3.7124e-13, 3.7645e-13, 2.6794e-13, 2.5046e-13, 2.7745e-13, 2.7615e-13,\n            2.3792e-13, 1.7616e-13, 9.3253e-14, 3.1115e-13, 2.0367e-13, 2.1456e-13,\n            2.2015e-13, 3.3564e-13, 2.6553e-13, 2.0867e-13, 2.3874e-13, 1.1312e-12,\n            1.8566e-13, 2.3113e-13, 2.7956e-13, 2.1452e-13, 2.9571e-13, 2.7352e-13,\n            9.5013e-14, 2.7560e-13, 2.7092e-13, 2.0797e-13, 2.3556e-13, 2.6646e-13,\n            3.5339e-13, 2.1473e-13, 1.9010e-13, 2.5994e-13, 1.8239e-13, 2.1376e-13,\n            1.8424e-13, 2.6318e-13, 3.0167e-13, 1.7900e-13, 2.6366e-13, 5.0109e-13,\n            2.7728e-13, 2.9147e-13, 2.9260e-13, 2.2823e-13, 2.8269e-13, 1.9531e-13,\n            1.7998e-13, 3.4402e-13, 4.8669e-13, 1.9235e-13, 5.9527e-13, 2.4851e-13,\n            2.5305e-13, 4.9352e-13, 3.0794e-13, 2.2335e-13, 3.8692e-13, 4.0168e-13,\n            2.9464e-13, 4.2752e-13, 3.2157e-13, 2.3102e-13, 1.7036e-13, 3.2389e-13,\n            1.4073e-13, 4.6576e-13, 2.7522e-13, 1.7020e-13, 2.8707e-13, 2.2296e-13,\n            2.0352e-13, 6.2911e-13, 2.3724e-13, 2.6920e-13, 1.8877e-13, 2.6985e-13,\n            2.8788e-13, 2.9891e-13, 3.7153e-13, 3.8599e-13, 1.4294e-13, 2.1288e-13,\n            2.4243e-13, 3.6843e-13, 5.0892e-13, 2.3441e-13, 1.6531e-13, 2.1712e-13,\n            2.3887e-13, 3.0257e-13, 3.8720e-13, 2.1121e-13, 3.4548e-13, 2.5982e-13,\n            3.0181e-13, 1.8993e-13, 3.2687e-13, 3.5384e-13, 3.2096e-13, 1.5839e-13,\n            3.2122e-13, 2.3831e-13, 2.0612e-13, 2.5584e-13, 3.0096e-13, 2.4839e-13,\n            3.3336e-13, 2.3754e-13, 2.6175e-13, 3.3529e-13, 3.6263e-13, 1.7446e-13,\n            3.0973e-13, 1.9443e-13, 8.8855e-13, 1.4199e-13, 1.0711e-13, 1.4330e-13,\n            2.4183e-13, 2.4534e-13, 3.5981e-13, 2.1366e-13, 3.5512e-13, 1.8477e-13,\n            2.2258e-13, 3.1276e-13, 2.2868e-13, 1.7146e-13, 2.0129e-13, 4.0598e-13,\n            3.3521e-13, 2.7669e-13, 1.9374e-13, 6.5115e-13, 1.9059e-13, 3.8349e-13,\n            2.1591e-13, 1.7784e-13, 3.5532e-13, 1.5783e-13, 2.9300e-13, 3.3632e-13,\n            2.3721e-13, 8.7707e-14, 3.1876e-13, 2.1610e-13, 3.0947e-13, 2.2441e-13,\n            2.0169e-13, 2.4429e-13, 2.1723e-13, 2.8346e-13, 3.5124e-13, 4.0174e-13,\n            1.7898e-13, 2.6235e-13, 2.8876e-13, 1.1809e-12, 2.9814e-13, 3.0363e-13,\n            2.2985e-13, 3.7573e-13, 2.1971e-13, 4.0350e-13, 1.8070e-13, 2.1752e-13,\n            2.1826e-13, 2.5155e-13, 2.2986e-13, 2.4231e-13, 2.9254e-13, 2.5085e-13,\n            3.5480e-13, 2.7086e-13, 1.8941e-13, 1.5619e-13, 3.2440e-13, 2.1578e-13,\n            2.6040e-13, 2.0770e-13, 3.1177e-13, 5.2109e-13, 3.2041e-13, 4.2335e-13,\n            3.0223e-13, 2.8449e-13, 2.8692e-13, 1.8609e-13, 2.6876e-13, 3.4998e-13,\n            1.6356e-13, 7.3309e-13, 1.6617e-13, 2.5771e-13, 3.5386e-13, 3.3121e-13,\n            2.0469e-13, 3.8472e-13, 2.4404e-13, 2.6882e-13, 3.2252e-13, 1.8634e-13,\n            2.3560e-13, 3.0424e-13, 2.1723e-13, 2.7225e-13, 3.6493e-13, 2.3086e-13,\n            3.1558e-13, 2.3173e-13, 3.5782e-13, 4.3910e-13, 2.5830e-13, 2.0380e-13,\n            3.9039e-13, 2.5994e-13, 2.2088e-12, 3.5019e-13, 3.0164e-13, 3.6950e-13,\n            3.0405e-13, 3.8454e-13, 8.1604e-13, 2.2890e-13, 1.2442e-13, 4.2581e-13,\n            2.0652e-13, 3.0237e-13, 3.6554e-13, 2.2516e-13, 2.5123e-13, 2.6544e-13,\n            2.3738e-13, 1.6128e-13, 2.5613e-13, 2.7982e-13])},\n   71: {'exp_avg': tensor([-1.0239e-07,  1.4426e-08,  8.2851e-08, -1.6615e-07, -7.2812e-08,\n             3.7357e-08, -5.4858e-08,  1.5090e-07,  1.1231e-08, -1.4338e-08,\n             1.7531e-07,  1.0884e-07, -9.0966e-08,  3.0337e-08, -6.8209e-08,\n             1.2853e-07,  5.5624e-08, -2.9515e-07,  1.4823e-07,  6.5690e-08,\n            -6.1736e-08, -3.3778e-08,  1.4832e-08, -1.3017e-08, -1.4221e-07,\n            -3.9423e-08, -5.8928e-08, -2.1346e-08, -5.9118e-08,  1.6250e-07,\n            -7.0646e-08, -3.9685e-08,  3.6096e-08,  6.8775e-08, -1.0869e-08,\n             1.8611e-07,  1.6913e-07,  1.5329e-07, -2.1335e-09,  8.7603e-08,\n             1.9550e-07, -6.5373e-08, -3.0251e-08, -1.0112e-07, -7.7843e-08,\n            -7.9259e-08, -1.0679e-08,  1.7311e-08, -9.6752e-08,  1.8071e-08,\n            -1.3358e-09, -1.4986e-07,  6.1753e-08,  3.7693e-08,  3.2804e-08,\n             9.8756e-08, -2.1201e-08, -1.2756e-07, -9.6026e-09, -1.4157e-07,\n            -1.6400e-08,  3.8573e-08, -1.9356e-07,  9.1659e-08,  8.9975e-08,\n             4.3292e-08, -2.4022e-07,  2.9548e-08, -9.7400e-08,  9.4455e-09,\n             2.2123e-07, -2.0501e-09,  1.3556e-08,  2.3494e-08,  7.9297e-08,\n            -6.2485e-09,  1.5441e-07, -2.9971e-07,  2.1926e-07, -9.7905e-08,\n             2.5048e-07, -1.4018e-08, -6.3369e-08, -3.6032e-08, -2.3335e-08,\n             1.2997e-07, -4.6517e-08,  1.5702e-07, -1.7524e-07,  1.5840e-09,\n            -5.1357e-08, -1.3578e-08, -6.2523e-08, -1.6434e-07,  4.0915e-08,\n            -1.0491e-08,  1.1579e-07, -3.3166e-08, -1.9147e-07, -1.3596e-07,\n             1.1639e-07,  1.3586e-08, -4.7266e-08,  1.5367e-08,  1.2539e-07,\n             1.9589e-07, -7.0837e-08, -1.1027e-07, -6.9240e-09,  4.5116e-08,\n             1.6320e-07, -5.0713e-08, -5.6414e-09, -9.4127e-08, -7.6822e-09,\n             1.2220e-08,  8.2247e-09, -1.2410e-07,  7.9115e-09, -3.5341e-08,\n            -4.6948e-08,  3.0865e-08,  6.9156e-08,  3.2763e-08, -1.1831e-07,\n             5.3708e-08,  1.1988e-07, -6.7547e-08,  3.0273e-08,  2.0435e-07,\n            -1.2483e-07, -5.1855e-08, -3.5162e-08,  7.9049e-08, -1.2388e-07,\n            -1.5365e-08,  2.1050e-08, -1.2026e-07, -1.1367e-07,  1.6269e-07,\n             5.1266e-08, -7.4390e-08,  1.0565e-07,  1.8354e-07,  7.6103e-09,\n             5.1336e-08,  1.9932e-08, -5.4075e-08,  7.9941e-08, -5.3053e-08,\n            -2.5065e-07,  1.0596e-07,  8.3205e-08,  4.5807e-08,  7.5376e-08,\n            -1.5693e-07,  1.6743e-08, -2.0206e-09,  7.3879e-09, -2.2525e-08,\n            -2.5863e-08,  7.7155e-08,  1.4969e-07, -7.5817e-09,  4.9442e-08,\n             4.4342e-08,  6.1761e-08, -7.8126e-08, -8.1660e-08, -1.5701e-08,\n             1.8925e-08, -8.1757e-09, -1.0411e-08, -8.8743e-08, -4.4757e-08,\n             1.1758e-07, -1.6220e-07,  9.1760e-08,  1.1895e-08,  1.0016e-07,\n            -8.5633e-08, -2.5216e-08,  6.3192e-10, -1.7183e-07,  6.3274e-08,\n            -8.5158e-08,  9.6025e-08,  1.9048e-09, -6.4278e-08, -2.0569e-07,\n            -5.2700e-08, -6.1884e-08, -7.2048e-08,  6.7243e-08, -1.4539e-07,\n             1.0749e-07, -8.8855e-08,  3.1347e-08,  1.5236e-07, -2.6682e-08,\n            -2.4428e-08, -6.0936e-08,  1.3482e-07,  1.5370e-07,  1.9593e-07,\n            -9.5629e-08, -1.0674e-07, -7.0704e-08, -5.5212e-08, -6.8770e-09,\n             3.4131e-08, -8.2382e-08, -1.0381e-08,  1.1349e-07,  4.1653e-08,\n            -1.0598e-07,  8.6120e-08, -6.4777e-09,  6.9867e-08, -1.0949e-07,\n            -1.1166e-07, -5.2137e-10, -1.7763e-08, -1.4682e-07, -1.2695e-07,\n             4.9854e-08, -1.1131e-07, -1.5245e-08, -8.0937e-09, -1.6421e-07,\n            -7.6938e-08,  2.7904e-07,  1.2764e-07, -8.0731e-08,  1.0049e-08,\n             2.0400e-07, -6.0022e-08, -1.0653e-07,  1.0496e-09, -3.6318e-08,\n            -1.1921e-09, -4.6094e-11, -5.4421e-08, -1.2839e-07, -2.0362e-08,\n             4.0105e-08,  9.5898e-08, -3.2743e-08,  4.0751e-08, -1.9496e-08,\n             5.1909e-08,  8.2444e-08, -1.5441e-08, -3.4302e-08, -9.4262e-08,\n             1.2953e-07]),\n    'exp_avg_sq': tensor([1.2851e-13, 1.1370e-13, 1.1110e-13, 1.7963e-13, 1.8436e-13, 1.0178e-13,\n            1.6720e-13, 2.3115e-13, 1.4780e-13, 1.2310e-13, 1.7106e-13, 2.0871e-13,\n            1.5990e-13, 1.0448e-13, 1.7286e-13, 1.3170e-13, 1.9831e-13, 1.5211e-13,\n            1.5758e-13, 2.4724e-13, 1.2223e-13, 1.3900e-13, 1.6838e-13, 1.6579e-13,\n            1.4253e-13, 1.0971e-13, 8.5974e-14, 2.0156e-13, 1.4231e-13, 1.2181e-13,\n            1.6708e-13, 1.8797e-13, 1.4022e-13, 1.5083e-13, 1.5785e-13, 5.3972e-13,\n            1.5033e-13, 1.1277e-13, 1.9586e-13, 1.2672e-13, 1.6759e-13, 1.4981e-13,\n            6.7564e-14, 1.1651e-13, 1.4286e-13, 1.1942e-13, 1.3190e-13, 1.7837e-13,\n            1.6833e-13, 1.1801e-13, 9.0461e-14, 1.7666e-13, 1.2010e-13, 1.1426e-13,\n            1.2394e-13, 1.6034e-13, 1.4767e-13, 1.0668e-13, 1.5318e-13, 2.4248e-13,\n            2.0436e-13, 1.8524e-13, 2.1120e-13, 1.3973e-13, 1.9824e-13, 1.9841e-13,\n            1.3033e-13, 1.7193e-13, 2.1482e-13, 1.0261e-13, 4.0905e-13, 1.4876e-13,\n            1.7316e-13, 1.9888e-13, 1.7648e-13, 1.1143e-13, 2.9729e-13, 2.2494e-13,\n            1.9131e-13, 1.8768e-13, 1.5561e-13, 1.2599e-13, 1.2591e-13, 1.5198e-13,\n            1.0333e-13, 1.9965e-13, 1.3648e-13, 1.1465e-13, 1.5952e-13, 1.1943e-13,\n            1.6014e-13, 5.1291e-13, 1.2369e-13, 1.7776e-13, 1.4739e-13, 1.5033e-13,\n            1.5867e-13, 1.2401e-13, 1.8275e-13, 2.2752e-13, 1.0925e-13, 1.3439e-13,\n            1.4664e-13, 1.8428e-13, 2.8413e-13, 1.1502e-13, 1.0583e-13, 1.3770e-13,\n            1.1629e-13, 1.4749e-13, 2.6561e-13, 1.5079e-13, 1.6847e-13, 2.1375e-13,\n            2.2970e-13, 1.2193e-13, 1.7791e-13, 1.8606e-13, 2.3920e-13, 1.1147e-13,\n            2.6972e-13, 1.9305e-13, 1.3533e-13, 1.3428e-13, 1.6732e-13, 1.4313e-13,\n            1.7914e-13, 1.7174e-13, 1.3278e-13, 2.2000e-13, 2.2870e-13, 1.0898e-13,\n            1.4270e-13, 1.5478e-13, 5.3857e-13, 1.1617e-13, 1.0874e-13, 1.1299e-13,\n            1.5010e-13, 1.3893e-13, 1.5988e-13, 1.3234e-13, 2.5069e-13, 1.1710e-13,\n            1.3815e-13, 1.7492e-13, 1.2639e-13, 8.6504e-14, 1.3212e-13, 2.5454e-13,\n            2.1014e-13, 1.6931e-13, 1.2171e-13, 2.4945e-13, 1.2514e-13, 2.0423e-13,\n            1.6246e-13, 9.4545e-14, 1.5599e-13, 1.1442e-13, 1.5190e-13, 1.6435e-13,\n            1.2225e-13, 8.1903e-14, 2.6349e-13, 1.6663e-13, 2.0529e-13, 1.2355e-13,\n            1.0698e-13, 1.9469e-13, 1.3357e-13, 1.5365e-13, 2.1487e-13, 2.6000e-13,\n            1.0879e-13, 2.0545e-13, 1.6955e-13, 4.4824e-13, 1.4720e-13, 1.7804e-13,\n            1.0330e-13, 2.0590e-13, 1.3808e-13, 2.1210e-13, 9.7921e-14, 1.2730e-13,\n            1.2068e-13, 1.4147e-13, 1.6499e-13, 2.0403e-13, 1.5629e-13, 1.5117e-13,\n            2.1930e-13, 1.3075e-13, 1.3031e-13, 1.2104e-13, 1.6448e-13, 1.0969e-13,\n            1.7876e-13, 1.3190e-13, 2.3469e-13, 2.2985e-13, 1.8815e-13, 2.4077e-13,\n            1.6096e-13, 1.4925e-13, 2.0661e-13, 1.0180e-13, 1.2888e-13, 2.7323e-13,\n            9.4695e-14, 4.8327e-13, 1.5526e-13, 1.3488e-13, 1.8972e-13, 1.5358e-13,\n            1.6703e-13, 2.3319e-13, 1.5920e-13, 1.4724e-13, 2.3938e-13, 1.4598e-13,\n            1.4843e-13, 2.0404e-13, 1.5066e-13, 1.3021e-13, 1.8803e-13, 1.5360e-13,\n            1.6908e-13, 1.9855e-13, 1.7627e-13, 2.2307e-13, 1.2048e-13, 1.0350e-13,\n            2.1078e-13, 1.5129e-13, 1.0375e-12, 1.7511e-13, 1.3433e-13, 1.5373e-13,\n            2.0137e-13, 2.0418e-13, 4.3785e-13, 1.3586e-13, 9.1108e-14, 2.0346e-13,\n            1.2124e-13, 1.8735e-13, 2.2908e-13, 1.3700e-13, 1.2816e-13, 1.7656e-13,\n            1.6329e-13, 1.5238e-13, 1.3358e-13, 1.4789e-13])},\n   72: {'exp_avg': tensor([-2.7552e-07, -3.0415e-07, -3.4532e-08,  ...,  4.6448e-08,\n             1.9944e-07, -1.4179e-07]),\n    'exp_avg_sq': tensor([1.0340e-12, 1.0329e-12, 1.0287e-12,  ..., 1.2318e-12, 1.4091e-12,\n            1.0639e-12])},\n   73: {'exp_avg': tensor([-1.0568e-07, -8.9703e-08,  1.2705e-07,  ..., -9.5900e-09,\n            -1.0162e-07, -1.9069e-07]),\n    'exp_avg_sq': tensor([9.8976e-14, 1.7502e-13, 2.2157e-13,  ..., 1.2855e-13, 3.1734e-13,\n            1.2683e-13])},\n   74: {'exp_avg': tensor([ 1.0970e-07,  2.9309e-07, -1.9046e-07,  3.4026e-08,  1.5258e-07,\n            -3.2697e-08,  4.5787e-08,  2.5486e-08, -1.5159e-07, -9.4846e-08,\n            -2.5025e-07,  1.0461e-07,  5.1705e-08, -1.5677e-07, -7.6808e-08,\n             1.0329e-08, -4.5757e-09,  4.2939e-09,  6.6439e-08,  5.8344e-08,\n            -2.3899e-07, -1.1754e-07,  1.4376e-08,  3.3038e-08, -1.7138e-07,\n             4.4864e-08, -4.3951e-08, -1.5426e-08,  1.9048e-07, -8.7969e-08,\n             5.2482e-09,  5.6569e-08, -1.4596e-08, -1.7068e-08,  8.8591e-08,\n             2.0365e-07,  4.9518e-08,  2.1175e-07, -1.1864e-08,  2.3836e-07,\n             7.6216e-08,  1.8614e-07, -1.5156e-07, -2.7099e-07, -1.9817e-07,\n             1.4512e-07,  2.0879e-07,  6.9381e-08, -9.6111e-08,  2.8039e-08,\n            -8.5889e-08, -1.4968e-07,  1.8568e-08,  2.6936e-08, -8.6257e-09,\n            -5.4732e-08, -8.7446e-08, -5.3661e-08, -2.3502e-08, -9.9287e-08,\n             4.4857e-09,  4.1509e-08, -8.6092e-08, -2.2001e-07,  3.2202e-08,\n            -9.9785e-08,  9.0080e-08,  3.2402e-08,  1.7954e-07, -1.3326e-07,\n             1.1555e-07,  2.2215e-07,  3.9924e-08,  4.1940e-08,  1.8418e-07,\n            -7.9055e-08,  1.1156e-07, -3.8734e-08, -1.8995e-08,  6.9710e-08,\n            -6.3063e-08,  1.1922e-07, -6.6904e-08, -1.4070e-07,  2.3857e-07,\n            -9.0050e-08,  1.2792e-07,  5.9336e-08, -4.8088e-08, -2.3378e-07,\n             2.2646e-08, -5.2072e-08,  5.5684e-08, -1.6142e-07, -1.7572e-07,\n            -2.9456e-07,  4.9875e-08, -1.2692e-07,  1.0752e-07,  6.5901e-08,\n            -9.1653e-08, -5.7738e-08,  6.0112e-08,  9.7453e-08,  8.9793e-08,\n             1.8479e-07, -1.1106e-07, -9.4881e-08, -1.0684e-07,  9.8266e-08,\n            -2.3289e-09, -1.4233e-07, -4.4302e-08,  2.4944e-08,  1.4077e-07,\n             3.6568e-08, -2.3939e-08,  1.0615e-07,  7.6767e-08,  2.3096e-07,\n            -2.2772e-07, -2.2146e-08,  2.0977e-08,  7.9799e-08,  4.3175e-08,\n             2.3612e-07, -1.7695e-07,  1.7204e-07, -3.3054e-08,  1.1004e-07,\n             3.7957e-08,  6.8023e-08,  7.0784e-08, -1.3523e-07, -5.2298e-08,\n             2.3074e-08,  1.2185e-07, -8.4212e-08, -2.1839e-09, -2.3106e-08,\n            -6.2375e-08,  1.3094e-07,  2.7567e-07, -2.7025e-07, -1.0092e-07,\n             3.7954e-08,  1.2181e-07, -6.3152e-08, -1.5289e-08,  1.3825e-07,\n             1.3794e-07, -1.3843e-07, -8.3650e-08,  2.3942e-07, -3.1455e-09,\n            -3.2249e-08,  2.0231e-08,  8.1150e-08, -1.2878e-08,  6.5911e-08,\n            -6.4693e-08, -1.5856e-07,  7.5904e-08,  1.5002e-08,  3.0365e-08,\n            -5.2151e-08, -1.9331e-07,  1.7936e-07, -2.0666e-08, -1.5922e-08,\n            -2.5060e-08,  1.8768e-07, -9.8555e-08,  1.7062e-07,  5.7767e-08,\n             2.9174e-08, -2.5464e-07, -8.3590e-08,  4.4081e-08,  1.2531e-07,\n            -9.6016e-09, -8.2464e-08, -1.1062e-07, -1.1093e-07, -9.1989e-08,\n             7.3926e-09,  1.1503e-07, -2.3365e-07,  2.1737e-07, -1.3762e-07,\n            -1.5790e-07,  6.6851e-08, -1.0770e-07,  1.6176e-07, -3.7290e-08,\n            -6.3238e-08, -1.3588e-07,  4.3400e-09, -1.9660e-07,  9.9913e-09,\n            -2.1097e-07, -5.7539e-08, -2.5160e-07, -1.9846e-07,  1.5131e-07,\n            -8.4529e-08, -7.9684e-09, -2.0065e-08,  1.7965e-07, -2.2431e-07,\n             2.5849e-07,  4.7543e-08,  2.2377e-08,  2.2041e-07,  4.3328e-08,\n            -2.2223e-08,  1.3557e-07,  1.0204e-07, -1.3791e-07,  1.3751e-07,\n             2.5213e-07,  1.2954e-07,  1.7830e-07, -7.7748e-08, -1.1559e-07,\n            -2.3234e-07, -1.1081e-07, -1.3721e-09, -9.7371e-08,  3.9887e-08,\n             2.7178e-07, -1.1116e-07, -4.8779e-08,  8.2706e-08, -8.8631e-08,\n            -5.1662e-09,  2.1111e-07, -2.3931e-07, -1.1967e-07, -5.3405e-08,\n            -1.1695e-07,  1.1291e-07, -9.5556e-08,  1.1092e-07,  3.2048e-08,\n             6.9341e-08, -5.0333e-08,  4.1123e-08, -1.4256e-07,  6.8948e-09,\n             1.0946e-07,  4.9605e-08, -3.8106e-08,  5.9304e-08, -9.0611e-08,\n             8.3737e-08]),\n    'exp_avg_sq': tensor([2.8908e-13, 2.7467e-13, 2.9080e-13, 2.1771e-13, 2.7255e-13, 2.3236e-13,\n            2.7591e-13, 1.8680e-13, 3.7400e-13, 2.9126e-13, 3.0196e-13, 2.4655e-13,\n            2.3854e-13, 2.3861e-13, 2.5144e-13, 3.9831e-13, 2.9235e-13, 3.2851e-13,\n            2.5171e-13, 3.5975e-13, 3.7462e-13, 3.8807e-13, 2.6433e-13, 1.9178e-13,\n            3.9748e-13, 2.9769e-13, 2.4143e-13, 3.5876e-13, 3.0410e-13, 3.1178e-13,\n            3.0186e-13, 2.9764e-13, 2.8479e-13, 3.4030e-13, 2.7182e-13, 3.6382e-13,\n            3.9641e-13, 3.6709e-13, 4.6017e-13, 2.6082e-13, 2.7608e-13, 3.1056e-13,\n            2.8750e-13, 2.7363e-13, 5.9177e-13, 3.1325e-13, 3.8452e-13, 1.9254e-13,\n            3.5091e-13, 2.3408e-13, 3.6234e-13, 2.1142e-13, 3.4160e-13, 2.4346e-13,\n            3.1354e-13, 2.9033e-13, 2.1634e-13, 2.0288e-13, 3.2383e-13, 3.4175e-13,\n            2.1582e-13, 5.3825e-13, 3.7949e-13, 2.6013e-13, 2.7674e-13, 2.6425e-13,\n            3.1409e-13, 3.5094e-13, 2.3096e-13, 2.9166e-13, 2.5933e-13, 3.1808e-13,\n            3.2409e-13, 2.9134e-13, 6.4867e-13, 3.3520e-13, 3.7510e-13, 3.5675e-13,\n            2.6814e-13, 4.0843e-13, 3.7383e-13, 4.1591e-13, 3.8193e-13, 3.4982e-13,\n            3.6337e-13, 3.4339e-13, 2.9853e-13, 2.4286e-13, 2.7053e-13, 2.7242e-13,\n            2.6255e-13, 2.5255e-13, 2.6365e-13, 3.2703e-13, 1.8913e-13, 2.9501e-13,\n            3.8235e-13, 4.3523e-13, 6.4004e-13, 3.4474e-13, 2.8360e-13, 1.6679e-13,\n            3.7400e-13, 4.3588e-13, 3.3827e-13, 2.9023e-13, 1.9476e-13, 3.1491e-13,\n            2.6040e-13, 5.2707e-13, 4.4974e-13, 3.8920e-13, 4.1592e-13, 4.3461e-13,\n            2.8362e-13, 4.2899e-13, 2.4304e-13, 1.6850e-13, 4.1162e-13, 1.8155e-13,\n            3.5538e-13, 1.6848e-13, 3.1435e-13, 3.5531e-13, 2.1438e-13, 2.8560e-13,\n            2.3170e-13, 4.5889e-13, 2.6174e-13, 2.7112e-13, 1.7823e-13, 2.6372e-13,\n            3.0420e-13, 2.8831e-13, 3.9481e-13, 4.0252e-13, 3.2096e-13, 2.3861e-13,\n            3.3178e-13, 2.9232e-13, 3.0233e-13, 2.5129e-13, 2.9230e-13, 3.9972e-13,\n            3.1923e-13, 2.4532e-13, 2.8860e-13, 4.1100e-13, 2.0288e-13, 4.5827e-13,\n            4.1940e-13, 2.1198e-13, 3.2233e-13, 3.8486e-13, 2.3710e-13, 3.0720e-13,\n            2.3442e-13, 5.9230e-13, 2.1461e-13, 3.1146e-13, 2.9506e-13, 3.5293e-13,\n            1.9152e-13, 2.7842e-13, 3.7161e-13, 2.6463e-13, 2.8045e-13, 3.6724e-13,\n            3.2496e-13, 3.9221e-13, 3.0089e-13, 2.5546e-13, 3.1530e-13, 3.7720e-13,\n            8.3151e-13, 3.9009e-13, 3.0277e-13, 3.2240e-13, 2.4988e-13, 2.1266e-13,\n            5.7506e-13, 3.0977e-13, 2.8806e-13, 4.0057e-13, 2.6748e-13, 3.3619e-13,\n            2.6433e-13, 2.2584e-13, 4.0931e-13, 2.7633e-13, 2.6062e-13, 2.9355e-13,\n            2.8685e-13, 5.5964e-13, 2.7809e-13, 3.4228e-13, 3.9726e-13, 2.6126e-13,\n            4.1530e-13, 2.1316e-13, 3.0025e-13, 2.5033e-13, 4.1511e-13, 2.2701e-13,\n            2.9895e-13, 3.0149e-13, 2.6990e-13, 6.7829e-13, 4.0670e-13, 3.6688e-13,\n            3.9500e-13, 2.2151e-13, 2.5327e-13, 4.6976e-13, 3.1347e-13, 2.8231e-13,\n            4.7953e-13, 2.4300e-13, 3.4686e-13, 2.8297e-13, 3.1247e-13, 2.7759e-13,\n            5.2998e-13, 2.6536e-13, 2.8503e-13, 4.2948e-13, 3.8968e-13, 3.1795e-13,\n            4.6588e-13, 3.3088e-13, 4.7522e-13, 3.8736e-13, 4.2397e-13, 3.9074e-13,\n            3.7517e-13, 3.2983e-13, 2.4612e-13, 6.0136e-13, 3.3727e-13, 2.6755e-13,\n            2.0362e-13, 2.7170e-13, 3.5449e-13, 3.1141e-13, 1.8201e-13, 4.4363e-13,\n            2.9962e-13, 3.1083e-13, 2.7901e-13, 2.4499e-13, 6.1850e-13, 2.7500e-13,\n            3.4029e-13, 3.4951e-13, 2.0727e-13, 1.9608e-13])},\n   75: {'exp_avg': tensor([ 1.2371e-07,  1.5193e-07, -1.1231e-07,  9.6474e-08,  3.5740e-08,\n             1.8602e-08,  4.6452e-09,  7.9823e-08, -9.6898e-08,  4.2598e-08,\n            -2.0769e-07,  6.2702e-08,  4.1436e-08, -1.5599e-07, -1.6031e-07,\n            -1.2035e-08,  1.5214e-08,  2.1210e-10,  7.2000e-08,  6.2884e-08,\n            -1.0694e-07, -3.0792e-08, -3.2849e-08,  4.0886e-08, -1.1412e-07,\n             6.3834e-08, -4.8821e-08,  7.7789e-09,  9.1573e-08, -3.8893e-08,\n            -3.1113e-08,  5.3547e-08,  6.2758e-08,  2.7550e-08,  1.0937e-07,\n             3.1667e-09, -7.6950e-08,  9.7425e-08, -6.4329e-08,  2.5369e-07,\n             3.5197e-08,  1.8588e-07, -1.1298e-07, -1.9355e-07, -6.6629e-08,\n             9.1480e-08,  4.0816e-08,  6.0306e-08,  6.5544e-09,  2.0963e-08,\n            -9.3612e-08, -2.0815e-07,  8.6076e-09, -2.5648e-10, -9.5018e-08,\n            -3.9631e-09, -3.3104e-08,  3.1513e-09, -5.9909e-09, -1.2156e-08,\n             9.0603e-09,  7.7280e-08, -2.0357e-08, -1.6485e-07, -9.1127e-08,\n             8.2104e-09,  1.0455e-07,  2.1817e-08,  6.1750e-08, -5.2446e-08,\n             2.8253e-08,  6.1824e-08,  1.1342e-07,  5.8211e-08,  1.4546e-07,\n             1.8363e-08,  1.3023e-08, -2.4423e-11, -8.2559e-08,  6.5755e-08,\n            -6.0677e-08,  4.5241e-09, -1.4835e-07, -3.6006e-08,  1.4199e-07,\n             5.4480e-09,  4.6686e-08,  3.2900e-09,  2.0889e-08, -1.2948e-07,\n             3.1677e-09, -1.3226e-07,  7.4122e-08, -1.5530e-07, -3.3102e-08,\n            -2.5517e-07, -1.8093e-08, -1.1471e-07,  1.5754e-07, -8.4248e-09,\n            -5.3941e-08,  2.1723e-08,  9.8033e-08,  4.0380e-08,  5.4548e-08,\n             7.0451e-08, -5.8353e-09, -1.1102e-07, -6.2331e-08,  5.6365e-08,\n            -3.5327e-08, -9.8001e-08, -2.1661e-08,  7.5634e-08,  4.4097e-08,\n            -4.3159e-08,  4.9919e-09,  4.1706e-08,  5.5375e-08,  1.2482e-07,\n            -1.4437e-07,  6.8449e-08, -4.9106e-08,  2.8610e-08, -7.0144e-09,\n             9.9283e-08, -1.1469e-07,  1.3181e-07, -4.7958e-08,  1.2616e-08,\n             2.1791e-08,  5.3134e-08,  2.2071e-08, -2.7224e-08, -1.3935e-07,\n            -3.6764e-08,  4.1509e-08, -4.0694e-08,  7.3882e-08, -8.1999e-08,\n            -1.2718e-07,  1.1259e-07,  1.8728e-07, -1.1832e-07, -9.7898e-08,\n             4.2186e-08,  4.5705e-10,  7.5901e-08,  9.7295e-09, -5.1561e-09,\n             7.7848e-08, -6.6318e-08, -5.3729e-08,  1.2194e-07, -7.8312e-08,\n            -2.1204e-08,  1.9108e-08,  1.2982e-07, -1.1604e-07,  9.0712e-08,\n            -2.3109e-08, -1.2452e-07,  6.3648e-08,  3.0976e-08,  8.1474e-08,\n            -4.0310e-08,  5.5417e-09,  9.1978e-08, -2.0210e-08, -1.8798e-08,\n             8.2744e-09,  7.6224e-08, -4.0693e-08,  1.1989e-07,  2.3662e-08,\n             4.8109e-08, -9.5548e-08,  5.4331e-08,  6.7892e-08,  1.1270e-07,\n            -3.5084e-08, -1.6419e-08,  1.0363e-08, -1.3604e-07, -7.4750e-08,\n            -7.4006e-08,  2.0343e-07, -1.0724e-07,  2.6278e-07, -4.9316e-08,\n            -5.3464e-08,  3.4170e-08, -6.7308e-08,  1.7668e-07,  1.7617e-08,\n            -6.1795e-08, -9.0460e-08,  2.9008e-08, -1.9173e-07, -2.8095e-08,\n            -1.9224e-07, -1.3697e-07, -1.9460e-07, -7.2247e-08,  7.2057e-08,\n             6.2280e-09, -3.2327e-08, -5.7071e-08,  5.7925e-08, -6.0181e-08,\n             2.0321e-07,  5.8571e-08,  9.8449e-08,  3.7794e-09,  2.6748e-08,\n             2.9087e-08,  6.6827e-08, -6.2935e-10, -1.3983e-07,  7.9772e-09,\n             1.3559e-07,  2.0692e-08,  1.5032e-07, -1.6539e-08, -1.0735e-07,\n            -1.7894e-07, -3.2779e-08, -9.4848e-08, -1.3207e-07, -2.8260e-08,\n             2.0576e-07, -3.6236e-08, -1.7451e-07, -1.4390e-08, -4.0974e-08,\n             5.8602e-08,  7.1068e-08, -3.4260e-08, -8.7066e-08, -8.2488e-08,\n            -5.1575e-08, -3.7755e-08, -4.3295e-08,  8.4497e-08, -7.1028e-09,\n             2.2114e-07,  7.0384e-10, -4.5510e-08, -1.1776e-07, -1.0348e-08,\n             1.2872e-07,  1.2011e-08, -1.8226e-08, -1.1453e-08, -7.5430e-08,\n            -6.3866e-08]),\n    'exp_avg_sq': tensor([1.7080e-13, 1.7201e-13, 1.9078e-13, 1.5068e-13, 1.7713e-13, 1.5091e-13,\n            1.9602e-13, 1.5552e-13, 1.8478e-13, 1.8169e-13, 1.9067e-13, 1.8195e-13,\n            1.3902e-13, 1.5447e-13, 1.6683e-13, 1.9588e-13, 1.8073e-13, 1.9174e-13,\n            1.6661e-13, 2.1054e-13, 1.9386e-13, 2.2980e-13, 1.7184e-13, 1.5527e-13,\n            2.1790e-13, 1.8050e-13, 1.8890e-13, 2.1730e-13, 1.9746e-13, 1.9420e-13,\n            2.5888e-13, 1.6542e-13, 1.7119e-13, 1.8329e-13, 1.6438e-13, 2.1878e-13,\n            2.4179e-13, 1.9483e-13, 2.9367e-13, 1.5276e-13, 1.5156e-13, 2.0052e-13,\n            1.7353e-13, 1.6994e-13, 2.6461e-13, 2.1748e-13, 1.8306e-13, 1.7212e-13,\n            1.8797e-13, 1.5990e-13, 2.0596e-13, 1.6481e-13, 1.6698e-13, 1.5828e-13,\n            1.9402e-13, 2.2483e-13, 1.5894e-13, 1.7672e-13, 2.0722e-13, 1.9884e-13,\n            1.7716e-13, 2.5864e-13, 2.1892e-13, 2.0665e-13, 1.7487e-13, 1.7635e-13,\n            1.6611e-13, 2.2379e-13, 1.6187e-13, 1.6905e-13, 1.5855e-13, 1.8135e-13,\n            2.2558e-13, 1.5874e-13, 2.2360e-13, 1.8571e-13, 2.3632e-13, 2.0743e-13,\n            1.9109e-13, 2.1209e-13, 1.8591e-13, 2.0875e-13, 1.7966e-13, 1.8169e-13,\n            2.3281e-13, 1.9427e-13, 2.0549e-13, 1.6600e-13, 2.0815e-13, 1.5625e-13,\n            1.6155e-13, 1.5953e-13, 1.9269e-13, 2.2523e-13, 1.4817e-13, 1.8624e-13,\n            1.6153e-13, 2.4717e-13, 2.7424e-13, 1.9004e-13, 1.7809e-13, 1.3708e-13,\n            1.8589e-13, 2.0806e-13, 2.0568e-13, 1.6276e-13, 1.3618e-13, 1.9318e-13,\n            1.8596e-13, 2.9397e-13, 2.1704e-13, 1.9604e-13, 1.9702e-13, 2.1553e-13,\n            1.9148e-13, 1.9303e-13, 1.5639e-13, 1.2829e-13, 1.8648e-13, 1.2339e-13,\n            2.1420e-13, 1.3129e-13, 1.5436e-13, 1.9396e-13, 1.5130e-13, 1.6052e-13,\n            1.3729e-13, 1.9193e-13, 1.8805e-13, 1.6733e-13, 1.4409e-13, 1.4696e-13,\n            1.6885e-13, 1.5944e-13, 2.0991e-13, 2.2427e-13, 1.9903e-13, 1.6428e-13,\n            1.7911e-13, 2.0138e-13, 1.6220e-13, 1.5781e-13, 2.1605e-13, 2.1015e-13,\n            1.6696e-13, 1.3823e-13, 1.5487e-13, 2.4345e-13, 1.2823e-13, 1.9692e-13,\n            2.1685e-13, 1.5544e-13, 1.7914e-13, 2.5129e-13, 1.7538e-13, 1.9245e-13,\n            1.9019e-13, 2.4537e-13, 1.4186e-13, 1.7277e-13, 1.7621e-13, 1.8852e-13,\n            1.3677e-13, 1.9813e-13, 1.7975e-13, 1.7411e-13, 2.0178e-13, 1.7501e-13,\n            2.0722e-13, 2.1796e-13, 1.6011e-13, 1.5159e-13, 2.2541e-13, 2.1168e-13,\n            2.8766e-13, 2.0811e-13, 1.8691e-13, 1.7514e-13, 1.7770e-13, 1.5732e-13,\n            2.4918e-13, 1.7611e-13, 1.5510e-13, 2.3856e-13, 1.5714e-13, 1.9968e-13,\n            1.4525e-13, 1.4903e-13, 2.4485e-13, 1.8179e-13, 1.5280e-13, 1.5990e-13,\n            1.6587e-13, 2.2729e-13, 1.6431e-13, 2.0473e-13, 2.1194e-13, 1.6198e-13,\n            2.2253e-13, 1.4782e-13, 1.9021e-13, 1.9321e-13, 2.0969e-13, 1.5362e-13,\n            1.7113e-13, 1.7324e-13, 2.1512e-13, 2.8770e-13, 1.8315e-13, 2.2059e-13,\n            2.5182e-13, 1.4539e-13, 1.6042e-13, 2.4781e-13, 2.4280e-13, 1.6991e-13,\n            2.0992e-13, 1.5099e-13, 1.6439e-13, 1.8451e-13, 1.8429e-13, 1.9369e-13,\n            2.7022e-13, 1.7624e-13, 1.7700e-13, 2.9581e-13, 2.2990e-13, 2.1827e-13,\n            2.7982e-13, 1.7537e-13, 2.2232e-13, 1.8235e-13, 2.1894e-13, 2.0137e-13,\n            1.8913e-13, 1.7908e-13, 1.6681e-13, 2.4363e-13, 1.8219e-13, 1.6837e-13,\n            1.4414e-13, 1.4550e-13, 1.9573e-13, 1.5597e-13, 1.4807e-13, 2.4547e-13,\n            1.9468e-13, 1.7516e-13, 1.5317e-13, 1.8063e-13, 2.2529e-13, 1.6957e-13,\n            2.2515e-13, 1.8177e-13, 1.7870e-13, 1.6953e-13])},\n   76: {'exp_avg': tensor([-2.2204e-07, -9.8849e-08, -2.0471e-07,  4.4677e-08,  7.3694e-08,\n            -9.1201e-08, -1.9930e-08,  1.4117e-07,  8.9650e-08,  2.4599e-08,\n            -5.7797e-08, -9.3958e-08,  1.6996e-07, -2.7383e-07,  1.1108e-07,\n            -9.2403e-08,  1.9608e-08, -1.1476e-07,  1.6691e-07,  1.0936e-07,\n             3.6672e-08, -7.4847e-08,  1.2315e-07,  7.2458e-08, -6.0020e-10,\n            -1.7882e-08,  3.1326e-08, -3.0426e-08,  1.8599e-07,  1.0553e-07,\n             3.2389e-08, -1.2051e-07,  8.2788e-08,  3.6697e-07,  1.3436e-07,\n             4.3852e-07, -1.2206e-07, -1.9777e-07,  3.2854e-10,  6.7508e-08,\n             6.8630e-08,  4.2366e-08,  3.5534e-08,  1.1081e-07,  3.5344e-09,\n             1.2140e-07, -1.7382e-07, -2.3743e-07, -5.0628e-08, -1.5099e-08,\n            -1.8377e-07, -7.8093e-08,  2.1569e-08,  6.1142e-08, -8.6034e-09,\n            -1.7902e-07,  9.5974e-08, -1.1515e-07, -2.6725e-08, -8.9710e-08,\n            -9.6186e-08,  1.2636e-07,  8.6395e-08,  1.0499e-07, -1.3390e-08,\n            -1.7059e-07, -2.6118e-07, -1.2325e-07, -1.7726e-07, -5.5825e-08,\n             1.9834e-07,  7.9016e-08, -3.7301e-08,  1.0997e-07, -1.9638e-07,\n            -8.0372e-08,  1.6425e-07, -1.4975e-07,  1.7550e-07, -2.3356e-07,\n             2.9379e-07, -1.7705e-08,  1.3595e-07,  1.0003e-07,  9.2195e-08,\n             2.0285e-07,  8.3197e-10, -3.8426e-08,  5.9465e-08,  2.3227e-08,\n            -1.2918e-07, -3.3496e-07, -8.6529e-08, -2.3006e-07, -4.8616e-08,\n             3.7039e-08, -8.7299e-08, -8.8689e-08,  1.1256e-07, -2.9018e-09,\n             1.7944e-07, -1.1141e-07, -1.9732e-07,  2.2317e-08, -9.9367e-08,\n             2.7046e-07, -1.3506e-07,  1.6723e-07,  2.6343e-07,  9.8676e-08,\n            -1.8883e-07,  1.0470e-07, -1.0478e-07,  1.6727e-08, -6.6034e-08,\n             2.8034e-07,  4.0253e-08,  2.9455e-07,  2.2122e-07, -2.6414e-08,\n            -2.1696e-07, -7.0718e-10,  9.4192e-08,  2.4966e-07,  2.2970e-07,\n             2.4714e-08, -1.3507e-07,  6.8473e-09, -1.2472e-07, -6.9018e-08,\n            -2.6531e-08, -4.2019e-08,  8.7796e-08, -1.6830e-09,  9.4913e-09,\n            -1.2227e-07,  1.5920e-07, -6.5657e-08, -1.8012e-07,  3.9666e-07,\n             1.6591e-08, -7.2374e-09, -2.9257e-08,  2.7475e-07, -7.8957e-08,\n            -1.1217e-07,  7.1532e-09,  2.7067e-08, -3.4491e-09,  6.2900e-08,\n             7.8405e-08, -1.2879e-07, -1.6862e-07, -8.1003e-08, -8.8358e-08,\n            -4.9819e-10, -5.5759e-08, -8.5397e-08,  1.7750e-08,  9.5376e-08,\n             1.1033e-07, -1.7381e-07,  1.4313e-07, -2.2469e-07,  9.7897e-09,\n            -1.8344e-08, -2.2988e-08,  1.2380e-07, -1.6916e-07, -5.3595e-08,\n             2.0074e-07, -1.2018e-07,  4.7621e-08, -1.8339e-08,  4.8208e-08,\n            -2.0087e-07,  1.4098e-07,  2.0556e-08, -8.1895e-08, -1.3385e-08,\n             2.6321e-09, -4.8403e-08, -2.0082e-08,  4.6815e-08,  6.4091e-08,\n            -2.8932e-08, -6.6888e-08,  1.7039e-07,  1.2192e-07, -8.9762e-08,\n             6.8113e-08, -1.9177e-07,  3.5227e-09, -1.5521e-07, -5.6460e-08,\n             4.6171e-08,  1.4148e-09, -1.4207e-07,  4.7617e-08, -4.5409e-08,\n             9.7370e-08,  1.4936e-07,  7.8793e-09, -3.3898e-07,  1.8024e-07,\n            -9.9543e-08,  4.8309e-08,  3.7544e-08, -7.2599e-08, -1.0008e-07,\n            -1.5909e-07,  2.7800e-08,  2.6643e-07,  9.8615e-09,  3.3305e-08,\n            -1.2217e-07,  5.5632e-08, -8.7934e-08,  1.2433e-07,  7.6618e-08,\n             1.3955e-08, -5.0190e-08, -1.1428e-07,  1.6904e-07, -2.5343e-08,\n             5.6746e-08, -2.4131e-07, -1.1330e-07,  1.4834e-08,  4.6556e-07,\n            -1.8080e-08, -1.1313e-07, -1.7117e-07, -3.3124e-08, -2.1825e-08,\n             3.5670e-09, -8.0555e-08, -5.5517e-09,  1.3438e-08,  2.8678e-09,\n            -1.7281e-07,  1.5781e-07,  8.3295e-08,  5.1545e-08,  8.9033e-08,\n            -2.2540e-07, -7.9129e-08, -8.6168e-08, -8.3373e-08, -8.7341e-08,\n             1.3763e-07, -1.0602e-08,  3.3166e-08, -4.3419e-08,  1.9804e-07,\n             8.3883e-08]),\n    'exp_avg_sq': tensor([2.5912e-13, 3.9190e-13, 2.9140e-13, 2.2587e-13, 3.2428e-13, 3.6789e-13,\n            2.1424e-13, 3.3348e-13, 1.4840e-13, 1.5326e-13, 2.6276e-13, 3.4264e-13,\n            2.8916e-13, 4.1388e-13, 2.7968e-13, 2.2038e-13, 2.3418e-13, 3.5795e-13,\n            3.0615e-13, 2.6432e-13, 1.8294e-13, 2.3172e-13, 1.8340e-13, 2.5029e-13,\n            3.1125e-13, 2.6843e-13, 2.2657e-13, 2.8308e-13, 2.5872e-13, 2.1476e-13,\n            3.9601e-13, 2.1914e-13, 2.4329e-13, 4.7268e-13, 3.4183e-13, 2.6946e-13,\n            2.5283e-13, 2.6916e-13, 2.1778e-13, 2.1069e-13, 3.2050e-13, 2.5851e-13,\n            2.2262e-13, 3.1834e-13, 1.2434e-13, 2.8417e-13, 2.5365e-13, 1.9331e-13,\n            3.1365e-13, 1.9700e-13, 1.8794e-13, 2.7547e-13, 4.0013e-13, 1.6742e-13,\n            3.3454e-13, 3.5631e-13, 4.5569e-13, 4.6426e-13, 1.9153e-13, 5.2627e-13,\n            1.8242e-13, 3.7446e-13, 2.3612e-13, 1.7432e-13, 2.5468e-13, 3.4605e-13,\n            2.5046e-13, 5.2969e-13, 2.5543e-13, 2.1472e-13, 4.0004e-13, 4.0541e-13,\n            9.8037e-14, 2.2986e-13, 5.5179e-13, 1.7728e-13, 2.2086e-13, 3.0461e-13,\n            2.7484e-13, 2.3257e-13, 3.3680e-13, 2.1580e-13, 2.9718e-13, 3.4865e-13,\n            2.9528e-13, 3.4944e-13, 1.5582e-13, 3.2648e-13, 3.5232e-13, 3.0551e-13,\n            2.4781e-13, 4.5227e-13, 3.6675e-13, 2.6708e-13, 2.7985e-13, 3.0663e-13,\n            1.8142e-13, 3.6179e-13, 3.5568e-13, 3.0208e-13, 1.9546e-13, 3.7454e-13,\n            2.4812e-13, 1.4507e-13, 1.5188e-13, 6.1803e-13, 2.6574e-13, 2.5336e-13,\n            2.3592e-13, 2.2697e-13, 2.0765e-13, 2.8682e-13, 1.9859e-13, 2.2186e-13,\n            2.0247e-13, 2.5632e-13, 2.1527e-13, 3.1377e-13, 2.3800e-13, 4.9558e-13,\n            3.4708e-13, 4.2491e-13, 3.1363e-13, 3.7624e-13, 2.8058e-13, 2.2261e-13,\n            1.9735e-13, 1.6806e-13, 2.3559e-13, 3.6681e-13, 2.1022e-13, 3.4464e-13,\n            1.9430e-13, 1.9987e-13, 1.7583e-13, 3.1287e-13, 1.7925e-13, 2.6856e-13,\n            1.5498e-13, 3.7273e-13, 2.5008e-13, 6.0417e-13, 3.9849e-13, 4.9961e-13,\n            2.0216e-13, 2.6239e-13, 2.5993e-13, 2.4498e-13, 1.2313e-13, 3.0660e-13,\n            3.5777e-13, 2.5721e-13, 1.9044e-13, 1.3804e-13, 1.9485e-13, 2.1415e-13,\n            3.2317e-13, 2.5763e-13, 2.2565e-13, 3.0304e-13, 2.9552e-13, 3.0010e-13,\n            3.5998e-13, 2.9776e-13, 3.0849e-13, 2.5511e-13, 3.1424e-13, 1.8031e-13,\n            1.6946e-13, 2.6054e-13, 2.8632e-13, 2.6274e-13, 1.8070e-13, 3.0976e-13,\n            1.9505e-13, 3.7884e-13, 2.4975e-13, 2.7366e-13, 2.3644e-13, 1.9434e-13,\n            1.8634e-13, 1.7590e-13, 2.2549e-13, 1.9127e-13, 2.3143e-13, 2.0545e-13,\n            2.6764e-13, 4.6663e-13, 2.2313e-13, 2.2021e-13, 1.8733e-13, 3.3494e-13,\n            3.5347e-13, 2.1148e-13, 2.4518e-13, 2.4919e-13, 4.1305e-13, 1.3596e-13,\n            1.9058e-13, 2.0902e-13, 2.0948e-13, 2.4778e-13, 4.0885e-13, 5.7591e-13,\n            2.5920e-13, 2.6027e-13, 2.2784e-13, 3.7591e-13, 2.6573e-13, 1.2661e-12,\n            2.6591e-13, 3.6432e-13, 2.7283e-13, 2.6173e-13, 2.3481e-13, 2.4721e-13,\n            2.1538e-13, 1.5919e-13, 3.2305e-13, 2.0146e-13, 2.2446e-13, 2.1277e-13,\n            2.5026e-13, 2.5537e-13, 2.4569e-13, 2.6688e-13, 2.7197e-13, 1.7889e-13,\n            3.1898e-13, 5.9231e-13, 2.7189e-13, 2.4345e-13, 4.1334e-13, 4.4738e-13,\n            2.5193e-13, 2.9282e-13, 2.9112e-13, 2.0069e-13, 1.7429e-13, 1.6266e-13,\n            3.1552e-13, 3.1237e-13, 2.8327e-13, 1.9953e-13, 3.3383e-13, 2.0125e-13,\n            1.5825e-13, 4.4485e-13, 2.6712e-13, 2.5635e-13, 1.9234e-13, 2.1419e-13,\n            1.9282e-13, 2.8495e-13, 3.2182e-13, 1.8554e-13])},\n   77: {'exp_avg': tensor([-1.2685e-07, -5.7073e-09, -1.1265e-07,  2.2389e-08,  1.4389e-08,\n            -6.6748e-08, -2.8730e-08,  6.6026e-08,  6.1763e-08,  4.4140e-08,\n            -4.7815e-08, -1.9399e-08,  1.2477e-07, -2.3001e-07,  5.5292e-08,\n            -1.3828e-07,  1.1910e-08, -8.5033e-08,  1.9277e-08,  6.8743e-08,\n             5.2241e-09, -4.4333e-09,  8.6574e-08,  6.4840e-08, -2.0339e-08,\n             2.5422e-09,  1.4936e-08, -6.6132e-08,  1.5857e-07,  1.0604e-07,\n             1.1672e-07, -1.1848e-07,  5.7139e-08,  1.9968e-07,  1.9606e-07,\n             1.3434e-07, -6.9754e-08, -1.5981e-07,  8.2965e-09, -9.2767e-10,\n            -2.3327e-08, -3.7243e-08,  7.3487e-08,  2.2135e-08, -7.6020e-08,\n            -7.9696e-08, -9.6212e-08, -1.6242e-07, -8.2547e-08,  4.4271e-09,\n            -7.7077e-08,  3.2068e-08, -2.6595e-08, -6.4833e-08, -3.7448e-08,\n            -6.0656e-08,  1.3714e-07, -3.0952e-08, -1.0860e-08, -1.7196e-07,\n            -1.5198e-08,  4.6479e-08,  6.2401e-08,  3.2747e-08, -1.9336e-08,\n             5.9464e-08, -1.1118e-07, -3.3564e-09, -1.0312e-07, -8.6445e-08,\n             1.1587e-07, -1.1994e-08, -2.0649e-08, -1.1680e-08, -1.2148e-08,\n            -3.8364e-08,  3.6686e-08,  8.9336e-09,  1.7402e-07, -4.6584e-08,\n             1.1822e-07, -2.3451e-08,  2.7514e-08,  6.1708e-09,  1.8236e-07,\n             6.5740e-08,  3.0018e-08,  5.4920e-08,  6.4554e-08,  3.0653e-08,\n             2.6626e-08, -2.8524e-07, -1.8533e-07, -1.1260e-07, -1.2960e-08,\n             7.4566e-08, -1.6672e-07, -6.4849e-11,  1.7225e-07,  7.0440e-08,\n             1.2027e-07, -9.1888e-08, -1.5328e-07, -2.1799e-08, -7.8386e-08,\n             1.9009e-07, -6.6037e-08,  6.4879e-08,  1.1645e-07,  3.1494e-08,\n            -4.5481e-08, -1.2397e-08,  8.6930e-09,  5.9214e-08, -1.2067e-07,\n             1.4109e-07,  5.3272e-08,  2.8453e-07,  6.5263e-08, -5.0751e-08,\n            -1.4594e-07,  6.9948e-08,  6.5114e-08,  2.0345e-07,  2.0624e-07,\n             9.1638e-08, -1.1867e-07, -5.8281e-09, -2.1323e-07,  3.3085e-08,\n             1.6117e-07, -6.4378e-08,  1.3868e-08,  3.0192e-08, -3.2630e-08,\n            -4.6159e-08,  1.7534e-07, -3.2881e-08, -2.8076e-08,  2.1072e-07,\n            -7.6449e-08,  9.1873e-08,  5.5022e-08,  2.8435e-07, -5.9592e-08,\n            -1.1676e-07, -2.2849e-09,  6.3344e-08, -3.3546e-08,  1.2095e-07,\n            -1.0439e-08, -1.2697e-07, -1.2643e-07, -3.7225e-08, -1.1591e-07,\n             2.8420e-08,  5.4191e-08, -8.8667e-08,  3.8509e-08,  7.4625e-08,\n             1.8975e-08, -1.5205e-07,  6.4982e-08, -2.3911e-07, -9.3330e-09,\n             1.5721e-08, -1.7329e-08,  1.1982e-07, -1.1192e-07,  7.9703e-09,\n             1.5095e-07, -9.9767e-08,  1.5829e-07, -3.0632e-08,  3.3820e-08,\n            -1.0453e-07,  1.0270e-07,  2.6111e-08, -3.3555e-08,  2.7964e-09,\n            -4.8045e-09, -1.1023e-07, -9.8713e-08,  5.5202e-08,  1.0867e-07,\n             2.2726e-08,  8.7522e-09,  1.0948e-07,  1.2877e-07, -1.4205e-07,\n             6.3168e-08, -1.1233e-07,  8.3133e-08, -2.9619e-08,  1.2055e-08,\n             5.7865e-08,  1.2616e-07, -7.5773e-08,  8.1405e-09, -4.7894e-08,\n             5.1518e-08, -7.4178e-09,  5.0861e-08, -2.4868e-07,  5.2265e-08,\n            -9.4578e-08,  8.4014e-09,  6.1039e-08,  1.6449e-08, -1.1015e-07,\n            -1.1390e-07, -1.0250e-07,  6.3595e-08,  2.3035e-08,  1.4744e-08,\n            -1.5985e-08,  3.3995e-09, -4.1205e-08,  1.3004e-07,  1.0201e-07,\n            -8.6359e-08, -1.5277e-08, -6.6240e-08,  3.8963e-08, -5.1251e-08,\n            -1.6194e-09, -1.7868e-07, -5.4401e-10,  3.1126e-08,  3.3392e-07,\n            -1.3918e-08, -1.4012e-07, -1.7654e-07,  5.5161e-08, -2.7606e-08,\n            -7.6660e-08, -2.8706e-08, -4.4345e-08, -3.9751e-08, -4.4076e-08,\n            -1.3649e-07,  1.1519e-07,  2.8213e-08, -1.3389e-08,  1.6021e-08,\n            -1.3630e-07, -2.0504e-08, -1.5528e-07, -9.6232e-08, -6.4448e-08,\n             1.6857e-07,  4.1834e-08,  7.5435e-08, -1.9186e-08,  3.3394e-08,\n             1.3819e-07]),\n    'exp_avg_sq': tensor([1.3157e-13, 2.1313e-13, 1.3908e-13, 1.1405e-13, 1.7938e-13, 1.8222e-13,\n            1.3891e-13, 1.6235e-13, 8.9298e-14, 1.1498e-13, 1.4355e-13, 1.7402e-13,\n            1.3849e-13, 1.9257e-13, 1.5374e-13, 1.2423e-13, 1.4685e-13, 2.0728e-13,\n            1.5330e-13, 1.3901e-13, 1.2329e-13, 1.3964e-13, 1.1104e-13, 1.1855e-13,\n            1.4501e-13, 1.5037e-13, 1.1521e-13, 1.6256e-13, 1.4173e-13, 1.1400e-13,\n            2.4341e-13, 1.3825e-13, 1.2695e-13, 2.6677e-13, 1.5399e-13, 1.2770e-13,\n            1.2057e-13, 1.8271e-13, 1.2329e-13, 1.1432e-13, 1.4856e-13, 1.4834e-13,\n            1.1673e-13, 2.0635e-13, 9.5240e-14, 1.6373e-13, 1.3243e-13, 1.0115e-13,\n            1.6470e-13, 1.2460e-13, 1.0385e-13, 1.2437e-13, 2.4962e-13, 8.9241e-14,\n            1.4153e-13, 1.7883e-13, 3.5636e-13, 2.5635e-13, 1.3227e-13, 2.4116e-13,\n            1.2052e-13, 1.6272e-13, 1.3103e-13, 1.1676e-13, 1.3134e-13, 1.4877e-13,\n            1.5335e-13, 2.5597e-13, 1.3915e-13, 1.3113e-13, 1.9041e-13, 1.8136e-13,\n            7.3178e-14, 8.9440e-14, 1.9985e-13, 1.1612e-13, 1.4027e-13, 1.3956e-13,\n            1.1562e-13, 1.1110e-13, 1.8078e-13, 1.1262e-13, 1.4909e-13, 1.5472e-13,\n            1.7910e-13, 1.7801e-13, 7.7392e-14, 1.6748e-13, 1.6613e-13, 1.6358e-13,\n            1.3210e-13, 2.2286e-13, 1.6345e-13, 1.3692e-13, 1.3108e-13, 1.5381e-13,\n            1.1440e-13, 1.8374e-13, 1.7436e-13, 1.5281e-13, 1.1313e-13, 1.3140e-13,\n            1.4660e-13, 1.2315e-13, 1.1285e-13, 2.5424e-13, 1.3998e-13, 1.3623e-13,\n            1.5214e-13, 1.4775e-13, 8.8808e-14, 1.4433e-13, 1.2009e-13, 1.7331e-13,\n            1.1174e-13, 1.4405e-13, 1.2294e-13, 1.8698e-13, 1.4558e-13, 2.7963e-13,\n            1.7824e-13, 2.1027e-13, 1.5943e-13, 1.5863e-13, 1.5898e-13, 1.3217e-13,\n            1.2365e-13, 1.1860e-13, 1.3686e-13, 1.7137e-13, 1.2231e-13, 1.5680e-13,\n            9.2334e-14, 1.2585e-13, 9.0363e-14, 1.2359e-13, 1.0254e-13, 1.3235e-13,\n            7.8002e-14, 1.7923e-13, 1.2163e-13, 4.1236e-13, 1.7360e-13, 3.2012e-13,\n            1.1228e-13, 1.4903e-13, 1.2648e-13, 1.1399e-13, 8.2490e-14, 1.6405e-13,\n            1.6560e-13, 1.3849e-13, 1.2874e-13, 8.0163e-14, 8.9878e-14, 1.5052e-13,\n            1.8406e-13, 1.1636e-13, 1.0603e-13, 1.4357e-13, 1.6159e-13, 1.7149e-13,\n            1.8235e-13, 1.5827e-13, 1.5112e-13, 1.3420e-13, 1.6754e-13, 1.0457e-13,\n            9.0602e-14, 1.3938e-13, 1.5161e-13, 1.6214e-13, 1.1656e-13, 1.6865e-13,\n            1.1405e-13, 1.7976e-13, 1.2787e-13, 1.7236e-13, 1.2994e-13, 9.2143e-14,\n            1.0794e-13, 8.6995e-14, 1.2410e-13, 1.1482e-13, 1.3337e-13, 1.1013e-13,\n            1.0375e-13, 1.9305e-13, 1.4583e-13, 1.1664e-13, 9.8927e-14, 1.5434e-13,\n            2.1342e-13, 1.0519e-13, 1.1970e-13, 1.2623e-13, 2.5085e-13, 9.5183e-14,\n            8.9826e-14, 9.0467e-14, 1.0678e-13, 1.1242e-13, 1.8918e-13, 2.2897e-13,\n            1.2283e-13, 1.3251e-13, 1.3662e-13, 1.8826e-13, 1.4147e-13, 1.2886e-12,\n            1.1389e-13, 2.0838e-13, 1.2624e-13, 1.3612e-13, 1.5117e-13, 1.3055e-13,\n            1.0547e-13, 1.2738e-13, 1.9188e-13, 1.0112e-13, 1.2231e-13, 1.1278e-13,\n            1.3790e-13, 1.3509e-13, 1.6053e-13, 1.3525e-13, 1.4369e-13, 1.0082e-13,\n            1.9276e-13, 2.8228e-13, 1.4678e-13, 1.6954e-13, 2.1927e-13, 2.2587e-13,\n            1.4253e-13, 1.4347e-13, 1.4460e-13, 1.0890e-13, 1.0232e-13, 8.8587e-14,\n            1.5328e-13, 1.4900e-13, 1.3658e-13, 1.2102e-13, 1.5130e-13, 1.2617e-13,\n            8.7548e-14, 1.9303e-13, 1.3077e-13, 1.4248e-13, 1.3093e-13, 1.1099e-13,\n            1.2783e-13, 1.5143e-13, 1.4006e-13, 1.0392e-13])},\n   78: {'exp_avg': tensor([-2.4953e-07,  4.6232e-08, -2.7598e-07,  ..., -2.3116e-07,\n             2.2678e-07,  7.0802e-08]),\n    'exp_avg_sq': tensor([9.3781e-13, 8.8672e-13, 6.6326e-13,  ..., 9.3949e-13, 9.5302e-13,\n            1.0469e-12])},\n   79: {'exp_avg': tensor([ 1.6389e-08, -9.4379e-08,  1.1361e-07,  ...,  2.2091e-08,\n            -1.6020e-07, -1.2149e-07]),\n    'exp_avg_sq': tensor([6.9032e-14, 1.2365e-13, 2.0077e-13,  ..., 1.0553e-13, 2.3889e-13,\n            8.5379e-14])},\n   80: {'exp_avg': tensor([-4.1346e-08,  1.7989e-07, -2.8108e-08,  1.0238e-07, -1.4315e-07,\n             6.8162e-08, -2.0233e-08, -1.2896e-07,  1.4344e-07, -1.5201e-07,\n            -1.4246e-07, -2.1034e-07,  3.7310e-07, -2.7858e-07,  2.3064e-07,\n             3.2092e-07,  4.1443e-08,  8.3698e-08, -1.4348e-07, -4.2252e-09,\n             1.5228e-07,  1.0561e-07, -1.0402e-08, -1.5151e-07,  1.3349e-09,\n            -1.9941e-07, -2.1922e-07, -6.9751e-08,  3.7362e-08, -2.5597e-08,\n             6.6489e-08, -2.6938e-07, -1.2222e-07,  7.2982e-08,  5.9528e-08,\n             1.1278e-07,  1.4702e-07,  5.1119e-08,  1.2890e-07, -8.6788e-08,\n            -3.9339e-08,  1.8968e-07,  1.6633e-07,  1.7693e-07,  2.6181e-07,\n             6.6040e-09,  5.6036e-08,  3.2711e-07,  1.8289e-07,  5.2368e-08,\n             1.5302e-07, -1.7630e-07, -3.8589e-07, -4.9855e-08,  5.0587e-08,\n             7.0366e-08,  6.9465e-08, -6.0963e-08, -7.3162e-08,  9.8111e-08,\n            -2.8194e-07,  3.3823e-08, -5.7824e-09,  1.9010e-07, -2.3791e-07,\n             1.9713e-07,  4.6130e-08, -1.7996e-07, -1.7791e-07, -1.6946e-07,\n            -1.6996e-08, -1.1099e-07, -1.6756e-07, -1.0584e-07,  4.7017e-08,\n            -1.4687e-07,  3.7604e-08, -6.4665e-08, -5.8312e-08,  1.4665e-07,\n             1.2093e-07, -4.0113e-08, -3.4160e-08,  1.5245e-07,  3.6109e-08,\n             6.4377e-09,  3.8053e-07,  9.2390e-08, -2.1217e-07,  1.9727e-08,\n            -1.8229e-07, -6.9887e-08,  3.6458e-08, -2.5012e-08, -1.0996e-07,\n             1.9058e-07,  9.3666e-08,  4.1546e-08, -3.6267e-07,  2.0932e-08,\n            -6.9455e-08,  7.7780e-08,  2.0586e-07, -2.2945e-08, -2.4813e-08,\n            -1.3255e-08,  1.4761e-07, -1.3964e-07,  6.2310e-08,  1.2250e-07,\n             9.8782e-08,  1.0548e-07,  1.5294e-07,  4.2165e-08, -5.1702e-08,\n             1.1922e-07, -6.7320e-08,  7.9988e-08, -1.9088e-07,  3.6479e-09,\n             3.9331e-08,  5.7811e-09,  5.4816e-08, -4.3856e-08,  6.3626e-08,\n            -1.7580e-08,  3.1830e-08, -1.7311e-08,  2.4985e-07, -1.2458e-07,\n            -2.0763e-07,  1.5174e-08, -2.4671e-07,  3.1759e-07,  1.0591e-07,\n             9.3099e-09, -1.8244e-08,  1.1017e-07, -1.8119e-07, -1.9079e-07,\n             7.3865e-09, -7.2276e-09,  1.3728e-08, -1.3928e-07,  7.3225e-08,\n            -1.4425e-09,  1.0408e-07,  1.5243e-07, -5.1357e-08,  1.4311e-07,\n            -1.8137e-07,  7.0357e-08, -4.1590e-07, -1.4686e-09, -1.0214e-07,\n            -1.3065e-07, -2.2596e-08,  1.5557e-07, -1.8421e-08,  5.3825e-08,\n            -1.3213e-07, -4.9040e-08, -1.7780e-07, -1.6540e-07,  3.2792e-08,\n            -1.2474e-07, -1.4930e-07, -4.9568e-08, -4.9832e-08,  5.6536e-08,\n             4.3867e-08,  1.0207e-07,  1.1826e-07,  2.1889e-07, -1.1878e-07,\n            -1.8828e-07, -1.3232e-07,  8.6119e-08,  2.3906e-07, -2.6793e-08,\n            -3.7415e-07,  5.0540e-08,  2.4786e-07, -1.2684e-07, -8.2120e-08,\n             1.5109e-07,  4.3484e-08, -5.9078e-08,  2.1671e-07,  8.0034e-09,\n             4.6133e-08, -8.5427e-08,  1.9892e-07, -1.6303e-07,  4.6136e-07,\n             1.4326e-07, -1.8236e-07,  1.1791e-07, -3.5977e-08, -9.7221e-08,\n            -9.0951e-08,  2.5933e-07, -4.2776e-08, -1.0776e-07, -2.0043e-07,\n             1.9985e-07, -8.7983e-08, -1.2733e-07, -3.7486e-08,  2.4024e-07,\n             8.2920e-08,  1.1253e-08,  1.4971e-07,  3.4158e-08,  7.5049e-09,\n            -6.6183e-08, -1.1082e-07, -5.1810e-08,  1.8425e-07,  1.6174e-07,\n            -2.5588e-07,  1.2031e-08, -9.6495e-08,  1.7456e-08,  1.1615e-07,\n             1.5024e-07, -2.4112e-08, -6.0044e-08,  3.3532e-08, -1.2843e-08,\n            -7.3314e-08, -2.7370e-08,  1.5599e-07,  2.2228e-08,  6.7633e-08,\n            -6.0592e-08, -2.1396e-08,  7.2349e-08,  6.6536e-08,  1.0287e-07,\n            -1.0003e-07, -1.3047e-07, -5.7797e-08, -2.5177e-07, -1.4629e-07,\n             8.0573e-08, -3.0790e-07,  6.6214e-08, -2.7450e-07, -1.7690e-07,\n            -2.2264e-08, -7.1604e-08,  2.9828e-07, -9.3068e-08,  4.0829e-08,\n            -8.1656e-08]),\n    'exp_avg_sq': tensor([3.6697e-13, 2.8926e-13, 3.1376e-13, 6.3187e-13, 6.3431e-13, 2.2187e-13,\n            2.5332e-13, 3.2614e-13, 2.0513e-13, 3.8826e-13, 3.0072e-13, 2.5055e-13,\n            1.4269e-12, 3.2951e-13, 4.0748e-13, 4.1201e-13, 3.0295e-13, 3.6347e-13,\n            1.2687e-13, 1.7639e-13, 5.6607e-13, 3.7468e-13, 5.1454e-13, 2.9844e-13,\n            3.8414e-13, 3.0080e-13, 4.3485e-13, 3.9059e-13, 2.1811e-13, 3.2133e-13,\n            2.1752e-13, 3.7323e-13, 3.1498e-13, 2.6859e-13, 3.3645e-13, 4.6814e-13,\n            4.1170e-13, 2.6801e-13, 4.5455e-13, 4.3949e-13, 2.7729e-13, 3.4079e-13,\n            2.1666e-13, 2.3960e-13, 3.0023e-13, 2.6973e-13, 1.4925e-13, 3.3696e-13,\n            3.5860e-13, 3.8216e-13, 3.0770e-13, 4.8869e-13, 5.4111e-13, 4.9110e-13,\n            4.4312e-13, 2.4265e-13, 2.0310e-13, 3.5163e-13, 3.7886e-13, 3.7973e-13,\n            2.6720e-13, 5.2702e-13, 2.3734e-13, 3.9362e-13, 4.4232e-13, 4.3780e-13,\n            4.4298e-13, 3.6265e-13, 5.0086e-13, 3.2125e-13, 3.7332e-13, 2.9305e-13,\n            2.3277e-13, 2.8935e-13, 4.4107e-13, 2.8439e-13, 3.8214e-13, 4.3406e-13,\n            9.9225e-13, 6.5007e-13, 5.8326e-13, 3.9564e-13, 2.5435e-13, 3.2019e-13,\n            3.3153e-13, 2.6309e-13, 3.6539e-13, 4.4021e-13, 2.0499e-13, 3.8596e-13,\n            3.5045e-13, 2.9549e-13, 2.9720e-13, 3.7123e-13, 3.5563e-13, 3.8276e-13,\n            1.9885e-13, 3.3272e-13, 2.2421e-13, 5.2228e-13, 2.7831e-13, 3.7827e-13,\n            5.3601e-13, 4.8899e-13, 1.7641e-13, 4.2083e-13, 2.4734e-13, 3.2430e-13,\n            2.7500e-13, 4.4783e-13, 2.5064e-13, 6.0074e-13, 2.8428e-13, 3.7140e-13,\n            3.5153e-13, 5.1174e-13, 2.6268e-13, 2.3870e-13, 3.3381e-13, 2.9224e-13,\n            4.0026e-13, 3.2165e-13, 3.5243e-13, 3.3078e-13, 3.4545e-13, 2.2458e-13,\n            4.2194e-13, 3.7611e-13, 4.6850e-13, 4.4978e-13, 3.2813e-13, 2.5521e-13,\n            2.5151e-13, 4.1543e-13, 3.6220e-13, 3.3049e-13, 3.8040e-13, 3.6392e-13,\n            7.3806e-13, 3.7062e-13, 4.2986e-13, 2.5438e-13, 3.1883e-13, 2.1620e-13,\n            4.0256e-13, 4.2593e-13, 3.6127e-13, 2.5493e-13, 2.0808e-13, 4.0003e-13,\n            3.1295e-13, 4.3186e-13, 3.9094e-13, 2.9391e-13, 4.4168e-13, 1.8438e-13,\n            3.2100e-13, 3.5216e-13, 4.8475e-13, 4.3320e-13, 3.5287e-13, 3.9721e-13,\n            4.1858e-13, 2.7918e-13, 3.4521e-13, 4.7720e-13, 3.2775e-13, 2.4287e-13,\n            2.3469e-13, 3.3918e-13, 2.7966e-13, 1.9038e-13, 4.1395e-13, 7.1609e-13,\n            4.8082e-13, 2.9683e-13, 2.4339e-13, 3.3899e-13, 3.8471e-13, 2.2658e-13,\n            3.9294e-13, 4.1966e-13, 6.4170e-13, 4.2376e-13, 2.6498e-13, 1.0264e-12,\n            4.2345e-13, 2.7673e-13, 5.5608e-13, 3.3636e-13, 2.5455e-13, 2.5403e-13,\n            3.5412e-13, 2.4872e-13, 6.0800e-13, 4.5585e-13, 5.4844e-13, 3.0219e-13,\n            2.2300e-13, 2.7231e-13, 2.2349e-13, 3.3375e-13, 4.2117e-13, 2.8207e-13,\n            4.8208e-13, 4.7554e-13, 3.4111e-13, 4.8106e-13, 3.4947e-13, 3.9969e-13,\n            3.2517e-13, 2.4494e-13, 6.0088e-13, 7.3560e-13, 3.9131e-13, 3.8756e-13,\n            2.3316e-13, 3.9424e-13, 2.5672e-13, 3.8405e-13, 3.9963e-13, 2.5112e-13,\n            6.1769e-13, 3.1637e-13, 5.4682e-13, 2.8968e-13, 2.8477e-13, 3.6141e-13,\n            6.4256e-13, 2.9541e-13, 2.1508e-13, 3.1265e-13, 5.3269e-13, 2.2514e-13,\n            3.2603e-13, 2.0268e-13, 1.2575e-13, 6.2146e-13, 4.9159e-13, 5.9762e-13,\n            4.2898e-13, 5.0355e-13, 2.9402e-13, 6.0812e-13, 5.4451e-13, 2.6820e-13,\n            3.2918e-13, 2.9935e-13, 3.9284e-13, 4.5216e-13, 3.0087e-13, 3.4230e-13,\n            4.3520e-13, 2.8360e-13, 3.3370e-13, 3.8902e-13])},\n   81: {'exp_avg': tensor([-9.3551e-08,  1.1985e-07,  2.9095e-08,  6.1738e-08, -5.8067e-08,\n             3.1863e-08,  6.1539e-08,  2.2286e-08, -7.9129e-09, -1.0080e-07,\n            -1.1882e-07, -1.1475e-07,  6.3340e-08, -1.7216e-07,  1.7431e-07,\n             2.0335e-07,  2.1756e-08, -1.9417e-08, -1.1572e-07,  2.6932e-08,\n             1.7203e-07,  8.6903e-08, -1.3349e-08, -8.8404e-08,  3.0779e-09,\n            -1.4218e-07, -9.3205e-08, -5.5881e-08,  6.8752e-08,  3.2477e-09,\n             9.6483e-08, -1.6935e-07, -5.9697e-08, -5.3175e-08, -1.1365e-08,\n             1.5695e-08,  1.0017e-07,  1.4194e-07,  1.1710e-07, -1.1605e-07,\n             2.3332e-08,  1.0275e-07,  4.7624e-08,  1.1007e-07,  2.2151e-07,\n             1.1129e-08,  7.5537e-08,  2.1637e-07,  1.5070e-07,  9.4794e-08,\n             1.3113e-07, -2.4521e-08, -2.2795e-07, -4.1291e-08, -1.7023e-08,\n             4.6973e-08,  3.2747e-08, -8.7927e-08,  7.3361e-09,  9.0610e-08,\n            -2.0268e-07,  9.1702e-08,  4.6784e-08,  1.9381e-07, -8.8106e-08,\n             1.2176e-07,  1.5473e-07, -7.8195e-08, -1.8769e-07, -1.0821e-07,\n            -3.1476e-08, -8.0842e-08, -5.4704e-08, -4.2839e-08,  7.0216e-08,\n            -1.3876e-07, -1.1623e-09, -7.8731e-08, -1.5458e-08,  8.8626e-08,\n            -5.6597e-08, -2.7960e-08, -2.9799e-08,  1.4577e-07, -3.7582e-08,\n            -5.1874e-08,  2.4819e-07,  1.6766e-08, -1.0261e-07, -7.9821e-08,\n            -1.6480e-07, -5.4818e-08,  3.3956e-08, -6.9904e-08, -4.5333e-08,\n             9.6836e-08, -3.5379e-08,  3.4369e-08, -2.0135e-07,  4.4152e-08,\n             5.5725e-08,  6.3107e-08,  1.5434e-07, -2.9831e-08,  2.0477e-08,\n            -7.5515e-08, -5.4773e-08, -1.5550e-07,  3.1820e-08,  1.7319e-07,\n             4.8226e-08, -8.1963e-09,  6.5533e-08,  6.2871e-08, -1.1479e-07,\n             4.4642e-08, -3.5989e-08,  7.6986e-08, -1.0078e-07,  4.0147e-08,\n            -1.0830e-07, -3.0504e-09, -2.9398e-08, -4.1786e-08,  9.4268e-08,\n            -2.2657e-08,  8.0160e-08,  3.7237e-08,  1.7727e-07,  2.0132e-08,\n            -1.8541e-07, -9.5568e-08, -2.1483e-07,  1.6200e-07,  7.4699e-08,\n             4.7740e-08, -1.0631e-07,  8.4649e-08, -9.4917e-08, -1.2658e-07,\n            -1.5261e-08, -8.2228e-08,  1.1511e-08, -5.9478e-08,  1.1320e-07,\n            -8.5353e-08,  7.3748e-08,  7.3982e-08, -5.2554e-08,  2.0889e-07,\n            -4.0282e-08,  5.5615e-08, -2.9091e-07,  5.5385e-08, -1.1588e-07,\n            -1.1042e-07, -6.1044e-08,  1.2286e-07, -3.0129e-08, -7.1414e-08,\n            -5.3914e-08, -2.8851e-08, -2.5683e-08, -1.1374e-07, -4.4587e-09,\n            -4.2634e-08, -2.1050e-07, -4.5977e-08, -7.7743e-08, -1.6159e-08,\n             8.3108e-09,  1.0216e-07,  1.7631e-07,  1.4375e-07, -1.1366e-07,\n            -8.6683e-08, -1.0545e-07, -2.7835e-08,  4.4103e-08, -1.7525e-08,\n            -1.8818e-07, -4.6491e-08,  8.3978e-08, -3.5285e-08, -3.0034e-08,\n             7.1951e-08,  1.1526e-07,  2.7522e-09,  1.4755e-07, -8.7006e-08,\n             1.2813e-07, -1.2400e-07,  1.0945e-07, -1.1053e-07,  2.7610e-07,\n             1.4053e-07, -1.6296e-07,  6.2746e-08, -1.1445e-07,  1.4952e-08,\n            -1.2725e-07,  1.5151e-07,  1.7084e-07, -4.4755e-08, -1.0517e-07,\n             1.0449e-07, -6.3531e-08,  1.7182e-08,  5.9794e-09,  1.7578e-07,\n             1.9799e-08, -9.7930e-09,  1.5224e-07,  2.6289e-08,  3.7069e-08,\n            -5.1402e-08, -1.4939e-07, -3.6385e-08,  1.6521e-07,  1.8718e-07,\n            -1.5931e-07,  8.0297e-08, -4.6854e-08, -3.5010e-09, -7.4412e-08,\n             1.2112e-07, -2.2608e-09, -1.1399e-07, -1.3373e-08,  8.0804e-08,\n            -4.7917e-08, -2.2359e-08,  5.5074e-08,  2.4842e-08, -1.9305e-09,\n            -1.0825e-08, -4.9704e-08,  4.5798e-09,  1.0597e-07, -7.1423e-08,\n             3.7901e-08, -6.5749e-08, -3.5314e-08, -1.6656e-07, -8.2810e-08,\n             9.6918e-08, -2.2708e-07,  1.1421e-07, -1.5174e-07, -6.7902e-08,\n             5.4655e-08, -5.7989e-08,  2.1195e-07, -2.4563e-08,  6.1666e-08,\n            -1.6715e-07]),\n    'exp_avg_sq': tensor([2.0606e-13, 1.9106e-13, 1.6494e-13, 3.1005e-13, 3.0008e-13, 1.5367e-13,\n            1.9043e-13, 1.8844e-13, 1.4665e-13, 2.2739e-13, 1.9997e-13, 1.6593e-13,\n            5.2372e-13, 1.8844e-13, 2.6452e-13, 2.1271e-13, 1.6247e-13, 2.3558e-13,\n            1.2218e-13, 1.4034e-13, 2.5809e-13, 2.6798e-13, 2.3909e-13, 1.7687e-13,\n            2.0009e-13, 1.8805e-13, 2.2044e-13, 2.1636e-13, 1.6329e-13, 2.1781e-13,\n            1.5513e-13, 2.2614e-13, 2.0446e-13, 1.8857e-13, 1.8614e-13, 2.2887e-13,\n            2.0846e-13, 1.7858e-13, 1.9600e-13, 3.4545e-13, 1.9078e-13, 2.3792e-13,\n            2.0227e-13, 1.6975e-13, 1.8849e-13, 1.8451e-13, 1.1927e-13, 2.0915e-13,\n            2.1153e-13, 1.9083e-13, 1.5086e-13, 2.3012e-13, 2.2706e-13, 2.3598e-13,\n            2.6250e-13, 1.5665e-13, 1.6416e-13, 1.9295e-13, 1.9753e-13, 2.1355e-13,\n            1.8270e-13, 2.5812e-13, 1.6264e-13, 2.2045e-13, 2.2557e-13, 2.4978e-13,\n            2.1637e-13, 1.8046e-13, 2.7096e-13, 1.8518e-13, 2.6931e-13, 1.7401e-13,\n            1.7694e-13, 1.9271e-13, 2.0798e-13, 2.0452e-13, 2.2065e-13, 2.5001e-13,\n            3.2199e-13, 2.6638e-13, 3.2036e-13, 2.4342e-13, 1.6186e-13, 2.0360e-13,\n            1.9220e-13, 1.6706e-13, 1.9710e-13, 2.3017e-13, 1.5711e-13, 2.1787e-13,\n            2.0187e-13, 1.7618e-13, 1.8207e-13, 2.2053e-13, 2.2345e-13, 2.0491e-13,\n            1.9124e-13, 2.2758e-13, 1.3145e-13, 2.9675e-13, 1.6933e-13, 2.1017e-13,\n            3.1839e-13, 2.7283e-13, 1.3032e-13, 2.0704e-13, 1.5313e-13, 1.8274e-13,\n            1.9057e-13, 2.5517e-13, 1.6086e-13, 2.4504e-13, 1.7279e-13, 2.1278e-13,\n            1.7707e-13, 2.5741e-13, 1.5955e-13, 1.6457e-13, 2.3460e-13, 1.9927e-13,\n            1.8565e-13, 2.1663e-13, 1.9639e-13, 1.8779e-13, 2.1221e-13, 1.5961e-13,\n            2.4245e-13, 2.1176e-13, 2.1155e-13, 2.7378e-13, 1.8610e-13, 1.6373e-13,\n            1.5172e-13, 2.0868e-13, 1.7655e-13, 1.8987e-13, 1.9810e-13, 1.9517e-13,\n            3.0341e-13, 1.9807e-13, 2.2577e-13, 1.5083e-13, 1.8913e-13, 1.3582e-13,\n            2.9668e-13, 2.2255e-13, 1.8947e-13, 1.7808e-13, 1.4217e-13, 2.3117e-13,\n            1.9149e-13, 2.6700e-13, 2.2778e-13, 1.8771e-13, 2.1559e-13, 1.5271e-13,\n            2.0285e-13, 1.8125e-13, 2.1269e-13, 2.0302e-13, 2.0916e-13, 2.1167e-13,\n            2.3660e-13, 1.7611e-13, 1.8723e-13, 2.3502e-13, 2.2638e-13, 1.7697e-13,\n            1.8057e-13, 1.9507e-13, 1.8181e-13, 1.5352e-13, 2.1825e-13, 4.0780e-13,\n            2.6672e-13, 1.8683e-13, 1.7040e-13, 1.9173e-13, 1.8251e-13, 1.6314e-13,\n            1.8963e-13, 2.3660e-13, 2.6772e-13, 2.2356e-13, 1.9235e-13, 3.8648e-13,\n            3.3911e-13, 2.1225e-13, 2.7131e-13, 1.9375e-13, 1.5401e-13, 1.5006e-13,\n            2.1391e-13, 1.6201e-13, 3.2731e-13, 2.6389e-13, 2.6077e-13, 2.0349e-13,\n            1.5805e-13, 1.6064e-13, 1.5929e-13, 2.4610e-13, 2.5217e-13, 1.5865e-13,\n            2.5667e-13, 2.5885e-13, 1.7003e-13, 2.3252e-13, 2.0547e-13, 2.1719e-13,\n            2.2602e-13, 1.8280e-13, 2.8028e-13, 2.6299e-13, 2.2413e-13, 2.0575e-13,\n            2.2104e-13, 2.3088e-13, 1.7980e-13, 2.0514e-13, 2.1493e-13, 1.7741e-13,\n            2.5062e-13, 1.9007e-13, 2.7589e-13, 1.7439e-13, 2.0491e-13, 2.0630e-13,\n            3.3510e-13, 2.0054e-13, 1.4893e-13, 1.7148e-13, 2.5180e-13, 1.5118e-13,\n            1.8410e-13, 1.2785e-13, 1.0444e-13, 3.2972e-13, 2.5374e-13, 3.2635e-13,\n            2.2210e-13, 2.9013e-13, 1.7804e-13, 3.3538e-13, 2.4409e-13, 1.8534e-13,\n            1.9766e-13, 1.8817e-13, 1.7863e-13, 2.2216e-13, 1.8466e-13, 1.6973e-13,\n            2.2146e-13, 1.6214e-13, 1.8747e-13, 1.9079e-13])},\n   82: {'exp_avg': tensor([ 6.9853e-08, -9.5138e-08, -2.4020e-07, -1.3317e-07, -2.3207e-07,\n             2.2139e-07,  8.0720e-08,  7.0871e-08,  4.6959e-08,  6.3430e-08,\n             3.4526e-07,  7.2829e-08, -1.4888e-07, -6.7878e-08,  1.9266e-07,\n            -4.5183e-08, -1.4005e-07, -7.2894e-08, -9.1988e-08, -1.0635e-07,\n            -2.5763e-09, -2.2320e-08,  2.1053e-08, -2.6426e-08, -3.1185e-08,\n            -2.8107e-08,  7.9829e-08,  1.2636e-07,  2.6003e-08, -4.9004e-08,\n            -1.0776e-07,  1.4392e-07,  1.6089e-07, -2.4000e-08, -4.2994e-08,\n             9.0694e-08,  9.9481e-08,  1.3546e-07,  9.3552e-08,  1.8135e-08,\n             9.2126e-08, -2.5363e-07, -1.1014e-07, -4.3605e-08, -9.9938e-08,\n            -2.4777e-07, -7.0544e-08, -1.2302e-07, -9.3056e-08, -2.2767e-07,\n             3.3298e-07,  2.4822e-08, -3.4764e-09, -4.2917e-08, -4.9427e-08,\n            -2.0102e-08, -3.8986e-08, -8.7708e-08,  1.9817e-08,  3.8370e-08,\n             7.7273e-08, -1.0369e-07, -1.9354e-08, -2.7961e-08,  2.5817e-08,\n            -1.0710e-07, -4.1281e-08,  2.6679e-09, -1.0213e-07, -3.7032e-09,\n             2.1100e-08,  3.9343e-08, -2.2442e-07, -2.6766e-08, -1.6668e-07,\n             1.2817e-08,  2.3084e-08,  1.0115e-08,  3.1617e-08, -2.1692e-08,\n             2.3612e-08, -1.6901e-08,  2.0890e-07, -1.4116e-07,  5.0837e-08,\n             1.2816e-07, -2.2909e-07, -1.1896e-07, -8.6054e-08, -3.4502e-08,\n            -3.2378e-08, -1.8191e-08, -6.0481e-08,  1.9703e-08,  1.2809e-07,\n            -7.3742e-08, -1.0787e-07,  1.4986e-07,  2.4222e-08, -4.4130e-08,\n            -2.1052e-08, -2.7033e-07,  5.3269e-08,  1.2777e-07,  1.1565e-07,\n            -2.0219e-07, -4.0252e-09,  1.3774e-07,  1.2208e-07,  7.1864e-08,\n             3.2592e-07,  3.3347e-07, -1.4355e-08,  8.9905e-08, -6.4874e-08,\n            -5.2407e-08, -1.5649e-08,  1.5435e-07,  1.3692e-07, -2.1560e-07,\n             1.3597e-07, -3.6967e-07, -1.4848e-07, -1.3040e-07,  2.1765e-07,\n            -2.1908e-08, -1.4968e-07, -1.1395e-07,  1.2424e-07, -1.5581e-07,\n            -8.2031e-08, -6.5347e-08,  5.0811e-08,  2.1026e-08, -1.7951e-08,\n             4.0874e-07,  2.2162e-07,  1.6459e-07,  2.2327e-07,  9.2035e-08,\n             9.0363e-08, -1.9895e-07,  1.8968e-07,  1.1769e-07, -4.2624e-08,\n             9.4779e-08,  1.2264e-07, -2.9520e-08,  9.8873e-08, -8.4327e-08,\n             2.5075e-08, -6.1529e-08, -3.3092e-07, -8.4572e-08,  2.6331e-08,\n            -3.4731e-08,  5.9470e-08,  5.7101e-08, -2.5177e-07,  3.7065e-09,\n             6.1805e-08, -4.5161e-08,  6.3243e-08, -1.6416e-07,  1.7173e-07,\n            -1.7093e-07, -1.5143e-08, -3.0398e-08,  2.1862e-08,  1.9070e-07,\n             3.5697e-08, -1.5818e-07, -3.9589e-08,  5.6865e-09, -9.2720e-08,\n             8.0366e-08,  3.9889e-08, -8.5193e-08, -1.5406e-07,  1.5485e-07,\n             4.7946e-08, -6.9731e-08,  4.7341e-08,  1.5576e-07, -4.1580e-08,\n             1.6337e-08,  3.2313e-07, -1.1367e-07, -4.7715e-09, -4.2966e-08,\n             2.4329e-07,  3.8348e-09, -3.1185e-08,  4.3776e-08,  1.6549e-07,\n             2.7087e-07, -1.1021e-07, -1.7361e-07, -1.1561e-07, -7.6382e-08,\n            -2.0240e-07,  6.9734e-08, -9.6969e-08, -1.8577e-07,  1.3007e-07,\n            -6.8346e-08, -5.2930e-08,  2.8378e-07,  4.2274e-08, -8.6869e-08,\n            -5.1633e-08, -6.1276e-09, -1.1489e-08, -4.5415e-08, -4.0670e-08,\n            -9.3863e-08, -1.5184e-07,  1.2359e-07,  5.7197e-08,  1.5788e-07,\n             2.6729e-07,  1.2315e-07,  4.6684e-08,  2.5635e-08,  1.9092e-07,\n            -3.6405e-07,  7.4623e-08, -4.5945e-08, -3.1631e-07, -9.8992e-08,\n             1.0251e-07,  1.0820e-07, -1.3818e-07,  1.5628e-07,  2.1025e-07,\n             2.0693e-07,  1.6635e-07,  2.7780e-08,  2.2124e-07, -2.8377e-07,\n            -7.5745e-08,  5.4825e-08, -7.9001e-08, -6.8644e-08, -3.5779e-08,\n            -4.7952e-08,  2.3623e-07,  7.4818e-09, -9.6158e-09, -7.5033e-08,\n            -1.1720e-07,  1.1883e-07, -8.9266e-08, -2.1571e-07,  7.6811e-09,\n            -5.4441e-09]),\n    'exp_avg_sq': tensor([4.7082e-13, 3.3026e-13, 3.2982e-13, 3.5077e-13, 3.4456e-13, 3.4494e-13,\n            2.1114e-13, 2.2900e-13, 2.5672e-13, 3.0125e-13, 3.5907e-13, 2.3866e-13,\n            2.0356e-13, 2.4217e-13, 2.8768e-13, 4.1678e-13, 3.2727e-13, 2.5618e-13,\n            4.5127e-13, 2.3664e-13, 3.8512e-13, 3.4378e-13, 2.7878e-13, 1.6193e-13,\n            2.5475e-13, 3.2573e-13, 3.7025e-13, 2.4328e-13, 4.1076e-13, 2.6697e-13,\n            2.1554e-13, 3.2472e-13, 4.1970e-13, 4.4378e-13, 2.9202e-13, 3.0808e-13,\n            2.7308e-13, 5.3500e-13, 2.3989e-13, 2.4452e-13, 4.2372e-13, 3.6641e-13,\n            2.7815e-13, 4.6895e-13, 2.9385e-13, 2.7790e-13, 2.0799e-13, 4.3185e-13,\n            3.4013e-13, 2.2215e-13, 3.6162e-13, 3.2043e-13, 2.3135e-13, 3.5532e-13,\n            2.4179e-13, 2.9329e-13, 2.8179e-13, 3.0215e-13, 3.2336e-13, 2.6365e-13,\n            3.5830e-13, 2.8940e-13, 2.2465e-13, 3.1515e-13, 2.7448e-13, 2.6386e-13,\n            2.9858e-13, 2.5840e-13, 3.6483e-13, 2.7579e-13, 3.5661e-13, 3.4059e-13,\n            4.2741e-13, 3.1393e-13, 2.4929e-13, 5.2841e-13, 1.3554e-13, 3.0542e-13,\n            1.9465e-13, 2.1400e-13, 2.1957e-13, 2.6394e-13, 2.7630e-13, 1.9955e-13,\n            3.9251e-13, 2.6016e-13, 3.0248e-13, 2.9289e-13, 2.2196e-13, 2.0031e-13,\n            2.9458e-13, 2.2340e-13, 2.5298e-13, 2.5139e-13, 2.2768e-13, 3.6731e-13,\n            1.8585e-13, 2.8981e-13, 2.0792e-13, 2.0943e-13, 1.7011e-13, 5.9634e-13,\n            2.4145e-13, 3.7367e-13, 3.3670e-13, 2.5766e-13, 2.0436e-13, 2.8651e-13,\n            3.2758e-13, 2.3253e-13, 4.7610e-13, 3.1700e-13, 2.1841e-13, 2.4464e-13,\n            2.8244e-13, 2.2791e-13, 2.5343e-13, 3.9423e-13, 3.1298e-13, 2.0183e-13,\n            1.6450e-13, 2.6871e-13, 2.8220e-13, 2.3183e-13, 2.9831e-13, 2.7012e-13,\n            4.2598e-13, 4.7274e-13, 2.9272e-13, 2.8787e-13, 4.1450e-13, 2.4405e-13,\n            3.3065e-13, 2.6580e-13, 1.9830e-13, 2.7418e-13, 4.0344e-13, 2.9218e-13,\n            8.3805e-13, 2.3207e-13, 2.5167e-13, 2.5789e-13, 4.1292e-13, 1.8466e-13,\n            2.9346e-13, 5.6708e-13, 2.1795e-13, 1.9268e-13, 3.1467e-13, 2.2218e-13,\n            2.5177e-13, 1.9524e-13, 4.6971e-13, 1.0444e-13, 2.4266e-13, 1.8173e-13,\n            3.8314e-13, 2.3378e-13, 3.5518e-13, 4.3670e-13, 2.4463e-13, 5.4970e-13,\n            1.8085e-13, 2.7533e-13, 4.4359e-13, 2.9099e-13, 3.2946e-13, 1.5147e-13,\n            1.6213e-13, 3.3378e-13, 4.0964e-13, 1.4739e-13, 2.6135e-13, 1.8956e-13,\n            3.3997e-13, 2.3703e-13, 7.1736e-13, 3.5828e-13, 2.9661e-13, 2.8710e-13,\n            3.5701e-13, 2.9009e-13, 2.2536e-13, 2.2015e-13, 1.9051e-13, 2.5103e-13,\n            2.9339e-13, 3.8430e-13, 1.7839e-13, 2.0771e-13, 5.2369e-13, 1.7848e-13,\n            2.7249e-13, 2.9085e-13, 1.8997e-13, 3.1387e-13, 2.6536e-13, 3.1636e-13,\n            2.9469e-13, 3.2519e-13, 3.5629e-13, 1.9032e-13, 3.0346e-13, 3.5778e-13,\n            3.4286e-13, 2.0331e-13, 1.6296e-13, 3.2439e-13, 1.9183e-13, 1.3109e-13,\n            1.8051e-13, 2.6916e-13, 3.2854e-13, 1.2845e-13, 2.1734e-13, 3.5125e-13,\n            4.3606e-13, 3.4489e-13, 1.1583e-13, 2.8568e-13, 2.2677e-13, 2.3213e-13,\n            3.2820e-13, 2.7125e-13, 2.6577e-13, 4.1072e-13, 3.4198e-13, 1.3320e-13,\n            3.4457e-13, 6.3688e-13, 2.9816e-13, 4.0930e-13, 2.4981e-13, 3.4956e-13,\n            2.4490e-13, 3.3861e-13, 5.7818e-13, 2.2540e-13, 3.0959e-13, 3.3331e-13,\n            3.1701e-13, 1.8702e-13, 2.0642e-13, 2.8036e-13, 3.3756e-13, 3.6913e-13,\n            3.4977e-13, 3.1273e-13, 2.7737e-13, 2.4900e-13, 2.7419e-13, 2.4865e-13,\n            3.8672e-13, 6.2396e-13, 4.4900e-13, 2.6006e-13])},\n   83: {'exp_avg': tensor([ 6.6616e-08,  1.1978e-08, -1.4597e-07, -9.1330e-08, -1.2329e-07,\n             1.3704e-07,  3.0545e-09,  4.1549e-08,  1.1129e-07, -3.2095e-08,\n             1.6148e-07,  6.1955e-08, -1.5142e-07, -4.2024e-08,  4.5403e-08,\n             3.2188e-08, -7.9372e-08, -1.4473e-08, -1.2210e-07,  6.6854e-08,\n             5.2074e-08,  9.8496e-09, -5.0237e-08, -3.6589e-08, -1.0571e-08,\n             5.6783e-08,  4.2990e-08,  6.2869e-08,  3.8640e-08, -6.0097e-08,\n            -1.2970e-07, -2.9898e-08, -6.7179e-08, -7.5471e-08,  2.4906e-08,\n             3.0850e-08,  4.2458e-08,  7.5602e-08,  7.6443e-08,  2.8698e-08,\n             1.1865e-08, -1.4683e-07, -1.2794e-07, -3.9779e-08, -5.0249e-08,\n            -1.0049e-07, -4.2788e-08, -1.1789e-07, -7.2112e-08, -1.3279e-07,\n             8.4281e-08, -1.2111e-08, -4.5228e-08, -9.8983e-09, -1.5604e-07,\n            -1.7093e-08, -5.1047e-08,  4.4600e-08,  9.4046e-08,  3.4235e-08,\n             2.3101e-08, -9.7123e-08, -6.8702e-08,  4.7645e-09, -1.4365e-08,\n             1.3785e-08,  6.4370e-08, -3.3742e-08,  2.8271e-08,  2.3633e-08,\n             3.6738e-08,  3.1766e-08, -1.2187e-07,  9.0272e-09, -1.2082e-07,\n            -1.7974e-08,  4.0140e-08,  7.3651e-08, -1.2106e-08, -2.3300e-08,\n            -1.3523e-08,  3.0690e-08,  1.1443e-07, -1.1185e-07,  7.9164e-08,\n             1.0407e-07, -1.1784e-07, -7.8321e-09, -7.9798e-08, -1.6828e-08,\n            -2.0311e-08, -4.0286e-08, -3.0529e-08,  2.6416e-08,  7.6799e-08,\n            -3.1593e-09, -9.6545e-08,  1.3106e-07,  1.3089e-08, -9.9057e-08,\n             2.4615e-08, -4.5310e-08, -3.4318e-08,  1.2707e-07,  4.5037e-08,\n            -6.9147e-08,  4.1266e-08,  1.4496e-07,  1.4183e-07,  4.0740e-08,\n             1.2068e-07,  1.6660e-07,  3.0678e-08,  5.7743e-08, -7.0042e-08,\n            -6.8035e-08, -2.6603e-08,  4.9040e-09,  1.3617e-07, -8.6607e-08,\n             5.3732e-08, -1.2118e-07, -1.3543e-07, -1.0565e-07,  1.4287e-07,\n            -1.9758e-08, -1.0187e-07,  2.5348e-08,  3.9864e-08, -1.1525e-07,\n            -7.0441e-08, -1.3779e-07,  6.8622e-08, -7.5176e-08,  7.8526e-08,\n             2.1092e-07,  1.3308e-07,  1.5030e-07,  9.9941e-08,  7.2545e-08,\n             7.8451e-08, -9.4143e-08,  1.0787e-07,  8.0737e-08, -3.3492e-08,\n             5.7880e-08, -4.0502e-08, -4.8008e-08,  1.7223e-07, -1.6789e-07,\n            -3.2514e-08,  3.3517e-08, -2.6955e-07, -7.7814e-08, -3.8172e-09,\n             4.3124e-08,  3.4708e-08, -1.8137e-08, -6.6137e-08, -8.7952e-09,\n            -8.0195e-09, -9.4679e-08, -6.9817e-08, -9.8439e-09,  1.5725e-07,\n            -1.8825e-07, -2.1153e-08,  1.0167e-08,  3.8201e-08,  1.4933e-08,\n            -8.7213e-08, -3.0020e-08,  3.6770e-08,  4.8617e-08, -1.3708e-07,\n             2.8896e-08, -6.2530e-08,  3.5622e-08, -1.2106e-07,  2.5894e-08,\n            -2.1082e-08, -2.3903e-08,  9.4171e-08,  1.1272e-08,  1.1978e-08,\n             2.2765e-08,  1.5456e-07, -5.2218e-08, -6.0428e-08, -1.3730e-08,\n             2.6243e-07,  7.2319e-08,  6.9200e-09,  1.0595e-07,  1.0556e-07,\n             1.4529e-07,  4.6573e-08,  3.1114e-08, -1.1184e-07, -8.8977e-08,\n            -1.8353e-07,  1.1512e-07, -1.4332e-07, -1.3922e-08, -2.3196e-08,\n            -1.5694e-08,  4.7483e-09,  1.5924e-07, -2.9125e-08, -2.3421e-08,\n             3.5386e-08, -3.6339e-08,  2.7705e-08, -2.2709e-08, -1.3484e-07,\n             5.6842e-09, -1.2144e-07, -2.6650e-08, -3.5871e-08,  8.2629e-08,\n             1.8195e-07,  5.7070e-08,  7.2741e-08,  2.0060e-08,  1.2578e-07,\n            -1.7521e-07,  1.0096e-07,  1.5680e-08, -6.0608e-08, -5.4242e-08,\n             1.9648e-08,  8.3059e-08, -9.2507e-08,  1.3669e-08,  1.3063e-07,\n             3.8213e-08, -7.4376e-09,  6.7453e-08,  1.8424e-07, -1.6308e-07,\n            -9.4287e-08,  2.8255e-09, -8.1911e-08, -8.3914e-08, -1.0777e-07,\n            -4.8327e-08,  9.3946e-08,  2.8932e-08, -1.5446e-07, -7.2240e-08,\n            -7.4721e-08,  1.7427e-08, -1.8981e-08, -2.5373e-07, -6.3859e-09,\n            -2.7746e-08]),\n    'exp_avg_sq': tensor([2.0121e-13, 1.4527e-13, 1.5746e-13, 1.5790e-13, 1.3061e-13, 1.4916e-13,\n            1.0797e-13, 9.8546e-14, 1.1287e-13, 1.2373e-13, 1.3870e-13, 1.0398e-13,\n            1.1725e-13, 1.2780e-13, 1.1462e-13, 1.0494e-13, 1.2634e-13, 1.1690e-13,\n            2.1015e-13, 1.2321e-13, 1.8869e-13, 1.9511e-13, 1.4934e-13, 7.6317e-14,\n            1.0184e-13, 1.7913e-13, 1.3856e-13, 1.2214e-13, 8.7467e-14, 1.0156e-13,\n            1.0815e-13, 1.2460e-13, 1.7346e-13, 1.9567e-13, 1.5334e-13, 1.0805e-13,\n            1.2522e-13, 1.6623e-13, 1.2044e-13, 1.1025e-13, 1.9930e-13, 1.7643e-13,\n            1.4429e-13, 1.8584e-13, 1.2554e-13, 1.4186e-13, 1.2964e-13, 1.8628e-13,\n            1.6451e-13, 1.0422e-13, 1.4450e-13, 1.7229e-13, 1.2005e-13, 1.0476e-13,\n            1.2830e-13, 1.2898e-13, 1.6027e-13, 1.4923e-13, 1.3483e-13, 1.2743e-13,\n            1.6348e-13, 1.1627e-13, 9.8757e-14, 1.2952e-13, 1.3671e-13, 1.2558e-13,\n            1.3804e-13, 1.0199e-13, 1.6952e-13, 1.0944e-13, 1.4167e-13, 1.7993e-13,\n            1.6735e-13, 1.6780e-13, 1.2849e-13, 1.9498e-13, 1.2063e-13, 1.5778e-13,\n            8.0220e-14, 1.0980e-13, 1.0751e-13, 1.2624e-13, 1.3670e-13, 8.6590e-14,\n            1.9044e-13, 1.1934e-13, 1.4273e-13, 1.1454e-13, 9.2272e-14, 9.3225e-14,\n            1.4778e-13, 9.5995e-14, 1.1377e-13, 1.0422e-13, 1.1777e-13, 1.6667e-13,\n            9.8700e-14, 1.1998e-13, 9.5489e-14, 1.0300e-13, 7.5949e-14, 2.2991e-13,\n            1.4504e-13, 1.7945e-13, 1.4596e-13, 1.1531e-13, 1.0492e-13, 1.5786e-13,\n            1.9811e-13, 1.2935e-13, 2.0656e-13, 1.4117e-13, 8.6364e-14, 1.1902e-13,\n            1.1659e-13, 1.1531e-13, 1.1579e-13, 1.7650e-13, 1.4358e-13, 8.7819e-14,\n            7.4603e-14, 1.2280e-13, 1.3503e-13, 1.3369e-13, 1.4068e-13, 1.2524e-13,\n            1.5362e-13, 1.7509e-13, 1.2634e-13, 1.2907e-13, 9.5536e-14, 1.4398e-13,\n            1.7679e-13, 1.3734e-13, 9.7535e-14, 1.1416e-13, 1.4990e-13, 1.3629e-13,\n            4.1608e-13, 1.0085e-13, 1.2994e-13, 8.4741e-14, 1.5875e-13, 8.7533e-14,\n            1.2955e-13, 2.1231e-13, 1.1604e-13, 8.9351e-14, 1.4058e-13, 1.1776e-13,\n            1.2870e-13, 8.2728e-14, 1.8823e-13, 6.8069e-14, 9.6970e-14, 8.6471e-14,\n            1.7008e-13, 1.2943e-13, 1.9724e-13, 2.0027e-13, 1.2997e-13, 1.6765e-13,\n            9.9787e-14, 1.5728e-13, 1.5952e-13, 8.7268e-14, 1.3205e-13, 9.6265e-14,\n            8.0034e-14, 1.3470e-13, 2.2910e-13, 8.3350e-14, 1.5434e-13, 8.4031e-14,\n            1.9592e-13, 1.1622e-13, 3.8896e-13, 1.8383e-13, 1.4858e-13, 1.3557e-13,\n            1.5238e-13, 1.1298e-13, 1.0611e-13, 1.4203e-13, 8.4019e-14, 9.3841e-14,\n            1.2590e-13, 1.4994e-13, 6.7441e-14, 1.0969e-13, 2.7071e-13, 9.9759e-14,\n            1.2459e-13, 1.2913e-13, 1.0317e-13, 1.3205e-13, 1.2438e-13, 1.4899e-13,\n            9.1370e-14, 1.5802e-13, 1.4991e-13, 9.4860e-14, 1.7387e-13, 1.5851e-13,\n            1.2870e-13, 9.5304e-14, 8.4007e-14, 1.4350e-13, 8.7004e-14, 8.4029e-14,\n            9.8180e-14, 1.2110e-13, 1.3015e-13, 7.5019e-14, 1.2446e-13, 1.7184e-13,\n            2.0524e-13, 1.2281e-13, 6.0575e-14, 1.2969e-13, 1.3079e-13, 1.1824e-13,\n            1.4221e-13, 1.1029e-13, 1.3632e-13, 1.5840e-13, 1.5743e-13, 7.9986e-14,\n            1.3506e-13, 8.3686e-14, 1.5420e-13, 1.3395e-13, 1.4183e-13, 1.5270e-13,\n            1.4164e-13, 1.7450e-13, 2.1296e-13, 1.1379e-13, 1.4828e-13, 1.2944e-13,\n            1.3576e-13, 8.9038e-14, 1.0100e-13, 1.3053e-13, 1.6415e-13, 1.7385e-13,\n            1.8188e-13, 1.6669e-13, 1.2280e-13, 1.2788e-13, 1.2055e-13, 1.3660e-13,\n            1.4721e-13, 2.7096e-13, 1.5784e-13, 1.0751e-13])},\n   84: {'exp_avg': tensor([ 4.5435e-07,  1.0273e-07, -1.3686e-07,  ...,  4.0134e-07,\n             1.7846e-07, -1.6725e-07]),\n    'exp_avg_sq': tensor([5.4652e-13, 6.7865e-13, 4.7986e-13,  ..., 9.5209e-13, 7.3916e-13,\n            8.7017e-13])},\n   85: {'exp_avg': tensor([-4.1034e-09, -5.7510e-08,  7.2825e-08,  ...,  4.0352e-08,\n            -1.1719e-07, -3.0367e-08]),\n    'exp_avg_sq': tensor([5.0767e-14, 9.0197e-14, 1.3799e-13,  ..., 1.8262e-14, 1.4455e-13,\n            3.2054e-14])},\n   86: {'exp_avg': tensor([-1.0795e-07, -8.7115e-08, -6.0346e-08,  8.2595e-08,  5.4941e-09,\n            -1.5809e-07, -3.2519e-08,  8.7167e-08,  3.3366e-08,  1.8964e-09,\n            -7.8608e-08, -1.9307e-07, -6.0797e-08,  1.8370e-07, -8.3010e-08,\n            -1.4362e-07,  8.4944e-08, -1.0583e-07,  1.0216e-07, -6.6224e-08,\n            -1.3319e-07,  1.3353e-07,  4.5684e-08, -1.2698e-07, -5.7810e-08,\n             9.6126e-08, -2.2319e-07, -4.3952e-08,  1.6911e-08,  9.8583e-09,\n             2.9347e-07, -6.6356e-08,  8.1988e-08, -3.0044e-09,  1.3416e-07,\n            -1.0224e-07,  4.3004e-09, -2.4075e-08,  1.5876e-08, -1.0856e-07,\n            -1.1700e-07, -2.2221e-07,  5.9525e-08, -1.9875e-07,  1.0483e-07,\n             1.1653e-07,  1.1822e-07,  1.9958e-08, -6.3241e-08, -3.6000e-08,\n             1.3253e-07, -8.4574e-08, -1.9473e-07,  4.6474e-09,  1.2645e-07,\n             3.0109e-08, -7.9463e-08,  1.3304e-07,  4.1615e-08, -7.1273e-08,\n             5.4109e-08,  3.9522e-08, -2.1438e-07, -1.6799e-08,  8.1067e-08,\n             1.6729e-08, -2.9660e-08,  1.2253e-07, -2.6451e-07,  9.6620e-08,\n             2.7375e-08,  2.3424e-07, -3.0148e-08,  1.8909e-08, -3.0054e-08,\n             1.5257e-08, -6.5655e-08,  3.6612e-08,  9.6965e-08,  1.0805e-08,\n            -1.8236e-07,  9.7066e-08,  2.8906e-07,  5.4334e-08, -4.2232e-08,\n             1.0438e-07, -2.4788e-07,  3.0669e-08, -2.2226e-08,  1.5535e-07,\n            -8.3489e-08, -6.6221e-08, -1.4164e-08,  1.8979e-08,  7.0407e-08,\n             1.9796e-07, -1.6474e-07,  1.3137e-07,  2.2511e-07, -4.6596e-08,\n            -7.0009e-08, -1.0952e-07, -3.5943e-08,  2.3882e-07,  1.1527e-07,\n            -1.8844e-08, -2.4759e-08,  1.0357e-07, -1.3217e-07,  2.4023e-07,\n             4.8305e-08, -1.7892e-07,  1.1090e-08, -3.6090e-08, -1.5271e-07,\n            -2.3367e-08, -2.1045e-08,  2.7513e-08,  1.2340e-07,  1.7994e-08,\n            -8.3874e-08,  9.0097e-08,  2.2171e-09,  4.5730e-08, -1.0802e-07,\n             2.3362e-08,  8.7604e-08, -7.8932e-08, -3.4413e-08, -7.5992e-08,\n            -1.7076e-08, -1.0207e-07, -1.8141e-07,  2.1575e-08,  1.0797e-07,\n            -7.1407e-08,  2.2918e-08,  3.9254e-07,  1.1853e-07, -1.8925e-07,\n             6.6446e-08,  1.6857e-07, -1.7273e-07,  7.8411e-08, -7.0300e-08,\n             5.7055e-08, -1.4317e-07, -9.5080e-08, -5.8966e-08,  9.0281e-08,\n             1.1153e-07, -4.6493e-08, -2.9796e-08, -1.6886e-07, -6.8633e-08,\n            -3.2727e-08,  1.0231e-08,  1.1347e-07, -1.6516e-08,  1.8479e-08,\n            -4.7752e-08,  4.3518e-09,  5.1860e-08, -3.9294e-08,  1.8808e-08,\n            -1.0784e-07, -3.1838e-08,  2.0463e-08,  6.1502e-08, -6.4500e-08,\n            -2.4293e-08, -9.3426e-08,  1.4287e-07, -8.6310e-08,  2.3452e-08,\n             5.4348e-08, -6.4856e-08,  4.1381e-09,  2.4897e-08,  7.9250e-08,\n             1.4534e-07, -1.0131e-07,  2.5853e-08, -2.6263e-09, -1.1747e-07,\n            -1.5148e-09,  2.5132e-08,  2.0571e-07,  4.1398e-08, -1.2704e-07,\n             1.3592e-08, -7.2300e-08, -1.1444e-07,  1.7629e-07, -1.1339e-07,\n            -1.5012e-07, -1.6178e-07, -7.4378e-08, -7.7333e-08,  1.2002e-08,\n             2.8646e-08,  2.1765e-08,  1.1415e-07,  7.2079e-09, -6.3527e-09,\n             1.3422e-07, -1.0798e-07,  1.3784e-07, -6.0743e-08,  1.8937e-08,\n            -1.9436e-07, -9.2059e-08,  1.0581e-07,  8.3717e-08, -9.4818e-08,\n            -1.2071e-07, -1.8188e-07, -9.5066e-08, -4.0400e-09,  2.7945e-08,\n            -6.0837e-08,  3.3176e-08,  3.3867e-08, -1.1544e-07,  1.7646e-07,\n             4.2033e-08, -1.8487e-08,  4.0555e-08,  1.1771e-07,  2.1136e-09,\n            -6.6512e-09, -7.9496e-08, -4.6271e-08, -1.1524e-07, -5.2317e-08,\n            -2.7966e-08,  2.1015e-08,  8.3050e-08,  5.0806e-08,  7.9441e-08,\n            -2.3216e-08,  3.6052e-09, -4.3882e-08, -9.1799e-10, -2.3953e-08,\n             1.1158e-07, -1.6752e-09,  1.0775e-07,  8.1040e-08,  7.6569e-08,\n            -4.4401e-08,  1.2064e-07,  1.0058e-07,  5.9637e-09, -1.5209e-07,\n            -5.0309e-08,  2.2137e-09, -1.4462e-08, -1.4628e-07, -1.2527e-07,\n            -7.7003e-08, -1.4187e-08, -8.7198e-08, -9.6096e-08,  3.3385e-08,\n            -5.3082e-08,  1.0594e-07,  1.9263e-08,  1.1268e-07, -1.2840e-07,\n             5.3255e-08,  1.6385e-07,  7.1150e-08,  6.6167e-10, -8.5000e-08,\n            -1.6943e-08,  1.2831e-07,  1.0422e-07,  3.5484e-08, -4.5810e-08,\n             4.9621e-08, -1.4983e-07,  1.1545e-07,  1.7603e-08,  1.3156e-07,\n             1.9707e-07,  6.3286e-08,  6.2959e-09,  2.0067e-07,  5.3199e-08,\n             1.6646e-07,  1.0141e-08, -7.2869e-08,  5.3520e-08, -2.6542e-08,\n            -4.4174e-08, -4.9940e-08, -1.7913e-08, -1.3459e-08,  3.2616e-08,\n             1.3603e-08,  1.2553e-07,  7.4995e-08,  2.1135e-08, -2.2832e-08,\n            -8.0738e-08, -1.0369e-07, -1.3473e-07, -3.0695e-08,  1.7103e-08,\n             1.4867e-07, -6.1583e-09,  1.4627e-07,  1.1121e-07, -1.4389e-07,\n            -3.5431e-08,  7.4375e-09,  4.4187e-08,  2.1489e-08, -2.4365e-07,\n             8.6375e-08, -6.9379e-08,  2.8994e-08, -4.9206e-08, -3.2698e-07,\n            -1.5817e-08,  7.7237e-08,  2.0308e-07, -8.7888e-08, -8.2574e-09,\n             7.6017e-08, -9.2792e-08, -3.3255e-08,  5.2807e-08,  9.4189e-08,\n            -1.8128e-08, -1.6624e-08, -1.0852e-07, -4.1008e-08,  1.1795e-09,\n            -1.5386e-08,  4.4101e-08,  6.3619e-08, -8.7152e-08,  9.4759e-08,\n            -9.5970e-08, -7.6073e-08,  2.0730e-07, -3.1432e-08, -3.4132e-08,\n             1.6514e-07, -4.9592e-08,  1.1201e-07,  8.9525e-08, -4.8922e-08,\n            -8.3644e-08, -8.3475e-08, -3.6150e-08,  2.4826e-07,  7.8066e-08,\n            -9.1515e-08,  1.8825e-10, -2.3518e-08, -1.4658e-07, -3.2252e-08,\n            -1.2750e-08, -6.1824e-08, -2.0468e-08,  1.3469e-07, -1.1547e-07,\n            -2.1950e-07, -8.9544e-08,  1.9685e-08,  2.8661e-08, -4.4522e-08,\n             1.5149e-07, -1.0429e-07,  5.9421e-08, -1.1879e-07, -4.9400e-08,\n            -3.1087e-07,  1.3328e-08,  2.1734e-08,  1.4208e-07, -1.8562e-07,\n             2.0588e-07,  2.5931e-07, -1.6641e-08, -3.2314e-08,  9.7902e-08,\n            -1.3382e-07, -3.7222e-08,  5.5212e-08,  5.5494e-08, -1.7059e-07,\n             8.2158e-08, -1.0379e-07,  3.2556e-08,  3.0913e-08, -7.6117e-09,\n            -7.7616e-08, -1.3604e-07,  1.9950e-08, -1.0403e-08, -2.6211e-08,\n             2.8089e-08, -3.8014e-09,  1.2550e-08,  7.6608e-08, -1.3971e-07,\n            -3.6927e-08,  4.9095e-08,  2.7938e-07,  1.0604e-08,  4.7424e-08,\n             2.4393e-08,  3.2430e-08, -4.6296e-08,  6.4063e-08,  3.0850e-09,\n             6.7840e-08, -9.5556e-08, -7.7966e-08,  9.1656e-08, -3.2625e-08,\n             1.1021e-07, -1.2952e-07,  2.2234e-07, -1.6396e-07, -8.7482e-08,\n             3.1046e-08, -5.8434e-09,  1.0392e-07,  3.9993e-08, -2.2429e-07,\n             5.6993e-08, -9.4457e-08,  5.9192e-09,  1.4238e-07, -1.7284e-07,\n            -8.7428e-08,  1.0507e-07, -1.2648e-07,  1.3659e-07,  7.6810e-08,\n             4.9900e-08,  1.1850e-07, -1.1789e-07, -1.8564e-07,  1.0939e-07,\n             5.3154e-08,  8.8012e-08,  9.6252e-09, -7.3982e-08,  1.5634e-07,\n            -8.4320e-08, -5.0453e-08, -1.7355e-07,  5.9861e-08, -1.6719e-07,\n             1.3096e-07,  1.0696e-08,  2.7097e-08,  3.2421e-08, -1.5152e-09,\n             1.7426e-08, -3.3813e-09,  1.3938e-08,  1.9793e-07,  2.6767e-07,\n             2.3373e-08, -4.6326e-09, -8.8835e-08, -4.3249e-08, -6.1629e-08,\n            -2.2490e-07,  9.8441e-08,  2.4546e-09, -3.9258e-08,  1.0161e-07,\n             3.6027e-08, -2.6862e-08,  6.6928e-08, -5.0341e-08,  1.1009e-07,\n             3.2538e-08,  5.4850e-08,  2.6787e-08,  2.9684e-08, -8.7237e-08,\n            -9.2534e-08,  9.9971e-09, -8.9750e-08, -3.2883e-08,  1.7885e-07,\n             8.7763e-09,  4.3719e-08, -9.1349e-08, -1.5150e-07,  2.4481e-08,\n             3.0863e-08,  4.0543e-08, -1.3156e-08, -1.3626e-07,  1.7594e-07,\n             3.2888e-08,  1.1070e-08, -5.5794e-10,  4.7919e-08, -1.6264e-07,\n             4.8342e-08,  8.6657e-08]),\n    'exp_avg_sq': tensor([1.5072e-13, 1.5096e-13, 1.7885e-13, 1.2750e-13, 1.3240e-13, 1.8604e-13,\n            1.1397e-13, 2.1355e-13, 1.7711e-13, 1.7382e-13, 1.5763e-13, 1.9548e-13,\n            1.7308e-13, 1.5586e-13, 1.6326e-13, 2.5287e-13, 2.4460e-13, 1.5654e-13,\n            1.4685e-13, 1.1910e-13, 3.5420e-13, 2.6738e-13, 1.7120e-13, 1.7541e-13,\n            1.7507e-13, 1.5131e-13, 2.0516e-13, 1.0072e-13, 1.0383e-13, 1.2626e-13,\n            1.9750e-13, 2.2971e-13, 1.9240e-13, 1.3387e-13, 1.3998e-13, 1.9952e-13,\n            2.2180e-13, 1.4273e-13, 1.4868e-13, 1.6806e-13, 2.1872e-13, 2.0277e-13,\n            2.3011e-13, 1.5548e-13, 1.2036e-13, 2.1530e-13, 1.6981e-13, 1.8480e-13,\n            1.8984e-13, 1.1139e-13, 1.8100e-13, 2.3238e-13, 1.4993e-13, 1.6583e-13,\n            1.3294e-13, 1.7819e-13, 1.8613e-13, 1.9827e-13, 1.1391e-13, 2.1160e-13,\n            1.6468e-13, 1.5949e-13, 1.6838e-13, 1.6633e-13, 1.3025e-13, 1.7157e-13,\n            1.5964e-13, 1.4292e-13, 1.4653e-13, 1.5411e-13, 1.4974e-13, 1.8141e-13,\n            1.6210e-13, 1.1896e-13, 2.1418e-13, 2.0863e-13, 1.6972e-13, 1.4975e-13,\n            2.1112e-13, 2.0184e-13, 1.1795e-13, 1.5647e-13, 1.7867e-13, 1.7981e-13,\n            1.2992e-13, 1.7155e-13, 1.8851e-13, 1.4716e-13, 2.0822e-13, 2.0214e-13,\n            1.7091e-13, 1.8994e-13, 2.2112e-13, 1.5114e-13, 3.7626e-13, 2.6846e-13,\n            1.4822e-13, 1.5732e-13, 2.2223e-13, 2.0592e-13, 1.4082e-13, 2.7697e-13,\n            4.3774e-13, 2.9311e-13, 1.9180e-13, 1.1914e-13, 1.8166e-13, 1.9013e-13,\n            1.4862e-13, 1.3551e-13, 2.3031e-13, 1.8775e-13, 1.4641e-13, 2.1936e-13,\n            2.5316e-13, 2.1654e-13, 1.3522e-13, 1.7071e-13, 1.9588e-13, 1.8883e-13,\n            1.2841e-13, 1.1433e-13, 1.7714e-13, 2.1418e-13, 1.7512e-13, 1.3597e-13,\n            9.6289e-14, 2.3252e-13, 2.4279e-13, 1.3571e-13, 1.6964e-13, 1.7556e-13,\n            1.3379e-13, 1.7849e-13, 1.7437e-13, 1.4492e-13, 1.9366e-13, 1.7970e-13,\n            1.3870e-13, 1.8311e-13, 1.2455e-13, 1.8300e-13, 2.1768e-13, 1.5382e-13,\n            1.7997e-13, 1.4910e-13, 1.2384e-13, 1.3098e-13, 1.9093e-13, 1.4583e-13,\n            1.4230e-13, 2.6711e-13, 1.3648e-13, 1.8766e-13, 1.6685e-13, 2.3669e-13,\n            1.6125e-13, 1.7074e-13, 1.2488e-13, 1.4628e-13, 2.1649e-13, 1.6251e-13,\n            1.6928e-13, 1.6979e-13, 1.8480e-13, 1.4227e-13, 1.5923e-13, 2.0414e-13,\n            1.3865e-13, 1.4963e-13, 1.0582e-13, 1.6604e-13, 1.5262e-13, 1.8917e-13,\n            2.1410e-13, 3.4031e-13, 1.6278e-13, 1.2433e-13, 1.6300e-13, 2.0982e-13,\n            2.6374e-13, 2.1497e-13, 2.6535e-13, 2.1084e-13, 2.0011e-13, 1.2064e-13,\n            1.7655e-13, 2.1983e-13, 1.5116e-13, 2.0438e-13, 1.7382e-13, 1.3061e-13,\n            1.4960e-13, 1.5339e-13, 2.3996e-13, 2.2561e-13, 1.7278e-13, 1.5772e-13,\n            1.1224e-13, 2.0799e-13, 1.3380e-13, 1.4240e-13, 1.2233e-13, 1.2634e-13,\n            1.4124e-13, 1.4215e-13, 1.7916e-13, 1.2398e-13, 1.7635e-13, 1.1972e-13,\n            1.3255e-13, 1.6465e-13, 1.9844e-13, 1.5283e-13, 1.3138e-13, 1.4971e-13,\n            1.3902e-13, 1.9266e-13, 9.9279e-14, 1.5553e-13, 2.0620e-13, 1.7576e-13,\n            1.4841e-13, 1.9132e-13, 1.5872e-13, 1.5041e-13, 1.6996e-13, 1.6469e-13,\n            1.7386e-13, 1.5823e-13, 2.0603e-13, 1.5850e-13, 1.6506e-13, 1.6878e-13,\n            2.1653e-13, 1.6238e-13, 1.8301e-13, 3.6113e-13, 1.3920e-13, 2.1634e-13,\n            1.5604e-13, 1.6356e-13, 1.8167e-13, 1.9697e-13, 1.9048e-13, 2.4384e-13,\n            1.9960e-13, 2.0130e-13, 1.6438e-13, 1.5495e-13, 1.3396e-13, 1.5689e-13,\n            2.1073e-13, 1.5169e-13, 2.7682e-13, 1.6304e-13, 1.3138e-13, 1.7028e-13,\n            1.6454e-13, 3.1164e-13, 1.2739e-13, 1.0311e-13, 1.5303e-13, 1.9717e-13,\n            1.3529e-13, 2.0028e-13, 1.4024e-13, 1.4325e-13, 2.5162e-13, 1.7301e-13,\n            1.5869e-13, 1.5622e-13, 1.7534e-13, 1.4645e-13, 1.6701e-13, 1.8305e-13,\n            2.2540e-13, 1.5399e-13, 1.5525e-13, 1.3909e-13, 1.1678e-13, 2.3689e-13,\n            1.7419e-13, 1.9140e-13, 2.1789e-13, 2.1577e-13, 1.6766e-13, 2.1736e-13,\n            2.0033e-13, 1.3313e-13, 1.6530e-13, 1.3789e-13, 1.9448e-13, 1.5601e-13,\n            1.4930e-13, 2.1311e-13, 1.8315e-13, 1.1635e-13, 1.5360e-13, 1.4397e-13,\n            1.9419e-13, 1.8468e-13, 2.7862e-13, 1.5055e-13, 1.9152e-13, 2.0482e-13,\n            1.6901e-13, 1.8349e-13, 1.7564e-13, 1.7050e-13, 1.2723e-13, 9.7534e-14,\n            1.6601e-13, 1.4998e-13, 1.0071e-13, 1.1772e-13, 1.5158e-13, 1.8888e-13,\n            1.3643e-13, 1.5173e-13, 9.3999e-14, 1.3786e-13, 1.2609e-13, 1.9694e-13,\n            1.9528e-13, 1.8744e-13, 2.0435e-13, 1.5506e-13, 1.4206e-13, 1.8083e-13,\n            1.4674e-13, 2.5879e-13, 2.3121e-13, 1.7624e-13, 1.6462e-13, 1.5519e-13,\n            1.7591e-13, 1.4471e-13, 1.5479e-13, 1.2704e-13, 1.5830e-13, 1.4819e-13,\n            1.5609e-13, 1.5502e-13, 1.1991e-13, 1.6766e-13, 1.8351e-13, 2.0893e-13,\n            1.2179e-13, 1.7554e-13, 1.4321e-13, 1.2276e-13, 1.6105e-13, 1.9933e-13,\n            1.3881e-13, 1.4220e-13, 1.6121e-13, 1.8707e-13, 1.2142e-13, 1.6689e-13,\n            1.5095e-13, 1.8053e-13, 1.7193e-13, 1.3264e-13, 1.5774e-13, 1.6604e-13,\n            2.1397e-13, 1.5697e-13, 1.5109e-13, 1.1534e-13, 2.1775e-13, 3.2542e-13,\n            1.8216e-13, 1.9925e-13, 1.7884e-13, 1.4781e-13, 1.8883e-13, 9.6756e-14,\n            2.1906e-13, 1.7969e-13, 2.8384e-13, 2.7581e-13, 1.5271e-13, 1.2766e-13,\n            1.6155e-13, 2.1926e-13, 1.7326e-13, 1.7635e-13, 1.1733e-13, 1.5218e-13,\n            2.7296e-13, 2.8383e-13, 1.3617e-13, 1.5414e-13, 1.4583e-13, 1.4945e-13,\n            1.9631e-13, 1.9534e-13, 1.3855e-13, 1.6276e-13, 1.6638e-13, 1.9024e-13,\n            1.8319e-13, 1.8425e-13, 1.3350e-13, 1.3010e-13, 1.7551e-13, 2.2863e-13,\n            2.4831e-13, 1.6264e-13, 2.4720e-13, 2.1334e-13, 2.2542e-13, 1.2324e-13,\n            1.3524e-13, 1.5167e-13, 1.4729e-13, 1.6066e-13, 1.9949e-13, 1.6706e-13,\n            1.6877e-13, 1.4359e-13, 2.0442e-13, 1.3650e-13, 1.1980e-13, 2.0331e-13,\n            1.9187e-13, 1.6482e-13, 1.7788e-13, 1.5090e-13, 1.8534e-13, 1.3724e-13,\n            1.6333e-13, 2.5022e-13, 1.6336e-13, 2.6203e-13, 1.6431e-13, 1.4597e-13,\n            2.2673e-13, 1.4822e-13, 2.4487e-13, 1.5499e-13, 1.4680e-13, 1.6665e-13,\n            1.6138e-13, 1.9158e-13, 1.6930e-13, 1.6580e-13, 1.4223e-13, 1.4237e-13,\n            1.3597e-13, 2.0594e-13, 1.5065e-13, 2.2070e-13, 2.1360e-13, 1.4624e-13,\n            1.1702e-13, 1.8475e-13, 1.5920e-13, 1.2999e-13, 1.6495e-13, 1.4970e-13,\n            1.3180e-13, 2.3391e-13, 1.3909e-13, 1.7331e-13, 1.9519e-13, 1.6114e-13,\n            1.6004e-13, 1.8817e-13, 2.5178e-13, 1.7658e-13, 8.6892e-14, 1.3275e-13,\n            1.9686e-13, 2.0039e-13, 1.5401e-13, 1.7649e-13, 1.8036e-13, 2.1124e-13,\n            1.9720e-13, 2.0525e-13, 1.2604e-13, 2.3534e-13, 1.3999e-13, 1.5876e-13,\n            1.9322e-13, 2.0227e-13, 2.7886e-13, 1.7134e-13, 1.9714e-13, 1.6022e-13,\n            1.5607e-13, 1.1499e-13, 1.1092e-13, 1.7001e-13, 1.9400e-13, 2.3503e-13,\n            1.7155e-13, 1.4684e-13, 1.8527e-13, 1.5425e-13, 1.2057e-13, 1.4226e-13,\n            1.3792e-13, 2.1017e-13, 1.6148e-13, 2.0582e-13, 1.4190e-13, 1.9540e-13,\n            2.0357e-13, 1.7299e-13])},\n   87: {'exp_avg': tensor([-3.0275e-08, -8.0245e-08,  7.7485e-09,  5.9835e-08, -3.1781e-08,\n            -7.7198e-08, -7.1736e-08,  8.2187e-08,  3.3419e-08, -3.5360e-08,\n            -1.1477e-07, -6.4313e-08, -1.9718e-08,  2.0523e-07, -1.7210e-07,\n            -2.2566e-07, -2.5735e-08, -6.3300e-09,  6.9997e-09, -1.3761e-07,\n            -1.5448e-07,  1.7819e-07, -3.9401e-10, -1.1181e-07, -1.0847e-08,\n             4.4646e-08, -1.2362e-07, -3.3719e-08, -1.7348e-08,  5.4755e-08,\n             1.3146e-07, -4.1733e-08,  7.5257e-08,  1.0399e-08,  5.4383e-08,\n            -7.2627e-08,  5.8928e-09, -2.8802e-08, -1.1028e-09, -1.3620e-07,\n            -4.9880e-08, -1.0856e-07,  4.7635e-08, -8.8658e-08,  7.1596e-08,\n             5.2684e-08, -3.8061e-08, -6.6092e-08,  8.2781e-09, -1.3310e-07,\n             7.3011e-08, -3.6361e-08, -2.4560e-07,  1.0480e-08,  1.7128e-07,\n            -6.0584e-08, -3.0587e-08,  6.6628e-08,  6.6182e-08, -3.4402e-08,\n             8.0697e-08, -4.4471e-08, -8.3183e-08,  2.2192e-08, -2.4354e-08,\n             3.3965e-08, -5.5324e-08,  1.4499e-07, -1.6324e-07,  8.1138e-08,\n             6.9142e-08,  1.3978e-07, -4.7164e-08, -8.3907e-09,  4.5317e-08,\n            -6.9775e-09, -1.0163e-07, -2.1279e-09,  4.5335e-10,  6.3102e-09,\n            -7.7983e-08,  4.5655e-08,  1.4376e-07,  4.4182e-08, -2.8726e-08,\n            -1.9927e-08, -1.2014e-07,  7.0408e-08,  1.6834e-08,  1.6554e-07,\n            -2.3577e-08, -6.7695e-08,  2.7512e-08,  2.5799e-08,  4.9903e-08,\n             6.5858e-08, -1.1005e-07,  5.9590e-08,  1.3452e-07, -1.1262e-07,\n            -5.1384e-08, -1.3542e-07,  5.1219e-08,  2.4100e-07,  7.3031e-08,\n             1.3619e-08,  2.6726e-08,  1.2886e-07, -1.9399e-09,  1.0694e-07,\n             1.1612e-07, -9.7792e-08, -2.0741e-08,  6.0053e-08, -1.0834e-07,\n            -8.7508e-08, -1.8316e-08, -1.0712e-08,  9.4873e-08,  3.3575e-08,\n            -3.1281e-08,  7.5133e-08, -1.7567e-08,  2.9961e-09, -1.9080e-08,\n            -5.4142e-08,  1.1815e-08, -7.9580e-08, -3.8325e-08, -3.6021e-08,\n            -3.5181e-08, -1.2763e-07, -2.9419e-08, -6.3360e-09,  5.4816e-08,\n            -9.2387e-08,  5.7986e-09,  1.8198e-07,  5.7617e-08, -1.0003e-07,\n             5.6384e-08,  1.7343e-07, -1.1475e-07,  8.3229e-08, -9.3481e-08,\n             9.1842e-08, -9.9773e-08, -9.0663e-08, -3.0584e-08,  9.7752e-08,\n             9.3940e-08, -5.1671e-08, -1.8957e-08, -1.0843e-07,  2.2313e-08,\n            -2.9484e-08,  6.1055e-08,  6.5591e-08,  2.3183e-08,  2.4987e-08,\n             5.2685e-08,  2.7038e-08,  9.5308e-08, -8.3039e-08, -2.9634e-08,\n             2.2757e-10,  5.1338e-08, -1.5577e-08,  3.4747e-08, -1.5894e-08,\n             4.6131e-08, -1.3294e-07,  9.2979e-08, -8.6248e-08,  7.7805e-08,\n             7.7584e-08, -1.0921e-07,  9.5209e-09,  1.0326e-07, -1.5623e-08,\n             1.3217e-07, -4.5501e-08,  4.0063e-08, -3.7523e-08, -1.3036e-07,\n             5.2605e-08, -3.3606e-08,  1.0073e-07,  7.3522e-08, -9.2465e-08,\n             1.2846e-08, -1.3541e-08, -8.7373e-08,  9.6697e-08,  3.1065e-09,\n            -6.4864e-08, -1.8203e-07, -5.8603e-08, -4.7891e-08, -5.0806e-08,\n            -5.1891e-08, -5.9662e-09,  2.4556e-08,  2.2574e-09,  9.6313e-08,\n             8.3352e-08, -2.2677e-08,  8.9894e-08, -3.1734e-08, -4.1965e-08,\n            -1.2757e-07, -6.3724e-08, -7.1574e-09,  3.2004e-08, -1.3598e-07,\n            -3.1001e-08, -1.1263e-07, -1.1033e-07, -3.1424e-08,  1.7270e-08,\n            -5.1462e-08,  4.4568e-08,  2.8525e-08,  2.2125e-08,  9.4654e-09,\n             4.7387e-08, -2.6633e-08,  4.5869e-08,  1.1854e-07,  8.3853e-08,\n             2.0453e-08, -5.0859e-08, -7.9467e-08, -1.0910e-07, -8.4971e-08,\n            -4.2939e-08,  1.3545e-08,  9.3058e-08,  7.0544e-08,  7.7529e-08,\n             5.1631e-08, -7.2875e-09, -4.1770e-08, -1.3999e-09,  3.7357e-08,\n             4.5496e-08,  1.3633e-08,  4.5457e-08,  3.9136e-08, -2.2374e-08,\n            -2.0656e-09,  6.0200e-08,  1.2068e-07,  4.8656e-08, -1.4179e-07,\n            -1.1116e-07, -1.0531e-08, -9.1205e-08, -6.2861e-08, -1.1321e-07,\n            -9.2140e-08, -2.6592e-08,  3.3994e-10, -6.4238e-08,  1.0828e-08,\n            -1.7015e-08,  1.1539e-07,  3.1507e-08,  4.2237e-08, -7.9460e-08,\n             2.1953e-09,  2.0560e-07,  1.7609e-09,  1.0078e-08, -7.8762e-08,\n             3.8491e-08,  1.3328e-07,  6.3554e-08,  3.2668e-08, -1.5904e-07,\n             5.0847e-08, -1.7034e-07, -1.2072e-08,  2.4605e-08,  1.3785e-07,\n             9.4136e-08,  4.5396e-08, -4.3511e-08,  1.4199e-07, -1.5842e-08,\n             9.4460e-08,  3.1214e-08, -3.0706e-08,  8.9980e-08, -1.7850e-09,\n            -5.8351e-08, -4.7433e-08,  1.3696e-08,  5.7585e-08,  8.2702e-09,\n             1.7534e-08,  1.9025e-08,  4.2843e-08,  9.5646e-10, -6.5613e-08,\n            -2.9133e-08, -1.0204e-07, -1.8548e-07, -7.5299e-08,  8.0081e-08,\n             7.8465e-08,  8.2157e-08,  1.6021e-08,  3.8624e-08, -1.2801e-07,\n            -4.7659e-08,  1.6381e-08, -4.0720e-08, -2.4720e-08, -1.5696e-07,\n             9.9376e-08, -1.2148e-07,  1.7158e-08, -1.1343e-07, -1.5746e-07,\n            -2.1829e-08,  6.6748e-08,  1.1541e-07, -8.4760e-08, -1.2038e-08,\n             3.0958e-08, -2.6508e-08,  1.6270e-08,  3.5320e-08,  9.5320e-08,\n             2.1547e-08,  9.8824e-09, -8.4260e-08, -6.3825e-08, -5.0364e-09,\n             6.8556e-08,  4.2989e-08, -1.6158e-08, -4.5696e-08,  6.3196e-08,\n            -2.1600e-08, -7.1491e-08,  1.5341e-07,  1.5564e-08, -1.2736e-07,\n             1.2199e-07,  8.1722e-10,  1.0944e-08,  2.0939e-08, -4.9813e-08,\n            -5.9364e-08,  3.1374e-08, -3.1188e-08,  1.2318e-07, -5.0732e-08,\n            -9.3153e-08,  1.3907e-08,  4.3265e-08, -1.5745e-07,  6.1555e-08,\n             3.3657e-08, -1.2718e-07, -7.0713e-08,  1.5583e-07, -6.3638e-08,\n            -1.5590e-07, -1.2139e-08,  4.2474e-08,  2.5997e-09, -5.3714e-08,\n             5.1798e-08, -7.8366e-08, -7.2034e-09, -8.1877e-08, -1.7710e-08,\n            -1.8069e-07, -3.1588e-08,  4.3293e-08,  1.2298e-07, -5.0253e-08,\n             1.0846e-07,  2.3882e-07, -1.8868e-08, -3.9288e-08,  6.6471e-08,\n             2.6118e-09, -9.4304e-08,  8.6164e-08, -2.0452e-08, -1.0754e-07,\n             3.3808e-08, -2.2643e-08, -2.8211e-08, -5.6534e-08, -1.6775e-08,\n             5.8890e-09, -1.1462e-07,  3.3197e-08,  7.6436e-08, -1.4568e-08,\n             5.0294e-08,  6.5588e-09, -3.2841e-08,  1.4410e-10, -1.5913e-07,\n            -3.1762e-08,  6.5121e-08,  1.4218e-07,  8.0021e-08,  4.5450e-08,\n             3.8493e-08,  7.8604e-08, -8.6669e-09,  2.8294e-08,  5.3148e-09,\n             9.1022e-08, -2.6469e-08, -3.7746e-08,  5.9298e-08, -6.2859e-08,\n             3.3552e-08, -9.5108e-08,  1.0806e-07, -1.0406e-07, -7.3259e-08,\n             1.5244e-08,  3.7245e-08,  4.4565e-08, -3.3661e-08, -1.2160e-07,\n             4.0371e-08, -8.6433e-08, -1.8694e-08,  1.3154e-07, -8.9237e-08,\n            -6.5085e-08,  4.4269e-08, -1.4367e-07,  9.3724e-08,  6.2423e-08,\n             7.1495e-08,  2.5225e-08, -9.9425e-08, -1.4953e-07,  1.0161e-07,\n             4.8654e-08,  4.4585e-08,  3.6794e-08,  4.0158e-10,  1.2920e-07,\n            -1.0677e-07,  1.4768e-08, -9.9383e-08,  4.7683e-08, -1.3472e-07,\n             3.5372e-08, -4.9470e-08,  1.0314e-07, -7.5997e-09,  3.6159e-09,\n            -1.0066e-07, -2.8517e-08,  2.9178e-08,  1.4083e-07,  2.0994e-07,\n             7.8803e-09,  2.7371e-08, -1.0348e-07, -2.6460e-08, -6.5095e-08,\n            -1.2526e-07,  9.4982e-08, -3.1979e-08,  7.7018e-08,  9.6961e-08,\n             7.7561e-08, -1.9675e-08,  4.2405e-08, -2.2897e-08,  3.3024e-08,\n            -3.4846e-08,  5.6719e-08,  6.7169e-08,  9.6945e-08, -6.9454e-08,\n            -7.7389e-08,  3.5143e-08, -7.5991e-08, -3.4762e-08,  4.3384e-08,\n             5.1023e-08,  3.0539e-08,  2.0699e-08, -8.8645e-08,  4.3966e-08,\n             6.9383e-08, -1.7473e-08, -3.5992e-08, -1.0273e-07,  9.5419e-08,\n            -8.6081e-08, -6.5127e-09,  4.0297e-08,  7.4582e-08,  2.5873e-09,\n             7.4114e-08,  6.7844e-09]),\n    'exp_avg_sq': tensor([9.2957e-14, 9.8837e-14, 1.2417e-13, 8.7184e-14, 8.7302e-14, 1.1250e-13,\n            8.5347e-14, 1.2814e-13, 1.0100e-13, 9.7962e-14, 9.2307e-14, 1.0155e-13,\n            9.6224e-14, 9.5067e-14, 1.0665e-13, 1.5112e-13, 1.1979e-13, 8.9417e-14,\n            8.7885e-14, 7.9932e-14, 1.6976e-13, 1.5408e-13, 1.0522e-13, 1.0423e-13,\n            1.2115e-13, 9.2960e-14, 9.7468e-14, 7.2949e-14, 7.6929e-14, 9.2236e-14,\n            1.1254e-13, 1.4305e-13, 1.1804e-13, 8.3683e-14, 1.1057e-13, 1.0679e-13,\n            1.2912e-13, 9.0478e-14, 9.6606e-14, 1.0916e-13, 1.2513e-13, 1.0259e-13,\n            1.4172e-13, 8.8968e-14, 8.5924e-14, 1.1896e-13, 1.0465e-13, 1.0399e-13,\n            1.0658e-13, 8.2790e-14, 9.5495e-14, 1.3108e-13, 9.8185e-14, 9.5500e-14,\n            8.8488e-14, 1.2123e-13, 1.2792e-13, 1.0383e-13, 6.5725e-14, 1.1445e-13,\n            1.1115e-13, 1.0506e-13, 9.9930e-14, 9.7576e-14, 8.2754e-14, 9.7249e-14,\n            1.0881e-13, 9.6963e-14, 9.0384e-14, 9.9964e-14, 9.6070e-14, 1.0828e-13,\n            1.1170e-13, 8.8942e-14, 1.0454e-13, 1.1280e-13, 9.4017e-14, 1.0400e-13,\n            1.2760e-13, 1.0090e-13, 8.6897e-14, 9.3765e-14, 1.1974e-13, 1.2433e-13,\n            8.8603e-14, 1.1211e-13, 1.1231e-13, 9.1697e-14, 1.1350e-13, 1.1732e-13,\n            1.1476e-13, 1.1460e-13, 1.1495e-13, 9.6326e-14, 1.9253e-13, 1.4808e-13,\n            9.5610e-14, 1.1286e-13, 1.0849e-13, 1.0381e-13, 9.0899e-14, 1.7277e-13,\n            2.6275e-13, 1.2503e-13, 1.0956e-13, 8.9301e-14, 1.1617e-13, 1.1092e-13,\n            9.9835e-14, 8.9918e-14, 1.4147e-13, 1.2016e-13, 8.4943e-14, 1.3430e-13,\n            1.2074e-13, 1.4791e-13, 9.1323e-14, 9.6422e-14, 1.1111e-13, 1.0883e-13,\n            8.4648e-14, 7.2190e-14, 1.1373e-13, 1.1243e-13, 9.5436e-14, 1.0084e-13,\n            7.2666e-14, 1.4151e-13, 1.4278e-13, 9.5366e-14, 1.0813e-13, 1.0768e-13,\n            9.1157e-14, 1.1825e-13, 1.0528e-13, 9.5080e-14, 1.0221e-13, 1.0989e-13,\n            9.6113e-14, 1.1625e-13, 7.6830e-14, 9.5844e-14, 1.1492e-13, 8.5096e-14,\n            1.0937e-13, 8.7744e-14, 7.7530e-14, 8.1159e-14, 1.0478e-13, 9.4802e-14,\n            1.0353e-13, 1.3268e-13, 8.1359e-14, 1.1448e-13, 1.0086e-13, 1.5240e-13,\n            1.0176e-13, 1.1596e-13, 8.6697e-14, 9.0364e-14, 1.2674e-13, 9.9260e-14,\n            1.1560e-13, 1.0291e-13, 1.1330e-13, 8.7209e-14, 9.9510e-14, 1.3236e-13,\n            8.8987e-14, 9.3170e-14, 8.0174e-14, 1.2037e-13, 9.6869e-14, 1.2509e-13,\n            1.1386e-13, 1.2296e-13, 9.9189e-14, 8.2467e-14, 9.2189e-14, 1.0163e-13,\n            1.6332e-13, 1.2888e-13, 1.3139e-13, 1.1474e-13, 1.2064e-13, 8.0715e-14,\n            1.0937e-13, 1.1457e-13, 9.6092e-14, 1.4348e-13, 1.1198e-13, 8.5820e-14,\n            1.0159e-13, 9.4794e-14, 1.1336e-13, 9.9341e-14, 1.0717e-13, 1.1081e-13,\n            7.3447e-14, 1.2002e-13, 8.9959e-14, 8.5408e-14, 8.8631e-14, 8.7997e-14,\n            1.0087e-13, 9.2038e-14, 1.0310e-13, 7.9697e-14, 1.1137e-13, 8.3561e-14,\n            8.6816e-14, 1.0852e-13, 1.1064e-13, 9.4004e-14, 9.8918e-14, 8.5866e-14,\n            8.4217e-14, 1.2856e-13, 7.5924e-14, 1.0270e-13, 1.1297e-13, 1.2168e-13,\n            8.7668e-14, 1.2095e-13, 9.2232e-14, 9.1871e-14, 9.7813e-14, 9.9282e-14,\n            9.7835e-14, 1.0245e-13, 1.0581e-13, 8.7408e-14, 1.0970e-13, 1.0098e-13,\n            1.1374e-13, 9.4138e-14, 1.1685e-13, 1.4080e-13, 8.7506e-14, 1.2959e-13,\n            9.9840e-14, 1.0258e-13, 1.0674e-13, 1.1142e-13, 1.2076e-13, 1.1769e-13,\n            1.1041e-13, 1.2139e-13, 9.7633e-14, 9.1304e-14, 8.9886e-14, 9.5688e-14,\n            1.2033e-13, 9.1522e-14, 1.3727e-13, 9.7189e-14, 8.2915e-14, 1.0515e-13,\n            1.0764e-13, 1.4281e-13, 8.4742e-14, 8.2006e-14, 1.0212e-13, 1.2262e-13,\n            9.8087e-14, 1.0988e-13, 8.5549e-14, 9.2310e-14, 1.3975e-13, 1.0412e-13,\n            1.0649e-13, 1.0322e-13, 1.1131e-13, 1.0162e-13, 1.2196e-13, 1.0120e-13,\n            1.1458e-13, 9.3795e-14, 1.0348e-13, 9.1852e-14, 8.6095e-14, 1.3118e-13,\n            1.0822e-13, 1.1992e-13, 1.2721e-13, 1.3687e-13, 1.0005e-13, 1.2037e-13,\n            9.8410e-14, 8.4542e-14, 9.6515e-14, 8.7050e-14, 1.1066e-13, 1.0723e-13,\n            8.4743e-14, 1.2617e-13, 1.1233e-13, 7.0492e-14, 9.6721e-14, 9.3540e-14,\n            1.2027e-13, 1.1688e-13, 1.3620e-13, 9.0031e-14, 1.1370e-13, 1.1043e-13,\n            1.1200e-13, 1.0506e-13, 1.0575e-13, 9.8252e-14, 1.0016e-13, 7.2949e-14,\n            9.3998e-14, 9.4231e-14, 7.2605e-14, 7.9172e-14, 8.6866e-14, 1.1258e-13,\n            9.4466e-14, 9.4694e-14, 7.3392e-14, 8.1219e-14, 9.3781e-14, 1.2926e-13,\n            1.2234e-13, 1.1465e-13, 1.0548e-13, 9.6477e-14, 1.0083e-13, 1.0423e-13,\n            9.3995e-14, 1.1201e-13, 1.2529e-13, 9.8167e-14, 1.0056e-13, 9.4179e-14,\n            9.1460e-14, 9.2873e-14, 1.0160e-13, 8.3381e-14, 9.0926e-14, 9.1928e-14,\n            1.0015e-13, 1.0807e-13, 7.9096e-14, 1.0040e-13, 1.0824e-13, 1.3885e-13,\n            9.5287e-14, 1.0094e-13, 1.0388e-13, 9.2396e-14, 9.9401e-14, 1.1886e-13,\n            8.8302e-14, 9.4830e-14, 9.7830e-14, 1.1345e-13, 8.6996e-14, 1.0432e-13,\n            1.0029e-13, 1.0222e-13, 1.0288e-13, 8.3846e-14, 1.0092e-13, 9.9356e-14,\n            1.2053e-13, 9.7586e-14, 9.2881e-14, 7.8265e-14, 1.2820e-13, 1.5472e-13,\n            1.0471e-13, 1.0215e-13, 1.0000e-13, 1.1045e-13, 1.0941e-13, 7.0040e-14,\n            1.2932e-13, 9.8857e-14, 1.4225e-13, 1.3657e-13, 8.8252e-14, 9.0869e-14,\n            1.1424e-13, 1.0342e-13, 9.5946e-14, 1.0726e-13, 8.0092e-14, 1.0671e-13,\n            1.3621e-13, 1.2866e-13, 8.1651e-14, 1.0267e-13, 9.9723e-14, 9.0605e-14,\n            1.1575e-13, 1.2589e-13, 8.8344e-14, 1.0113e-13, 9.4087e-14, 1.0019e-13,\n            1.0420e-13, 1.1292e-13, 9.3558e-14, 9.6046e-14, 1.1581e-13, 1.2908e-13,\n            1.2468e-13, 9.9937e-14, 1.3571e-13, 1.2661e-13, 1.4016e-13, 8.3365e-14,\n            8.8100e-14, 8.9539e-14, 1.0110e-13, 9.9331e-14, 1.2177e-13, 1.0432e-13,\n            1.0203e-13, 8.7981e-14, 1.0525e-13, 8.7560e-14, 8.6222e-14, 1.0514e-13,\n            1.1582e-13, 1.0466e-13, 1.0061e-13, 9.5483e-14, 1.0321e-13, 9.3575e-14,\n            9.1964e-14, 1.3449e-13, 9.2878e-14, 1.2376e-13, 1.0217e-13, 9.0112e-14,\n            1.1504e-13, 9.5267e-14, 1.4472e-13, 9.2559e-14, 1.0454e-13, 1.0137e-13,\n            1.0056e-13, 1.1592e-13, 1.0393e-13, 9.8699e-14, 9.3183e-14, 9.3155e-14,\n            9.3919e-14, 1.2659e-13, 9.1462e-14, 1.1826e-13, 1.1599e-13, 8.5497e-14,\n            7.9071e-14, 1.0324e-13, 8.2218e-14, 8.2851e-14, 1.0127e-13, 9.1397e-14,\n            8.9214e-14, 1.1473e-13, 9.1840e-14, 1.0005e-13, 1.1585e-13, 1.0760e-13,\n            9.8530e-14, 1.1895e-13, 1.3650e-13, 1.2042e-13, 6.5844e-14, 7.8826e-14,\n            1.0086e-13, 1.1986e-13, 8.9834e-14, 1.1157e-13, 1.0587e-13, 1.1347e-13,\n            1.1795e-13, 1.0869e-13, 8.6511e-14, 1.1649e-13, 8.4308e-14, 1.1059e-13,\n            1.0814e-13, 1.0655e-13, 1.5220e-13, 1.0160e-13, 1.1815e-13, 9.4595e-14,\n            1.0043e-13, 6.9676e-14, 7.5460e-14, 1.0450e-13, 1.2529e-13, 1.1723e-13,\n            1.0314e-13, 1.0100e-13, 1.1308e-13, 1.0275e-13, 7.8859e-14, 1.0183e-13,\n            9.5969e-14, 1.2232e-13, 8.5519e-14, 1.1183e-13, 9.2203e-14, 1.1405e-13,\n            1.1141e-13, 1.0860e-13])},\n   88: {'exp_avg': tensor([-5.3540e-08,  8.9596e-09, -2.9142e-07,  5.0566e-08,  1.2626e-07,\n             1.0864e-08, -2.8541e-08,  1.2741e-07, -2.8507e-08,  7.4674e-08,\n             5.0516e-08, -5.2702e-08,  3.9731e-08, -6.0547e-08,  1.8890e-07,\n            -1.5937e-08,  1.3237e-07, -2.9118e-08, -8.8148e-08,  4.8063e-08,\n             1.7085e-08, -1.1143e-07, -1.1040e-07,  7.7437e-10, -1.7439e-08,\n             1.9239e-07,  3.2915e-08, -3.5861e-08,  5.9321e-08, -5.7040e-08,\n             3.0332e-09, -1.1147e-07,  1.8232e-07, -1.6191e-07,  7.4575e-08,\n             9.6327e-08,  1.1923e-07,  1.0730e-08, -3.2077e-08, -2.4590e-07,\n             1.0591e-07, -1.6548e-07,  2.7991e-08, -3.5757e-08, -1.8231e-07,\n             1.4662e-07,  1.5519e-09,  6.7150e-09,  2.9837e-08, -8.2845e-08,\n            -1.1088e-07, -8.1533e-08, -5.5555e-08, -2.6464e-08, -9.7515e-08,\n             5.4897e-08, -3.8982e-08, -3.2869e-09, -3.5060e-08, -1.2868e-07,\n             1.0729e-07,  5.9563e-08,  9.2219e-08,  1.7462e-07, -1.0772e-08,\n             7.7094e-09, -5.2532e-08, -4.9028e-08, -4.3608e-08, -1.4024e-07,\n             1.1478e-07,  5.2789e-08,  9.5077e-09, -5.1065e-08, -4.4517e-08,\n            -1.9339e-08, -1.4727e-08,  5.6508e-08, -2.4709e-08,  1.5109e-07,\n             1.0840e-07, -6.4494e-09,  5.6787e-08, -4.0629e-08,  2.1358e-08,\n            -1.9931e-08, -6.6256e-08,  9.0450e-08, -5.6916e-08, -4.9495e-08,\n            -1.4863e-08, -8.7127e-08, -5.8417e-08,  6.5065e-08,  1.8707e-08,\n             8.6278e-08,  1.6270e-08,  6.8692e-08,  8.4975e-08,  6.4736e-08,\n            -1.9650e-07,  1.1203e-08, -3.8260e-08, -1.5541e-09,  6.3398e-08,\n             3.3973e-08, -4.1975e-09, -1.0740e-08, -1.4370e-08, -6.0651e-08,\n            -3.0498e-08,  2.0071e-08, -1.0019e-07, -2.7365e-08,  2.3341e-08,\n            -1.0508e-07, -4.3748e-08, -5.3783e-09, -1.1990e-07, -4.0498e-08,\n            -4.8988e-10,  1.3034e-07, -1.3878e-07, -4.0112e-08,  1.7044e-07,\n            -9.5334e-09,  5.3573e-08, -1.4760e-07, -8.8288e-09,  1.9862e-07,\n             6.0792e-08, -5.2712e-08,  2.2524e-07,  1.9160e-08,  9.1853e-08,\n             3.4098e-08, -8.1834e-08, -1.8747e-07, -1.8184e-07, -6.9431e-08,\n             3.1430e-08, -1.0439e-07,  4.3131e-08, -7.4004e-08, -3.2914e-08,\n            -1.9092e-07, -5.3428e-08, -1.2118e-09, -7.9023e-08, -1.2982e-07,\n            -4.9063e-09,  6.6839e-08,  2.2256e-08,  1.9905e-07, -1.1235e-07,\n             3.1156e-07,  5.2452e-08, -1.1877e-08,  5.7495e-08,  1.9766e-09,\n            -1.2337e-08, -2.1665e-07, -8.4128e-08, -3.1036e-08, -3.5433e-08,\n             5.1414e-08,  7.9049e-08,  3.2736e-08,  2.9574e-08,  2.2333e-08,\n            -3.9592e-09,  7.3712e-08,  6.5013e-08, -1.4231e-07, -3.2058e-08,\n            -5.0811e-09,  1.8946e-07, -2.8655e-08, -2.4315e-08,  2.3919e-08,\n             1.0860e-07, -3.9877e-08, -7.5360e-08, -2.1456e-08, -1.5217e-07,\n            -1.0463e-07, -9.4028e-08, -8.4468e-08,  1.0801e-07, -6.3810e-08,\n             4.2104e-08, -6.1556e-08, -1.3628e-07,  7.2511e-08, -8.6519e-08,\n            -1.5955e-07,  7.9188e-08,  7.8675e-08,  1.3018e-08, -4.6312e-08,\n             8.7165e-09, -1.2522e-07, -6.9349e-08, -1.3331e-07,  5.4553e-08,\n             1.0523e-07, -5.4746e-09,  6.6275e-08,  3.2608e-08,  8.5814e-08,\n            -2.5643e-07, -1.0283e-07,  1.8151e-08,  1.1036e-08, -1.4478e-07,\n             7.5290e-08,  2.1116e-08, -3.1857e-08,  6.0673e-08, -1.0414e-07,\n             8.6756e-08,  1.1081e-07,  2.9585e-08,  1.1062e-07,  1.9466e-07,\n            -5.2470e-08,  1.9722e-08, -1.1399e-07,  6.5950e-08,  2.3499e-08,\n            -1.6280e-07,  1.2964e-07, -1.8315e-08, -6.9390e-08,  3.3473e-08,\n             1.6572e-07,  2.1464e-07, -1.3782e-07,  1.8653e-07,  1.5046e-07,\n            -7.0423e-08,  3.8527e-09,  2.9023e-08,  1.7193e-07,  9.6154e-08,\n            -6.7361e-08,  4.6033e-08,  9.8940e-08, -1.5872e-07, -4.0996e-08,\n             5.5128e-08,  7.3448e-09,  3.9838e-09, -6.0631e-08, -6.5199e-08,\n             1.0086e-08,  4.3384e-08, -2.0902e-08,  7.9271e-08,  1.1546e-07,\n             7.1494e-08, -1.6226e-07, -1.6846e-07,  9.2343e-08,  5.6025e-08,\n             5.7381e-09, -3.2509e-08,  8.0375e-08, -1.4479e-08,  2.5458e-08,\n             1.1961e-07, -3.8602e-08,  5.3680e-08,  3.8895e-09, -2.2063e-07,\n            -4.0995e-09,  1.0093e-08,  1.2924e-08,  4.8963e-08,  2.3157e-08,\n            -5.1725e-08, -8.3307e-08,  1.3065e-07, -5.6547e-08, -8.2228e-08,\n            -8.4116e-10, -1.0666e-07, -1.0812e-08, -3.3838e-09,  6.7664e-08,\n             1.0717e-07, -9.1937e-08,  1.2326e-07, -5.0195e-08,  7.0752e-09,\n             2.9164e-08,  1.0010e-07, -9.3178e-08, -1.4886e-08,  2.9140e-08,\n             4.9089e-09, -1.3876e-09, -5.2864e-08, -8.7012e-08, -1.0178e-07,\n            -4.4179e-08, -6.1611e-08, -4.0463e-08,  4.0037e-08,  3.4807e-08,\n             5.1856e-08,  2.1035e-08, -2.0614e-07,  3.3751e-08,  2.5634e-08,\n             7.4769e-08,  9.7674e-08,  1.3283e-08, -1.0488e-07, -1.4320e-07,\n             5.1999e-08, -1.2081e-08, -2.2131e-08,  1.2109e-08,  9.1374e-09,\n             6.6410e-08,  5.8617e-08, -1.4025e-08,  3.8507e-08, -7.6939e-08,\n             9.7225e-08,  1.3015e-07, -4.4515e-08, -1.0293e-07, -1.2151e-08,\n            -5.3606e-08,  1.6490e-07, -5.3282e-09,  2.0185e-08,  4.0274e-08,\n             1.1007e-07,  7.7865e-08, -1.5140e-07, -2.3813e-08,  8.8115e-08,\n             1.2426e-07, -3.2383e-08, -7.8165e-08, -1.6198e-08, -5.7279e-08,\n            -6.7838e-08,  1.8149e-07,  5.6057e-08, -1.2015e-07,  1.7402e-07,\n             3.3490e-08,  1.0472e-07,  8.0896e-08,  2.2859e-08, -1.7837e-08,\n            -1.4118e-07, -5.0596e-09,  8.8631e-08,  1.8146e-08, -2.4344e-08,\n            -6.2106e-08, -3.3935e-09,  1.5392e-09, -9.8197e-08, -1.9307e-08,\n             1.3994e-09, -4.4192e-08,  1.6983e-08,  8.5757e-10, -5.7271e-08,\n             2.2820e-08,  1.4548e-09,  4.6457e-08,  3.1115e-08,  8.3601e-08,\n            -4.2078e-08,  1.4519e-07,  1.0387e-07, -4.5468e-08,  1.1644e-07,\n            -1.1451e-07, -2.1398e-07,  4.4075e-08, -7.2714e-08,  1.1781e-07,\n            -1.1893e-07,  1.2188e-07, -1.9300e-08, -1.8626e-08, -1.0384e-08,\n            -1.6345e-07, -1.2530e-08,  9.1032e-08,  9.3253e-08,  4.8795e-08,\n            -6.4386e-08, -9.1841e-08, -7.1795e-08,  9.7815e-08, -1.4029e-09,\n             1.9177e-07,  2.2028e-08,  1.7660e-07,  4.0324e-09,  1.7422e-07,\n            -6.8405e-08,  2.8722e-08,  1.9122e-07, -3.8236e-08, -1.1986e-08,\n             1.4149e-07,  1.0025e-09,  3.7397e-08, -3.8773e-08, -2.7137e-08,\n             4.4724e-08, -1.3177e-08, -3.2569e-08, -1.2378e-07, -1.4342e-07,\n            -1.3305e-07,  1.9494e-08, -3.0011e-08,  6.1151e-08, -6.3482e-08,\n            -4.6345e-08,  9.5884e-09, -8.3399e-08,  3.0494e-08, -1.7037e-07,\n            -9.4827e-08,  1.0521e-07, -2.3072e-08, -4.3185e-08, -8.6878e-08,\n            -1.4508e-08, -1.2890e-07, -5.2473e-08, -2.9510e-08, -7.5256e-08,\n             3.7032e-08,  8.4582e-08, -1.0457e-07, -4.6732e-08,  1.7027e-08,\n            -1.6685e-08, -2.4831e-08,  1.0331e-08,  6.1032e-08,  7.6330e-09,\n            -1.0775e-07, -5.0856e-08, -7.7143e-08, -4.0417e-08,  9.5479e-09,\n             4.5805e-11,  8.2154e-08, -1.3632e-07, -1.5106e-07, -2.1155e-08,\n             3.0141e-08,  8.2719e-08, -8.5727e-08,  1.5391e-07, -1.2267e-08,\n             2.1859e-08, -5.3890e-08,  1.5703e-07,  7.9505e-08,  6.4554e-08,\n             6.4228e-08, -1.5046e-08,  5.7687e-08, -5.6522e-08, -1.3347e-07,\n             1.1643e-09, -1.3515e-08, -1.7425e-07,  1.7600e-08,  3.9227e-08,\n             1.0828e-07,  1.5344e-07,  2.7000e-08,  2.4805e-07,  1.0991e-07,\n            -3.0195e-08, -2.0267e-07,  5.5420e-08,  7.2683e-08, -4.1275e-08,\n             1.1863e-07,  1.3173e-07, -2.2409e-08,  6.1986e-08, -8.1949e-08,\n            -5.8152e-08, -6.3889e-08, -2.8580e-08,  2.2113e-08,  4.2106e-08,\n             1.1634e-07,  4.4128e-08, -4.1068e-08,  8.5524e-08,  8.5787e-08,\n            -4.1610e-08, -5.8594e-08]),\n    'exp_avg_sq': tensor([1.2007e-13, 1.2845e-13, 2.2007e-13, 8.0207e-14, 1.1475e-13, 9.7279e-14,\n            1.5208e-13, 1.2522e-13, 1.1617e-13, 1.9092e-13, 1.1091e-13, 1.0762e-13,\n            1.1380e-13, 2.3194e-13, 1.0291e-13, 1.5451e-13, 1.1118e-13, 9.5744e-14,\n            1.0129e-13, 1.2140e-13, 1.1200e-13, 1.5249e-13, 1.2221e-13, 1.5669e-13,\n            1.3516e-13, 1.2448e-13, 1.3222e-13, 1.4643e-13, 1.1966e-13, 1.0614e-13,\n            1.4329e-13, 1.0510e-13, 1.4003e-13, 1.0716e-13, 1.5297e-13, 1.0139e-13,\n            1.0184e-13, 1.0118e-13, 1.1375e-13, 1.1421e-13, 1.5594e-13, 1.4504e-13,\n            1.0340e-13, 4.9271e-14, 1.7921e-13, 1.4153e-13, 1.5314e-13, 1.9818e-13,\n            1.1298e-13, 1.1217e-13, 1.3045e-13, 1.2315e-13, 1.4463e-13, 1.1054e-13,\n            1.8925e-13, 1.3149e-13, 1.4322e-13, 1.4298e-13, 1.0567e-13, 1.1729e-13,\n            1.0865e-13, 9.6018e-14, 7.4851e-14, 1.4284e-13, 9.7395e-14, 1.2112e-13,\n            8.4513e-14, 1.5283e-13, 1.0770e-13, 9.6869e-14, 9.7705e-14, 7.7559e-14,\n            1.2967e-13, 1.6618e-13, 7.5489e-14, 1.0374e-13, 1.1731e-13, 1.3003e-13,\n            1.7543e-13, 1.4852e-13, 1.1190e-13, 9.1616e-14, 1.2348e-13, 1.3879e-13,\n            1.5452e-13, 1.0495e-13, 1.2784e-13, 1.3004e-13, 1.7907e-13, 8.9102e-14,\n            1.5919e-13, 1.3388e-13, 1.1186e-13, 7.7609e-14, 1.3678e-13, 1.1629e-13,\n            1.9260e-13, 1.6198e-13, 1.1379e-13, 1.2453e-13, 1.1356e-13, 1.1653e-13,\n            1.2274e-13, 1.1726e-13, 1.1454e-13, 1.2374e-13, 1.2795e-13, 1.4007e-13,\n            1.2816e-13, 1.0254e-13, 1.1777e-13, 1.2963e-13, 1.9642e-13, 9.6423e-14,\n            1.2151e-13, 8.3625e-14, 1.2747e-13, 9.4657e-14, 1.3749e-13, 1.0760e-13,\n            1.6508e-13, 1.2372e-13, 1.5915e-13, 1.0234e-13, 9.9794e-14, 1.2557e-13,\n            9.5941e-14, 1.4273e-13, 1.1201e-13, 1.1616e-13, 1.3387e-13, 1.2185e-13,\n            1.2236e-13, 1.0196e-13, 1.0767e-13, 1.0474e-13, 1.0612e-13, 1.0414e-13,\n            1.5428e-13, 7.2491e-14, 8.6224e-14, 1.1648e-13, 1.1911e-13, 1.7238e-13,\n            1.2342e-13, 1.2944e-13, 9.6668e-14, 7.9293e-14, 1.2734e-13, 1.0081e-13,\n            1.1033e-13, 1.1182e-13, 1.1377e-13, 1.0404e-13, 9.6760e-14, 1.1306e-13,\n            1.0083e-13, 1.1048e-13, 9.0746e-14, 1.3938e-13, 1.1023e-13, 1.5272e-13,\n            1.6054e-13, 1.1597e-13, 9.2137e-14, 1.4210e-13, 8.3018e-14, 1.1689e-13,\n            1.2567e-13, 1.5236e-13, 1.0115e-13, 1.1349e-13, 1.2625e-13, 1.0698e-13,\n            1.3315e-13, 1.0548e-13, 2.3721e-13, 1.1523e-13, 1.2347e-13, 1.5265e-13,\n            1.4415e-13, 1.5227e-13, 1.2313e-13, 1.2466e-13, 1.3645e-13, 1.2222e-13,\n            1.2826e-13, 1.1364e-13, 1.3917e-13, 1.0883e-13, 1.2653e-13, 1.4063e-13,\n            1.3872e-13, 9.1056e-14, 1.1780e-13, 1.8068e-13, 1.8869e-13, 1.2997e-13,\n            1.9945e-13, 1.0612e-13, 1.2190e-13, 1.5346e-13, 1.5476e-13, 1.0185e-13,\n            1.2576e-13, 1.3598e-13, 1.3295e-13, 8.4647e-14, 1.1431e-13, 1.3141e-13,\n            1.5342e-13, 1.4435e-13, 9.6885e-14, 9.4531e-14, 1.0755e-13, 2.0240e-13,\n            9.9648e-14, 1.0238e-13, 9.7026e-14, 1.4831e-13, 1.7467e-13, 1.4892e-13,\n            1.1570e-13, 1.2282e-13, 1.9448e-13, 1.3888e-13, 5.8107e-14, 1.1641e-13,\n            1.2168e-13, 9.8935e-14, 1.1275e-13, 1.3547e-13, 1.2240e-13, 1.8234e-13,\n            1.3305e-13, 1.3651e-13, 1.5427e-13, 8.3356e-14, 1.0324e-13, 1.3329e-13,\n            1.4637e-13, 1.3379e-13, 1.3358e-13, 1.4876e-13, 1.2697e-13, 1.1548e-13,\n            2.2421e-13, 1.4995e-13, 1.8722e-13, 1.2052e-13, 1.2711e-13, 1.3590e-13,\n            1.0529e-13, 2.1425e-13, 9.0941e-14, 1.5323e-13, 1.1719e-13, 1.8526e-13,\n            6.8997e-14, 2.0387e-13, 2.1416e-13, 1.4141e-13, 1.2530e-13, 1.1281e-13,\n            1.2122e-13, 1.2840e-13, 1.3769e-13, 8.7816e-14, 1.0132e-13, 1.1187e-13,\n            9.7592e-14, 1.7023e-13, 1.4208e-13, 1.2334e-13, 1.2676e-13, 1.1591e-13,\n            1.0474e-13, 1.4859e-13, 1.2551e-13, 7.6580e-14, 1.3251e-13, 1.1849e-13,\n            1.5232e-13, 1.3434e-13, 1.2638e-13, 2.0859e-13, 1.1393e-13, 1.4865e-13,\n            1.3820e-13, 1.4030e-13, 1.6238e-13, 1.3662e-13, 1.2531e-13, 1.2450e-13,\n            1.5158e-13, 1.5928e-13, 1.5967e-13, 1.9655e-13, 1.3990e-13, 1.2547e-13,\n            1.1720e-13, 9.3712e-14, 1.1338e-13, 1.5735e-13, 7.0197e-14, 8.4529e-14,\n            1.6688e-13, 1.0859e-13, 1.1761e-13, 9.3559e-14, 1.1510e-13, 9.3147e-14,\n            1.8840e-13, 1.7454e-13, 9.2293e-14, 1.3095e-13, 1.3333e-13, 8.2916e-14,\n            1.0633e-13, 9.7112e-14, 1.1642e-13, 1.5601e-13, 1.2125e-13, 1.6224e-13,\n            1.1492e-13, 1.3799e-13, 1.3279e-13, 1.0642e-13, 1.2848e-13, 1.0949e-13,\n            1.5514e-13, 8.9633e-14, 1.0974e-13, 7.6281e-14, 1.3408e-13, 1.4981e-13,\n            7.3742e-14, 1.1157e-13, 2.1730e-13, 7.0047e-14, 1.0442e-13, 1.1987e-13,\n            1.0373e-13, 1.4115e-13, 1.5367e-13, 1.2838e-13, 1.7683e-13, 1.4124e-13,\n            1.2656e-13, 1.3971e-13, 9.1103e-14, 1.3920e-13, 1.7707e-13, 9.7479e-14,\n            1.9031e-13, 1.4365e-13, 1.7192e-13, 1.0812e-13, 1.3451e-13, 1.2580e-13,\n            1.4568e-13, 1.2506e-13, 1.2855e-13, 1.4535e-13, 1.2606e-13, 1.1928e-13,\n            8.3664e-14, 1.2271e-13, 1.2455e-13, 1.3721e-13, 1.3377e-13, 1.2508e-13,\n            1.2592e-13, 1.3184e-13, 1.4052e-13, 1.4798e-13, 1.2520e-13, 1.2928e-13,\n            1.0071e-13, 4.8183e-14, 1.4516e-13, 3.1071e-13, 1.1662e-13, 1.3129e-13,\n            1.0180e-13, 1.2254e-13, 1.2938e-13, 1.3469e-13, 1.0616e-13, 1.3518e-13,\n            1.3479e-13, 1.6372e-13, 1.4285e-13, 1.3602e-13, 1.1780e-13, 1.2608e-13,\n            1.2984e-13, 1.4536e-13, 5.6431e-14, 1.2224e-13, 9.7603e-14, 1.2016e-13,\n            1.3886e-13, 1.7396e-13, 1.0766e-13, 1.0463e-13, 8.9909e-14, 1.5648e-13,\n            1.1298e-13, 1.4130e-13, 1.2643e-13, 1.3727e-13, 9.3560e-14, 1.2830e-13,\n            1.1543e-13, 1.2774e-13, 1.6954e-13, 1.1474e-13, 9.9321e-14, 1.8374e-13,\n            1.8159e-13, 9.1925e-14, 1.1605e-13, 1.5578e-13, 1.1674e-13, 9.9490e-14,\n            1.3805e-13, 1.2555e-13, 9.0087e-14, 1.5567e-13, 1.1378e-13, 8.2336e-14,\n            1.7529e-13, 1.0353e-13, 1.2038e-13, 8.9558e-14, 1.2422e-13, 1.3919e-13,\n            1.1466e-13, 1.2115e-13, 1.0021e-13, 1.3594e-13, 1.1035e-13, 8.7269e-14,\n            1.3647e-13, 1.1062e-13, 9.6927e-14, 1.3306e-13, 1.2652e-13, 1.0627e-13,\n            1.8504e-13, 9.1235e-14, 1.4926e-13, 1.0537e-13, 9.4573e-14, 1.4889e-13,\n            1.0988e-13, 1.3525e-13, 8.6937e-14, 8.8386e-14, 1.0574e-13, 1.2357e-13,\n            1.2483e-13, 1.4553e-13, 1.1111e-13, 1.4248e-13, 8.1015e-14, 1.3530e-13,\n            1.3908e-13, 2.3667e-13, 1.0712e-13, 7.0111e-14, 1.3694e-13, 9.8191e-14,\n            1.5436e-13, 1.1319e-13, 1.1732e-13, 1.1660e-13, 1.4225e-13, 2.2724e-13,\n            1.4950e-13, 1.3050e-13, 1.6080e-13, 1.4859e-13, 9.9333e-14, 8.4916e-14,\n            1.5451e-13, 1.3103e-13, 1.5156e-13, 1.4056e-13, 1.0768e-13, 2.5119e-13,\n            1.7347e-13, 1.4974e-13, 1.6241e-13, 1.1117e-13, 1.4919e-13, 1.0122e-13,\n            9.7320e-14, 1.6588e-13, 1.1522e-13, 1.2181e-13, 9.6246e-14, 1.8631e-13,\n            1.1896e-13, 1.3117e-13, 8.7937e-14, 1.4895e-13, 1.4395e-13, 1.0187e-13,\n            1.4342e-13, 2.9303e-13])},\n   89: {'exp_avg': tensor([-2.4700e-08, -3.6139e-08,  2.0208e-08,  7.1557e-08, -6.8508e-09,\n            -3.7408e-08, -7.0063e-08,  3.1092e-08, -3.9534e-08,  2.4512e-08,\n             1.0515e-07, -1.2680e-08,  7.0538e-08, -1.4121e-08,  9.6943e-08,\n             2.7405e-08,  6.3753e-08,  6.1811e-09, -3.4827e-08, -2.4254e-08,\n             2.3369e-08, -4.3942e-08, -8.4329e-08, -1.1617e-08,  3.7357e-08,\n             6.3708e-08,  1.5603e-08, -2.7384e-08, -6.5135e-09, -1.3468e-07,\n            -2.2097e-08,  1.3916e-08,  6.8848e-08, -1.1838e-07,  7.3180e-08,\n             5.3597e-08,  1.4799e-07, -2.4340e-08, -2.4286e-08, -2.1867e-07,\n             9.5554e-09, -4.6891e-08,  1.6622e-08, -4.4743e-09, -8.5419e-08,\n             5.2736e-08,  2.5648e-08,  5.2182e-08, -2.1797e-08, -9.7680e-08,\n            -7.9430e-09, -7.5950e-08, -2.5076e-08, -2.7292e-08, -1.1237e-07,\n            -1.9430e-08,  3.9138e-10,  6.5303e-08,  2.7959e-08, -1.1033e-07,\n             9.4788e-08,  5.6418e-08,  1.3009e-07,  4.8528e-08, -1.3648e-08,\n             1.3183e-08, -2.1302e-08,  2.4027e-08, -4.8730e-08, -4.2079e-08,\n             1.4103e-08,  3.9231e-08,  3.6970e-08, -1.0192e-08, -5.9731e-08,\n             2.0415e-08, -1.5831e-08, -5.7578e-08, -4.9036e-08,  6.5231e-08,\n            -6.8158e-10,  5.6838e-08,  7.4614e-08,  2.4876e-08,  4.4410e-08,\n             2.4726e-08,  3.8254e-08,  5.1713e-08, -4.1181e-08, -4.8758e-08,\n            -8.8752e-08, -7.4077e-10, -3.6384e-08,  2.5198e-08,  5.8660e-08,\n             1.0020e-07,  3.3447e-08, -1.9212e-08,  7.2611e-08,  9.9179e-08,\n            -1.1020e-07,  3.4663e-08, -2.7901e-08,  3.8429e-09,  3.0056e-08,\n             4.6205e-08,  3.3316e-08, -3.9315e-08, -1.3386e-08, -3.2302e-08,\n             2.4429e-08,  3.5258e-08, -5.7326e-08,  4.4245e-08, -1.3045e-08,\n            -1.9068e-08, -5.5260e-08,  4.4112e-08, -5.2861e-08,  4.6318e-08,\n            -2.1475e-08,  5.3671e-08, -4.9639e-08, -4.5557e-08,  6.3681e-08,\n             4.1437e-09,  5.6416e-08, -8.6867e-08, -3.5149e-08,  1.0013e-07,\n             4.0040e-08, -6.3015e-08,  1.0869e-07, -1.8790e-10,  6.5721e-08,\n            -1.2332e-08, -9.6109e-08, -1.2785e-07, -1.7492e-07, -1.6653e-08,\n             2.6033e-09, -3.7192e-08, -6.7471e-08, -5.5612e-08,  3.0817e-08,\n            -9.3374e-08, -1.5608e-08, -2.6709e-08,  8.5502e-09, -6.8023e-08,\n            -4.5978e-08,  5.8810e-08,  2.9697e-09,  1.1948e-07, -1.0223e-07,\n             1.3843e-07,  4.4675e-08,  2.8273e-08,  5.3942e-08,  8.3370e-09,\n            -3.8147e-08, -2.1943e-07, -3.8467e-08, -3.0451e-09, -1.3572e-08,\n             1.8776e-09,  2.9880e-08,  4.5080e-08,  3.6009e-08, -8.8614e-08,\n            -3.0644e-09, -1.1126e-08,  1.4181e-07, -3.0890e-08, -1.7619e-08,\n             3.5592e-08,  1.0941e-07, -2.4686e-08, -7.6630e-08,  2.7864e-08,\n             6.5933e-08, -3.3423e-08,  3.7759e-09, -5.9280e-08, -9.9941e-08,\n            -4.5302e-08, -1.0592e-07, -2.2556e-08,  1.2978e-07, -2.7878e-08,\n             5.4745e-08, -1.2718e-09, -4.6882e-08,  6.7011e-08, -2.5640e-09,\n            -9.0448e-08,  5.1768e-08,  1.2614e-07, -1.3428e-08, -5.3047e-08,\n             6.0387e-09, -1.1121e-07, -7.5858e-08, -5.5666e-08,  8.1498e-08,\n             8.7604e-09,  5.4970e-09,  7.0721e-08,  2.8793e-08,  4.9968e-08,\n            -1.9788e-07, -7.3914e-09,  7.1290e-09,  7.8054e-08, -1.3894e-07,\n             1.3294e-07, -7.9093e-08, -2.6200e-08,  1.9749e-08, -5.3273e-09,\n            -4.3027e-08, -1.8541e-09, -4.4817e-08,  1.0040e-07,  3.1207e-08,\n             3.2732e-08, -7.4538e-10, -6.8985e-08,  1.1839e-07, -1.6484e-08,\n            -1.2726e-07,  7.6787e-08, -6.5071e-08, -6.0130e-08,  4.5412e-08,\n             1.2245e-07,  5.5573e-08, -1.0573e-09,  1.2185e-07,  6.1614e-08,\n            -1.5664e-08,  4.7326e-08,  1.3642e-08,  1.3640e-07,  8.2215e-08,\n            -4.4927e-08,  5.2506e-08,  9.5627e-08, -2.2921e-07, -2.5654e-08,\n             1.7700e-08,  7.4660e-09, -6.6625e-09,  1.5450e-09, -4.7371e-08,\n            -3.6393e-08, -1.6784e-08, -7.4910e-10,  8.8963e-08,  6.1409e-08,\n             1.0208e-09, -1.2820e-07, -1.4689e-07,  3.9397e-08,  5.9907e-08,\n             3.4920e-08,  7.6651e-08,  5.8138e-08,  2.8827e-09,  9.0433e-08,\n             9.8637e-08,  2.2891e-08,  5.5431e-08,  5.0209e-08, -1.3498e-07,\n             5.5210e-08,  1.6417e-08, -1.2362e-07,  2.8145e-08,  3.2813e-09,\n             4.9470e-08, -1.1309e-07,  4.1998e-08, -3.2833e-08, -7.8119e-08,\n            -9.6176e-08, -3.8028e-08,  3.5083e-09, -2.7176e-09, -4.5458e-08,\n            -3.5135e-08,  2.5114e-08,  6.5672e-08, -4.1274e-08,  1.9610e-08,\n             8.1405e-08,  7.4786e-08,  3.0737e-08, -2.6689e-08,  2.3401e-08,\n             1.6090e-08,  1.6471e-09, -1.3155e-08, -5.4609e-08, -5.6900e-08,\n            -2.1992e-08,  1.3583e-08, -7.5682e-08, -6.9728e-09,  7.1416e-09,\n             3.9274e-08, -9.3091e-09, -1.6576e-07, -3.3110e-08,  2.8779e-08,\n             7.8925e-08,  2.4783e-08, -1.0133e-08, -3.9525e-08, -2.6397e-08,\n             3.4690e-08, -1.0622e-08, -1.2766e-08,  2.3936e-08, -3.9731e-08,\n             6.9321e-08,  4.9197e-09, -2.6505e-08,  1.0653e-07, -3.3080e-08,\n             1.8502e-09,  7.2077e-08, -6.3369e-08, -5.2921e-08, -6.1792e-08,\n            -5.3373e-08,  1.7292e-07, -3.2004e-08,  2.4447e-08,  3.8365e-08,\n             6.2673e-08,  6.7936e-08,  5.0168e-09, -3.9927e-08,  2.7956e-08,\n             9.6981e-08, -2.5933e-08,  6.0139e-08, -1.1761e-08,  7.6213e-09,\n            -1.1372e-09,  4.3353e-08,  1.4261e-08, -5.9150e-08,  3.6948e-08,\n             5.2600e-08,  1.1247e-07,  1.2989e-07,  1.3528e-08, -9.8182e-09,\n            -5.8169e-08, -7.8332e-09,  7.9775e-08, -8.1368e-08, -4.0913e-08,\n            -4.0092e-08,  2.3726e-08, -1.4828e-08, -9.2603e-08, -9.6527e-08,\n            -5.1740e-08,  2.2958e-08,  3.1651e-08, -3.9678e-08, -4.3818e-08,\n             1.2311e-07, -1.8042e-08,  4.2354e-08, -1.6032e-08,  3.7324e-08,\n            -6.4313e-08,  1.0915e-07,  1.2639e-07, -3.0136e-08,  5.7959e-08,\n            -6.1216e-08, -9.8652e-08,  5.8103e-08, -5.1317e-08, -9.0620e-10,\n            -1.0269e-07,  3.6494e-08, -1.0471e-08, -5.5117e-08, -1.0137e-07,\n            -7.7580e-08,  5.6814e-08,  5.5596e-09,  1.1194e-07,  6.7275e-08,\n            -1.2175e-08, -1.1969e-08, -4.8425e-08,  6.7926e-08, -1.1076e-08,\n             1.5421e-07, -3.5694e-08,  8.5460e-08, -1.0252e-08,  6.0371e-08,\n            -1.2856e-07,  1.3075e-08,  1.4161e-07,  4.6018e-09,  4.8175e-08,\n             8.2935e-08, -4.1658e-08, -2.1292e-08, -9.2091e-08,  1.3390e-08,\n             8.1122e-08, -6.4040e-08,  6.9232e-08, -2.6536e-08, -1.0653e-07,\n            -5.7951e-08, -2.1979e-08,  1.5978e-08,  1.3369e-07, -5.6305e-08,\n            -1.9590e-08,  1.2170e-09, -2.5025e-08, -6.7198e-09, -7.8600e-08,\n             1.1091e-08,  8.2385e-08, -8.2653e-08, -1.6001e-08, -3.6351e-08,\n            -4.2148e-09, -7.3565e-08, -5.7379e-08, -2.0392e-08,  5.3392e-09,\n             4.6047e-08,  5.3863e-08, -6.7548e-08,  6.1880e-09,  3.2230e-08,\n            -6.0579e-09,  1.6947e-08,  4.2686e-08, -4.8361e-08, -3.0616e-08,\n            -9.3076e-09, -8.6814e-08,  1.0460e-08, -3.4559e-10, -4.0163e-08,\n             4.6656e-08,  1.1529e-07, -5.6326e-08, -7.0685e-08, -2.5744e-08,\n             2.3972e-08, -6.8385e-09, -1.1696e-07,  6.7109e-08,  5.6381e-08,\n             9.2358e-09, -6.8290e-08,  1.1452e-07,  2.3905e-08, -9.2227e-09,\n             1.5128e-08, -1.0784e-07,  5.4776e-08, -1.0021e-07,  9.3981e-09,\n            -1.6601e-08,  7.5406e-09, -1.8105e-07,  3.5692e-08,  2.9537e-08,\n            -4.5465e-10,  1.0500e-07, -4.1398e-08,  7.2601e-08,  1.4986e-07,\n            -2.1879e-08, -1.7844e-07,  1.6088e-07,  6.8725e-08, -3.5141e-08,\n             1.2315e-07,  3.2617e-08, -4.6066e-08,  2.8934e-08,  2.6523e-08,\n             4.4482e-08, -3.3935e-09, -2.5824e-08,  2.2399e-08,  3.8169e-08,\n             1.0087e-07,  4.5132e-08,  3.2294e-08,  1.1304e-07, -9.3117e-08,\n             2.0187e-08, -8.9112e-08]),\n    'exp_avg_sq': tensor([7.1756e-14, 6.4838e-14, 1.0295e-13, 5.2205e-14, 6.8880e-14, 5.3241e-14,\n            8.9364e-14, 7.3335e-14, 7.2163e-14, 8.6968e-14, 6.7342e-14, 6.2865e-14,\n            7.2678e-14, 9.7150e-14, 6.4025e-14, 7.0311e-14, 6.6152e-14, 5.6860e-14,\n            5.8700e-14, 6.7866e-14, 6.8557e-14, 8.1720e-14, 6.8780e-14, 8.5594e-14,\n            7.8634e-14, 6.8116e-14, 7.8679e-14, 8.4701e-14, 7.2091e-14, 5.6263e-14,\n            8.5484e-14, 6.8120e-14, 7.1088e-14, 6.1050e-14, 8.2319e-14, 6.2031e-14,\n            6.3148e-14, 6.3326e-14, 7.0215e-14, 6.5705e-14, 8.3045e-14, 8.8445e-14,\n            6.2080e-14, 3.1490e-14, 7.9586e-14, 7.6079e-14, 8.9415e-14, 8.2469e-14,\n            7.5192e-14, 5.7160e-14, 7.6631e-14, 6.1657e-14, 7.5214e-14, 6.7512e-14,\n            9.1332e-14, 7.7599e-14, 8.1301e-14, 8.4903e-14, 5.7893e-14, 7.0975e-14,\n            6.2595e-14, 5.7736e-14, 5.1583e-14, 8.1811e-14, 6.3948e-14, 6.7322e-14,\n            5.3981e-14, 9.4790e-14, 6.1143e-14, 5.3289e-14, 5.9527e-14, 4.7456e-14,\n            6.7827e-14, 8.3565e-14, 4.8242e-14, 5.1199e-14, 7.1632e-14, 7.4966e-14,\n            9.1966e-14, 7.4090e-14, 5.8594e-14, 5.9144e-14, 6.9667e-14, 7.5095e-14,\n            8.8276e-14, 6.9085e-14, 6.7955e-14, 6.7686e-14, 9.1378e-14, 5.8836e-14,\n            8.8722e-14, 6.5735e-14, 6.8335e-14, 5.3935e-14, 7.8033e-14, 6.3418e-14,\n            1.0228e-13, 7.8976e-14, 6.5551e-14, 7.8035e-14, 7.3171e-14, 6.6517e-14,\n            6.8860e-14, 7.5294e-14, 5.8124e-14, 8.0408e-14, 6.6002e-14, 7.4852e-14,\n            6.6719e-14, 5.5989e-14, 7.0498e-14, 7.1084e-14, 8.5417e-14, 5.7862e-14,\n            6.5341e-14, 5.3883e-14, 6.8817e-14, 5.6413e-14, 7.4803e-14, 6.8317e-14,\n            7.4923e-14, 7.2583e-14, 8.2868e-14, 6.3188e-14, 6.2181e-14, 7.0596e-14,\n            5.4075e-14, 7.3249e-14, 6.5033e-14, 7.1152e-14, 7.0549e-14, 6.7423e-14,\n            6.3559e-14, 6.7689e-14, 7.1730e-14, 6.1950e-14, 6.5218e-14, 6.6363e-14,\n            9.7365e-14, 4.7307e-14, 5.0634e-14, 6.2808e-14, 7.2761e-14, 8.9718e-14,\n            7.0694e-14, 7.0140e-14, 5.8889e-14, 4.6940e-14, 7.6959e-14, 6.4021e-14,\n            6.5436e-14, 6.6163e-14, 6.6257e-14, 6.2752e-14, 6.0089e-14, 5.8738e-14,\n            7.3967e-14, 7.3394e-14, 5.5745e-14, 7.9440e-14, 6.7812e-14, 8.4554e-14,\n            8.2709e-14, 7.3080e-14, 5.7218e-14, 7.7093e-14, 5.4253e-14, 6.8010e-14,\n            7.2247e-14, 7.8962e-14, 6.6729e-14, 6.3584e-14, 6.8663e-14, 6.3022e-14,\n            8.3367e-14, 5.8795e-14, 1.0704e-13, 7.3167e-14, 6.9484e-14, 8.1656e-14,\n            7.8358e-14, 7.5450e-14, 7.7487e-14, 6.9552e-14, 8.3884e-14, 7.7614e-14,\n            7.1147e-14, 6.7240e-14, 7.7414e-14, 6.4425e-14, 6.9026e-14, 8.2780e-14,\n            7.3779e-14, 5.3924e-14, 7.1489e-14, 8.3943e-14, 8.7639e-14, 7.4733e-14,\n            9.1979e-14, 7.1216e-14, 7.0904e-14, 8.7349e-14, 8.3135e-14, 6.2886e-14,\n            6.9464e-14, 6.3100e-14, 6.3999e-14, 5.1995e-14, 7.0817e-14, 6.9235e-14,\n            8.4845e-14, 8.0350e-14, 5.8796e-14, 6.6273e-14, 6.0087e-14, 8.7307e-14,\n            6.0875e-14, 5.7743e-14, 5.6405e-14, 7.8193e-14, 7.8107e-14, 7.4867e-14,\n            6.6646e-14, 7.1060e-14, 9.5084e-14, 7.6795e-14, 4.0476e-14, 6.6783e-14,\n            7.7516e-14, 5.9727e-14, 7.6285e-14, 7.5214e-14, 7.6174e-14, 7.8008e-14,\n            7.4209e-14, 7.6092e-14, 7.0417e-14, 5.1308e-14, 6.5388e-14, 6.6241e-14,\n            8.4120e-14, 6.7812e-14, 7.9893e-14, 9.0568e-14, 7.2340e-14, 7.4739e-14,\n            1.0460e-13, 7.7870e-14, 1.0529e-13, 7.9849e-14, 7.5618e-14, 7.2955e-14,\n            6.7544e-14, 8.8322e-14, 5.4765e-14, 7.9260e-14, 7.3521e-14, 9.5287e-14,\n            4.0442e-14, 8.7762e-14, 9.9593e-14, 7.2899e-14, 7.0085e-14, 6.4875e-14,\n            7.4876e-14, 7.4790e-14, 8.0162e-14, 5.7699e-14, 5.7198e-14, 6.7496e-14,\n            5.4702e-14, 8.0670e-14, 8.5709e-14, 7.1522e-14, 7.3300e-14, 6.5407e-14,\n            5.6606e-14, 6.8494e-14, 7.0158e-14, 4.4623e-14, 6.8248e-14, 6.2234e-14,\n            8.7902e-14, 7.5252e-14, 6.0233e-14, 1.0391e-13, 6.7670e-14, 7.1684e-14,\n            8.1442e-14, 8.2789e-14, 8.2792e-14, 7.2209e-14, 7.0533e-14, 7.1042e-14,\n            7.8125e-14, 7.7071e-14, 8.2997e-14, 9.8710e-14, 7.6734e-14, 6.6807e-14,\n            6.8942e-14, 5.8341e-14, 6.2691e-14, 1.1438e-13, 4.6199e-14, 5.0909e-14,\n            8.4566e-14, 6.4749e-14, 6.9852e-14, 5.7684e-14, 6.8556e-14, 5.9739e-14,\n            9.4078e-14, 1.0195e-13, 5.0506e-14, 6.7760e-14, 7.3113e-14, 5.4220e-14,\n            6.1840e-14, 6.0541e-14, 6.7094e-14, 8.8667e-14, 6.1434e-14, 9.5180e-14,\n            6.4392e-14, 7.7197e-14, 7.8851e-14, 6.3392e-14, 7.5775e-14, 6.6067e-14,\n            7.6276e-14, 5.2896e-14, 7.0910e-14, 5.1263e-14, 7.0949e-14, 9.1274e-14,\n            5.0698e-14, 7.9061e-14, 9.7261e-14, 4.7259e-14, 6.1268e-14, 6.4501e-14,\n            6.2768e-14, 7.3315e-14, 7.5401e-14, 7.6005e-14, 9.0202e-14, 7.3148e-14,\n            7.2643e-14, 9.3053e-14, 5.5904e-14, 7.7162e-14, 1.1631e-13, 5.4357e-14,\n            9.5359e-14, 8.0216e-14, 9.2110e-14, 6.5600e-14, 7.4906e-14, 7.1985e-14,\n            7.8124e-14, 6.9253e-14, 7.4525e-14, 8.1133e-14, 7.1612e-14, 7.5233e-14,\n            4.5715e-14, 7.0599e-14, 7.4294e-14, 7.4471e-14, 6.9471e-14, 6.8222e-14,\n            7.2599e-14, 8.2383e-14, 7.1568e-14, 7.1341e-14, 7.8865e-14, 7.6676e-14,\n            6.3171e-14, 3.3598e-14, 8.2669e-14, 1.2247e-13, 7.1765e-14, 6.8400e-14,\n            5.9079e-14, 7.5541e-14, 6.2876e-14, 7.7528e-14, 6.0089e-14, 6.8939e-14,\n            6.6594e-14, 7.9600e-14, 7.3341e-14, 7.7937e-14, 7.1302e-14, 6.8449e-14,\n            6.7256e-14, 6.3961e-14, 4.1992e-14, 7.0504e-14, 5.8848e-14, 7.1819e-14,\n            7.7278e-14, 9.8162e-14, 6.2632e-14, 6.0305e-14, 5.0001e-14, 8.9198e-14,\n            6.6164e-14, 7.6956e-14, 7.3114e-14, 7.4272e-14, 5.8078e-14, 7.0631e-14,\n            6.8531e-14, 7.7192e-14, 8.9482e-14, 6.1026e-14, 5.9513e-14, 9.7385e-14,\n            8.3115e-14, 5.5295e-14, 6.9077e-14, 9.1058e-14, 6.2482e-14, 5.3868e-14,\n            7.5521e-14, 7.7066e-14, 5.6617e-14, 8.8074e-14, 6.5364e-14, 5.1903e-14,\n            8.8501e-14, 6.8752e-14, 7.2633e-14, 5.5771e-14, 7.2139e-14, 8.3390e-14,\n            6.2931e-14, 7.3804e-14, 6.6495e-14, 7.9860e-14, 6.7733e-14, 5.3112e-14,\n            8.2006e-14, 5.5845e-14, 5.6809e-14, 6.9257e-14, 7.3793e-14, 6.8632e-14,\n            9.1730e-14, 5.6625e-14, 7.7560e-14, 5.7286e-14, 5.7350e-14, 7.9755e-14,\n            7.4052e-14, 8.5551e-14, 5.0685e-14, 6.1795e-14, 6.8262e-14, 6.6331e-14,\n            7.5235e-14, 7.4143e-14, 6.4843e-14, 8.1316e-14, 5.5798e-14, 8.2877e-14,\n            7.3300e-14, 1.0753e-13, 6.3082e-14, 4.8730e-14, 7.0167e-14, 5.9252e-14,\n            7.4774e-14, 6.5811e-14, 6.2670e-14, 6.7573e-14, 8.2183e-14, 1.0721e-13,\n            8.4138e-14, 8.6003e-14, 8.9260e-14, 8.6673e-14, 5.3715e-14, 5.3650e-14,\n            8.2272e-14, 7.0609e-14, 8.9570e-14, 8.2573e-14, 7.1588e-14, 1.0520e-13,\n            8.7569e-14, 7.0982e-14, 7.9734e-14, 5.8469e-14, 8.2310e-14, 6.0163e-14,\n            6.1145e-14, 8.8078e-14, 6.5070e-14, 6.6951e-14, 5.6228e-14, 9.7006e-14,\n            6.3360e-14, 7.6858e-14, 5.8141e-14, 7.1607e-14, 8.1146e-14, 7.2816e-14,\n            8.7814e-14, 1.3477e-13])},\n   90: {'exp_avg': tensor([ 4.2169e-08,  2.2710e-08,  9.6616e-08,  ..., -3.8859e-08,\n            -1.3555e-07,  3.7735e-08]),\n    'exp_avg_sq': tensor([4.2550e-14, 4.3697e-14, 4.8282e-14,  ..., 2.4824e-14, 3.7953e-14,\n            4.5035e-14])},\n   91: {'exp_avg': tensor([-2.2475e-08, -7.5927e-08, -1.9598e-08,  ...,  5.2987e-09,\n             4.4225e-09,  2.1426e-08]),\n    'exp_avg_sq': tensor([5.2945e-14, 4.5095e-14, 5.3437e-14,  ..., 2.6900e-14, 5.7211e-14,\n            7.5023e-14])},\n   92: {'exp_avg': tensor([-1.9477e-08, -1.0193e-07, -5.7740e-08,  ..., -5.2850e-08,\n            -9.3597e-09, -1.0396e-09]),\n    'exp_avg_sq': tensor([4.6464e-14, 4.6719e-14, 5.2840e-14,  ..., 2.7811e-14, 4.6883e-14,\n            6.5056e-14])},\n   93: {'exp_avg': tensor([-2.2475e-08, -7.5927e-08, -1.9598e-08,  ...,  5.2987e-09,\n             4.4225e-09,  2.1426e-08]),\n    'exp_avg_sq': tensor([5.2945e-14, 4.5095e-14, 5.3437e-14,  ..., 2.6900e-14, 5.7211e-14,\n            7.5023e-14])},\n   94: {'exp_avg': tensor([ 4.9353e-08,  1.0610e-08, -4.6337e-08,  3.0756e-07, -1.2679e-07,\n            -9.1276e-08, -7.2055e-08,  3.6414e-09, -1.9954e-08, -1.2450e-07,\n            -4.2250e-08,  4.9136e-08,  8.3042e-08, -2.2671e-08,  6.8664e-08,\n             2.2780e-08,  8.5372e-09,  1.8192e-07, -6.4945e-08, -1.2943e-07,\n            -6.8050e-08,  4.9427e-08, -1.6413e-08, -1.2104e-08,  7.4275e-08,\n             5.1999e-08,  3.1915e-08,  1.7921e-07, -6.6811e-08,  8.5296e-08,\n            -1.6938e-07, -5.8065e-08,  8.6739e-08,  1.6901e-07, -2.2093e-08,\n             7.0579e-08,  3.9766e-09,  4.1660e-08,  2.3860e-09, -2.4347e-08,\n             9.6950e-08, -1.5762e-07, -4.1195e-09,  9.5750e-08,  2.1486e-08,\n             5.0341e-08,  5.2362e-09, -6.1814e-08,  4.7759e-08,  8.7279e-08,\n             1.1781e-07,  1.0736e-07,  8.8257e-08,  6.7143e-08,  5.4010e-08,\n             9.6264e-08,  1.9505e-08,  1.2630e-07,  3.4092e-07, -1.2681e-07,\n             5.5968e-08,  1.7174e-07, -2.9371e-08, -6.3202e-08,  2.3574e-08,\n            -2.6300e-08, -9.8365e-08, -4.2115e-08,  2.3289e-07, -8.3503e-08,\n             1.1423e-07,  4.3341e-08,  8.4536e-08,  1.1624e-07, -7.9290e-08,\n             3.6036e-08,  7.8372e-08,  1.4899e-08, -1.2563e-07,  1.4391e-07,\n             4.6842e-10, -4.3395e-08,  1.1817e-07, -2.1947e-08,  7.1361e-08,\n            -5.1514e-08, -6.7941e-08, -5.4187e-08,  7.3960e-08, -1.5896e-07,\n            -5.5124e-08, -5.6727e-08,  3.1525e-08,  5.6509e-09, -1.8633e-07,\n            -3.5649e-08,  2.0449e-08, -6.8786e-09,  1.6941e-07, -1.2371e-07,\n            -6.4665e-09,  3.0963e-08, -2.3958e-08,  1.7322e-07, -1.1808e-07,\n             9.3897e-08, -3.9096e-08, -1.1021e-08,  7.0889e-09, -6.3731e-10,\n            -5.8351e-08,  1.1308e-07, -2.8470e-08, -3.1666e-08, -3.2304e-08,\n            -3.7797e-08,  4.1879e-08,  9.1692e-09, -4.1858e-10, -9.1167e-08,\n            -4.8581e-08,  2.4503e-07, -7.5505e-09,  7.4734e-08, -1.1435e-07,\n             1.1737e-08,  7.8816e-08, -2.9475e-08, -1.3620e-07,  1.0026e-07,\n            -6.1694e-08, -8.1522e-08, -5.9015e-08, -1.7331e-08,  2.2489e-08,\n            -7.1496e-08, -1.3906e-07,  1.7859e-07, -3.8716e-08, -6.5416e-08,\n            -2.7288e-08, -2.2228e-08, -3.3164e-08,  1.3298e-08, -1.5765e-08,\n             1.5823e-08, -2.7717e-09, -3.6521e-08, -3.6503e-08,  5.8252e-08,\n             5.2133e-08, -2.1655e-07,  8.2086e-08,  4.9834e-08,  3.7153e-08,\n            -1.3165e-07,  3.0905e-08,  5.7733e-08,  1.4560e-08, -2.0497e-07,\n             1.4645e-07, -1.5110e-07,  1.4669e-07,  4.5253e-08,  1.5182e-08,\n            -1.8293e-08,  4.0972e-08,  1.9114e-07,  1.8164e-07,  5.1254e-08,\n            -7.3058e-08, -2.7312e-08,  9.5874e-08, -8.1142e-08,  1.3091e-07,\n            -2.7220e-08,  7.8670e-08,  1.6116e-07, -5.0173e-08,  1.0498e-07,\n            -4.1229e-08, -3.0653e-08,  5.0975e-09,  1.1085e-07,  9.8993e-08,\n            -2.3875e-08,  3.1569e-08,  9.3067e-08, -1.1131e-07,  1.2816e-08,\n            -1.5092e-07,  2.5295e-07, -5.0844e-08, -1.9640e-08,  1.2340e-07,\n            -9.6366e-08,  5.9412e-08,  2.0871e-07,  4.7192e-08, -6.2221e-08,\n             7.8920e-08,  6.7975e-09, -2.0323e-08,  9.4375e-08,  4.1895e-08,\n             1.7694e-07, -5.7887e-09,  7.6911e-08,  7.2188e-08,  4.9708e-09,\n            -8.3113e-08,  4.6785e-08, -1.0329e-07, -1.8113e-07,  2.1417e-08,\n             4.2636e-08, -4.5877e-08, -2.1118e-07, -1.4665e-07,  8.9478e-08,\n            -1.2136e-07, -3.9470e-08,  5.4118e-08, -4.9464e-08, -8.6987e-08,\n             1.1611e-07,  1.3504e-08, -5.7674e-08, -8.7124e-08,  2.1333e-08,\n             2.9725e-07,  1.7017e-08, -1.2547e-08,  2.0373e-07, -1.8445e-08,\n             3.9563e-08, -3.5141e-08,  3.6356e-08,  8.7652e-08, -8.0040e-08,\n            -6.1678e-08,  7.0798e-08, -5.1536e-08, -9.1290e-08,  7.1091e-08,\n            -1.1314e-07,  1.0303e-07, -6.5029e-09, -4.6467e-08,  4.0847e-07,\n             7.1411e-08, -1.3306e-07, -2.9722e-09, -1.1831e-07, -2.7198e-07,\n            -8.2583e-08,  1.6657e-07,  9.1412e-08, -9.1125e-09, -5.2570e-08,\n             3.1203e-08, -2.8477e-08, -4.5212e-08, -1.7796e-08,  6.7849e-08,\n            -3.2180e-07, -1.4598e-08,  7.7315e-08,  1.5019e-07,  2.2498e-08,\n            -1.3134e-07,  1.2615e-08, -1.6989e-07,  4.6998e-08, -1.3843e-07,\n             1.9810e-08,  4.9138e-08, -3.7284e-08,  5.8070e-08,  5.7848e-08,\n            -3.4268e-08,  1.1264e-07, -9.5125e-08, -1.6868e-07, -1.3025e-07,\n            -9.5635e-08,  4.4478e-08, -1.0469e-07, -6.1961e-08, -7.0021e-08,\n            -5.7003e-09, -4.9393e-08,  7.6238e-08, -4.2125e-08,  1.2318e-07,\n            -5.8520e-08, -1.6804e-07, -9.0649e-08,  2.4026e-08, -1.4754e-08,\n            -4.9719e-09,  1.0792e-07,  6.2559e-08, -1.5161e-08, -7.1464e-08,\n            -1.4387e-07, -1.1935e-07,  1.0000e-07,  4.8576e-08,  9.2111e-08,\n             5.4876e-08, -7.9347e-08, -1.4296e-08,  6.4194e-08,  8.0765e-08,\n             4.6998e-08,  7.2468e-08,  3.9541e-08, -2.0920e-07, -6.9389e-08,\n            -9.3925e-08,  6.8333e-08, -9.9603e-08, -2.6409e-07, -8.8561e-08,\n            -8.2648e-08, -2.0099e-07, -2.3799e-08,  3.8129e-08,  1.2443e-07,\n             4.1187e-08, -9.5116e-08,  4.9186e-08, -6.9759e-08, -4.2050e-08,\n             1.4961e-08,  1.1659e-07, -9.1762e-08,  2.4118e-08, -1.1085e-07,\n            -1.3966e-08,  1.7675e-07,  1.8273e-07, -1.1782e-07, -1.8652e-07,\n            -1.5657e-08,  1.4965e-07,  2.6480e-08, -5.9871e-08, -3.9763e-09,\n             1.7827e-08,  4.9614e-08,  1.7698e-07,  5.3743e-08,  8.8609e-08,\n            -1.1740e-07,  4.7978e-09,  1.0675e-07,  9.5595e-08,  6.6924e-09,\n            -1.0362e-07,  2.2515e-08,  2.1144e-09,  1.2638e-08,  4.5226e-08,\n             1.1900e-07, -1.9548e-07, -1.1215e-07, -2.3087e-08, -2.2282e-08,\n             6.6611e-08, -2.1335e-08,  2.4093e-08, -4.0537e-08, -3.4085e-08,\n             5.4603e-08, -2.4006e-08,  1.9616e-08, -8.6201e-08,  4.2400e-08,\n             1.2839e-07,  8.7193e-08, -2.3160e-08, -3.3931e-08, -1.1823e-07,\n             1.0944e-07, -5.9684e-08, -3.4346e-08, -4.9558e-08, -9.2359e-08,\n             2.9444e-07, -8.6835e-08,  1.4652e-08,  1.1174e-08,  1.1682e-07,\n             1.8949e-07,  3.5642e-08, -1.3531e-07, -1.1467e-07, -2.0687e-07,\n            -3.2280e-07, -1.5195e-08, -9.5902e-08,  1.3691e-07, -2.1152e-08,\n            -3.8371e-08,  2.4965e-08, -1.4743e-08, -5.8984e-09, -1.1611e-07,\n             1.6289e-07,  8.4211e-08, -3.9897e-08, -1.1283e-07, -1.0929e-07,\n             1.1932e-07,  1.2115e-07,  1.0787e-07,  2.0789e-07, -1.2969e-07,\n            -4.3247e-08, -2.7142e-09,  2.9938e-07,  6.7270e-08,  4.1559e-09,\n            -1.4903e-07, -7.9981e-08, -6.0376e-08, -1.8178e-07,  5.5182e-08,\n             9.8085e-10,  7.4545e-08, -4.1903e-08,  5.1624e-08, -1.5667e-07,\n            -6.4988e-09, -4.0379e-08, -4.4024e-08,  9.9127e-08,  7.5871e-08,\n             1.1963e-07, -1.1694e-07, -6.5045e-08,  6.8316e-08, -2.8518e-08,\n            -2.6218e-08,  6.9027e-08,  9.9778e-08, -3.4041e-08, -7.5932e-08,\n            -3.0952e-08, -1.1735e-07, -1.4917e-08, -5.1713e-08, -4.8121e-08,\n            -6.6651e-08, -1.5135e-07, -3.0113e-07,  3.6210e-08, -6.6525e-09,\n             5.2759e-08, -1.1154e-07,  1.4663e-07,  1.1991e-08,  5.9722e-08,\n             1.7394e-07,  1.0749e-07,  8.4126e-08, -3.0544e-09, -1.6384e-08,\n            -1.1718e-08,  2.8675e-08, -1.0413e-07,  3.0068e-08,  6.5157e-09,\n            -1.7066e-07, -2.0173e-08,  9.6948e-10,  1.2033e-08,  1.2607e-07,\n             1.8461e-07,  6.6591e-08, -4.2543e-08, -6.7554e-08, -8.0611e-08,\n            -1.5974e-08, -3.4827e-08,  1.5028e-09, -4.3084e-08, -2.3510e-08,\n            -8.2514e-08, -4.7296e-08, -4.9264e-08,  3.3299e-08, -1.4616e-07,\n             1.4764e-07,  5.0691e-08, -1.0573e-07,  8.1837e-09, -7.1560e-08,\n             1.4848e-07, -6.0602e-08, -3.9520e-08, -3.1787e-08,  2.3989e-08,\n            -9.2027e-08,  7.0371e-08,  1.0230e-07, -3.9483e-08, -1.0488e-07,\n            -2.1176e-07, -1.0375e-07]),\n    'exp_avg_sq': tensor([1.6503e-13, 2.2695e-13, 1.7236e-13, 5.0322e-13, 4.0129e-13, 1.6945e-13,\n            1.2207e-13, 1.8504e-13, 1.2986e-13, 1.8511e-13, 1.7299e-13, 2.2465e-13,\n            1.7558e-13, 2.5961e-13, 2.5982e-13, 2.1359e-13, 1.3234e-13, 1.6238e-13,\n            2.1821e-13, 2.0901e-13, 2.4034e-13, 1.2760e-13, 2.0099e-13, 1.8917e-13,\n            2.1914e-13, 1.5214e-13, 1.6499e-13, 1.6367e-13, 2.0380e-13, 1.6144e-13,\n            2.3126e-13, 1.4128e-13, 1.5236e-13, 1.6933e-13, 1.6246e-13, 2.7325e-13,\n            1.9274e-13, 1.5110e-13, 1.8544e-13, 2.3444e-13, 1.5263e-13, 1.5403e-13,\n            1.2200e-13, 2.0452e-13, 1.6837e-13, 2.0304e-13, 1.7469e-13, 1.6361e-13,\n            1.5047e-13, 2.2195e-13, 1.6962e-13, 1.0790e-13, 1.4526e-13, 1.7075e-13,\n            2.2823e-13, 3.5628e-13, 1.6380e-13, 2.2064e-13, 3.7062e-13, 1.8405e-13,\n            1.5395e-13, 1.6220e-13, 1.9477e-13, 1.8556e-13, 1.4308e-13, 2.0160e-13,\n            1.9057e-13, 1.9133e-13, 2.2849e-13, 2.1632e-13, 1.5848e-13, 2.1390e-13,\n            1.6938e-13, 1.4708e-13, 1.5515e-13, 1.7636e-13, 1.8865e-13, 1.5410e-13,\n            1.6092e-13, 2.3799e-13, 1.5625e-13, 1.5167e-13, 1.9786e-13, 1.3102e-13,\n            1.9045e-13, 1.5458e-13, 1.9368e-13, 1.4490e-13, 1.9324e-13, 1.6834e-13,\n            2.0148e-13, 1.3335e-13, 2.3701e-13, 1.5741e-13, 1.7163e-13, 1.6959e-13,\n            2.0599e-13, 1.6410e-13, 1.8801e-13, 2.0350e-13, 1.7989e-13, 1.6959e-13,\n            2.8467e-13, 1.6580e-13, 1.3561e-13, 1.7568e-13, 1.4737e-13, 2.0749e-13,\n            1.5961e-13, 1.7694e-13, 2.7745e-13, 1.6954e-13, 1.8062e-13, 1.4349e-13,\n            1.5553e-13, 1.3721e-13, 1.6473e-13, 1.9752e-13, 1.4974e-13, 1.9985e-13,\n            1.2234e-13, 1.5565e-13, 1.5962e-13, 1.5609e-13, 1.6323e-13, 1.6643e-13,\n            2.1970e-13, 1.6484e-13, 2.0342e-13, 4.8911e-13, 2.8683e-13, 1.5057e-13,\n            1.9081e-13, 1.8555e-13, 1.3240e-13, 1.5005e-13, 1.4454e-13, 1.5666e-13,\n            1.6520e-13, 1.8847e-13, 1.6960e-13, 1.7214e-13, 1.3253e-13, 1.4317e-13,\n            1.7812e-13, 1.3639e-13, 1.5212e-13, 1.8414e-13, 1.7962e-13, 1.3798e-13,\n            1.5567e-13, 2.3345e-13, 1.6544e-13, 1.6535e-13, 2.0713e-13, 1.4350e-13,\n            1.5562e-13, 1.7669e-13, 1.8151e-13, 1.8922e-13, 1.6526e-13, 1.5381e-13,\n            2.2509e-13, 2.2917e-13, 2.6501e-13, 2.8806e-13, 2.5467e-13, 1.4986e-13,\n            2.4446e-13, 1.9578e-13, 1.7227e-13, 2.1990e-13, 1.6002e-13, 4.2138e-13,\n            2.3436e-13, 1.6247e-13, 2.0842e-13, 1.6064e-13, 2.5063e-13, 2.1858e-13,\n            1.8613e-13, 2.1105e-13, 1.5408e-13, 1.3261e-13, 1.4451e-13, 1.9282e-13,\n            1.2931e-13, 1.4030e-13, 2.2565e-13, 1.7874e-13, 2.1677e-13, 2.2010e-13,\n            1.6337e-13, 3.3263e-13, 1.6643e-13, 1.2265e-13, 1.5115e-13, 3.2433e-13,\n            1.4574e-13, 2.0242e-13, 2.4351e-13, 2.4643e-13, 2.0256e-13, 1.4070e-13,\n            1.5218e-13, 2.0943e-13, 1.5510e-13, 2.1359e-13, 1.4305e-13, 1.2590e-13,\n            1.9482e-13, 2.4474e-13, 1.7747e-13, 4.9389e-13, 1.4549e-13, 1.6589e-13,\n            1.9939e-13, 2.3008e-13, 1.8007e-13, 2.3152e-13, 1.8393e-13, 1.8829e-13,\n            1.1873e-13, 2.2191e-13, 1.7488e-13, 1.3823e-13, 1.4200e-13, 1.8937e-13,\n            1.6183e-13, 1.3462e-13, 2.1429e-13, 1.1848e-13, 1.4751e-13, 2.4622e-13,\n            1.9261e-13, 1.3413e-13, 1.8991e-13, 1.6848e-13, 1.7282e-13, 1.6914e-13,\n            1.7882e-13, 1.3123e-13, 1.6566e-13, 1.7549e-13, 1.8450e-13, 2.8118e-13,\n            1.1844e-13, 1.4989e-13, 2.1287e-13, 3.0439e-13, 2.0005e-13, 1.9658e-13,\n            1.6885e-13, 1.6850e-13, 1.9463e-13, 2.1734e-13, 1.5548e-13, 2.0383e-13,\n            1.7903e-13, 1.7735e-13, 1.5014e-13, 1.1835e-13, 1.4066e-13, 1.6618e-13,\n            1.4639e-13, 2.0942e-13, 2.1343e-13, 1.9546e-13, 1.7132e-13, 1.2851e-13,\n            2.1943e-13, 1.8904e-13, 1.7239e-13, 1.1267e-13, 2.4823e-13, 1.4682e-13,\n            1.9558e-13, 2.0326e-13, 2.2332e-13, 1.7053e-13, 1.5479e-13, 1.8192e-13,\n            1.5697e-13, 1.3768e-13, 1.6663e-13, 1.5639e-13, 1.9847e-13, 1.8563e-13,\n            1.6494e-13, 2.1349e-13, 2.0152e-13, 1.6805e-13, 1.3889e-13, 1.5742e-13,\n            1.4687e-13, 2.8594e-13, 2.1204e-13, 1.6215e-13, 1.4513e-13, 1.9707e-13,\n            1.7602e-13, 1.5738e-13, 1.3260e-13, 1.0015e-13, 1.3418e-13, 2.1918e-13,\n            1.7537e-13, 1.7715e-13, 4.3023e-13, 1.4503e-13, 1.9321e-13, 1.8952e-13,\n            2.1859e-13, 2.0743e-13, 4.4290e-13, 1.5933e-13, 1.5569e-13, 1.5010e-13,\n            2.1003e-13, 2.9112e-13, 1.6580e-13, 1.9968e-13, 2.7926e-13, 1.5918e-13,\n            2.0036e-13, 1.6228e-13, 2.0000e-13, 2.4271e-13, 1.7371e-13, 2.2637e-13,\n            1.7537e-13, 1.3234e-13, 1.7618e-13, 1.9894e-13, 2.0160e-13, 2.6461e-13,\n            1.9610e-13, 1.7928e-13, 1.6149e-13, 2.1803e-13, 1.3322e-13, 1.5442e-13,\n            1.5346e-13, 1.7782e-13, 1.4545e-13, 1.5478e-13, 1.5481e-13, 1.4343e-13,\n            1.7354e-13, 1.9365e-13, 1.8061e-13, 1.6062e-13, 1.5497e-13, 1.4031e-13,\n            1.9388e-13, 1.6647e-13, 1.6248e-13, 2.3896e-13, 2.2412e-13, 1.7811e-13,\n            1.5665e-13, 1.8835e-13, 1.4855e-13, 1.7011e-13, 1.3965e-13, 1.7083e-13,\n            2.8347e-13, 1.7369e-13, 1.5825e-13, 1.6658e-13, 1.7033e-13, 2.2761e-13,\n            1.5759e-13, 2.0081e-13, 1.4307e-13, 1.7213e-13, 1.2803e-13, 1.3749e-13,\n            1.3999e-13, 1.9892e-13, 1.6269e-13, 1.9995e-13, 1.4633e-13, 1.9667e-13,\n            1.3975e-13, 1.6642e-13, 2.3039e-13, 1.4343e-13, 1.5291e-13, 1.9196e-13,\n            1.9024e-13, 1.5077e-13, 3.0663e-13, 1.6169e-13, 1.5304e-13, 1.6466e-13,\n            1.8966e-13, 1.5647e-13, 1.7323e-13, 2.4130e-13, 2.3308e-13, 1.6756e-13,\n            1.7155e-13, 1.5237e-13, 1.6743e-13, 1.6155e-13, 2.3000e-13, 1.4039e-13,\n            1.1624e-13, 4.0498e-13, 1.8534e-13, 2.0195e-13, 1.1624e-13, 1.5069e-13,\n            1.4874e-13, 1.8516e-13, 1.5000e-13, 1.8236e-13, 1.8515e-13, 1.8538e-13,\n            1.7479e-13, 1.2428e-13, 1.6154e-13, 1.2407e-13, 1.5511e-13, 1.7814e-13,\n            2.3794e-13, 1.7756e-13, 1.7473e-13, 2.3822e-13, 1.8667e-13, 1.5965e-13,\n            1.5953e-13, 1.7447e-13, 1.7142e-13, 1.3527e-13, 1.6273e-13, 2.5362e-13,\n            1.9903e-13, 1.4191e-13, 1.5944e-13, 1.5895e-13, 2.3776e-13, 1.8411e-13,\n            1.5481e-13, 1.3847e-13, 2.0924e-13, 2.0793e-13, 1.4830e-13, 1.6448e-13,\n            1.6330e-13, 1.8022e-13, 1.4906e-13, 1.5890e-13, 1.4478e-13, 1.5667e-13,\n            1.6397e-13, 1.6726e-13, 2.9683e-13, 1.4906e-13, 1.5420e-13, 1.6657e-13,\n            1.4549e-13, 1.5438e-13, 1.7522e-13, 1.3514e-13, 2.1980e-13, 1.6317e-13,\n            2.3392e-13, 1.5255e-13, 1.6026e-13, 1.8511e-13, 1.5816e-13, 1.5615e-13,\n            2.5597e-13, 2.5067e-13, 1.7452e-13, 2.2697e-13, 1.5099e-13, 2.0271e-13,\n            1.8470e-13, 1.9591e-13, 2.1394e-13, 1.7146e-13, 1.2173e-13, 1.6534e-13,\n            1.8313e-13, 1.5736e-13, 1.5333e-13, 1.3800e-13, 1.2889e-13, 4.5798e-13,\n            1.3251e-13, 1.3523e-13, 1.7751e-13, 2.9901e-13, 1.5966e-13, 1.2208e-13,\n            1.3975e-13, 1.8074e-13, 2.0196e-13, 1.8728e-13, 1.3582e-13, 1.3061e-13,\n            1.9681e-13, 1.7042e-13, 2.9312e-13, 1.8402e-13, 2.1487e-13, 1.3775e-13,\n            2.4362e-13, 1.6069e-13])},\n   95: {'exp_avg': tensor([ 4.0691e-08,  1.3280e-08, -4.2275e-09,  2.1922e-07, -4.4936e-08,\n            -8.2307e-08,  5.1217e-08, -5.1196e-08, -8.6269e-09, -5.3011e-08,\n            -5.9964e-08,  1.7686e-08,  3.2541e-08, -1.2700e-07,  4.9297e-08,\n             1.4411e-08,  4.7785e-08,  8.3561e-08, -5.0787e-08, -7.9942e-08,\n            -9.6348e-10,  8.6122e-08, -9.2818e-08,  9.1537e-08,  3.1585e-08,\n             1.1077e-07, -7.4747e-08,  1.8695e-07,  2.3472e-08,  6.3228e-08,\n             6.6107e-09, -6.4759e-08,  4.1444e-08,  1.2643e-07, -3.6588e-08,\n             9.9951e-08,  4.0978e-08,  3.7840e-08, -3.0698e-08, -6.2044e-08,\n             3.3349e-08, -1.3070e-07, -1.1973e-08,  1.0302e-07, -6.4909e-08,\n             5.4692e-08,  4.8828e-08, -5.2632e-08, -1.0330e-08,  3.7923e-08,\n             8.5698e-08,  1.0085e-07,  7.6795e-08, -7.4598e-08, -3.2474e-09,\n             6.1469e-09,  1.5152e-08,  4.6325e-08,  2.2263e-07, -8.2321e-08,\n            -2.3360e-08,  1.3219e-07, -5.9434e-08,  5.4611e-08,  5.9027e-08,\n            -5.4529e-08, -1.1493e-07, -8.4496e-09,  1.1188e-07,  6.2482e-09,\n             7.0953e-08, -3.2006e-08,  1.4014e-08,  7.0393e-08, -4.8900e-08,\n            -3.3157e-09,  3.3365e-08, -4.9199e-08, -6.0724e-08,  7.3514e-08,\n            -1.8647e-08, -6.5816e-08,  6.9800e-08, -9.2190e-09, -4.5383e-08,\n             7.3158e-09, -1.0027e-07, -8.9160e-08,  1.5342e-07, -3.6132e-08,\n            -4.8789e-08, -4.5753e-08, -3.5339e-08, -2.2269e-08, -1.2161e-07,\n            -1.3929e-09,  1.8523e-08,  3.2529e-08,  5.2981e-08, -1.5347e-08,\n             2.5344e-08,  9.0103e-08,  5.6769e-08,  2.1756e-07, -1.0499e-07,\n             4.3494e-08, -2.8597e-08, -2.3501e-08, -3.0590e-09,  3.7214e-08,\n            -9.4567e-08,  1.3394e-07,  2.6888e-08,  3.5728e-08,  3.3985e-08,\n            -2.0064e-08,  8.4413e-09,  7.9589e-08, -2.2532e-08, -2.9806e-08,\n            -1.0821e-07,  2.1738e-07, -1.8610e-08,  2.0872e-08, -7.8789e-08,\n            -4.6463e-08,  1.6474e-07,  3.9189e-09,  2.5201e-08,  1.7518e-07,\n             7.2420e-08, -1.4817e-08, -1.3586e-07, -1.9106e-08, -2.4042e-08,\n            -6.3985e-08, -1.3494e-07,  1.5426e-07, -8.2525e-08,  2.2820e-08,\n            -5.8230e-08, -3.5592e-08, -3.7965e-08,  3.2480e-08,  3.8504e-08,\n            -9.9954e-09,  3.8958e-08,  5.4462e-08,  2.1711e-08,  2.4687e-08,\n             6.3636e-08, -6.7355e-08,  5.0123e-08,  2.7442e-08,  4.5959e-08,\n            -9.0040e-08,  1.0889e-07,  8.3711e-08,  7.8653e-08, -1.2122e-07,\n             2.5228e-08, -1.3677e-07,  3.7636e-08, -5.0294e-08,  6.9050e-08,\n             4.1110e-08, -3.0732e-08,  1.9984e-07,  9.4079e-08,  1.7700e-08,\n            -4.3469e-08, -2.1063e-08,  1.2006e-07, -1.0693e-08,  5.5857e-08,\n             1.8835e-08,  5.2557e-08,  1.1274e-07, -8.5346e-09,  5.1191e-08,\n            -6.4861e-08, -9.2407e-09, -7.5779e-09,  1.1709e-07,  3.4384e-08,\n            -1.7675e-08, -1.0318e-08,  7.5635e-08,  5.9193e-09,  5.8112e-08,\n            -4.6149e-08,  1.0071e-07, -1.1434e-07, -1.0284e-08,  4.1522e-08,\n            -8.6363e-08,  3.2302e-09,  1.3389e-07,  1.5905e-08, -2.2793e-08,\n             6.8686e-08,  1.1460e-08,  2.8461e-08,  9.9843e-08, -1.5752e-08,\n             1.0224e-07,  3.6460e-08,  6.2698e-09,  4.3135e-08, -4.9112e-09,\n             1.5855e-08,  1.2582e-07, -1.4254e-07, -1.5647e-07,  2.8921e-08,\n             1.3398e-08,  1.7582e-08, -1.0823e-07, -9.5846e-08, -3.7843e-08,\n            -1.2378e-07,  2.1228e-09,  7.5850e-09, -7.2179e-08, -1.3222e-08,\n             8.2253e-08,  5.6647e-08, -1.3633e-07, -2.5490e-08,  4.4398e-08,\n             1.9817e-07, -1.3764e-08, -1.6168e-08,  1.5364e-07, -3.9065e-08,\n             8.4796e-08,  1.5882e-08, -3.7812e-08,  6.7349e-08, -4.6648e-08,\n            -2.2419e-08,  9.7486e-08, -1.2699e-08, -8.0738e-08, -6.3491e-08,\n            -8.1883e-08,  2.6207e-08, -2.3925e-10, -6.7666e-08,  1.8009e-07,\n             6.6776e-08, -7.5340e-08,  2.3381e-08, -1.1641e-07, -2.1972e-07,\n            -6.9950e-08,  3.6127e-08,  5.3735e-08, -2.7891e-08, -8.1854e-08,\n            -3.7631e-08,  4.8484e-08, -5.3636e-09,  9.3066e-09, -5.0622e-08,\n            -1.7187e-07,  3.2971e-08,  6.5007e-08,  5.8484e-08,  8.7817e-08,\n            -5.0374e-08, -5.1830e-09, -1.0383e-07,  1.0104e-08, -2.5628e-08,\n             1.8182e-08,  1.8064e-08, -2.8795e-08,  1.9332e-08,  3.6313e-09,\n            -9.1898e-08,  5.0566e-08, -4.9542e-08, -9.5552e-08, -6.7190e-08,\n            -1.1628e-07,  2.0649e-08, -1.0648e-07, -3.2026e-08, -5.7757e-08,\n             2.7392e-08, -6.0538e-08,  9.3699e-08, -4.2275e-08,  7.0381e-08,\n            -5.1905e-08, -3.0862e-08, -4.2497e-08,  2.9391e-08, -3.5823e-08,\n             3.0976e-08,  9.5203e-08,  4.6403e-08, -2.9939e-08, -6.9739e-08,\n            -1.1905e-08, -3.9910e-08,  3.6387e-09, -2.4589e-08,  4.0738e-08,\n             3.3076e-08, -8.8515e-08, -3.7468e-08,  1.2608e-08,  1.2488e-07,\n             5.1757e-08,  5.5385e-08,  4.6176e-08, -1.4504e-07, -1.4190e-08,\n            -7.1088e-08,  2.3300e-08, -9.8984e-08, -7.8579e-08,  2.9844e-08,\n            -8.8166e-08, -1.0368e-07, -9.0070e-08,  6.8789e-08,  9.6171e-08,\n            -4.4305e-08, -1.3656e-07,  2.1942e-08, -1.0084e-08, -2.4707e-08,\n             1.9048e-08,  8.5966e-08,  1.3371e-08, -2.2946e-08, -8.3430e-08,\n            -8.5461e-09,  1.4436e-07,  1.3191e-07,  5.8802e-09, -1.7104e-07,\n             5.9549e-08,  4.0714e-08,  1.7869e-08, -7.4715e-09,  8.4250e-10,\n             1.0415e-07, -5.5070e-08,  1.9058e-08,  3.9240e-08,  6.1422e-08,\n            -3.4456e-09, -7.3181e-10,  7.3288e-08,  1.3286e-07,  4.2686e-09,\n            -3.3019e-08, -6.8214e-08, -3.5706e-08,  3.3983e-08,  1.6222e-08,\n             2.7236e-08, -9.8895e-08, -8.8660e-08, -2.5413e-08,  2.5181e-09,\n             1.0104e-07, -2.1028e-08, -1.7032e-08, -1.2041e-07, -2.5487e-08,\n             4.4152e-09, -3.3485e-10, -7.1660e-09, -1.0575e-07,  9.1621e-08,\n             1.0799e-07,  4.1264e-08, -2.2062e-08, -7.8210e-09, -7.0556e-08,\n             5.5787e-08,  4.2005e-08, -9.6567e-08, -4.3156e-08, -2.1134e-08,\n             1.8341e-07, -1.6245e-07,  1.0310e-08,  2.3657e-09,  4.4105e-09,\n             1.3639e-07, -3.7397e-08, -5.5646e-08, -4.1396e-08, -1.4751e-07,\n            -1.7194e-07, -2.5131e-08, -7.6662e-08,  1.0137e-07, -2.2149e-08,\n             3.4660e-08,  8.7030e-09,  2.7791e-08, -2.5560e-08, -3.8105e-08,\n             9.4320e-08,  2.8044e-08, -3.0351e-08, -4.3566e-08, -9.5461e-09,\n             1.5039e-07,  1.0108e-07,  5.9091e-08,  2.2786e-07, -2.3470e-08,\n            -3.7796e-08,  1.6670e-08,  1.8341e-07,  9.1461e-08, -1.5854e-08,\n            -2.0999e-08, -2.0332e-09, -5.0583e-08, -1.1657e-07,  8.2620e-08,\n             5.3571e-08,  4.0525e-08, -5.0025e-08,  1.4312e-07, -1.4132e-07,\n            -3.1432e-08, -1.4951e-08, -3.9942e-08,  1.2827e-08,  6.9510e-08,\n             8.4215e-08, -5.8931e-09, -7.9531e-08,  7.0813e-09,  7.9709e-09,\n            -2.3932e-08,  6.4730e-08,  1.2378e-07, -1.1837e-08,  1.9501e-08,\n            -6.4915e-08, -9.0363e-08, -7.6848e-08, -1.9360e-08,  3.3989e-08,\n             7.4207e-09, -4.4497e-08, -1.6485e-07, -8.2520e-09, -3.4437e-08,\n            -2.3693e-08, -3.6989e-08,  1.0038e-07, -9.4003e-08,  1.4430e-08,\n             1.1519e-07, -5.2983e-08, -1.3756e-08,  4.5503e-08,  5.1082e-08,\n             1.3303e-09,  1.5492e-08, -9.6386e-08,  7.7731e-09, -8.3905e-08,\n            -8.5247e-08,  2.0909e-08,  3.2226e-08,  6.4694e-08,  7.3520e-08,\n             1.6759e-07,  1.0241e-07, -7.7907e-09,  7.8014e-10, -7.7251e-08,\n            -2.0503e-08, -1.9406e-08, -4.7692e-08, -4.0046e-08, -4.4569e-08,\n            -3.6550e-08,  6.6568e-08, -9.4403e-08,  6.6057e-08, -1.2538e-07,\n             1.2473e-07,  5.6026e-08, -6.3656e-08,  2.4835e-08, -5.1505e-08,\n             1.3580e-08, -1.1778e-07, -9.0540e-09, -6.7510e-08,  1.1023e-08,\n            -7.1371e-08,  6.8001e-08,  5.7023e-08, -3.6211e-08, -7.7410e-08,\n            -7.7880e-08, -8.2496e-08]),\n    'exp_avg_sq': tensor([1.0478e-13, 1.1484e-13, 9.7558e-14, 1.7447e-13, 1.9203e-13, 1.0278e-13,\n            7.7710e-14, 1.0932e-13, 9.2021e-14, 1.0731e-13, 1.0088e-13, 1.1475e-13,\n            9.9184e-14, 1.2078e-13, 1.5264e-13, 1.1792e-13, 8.3651e-14, 8.4499e-14,\n            1.1478e-13, 1.1579e-13, 1.3238e-13, 8.8153e-14, 1.1198e-13, 9.8573e-14,\n            1.1156e-13, 1.0777e-13, 1.0280e-13, 8.9476e-14, 1.1013e-13, 8.7876e-14,\n            1.2448e-13, 8.2704e-14, 9.5625e-14, 9.6882e-14, 1.0359e-13, 1.2719e-13,\n            1.2092e-13, 1.0298e-13, 1.0382e-13, 1.0937e-13, 9.7472e-14, 9.4185e-14,\n            8.6877e-14, 1.1125e-13, 9.1630e-14, 1.2305e-13, 9.3945e-14, 9.8218e-14,\n            9.8010e-14, 1.1898e-13, 9.6432e-14, 7.9327e-14, 9.3653e-14, 1.0417e-13,\n            1.1338e-13, 1.5183e-13, 1.0334e-13, 1.0934e-13, 1.4213e-13, 1.0049e-13,\n            9.2218e-14, 9.5460e-14, 9.7706e-14, 1.0615e-13, 8.9821e-14, 1.0939e-13,\n            1.1294e-13, 1.1641e-13, 1.2036e-13, 1.0723e-13, 9.2980e-14, 1.0865e-13,\n            9.8239e-14, 9.3073e-14, 9.2130e-14, 1.0408e-13, 1.0356e-13, 9.2226e-14,\n            1.0241e-13, 1.2209e-13, 9.3479e-14, 9.1861e-14, 9.6695e-14, 7.9748e-14,\n            1.0531e-13, 9.2169e-14, 1.0716e-13, 8.8667e-14, 1.1007e-13, 9.8624e-14,\n            1.0676e-13, 8.9355e-14, 1.2096e-13, 9.8077e-14, 9.7052e-14, 9.6833e-14,\n            1.0717e-13, 9.6053e-14, 1.0579e-13, 1.0921e-13, 1.0571e-13, 1.1091e-13,\n            1.4371e-13, 1.0160e-13, 8.4097e-14, 1.0948e-13, 8.5994e-14, 1.0471e-13,\n            9.1576e-14, 9.6750e-14, 1.2862e-13, 1.1704e-13, 1.2444e-13, 8.4114e-14,\n            1.0220e-13, 8.3405e-14, 1.0092e-13, 1.0784e-13, 8.9355e-14, 1.0696e-13,\n            8.1197e-14, 9.5495e-14, 9.2184e-14, 8.9822e-14, 9.7374e-14, 9.8021e-14,\n            1.0869e-13, 1.0535e-13, 1.0902e-13, 1.6589e-13, 1.2657e-13, 8.8759e-14,\n            9.8893e-14, 9.7308e-14, 9.1594e-14, 9.6080e-14, 9.3076e-14, 9.7648e-14,\n            1.0377e-13, 1.2044e-13, 1.0318e-13, 1.0189e-13, 9.7783e-14, 8.9265e-14,\n            9.6712e-14, 9.8040e-14, 8.6436e-14, 9.0568e-14, 9.4790e-14, 9.2311e-14,\n            9.8308e-14, 1.0730e-13, 9.9724e-14, 9.5066e-14, 1.0136e-13, 8.8051e-14,\n            8.8989e-14, 1.0580e-13, 9.6192e-14, 9.8590e-14, 1.0831e-13, 1.0323e-13,\n            1.1435e-13, 1.1717e-13, 1.1675e-13, 1.5711e-13, 1.1811e-13, 8.9699e-14,\n            1.3315e-13, 1.1180e-13, 9.6546e-14, 1.0280e-13, 1.0810e-13, 1.3316e-13,\n            1.1931e-13, 1.2061e-13, 1.1285e-13, 9.1993e-14, 1.2408e-13, 1.0572e-13,\n            1.0424e-13, 1.2047e-13, 9.8883e-14, 9.1972e-14, 9.4951e-14, 1.0438e-13,\n            8.3744e-14, 9.7788e-14, 1.0222e-13, 9.9070e-14, 1.0624e-13, 1.0675e-13,\n            1.1416e-13, 1.5314e-13, 9.2785e-14, 8.8298e-14, 9.2962e-14, 1.2374e-13,\n            8.3614e-14, 1.0615e-13, 1.1359e-13, 1.1321e-13, 1.1307e-13, 9.5948e-14,\n            9.6410e-14, 1.1550e-13, 8.7757e-14, 1.1762e-13, 9.5423e-14, 8.9082e-14,\n            1.0608e-13, 1.5187e-13, 1.0559e-13, 2.1414e-13, 8.3695e-14, 9.7200e-14,\n            1.3468e-13, 1.1547e-13, 1.0547e-13, 1.2041e-13, 1.0896e-13, 1.1137e-13,\n            7.6846e-14, 1.1301e-13, 1.0204e-13, 8.6878e-14, 9.4240e-14, 1.1418e-13,\n            1.0380e-13, 8.6673e-14, 1.2151e-13, 8.1040e-14, 9.6849e-14, 1.7751e-13,\n            1.0916e-13, 8.6958e-14, 1.0141e-13, 9.2292e-14, 1.1130e-13, 9.1665e-14,\n            9.1529e-14, 8.0374e-14, 9.5066e-14, 1.0937e-13, 1.0425e-13, 1.1337e-13,\n            7.2222e-14, 1.0788e-13, 1.1942e-13, 1.2102e-13, 1.1426e-13, 1.1223e-13,\n            1.1012e-13, 9.4181e-14, 1.0995e-13, 1.1587e-13, 9.0251e-14, 1.0551e-13,\n            9.0943e-14, 1.0573e-13, 9.6153e-14, 8.3005e-14, 9.3701e-14, 1.0225e-13,\n            9.3526e-14, 1.1523e-13, 1.1109e-13, 1.1041e-13, 1.0550e-13, 9.0345e-14,\n            1.3363e-13, 1.2395e-13, 9.7623e-14, 7.6745e-14, 1.3587e-13, 9.7452e-14,\n            1.0795e-13, 9.7929e-14, 1.1720e-13, 1.0950e-13, 9.9744e-14, 1.1231e-13,\n            1.0709e-13, 8.7207e-14, 1.0356e-13, 9.8989e-14, 1.0260e-13, 1.0487e-13,\n            1.0184e-13, 1.0465e-13, 1.1399e-13, 1.1309e-13, 8.3755e-14, 9.6843e-14,\n            8.6798e-14, 1.1818e-13, 1.1617e-13, 9.0772e-14, 9.3162e-14, 1.4174e-13,\n            1.0223e-13, 1.0196e-13, 9.5252e-14, 6.9249e-14, 9.9502e-14, 1.2209e-13,\n            9.9368e-14, 1.0287e-13, 1.7184e-13, 1.0181e-13, 1.0475e-13, 1.0834e-13,\n            1.0762e-13, 1.2087e-13, 1.5654e-13, 1.0864e-13, 9.3104e-14, 9.2409e-14,\n            9.3387e-14, 1.2027e-13, 9.5469e-14, 1.0230e-13, 1.3528e-13, 1.0436e-13,\n            1.0503e-13, 9.9837e-14, 1.1351e-13, 1.4102e-13, 1.1130e-13, 1.2267e-13,\n            1.0051e-13, 8.1947e-14, 1.1275e-13, 1.1184e-13, 1.0311e-13, 1.1076e-13,\n            1.1050e-13, 1.0513e-13, 9.1428e-14, 1.1272e-13, 8.6855e-14, 1.0189e-13,\n            9.6053e-14, 1.0084e-13, 9.1260e-14, 9.1438e-14, 9.2864e-14, 9.8015e-14,\n            9.7736e-14, 1.0740e-13, 1.0371e-13, 9.8641e-14, 1.0236e-13, 1.0055e-13,\n            1.0596e-13, 1.0121e-13, 9.9322e-14, 1.1240e-13, 1.1372e-13, 1.1081e-13,\n            9.5041e-14, 1.0253e-13, 9.3029e-14, 9.5606e-14, 9.5484e-14, 9.0524e-14,\n            1.3674e-13, 8.9778e-14, 9.7051e-14, 9.1599e-14, 1.0642e-13, 1.1575e-13,\n            8.9404e-14, 1.1431e-13, 9.1120e-14, 1.0728e-13, 9.4690e-14, 9.1523e-14,\n            8.6055e-14, 1.1506e-13, 9.9745e-14, 1.1046e-13, 9.2401e-14, 1.0030e-13,\n            8.7182e-14, 9.0862e-14, 1.0868e-13, 8.6067e-14, 9.5841e-14, 1.0703e-13,\n            1.0077e-13, 8.8908e-14, 1.4784e-13, 8.8923e-14, 9.5925e-14, 9.9893e-14,\n            9.5005e-14, 9.6164e-14, 1.1161e-13, 1.1710e-13, 9.7150e-14, 1.1017e-13,\n            1.0448e-13, 9.5498e-14, 1.0545e-13, 1.0528e-13, 1.4534e-13, 8.1887e-14,\n            7.4082e-14, 1.7287e-13, 1.0432e-13, 1.0545e-13, 8.7726e-14, 9.4280e-14,\n            9.4857e-14, 1.0789e-13, 8.9662e-14, 1.0199e-13, 1.0271e-13, 1.1123e-13,\n            9.5457e-14, 8.1628e-14, 8.9551e-14, 8.2386e-14, 8.8324e-14, 9.9879e-14,\n            1.1435e-13, 1.0969e-13, 1.0524e-13, 1.2137e-13, 1.0241e-13, 9.3594e-14,\n            8.8783e-14, 1.0635e-13, 9.4705e-14, 9.7392e-14, 9.9201e-14, 1.2455e-13,\n            9.5520e-14, 8.2084e-14, 9.8374e-14, 9.2032e-14, 1.1738e-13, 9.7081e-14,\n            9.0399e-14, 1.0701e-13, 1.1131e-13, 1.0753e-13, 9.0875e-14, 9.9829e-14,\n            1.0923e-13, 1.0461e-13, 1.0815e-13, 9.6897e-14, 9.1143e-14, 9.6514e-14,\n            1.0079e-13, 9.4116e-14, 1.2842e-13, 9.0488e-14, 9.1308e-14, 9.5219e-14,\n            9.8348e-14, 9.7650e-14, 9.7667e-14, 8.2540e-14, 1.2915e-13, 9.4689e-14,\n            1.1454e-13, 9.8338e-14, 9.3649e-14, 1.0364e-13, 9.6251e-14, 1.0562e-13,\n            1.1358e-13, 1.1278e-13, 9.7784e-14, 1.1732e-13, 7.9636e-14, 1.0634e-13,\n            1.0479e-13, 1.0306e-13, 1.2317e-13, 1.0200e-13, 8.2528e-14, 1.0956e-13,\n            9.6462e-14, 9.7464e-14, 1.0241e-13, 9.0406e-14, 8.0863e-14, 1.9518e-13,\n            9.8875e-14, 8.3487e-14, 1.0878e-13, 1.1862e-13, 1.0033e-13, 6.8417e-14,\n            8.6355e-14, 1.0165e-13, 1.0694e-13, 1.0704e-13, 8.6712e-14, 8.0907e-14,\n            1.0675e-13, 9.2834e-14, 1.4049e-13, 9.7917e-14, 1.1484e-13, 8.5899e-14,\n            1.1002e-13, 1.0841e-13])},\n   96: {'exp_avg': tensor([ 1.6817e-07,  9.1014e-08, -1.5493e-07,  9.7806e-08, -5.7394e-09,\n            -2.1726e-07, -3.1726e-08, -8.6698e-08,  1.1441e-07, -4.6066e-08,\n            -4.6197e-08,  5.3481e-08,  4.7968e-08,  9.7799e-08, -5.0989e-08,\n            -1.2233e-07,  1.2073e-07, -1.6753e-07,  7.5283e-08, -2.7124e-08,\n            -1.6662e-07,  3.1672e-07, -3.3050e-08,  1.0566e-08, -7.2716e-08,\n            -2.5494e-08,  3.8655e-08,  1.6165e-07,  6.4894e-08, -1.2982e-07,\n             6.5312e-09, -2.6445e-07, -7.9146e-08,  9.9373e-08,  7.2834e-08,\n             8.0206e-08,  5.0356e-08, -6.1044e-08,  2.5865e-08, -1.4052e-07,\n             6.3822e-09,  6.6304e-09,  2.3811e-09,  4.4188e-08,  9.7884e-08,\n            -1.2829e-07,  1.5968e-08,  4.7789e-08,  1.8463e-08,  1.6001e-07,\n             1.4566e-07, -4.6136e-08,  5.9920e-08,  4.1715e-08, -2.3525e-07,\n             5.3891e-09,  3.9200e-08, -4.6388e-09, -1.7821e-07,  2.7192e-07,\n            -5.5319e-08, -1.6865e-07, -5.1005e-08, -4.4361e-08,  6.5681e-08,\n            -3.7521e-08,  3.7633e-08,  1.1459e-07,  3.9711e-08,  1.6665e-08,\n             5.9102e-08, -6.7806e-08,  1.2239e-07, -9.9101e-08, -1.9652e-07,\n            -4.2925e-08, -2.2460e-08, -6.1880e-08,  1.3131e-08, -3.9362e-08,\n            -2.8827e-08, -9.5191e-08,  3.2999e-08, -1.7614e-07,  4.4035e-08,\n            -1.3483e-08, -1.1700e-07,  5.1304e-08, -1.4716e-07, -7.9949e-09,\n            -7.7646e-10,  9.9277e-08,  8.8870e-08,  1.8963e-07,  4.5983e-08,\n             4.3140e-08,  1.0743e-07, -1.4826e-07, -6.1914e-08,  1.2711e-07,\n            -3.6648e-08,  7.7612e-08,  1.2960e-07, -5.6524e-08, -3.8259e-08,\n            -3.0199e-08, -3.4943e-08, -2.2553e-08,  1.9985e-08,  1.0586e-07,\n             6.9374e-08, -1.0155e-07, -1.1094e-08, -8.8417e-08,  1.3384e-08,\n            -1.7739e-07,  2.2921e-07, -1.4242e-07, -2.8159e-08,  1.2399e-07,\n            -7.0371e-09, -6.5239e-08, -1.7228e-08,  1.5268e-08,  3.2559e-07,\n             1.6164e-08,  1.3707e-08, -5.7292e-08, -5.5649e-09, -1.0378e-07,\n             3.3178e-08, -4.2384e-08, -1.1643e-07, -9.0592e-08,  1.6313e-07,\n             4.6895e-08,  8.4973e-08,  8.1541e-08, -4.5515e-09, -1.6705e-08,\n            -6.4801e-09,  6.9968e-09, -3.6547e-08,  1.2767e-07, -8.6875e-09,\n             1.4691e-07,  6.3331e-08, -6.8407e-08, -4.0773e-08, -2.7876e-08,\n             7.7105e-08, -9.0830e-08, -9.1390e-08, -2.6896e-08, -1.6649e-08,\n             9.4159e-08, -6.8869e-08,  5.7649e-08, -4.1468e-08, -7.6411e-08,\n             4.8157e-08, -1.3839e-07, -5.3298e-08,  8.0968e-08, -4.4580e-08,\n             2.0967e-08, -4.8524e-08, -1.4440e-07,  6.9287e-08,  1.3461e-08,\n             2.0994e-08,  2.7810e-08, -5.2505e-08,  1.3538e-07,  1.7438e-08,\n            -3.3038e-08,  4.7114e-08,  7.6437e-08,  4.9355e-09,  5.6230e-08,\n             9.7666e-08,  9.2948e-08, -8.9001e-08,  1.5362e-07, -2.2494e-08,\n             4.4116e-08, -9.8195e-08, -1.1735e-08, -1.1007e-07, -9.5582e-08,\n             2.3683e-08, -1.4163e-07, -8.4936e-08,  1.6309e-07,  2.5704e-09,\n             1.6752e-07, -1.7636e-08,  9.0134e-08,  5.9232e-08, -1.4613e-07,\n            -1.0188e-07,  4.0400e-08, -6.0082e-09, -1.0537e-07,  4.7710e-08,\n             6.3032e-09,  1.3508e-08, -2.2439e-07, -2.2498e-08,  1.6575e-07,\n            -8.0016e-08,  8.4484e-08,  5.8187e-08, -8.5069e-08, -2.1721e-07,\n             1.2684e-08,  1.1523e-07, -5.1652e-08,  1.2347e-09, -1.2558e-08,\n            -1.1060e-08, -7.4513e-09, -7.8824e-08, -2.2534e-08,  7.4931e-08,\n             9.0595e-08, -4.8288e-08, -4.2360e-10,  1.4335e-07,  6.8527e-08,\n             7.3269e-09,  1.5026e-07,  7.6846e-08,  5.6472e-09, -4.6658e-08,\n             7.3311e-09, -2.4741e-08,  6.6874e-09,  2.2141e-08, -1.0517e-07,\n             6.2119e-09,  7.0415e-08,  8.4917e-08,  1.4388e-07,  1.5640e-07,\n            -2.0411e-08, -5.1211e-08,  1.1193e-07,  1.4691e-07,  1.4094e-07,\n             1.0482e-07,  1.3999e-08,  1.4849e-07, -3.2816e-09, -7.1806e-08,\n            -9.7340e-08, -5.7618e-08, -3.3751e-08, -3.0459e-08, -8.1221e-08,\n             2.1104e-07, -1.7523e-07, -6.0921e-08, -2.3118e-08, -1.0755e-07,\n            -1.7124e-08, -1.6741e-07, -9.6019e-08, -6.2693e-08, -5.9246e-09,\n             9.9664e-09, -2.1797e-07,  5.3737e-08,  3.9145e-08, -2.8575e-08,\n             3.7624e-08, -6.5914e-08,  9.0542e-08, -1.9220e-07, -4.0945e-08,\n            -1.0165e-07, -4.7917e-08, -1.6428e-08,  3.8116e-08,  1.3566e-07,\n            -3.1551e-08,  1.2033e-09,  2.0453e-08, -3.7020e-08, -2.1758e-08,\n            -9.5709e-08,  6.5224e-08, -4.6909e-08, -6.8844e-08, -1.2941e-08,\n            -7.2701e-08,  2.9146e-08,  1.0257e-07,  1.1139e-07, -6.1157e-08,\n             1.3919e-07,  4.8192e-10, -1.4327e-07,  2.6168e-08,  2.0857e-08,\n             1.4531e-07, -5.3538e-08,  9.1703e-08, -1.0006e-08, -1.4475e-07,\n            -1.1068e-07, -1.3256e-07,  7.7628e-08,  2.5062e-07,  5.8646e-08,\n            -1.0561e-07,  1.7084e-08,  4.5300e-08,  2.9989e-08,  2.2522e-08,\n             6.0858e-08, -5.8222e-08, -1.3587e-07,  1.3460e-07,  1.2168e-07,\n             5.3656e-08,  8.2822e-08, -9.3668e-08,  1.3036e-07, -7.0413e-08,\n             1.3078e-07,  6.8483e-08,  3.7112e-09,  2.4331e-08,  4.1817e-08,\n             5.4653e-08,  1.5493e-07, -2.5505e-08,  8.6215e-09,  1.9897e-07,\n            -9.6668e-09, -1.3718e-07, -2.5535e-07, -2.3499e-09, -1.2975e-08,\n            -1.0560e-07,  1.8436e-08,  4.1355e-08,  1.0311e-07, -5.2794e-08,\n             4.4904e-08, -9.8693e-08,  1.6180e-08, -3.8618e-08, -8.3853e-08,\n            -1.7171e-07,  2.1688e-07, -8.5024e-08, -8.6914e-08, -2.7882e-08,\n             6.7200e-08, -1.7170e-08, -1.4245e-08,  1.2407e-07, -5.2795e-08,\n            -3.9367e-08, -5.8757e-08,  6.6275e-08, -1.0683e-07,  1.1124e-07,\n             7.0795e-08, -7.1450e-08,  2.6308e-09,  1.2027e-07, -4.9182e-08,\n             4.6463e-08,  1.2039e-07, -6.3061e-08, -5.9670e-08,  4.1099e-08,\n            -7.4230e-08, -9.3105e-08,  2.2232e-07, -1.1070e-09, -8.4680e-09,\n             7.6737e-08,  8.3167e-08,  1.9246e-07, -1.7471e-07,  4.2348e-08,\n             1.3254e-07, -7.3351e-08,  3.3232e-08, -6.9829e-08, -3.0484e-08,\n            -4.8307e-08, -6.7756e-08,  1.9750e-07,  1.5208e-08, -1.0589e-07,\n            -2.1081e-07, -4.0587e-08,  1.2440e-07,  1.8213e-08, -4.7614e-08,\n             1.2325e-07, -3.6481e-09, -5.2157e-08,  3.5355e-08,  3.4128e-08,\n             1.1702e-07, -1.3168e-08,  9.2632e-08,  1.3577e-08, -2.6570e-08,\n             4.2911e-09,  3.4576e-08,  1.7298e-08, -2.6787e-08, -7.0488e-08,\n             1.2517e-07, -1.0818e-08, -3.1313e-07,  4.4054e-08, -3.1533e-08,\n             3.6735e-08, -1.5079e-07, -2.1415e-08,  1.9670e-08, -2.6799e-09,\n             9.3304e-10,  1.0027e-07, -1.0085e-07, -6.6206e-08, -1.4991e-07,\n            -2.2825e-08, -7.8873e-08,  1.4777e-08,  2.8380e-08, -1.2585e-07,\n            -1.9969e-08,  1.7414e-07, -1.0949e-07,  1.2408e-08, -1.4284e-07,\n             1.3984e-07,  2.6575e-08,  6.8850e-08,  1.1518e-07, -9.3574e-08,\n             1.2651e-07, -2.2706e-08, -1.3392e-07,  1.4046e-07,  7.0641e-08,\n            -1.5698e-07,  1.4669e-07, -1.8006e-07, -2.1305e-08,  3.9888e-08,\n             3.9361e-08, -1.1705e-08,  1.5402e-08, -1.0069e-07, -1.9841e-07,\n            -9.6022e-08, -9.7756e-08, -3.6634e-08,  1.0659e-07,  3.3420e-08,\n            -6.2037e-08, -1.4023e-07,  3.7576e-08,  1.9111e-07, -9.3615e-08,\n             1.7267e-07,  8.2088e-08, -1.6236e-07,  2.3254e-07,  2.3847e-10,\n             1.2776e-07, -2.0260e-07,  2.9533e-08,  3.3164e-08,  4.1881e-08,\n            -1.3605e-07, -6.1624e-08,  6.6313e-08, -4.6081e-08, -1.0224e-07,\n            -6.3273e-08,  9.4097e-08, -1.9853e-07, -7.4740e-08,  4.9830e-08,\n            -3.9088e-08,  1.6899e-07,  1.0243e-07,  3.4983e-08,  1.1935e-07,\n             2.2931e-09, -8.0183e-08,  2.9115e-08,  6.4707e-08,  2.7490e-09,\n            -1.1257e-07, -8.2643e-08,  2.0203e-08,  9.2998e-09,  9.5978e-08,\n             1.0533e-07, -3.0784e-08]),\n    'exp_avg_sq': tensor([2.3751e-13, 3.7435e-13, 2.6549e-13, 1.6809e-13, 1.0842e-13, 1.5609e-13,\n            2.6255e-13, 2.2480e-13, 2.3738e-13, 8.4137e-14, 9.9183e-14, 2.3894e-13,\n            1.7780e-14, 1.6824e-13, 2.9512e-13, 1.5804e-13, 1.0980e-13, 2.1444e-13,\n            2.3352e-13, 1.4999e-13, 7.3188e-13, 1.5097e-13, 1.6247e-13, 9.5261e-14,\n            1.7235e-13, 5.0728e-14, 1.5035e-13, 1.8892e-13, 1.2066e-13, 1.2548e-13,\n            1.9491e-13, 1.8844e-13, 1.9037e-13, 1.2656e-13, 1.1138e-13, 2.0595e-13,\n            2.2829e-13, 1.5216e-13, 1.0818e-13, 2.0053e-13, 1.7667e-13, 2.1199e-13,\n            1.5026e-13, 2.1626e-13, 5.9172e-14, 2.0800e-13, 1.7565e-13, 2.4232e-13,\n            2.0351e-13, 1.3001e-13, 1.7025e-13, 1.6696e-13, 2.0539e-13, 8.0376e-14,\n            2.3041e-13, 1.1648e-13, 1.9827e-13, 1.5604e-13, 7.5853e-14, 5.1142e-13,\n            1.6759e-13, 3.3846e-13, 2.8160e-13, 1.5900e-13, 1.7613e-13, 1.9766e-13,\n            2.2017e-13, 3.4000e-13, 2.4368e-13, 1.7611e-13, 1.1765e-13, 8.1109e-14,\n            1.4534e-13, 2.1705e-13, 1.7022e-13, 1.6210e-13, 2.4345e-13, 2.2118e-13,\n            2.0276e-13, 1.8106e-13, 9.8998e-14, 1.6429e-13, 1.0985e-13, 1.6653e-13,\n            1.8734e-13, 1.3185e-13, 1.4936e-13, 1.3100e-13, 1.8216e-13, 1.1381e-13,\n            1.4434e-13, 8.2950e-14, 1.4647e-13, 1.3533e-13, 2.9807e-14, 1.7563e-13,\n            2.0752e-13, 1.7486e-13, 2.1626e-13, 1.6748e-13, 1.9978e-13, 1.9014e-13,\n            3.6196e-13, 2.3487e-13, 2.0246e-13, 4.0517e-14, 1.8249e-13, 8.4534e-14,\n            4.1150e-14, 1.8968e-13, 2.0590e-13, 1.7151e-13, 1.2978e-13, 1.9859e-13,\n            1.9331e-13, 1.5284e-13, 1.8851e-13, 2.0870e-13, 1.8906e-13, 1.9648e-13,\n            1.7527e-13, 1.5177e-13, 1.8732e-13, 2.5590e-13, 4.0037e-13, 1.8677e-13,\n            1.2805e-13, 1.9764e-13, 7.1643e-13, 1.8595e-13, 1.3755e-13, 1.4155e-13,\n            1.7677e-13, 1.9414e-13, 1.3085e-13, 1.4716e-13, 7.8150e-14, 2.2028e-13,\n            1.0292e-13, 1.5862e-13, 2.2660e-13, 9.4860e-14, 1.7352e-13, 2.0625e-13,\n            9.8571e-14, 1.2141e-13, 1.5556e-13, 2.0703e-13, 2.4737e-13, 5.2405e-14,\n            1.0670e-13, 1.7514e-13, 8.2323e-14, 2.2343e-13, 1.2023e-13, 2.4342e-13,\n            1.8046e-13, 3.0341e-13, 2.7180e-13, 1.5383e-13, 9.1160e-14, 2.0053e-13,\n            1.5090e-13, 1.6448e-13, 4.4013e-13, 1.5852e-13, 1.7092e-13, 1.9417e-13,\n            1.1098e-13, 1.8754e-13, 1.9041e-13, 2.0625e-13, 3.3191e-13, 2.1737e-13,\n            2.0067e-13, 1.0791e-13, 1.1794e-13, 1.0590e-13, 1.8617e-13, 1.3952e-13,\n            1.3798e-13, 8.0395e-14, 1.9779e-13, 1.2765e-13, 1.0412e-13, 1.7494e-13,\n            1.6211e-13, 2.0922e-13, 1.4665e-13, 1.7182e-13, 2.0296e-13, 1.4073e-13,\n            2.4819e-13, 1.9426e-13, 1.2830e-13, 1.0263e-13, 5.3200e-14, 1.2365e-13,\n            7.3329e-14, 1.1281e-13, 1.5069e-13, 2.7463e-13, 2.3402e-13, 2.1437e-13,\n            1.7925e-13, 7.3195e-14, 2.0853e-13, 1.6654e-13, 1.9293e-13, 1.6289e-13,\n            2.3291e-13, 1.3978e-13, 6.4234e-14, 2.0633e-13, 2.1484e-13, 8.1676e-14,\n            2.4416e-13, 1.6235e-13, 8.0118e-14, 1.6054e-13, 1.9971e-13, 1.6479e-13,\n            1.5246e-13, 1.4108e-13, 1.1094e-13, 1.2150e-13, 1.1463e-13, 1.5691e-13,\n            1.9177e-13, 2.0122e-13, 7.8297e-14, 1.2035e-13, 1.4952e-13, 1.4020e-13,\n            2.0009e-13, 9.8032e-14, 1.7998e-13, 1.8111e-13, 1.0133e-13, 1.0835e-13,\n            9.5686e-14, 2.0172e-13, 2.1754e-13, 1.7356e-13, 1.8873e-13, 1.3224e-13,\n            1.1591e-13, 1.5092e-13, 1.3991e-13, 2.0018e-13, 1.6675e-13, 1.5223e-13,\n            1.5869e-13, 1.7173e-13, 3.3162e-13, 2.1533e-13, 2.3010e-13, 2.0164e-13,\n            1.7412e-13, 1.9262e-13, 1.9051e-13, 1.9060e-13, 2.4198e-13, 8.5674e-14,\n            1.9417e-13, 1.6343e-13, 1.9713e-13, 1.8286e-13, 1.6658e-13, 2.2676e-13,\n            1.7807e-13, 2.0902e-13, 3.8716e-13, 1.2453e-13, 2.0548e-13, 1.9754e-13,\n            2.7385e-13, 1.7990e-13, 1.6515e-13, 1.3064e-13, 2.0832e-13, 7.1823e-14,\n            9.0101e-14, 1.7791e-13, 1.6719e-13, 1.9872e-13, 3.0931e-13, 1.0889e-13,\n            2.8524e-13, 1.9854e-13, 1.5325e-13, 1.7704e-13, 2.1595e-13, 1.4732e-13,\n            2.5152e-13, 2.1456e-13, 1.4244e-13, 1.9174e-13, 1.5820e-13, 1.8683e-13,\n            1.2760e-13, 7.4329e-14, 1.7081e-13, 1.6428e-14, 1.0218e-13, 1.5496e-13,\n            1.4818e-13, 1.4164e-13, 2.1865e-13, 1.5722e-13, 1.2363e-13, 2.3842e-13,\n            1.7103e-13, 1.9555e-13, 2.4318e-13, 1.5680e-13, 4.0921e-13, 2.7176e-13,\n            3.3137e-13, 1.0039e-13, 2.9542e-13, 1.6860e-13, 2.4874e-13, 1.6519e-13,\n            1.4143e-13, 1.9720e-13, 1.7803e-13, 1.6005e-13, 2.3898e-13, 1.2004e-13,\n            1.6679e-13, 1.6421e-13, 1.8497e-13, 2.5141e-13, 6.3477e-14, 8.2941e-14,\n            9.3492e-14, 1.9985e-13, 1.9952e-13, 2.5075e-13, 9.3405e-14, 1.5792e-13,\n            2.0069e-13, 1.5683e-13, 1.8516e-13, 1.6373e-13, 1.5459e-13, 2.6536e-13,\n            1.1490e-13, 1.9782e-13, 1.1950e-13, 2.7589e-13, 1.7716e-13, 1.5890e-13,\n            1.6857e-13, 2.1266e-13, 2.1250e-13, 2.1747e-13, 1.7222e-13, 1.8866e-13,\n            1.8025e-13, 1.5372e-13, 1.3061e-13, 3.1435e-13, 1.7191e-13, 9.2646e-14,\n            9.8675e-14, 6.0271e-14, 8.9496e-14, 2.1253e-13, 1.6417e-13, 2.0170e-13,\n            2.1023e-13, 2.7254e-13, 1.4305e-13, 1.8866e-13, 1.7511e-13, 1.5454e-13,\n            2.2288e-13, 1.6654e-13, 2.0618e-13, 1.3811e-13, 2.1969e-13, 2.1221e-13,\n            4.2469e-14, 1.5815e-13, 2.2216e-13, 1.7160e-13, 2.0510e-13, 1.9822e-13,\n            2.0904e-13, 2.9608e-13, 1.5187e-13, 1.7505e-13, 1.4251e-13, 1.8677e-13,\n            1.6252e-13, 3.7712e-13, 8.9053e-14, 2.0315e-13, 1.7931e-13, 1.4762e-13,\n            1.3637e-13, 8.2164e-14, 2.2336e-13, 1.6226e-13, 1.4793e-13, 1.7360e-13,\n            1.7060e-13, 1.4571e-13, 3.2795e-13, 1.4450e-13, 2.2542e-13, 1.9948e-13,\n            2.0905e-13, 4.9378e-14, 5.1444e-14, 1.4592e-13, 1.9434e-13, 4.5228e-13,\n            1.1393e-13, 1.9575e-13, 2.0905e-13, 1.7187e-13, 1.4677e-13, 1.7779e-13,\n            1.6507e-13, 1.8160e-13, 1.7811e-13, 1.9013e-13, 7.9704e-14, 1.5020e-13,\n            1.4268e-13, 1.6408e-13, 1.3782e-13, 1.4931e-13, 1.6576e-13, 8.6365e-14,\n            1.0978e-13, 2.2023e-13, 6.2476e-14, 2.4411e-13, 2.8146e-13, 1.6637e-13,\n            2.3240e-13, 2.2147e-13, 1.9236e-13, 1.0952e-13, 5.2957e-13, 1.5247e-13,\n            1.6137e-13, 1.2916e-13, 2.2807e-13, 2.1980e-13, 1.8655e-13, 1.2779e-13,\n            1.1858e-13, 2.4153e-13, 2.1638e-13, 1.2734e-13, 7.8526e-14, 1.3419e-13,\n            8.2242e-14, 1.7776e-13, 2.2031e-13, 1.3685e-13, 1.2959e-13, 1.7361e-13,\n            1.7377e-13, 1.0361e-13, 1.9116e-13, 3.5950e-13, 1.8907e-13, 1.6883e-13,\n            1.8584e-13, 2.0250e-13, 2.3021e-13, 1.6903e-13, 1.0695e-13, 1.8509e-13,\n            2.1844e-13, 2.0397e-13, 1.3437e-13, 1.6031e-13, 8.7509e-14, 5.3322e-14,\n            7.6158e-14, 1.9454e-13, 1.8913e-13, 2.6331e-13, 1.6828e-13, 1.6285e-13,\n            2.7861e-13, 1.8371e-13, 7.9149e-14, 1.8409e-13, 1.5340e-13, 1.8606e-13,\n            2.0203e-13, 1.4788e-13, 1.9277e-13, 2.0571e-13, 1.7727e-13, 1.9506e-13,\n            8.0974e-14, 1.8431e-13, 1.4432e-13, 1.8729e-13, 6.6312e-14, 1.2693e-13,\n            2.2840e-13, 1.7515e-13])},\n   97: {'exp_avg': tensor([ 8.8770e-08,  1.2336e-07, -9.2695e-08,  1.0664e-07,  5.6524e-08,\n            -7.5070e-08,  6.8075e-08, -7.7220e-08,  6.2355e-08, -7.4578e-09,\n            -1.6019e-08,  4.9039e-08,  5.2381e-08,  1.7042e-07,  3.0893e-08,\n            -6.5498e-08,  1.4072e-07, -6.9114e-08,  1.6368e-07,  5.6266e-09,\n            -1.1383e-07,  2.9475e-07, -1.2863e-08,  2.0468e-08, -5.4870e-08,\n            -3.6797e-08, -5.3427e-11,  9.3171e-08,  6.1234e-08, -1.3183e-07,\n            -2.6261e-08, -1.6276e-07, -3.1938e-08,  1.7324e-08,  2.0523e-08,\n             3.8061e-08,  3.2696e-08, -1.1565e-07, -2.2444e-08, -3.1638e-08,\n             1.1653e-07,  4.2185e-09,  4.9947e-08, -2.2610e-08,  9.6360e-08,\n            -6.5772e-08,  2.4160e-08, -1.6076e-09,  5.3317e-08,  2.6356e-08,\n             1.3666e-07, -2.4535e-08,  3.4596e-09,  2.4247e-08, -1.1209e-07,\n             2.3729e-08,  7.9234e-08,  6.9596e-08, -1.1940e-07,  1.9127e-07,\n            -4.1253e-08, -1.2284e-07, -8.1713e-08, -4.1535e-08,  5.4252e-09,\n            -3.6630e-09,  3.5906e-08,  7.1931e-08,  5.6533e-08,  7.2124e-08,\n             2.5327e-08, -3.7268e-08,  7.5081e-08, -1.3375e-07, -4.5774e-08,\n            -3.1244e-08,  1.4649e-08, -8.0709e-08,  2.0430e-08,  2.3586e-09,\n             4.4819e-08, -1.6989e-08,  6.7894e-08, -4.5600e-08, -4.1817e-08,\n             4.4726e-08, -5.1171e-08,  7.5859e-08, -1.0567e-07, -4.0915e-08,\n             7.1051e-08,  1.0142e-07,  2.2619e-09,  1.0508e-07, -1.7633e-08,\n             2.8726e-08,  8.8850e-08, -1.3397e-07, -6.7103e-09,  5.8619e-08,\n             5.8292e-08, -6.4018e-09,  8.7179e-08, -6.6184e-08, -3.6755e-08,\n             3.2125e-08, -9.8881e-08, -2.2107e-08, -6.3750e-09,  1.9527e-08,\n             6.3554e-08, -4.2222e-08, -1.8527e-08, -8.4880e-08,  1.1313e-07,\n            -2.3105e-07,  8.9222e-08, -8.7390e-08, -4.1295e-09,  7.4274e-09,\n             1.6920e-08, -4.2786e-08,  2.6654e-08,  6.0193e-08,  2.1738e-07,\n            -2.7385e-08, -2.0297e-08, -7.3809e-08, -1.9466e-08, -5.2858e-08,\n            -2.5645e-10,  8.1542e-09, -9.1158e-08, -7.0037e-08,  1.0821e-07,\n            -6.3170e-09,  4.3676e-08,  8.3200e-08,  3.0116e-08,  9.0528e-09,\n             2.5944e-08,  1.3501e-08, -3.2290e-08,  1.0368e-07, -2.2397e-08,\n             1.0095e-07,  5.0777e-08, -5.2779e-08, -1.2982e-09, -1.1260e-08,\n             5.2037e-08, -1.2476e-07,  9.1630e-10, -2.6985e-08, -2.7378e-08,\n             9.6540e-08,  1.6085e-08, -3.0047e-08, -7.8715e-08, -7.2831e-08,\n             3.3718e-08, -5.6610e-08,  4.6688e-08,  4.9993e-08, -2.8321e-08,\n            -4.4299e-08, -2.7814e-08, -8.5840e-08,  5.1201e-08, -4.2574e-08,\n            -3.7144e-08, -2.3762e-08, -5.6559e-08,  3.4215e-08,  1.7392e-08,\n            -1.7751e-08,  1.1344e-08,  9.0495e-08,  7.8890e-10,  6.4088e-08,\n             7.5696e-08,  6.7199e-08, -4.6987e-08,  9.5371e-08, -4.4049e-08,\n            -1.1318e-09,  2.1719e-08,  1.7727e-09, -5.2998e-08, -8.6672e-08,\n            -6.2175e-08, -1.1912e-07, -8.8637e-08,  1.4780e-07,  1.0771e-07,\n             1.3308e-07, -1.9553e-08,  1.9961e-08,  7.6776e-08, -1.0256e-07,\n            -1.5283e-07, -5.3777e-09, -1.8700e-08, -8.3358e-08,  6.9596e-08,\n            -1.9620e-08,  3.1146e-08, -2.0464e-07, -8.8413e-08,  1.2796e-07,\n            -6.9745e-08,  6.2713e-08,  3.0277e-08, -9.3733e-08, -1.1296e-07,\n             2.6969e-08,  1.3527e-07, -7.8220e-08,  3.9499e-08, -2.2259e-08,\n             4.0841e-08, -4.5220e-08, -2.6772e-08,  2.5616e-08,  2.0256e-08,\n             1.1863e-07, -1.1129e-07, -2.4600e-08, -3.1669e-08, -1.9931e-09,\n             9.0103e-09,  8.6794e-08,  8.7468e-08, -4.9185e-09,  5.7044e-08,\n             6.2387e-08, -3.3075e-08, -3.5816e-08, -5.5551e-08, -7.5871e-08,\n             1.7594e-08,  9.2884e-08,  1.8327e-09,  1.6838e-07,  1.4695e-07,\n            -3.9162e-08, -6.6606e-08,  6.3675e-08,  1.5809e-07,  1.1607e-07,\n             6.6396e-08,  2.1710e-09,  7.2914e-08,  5.9236e-08,  6.6253e-08,\n            -1.0349e-07, -2.0441e-08,  1.4432e-08, -1.2640e-08, -4.6109e-08,\n             9.1016e-08, -7.9696e-08,  2.2159e-08,  6.5571e-08, -1.1276e-07,\n             2.8948e-08, -1.3844e-07,  3.9214e-09,  7.6807e-08, -7.0765e-08,\n             2.2108e-08, -2.0440e-07,  2.2641e-08,  2.4546e-08,  3.9715e-08,\n             1.2730e-07, -4.3737e-08,  1.0689e-07, -1.3020e-07,  6.5289e-09,\n             1.3622e-08, -3.3433e-08,  1.2403e-08,  9.6200e-08,  1.1241e-07,\n             3.5052e-08, -2.0072e-08,  2.4829e-08, -4.2767e-08, -6.9144e-08,\n            -1.3812e-07,  1.1372e-07,  1.7623e-09,  3.7141e-09,  2.9291e-09,\n            -2.1509e-08,  7.3271e-09, -3.2153e-08,  1.3804e-07, -3.1958e-08,\n             3.4060e-08,  4.8835e-08, -2.8617e-08,  1.9461e-08,  1.8476e-08,\n             1.3935e-07, -4.5183e-08,  2.6739e-08, -1.0474e-08, -3.7185e-08,\n             2.9116e-08, -8.3884e-09,  5.1520e-08,  2.1447e-07,  2.5790e-08,\n            -1.1987e-07,  2.0827e-08,  6.2663e-08, -4.4480e-08,  2.7728e-08,\n             1.0937e-07, -1.4030e-09, -1.6167e-07,  5.0568e-08,  5.5936e-08,\n             4.2558e-08,  7.2200e-08, -5.6050e-08,  1.2196e-07, -4.3398e-08,\n             1.2832e-07,  3.3548e-08, -5.8591e-08,  2.5626e-08,  1.1932e-08,\n             5.7598e-08,  1.2128e-07, -7.0514e-08,  1.7018e-08,  1.2798e-07,\n            -3.5592e-08, -4.1386e-08, -1.1145e-07,  5.9848e-08,  5.5625e-09,\n            -4.3772e-08,  3.3468e-08,  6.0840e-08,  6.7705e-08, -1.7448e-08,\n            -4.1920e-08, -4.1533e-08,  4.5977e-08, -6.7456e-08, -6.2579e-08,\n            -1.0403e-07,  1.4720e-07, -1.1931e-07, -9.3318e-09,  8.6541e-08,\n             8.4621e-08, -6.5887e-08, -2.6524e-08,  3.2573e-08, -1.2068e-08,\n            -8.0033e-09, -1.0459e-08,  7.2179e-08, -5.9848e-08,  1.5897e-08,\n            -9.3007e-08, -2.0855e-08, -1.5501e-08,  1.0797e-07,  1.7381e-08,\n             1.9820e-09,  7.5674e-08,  6.1472e-09, -1.0380e-09,  5.0673e-08,\n            -7.2790e-08,  4.7831e-09,  1.7549e-07,  3.5738e-08,  1.8978e-08,\n             1.5862e-08,  6.3067e-08,  1.9667e-07, -4.3711e-08,  1.3050e-07,\n             7.5108e-08,  1.8077e-10, -2.2396e-08, -2.5565e-10,  3.6069e-08,\n            -4.2957e-08, -4.0810e-08,  3.6118e-08,  4.5465e-08, -2.8669e-08,\n            -1.2262e-07,  2.6748e-08,  8.9664e-08,  2.4790e-08,  8.0828e-08,\n             5.6063e-08, -3.9644e-08,  8.7286e-08,  1.4097e-09,  9.1546e-08,\n             3.6728e-08,  7.2371e-08,  7.2735e-08,  6.9234e-08, -1.0224e-07,\n            -3.1830e-08,  3.8494e-08,  1.2429e-08, -7.3931e-09, -2.0240e-08,\n             1.6354e-07,  2.5613e-08, -1.6616e-07,  1.4049e-07, -9.9598e-08,\n             1.5715e-09, -1.5336e-07, -1.4540e-07,  4.8585e-08,  2.1282e-08,\n            -7.5253e-10,  2.6561e-08, -2.0784e-08,  1.9127e-08, -1.3751e-07,\n             1.0103e-07, -4.5390e-08,  4.7074e-08,  1.8019e-08, -5.9456e-08,\n            -9.3640e-09,  9.7748e-08, -6.1549e-08,  2.6754e-09, -6.3934e-08,\n             1.8637e-07,  9.7706e-09, -5.4156e-09,  8.0007e-08, -8.5984e-08,\n             6.7570e-08,  4.8318e-08, -8.1797e-08,  9.0708e-08, -1.6169e-08,\n            -1.4513e-07,  9.0869e-08, -1.1785e-07,  1.7034e-08,  4.3757e-08,\n            -4.5480e-09, -5.2362e-08,  6.2430e-08, -1.3585e-07, -1.6826e-07,\n            -9.4365e-08, -1.0022e-07, -4.7140e-08,  6.8855e-08, -3.5455e-08,\n            -4.5627e-09, -7.8627e-08, -1.7578e-08,  1.1761e-07,  3.2597e-09,\n             1.8182e-07,  2.8209e-08, -1.2776e-07,  1.4009e-07, -5.4402e-08,\n             1.3745e-07, -1.2393e-07,  3.3227e-08, -7.0531e-08,  9.6109e-08,\n            -4.7543e-08, -8.5735e-08, -9.9352e-10, -3.3422e-08, -6.8851e-09,\n            -2.4908e-08, -4.6481e-08, -6.2387e-08, -3.5270e-08,  3.1357e-08,\n             9.5146e-09,  5.8806e-08,  6.6962e-08, -1.9562e-08,  1.3369e-07,\n             8.0566e-09, -6.4287e-08,  5.5399e-08,  1.3873e-07,  6.9635e-09,\n            -1.0943e-07, -2.8331e-08,  4.5832e-08,  4.0707e-08,  1.0074e-07,\n            -5.2892e-08,  5.9711e-08]),\n    'exp_avg_sq': tensor([1.3471e-13, 2.7297e-13, 2.7638e-13, 1.0061e-13, 6.8905e-14, 8.5485e-14,\n            1.2841e-13, 1.3765e-13, 1.4309e-13, 4.8219e-14, 6.1499e-14, 1.2201e-13,\n            1.3973e-14, 1.0789e-13, 1.4998e-13, 1.0924e-13, 7.2228e-14, 1.7227e-13,\n            1.2033e-13, 1.2469e-13, 7.0374e-13, 1.0435e-13, 1.1443e-13, 6.5961e-14,\n            1.1932e-13, 3.6294e-14, 9.3262e-14, 1.1732e-13, 8.0924e-14, 9.6803e-14,\n            1.2405e-13, 1.1335e-13, 1.9822e-13, 9.3345e-14, 9.8416e-14, 1.3781e-13,\n            1.2538e-13, 1.1744e-13, 7.5089e-14, 1.5284e-13, 1.1485e-13, 1.4908e-13,\n            1.1755e-13, 1.5029e-13, 3.5648e-14, 1.3942e-13, 1.0492e-13, 1.3613e-13,\n            1.6039e-13, 7.9250e-14, 1.3106e-13, 1.0951e-13, 1.2066e-13, 5.4435e-14,\n            1.4355e-13, 6.9548e-14, 1.2687e-13, 9.7512e-14, 4.9462e-14, 2.7595e-13,\n            1.2431e-13, 2.2320e-13, 1.8097e-13, 1.0570e-13, 1.3018e-13, 1.1719e-13,\n            1.2391e-13, 3.0981e-13, 1.1297e-13, 1.4185e-13, 7.0992e-14, 5.3862e-14,\n            1.0116e-13, 1.7547e-13, 1.0569e-13, 1.1065e-13, 1.3972e-13, 1.3677e-13,\n            1.3046e-13, 1.0684e-13, 6.5719e-14, 1.1035e-13, 6.5750e-14, 1.0103e-13,\n            1.2028e-13, 7.5303e-14, 8.2946e-14, 1.0025e-13, 1.1437e-13, 9.4479e-14,\n            1.0379e-13, 5.0103e-14, 9.3766e-14, 9.2422e-14, 2.2627e-14, 1.1117e-13,\n            1.2280e-13, 1.1914e-13, 1.2051e-13, 9.8079e-14, 1.2947e-13, 1.2045e-13,\n            1.7097e-13, 3.1532e-13, 1.3535e-13, 2.5364e-14, 1.2011e-13, 6.1605e-14,\n            2.6955e-14, 1.3164e-13, 1.2395e-13, 1.4618e-13, 7.3973e-14, 1.1205e-13,\n            1.2104e-13, 1.0673e-13, 1.1363e-13, 1.1679e-13, 1.1369e-13, 1.5317e-13,\n            1.0370e-13, 1.1858e-13, 1.2375e-13, 1.4711e-13, 2.6761e-13, 9.9661e-14,\n            7.1811e-14, 9.5920e-14, 8.4242e-13, 1.2492e-13, 1.0498e-13, 9.8168e-14,\n            1.2246e-13, 2.1833e-13, 8.3410e-14, 9.0312e-14, 5.0942e-14, 1.0585e-13,\n            5.9249e-14, 1.1132e-13, 1.3109e-13, 5.9564e-14, 1.0027e-13, 1.1845e-13,\n            6.3211e-14, 7.3757e-14, 1.1220e-13, 1.4400e-13, 1.3270e-13, 3.8605e-14,\n            6.2024e-14, 1.1665e-13, 5.5516e-14, 1.2477e-13, 7.1316e-14, 1.3684e-13,\n            1.7211e-13, 1.6799e-13, 3.0723e-13, 9.0628e-14, 5.8052e-14, 1.1186e-13,\n            9.4567e-14, 1.0228e-13, 3.6175e-13, 1.1638e-13, 1.0391e-13, 1.3213e-13,\n            7.0116e-14, 1.3331e-13, 1.2531e-13, 1.1184e-13, 3.0877e-13, 1.3612e-13,\n            1.3214e-13, 6.7807e-14, 7.1194e-14, 7.8508e-14, 9.5323e-14, 9.1795e-14,\n            9.0804e-14, 5.1333e-14, 1.3347e-13, 1.0073e-13, 7.0094e-14, 1.0607e-13,\n            1.1069e-13, 1.5909e-13, 9.3880e-14, 1.3715e-13, 1.4272e-13, 9.9940e-14,\n            1.4847e-13, 1.7122e-13, 8.4979e-14, 6.0835e-14, 3.6159e-14, 7.6056e-14,\n            4.8229e-14, 7.9954e-14, 9.6034e-14, 1.5165e-13, 1.9018e-13, 1.7972e-13,\n            1.1732e-13, 4.9772e-14, 1.2825e-13, 9.7365e-14, 1.2367e-13, 9.9164e-14,\n            1.3361e-13, 8.4116e-14, 4.0667e-14, 1.2204e-13, 1.4444e-13, 4.9784e-14,\n            1.1708e-13, 1.0470e-13, 5.4781e-14, 9.6881e-14, 1.2831e-13, 1.2784e-13,\n            8.8578e-14, 1.0083e-13, 7.1435e-14, 8.5028e-14, 7.0874e-14, 1.1158e-13,\n            1.2690e-13, 1.0840e-13, 5.3845e-14, 7.5186e-14, 9.2077e-14, 7.2748e-14,\n            1.3685e-13, 6.5301e-14, 1.1399e-13, 1.0782e-13, 6.8293e-14, 6.9710e-14,\n            5.9625e-14, 1.3265e-13, 1.3779e-13, 1.0840e-13, 1.1994e-13, 8.2618e-14,\n            7.0735e-14, 1.1188e-13, 9.1458e-14, 1.1593e-13, 1.2063e-13, 9.9013e-14,\n            9.4637e-14, 1.2363e-13, 3.5590e-13, 1.5972e-13, 1.4814e-13, 1.0673e-13,\n            9.9019e-14, 1.2944e-13, 1.1740e-13, 1.1522e-13, 1.2514e-13, 5.7766e-14,\n            1.2007e-13, 9.4649e-14, 1.5949e-13, 1.2192e-13, 1.0333e-13, 1.2312e-13,\n            1.1377e-13, 1.5585e-13, 2.6306e-13, 7.5982e-14, 1.2092e-13, 1.0893e-13,\n            1.4694e-13, 1.0961e-13, 1.0029e-13, 9.0630e-14, 1.5776e-13, 4.1166e-14,\n            6.4244e-14, 1.1594e-13, 1.1467e-13, 1.5271e-13, 2.5060e-13, 7.3389e-14,\n            2.8834e-13, 1.9608e-13, 1.3120e-13, 1.1605e-13, 1.3456e-13, 8.2256e-14,\n            1.9997e-13, 1.2743e-13, 1.2647e-13, 1.2303e-13, 1.0914e-13, 1.2219e-13,\n            7.7925e-14, 4.9895e-14, 1.0742e-13, 1.1897e-14, 6.8460e-14, 1.0441e-13,\n            1.0024e-13, 8.6018e-14, 1.4762e-13, 9.7101e-14, 9.6189e-14, 2.2983e-13,\n            1.0469e-13, 1.3132e-13, 1.4130e-13, 1.1986e-13, 3.2134e-13, 1.3877e-13,\n            4.0175e-13, 6.8948e-14, 1.3152e-13, 1.2116e-13, 2.0477e-13, 1.0492e-13,\n            1.0871e-13, 1.4843e-13, 1.0908e-13, 1.1965e-13, 1.5527e-13, 6.9499e-14,\n            1.0905e-13, 1.1443e-13, 1.1860e-13, 1.3881e-13, 4.0913e-14, 5.6265e-14,\n            5.7066e-14, 1.7034e-13, 1.2634e-13, 1.5051e-13, 6.1821e-14, 1.1033e-13,\n            1.3070e-13, 1.1330e-13, 1.6887e-13, 1.1884e-13, 1.1557e-13, 2.3239e-13,\n            6.9418e-14, 1.2171e-13, 7.8720e-14, 1.6321e-13, 1.2774e-13, 1.1048e-13,\n            1.3857e-13, 1.4618e-13, 1.5342e-13, 1.8644e-13, 9.3976e-14, 1.3387e-13,\n            1.0395e-13, 1.1047e-13, 8.4700e-14, 1.6822e-13, 9.8326e-14, 4.9586e-14,\n            6.0042e-14, 4.2812e-14, 5.8570e-14, 1.0285e-13, 1.3474e-13, 1.1742e-13,\n            1.4094e-13, 1.4283e-13, 8.2178e-14, 1.3296e-13, 1.1485e-13, 9.9979e-14,\n            1.2583e-13, 1.0878e-13, 1.7800e-13, 8.2551e-14, 1.7798e-13, 1.4618e-13,\n            4.0423e-14, 1.0296e-13, 1.0087e-13, 1.1179e-13, 1.2120e-13, 1.2042e-13,\n            1.2504e-13, 1.5022e-13, 1.0139e-13, 1.0342e-13, 1.1348e-13, 1.2724e-13,\n            1.1774e-13, 2.8196e-13, 4.7288e-14, 1.5955e-13, 1.1953e-13, 9.7412e-14,\n            8.9965e-14, 5.7256e-14, 1.3400e-13, 9.4725e-14, 1.0982e-13, 1.9606e-13,\n            1.0411e-13, 8.7380e-14, 1.6297e-13, 9.4871e-14, 1.8364e-13, 1.1144e-13,\n            1.3134e-13, 3.3604e-14, 3.8231e-14, 7.8456e-14, 1.1778e-13, 3.5839e-13,\n            7.2924e-14, 1.1635e-13, 1.8712e-13, 1.0030e-13, 9.5968e-14, 1.3903e-13,\n            1.3284e-13, 1.2823e-13, 9.7479e-14, 1.3142e-13, 4.8489e-14, 1.2257e-13,\n            8.1139e-14, 9.7512e-14, 8.0779e-14, 1.0427e-13, 1.0993e-13, 5.6799e-14,\n            7.4137e-14, 1.3569e-13, 3.8423e-14, 1.4635e-13, 2.9073e-13, 9.9963e-14,\n            1.1965e-13, 2.0650e-13, 1.6219e-13, 7.0600e-14, 3.7969e-13, 8.5864e-14,\n            9.5639e-14, 1.0649e-13, 1.2865e-13, 1.2067e-13, 9.9571e-14, 8.4232e-14,\n            7.5053e-14, 2.5720e-13, 1.4378e-13, 7.1684e-14, 4.3687e-14, 8.2976e-14,\n            5.3766e-14, 1.2609e-13, 1.5688e-13, 9.8320e-14, 9.4124e-14, 1.1358e-13,\n            1.3065e-13, 6.0903e-14, 1.3814e-13, 3.9109e-13, 1.2098e-13, 1.0624e-13,\n            1.1338e-13, 1.3409e-13, 1.6426e-13, 1.2941e-13, 5.7389e-14, 1.0474e-13,\n            1.2035e-13, 1.6472e-13, 8.7857e-14, 9.9940e-14, 5.8661e-14, 3.9591e-14,\n            5.6207e-14, 1.5935e-13, 1.1659e-13, 1.2878e-13, 1.3134e-13, 1.1132e-13,\n            2.4218e-13, 1.2427e-13, 4.7614e-14, 1.3209e-13, 1.0024e-13, 1.3117e-13,\n            1.1158e-13, 1.0200e-13, 1.1878e-13, 1.2418e-13, 1.2320e-13, 1.5664e-13,\n            4.5711e-14, 1.4731e-13, 9.3031e-14, 1.2131e-13, 4.7847e-14, 9.4201e-14,\n            1.4442e-13, 1.0151e-13])},\n   98: {'exp_avg': tensor([ 2.6861e-08, -5.7067e-09, -5.5975e-08,  ...,  9.4722e-09,\n             1.0514e-07,  6.3598e-08]),\n    'exp_avg_sq': tensor([4.0145e-14, 3.7268e-14, 3.7749e-14,  ..., 1.6140e-14, 3.6542e-14,\n            3.8785e-14])},\n   99: {'exp_avg': tensor([-2.2124e-08, -6.2828e-08, -4.1923e-09,  ...,  3.4921e-08,\n             2.6586e-08,  4.2508e-09]),\n    'exp_avg_sq': tensor([7.1218e-14, 6.4721e-14, 9.9775e-14,  ..., 2.2515e-14, 9.1317e-14,\n            1.5394e-13])},\n   100: {'exp_avg': tensor([ 1.3648e-07, -1.5569e-07,  3.2671e-08,  6.4539e-08,  1.0380e-08,\n             1.1913e-07, -1.2987e-07, -3.2953e-08, -9.2511e-09,  7.6746e-08,\n             9.6443e-08, -6.2776e-08,  1.3642e-07, -1.2883e-07, -5.6510e-08,\n            -5.6285e-08,  6.2178e-08,  6.4687e-08, -1.4634e-07, -2.8763e-08,\n             2.2954e-08,  3.8554e-08, -1.4829e-07, -1.0990e-07,  1.1947e-07,\n             7.6080e-08, -3.8192e-09, -4.5490e-08, -9.3200e-09, -3.5453e-08,\n            -1.5139e-08,  1.2609e-07, -6.6477e-10,  1.6468e-07, -4.5164e-08,\n            -3.0740e-08,  1.0793e-07,  6.2225e-08, -8.8819e-08, -8.4026e-09,\n             3.2861e-08, -2.2973e-08,  7.0547e-09,  2.6308e-09,  1.4152e-08,\n            -5.0692e-08,  1.3754e-07,  7.4375e-08, -1.5329e-07,  1.8756e-07,\n            -2.4195e-07,  1.9923e-07, -1.7246e-07, -5.2635e-10,  2.8381e-08,\n             2.0285e-08, -1.0484e-07,  1.6315e-07,  1.9522e-09,  4.6702e-08,\n             6.9723e-08,  1.6995e-08,  1.2579e-07, -1.4522e-07,  1.6418e-07,\n            -7.6975e-08,  2.8791e-07,  5.5058e-09,  6.8025e-08,  8.5477e-08,\n            -1.1452e-07, -9.5595e-08, -1.0947e-07, -5.6612e-08,  1.2096e-07,\n            -4.6062e-08, -2.8452e-08, -8.5747e-08, -2.1364e-08, -1.1820e-07,\n             4.5605e-08, -1.2897e-07,  6.5742e-08, -1.0963e-07, -1.1611e-07,\n             2.0548e-07, -5.9233e-08,  2.2316e-07,  7.9676e-08,  3.2058e-08,\n            -1.0484e-08, -1.1862e-07,  7.3886e-08, -1.2532e-07, -5.2621e-09,\n            -1.7326e-07, -3.6334e-08,  2.0685e-07, -1.3130e-08, -6.8138e-08,\n             1.7732e-07,  2.4768e-07, -1.6045e-08,  6.0636e-09,  2.5262e-07,\n            -7.3928e-08,  4.4900e-09,  1.3273e-07,  1.2272e-07,  8.7649e-08,\n             8.5241e-08,  1.0204e-07, -8.2945e-08, -1.0503e-07,  5.0146e-08,\n            -2.6198e-07,  1.2167e-07,  1.0866e-09, -1.2628e-08,  2.0070e-07,\n            -1.6499e-07,  6.8429e-09,  9.6216e-08,  7.0810e-08, -3.4924e-08,\n             9.7985e-08, -2.4006e-08, -6.9985e-09, -1.6504e-07,  7.9254e-08,\n             7.9270e-08, -2.8504e-07, -5.2297e-08,  6.0884e-08,  1.9760e-07,\n             1.1479e-07, -1.3095e-07, -7.8667e-08,  1.8445e-08, -1.5686e-07,\n            -6.7080e-08,  2.1923e-07,  1.5581e-07,  8.2199e-09,  1.6824e-07,\n             2.0060e-08, -4.5386e-08, -1.3837e-07, -8.0972e-08,  1.3483e-07,\n            -1.0000e-07, -4.0120e-08, -8.3965e-08,  2.2984e-07, -1.1841e-07,\n            -7.6283e-08,  4.4043e-08,  3.0768e-07,  1.1815e-07, -1.8900e-07,\n             1.2198e-07,  5.5061e-08,  4.4475e-08, -1.3453e-07,  1.5487e-07,\n            -1.6185e-07,  4.8672e-09,  1.5295e-08, -1.0755e-07, -5.2007e-08,\n            -8.9736e-09, -7.7580e-08,  3.7191e-08, -5.6250e-09,  8.7516e-08,\n            -1.1997e-07, -2.0411e-07, -1.2804e-07, -7.7375e-09,  6.7575e-08,\n             7.4553e-08, -1.2062e-08, -6.8051e-08, -5.6771e-08, -1.2524e-07,\n             9.8793e-08, -1.3376e-07,  1.6263e-07,  2.5446e-08,  1.3346e-07,\n            -8.5865e-09,  7.2704e-08,  1.1658e-07, -2.4201e-08,  7.6753e-08,\n            -2.1790e-07, -3.7302e-09, -3.7902e-08,  9.9014e-08,  1.6088e-07,\n            -1.0442e-07,  5.7814e-08, -4.8588e-08,  9.8124e-08,  6.4323e-08,\n            -2.5019e-08, -1.2677e-07,  1.4968e-07,  9.6515e-08,  8.0754e-08,\n            -1.6931e-07,  6.8438e-08, -1.0004e-07, -5.9650e-08,  7.8586e-09,\n            -4.8265e-08,  1.8389e-07, -6.5136e-08, -2.5988e-07, -8.9322e-09,\n             9.2222e-08,  9.0275e-09, -4.2051e-08,  1.7890e-07,  1.5846e-07,\n             4.4192e-08, -1.2327e-07,  1.0198e-08,  7.7456e-08, -3.1847e-08,\n            -3.9708e-08, -1.0372e-07, -1.5017e-08,  1.0831e-07, -3.7651e-08,\n             2.0052e-08, -6.2035e-08, -6.1642e-08,  8.2912e-08, -1.4421e-07,\n             1.6139e-07, -6.0471e-08, -1.1061e-08,  6.5666e-08,  1.5351e-07,\n            -1.0665e-07,  3.9700e-09,  4.5283e-08, -5.5450e-08,  5.1830e-09,\n             5.5413e-08,  4.2088e-08, -1.8460e-07,  1.1649e-08,  1.9057e-07,\n             5.7822e-08,  9.0164e-08, -6.9969e-08,  8.8750e-08, -1.1589e-07,\n             1.1717e-07, -7.7958e-08,  1.2594e-07, -9.5247e-08, -4.0464e-08,\n             4.8211e-08,  1.7511e-07, -6.2615e-08, -2.5469e-07,  2.5277e-07,\n            -1.0386e-07,  5.7808e-08, -2.5475e-08,  3.6550e-08, -5.7110e-08,\n            -6.2677e-08,  1.0393e-07,  3.6310e-09, -1.6056e-07,  1.0556e-07,\n            -8.4990e-08,  1.1080e-07, -3.9478e-08, -1.1587e-07,  1.1741e-07,\n            -2.7040e-08,  1.1864e-07, -6.6055e-08, -1.2503e-07, -3.3721e-08,\n            -1.3890e-07,  6.4092e-08, -4.5099e-08, -4.1125e-08,  7.7819e-08,\n             8.5043e-09, -1.9825e-07,  1.1390e-07, -2.8303e-07,  4.5026e-08,\n             2.0947e-07, -1.0178e-07, -6.2739e-08,  6.1921e-09, -4.2165e-08,\n             1.2367e-07,  8.8839e-08, -2.4736e-07, -4.0597e-08,  1.8728e-09,\n            -6.1356e-08,  6.1906e-09,  1.9232e-07, -6.8839e-08, -4.8022e-09,\n            -1.4291e-07, -4.1839e-08, -5.5589e-09, -4.8765e-08, -1.9230e-09,\n             3.1802e-08,  8.2132e-09,  1.9085e-08,  3.9022e-08, -7.3901e-08,\n             7.7396e-08,  3.6486e-08, -2.8001e-08, -1.3586e-07,  7.4399e-08,\n             1.6547e-08,  4.3075e-08,  4.0402e-08, -1.0138e-07, -1.8334e-08,\n             4.9611e-08, -2.5360e-07, -6.7549e-08, -9.5135e-08, -6.9160e-09,\n             8.5607e-10,  1.1861e-07,  8.7049e-09, -2.9273e-08,  1.1911e-07,\n             1.1300e-07,  2.3742e-07,  7.2023e-08,  6.7390e-08, -3.6461e-08,\n             1.1201e-07, -7.9189e-08, -3.1818e-08,  2.8105e-07, -6.2268e-08,\n            -1.1165e-08, -1.2103e-07,  5.9482e-08,  5.9624e-08,  5.4447e-08,\n            -7.0274e-08, -2.3005e-07, -1.7448e-07,  4.9198e-08,  9.5994e-08,\n            -1.1269e-07, -6.6734e-09, -6.9385e-08, -4.2098e-09,  1.1207e-07,\n            -1.6388e-07, -2.3828e-08, -5.6368e-08, -6.0852e-09,  7.8570e-09,\n            -6.4074e-08, -1.3997e-07,  1.3931e-07,  1.4171e-08, -1.2714e-07,\n            -7.2598e-08, -1.0687e-07,  3.0517e-08,  8.4780e-08,  1.2447e-08,\n            -1.6099e-07,  4.4239e-08,  3.8956e-09, -1.0824e-07,  7.2743e-08,\n             1.7725e-09, -1.4732e-07,  3.4153e-08, -8.1397e-08, -3.0843e-08,\n             9.0762e-09, -3.0602e-09,  6.9896e-08,  1.3124e-07, -1.8260e-07,\n             9.1303e-08, -9.7467e-09, -1.1778e-07,  1.6505e-07, -5.8369e-08,\n            -7.0408e-08, -1.2430e-07, -4.2602e-08,  1.9131e-08, -6.6864e-08,\n            -4.6780e-08,  4.3197e-09, -4.3046e-08,  6.9560e-08, -9.7441e-08,\n             1.6665e-07, -9.7615e-08, -4.3929e-08, -1.5738e-07, -3.3229e-08,\n             2.2816e-08,  1.4180e-07, -1.2738e-07, -2.2414e-08,  1.1673e-07,\n             4.4739e-08, -6.3020e-08, -8.0732e-08,  1.8958e-07,  7.5764e-08,\n             7.0505e-08,  1.8701e-08,  2.1352e-08,  7.3523e-08, -1.3996e-08,\n            -1.3130e-08,  5.2952e-08,  1.3325e-07, -4.0912e-09, -1.7810e-07,\n             5.9520e-08, -5.5385e-08,  1.6428e-07,  2.2351e-07, -2.9327e-08,\n             4.4874e-09,  5.0601e-08,  8.2418e-08,  1.6703e-07, -1.8624e-07,\n             2.0259e-08,  7.4324e-08,  1.5655e-08, -1.2995e-07, -1.5068e-08,\n            -8.6162e-09,  9.4748e-09,  6.8130e-08, -3.3860e-08,  1.0306e-07,\n            -2.5321e-08, -2.6697e-08, -1.0737e-07,  1.7341e-09, -1.3069e-08,\n            -9.9941e-09,  1.5571e-07,  6.1563e-08, -2.7781e-07, -7.4775e-08,\n            -4.2383e-08,  1.5793e-07, -1.1941e-07,  4.7658e-08, -1.4815e-07,\n            -7.2275e-08,  6.5010e-08,  8.7521e-08, -2.3891e-07,  1.4100e-08,\n            -2.2135e-08, -5.3032e-08,  5.9517e-08, -1.2972e-07,  2.0343e-07,\n             1.0344e-07,  1.0041e-07, -5.2629e-08, -1.1286e-07,  6.4549e-08,\n             2.8305e-08, -3.5260e-08,  7.7221e-08, -1.4954e-07,  7.5453e-08,\n             2.1250e-07, -2.2307e-07, -5.5365e-09, -1.2298e-07,  1.2502e-07,\n             4.0745e-08, -1.3660e-07,  1.9725e-07, -3.4861e-08, -6.4023e-08,\n             2.9242e-07, -8.6589e-08, -3.2552e-08,  5.1178e-08,  1.1721e-08,\n            -1.7105e-07,  4.9798e-08]),\n    'exp_avg_sq': tensor([1.9095e-13, 1.6948e-13, 1.5348e-13, 1.5318e-13, 1.6401e-13, 3.2203e-13,\n            1.8858e-13, 1.8074e-13, 2.6948e-13, 1.6880e-13, 1.5941e-13, 2.0308e-13,\n            1.8914e-13, 1.5239e-13, 1.6301e-13, 1.6859e-13, 1.3641e-13, 2.2607e-13,\n            1.7633e-13, 1.9211e-13, 1.9650e-13, 2.0371e-13, 1.5476e-13, 2.3293e-13,\n            2.2530e-13, 2.6065e-13, 1.6868e-13, 1.7855e-13, 1.5912e-13, 2.2672e-13,\n            3.7259e-13, 2.0144e-13, 1.4169e-13, 1.7919e-13, 7.0846e-13, 1.7703e-13,\n            1.6927e-13, 1.5595e-13, 1.7990e-13, 1.6573e-13, 1.9237e-13, 2.0425e-13,\n            2.0923e-13, 1.5753e-13, 1.3970e-13, 1.6661e-13, 1.4876e-13, 2.2058e-13,\n            1.6447e-13, 1.9786e-13, 1.9292e-13, 2.5767e-13, 1.4946e-13, 1.8064e-13,\n            1.9152e-13, 1.5614e-13, 1.8578e-13, 1.7600e-13, 1.4718e-12, 2.0786e-13,\n            1.9852e-13, 1.4434e-13, 2.1523e-13, 1.5453e-13, 1.8255e-13, 1.2767e-13,\n            2.3967e-13, 2.4182e-13, 1.7964e-13, 1.6952e-13, 1.6183e-13, 1.5414e-13,\n            1.6531e-13, 2.5736e-13, 4.4196e-13, 2.0051e-13, 1.1396e-13, 1.5049e-13,\n            1.4116e-13, 1.6776e-13, 1.6119e-13, 1.6767e-13, 1.4425e-13, 1.9098e-13,\n            1.6196e-13, 1.6194e-13, 1.5911e-13, 1.6208e-13, 1.5787e-13, 1.4609e-13,\n            1.9786e-13, 1.2723e-13, 1.6646e-13, 1.5720e-13, 1.9791e-13, 1.7665e-13,\n            1.6434e-13, 2.1841e-13, 1.9357e-13, 1.5124e-13, 1.4932e-13, 1.7658e-13,\n            1.6746e-13, 1.8817e-13, 1.9205e-13, 6.4737e-13, 1.3801e-13, 1.3948e-13,\n            2.8430e-13, 1.9773e-13, 2.0210e-13, 2.3688e-13, 1.5800e-13, 2.1262e-13,\n            1.7309e-13, 3.2034e-13, 1.5694e-13, 1.5613e-13, 2.1124e-13, 1.7801e-13,\n            2.6327e-13, 3.1510e-13, 1.5195e-13, 2.1893e-13, 1.4548e-13, 1.7517e-13,\n            1.4715e-13, 1.6884e-13, 3.2041e-13, 1.6144e-13, 1.8118e-13, 2.8291e-13,\n            1.6883e-13, 1.6601e-13, 2.3770e-13, 1.5405e-13, 1.6983e-13, 1.3821e-13,\n            1.5124e-13, 1.7063e-13, 1.7583e-13, 1.7402e-13, 3.1778e-13, 4.0866e-13,\n            1.7203e-13, 1.5221e-13, 1.4546e-13, 1.4717e-13, 2.1361e-13, 1.6362e-13,\n            1.8451e-13, 1.2044e-13, 1.5564e-13, 2.4138e-13, 1.6809e-13, 1.4249e-13,\n            1.7046e-13, 2.9267e-13, 1.5764e-13, 2.0165e-13, 1.4976e-13, 2.0565e-13,\n            1.9885e-13, 3.2345e-13, 2.4406e-13, 1.8031e-13, 2.2417e-13, 1.2367e-13,\n            2.2915e-13, 3.5259e-13, 1.5573e-13, 1.7700e-13, 1.7388e-13, 1.8792e-13,\n            1.5008e-13, 1.5280e-13, 2.6138e-13, 1.4577e-13, 1.6498e-13, 1.9810e-13,\n            1.6971e-13, 1.7156e-13, 2.0512e-13, 2.5426e-13, 1.3296e-13, 1.7788e-13,\n            3.2211e-13, 2.6266e-13, 1.4103e-13, 1.8831e-13, 1.9121e-13, 1.7914e-13,\n            1.6974e-13, 1.9311e-13, 1.7100e-13, 2.0087e-13, 1.5400e-13, 2.4201e-13,\n            1.5476e-13, 2.5551e-13, 1.7367e-13, 1.7692e-13, 2.2724e-13, 1.5586e-13,\n            1.6486e-13, 1.9053e-13, 1.5937e-13, 2.7924e-13, 1.7192e-13, 1.8462e-13,\n            2.6042e-13, 2.7713e-13, 1.6046e-13, 1.6178e-13, 1.9157e-13, 1.1866e-13,\n            3.3962e-13, 1.6997e-13, 1.2360e-13, 2.6330e-13, 1.6118e-13, 1.9397e-13,\n            2.3286e-13, 1.9320e-13, 2.2547e-13, 2.3470e-13, 1.5709e-13, 1.3038e-13,\n            1.3171e-13, 1.8640e-13, 1.5304e-13, 1.7988e-13, 1.9802e-13, 1.4678e-13,\n            1.3100e-13, 2.5893e-13, 2.1477e-13, 2.4523e-13, 1.9795e-13, 3.6488e-13,\n            2.7401e-13, 1.8083e-13, 1.8035e-13, 1.6939e-13, 2.1600e-13, 1.4450e-13,\n            2.0791e-13, 3.2974e-13, 1.7713e-13, 1.8852e-13, 1.3269e-13, 1.7449e-13,\n            1.8812e-13, 1.7524e-13, 1.9881e-13, 1.8249e-13, 1.7222e-13, 1.8925e-13,\n            2.7551e-13, 2.0376e-13, 1.3703e-13, 1.6943e-13, 2.0264e-13, 2.6608e-13,\n            2.0862e-13, 1.9516e-13, 1.4731e-13, 1.8972e-13, 1.8770e-13, 2.6634e-13,\n            2.4612e-13, 2.5157e-13, 1.5056e-13, 1.4551e-13, 2.5963e-13, 2.2409e-13,\n            1.5807e-13, 1.7357e-13, 2.4347e-13, 1.6472e-13, 1.9215e-13, 1.9322e-13,\n            1.8938e-13, 3.0982e-13, 1.4825e-13, 1.5674e-13, 1.6614e-13, 2.1073e-13,\n            2.0737e-13, 1.8375e-13, 1.6343e-13, 1.8895e-13, 1.6660e-13, 1.8645e-13,\n            1.3973e-13, 2.1647e-13, 1.7432e-13, 1.6638e-13, 3.4197e-13, 1.6699e-13,\n            1.4715e-13, 2.4705e-13, 2.1060e-13, 2.3131e-13, 1.4349e-13, 1.5628e-13,\n            1.5979e-13, 2.2553e-13, 3.9184e-13, 1.8891e-13, 2.3704e-13, 1.8803e-13,\n            1.8985e-13, 1.6164e-13, 1.8720e-13, 2.0407e-13, 1.5005e-13, 1.5401e-13,\n            1.9802e-13, 5.2476e-13, 1.4216e-13, 1.2814e-13, 2.2100e-13, 2.0818e-13,\n            1.5731e-13, 2.5376e-13, 1.4845e-13, 1.5250e-13, 2.2643e-13, 1.8620e-13,\n            1.9619e-13, 1.3117e-13, 1.7789e-13, 2.2037e-13, 1.8537e-13, 1.4741e-13,\n            1.9171e-13, 1.1355e-13, 1.3321e-13, 4.1115e-13, 2.1418e-13, 2.7574e-13,\n            2.1457e-13, 1.8130e-13, 1.8744e-13, 1.8047e-13, 1.6432e-13, 1.6309e-13,\n            1.6081e-13, 2.9790e-13, 2.0317e-13, 1.6520e-13, 1.2976e-13, 3.5064e-13,\n            1.7256e-13, 1.9580e-13, 1.8080e-13, 2.0565e-13, 1.5586e-13, 1.6071e-13,\n            1.8297e-13, 1.7055e-13, 1.8891e-13, 1.5420e-13, 1.3608e-13, 1.6356e-13,\n            1.9165e-13, 1.4816e-13, 1.5989e-13, 2.6914e-13, 2.4458e-13, 2.0112e-13,\n            1.9973e-13, 2.3265e-13, 1.4912e-13, 1.5728e-13, 1.7383e-13, 1.9216e-13,\n            1.8949e-13, 2.0252e-13, 1.5874e-13, 1.4572e-13, 1.8833e-13, 1.8707e-13,\n            1.5889e-13, 1.8083e-13, 1.8036e-13, 2.1711e-13, 1.9766e-13, 2.3424e-13,\n            1.3569e-13, 1.4475e-13, 2.1288e-13, 1.5117e-13, 1.6194e-13, 1.4654e-13,\n            2.2446e-13, 2.4655e-13, 1.5238e-13, 1.7034e-13, 1.7636e-13, 1.4310e-13,\n            1.7958e-13, 1.4128e-13, 2.7469e-13, 1.6948e-13, 1.9859e-13, 2.7658e-13,\n            2.5421e-13, 1.7419e-13, 2.1090e-13, 2.4965e-13, 1.6236e-13, 2.2243e-13,\n            1.5254e-13, 1.9875e-13, 1.3818e-13, 1.9278e-13, 3.2171e-13, 1.5322e-13,\n            1.5808e-13, 1.6709e-13, 1.6114e-13, 1.8740e-13, 2.5250e-13, 2.2751e-13,\n            2.3028e-13, 1.5913e-13, 1.8688e-13, 2.2675e-13, 2.0643e-13, 1.8145e-13,\n            1.2401e-13, 1.3779e-13, 1.4183e-13, 2.1488e-13, 1.4164e-13, 2.0950e-13,\n            1.5466e-13, 1.8642e-13, 2.7541e-13, 2.2951e-13, 1.7667e-13, 3.9278e-13,\n            1.4730e-13, 1.9423e-13, 1.7697e-13, 1.4345e-13, 1.7580e-13, 1.6557e-13,\n            1.8188e-13, 1.6799e-13, 1.7377e-13, 1.6060e-13, 4.2773e-13, 2.1374e-13,\n            1.4017e-13, 1.8006e-13, 2.0067e-13, 1.9342e-13, 1.7928e-13, 1.5992e-13,\n            1.7929e-13, 1.7937e-13, 2.0241e-13, 1.9484e-13, 1.8700e-13, 2.2940e-13,\n            2.4602e-13, 1.6395e-13, 1.6906e-13, 1.6581e-13, 1.4825e-13, 1.8879e-13,\n            2.2129e-13, 2.6156e-13, 2.5752e-13, 1.2739e-13, 2.0788e-13, 1.9263e-13,\n            1.4989e-13, 1.5756e-13, 1.7364e-13, 2.1028e-13, 1.6699e-13, 2.5431e-13,\n            1.9072e-13, 1.3962e-13, 2.0863e-13, 2.0284e-13, 2.1684e-13, 1.3738e-13,\n            1.7212e-13, 1.4673e-13, 1.8445e-13, 2.5289e-13, 1.3391e-13, 1.8616e-13,\n            1.8726e-13, 1.5616e-13, 1.1719e-13, 1.3580e-13, 1.9397e-13, 1.6337e-13,\n            1.6922e-13, 1.7532e-13, 2.2939e-13, 3.3498e-13, 1.9572e-13, 1.6100e-13,\n            1.6170e-13, 2.0390e-13])},\n   101: {'exp_avg': tensor([ 1.1133e-07, -1.1825e-07,  3.4466e-08,  5.1736e-08, -5.2246e-08,\n             4.8285e-08, -1.0417e-07,  1.8587e-08, -3.7605e-08,  2.7945e-09,\n             8.8008e-08, -1.5926e-08,  4.0401e-08, -5.5083e-08, -4.2032e-08,\n            -4.5910e-08,  6.0027e-09,  1.6411e-07, -1.2215e-07, -5.2686e-08,\n             3.6951e-08,  2.1917e-08, -1.1414e-07, -4.9380e-08,  3.8445e-08,\n             8.3760e-08,  8.2134e-10, -6.5016e-08, -1.8069e-08, -4.6572e-08,\n            -1.0432e-08,  1.3552e-07, -4.2466e-09,  6.4548e-08, -4.4497e-08,\n            -4.8394e-08,  4.3963e-08,  5.8420e-08, -1.3736e-08, -1.3462e-08,\n             2.1939e-09, -2.2812e-08,  7.3288e-08, -4.1438e-08,  1.3281e-08,\n            -5.4842e-08,  7.1286e-08,  2.8716e-08, -7.9730e-08,  1.5620e-07,\n            -1.2139e-07,  1.7301e-07, -9.9601e-08,  1.1485e-08,  2.4677e-08,\n            -5.5887e-08, -8.6430e-08,  9.5287e-08, -1.0908e-07,  5.1286e-08,\n             9.8874e-08,  2.1492e-08,  1.2549e-07, -2.1317e-08,  1.1375e-07,\n            -8.6906e-08,  2.2136e-07,  2.7457e-08,  9.7267e-08,  8.2497e-08,\n            -5.5948e-08, -6.7073e-08, -1.1184e-07, -1.1982e-08,  8.1842e-08,\n             2.0979e-08,  2.6043e-08,  6.1286e-09, -2.2610e-08, -1.4491e-07,\n            -4.0986e-08, -2.7708e-08, -1.5901e-08,  3.5423e-08, -1.9535e-08,\n             1.4579e-07, -1.0644e-07,  1.1101e-07,  8.0732e-08,  3.9793e-09,\n             3.7476e-08, -3.9464e-08,  2.8051e-08, -4.1011e-08, -4.7312e-08,\n            -1.2324e-07, -2.0502e-08,  1.5247e-07, -6.8126e-09, -8.3123e-08,\n             5.5423e-08,  1.7165e-07, -1.6550e-08,  7.7089e-08,  1.7714e-07,\n            -5.0274e-08, -1.7410e-08,  9.2407e-08,  7.4657e-08, -4.0189e-08,\n             2.1836e-08,  9.5874e-08, -4.8643e-08, -9.8584e-08, -5.1346e-08,\n            -4.0255e-08,  8.3906e-08, -7.7258e-08, -4.8555e-09,  1.6441e-07,\n            -1.4075e-07,  1.0104e-07,  4.9667e-08,  1.6868e-08, -2.6331e-08,\n             2.9872e-08, -3.8690e-08,  8.3339e-08, -1.1366e-07,  4.5230e-08,\n             5.2738e-08, -1.2891e-07, -2.0358e-08,  4.6295e-08,  1.2409e-07,\n             6.3892e-08, -6.5422e-08,  2.8069e-09,  4.4790e-08, -1.6651e-08,\n            -1.0373e-07,  1.4421e-07,  7.2731e-08,  1.5883e-08,  1.0262e-07,\n             4.9482e-08, -2.1557e-08, -1.5701e-07, -3.4217e-08,  1.0740e-07,\n            -3.9845e-08, -9.8335e-08, -2.4416e-10,  7.0438e-08, -2.3871e-08,\n            -7.2902e-08,  2.8349e-08,  2.1711e-07,  6.8802e-08, -1.2425e-07,\n             9.0954e-08, -1.2030e-08,  5.8116e-08, -1.0255e-07,  1.3076e-07,\n            -1.7300e-07,  4.0349e-08,  8.3233e-08, -9.5137e-08,  1.9816e-08,\n             9.1239e-09, -1.4326e-08, -4.0894e-09, -6.3304e-08,  6.2473e-09,\n            -6.8837e-08, -1.3070e-07, -9.2259e-08, -2.7169e-09,  1.6883e-08,\n             1.0933e-07, -2.6465e-08, -7.5791e-08, -1.2849e-08, -7.0824e-08,\n            -6.5929e-10, -1.1652e-08,  5.9924e-08,  6.6066e-08,  1.0895e-07,\n            -1.9505e-08,  3.8719e-08,  8.3899e-08, -6.0538e-08,  6.9035e-08,\n            -1.3141e-07,  2.3847e-08,  7.8915e-08,  2.4931e-08,  8.5130e-08,\n            -8.1532e-08,  2.1168e-08, -1.5764e-08,  1.3717e-08,  7.7474e-08,\n             1.1009e-08, -7.8102e-08,  3.2518e-08,  5.6699e-08,  9.7255e-08,\n            -2.6915e-08,  9.9942e-08, -8.5667e-08, -3.8122e-08,  2.4404e-08,\n            -1.4752e-08,  5.6206e-08, -8.8664e-08, -1.9954e-07, -3.3290e-08,\n             6.4608e-08,  1.2441e-07, -2.5794e-08,  1.0085e-07,  1.1574e-07,\n             6.2324e-08, -6.2500e-08, -8.8503e-08,  9.9494e-08, -1.1895e-07,\n            -2.0879e-08, -7.8521e-08,  7.8917e-08,  6.9000e-08,  4.8109e-08,\n             5.4974e-09,  6.3582e-08,  1.4048e-08,  9.3196e-08, -4.2201e-08,\n             8.2792e-08,  1.3282e-08,  3.4593e-08,  1.6861e-08,  5.6621e-08,\n            -4.8209e-08,  8.8601e-08,  1.3428e-07,  7.5499e-09,  5.8733e-08,\n             3.0969e-08,  9.0813e-08, -3.7610e-08,  9.2195e-08,  1.1454e-07,\n             2.0328e-08, -3.1285e-08, -1.6597e-08,  1.2047e-08, -2.9260e-08,\n             2.5513e-08, -8.0459e-08,  1.2081e-07, -2.0797e-08, -7.5051e-10,\n            -2.2305e-08,  9.0798e-08, -5.9234e-08, -9.8970e-08,  2.3525e-07,\n            -6.5193e-08,  1.0352e-07, -1.0445e-08, -4.9362e-08, -3.4423e-09,\n            -1.6515e-08,  1.2852e-07,  3.6080e-08, -7.3812e-08,  1.0921e-07,\n            -5.7740e-08,  7.0716e-08, -2.1651e-08,  2.2207e-08,  4.6664e-08,\n            -2.7625e-08,  8.0253e-08, -3.6272e-08, -4.6220e-08,  6.7410e-08,\n            -7.8206e-08,  4.7807e-08, -1.4976e-08, -1.9495e-08,  8.9675e-08,\n             3.7524e-08, -1.3689e-07,  1.1194e-07, -1.9894e-07,  6.8641e-08,\n             1.4057e-07, -8.3272e-08, -1.7926e-08, -3.1237e-08,  6.3651e-08,\n             2.6479e-08,  3.6367e-08, -3.4412e-08, -3.9998e-09, -5.3237e-09,\n             1.0447e-08,  5.9621e-08,  1.0017e-07, -1.0306e-09, -2.4849e-08,\n            -7.8684e-08, -1.0592e-07, -9.1306e-09,  3.5151e-08, -4.6142e-08,\n             1.9856e-09,  1.9755e-08,  9.4857e-08,  2.7294e-08,  8.0252e-08,\n            -7.7134e-10,  9.5630e-08,  5.1176e-08, -4.9284e-08,  9.9653e-08,\n             3.8519e-08, -5.8706e-09,  6.7206e-08, -8.4931e-08,  5.7463e-08,\n             7.4237e-08, -1.6100e-07, -4.5367e-08, -5.9012e-08, -4.1252e-08,\n             7.6157e-08,  8.0773e-08, -3.1494e-08, -5.1024e-08,  1.3992e-07,\n             2.3239e-08,  1.5490e-07,  1.4283e-08,  1.1357e-07,  1.1905e-08,\n             8.9763e-08, -6.7478e-08,  1.4651e-08,  1.2572e-07, -2.1828e-08,\n             1.1463e-08, -7.3286e-08,  4.3416e-08,  3.8806e-08,  6.1497e-08,\n            -2.7688e-08, -1.0054e-07, -2.2057e-08,  4.4169e-08,  1.2700e-07,\n            -1.5064e-08,  3.6693e-09, -4.1439e-08, -5.1338e-08,  8.2416e-08,\n            -6.4559e-08, -3.0290e-08, -6.0354e-08,  3.1557e-08, -8.6882e-08,\n            -2.2460e-08, -1.1641e-08,  1.0059e-07, -4.9134e-08, -1.1989e-07,\n             1.0420e-08, -5.7377e-08,  4.6298e-08,  3.1273e-08,  2.6880e-08,\n            -9.0802e-08,  9.0887e-09, -1.3820e-08, -2.0060e-08,  1.3501e-07,\n             3.3562e-08, -9.7041e-08, -1.0819e-08, -7.2650e-08, -7.5515e-08,\n             1.4703e-10, -5.7641e-08,  4.2772e-08,  6.8188e-08, -1.3688e-07,\n             4.2682e-08,  4.6926e-08, -1.0827e-07,  1.3040e-07,  1.9128e-08,\n            -3.6381e-08, -3.1271e-08,  1.1541e-08, -3.0327e-08, -5.5269e-08,\n            -2.0699e-08, -1.9455e-08, -1.7402e-08,  7.1406e-08, -6.9358e-08,\n             1.4591e-07, -2.2185e-08, -5.4615e-08, -9.0231e-08, -6.2210e-08,\n             5.6354e-08,  9.1350e-08, -1.1674e-07, -4.9777e-08,  8.5508e-08,\n             8.0072e-08,  8.6495e-09, -8.9890e-08,  9.3968e-08, -5.8127e-09,\n             2.5951e-08,  1.7244e-09,  2.1272e-08,  6.1399e-08,  2.5160e-08,\n             1.3803e-08,  1.3481e-07,  1.2894e-07, -6.7269e-09, -1.6928e-07,\n             2.7000e-09, -2.6359e-08,  1.3983e-07, -4.4546e-08,  1.3713e-07,\n             8.3401e-08,  1.0908e-07,  9.1076e-08,  2.9234e-08, -1.4286e-07,\n             5.3194e-08,  7.9657e-08, -2.2915e-08, -1.2556e-07,  4.5709e-08,\n             4.5191e-08,  2.9318e-08,  2.5653e-08,  2.0461e-08,  6.7417e-08,\n             2.1692e-08, -6.8937e-09, -1.4526e-07,  3.1186e-08, -1.4717e-07,\n             5.0474e-10,  1.4798e-07,  9.4676e-08, -2.0728e-07, -4.9662e-08,\n            -4.8262e-08,  5.0116e-08,  7.8541e-09,  5.8618e-08, -1.3585e-08,\n             2.2392e-09,  3.2220e-08,  9.1644e-08, -1.7249e-07,  1.4834e-08,\n            -3.8617e-09, -1.8074e-08,  6.4083e-08, -1.0859e-07,  1.6888e-07,\n             6.6775e-08,  4.5634e-08,  7.5871e-09, -8.4238e-08, -1.2110e-09,\n             6.0610e-08, -5.4353e-08,  5.1992e-08, -8.3197e-09, -4.1339e-09,\n             1.1340e-07, -1.4404e-07,  4.4236e-08, -3.5679e-08,  8.1759e-08,\n             3.8631e-08, -1.0475e-07,  2.0766e-07, -6.3874e-08, -6.5952e-09,\n             1.7220e-07, -3.6662e-08, -4.0823e-08,  3.7982e-08,  2.8300e-08,\n            -6.3571e-08,  9.8250e-08]),\n    'exp_avg_sq': tensor([1.0406e-13, 9.0437e-14, 9.2667e-14, 1.0110e-13, 8.9337e-14, 1.3888e-13,\n            1.0363e-13, 8.5464e-14, 1.2066e-13, 9.4283e-14, 9.3298e-14, 1.0926e-13,\n            1.1031e-13, 8.7363e-14, 9.0914e-14, 9.1476e-14, 8.9406e-14, 1.0853e-13,\n            1.0136e-13, 1.0915e-13, 9.6118e-14, 1.1090e-13, 9.0574e-14, 1.1331e-13,\n            1.6422e-13, 1.8248e-13, 9.0025e-14, 9.8881e-14, 1.0730e-13, 1.5501e-13,\n            1.6023e-13, 1.0385e-13, 8.4899e-14, 9.2373e-14, 2.4681e-13, 9.3370e-14,\n            9.7387e-14, 9.0053e-14, 1.0936e-13, 9.9481e-14, 1.1823e-13, 1.1202e-13,\n            1.1007e-13, 9.1207e-14, 8.7144e-14, 1.2689e-13, 8.9610e-14, 1.0393e-13,\n            9.2003e-14, 1.0763e-13, 1.1490e-13, 1.3240e-13, 9.1835e-14, 9.5009e-14,\n            9.5347e-14, 9.2769e-14, 9.6838e-14, 9.6213e-14, 7.5274e-13, 1.2037e-13,\n            9.1291e-14, 8.5380e-14, 1.0559e-13, 8.9394e-14, 8.6352e-14, 6.6297e-14,\n            1.2717e-13, 1.1917e-13, 9.8653e-14, 9.3978e-14, 9.4714e-14, 9.5007e-14,\n            9.3296e-14, 1.0565e-13, 1.6160e-13, 1.0947e-13, 7.2144e-14, 8.6345e-14,\n            7.7699e-14, 1.0216e-13, 9.5466e-14, 9.1979e-14, 8.6227e-14, 1.0964e-13,\n            9.4256e-14, 9.5065e-14, 9.6958e-14, 9.9479e-14, 9.6255e-14, 7.8291e-14,\n            1.0150e-13, 8.1955e-14, 9.1329e-14, 9.1665e-14, 1.0495e-13, 9.8909e-14,\n            9.4651e-14, 1.1861e-13, 1.1071e-13, 9.6386e-14, 9.6110e-14, 1.0672e-13,\n            1.0527e-13, 9.7009e-14, 1.1793e-13, 2.5896e-13, 7.0966e-14, 8.5987e-14,\n            1.2479e-13, 1.0086e-13, 9.7860e-14, 1.1908e-13, 8.7282e-14, 1.0456e-13,\n            8.6926e-14, 1.2442e-13, 8.3536e-14, 8.9498e-14, 9.4996e-14, 8.8313e-14,\n            1.3048e-13, 1.2140e-13, 8.7216e-14, 1.0823e-13, 9.7171e-14, 8.9045e-14,\n            7.7672e-14, 9.6696e-14, 1.0520e-13, 9.5678e-14, 9.5186e-14, 1.2878e-13,\n            1.0203e-13, 8.6109e-14, 9.9543e-14, 8.8675e-14, 9.4187e-14, 8.0920e-14,\n            8.9333e-14, 8.5177e-14, 1.0633e-13, 9.3969e-14, 1.1703e-13, 2.1567e-13,\n            1.0276e-13, 8.8767e-14, 9.5322e-14, 8.5007e-14, 1.0484e-13, 8.9996e-14,\n            1.0090e-13, 7.1432e-14, 8.4534e-14, 1.0912e-13, 9.0786e-14, 9.0618e-14,\n            9.1477e-14, 1.3570e-13, 9.0191e-14, 1.1688e-13, 8.6515e-14, 9.8619e-14,\n            1.0507e-13, 1.3381e-13, 1.2094e-13, 1.0505e-13, 1.0547e-13, 8.2767e-14,\n            1.1973e-13, 2.5792e-13, 1.0159e-13, 9.9961e-14, 9.4732e-14, 9.4423e-14,\n            8.8059e-14, 1.0159e-13, 1.6757e-13, 8.8564e-14, 9.7495e-14, 1.0310e-13,\n            9.6438e-14, 1.0030e-13, 1.0322e-13, 1.2676e-13, 9.4461e-14, 8.9220e-14,\n            1.1911e-13, 1.4166e-13, 7.3619e-14, 1.0111e-13, 9.5358e-14, 9.9545e-14,\n            9.2869e-14, 1.1444e-13, 1.0174e-13, 1.0856e-13, 9.4926e-14, 1.0980e-13,\n            8.2760e-14, 1.2437e-13, 9.4921e-14, 9.9194e-14, 1.2073e-13, 8.5549e-14,\n            9.6365e-14, 9.2821e-14, 9.2378e-14, 1.9406e-13, 9.7024e-14, 9.2495e-14,\n            1.2327e-13, 1.1569e-13, 8.7620e-14, 9.6050e-14, 1.2272e-13, 7.5611e-14,\n            1.4192e-13, 9.5787e-14, 7.5141e-14, 1.0951e-13, 9.1221e-14, 1.0146e-13,\n            1.0494e-13, 9.4253e-14, 1.0212e-13, 1.2841e-13, 9.8494e-14, 7.9678e-14,\n            8.2345e-14, 9.9363e-14, 9.4822e-14, 1.2100e-13, 1.1133e-13, 8.2208e-14,\n            8.0215e-14, 1.3223e-13, 9.5501e-14, 1.1553e-13, 1.0849e-13, 1.9180e-13,\n            1.1952e-13, 9.0466e-14, 1.0386e-13, 9.2826e-14, 1.1371e-13, 9.1589e-14,\n            1.0619e-13, 1.3303e-13, 1.0160e-13, 9.8469e-14, 7.7634e-14, 1.0442e-13,\n            1.0363e-13, 1.0318e-13, 1.0741e-13, 9.1939e-14, 1.1117e-13, 1.0611e-13,\n            1.2462e-13, 1.1099e-13, 8.2180e-14, 9.5111e-14, 9.2322e-14, 1.2615e-13,\n            1.0813e-13, 1.0356e-13, 9.0965e-14, 1.0529e-13, 9.7576e-14, 1.3305e-13,\n            1.1216e-13, 1.0651e-13, 9.3055e-14, 8.5182e-14, 1.7364e-13, 1.1732e-13,\n            9.3653e-14, 9.5994e-14, 9.8834e-14, 9.0338e-14, 1.1110e-13, 1.0015e-13,\n            8.4894e-14, 1.3967e-13, 8.4736e-14, 9.3854e-14, 9.0513e-14, 9.9787e-14,\n            1.0925e-13, 9.4314e-14, 9.2140e-14, 1.0170e-13, 9.3519e-14, 9.9682e-14,\n            8.5061e-14, 9.8175e-14, 9.1201e-14, 9.7263e-14, 1.6040e-13, 9.2237e-14,\n            1.2468e-13, 1.0733e-13, 1.0532e-13, 1.0495e-13, 8.3885e-14, 1.0432e-13,\n            8.5801e-14, 1.0107e-13, 1.8853e-13, 1.0326e-13, 1.2890e-13, 9.0036e-14,\n            1.0379e-13, 9.8349e-14, 1.1784e-13, 1.0299e-13, 9.1474e-14, 1.0485e-13,\n            1.0012e-13, 1.9265e-13, 8.4658e-14, 8.5010e-14, 9.9152e-14, 1.0824e-13,\n            1.0072e-13, 1.7763e-13, 8.7268e-14, 9.1726e-14, 1.1862e-13, 9.7146e-14,\n            9.3265e-14, 8.0917e-14, 9.3153e-14, 1.2458e-13, 9.6428e-14, 7.8359e-14,\n            1.1243e-13, 8.1350e-14, 8.3726e-14, 1.4680e-13, 1.2782e-13, 1.2068e-13,\n            1.6066e-13, 1.0020e-13, 1.0512e-13, 9.8727e-14, 8.8196e-14, 1.0478e-13,\n            9.0987e-14, 1.3031e-13, 1.0319e-13, 9.5238e-14, 8.5169e-14, 1.3075e-13,\n            1.0975e-13, 1.1049e-13, 1.0173e-13, 1.0876e-13, 9.5482e-14, 9.1980e-14,\n            9.8724e-14, 9.8862e-14, 1.0528e-13, 9.2754e-14, 7.9015e-14, 1.0762e-13,\n            9.4763e-14, 8.4747e-14, 8.5004e-14, 1.1939e-13, 1.0136e-13, 9.9551e-14,\n            1.0600e-13, 1.1001e-13, 8.1014e-14, 9.9035e-14, 1.0314e-13, 1.0795e-13,\n            1.1264e-13, 1.0492e-13, 8.8628e-14, 8.2818e-14, 1.0136e-13, 8.7095e-14,\n            8.8782e-14, 8.8040e-14, 1.0071e-13, 1.1505e-13, 1.1299e-13, 1.1097e-13,\n            8.4685e-14, 9.0368e-14, 1.0658e-13, 8.7137e-14, 9.1628e-14, 9.8398e-14,\n            1.0111e-13, 1.1265e-13, 8.8894e-14, 8.7026e-14, 9.1017e-14, 8.2986e-14,\n            9.7863e-14, 9.8375e-14, 1.2057e-13, 1.1024e-13, 9.2077e-14, 1.4266e-13,\n            1.1663e-13, 9.6952e-14, 1.1277e-13, 1.2612e-13, 9.6110e-14, 1.5934e-13,\n            1.0162e-13, 1.0476e-13, 7.8323e-14, 1.0435e-13, 1.1064e-13, 8.4864e-14,\n            8.4777e-14, 1.0639e-13, 9.4499e-14, 9.5514e-14, 1.0857e-13, 9.8353e-14,\n            1.0111e-13, 9.2488e-14, 1.0089e-13, 1.1091e-13, 1.2931e-13, 8.5862e-14,\n            8.3881e-14, 8.8225e-14, 8.1446e-14, 1.1659e-13, 8.0753e-14, 9.5511e-14,\n            8.9238e-14, 1.0109e-13, 1.2257e-13, 1.1967e-13, 9.6094e-14, 2.3976e-13,\n            8.9277e-14, 9.9208e-14, 8.9449e-14, 9.2632e-14, 1.0461e-13, 1.0651e-13,\n            1.0341e-13, 9.9722e-14, 9.7122e-14, 9.7856e-14, 1.5743e-13, 9.7234e-14,\n            8.3814e-14, 1.0981e-13, 1.0312e-13, 9.1389e-14, 9.5800e-14, 7.5230e-14,\n            1.1021e-13, 9.9548e-14, 1.0932e-13, 1.1935e-13, 1.0188e-13, 1.0780e-13,\n            1.0187e-13, 9.5615e-14, 8.8912e-14, 8.6783e-14, 8.9728e-14, 1.0144e-13,\n            9.5784e-14, 1.1796e-13, 1.4189e-13, 8.1683e-14, 9.6661e-14, 1.2368e-13,\n            9.3511e-14, 9.1853e-14, 9.2601e-14, 1.2830e-13, 1.0764e-13, 1.1317e-13,\n            1.0198e-13, 8.1600e-14, 1.3009e-13, 1.0021e-13, 9.6556e-14, 8.9518e-14,\n            1.0527e-13, 7.7984e-14, 9.8832e-14, 1.1568e-13, 8.4110e-14, 9.2902e-14,\n            9.0964e-14, 9.1040e-14, 7.1621e-14, 7.6295e-14, 1.0484e-13, 9.5291e-14,\n            8.7309e-14, 9.9554e-14, 1.1126e-13, 1.3563e-13, 9.6400e-14, 9.1709e-14,\n            8.5653e-14, 1.1154e-13])},\n   102: {'exp_avg': tensor([ 2.7823e-08, -6.5973e-08, -5.3424e-08,  1.9834e-08,  4.2965e-08,\n            -2.9007e-07,  4.2878e-08, -2.0750e-07,  2.1370e-09,  3.9518e-08,\n             3.8298e-08,  5.7970e-08, -1.1223e-07, -2.2307e-08, -2.1068e-07,\n             1.2984e-07, -1.0847e-07, -1.1141e-07,  2.7943e-08, -4.2315e-08,\n             5.0628e-08,  3.1058e-09,  3.6501e-09,  1.4829e-07, -1.5726e-08,\n             1.6367e-07, -5.2381e-08, -3.7210e-08,  4.9190e-08, -8.6373e-08,\n             4.5502e-08, -8.6229e-08, -2.0390e-08, -1.4757e-07, -5.5008e-08,\n            -1.1156e-07, -8.7281e-08, -1.8629e-08, -1.7554e-07,  4.0459e-08,\n             1.4675e-08, -1.4104e-07, -9.3741e-08, -2.1609e-08, -7.5425e-08,\n            -1.3007e-07, -9.5230e-08, -1.0804e-07, -4.2605e-08,  3.6747e-08,\n             3.2433e-08,  2.2388e-07,  1.3461e-08,  5.1203e-08,  1.9418e-07,\n            -6.3184e-08,  1.8943e-07, -1.6351e-07, -4.8856e-08, -2.2738e-08,\n            -7.1257e-08,  4.8894e-08,  9.0304e-09, -7.0810e-08, -8.8340e-08,\n             3.1863e-07, -6.4459e-08, -1.1531e-07, -5.4845e-08, -2.1295e-07,\n             4.0836e-08,  1.0287e-08,  2.5972e-07, -5.8338e-08,  1.3719e-07,\n            -9.6679e-08, -1.9058e-07, -1.8199e-07,  1.7278e-07, -4.5251e-08,\n            -1.4032e-07,  3.0059e-08,  5.3059e-09, -7.3498e-08, -8.2746e-09,\n            -1.7698e-07, -1.0331e-08, -5.4407e-08, -1.0418e-07,  1.3349e-07,\n             1.3162e-08,  6.8706e-08, -3.2828e-08,  1.5932e-07, -6.5876e-08,\n            -3.5684e-08, -1.8445e-07,  7.0367e-09,  4.4402e-08, -1.3985e-08,\n            -1.6892e-08, -6.8711e-08, -4.2527e-08,  5.8489e-08,  1.5930e-07,\n             1.7957e-07,  9.8472e-08, -6.9967e-08,  4.9805e-09, -2.2699e-08,\n             4.9214e-08, -6.5443e-08, -9.0390e-09, -2.9199e-08,  4.7971e-08,\n            -6.9610e-08,  1.6314e-07, -1.3138e-09,  6.1695e-08,  9.2291e-08,\n            -1.5462e-08,  7.3766e-08, -7.5449e-08, -9.1812e-08, -1.1909e-07,\n             1.3297e-07,  2.3927e-07, -9.8911e-08, -3.3864e-08, -4.2022e-08,\n            -1.2066e-07,  5.0255e-08,  1.0315e-07, -1.6262e-08, -2.1989e-08,\n            -4.5086e-08, -5.4402e-09,  3.9383e-08,  3.5466e-09, -2.2271e-07,\n             6.4382e-08, -1.5214e-09,  8.6265e-08,  1.0903e-07,  3.3795e-07,\n            -5.1906e-08,  3.7757e-08,  8.4339e-08, -2.7550e-08,  1.1325e-09,\n            -1.5797e-07,  1.8410e-08,  2.6278e-07,  1.2568e-08, -2.7670e-08,\n             6.2589e-08, -1.4963e-07, -7.0908e-08,  7.1554e-08,  1.7493e-08,\n             1.2615e-07, -1.4169e-07,  2.2215e-08, -1.2929e-07, -1.5478e-08,\n            -1.6171e-08,  1.6084e-08,  1.8738e-08,  2.1246e-08, -6.0623e-08,\n             3.3327e-08,  2.5479e-08, -6.8924e-08, -1.2447e-07,  8.4918e-08,\n            -1.1201e-07, -1.1445e-07,  1.7730e-07,  1.1365e-07,  1.4388e-07,\n            -8.2389e-08,  2.1451e-07,  1.0487e-07,  2.3804e-10, -1.7983e-07,\n             1.9431e-07, -7.8489e-08, -2.3371e-08, -7.5109e-09, -6.7754e-08,\n            -5.7889e-08, -6.3748e-08,  1.8909e-07,  4.1748e-08, -2.5608e-08,\n             1.8550e-07,  1.1968e-08,  2.9566e-09, -3.6268e-08, -1.0442e-07,\n            -8.6765e-08,  6.2813e-08, -9.7488e-09, -2.9592e-08,  6.9682e-10,\n             5.3108e-08, -7.1278e-08, -3.0750e-08,  9.3603e-08,  3.5022e-08,\n            -8.2714e-09, -5.8792e-08,  2.2166e-07, -4.2614e-09,  5.7087e-09,\n            -5.8345e-08, -9.3960e-08,  9.1653e-08,  1.0861e-08, -3.9550e-09,\n             3.4297e-08, -2.6111e-08,  3.7432e-08, -9.9518e-08,  1.8533e-07,\n             5.5433e-09, -1.5697e-08, -1.1609e-07, -1.3932e-07,  1.0301e-07,\n            -5.6455e-08,  5.2062e-08,  9.9477e-08, -1.1532e-07, -1.5617e-07,\n            -1.7130e-08,  1.9478e-07,  3.9944e-08, -5.2662e-08, -1.2700e-07,\n            -7.1286e-08, -1.9258e-07, -1.9364e-07, -1.1920e-08,  2.1846e-08,\n             2.8238e-07,  2.6262e-08, -4.7741e-08,  3.0639e-08,  1.5237e-07,\n            -1.0535e-07, -2.3206e-08, -2.4241e-08,  4.2239e-08, -1.2543e-07,\n             5.3989e-08, -1.2579e-07,  1.3077e-07,  5.3197e-09,  3.1473e-08,\n             1.4563e-08, -8.3751e-08, -1.1468e-08,  1.3695e-08,  1.4997e-08,\n             6.6237e-08, -2.5783e-07, -3.3309e-08, -1.6403e-07,  3.6567e-07,\n             2.0913e-07,  2.4605e-07,  3.4002e-09, -1.1189e-07, -4.7841e-08,\n            -1.5106e-07,  1.7932e-07, -9.5185e-09, -1.3411e-07,  3.3608e-08,\n             5.4162e-08, -7.6252e-09, -1.2103e-07, -8.9894e-09,  9.3240e-08,\n            -7.9654e-08, -1.4294e-07, -2.6287e-09,  5.8809e-08,  5.2916e-08,\n            -3.6318e-08, -3.0332e-08, -4.4787e-08, -7.7807e-08, -4.2178e-08,\n             5.3487e-08,  1.4341e-07, -1.1689e-08,  1.2593e-08,  8.1688e-08,\n             4.6195e-08, -5.8937e-08,  5.6346e-08, -1.1521e-07,  3.5470e-07,\n            -6.7530e-08,  1.6629e-07,  6.1674e-08,  1.3592e-07,  9.5972e-08,\n            -4.8783e-08, -1.6451e-07, -2.4334e-08, -1.3012e-08, -3.0682e-08,\n             9.4057e-09,  1.9267e-07,  6.7407e-08, -1.1810e-07,  5.9604e-08,\n             1.1016e-09, -2.8985e-08,  1.4654e-08, -1.5032e-07, -3.2203e-08,\n             9.8074e-08, -1.2009e-07, -6.8727e-08,  4.8984e-08, -3.9376e-08,\n             1.2921e-07, -1.0015e-08, -1.3634e-07, -1.1797e-07, -7.0817e-08,\n             4.5981e-08, -1.0680e-07,  1.2096e-07,  7.6687e-08,  1.2671e-08,\n             8.2438e-08,  5.9843e-08, -4.4973e-08,  1.8461e-08,  1.0189e-07,\n            -5.8659e-08, -6.7325e-08,  1.4367e-07,  1.0553e-07,  2.7929e-08,\n             6.5075e-08, -8.0751e-08, -1.4281e-08, -2.3563e-08,  5.5114e-08,\n            -2.6046e-08, -7.1372e-08, -4.1959e-08, -3.2374e-09,  5.5094e-10,\n            -1.0608e-07, -1.0010e-07, -1.8195e-07, -3.9921e-08, -1.7098e-09,\n             1.0951e-08,  3.9901e-08, -1.5468e-08, -3.1042e-08, -1.3201e-07,\n            -2.2466e-08,  1.1560e-07,  1.0291e-07,  7.7860e-08,  9.2220e-08,\n            -5.1477e-08, -7.6960e-08,  6.3331e-09, -1.2133e-07,  3.3133e-08,\n            -1.5186e-07, -7.7925e-10,  1.6142e-07, -6.7673e-08, -1.0172e-08,\n            -5.0087e-08, -1.1190e-07, -6.6845e-08, -9.5522e-08, -4.9097e-08,\n             1.8508e-07, -1.3058e-07,  4.4007e-08, -1.1873e-08, -4.5742e-09,\n            -7.8905e-08, -2.9221e-08,  1.7917e-08, -1.4028e-07,  6.8975e-08,\n             1.3660e-08,  1.2687e-07, -3.4156e-09, -5.6101e-08,  1.1689e-07,\n             1.7941e-07, -9.5365e-09,  6.3462e-08,  1.5692e-07,  2.6912e-08,\n            -8.3848e-08,  1.1785e-07, -7.6688e-08, -3.9452e-08,  1.0387e-08,\n            -1.2736e-07, -5.4590e-08,  1.4108e-07,  1.8466e-08,  1.6850e-08,\n            -3.0403e-08, -2.5534e-09,  1.4533e-07, -1.9253e-08,  2.4580e-08,\n             1.6682e-07, -1.1523e-07, -8.0756e-08,  5.4350e-08, -7.8229e-08,\n            -7.8827e-08, -3.5920e-08,  3.0851e-08, -4.5081e-08, -1.8055e-07,\n             1.3865e-07,  8.4956e-08, -2.5268e-08, -4.3673e-08, -8.4022e-09,\n             9.6780e-08, -1.4070e-07, -1.5295e-07,  8.4332e-08, -8.8911e-08,\n             6.0188e-08, -8.4469e-08,  8.5522e-08,  2.9307e-07,  1.3769e-07,\n            -1.5205e-07,  2.9834e-08, -1.2442e-07,  1.6555e-07, -7.3872e-09,\n            -1.3631e-08, -1.7385e-07,  6.2540e-08, -6.9149e-09,  4.2379e-08,\n            -3.7632e-08, -9.8367e-08, -1.7367e-07,  1.1572e-07,  6.8699e-08,\n             2.7282e-07, -1.8075e-08,  8.7999e-08,  2.8529e-08,  2.3728e-07,\n            -8.3784e-09, -5.7024e-08,  6.8638e-08, -2.1372e-09,  6.3979e-08,\n            -1.4618e-07, -4.3471e-08, -2.2852e-08,  2.8597e-08,  2.8339e-09,\n             8.9384e-08,  2.5085e-07,  6.3444e-08,  3.4286e-08, -3.8196e-08,\n            -6.1077e-08, -9.5420e-08,  3.1153e-08, -1.4301e-07, -1.9906e-07,\n            -6.6057e-08,  9.3617e-08,  2.3380e-08, -9.6480e-08,  3.4687e-08,\n             5.8232e-08,  7.2577e-09,  1.8924e-08, -1.7629e-08, -3.6179e-08,\n             6.5873e-08,  7.5262e-08,  1.6631e-08,  1.6328e-07,  1.7970e-07,\n             1.2437e-08,  1.3078e-07, -4.8622e-08,  2.5322e-07, -1.9457e-08,\n             2.8004e-09,  1.0400e-07]),\n    'exp_avg_sq': tensor([2.3157e-13, 1.9478e-13, 1.6615e-13, 1.2704e-13, 1.8450e-13, 4.5073e-13,\n            1.8131e-13, 1.7873e-13, 1.7567e-13, 1.6991e-13, 1.8896e-13, 1.4177e-13,\n            1.8786e-13, 2.1861e-13, 3.6906e-13, 2.0765e-13, 2.0142e-13, 1.3104e-13,\n            1.2763e-13, 2.0409e-13, 1.6322e-13, 1.7483e-13, 1.7273e-13, 2.8160e-13,\n            1.8875e-13, 1.7300e-13, 1.5062e-13, 1.0538e-13, 1.8170e-13, 1.3132e-13,\n            4.7352e-14, 7.5023e-14, 1.5369e-13, 1.6660e-13, 1.6582e-13, 1.9295e-13,\n            1.8109e-13, 5.6016e-14, 1.3887e-13, 1.9049e-13, 1.6842e-13, 1.7023e-13,\n            1.3113e-13, 1.3977e-13, 1.2095e-13, 3.7208e-13, 2.0415e-13, 1.3301e-13,\n            1.4392e-13, 1.5388e-13, 1.7234e-13, 1.8795e-13, 4.6920e-14, 1.2873e-13,\n            1.6954e-13, 1.9646e-13, 1.9302e-13, 1.6373e-13, 2.2792e-13, 1.8866e-13,\n            1.7119e-13, 4.0529e-14, 1.3155e-13, 1.3764e-13, 1.5363e-13, 2.0301e-13,\n            2.7362e-13, 1.4212e-13, 2.2249e-13, 1.4839e-13, 1.5251e-13, 1.4587e-13,\n            4.7255e-13, 2.2440e-13, 1.7650e-13, 1.7110e-13, 2.8249e-13, 1.6329e-13,\n            1.7528e-13, 1.6833e-13, 2.7184e-13, 1.7975e-13, 1.7061e-13, 1.0458e-13,\n            1.6241e-13, 1.5654e-13, 2.9018e-13, 1.6854e-13, 1.6431e-13, 1.9056e-13,\n            3.3902e-13, 1.6000e-13, 1.3642e-13, 1.4856e-13, 1.4851e-13, 1.6610e-13,\n            1.6794e-13, 1.4748e-13, 1.7294e-13, 1.3961e-13, 1.7437e-13, 1.4525e-13,\n            1.1159e-13, 1.2500e-13, 1.4976e-13, 1.5464e-13, 1.5976e-13, 1.7403e-12,\n            1.3723e-13, 2.2511e-13, 1.5260e-13, 1.0636e-13, 2.0331e-13, 1.5167e-13,\n            1.7806e-13, 1.1507e-13, 1.6685e-13, 3.7559e-13, 1.5655e-13, 1.8878e-13,\n            7.9914e-14, 1.4971e-13, 1.1566e-13, 1.3702e-13, 1.9314e-13, 4.0221e-13,\n            3.8915e-13, 1.7296e-13, 1.5874e-13, 1.7332e-13, 1.5939e-13, 1.7255e-13,\n            1.1683e-13, 2.1918e-13, 1.3217e-13, 1.3632e-13, 3.4253e-13, 1.0888e-13,\n            1.2582e-13, 4.7492e-13, 1.6243e-13, 1.9305e-13, 1.6132e-13, 1.5239e-13,\n            4.1607e-13, 1.4008e-13, 1.5518e-13, 2.4333e-13, 1.9365e-13, 2.1913e-13,\n            1.1748e-13, 1.1144e-13, 4.9222e-13, 1.0427e-13, 1.4299e-13, 1.4978e-13,\n            1.2082e-13, 2.2717e-13, 1.3792e-13, 1.7909e-13, 1.7762e-13, 1.4553e-13,\n            1.7921e-13, 1.5377e-13, 1.3282e-13, 1.4495e-13, 1.6240e-13, 1.5009e-13,\n            1.8368e-13, 3.3991e-13, 1.7253e-13, 1.3675e-13, 1.3952e-13, 1.4456e-13,\n            1.6445e-13, 2.2786e-13, 1.3571e-13, 2.5543e-13, 1.5406e-13, 1.7298e-13,\n            1.8538e-13, 5.7232e-13, 6.6624e-13, 1.5782e-13, 2.2959e-13, 2.2597e-13,\n            1.5301e-13, 1.4952e-13, 3.2510e-13, 1.0224e-13, 1.8041e-13, 1.6691e-13,\n            1.9601e-13, 1.4854e-13, 2.9683e-13, 2.4332e-13, 1.4678e-13, 1.6051e-13,\n            2.0577e-13, 1.1875e-13, 1.5986e-13, 3.3999e-13, 1.7250e-13, 1.3533e-13,\n            1.5663e-13, 1.7081e-13, 2.0399e-13, 1.8671e-13, 3.7588e-14, 8.5841e-14,\n            1.1423e-13, 1.4338e-13, 1.8267e-13, 2.2011e-13, 1.9296e-13, 1.3720e-13,\n            1.3816e-13, 3.9934e-13, 1.5416e-13, 2.1951e-13, 1.4483e-13, 1.5076e-13,\n            1.8120e-13, 9.4490e-14, 1.7049e-13, 1.1399e-13, 1.3719e-13, 1.4766e-13,\n            1.5573e-13, 1.0851e-13, 9.2402e-14, 1.2212e-13, 2.0570e-13, 1.5594e-13,\n            1.6862e-13, 1.5178e-13, 3.7898e-13, 6.1904e-14, 1.4176e-13, 1.8746e-13,\n            2.0954e-13, 1.6856e-13, 2.1922e-13, 1.8184e-13, 1.8683e-13, 4.4165e-13,\n            1.0526e-13, 2.3475e-13, 2.2437e-13, 9.8193e-14, 1.0744e-12, 1.3419e-13,\n            1.0334e-13, 1.5082e-13, 1.7448e-13, 7.7453e-14, 1.1546e-13, 2.0071e-13,\n            2.2375e-13, 1.1160e-13, 1.7202e-13, 1.4554e-13, 1.8027e-13, 2.4703e-13,\n            1.5276e-13, 1.5905e-13, 3.6816e-13, 1.6959e-13, 1.3576e-13, 5.3233e-13,\n            4.4191e-13, 1.4090e-13, 1.3808e-13, 1.6800e-13, 1.7538e-13, 1.5662e-13,\n            5.4802e-13, 1.8450e-13, 1.6294e-13, 1.5660e-13, 1.7592e-13, 6.1173e-14,\n            1.3660e-13, 1.4434e-13, 2.4962e-13, 1.5677e-13, 1.8477e-13, 1.8605e-13,\n            1.8143e-13, 1.4935e-13, 1.9773e-13, 1.3290e-13, 1.5274e-13, 1.8811e-13,\n            1.1473e-13, 1.5557e-13, 1.6802e-13, 2.1915e-13, 1.7864e-13, 2.2403e-13,\n            6.8483e-14, 1.2835e-13, 1.5203e-13, 1.9453e-13, 1.2535e-12, 1.7545e-13,\n            1.2568e-13, 1.9418e-13, 4.4773e-13, 1.5322e-13, 7.5122e-14, 1.7198e-13,\n            1.2645e-13, 1.3221e-13, 2.5409e-13, 1.5983e-13, 3.2413e-13, 1.5016e-13,\n            1.2857e-13, 1.1508e-13, 1.3333e-13, 5.9527e-14, 1.6284e-13, 3.7951e-13,\n            1.2836e-13, 1.7094e-13, 1.7325e-13, 1.7483e-13, 1.6168e-13, 1.8625e-13,\n            1.6293e-13, 1.4429e-13, 1.6863e-13, 1.8010e-13, 1.5154e-13, 1.5386e-13,\n            1.3954e-13, 1.7354e-13, 1.6092e-13, 1.3103e-13, 7.7262e-14, 1.3384e-13,\n            4.9316e-14, 1.8798e-13, 1.5227e-13, 1.6948e-13, 1.4152e-13, 1.3271e-13,\n            1.8608e-13, 9.0804e-14, 2.2340e-13, 3.2254e-13, 1.1433e-13, 1.3334e-13,\n            1.3676e-13, 1.8961e-13, 2.3351e-13, 1.1445e-13, 1.8438e-13, 9.7343e-14,\n            1.5730e-13, 1.0602e-13, 2.3192e-13, 1.5419e-13, 1.5762e-13, 1.3224e-13,\n            1.3822e-13, 1.7345e-13, 1.5919e-13, 1.4557e-13, 1.4198e-13, 1.6816e-13,\n            1.5557e-13, 2.2896e-13, 1.1894e-13, 1.9708e-13, 1.4052e-13, 1.0566e-13,\n            1.8525e-13, 1.1741e-13, 1.4916e-13, 1.8658e-13, 1.3907e-13, 1.4310e-13,\n            1.8192e-13, 1.5428e-13, 1.5594e-13, 1.2662e-13, 1.7175e-13, 1.6593e-13,\n            4.3302e-13, 1.1607e-13, 3.9273e-13, 1.3907e-13, 1.7603e-13, 1.6165e-13,\n            6.1664e-13, 1.6411e-13, 1.7114e-13, 1.7496e-13, 1.6053e-13, 1.7264e-13,\n            1.7032e-13, 1.6615e-13, 3.4286e-13, 9.5601e-14, 1.8689e-14, 4.1360e-14,\n            1.8926e-13, 1.5172e-13, 1.2668e-13, 1.9557e-13, 1.7271e-13, 1.5387e-13,\n            1.5111e-13, 2.2848e-13, 1.8681e-13, 2.2397e-12, 2.1475e-13, 1.4382e-13,\n            1.5701e-13, 1.5968e-13, 1.3452e-13, 1.6682e-13, 1.5340e-13, 3.1826e-13,\n            1.5789e-13, 1.6152e-13, 4.0010e-13, 1.5450e-13, 1.9013e-13, 1.6763e-13,\n            2.0757e-13, 6.8014e-14, 3.6735e-13, 1.6534e-13, 2.2003e-13, 1.4715e-13,\n            2.3697e-13, 1.4100e-13, 6.4020e-14, 1.4820e-13, 1.6017e-13, 2.5976e-13,\n            2.0783e-13, 1.3689e-13, 1.8056e-13, 1.0271e-13, 2.5529e-13, 1.4886e-13,\n            1.7790e-13, 1.6912e-13, 2.1485e-13, 1.1326e-13, 1.5003e-13, 1.6521e-13,\n            2.4092e-13, 1.7279e-13, 1.7742e-13, 1.9879e-13, 1.6384e-13, 1.4589e-13,\n            3.0906e-13, 2.2173e-13, 1.9328e-13, 3.4561e-13, 1.5208e-13, 1.1328e-13,\n            1.9075e-13, 1.2930e-13, 1.6108e-13, 1.2243e-13, 1.4108e-13, 1.5962e-13,\n            1.8498e-13, 1.8687e-13, 1.4888e-13, 1.2557e-13, 3.5221e-13, 1.3199e-13,\n            2.2097e-13, 5.1229e-13, 1.0266e-13, 1.2290e-13, 1.5697e-13, 1.3663e-13,\n            1.7752e-13, 1.3223e-13, 1.4452e-13, 1.7515e-13, 1.9577e-13, 2.0029e-13,\n            9.3081e-14, 1.4799e-13, 1.2273e-13, 1.6203e-13, 1.6071e-13, 1.5275e-13,\n            3.5153e-14, 1.6594e-13, 3.1357e-13, 1.5288e-13, 1.5199e-13, 1.8730e-13,\n            1.7463e-13, 1.8008e-13, 2.2497e-13, 1.3201e-13, 5.5018e-13, 1.3466e-13,\n            1.5058e-13, 2.2839e-13])},\n   103: {'exp_avg': tensor([ 1.0515e-07, -1.2312e-07, -3.0121e-08, -8.4298e-08,  9.2692e-08,\n            -3.4735e-07, -1.9484e-08, -1.8456e-07, -1.1045e-07,  9.1523e-08,\n             1.5345e-07,  2.3542e-08, -1.5975e-07, -4.6924e-08, -2.3117e-07,\n             1.3498e-08, -1.3882e-07, -8.4322e-08,  2.9630e-08, -1.4766e-08,\n             6.3049e-08,  3.2464e-08, -5.7933e-08,  8.9702e-08,  1.3128e-07,\n             1.5534e-07, -7.9166e-08, -2.8072e-08,  3.0924e-08, -1.2736e-07,\n            -1.1785e-08, -9.0875e-09, -1.0025e-08, -1.4121e-07, -4.4213e-08,\n            -6.3653e-08, -1.1674e-07, -2.0488e-09, -9.4313e-08, -2.3439e-08,\n             2.1183e-08, -1.5133e-07, -6.3356e-08,  1.3839e-08, -2.0081e-08,\n            -1.7308e-07, -3.7392e-08, -1.7989e-08, -4.4997e-08, -4.3619e-08,\n             7.5454e-08,  3.0854e-08,  4.1491e-08,  6.3082e-09,  4.4285e-08,\n            -1.7329e-08,  4.0503e-08, -1.4755e-07, -4.6981e-08, -1.1909e-08,\n            -7.7287e-08,  3.6837e-08,  3.6646e-08, -7.9633e-08, -4.2580e-08,\n             2.1809e-07, -1.7046e-07, -1.3561e-07,  4.9736e-08, -1.0586e-07,\n             6.5994e-08,  5.4538e-08,  2.1776e-07, -2.3002e-08,  6.6372e-08,\n            -2.7517e-08, -2.1715e-07, -1.9874e-07,  1.0217e-07,  2.8702e-08,\n            -1.3625e-07, -3.7946e-09, -1.0511e-08, -9.0031e-08, -5.0462e-08,\n            -3.8927e-08, -1.0473e-07,  3.6149e-08,  1.6681e-08,  1.1030e-07,\n            -4.0713e-09,  3.9386e-08,  3.4743e-09,  1.0183e-07, -3.0388e-08,\n            -1.4486e-08, -2.0862e-07, -4.8383e-09,  1.1107e-07,  2.6136e-08,\n             6.7499e-08, -3.7134e-09,  3.6922e-08,  1.1232e-07,  1.6436e-07,\n             1.0594e-07,  7.6591e-09, -2.0635e-07,  1.8816e-08, -5.0867e-08,\n             1.1515e-07, -6.2138e-08, -7.0393e-08, -9.6640e-09, -5.0350e-08,\n            -5.0557e-08,  1.5106e-07, -5.3815e-08, -2.4141e-09,  7.7406e-08,\n            -2.0429e-08,  1.0168e-07, -7.0685e-08, -8.9058e-08, -1.3626e-07,\n             4.7898e-08,  1.6700e-07, -1.1918e-07, -1.3285e-07, -2.6945e-08,\n            -4.3562e-08,  9.2244e-08,  7.4264e-08,  1.8225e-08, -3.6499e-08,\n            -1.4240e-07,  7.0530e-09, -3.4395e-08,  3.4177e-08, -2.5540e-07,\n             9.7691e-08, -1.0524e-07,  4.6526e-08,  1.0152e-07,  1.4850e-07,\n            -6.3608e-08,  4.9972e-08,  4.0959e-08, -2.6889e-08, -2.4515e-08,\n            -1.1443e-07,  1.0647e-08,  1.2118e-07,  8.1158e-08,  4.7727e-08,\n            -5.1602e-08, -6.3446e-08, -1.2205e-07,  6.7773e-08,  7.6402e-08,\n             7.5039e-08, -9.3587e-08, -1.4314e-08, -1.4855e-08, -1.1727e-07,\n             6.1919e-09,  2.4653e-08,  1.7223e-08,  4.1390e-08, -5.9316e-09,\n            -2.2938e-08, -3.3523e-08,  2.4473e-08, -6.2424e-08,  6.8623e-08,\n            -1.6942e-07,  1.3487e-08,  2.0189e-09,  3.6296e-08,  1.1836e-07,\n            -7.6352e-08,  1.3897e-07,  1.6113e-07,  6.1791e-08, -1.3637e-07,\n             1.8265e-07, -1.2197e-08, -8.9338e-08,  2.1508e-08, -2.0446e-09,\n            -7.0317e-08, -6.1525e-08,  2.1935e-07, -2.0749e-08, -4.0707e-08,\n             2.2533e-07, -2.9747e-08, -6.8861e-09, -7.5864e-08, -3.8121e-08,\n             4.1737e-08,  3.6781e-08, -4.0916e-08, -6.3614e-09,  2.1389e-08,\n             5.0550e-08, -7.9598e-08, -6.5309e-09,  8.1294e-08,  3.4768e-08,\n            -8.7403e-08, -5.1066e-08,  1.9072e-07,  5.8881e-09, -3.7527e-08,\n            -1.4143e-07, -5.6814e-08,  1.3120e-08,  2.0646e-08,  6.4392e-08,\n            -1.0267e-09, -7.2830e-08,  3.2161e-08, -8.9277e-08,  1.2256e-07,\n             2.0339e-08, -7.4930e-09, -5.9937e-08, -1.4327e-07,  1.2546e-07,\n            -2.2174e-08,  4.1505e-08,  3.5332e-08, -3.4724e-08, -1.1414e-07,\n            -3.0286e-08,  7.9613e-08, -8.1706e-08, -1.0063e-07, -8.5934e-08,\n            -1.1761e-07, -1.4775e-07, -1.8149e-07, -1.0760e-07, -8.7385e-09,\n             2.0526e-07, -1.6000e-08, -1.4710e-08,  3.0266e-08,  6.7112e-08,\n            -2.2885e-07,  5.0083e-08, -9.1553e-10, -3.0224e-08, -1.9165e-08,\n             1.1064e-07, -4.7810e-08,  4.1805e-08, -3.2367e-08, -3.0961e-08,\n            -1.4769e-08, -2.7424e-08,  2.7362e-08,  1.3015e-08,  1.2423e-07,\n             3.2534e-08, -1.2086e-07, -4.8521e-08, -1.0946e-07,  1.6429e-07,\n             1.2629e-07,  1.9620e-07, -1.4993e-08, -5.9205e-08, -5.2753e-08,\n            -1.0697e-07,  1.2985e-07, -1.6777e-07, -5.2717e-10,  8.8712e-10,\n            -1.3625e-09,  5.6335e-08, -3.1331e-08,  8.1500e-08,  4.7585e-08,\n            -7.4351e-08, -7.0703e-08, -2.0369e-08, -7.9537e-08,  7.3136e-08,\n             1.0384e-08, -5.0784e-09,  1.4456e-08,  4.7355e-08, -7.3259e-09,\n             9.1504e-08, -3.4871e-09, -6.9787e-08, -3.9125e-08,  7.8122e-08,\n            -2.2579e-08, -9.1343e-08,  3.7535e-08, -7.6033e-08,  3.7701e-07,\n            -1.2749e-07,  1.1722e-07,  1.0110e-07,  7.1133e-08,  7.0081e-08,\n            -1.0831e-08, -1.6825e-07,  3.0134e-08, -3.6801e-09, -1.2943e-07,\n             8.6010e-08,  1.6080e-07, -4.3673e-09, -1.0227e-07,  3.5800e-08,\n            -1.9167e-08, -6.4095e-08, -6.4416e-08, -2.1998e-07,  1.3648e-09,\n             7.3576e-08, -1.0209e-07, -7.2932e-08,  4.0234e-08, -8.8990e-08,\n             7.0193e-08, -4.2555e-08, -7.9954e-08, -1.8413e-07, -8.0595e-08,\n             5.8304e-10, -1.1744e-08,  5.4781e-08,  5.1888e-08,  2.1535e-08,\n             6.9613e-08,  7.8090e-08, -2.4847e-08, -4.3328e-08,  2.1534e-09,\n            -1.6001e-07, -1.1444e-07,  1.1702e-07,  1.1623e-07,  5.4740e-09,\n             3.8398e-08,  3.5685e-08,  8.7873e-09,  2.1956e-08,  6.0923e-08,\n             1.5617e-08, -3.0991e-08, -1.4698e-08,  4.2036e-08, -3.2291e-08,\n            -1.7742e-07, -1.6564e-08, -2.3284e-07, -1.9651e-08,  2.3130e-09,\n             1.4462e-08,  7.5576e-09,  4.6150e-08,  8.0697e-08, -6.7032e-08,\n             1.2459e-08,  9.7505e-09,  1.1454e-07,  1.7026e-08,  6.2133e-08,\n             5.3750e-08,  3.0771e-08,  2.3635e-08, -7.2890e-08,  4.5919e-08,\n            -1.2863e-07,  8.0702e-09,  7.3871e-08, -5.2519e-08, -5.5854e-08,\n            -3.5269e-08, -4.3292e-08, -1.0345e-07, -3.5267e-08, -2.8420e-08,\n             7.2173e-08, -1.2236e-07,  7.3152e-08, -5.8106e-09,  1.0199e-08,\n            -2.9386e-08, -9.6613e-08,  1.4178e-08,  2.5360e-08,  2.2873e-08,\n            -1.2283e-08,  7.7203e-08,  4.0321e-08,  2.5171e-08,  1.5351e-07,\n             2.9884e-08,  5.6576e-09,  3.0362e-08,  9.1763e-08, -5.1616e-08,\n            -6.2040e-08,  4.0830e-08, -2.1252e-08, -7.0926e-08, -2.7247e-08,\n            -9.7861e-08, -7.1413e-08,  1.4377e-07,  2.6481e-08, -4.1535e-08,\n             6.9293e-08,  1.4561e-08,  7.0301e-08,  3.3463e-08,  3.2396e-08,\n             1.5244e-07, -4.4665e-08, -4.5694e-08,  6.5013e-08, -4.6218e-08,\n            -4.7088e-08, -4.2081e-08,  1.1782e-07, -8.3158e-08, -1.3423e-07,\n            -1.1377e-09,  1.3107e-07, -8.7720e-08,  1.0051e-07, -2.5898e-08,\n             5.6942e-08, -1.2806e-07, -1.0455e-07,  7.7533e-08, -5.3066e-08,\n             1.0850e-08, -4.6306e-08,  7.0621e-08,  2.3054e-07,  9.5537e-08,\n            -1.0006e-07, -9.5586e-08, -7.1115e-08,  9.3652e-08,  3.9128e-08,\n            -2.2955e-09, -1.2864e-07, -3.2716e-08, -6.5585e-08,  3.5416e-08,\n            -8.9251e-08, -5.7499e-08, -1.4126e-07,  6.8429e-08,  2.3367e-08,\n             1.6861e-07,  6.6255e-08,  6.5594e-08,  1.0573e-07,  1.9004e-07,\n             4.1106e-09, -1.7835e-08,  4.1804e-08, -4.6578e-09,  6.6035e-08,\n            -9.3895e-08,  2.8665e-08,  9.5317e-08, -3.7848e-08, -3.4761e-08,\n             4.1128e-08,  1.0680e-07, -8.1126e-08,  1.2580e-08, -7.6522e-08,\n            -1.6302e-08, -3.8493e-08,  2.2741e-08, -6.1192e-08, -1.3081e-07,\n            -3.9824e-08,  8.9473e-08,  4.3131e-08, -1.0396e-07,  1.8767e-08,\n             5.2287e-08,  2.0396e-08,  6.4422e-09, -1.3217e-08, -6.6150e-08,\n             6.2554e-08,  1.3407e-07, -6.4563e-08,  1.0998e-07,  1.6944e-07,\n             1.4618e-07,  3.1054e-08,  2.5453e-08,  1.8912e-07, -5.7086e-08,\n            -4.2633e-08,  5.1302e-08]),\n    'exp_avg_sq': tensor([1.2439e-13, 1.7938e-13, 1.1765e-13, 8.7206e-14, 1.4351e-13, 6.6155e-13,\n            1.1281e-13, 1.2348e-13, 2.0427e-13, 1.1664e-13, 1.0023e-13, 1.0513e-13,\n            1.9412e-13, 1.7334e-13, 4.5175e-13, 9.2363e-14, 1.5662e-13, 7.5954e-14,\n            8.3835e-14, 1.1303e-13, 1.4239e-13, 1.2926e-13, 1.0338e-13, 1.3459e-13,\n            1.0756e-13, 1.0497e-13, 1.1060e-13, 7.9505e-14, 1.1611e-13, 1.0884e-13,\n            2.6551e-14, 4.7141e-14, 1.1606e-13, 1.8917e-13, 8.9059e-14, 1.6976e-13,\n            1.0549e-13, 3.7072e-14, 1.0258e-13, 1.0134e-13, 1.2499e-13, 1.1532e-13,\n            7.2740e-14, 7.5658e-14, 7.2475e-14, 4.9521e-13, 1.0768e-13, 7.4315e-14,\n            8.8920e-14, 1.0936e-13, 1.1200e-13, 1.1836e-13, 3.1972e-14, 7.5967e-14,\n            8.4209e-14, 1.8714e-13, 1.3080e-13, 1.1993e-13, 1.2321e-13, 1.4266e-13,\n            9.8630e-14, 2.3011e-14, 8.1258e-14, 8.9467e-14, 1.2608e-13, 1.1526e-13,\n            3.7096e-13, 1.1117e-13, 1.1693e-13, 1.2416e-13, 1.1601e-13, 1.1164e-13,\n            1.9612e-13, 9.3467e-14, 1.0737e-13, 1.0782e-13, 2.7007e-13, 1.2621e-13,\n            1.0507e-13, 1.0140e-13, 3.3440e-13, 1.1866e-13, 1.1519e-13, 7.7118e-14,\n            1.0714e-13, 1.0213e-13, 4.0940e-13, 1.0168e-13, 9.6368e-14, 1.0633e-13,\n            3.6177e-13, 1.0165e-13, 9.6456e-14, 6.8854e-14, 1.1077e-13, 1.0675e-13,\n            1.1127e-13, 9.7418e-14, 1.3536e-13, 7.8276e-14, 1.3147e-13, 1.1486e-13,\n            1.0629e-13, 7.5476e-14, 9.0366e-14, 8.8232e-14, 9.4514e-14, 1.9041e-12,\n            8.8330e-14, 1.1403e-13, 1.2564e-13, 7.6480e-14, 1.6512e-13, 1.0512e-13,\n            1.0913e-13, 8.4914e-14, 1.0545e-13, 6.9693e-13, 1.1587e-13, 2.2656e-13,\n            6.0985e-14, 1.0247e-13, 7.7378e-14, 9.7458e-14, 2.0237e-13, 2.7220e-13,\n            2.3349e-13, 9.5134e-14, 1.3138e-13, 1.3135e-13, 8.4812e-14, 1.0496e-13,\n            6.8498e-14, 1.1756e-13, 1.1031e-13, 8.1810e-14, 1.6979e-13, 5.8409e-14,\n            1.0932e-13, 6.0558e-13, 1.0589e-13, 1.3370e-13, 1.0463e-13, 1.0347e-13,\n            1.7020e-13, 9.3412e-14, 1.1111e-13, 1.7629e-13, 1.8453e-13, 1.0123e-13,\n            7.0982e-14, 6.1720e-14, 2.1049e-13, 5.8756e-14, 1.1151e-13, 9.4923e-14,\n            8.7099e-14, 1.7847e-13, 9.9470e-14, 9.9007e-14, 1.5123e-13, 9.1861e-14,\n            1.1894e-13, 9.6297e-14, 1.0644e-13, 9.9040e-14, 1.0216e-13, 9.7594e-14,\n            1.0465e-13, 3.1770e-13, 9.8578e-14, 8.6303e-14, 1.0059e-13, 9.0092e-14,\n            8.7200e-14, 1.0683e-13, 1.1601e-13, 1.7213e-13, 1.0987e-13, 1.0724e-13,\n            8.0354e-14, 2.5057e-13, 3.8758e-13, 7.7136e-14, 2.1696e-13, 1.6477e-13,\n            1.0388e-13, 1.0532e-13, 3.0397e-13, 6.1279e-14, 1.6519e-13, 1.6565e-13,\n            1.2946e-13, 1.1022e-13, 1.1859e-13, 2.1594e-13, 9.7330e-14, 1.2851e-13,\n            1.9943e-13, 7.6031e-14, 1.0260e-13, 1.5044e-13, 1.1879e-13, 8.4766e-14,\n            9.4133e-14, 9.7425e-14, 1.5078e-13, 1.1068e-13, 2.0483e-14, 4.8539e-14,\n            8.0399e-14, 1.0253e-13, 1.3490e-13, 1.1691e-13, 1.7158e-13, 1.0900e-13,\n            1.2452e-13, 1.5674e-13, 9.7880e-14, 1.0201e-13, 1.1842e-13, 1.0990e-13,\n            1.0563e-13, 5.9330e-14, 1.2514e-13, 7.2607e-14, 1.1504e-13, 1.0224e-13,\n            9.9422e-14, 7.6408e-14, 5.8321e-14, 9.0876e-14, 1.2012e-13, 1.1922e-13,\n            1.1999e-13, 1.2031e-13, 1.6229e-13, 3.6792e-14, 9.7671e-14, 1.2521e-13,\n            2.7863e-13, 1.2175e-13, 1.2465e-13, 1.3616e-13, 1.1273e-13, 2.5613e-13,\n            6.3259e-14, 1.1633e-13, 1.0569e-13, 5.7061e-14, 1.3415e-12, 9.9971e-14,\n            5.7348e-14, 8.2090e-14, 1.1593e-13, 4.1557e-14, 8.2056e-14, 1.0515e-13,\n            1.2626e-13, 5.7601e-14, 1.0374e-13, 1.0705e-13, 1.3698e-13, 1.1590e-13,\n            9.4304e-14, 1.0297e-13, 3.7808e-13, 9.0241e-14, 8.0358e-14, 2.0430e-13,\n            1.9086e-13, 9.2352e-14, 1.0720e-13, 1.0831e-13, 1.0469e-13, 1.3552e-13,\n            5.7742e-13, 1.0593e-13, 9.4767e-14, 9.8698e-14, 1.3511e-13, 3.6301e-14,\n            9.1665e-14, 9.9139e-14, 1.3558e-13, 1.2924e-13, 1.5482e-13, 1.0135e-13,\n            9.8550e-14, 1.2232e-13, 1.0748e-13, 9.2086e-14, 1.2093e-13, 1.0843e-13,\n            6.8445e-14, 1.0040e-13, 1.0446e-13, 1.9465e-13, 1.9261e-13, 9.9927e-14,\n            3.8498e-14, 8.1646e-14, 9.9765e-14, 1.0879e-13, 9.6915e-13, 1.0783e-13,\n            8.7941e-14, 1.0029e-13, 1.8813e-13, 1.0272e-13, 4.5035e-14, 1.9617e-13,\n            7.4863e-14, 1.0884e-13, 1.7632e-13, 1.1194e-13, 1.6742e-13, 1.1464e-13,\n            7.8451e-14, 6.5086e-14, 9.6848e-14, 4.3501e-14, 1.1329e-13, 4.1675e-13,\n            8.0232e-14, 1.0184e-13, 1.1554e-13, 1.0138e-13, 9.6285e-14, 1.1651e-13,\n            8.7229e-14, 9.8734e-14, 8.4563e-14, 1.9171e-13, 8.3711e-14, 1.3338e-13,\n            9.3401e-14, 9.7862e-14, 1.3518e-13, 7.0019e-14, 5.0090e-14, 1.0291e-13,\n            2.8411e-14, 1.2456e-13, 9.3908e-14, 1.1154e-13, 1.0117e-13, 8.9717e-14,\n            1.8002e-13, 5.1730e-14, 1.1944e-13, 1.4151e-13, 6.7431e-14, 8.7392e-14,\n            1.1099e-13, 1.7643e-13, 2.3438e-13, 8.7825e-14, 1.4975e-13, 6.4539e-14,\n            1.3663e-13, 8.4828e-14, 3.1072e-13, 1.2618e-13, 1.3235e-13, 7.8551e-14,\n            8.2699e-14, 9.8827e-14, 1.0385e-13, 1.0376e-13, 9.6488e-14, 9.8352e-14,\n            1.0493e-13, 1.2862e-13, 6.9192e-14, 1.1167e-13, 8.0072e-14, 7.8258e-14,\n            1.0886e-13, 6.6631e-14, 9.7480e-14, 1.7316e-13, 8.5896e-14, 7.9898e-14,\n            1.2840e-13, 9.4258e-14, 8.8787e-14, 9.1015e-14, 1.3042e-13, 9.3893e-14,\n            1.8036e-13, 7.3971e-14, 1.6993e-13, 9.6378e-14, 1.2107e-13, 9.1891e-14,\n            7.1785e-13, 1.0112e-13, 1.1463e-13, 8.1145e-14, 9.1931e-14, 1.0031e-13,\n            9.8164e-14, 1.1872e-13, 1.4275e-13, 6.7302e-14, 1.0218e-14, 2.6902e-14,\n            1.0180e-13, 1.4214e-13, 8.4615e-14, 1.1811e-13, 9.0774e-14, 1.3133e-13,\n            9.8703e-14, 1.3108e-13, 1.1809e-13, 7.3104e-13, 1.1322e-13, 1.3135e-13,\n            1.2064e-13, 1.5516e-13, 7.2135e-14, 1.0080e-13, 1.0554e-13, 1.4268e-13,\n            8.8591e-14, 1.4024e-13, 2.0795e-13, 1.1311e-13, 1.1140e-13, 1.3174e-13,\n            1.0998e-13, 3.8439e-14, 4.2547e-13, 9.5900e-14, 1.0930e-13, 1.7244e-13,\n            1.1405e-13, 8.7457e-14, 4.4603e-14, 9.8458e-14, 8.7432e-14, 2.4895e-13,\n            1.1337e-13, 9.5422e-14, 1.0162e-13, 6.1547e-14, 1.2674e-13, 1.1542e-13,\n            1.2766e-13, 1.1376e-13, 1.7145e-13, 6.1670e-14, 8.3700e-14, 8.1541e-14,\n            1.5798e-13, 9.6179e-14, 1.0897e-13, 1.3096e-13, 1.1868e-13, 8.5527e-14,\n            3.7389e-13, 1.3058e-13, 1.8715e-13, 1.8356e-13, 9.8991e-14, 7.3598e-14,\n            1.2337e-13, 7.3073e-14, 1.4864e-13, 8.0561e-14, 8.6566e-14, 1.2372e-13,\n            1.3839e-13, 1.1272e-13, 9.8133e-14, 9.2949e-14, 3.2912e-13, 1.1029e-13,\n            1.2695e-13, 1.8329e-13, 6.8022e-14, 7.9680e-14, 1.4742e-13, 9.9134e-14,\n            1.2923e-13, 9.2656e-14, 9.3567e-14, 1.2789e-13, 1.1473e-13, 1.6276e-13,\n            7.2419e-14, 1.3366e-13, 9.3538e-14, 1.2061e-13, 1.4708e-13, 1.0382e-13,\n            2.2068e-14, 1.0932e-13, 1.4934e-13, 9.8609e-14, 9.2935e-14, 1.0868e-13,\n            1.0810e-13, 1.4136e-13, 1.1231e-13, 8.6259e-14, 2.2042e-13, 1.0816e-13,\n            8.2596e-14, 1.1991e-13])},\n   104: {'exp_avg': tensor([ 7.4610e-08,  5.9406e-08, -2.9284e-08,  ...,  1.6449e-09,\n             5.1124e-08,  1.8547e-08]),\n    'exp_avg_sq': tensor([3.0411e-14, 2.7646e-14, 2.4661e-14,  ..., 7.6015e-15, 2.8870e-14,\n            2.4707e-14])},\n   105: {'exp_avg': tensor([-1.3508e-08, -6.1290e-08, -2.2345e-08,  ...,  1.3191e-08,\n             2.0347e-08,  1.6251e-08]),\n    'exp_avg_sq': tensor([7.9684e-14, 7.2256e-14, 1.1373e-13,  ..., 2.1036e-14, 1.0443e-13,\n            1.7239e-13])},\n   106: {'exp_avg': tensor([-8.8870e-08,  2.9202e-08, -1.3062e-08,  7.6566e-08,  9.9406e-08,\n             7.6451e-08,  1.6980e-09, -9.6112e-08, -7.9185e-08,  4.1030e-08,\n             9.7161e-08,  2.8114e-08,  6.4452e-09, -5.3689e-08,  5.3169e-08,\n            -5.2111e-08, -6.5279e-08,  4.3157e-09,  7.3603e-08,  1.7007e-07,\n             3.8074e-08,  4.8590e-08, -2.6007e-08, -4.6817e-08,  2.2584e-08,\n             1.9671e-07, -7.8323e-08, -3.9198e-08, -1.2495e-07,  4.2500e-08,\n            -5.3184e-09, -6.0345e-08,  1.0106e-07,  1.5225e-07,  9.4658e-08,\n             5.2407e-08, -6.6022e-08,  1.2109e-07, -1.3857e-08,  6.9272e-08,\n            -9.6403e-09,  9.6986e-08,  6.8050e-08,  2.8087e-08,  5.2144e-09,\n            -4.1376e-08,  4.3673e-08,  1.6070e-07, -5.5699e-08, -1.0409e-07,\n             3.0110e-08, -1.0700e-07,  8.4166e-09, -7.1030e-08,  4.6029e-08,\n             6.4596e-08,  1.5938e-08,  5.7198e-08, -6.9164e-08,  2.7190e-07,\n             7.5328e-08,  3.7697e-08, -2.1820e-08, -8.2277e-08,  5.0635e-08,\n             1.2082e-07, -1.2365e-08,  3.4296e-08,  3.7070e-08,  7.5623e-09,\n            -7.1816e-08,  1.1856e-07, -1.3799e-08,  1.1817e-07,  1.2505e-07,\n             9.6881e-08, -5.6178e-09, -5.8758e-08, -5.3179e-08,  2.2849e-08,\n             1.8387e-07,  6.9996e-08,  2.1362e-09,  6.3262e-08,  4.5519e-08,\n            -9.0973e-08, -7.4588e-08, -2.1280e-07,  1.2254e-07,  7.5538e-08,\n             5.0229e-08,  6.6108e-08, -2.1638e-08,  6.0488e-08,  7.4059e-08,\n             9.9592e-08,  2.8159e-08, -1.1603e-07,  6.1300e-09,  6.5587e-08,\n             1.1657e-07, -6.6507e-08,  5.8787e-08,  1.8775e-07, -3.9796e-08,\n            -8.4060e-08, -1.1669e-07, -1.6127e-07,  1.4740e-07, -2.2447e-07,\n            -9.4132e-08,  7.4738e-08,  3.0243e-08,  8.6474e-08,  3.9630e-08,\n             3.5854e-08, -3.7576e-08,  1.5323e-07, -4.1399e-08,  6.1971e-08,\n            -3.4108e-08, -7.2327e-09, -1.4782e-07,  1.2155e-07, -1.1786e-08,\n            -8.1080e-08,  7.0981e-08,  4.6749e-08,  4.6016e-08, -1.5989e-08,\n            -9.9186e-09, -6.8976e-08,  1.0176e-08, -8.4644e-08,  1.6936e-08,\n             5.7041e-08, -1.6060e-07,  6.8829e-08,  3.9145e-08, -4.0158e-08,\n            -1.9176e-08,  1.5192e-07,  6.4153e-08, -1.2021e-08,  2.8001e-08,\n            -2.4220e-08,  2.0754e-07,  2.5895e-08,  1.3152e-07, -1.6535e-08,\n             3.1481e-08,  5.0653e-08,  1.7338e-08,  5.6201e-08, -1.2241e-07,\n             7.1799e-08,  4.6913e-08, -1.2601e-07,  8.8620e-08,  1.9643e-09,\n            -4.6473e-08, -1.5262e-08, -1.0669e-07, -7.7684e-08,  1.0674e-08,\n            -1.3094e-07,  1.2929e-07, -1.2498e-07,  9.4305e-08, -1.1942e-07,\n             6.4965e-08,  9.8875e-08, -1.3938e-07, -9.0041e-08, -1.0643e-08,\n            -1.0716e-07, -3.0817e-08,  9.5162e-08, -2.9468e-09,  1.0147e-07,\n             5.9919e-08, -2.0474e-08,  1.3454e-07, -8.1639e-10, -3.4748e-09,\n            -1.2422e-07,  2.0549e-08,  8.2771e-08, -1.9176e-08,  5.6576e-08,\n            -1.6688e-08,  2.7821e-08,  2.9704e-08, -1.0473e-08, -7.2238e-08,\n             1.0104e-07, -1.0290e-07, -7.6377e-08, -9.0623e-08,  9.3943e-09,\n            -1.3805e-07, -1.1405e-07, -1.7176e-07,  7.2072e-08,  1.9856e-07,\n             3.9472e-08,  2.1834e-08,  9.1272e-08,  7.2467e-08,  1.5018e-08,\n             6.1519e-08, -2.4732e-07,  8.7174e-08,  5.4948e-09, -7.8622e-08,\n            -8.1227e-08, -5.3094e-08, -3.1681e-08, -7.5427e-11, -1.1392e-07,\n             7.0429e-08, -4.2937e-08,  6.0245e-08,  5.4837e-08, -5.3402e-08,\n             2.6622e-08,  7.9318e-08,  1.3611e-07, -4.6585e-08, -1.7493e-08,\n            -1.3867e-07,  8.6577e-08,  1.4691e-08,  3.4629e-08, -1.1867e-07,\n            -2.1848e-08, -2.1121e-09,  1.6359e-07, -3.8953e-08, -4.5109e-08,\n            -1.0316e-07,  2.5054e-08,  1.2647e-07, -1.5345e-07,  2.3032e-08,\n            -2.1506e-08,  1.2388e-08,  3.3012e-08, -7.6588e-08,  6.1441e-08,\n            -5.6528e-08,  1.5825e-07,  1.8385e-07,  6.9661e-08, -1.6578e-07,\n            -7.7319e-08, -9.6988e-08,  1.1393e-07,  4.3219e-08,  2.6128e-08,\n            -2.8600e-08, -4.0625e-08,  4.9420e-08,  7.0688e-08,  9.0132e-08,\n            -1.3325e-07, -1.9940e-07,  5.5126e-08,  1.4880e-07,  4.2569e-08,\n            -8.4872e-09,  9.1156e-08, -3.5349e-09,  5.2030e-08, -8.4892e-08,\n            -1.2820e-07,  3.8728e-08, -2.9204e-08, -7.9677e-08,  2.4372e-08,\n             1.1981e-07,  1.3296e-07, -1.7975e-07, -1.6243e-07,  8.9237e-08,\n             2.2735e-07,  6.8181e-08,  3.6158e-08,  3.4815e-08,  5.7326e-08,\n            -6.8318e-08, -3.0971e-08,  1.0815e-07, -2.1604e-08,  1.0134e-07,\n             4.3482e-08,  2.4316e-07, -7.5279e-09,  1.2109e-07, -4.2696e-08,\n            -4.3152e-08, -2.3009e-08, -4.8207e-08, -3.2199e-08, -1.1288e-07,\n             1.0275e-07,  1.0670e-07, -1.2715e-07, -6.5404e-09,  7.3025e-08,\n            -7.0794e-08,  9.0567e-08, -1.1070e-07, -8.4767e-09,  1.3946e-07,\n             7.7665e-08,  4.7547e-08, -3.8175e-08,  6.3960e-08, -1.5480e-07,\n             4.4710e-08, -2.5202e-08, -3.3460e-08,  1.0120e-07,  6.5915e-09,\n            -5.2711e-08,  6.8848e-08, -5.8082e-08,  1.1620e-07,  9.5021e-08,\n             1.3406e-08, -8.8147e-08,  9.7144e-08,  2.4462e-07, -1.9042e-07,\n             1.0560e-07, -1.8413e-08,  6.1055e-08, -3.2446e-08, -1.4271e-07,\n             7.7630e-08, -1.1234e-07, -1.4801e-07, -2.0244e-08,  1.0660e-07,\n             1.3252e-07, -7.6432e-08,  1.9496e-07,  7.5931e-09,  1.8409e-07,\n            -6.2386e-08, -7.7642e-08, -2.2111e-07, -7.3935e-08, -5.1173e-08,\n            -3.3938e-08,  5.0644e-08,  2.4753e-08, -1.2290e-07, -1.0203e-07,\n            -3.0818e-08,  8.5731e-08,  5.1367e-08, -1.4134e-08,  3.0386e-09,\n             1.2090e-07, -3.5332e-07,  5.0849e-08,  1.1842e-08,  7.5503e-09,\n            -9.2424e-08, -2.2769e-08, -6.4044e-08, -2.0081e-08,  1.6282e-07,\n             4.4088e-08,  1.7033e-07,  1.2388e-07, -4.8209e-08, -1.8195e-07,\n            -1.8871e-07,  1.3130e-07, -2.5530e-08, -1.4205e-07,  1.2576e-08,\n             3.3802e-08, -3.8308e-08, -5.8510e-08, -6.8677e-09, -2.4663e-08,\n             5.2008e-08,  3.3412e-08, -4.6036e-08, -9.3908e-08,  1.4858e-08,\n             1.8432e-08, -2.3003e-07,  3.6487e-08,  6.3459e-08, -3.4724e-08,\n             1.1298e-07, -3.8510e-08,  2.3911e-08,  3.6792e-08, -3.6660e-08,\n            -5.3998e-08,  3.5880e-08, -6.7684e-08, -4.5329e-08,  2.5423e-08,\n             3.8543e-08,  1.6944e-07,  5.9933e-08,  4.7169e-08,  8.1849e-08,\n            -1.4322e-09, -5.0544e-08,  2.2702e-08,  2.2165e-08, -1.5279e-08,\n             7.0368e-08, -7.2884e-08, -1.4410e-07, -2.7030e-08,  1.0340e-08,\n             1.0305e-07,  2.4192e-08,  9.0533e-08, -5.1940e-08, -1.1197e-07,\n            -1.0022e-08,  4.5150e-08, -4.6480e-08,  1.1646e-07,  1.9631e-07,\n            -4.9021e-08,  6.2657e-08,  1.5633e-07,  9.7480e-08,  5.8094e-08,\n             4.0703e-09, -7.3026e-08, -3.9032e-08,  5.2233e-08, -2.6739e-08,\n            -1.3176e-07, -2.2045e-08, -1.6173e-08,  1.6665e-07,  7.1476e-08,\n            -1.5141e-07, -2.4045e-08, -1.8919e-08,  2.8967e-08,  1.0600e-07,\n             4.0403e-08,  6.1094e-08,  7.0609e-08,  9.8730e-08,  1.0317e-07,\n            -9.2090e-08,  7.7185e-08,  1.6714e-07,  5.0814e-08, -5.9970e-08,\n             3.4500e-08, -1.9809e-07, -1.0980e-07, -1.1130e-07, -8.6051e-08,\n            -5.9021e-08, -7.0431e-09, -1.1841e-07,  5.9695e-08,  1.5129e-08,\n            -1.3186e-08,  1.0650e-07,  1.3993e-07,  5.8645e-08,  6.3241e-08,\n            -1.9552e-07,  5.2282e-08,  1.2184e-07, -1.1743e-07, -6.2788e-09,\n             9.2365e-08, -1.1339e-07, -1.0558e-07, -1.9370e-07,  1.8835e-07,\n            -8.2539e-08,  1.5107e-07,  8.2133e-08,  1.4460e-08,  2.7606e-08,\n            -2.3394e-08,  1.2830e-07,  3.5508e-08,  7.6385e-08,  9.7079e-08,\n            -3.2392e-08,  4.4946e-08, -5.5856e-08,  1.6586e-08,  6.3274e-09,\n             1.6544e-07,  4.0398e-08, -1.2259e-07, -1.2211e-08, -8.0039e-08,\n            -7.1228e-08,  2.2873e-07, -7.6011e-08,  9.1175e-08,  5.7936e-08,\n             3.2892e-08, -1.4555e-07, -1.1189e-07,  5.8752e-08,  3.0041e-08,\n            -9.1049e-08,  1.5046e-07, -6.8441e-08,  1.1097e-07,  2.7244e-08,\n            -1.5869e-08,  1.1928e-08,  9.1538e-08,  7.2043e-08, -1.8333e-08,\n            -1.0295e-07, -5.7856e-08, -8.7875e-08,  1.1558e-07,  8.5335e-08,\n            -1.1230e-07, -4.2524e-08,  2.9992e-08,  6.5252e-09,  6.1966e-08,\n             8.5584e-08, -1.3221e-07,  1.4242e-07,  1.3932e-07,  4.3250e-09,\n             1.0767e-07, -7.1355e-08,  4.7823e-08,  5.4995e-08, -5.5015e-08,\n            -6.6211e-08, -1.4401e-08,  6.3245e-08, -1.0515e-07,  4.4007e-09,\n             9.7883e-08, -9.3014e-08,  2.4194e-08,  5.3226e-08,  4.8041e-08,\n             1.0071e-07,  1.0948e-08,  1.3466e-07,  1.1274e-08, -9.4105e-08,\n            -4.2896e-08,  2.9007e-08,  1.1119e-07,  6.7156e-08,  5.9361e-08,\n            -1.5658e-07, -1.2681e-07, -7.9269e-08, -1.6749e-07,  1.0996e-07,\n            -7.8128e-08,  3.9809e-08,  7.4109e-08, -1.5872e-07,  6.2788e-08,\n            -5.6129e-08, -7.2529e-08,  8.7990e-08,  1.8649e-07,  2.6444e-08,\n            -7.3499e-08,  3.9816e-08,  3.2953e-08,  1.2014e-07, -2.4563e-08,\n             1.6459e-07,  6.9404e-08,  1.4386e-07, -1.0311e-07,  1.0533e-07,\n            -9.6251e-08,  1.4432e-07, -9.1736e-08, -7.4773e-08,  6.2762e-08,\n            -3.6022e-08, -6.1708e-08,  3.7336e-08,  1.7247e-07,  5.7197e-08,\n            -1.2329e-07,  9.1107e-08,  6.0297e-08, -8.6215e-08,  7.1144e-08,\n             2.6763e-08,  1.0440e-07, -5.2384e-08, -7.0078e-08, -2.2476e-07,\n             4.8537e-08,  6.6316e-08, -3.8000e-08, -4.6904e-08, -2.0934e-08,\n            -6.3161e-08, -2.8999e-08, -1.3848e-07,  2.4066e-08, -6.6228e-08,\n             1.0977e-07, -2.9131e-08, -6.1806e-09, -5.8423e-08, -3.6912e-08,\n             2.0665e-08, -1.2228e-07, -1.2285e-07,  2.3707e-07, -2.2623e-08,\n            -5.8665e-09,  1.2220e-07,  6.2023e-08, -5.8478e-08,  1.2232e-08,\n            -1.1042e-08, -4.5000e-08, -1.5965e-08, -2.9764e-09, -3.2092e-08,\n             4.1450e-08,  1.8579e-08,  6.2880e-08,  8.2729e-08, -1.0722e-07,\n             1.4804e-07, -1.2082e-08, -1.5242e-07, -7.4875e-08,  5.4058e-08,\n             2.8569e-08, -1.5033e-09, -3.9689e-08, -4.7919e-08,  6.3677e-08,\n             2.6818e-08,  3.4341e-08, -1.0654e-08,  6.2204e-08,  2.0992e-07,\n             1.0280e-07,  1.3073e-07, -6.0255e-08,  1.7960e-07, -1.8584e-07,\n             6.0109e-08, -8.5557e-08,  4.7643e-08, -8.6443e-08,  1.0864e-08,\n             1.0200e-07,  5.6421e-08, -1.0583e-07, -3.2641e-08,  7.1814e-08,\n            -2.8041e-08, -2.8406e-08,  1.5821e-07,  1.4679e-07,  3.8146e-08,\n             9.2561e-08,  4.2157e-08,  1.5128e-07,  6.1203e-08,  1.3406e-08,\n             1.1928e-07,  1.0426e-07,  4.8796e-08, -1.0413e-07,  1.3261e-07,\n             6.4910e-08,  3.7834e-09,  1.2879e-07,  5.3465e-08, -5.3237e-08,\n            -6.9525e-08,  1.1498e-07, -1.9674e-07,  1.2633e-08,  1.0612e-07,\n            -4.8139e-08, -1.1396e-07, -1.8651e-08, -5.3497e-08,  3.3190e-08,\n             1.5360e-07, -1.5315e-07,  3.8927e-08, -1.9744e-08,  4.0473e-08,\n             7.0420e-08, -3.3498e-08, -1.5192e-07,  8.9078e-09,  2.3891e-07,\n            -2.8318e-08,  1.2308e-08, -1.5864e-07,  5.1473e-08, -3.5550e-08,\n             1.1041e-07, -7.6471e-08,  1.5554e-07, -7.6099e-08, -1.8809e-08,\n             1.0174e-07, -5.4531e-08, -1.0411e-07,  8.8363e-08, -1.0382e-07,\n            -6.7143e-08, -7.8887e-09,  3.9784e-08,  4.9462e-08, -7.0472e-08,\n             8.8986e-08,  4.4595e-09,  1.4835e-08,  3.4031e-08,  1.6054e-08,\n             7.2690e-08, -1.0574e-08,  2.2340e-08,  5.4826e-08,  3.5509e-08,\n            -2.3889e-08,  6.7404e-08,  1.3783e-09,  2.1175e-07, -1.0986e-08,\n             1.0476e-07, -8.2273e-08,  8.9137e-08, -4.4063e-08, -6.5530e-08,\n            -8.1760e-08, -3.5320e-08,  6.6156e-09,  5.1303e-08,  6.3560e-08,\n            -1.3572e-07, -6.1248e-10, -3.0828e-09,  7.1873e-08,  5.7291e-08,\n             6.1966e-08, -4.7621e-08, -5.5833e-08,  6.0459e-08, -7.6798e-08,\n            -1.0809e-07,  2.8610e-08, -1.0193e-07, -7.4233e-09,  4.9826e-09,\n            -1.2438e-07, -6.3078e-08, -1.5387e-08,  3.0337e-08,  5.5914e-08,\n            -1.5044e-07, -1.9027e-07,  9.0320e-09,  1.4060e-07,  8.6130e-08,\n            -2.0415e-08,  8.9481e-08, -6.5940e-08,  1.5532e-07, -1.1153e-08,\n            -2.6565e-08, -3.4021e-08,  1.9379e-07,  1.2736e-08,  9.4373e-08,\n             9.2128e-10,  7.4203e-08,  3.4619e-08, -1.6973e-08, -5.2658e-08,\n             1.1803e-07,  6.7719e-08, -5.7508e-08, -1.8823e-07,  1.0449e-08,\n             1.4694e-07,  5.0118e-08,  9.1369e-08, -1.3921e-07, -2.2936e-07,\n            -1.3240e-07,  1.2008e-07, -9.2076e-08,  2.1059e-08, -5.2717e-08,\n             6.9891e-09,  6.6041e-08, -5.1571e-08, -8.5931e-08,  7.1865e-08,\n            -2.0909e-07,  1.6874e-07,  7.3474e-08,  1.6297e-07, -7.6088e-08,\n             5.1347e-08, -8.3300e-08,  7.8202e-08, -4.9501e-08,  1.1119e-07,\n            -2.1507e-08,  4.3197e-08,  2.2220e-08, -3.9423e-08,  9.4185e-08,\n             1.4564e-08, -1.6589e-08,  5.3429e-08, -4.0569e-08,  1.4258e-07,\n             1.2632e-07, -4.9804e-08, -8.4714e-09,  2.9716e-08,  1.0839e-07,\n             1.1771e-07,  1.4225e-07,  8.2768e-08, -3.9768e-08, -9.4250e-08,\n             1.3608e-07,  2.3702e-08,  1.2642e-09,  1.9744e-08, -2.3587e-07,\n             8.7692e-08,  1.8556e-07, -8.5810e-08,  4.4603e-08,  9.8202e-09,\n            -3.7525e-08, -5.5163e-08,  1.4838e-08,  2.0044e-07, -6.9924e-08,\n             1.2532e-07, -7.6057e-08,  1.0404e-07,  9.7042e-08,  1.1635e-07,\n            -3.6620e-08, -1.8412e-07,  5.8748e-08, -2.2932e-07, -4.9393e-08,\n             4.7880e-09, -6.2316e-09,  7.3090e-08,  2.0384e-07, -6.4444e-08,\n             7.1759e-08,  1.7257e-08,  3.2309e-08, -7.0463e-09, -9.1368e-09,\n             1.7331e-07,  4.1142e-08, -2.5808e-09, -6.0668e-11,  6.7706e-08,\n             9.6770e-08, -1.0163e-07, -6.6015e-08, -5.3062e-08, -1.0277e-07,\n             3.4697e-08, -1.1806e-08, -5.4703e-08,  1.5521e-07,  1.1032e-07,\n             5.1113e-08, -8.5357e-08,  2.2959e-08,  1.8217e-07,  3.2580e-08,\n             4.7987e-08, -2.1370e-07, -5.1525e-08,  3.8894e-09, -4.9505e-08,\n            -3.9080e-08,  1.4503e-07, -1.2376e-08, -2.6670e-07,  6.2946e-08,\n             2.4882e-08,  1.2915e-08,  1.4134e-07,  1.9330e-07,  5.0421e-08,\n            -7.9720e-08,  7.6129e-08, -2.7890e-08,  6.5515e-08,  1.4599e-07,\n            -1.5249e-07,  8.5705e-08,  1.0005e-07, -1.0892e-07, -1.1663e-07,\n            -2.2838e-07, -4.0048e-08,  5.3081e-08, -7.7431e-08, -1.3573e-07,\n            -1.1247e-07,  3.1486e-08,  6.9843e-09,  2.7041e-07, -2.1494e-08,\n             4.7978e-08,  7.1438e-08, -1.4630e-07, -9.4199e-08, -1.8549e-08,\n             1.4501e-07,  1.5486e-07, -1.4816e-07,  1.5721e-08, -1.2188e-08,\n             4.0057e-08,  9.3798e-08, -8.8493e-09, -1.3899e-07, -2.2668e-09,\n            -1.0832e-07,  1.3775e-07, -1.4476e-07,  9.5317e-08,  1.0523e-07,\n            -8.4103e-08,  5.5228e-08,  8.0143e-08,  1.8608e-07,  1.1995e-07,\n             1.0430e-07,  2.2840e-07,  3.3342e-08,  1.6286e-08,  4.7961e-08,\n            -4.2536e-08,  4.9039e-08, -3.4520e-09,  3.7682e-08, -7.6531e-08,\n            -1.7263e-07, -1.9695e-07,  1.1472e-07,  1.3445e-07,  2.4078e-08,\n            -9.4013e-08,  9.5052e-08, -1.2511e-07,  2.8020e-08, -2.8821e-08,\n            -2.0469e-07,  4.6900e-08, -2.2429e-08, -1.6896e-07,  8.8658e-08,\n            -1.0994e-07, -2.5250e-08, -9.2617e-08, -5.2235e-08,  7.3130e-08]),\n    'exp_avg_sq': tensor([2.9710e-13, 3.2554e-13, 3.7366e-13, 3.5212e-13, 2.6801e-13, 2.1115e-13,\n            1.8100e-13, 3.4092e-13, 2.7557e-13, 3.0200e-13, 2.5981e-13, 2.5827e-13,\n            2.8710e-13, 2.9190e-13, 3.1855e-13, 2.4618e-13, 3.3810e-13, 2.7235e-13,\n            2.5812e-13, 2.8595e-13, 3.0063e-13, 2.1695e-13, 3.2657e-13, 2.9122e-13,\n            2.6187e-13, 3.1371e-13, 2.6478e-13, 2.5427e-13, 3.2463e-13, 2.0971e-13,\n            2.0767e-13, 3.5812e-13, 3.1167e-13, 2.5912e-13, 2.5429e-13, 3.7016e-13,\n            3.2406e-13, 2.9552e-13, 1.9418e-13, 3.2123e-13, 2.1837e-13, 2.1349e-13,\n            2.8202e-13, 2.4818e-13, 3.6932e-13, 1.9959e-13, 3.2284e-13, 3.7300e-13,\n            3.4362e-13, 3.7047e-13, 2.7103e-13, 3.1750e-13, 3.6405e-13, 2.7629e-13,\n            3.0362e-13, 3.4507e-13, 2.5158e-13, 2.9208e-13, 2.7373e-13, 3.0674e-13,\n            2.8907e-13, 3.1492e-13, 2.9149e-13, 2.9144e-13, 2.0435e-13, 2.9001e-13,\n            3.2570e-13, 2.7909e-13, 2.9254e-13, 2.5726e-13, 3.4282e-13, 2.2055e-13,\n            2.6780e-13, 3.2647e-13, 3.4039e-13, 2.1221e-13, 3.0565e-13, 2.8498e-13,\n            2.7885e-13, 2.1157e-13, 3.1586e-13, 3.1524e-13, 2.6736e-13, 2.7660e-13,\n            3.2258e-13, 3.3902e-13, 2.9646e-13, 2.8657e-13, 2.1109e-13, 2.9807e-13,\n            3.1868e-13, 2.6139e-13, 2.6851e-13, 2.5523e-13, 2.5331e-13, 2.8554e-13,\n            2.3924e-13, 2.7903e-13, 2.2367e-13, 2.1806e-13, 2.4430e-13, 2.5626e-13,\n            2.6871e-13, 2.4498e-13, 2.9577e-13, 3.0807e-13, 2.7718e-13, 2.9914e-13,\n            3.1357e-13, 2.5865e-13, 3.4301e-13, 3.2755e-13, 3.4247e-13, 2.9027e-13,\n            2.9140e-13, 2.9310e-13, 2.2444e-13, 2.7605e-13, 2.5249e-13, 2.8425e-13,\n            3.1584e-13, 2.9026e-13, 2.8604e-13, 3.4921e-13, 2.8017e-13, 3.0427e-13,\n            2.4953e-13, 3.4354e-13, 2.7197e-13, 2.9646e-13, 2.6118e-13, 3.0806e-13,\n            2.5950e-13, 3.0330e-13, 3.0865e-13, 3.1271e-13, 3.2617e-13, 2.8173e-13,\n            3.6508e-13, 2.8518e-13, 3.1141e-13, 3.0656e-13, 2.6732e-13, 2.2873e-13,\n            3.1219e-13, 3.2054e-13, 2.9721e-13, 2.3685e-13, 3.0677e-13, 2.4871e-13,\n            3.6591e-13, 3.3623e-13, 2.5881e-13, 3.0356e-13, 2.8669e-13, 3.1066e-13,\n            2.7239e-13, 2.9955e-13, 2.6568e-13, 2.5894e-13, 2.9738e-13, 2.9691e-13,\n            3.2668e-13, 3.2133e-13, 2.3259e-13, 2.9230e-13, 2.8712e-13, 2.5283e-13,\n            2.2481e-13, 3.2558e-13, 2.9115e-13, 3.5011e-13, 2.6770e-13, 2.4931e-13,\n            2.7126e-13, 3.0777e-13, 3.1210e-13, 2.1677e-13, 2.8145e-13, 2.9109e-13,\n            2.9175e-13, 3.1168e-13, 2.9721e-13, 2.8799e-13, 2.6731e-13, 3.6420e-13,\n            3.0130e-13, 2.4794e-13, 3.3214e-13, 2.1692e-13, 2.8805e-13, 2.6552e-13,\n            2.4611e-13, 3.0648e-13, 2.7564e-13, 3.0295e-13, 2.6096e-13, 2.4019e-13,\n            2.1658e-13, 2.9055e-13, 2.9860e-13, 2.2469e-13, 2.6083e-13, 2.6103e-13,\n            3.7184e-13, 2.3478e-13, 2.6849e-13, 3.0074e-13, 2.4364e-13, 2.8100e-13,\n            2.6533e-13, 2.9666e-13, 2.6809e-13, 3.0667e-13, 2.3435e-13, 3.0063e-13,\n            2.8116e-13, 2.8121e-13, 3.4255e-13, 3.2356e-13, 2.8859e-13, 2.7893e-13,\n            2.6105e-13, 3.3620e-13, 2.5785e-13, 2.6104e-13, 3.3026e-13, 2.7762e-13,\n            1.8429e-13, 2.3220e-13, 2.3600e-13, 2.1976e-13, 2.9892e-13, 2.5098e-13,\n            2.2164e-13, 2.2063e-13, 2.5585e-13, 1.6480e-13, 2.7235e-13, 2.4277e-13,\n            3.0782e-13, 2.8700e-13, 2.2014e-13, 2.3452e-13, 1.8640e-13, 2.3946e-13,\n            2.8135e-13, 2.6743e-13, 2.3975e-13, 2.8259e-13, 3.2344e-13, 3.2204e-13,\n            2.5336e-13, 2.3466e-13, 2.6039e-13, 1.8824e-13, 2.5438e-13, 3.5909e-13,\n            3.1871e-13, 3.2981e-13, 2.6682e-13, 2.3228e-13, 2.6686e-13, 3.1037e-13,\n            2.3965e-13, 2.6797e-13, 2.6184e-13, 2.7275e-13, 2.9183e-13, 2.6270e-13,\n            2.8887e-13, 2.5449e-13, 2.7286e-13, 2.6006e-13, 2.7423e-13, 2.6693e-13,\n            3.6615e-13, 2.2267e-13, 2.4171e-13, 2.6798e-13, 3.2948e-13, 3.1595e-13,\n            2.9456e-13, 2.3741e-13, 2.5067e-13, 3.0178e-13, 3.1494e-13, 2.5362e-13,\n            2.8927e-13, 2.8018e-13, 3.2781e-13, 2.8212e-13, 3.0318e-13, 2.7338e-13,\n            3.3243e-13, 3.0289e-13, 4.1758e-13, 2.6790e-13, 2.6279e-13, 3.4771e-13,\n            2.7739e-13, 3.0170e-13, 2.1249e-13, 2.9742e-13, 3.0048e-13, 2.9461e-13,\n            2.9542e-13, 2.4568e-13, 3.1324e-13, 2.8226e-13, 2.8786e-13, 2.9686e-13,\n            2.9574e-13, 2.4705e-13, 2.7490e-13, 2.3769e-13, 3.1230e-13, 2.4413e-13,\n            2.7376e-13, 2.4860e-13, 2.5597e-13, 2.4584e-13, 2.3002e-13, 2.5968e-13,\n            2.3983e-13, 2.0585e-13, 3.0355e-13, 2.2212e-13, 3.2826e-13, 1.4362e-13,\n            2.8505e-13, 2.0529e-13, 2.6103e-13, 3.0008e-13, 3.6214e-13, 3.5283e-13,\n            2.8839e-13, 2.9683e-13, 2.7077e-13, 3.4380e-13, 3.0115e-13, 3.1809e-13,\n            3.2730e-13, 3.5619e-13, 2.8058e-13, 3.3114e-13, 3.5958e-13, 2.6964e-13,\n            3.0047e-13, 2.9646e-13, 2.5578e-13, 2.8071e-13, 3.5447e-13, 3.0403e-13,\n            2.8706e-13, 3.5078e-13, 1.5946e-13, 1.4864e-13, 2.8167e-13, 2.8169e-13,\n            2.5155e-13, 2.3251e-13, 2.7031e-13, 2.8165e-13, 2.7012e-13, 2.9799e-13,\n            3.4314e-13, 1.9536e-13, 2.1200e-13, 2.5532e-13, 2.4144e-13, 3.1008e-13,\n            2.2933e-13, 2.7653e-13, 3.3453e-13, 3.2586e-13, 2.9826e-13, 3.1021e-13,\n            3.1978e-13, 3.8198e-13, 3.2011e-13, 3.1226e-13, 2.4783e-13, 2.5796e-13,\n            2.3674e-13, 2.6787e-13, 1.8066e-13, 2.3191e-13, 3.2342e-13, 1.7590e-13,\n            2.1902e-13, 2.6810e-13, 2.3108e-13, 2.9392e-13, 2.2303e-13, 2.3861e-13,\n            2.6469e-13, 2.3804e-13, 3.2289e-13, 2.2458e-13, 2.1468e-13, 2.5711e-13,\n            2.9515e-13, 1.8869e-13, 2.0544e-13, 2.5097e-13, 2.6288e-13, 2.7014e-13,\n            2.2446e-13, 2.7728e-13, 1.9108e-13, 2.3126e-13, 2.0284e-13, 3.0558e-13,\n            3.3857e-13, 1.8781e-13, 2.1039e-13, 2.3067e-13, 2.0278e-13, 2.5936e-13,\n            2.0944e-13, 2.0893e-13, 2.2975e-13, 2.5518e-13, 1.7920e-13, 2.7902e-13,\n            2.5055e-13, 2.4426e-13, 2.6759e-13, 3.1525e-13, 2.2047e-13, 2.5426e-13,\n            2.2372e-13, 2.1629e-13, 2.1387e-13, 2.8094e-13, 2.5183e-13, 2.4315e-13,\n            2.9457e-13, 1.8775e-13, 2.5461e-13, 2.7865e-13, 2.7065e-13, 2.3442e-13,\n            3.2043e-13, 2.6020e-13, 2.6363e-13, 2.8710e-13, 2.0933e-13, 1.9964e-13,\n            2.5911e-13, 1.4357e-13, 2.1349e-13, 2.3750e-13, 2.8524e-13, 3.0283e-13,\n            3.1430e-13, 2.7711e-13, 2.5780e-13, 2.7962e-13, 3.0260e-13, 2.5360e-13,\n            2.6972e-13, 3.3214e-13, 3.4213e-13, 2.8053e-13, 2.6501e-13, 2.8754e-13,\n            3.4406e-13, 1.9255e-13, 3.5113e-13, 2.9654e-13, 2.9636e-13, 2.8729e-13,\n            3.1586e-13, 2.7851e-13, 3.1660e-13, 2.4925e-13, 3.4613e-13, 3.2400e-13,\n            2.7113e-13, 2.5762e-13, 2.6208e-13, 2.7195e-13, 3.3168e-13, 3.6380e-13,\n            2.8781e-13, 2.7270e-13, 2.7632e-13, 2.9920e-13, 3.0097e-13, 3.7335e-13,\n            3.3977e-13, 1.7794e-13, 3.4836e-13, 2.4055e-13, 2.4963e-13, 2.0772e-13,\n            2.5904e-13, 2.7691e-13, 3.1832e-13, 3.5655e-13, 2.6599e-13, 2.8854e-13,\n            3.6376e-13, 3.2705e-13, 3.2871e-13, 3.2341e-13, 3.3737e-13, 3.1469e-13,\n            2.9824e-13, 3.0704e-13, 2.5185e-13, 2.9612e-13, 2.5823e-13, 2.9261e-13,\n            3.0123e-13, 2.9024e-13, 2.7586e-13, 1.9199e-13, 3.1406e-13, 3.4585e-13,\n            2.8741e-13, 3.5130e-13, 2.6144e-13, 2.9785e-13, 2.7730e-13, 2.6448e-13,\n            2.6246e-13, 2.8926e-13, 3.4318e-13, 2.4315e-13, 3.1413e-13, 3.3695e-13,\n            3.2238e-13, 3.2156e-13, 2.5273e-13, 2.8426e-13, 3.7866e-13, 2.9322e-13,\n            3.2724e-13, 3.2342e-13, 2.6063e-13, 2.7542e-13, 2.8165e-13, 3.4526e-13,\n            2.5166e-13, 2.7033e-13, 2.1638e-13, 2.8651e-13, 2.8605e-13, 3.0766e-13,\n            2.0942e-13, 2.8481e-13, 3.1235e-13, 3.0588e-13, 2.3021e-13, 2.4957e-13,\n            2.8151e-13, 2.5546e-13, 3.2811e-13, 3.2624e-13, 2.3320e-13, 2.6556e-13,\n            2.2169e-13, 2.8651e-13, 2.7549e-13, 3.0372e-13, 3.9178e-13, 3.8114e-13,\n            3.0290e-13, 2.2898e-13, 2.8917e-13, 3.1207e-13, 2.6289e-13, 2.7662e-13,\n            2.8688e-13, 3.0426e-13, 3.1594e-13, 3.5853e-13, 2.8287e-13, 3.5416e-13,\n            3.0482e-13, 3.0514e-13, 3.3624e-13, 3.5942e-13, 3.2354e-13, 2.7492e-13,\n            3.2078e-13, 2.5115e-13, 2.9963e-13, 2.1326e-13, 3.4121e-13, 3.0070e-13,\n            3.1852e-13, 3.1550e-13, 2.6988e-13, 3.1758e-13, 3.3504e-13, 2.8971e-13,\n            2.6385e-13, 2.8656e-13, 3.2766e-13, 2.7769e-13, 3.0637e-13, 2.9972e-13,\n            2.6698e-13, 2.8724e-13, 2.6626e-13, 3.2294e-13, 2.8590e-13, 2.7884e-13,\n            2.8366e-13, 2.9213e-13, 2.6106e-13, 3.0361e-13, 2.5615e-13, 2.4739e-13,\n            2.8958e-13, 3.0105e-13, 2.1557e-13, 2.2868e-13, 2.6046e-13, 3.0450e-13,\n            2.6780e-13, 2.7000e-13, 2.8077e-13, 3.1240e-13, 2.5251e-13, 2.5934e-13,\n            3.1590e-13, 3.4004e-13, 3.1775e-13, 2.9545e-13, 3.2177e-13, 3.2097e-13,\n            2.3346e-13, 2.7162e-13, 3.6316e-13, 2.7627e-13, 1.8504e-13, 2.1101e-13,\n            1.7531e-13, 1.9984e-13, 1.8386e-13, 2.3655e-13, 2.1551e-13, 2.4778e-13,\n            2.0860e-13, 2.4891e-13, 2.5344e-13, 2.7981e-13, 2.7367e-13, 2.8895e-13,\n            2.5961e-13, 2.5272e-13, 2.3916e-13, 3.0796e-13, 3.4329e-13, 2.2648e-13,\n            3.4561e-13, 2.7900e-13, 2.8389e-13, 2.9446e-13, 2.6641e-13, 3.3182e-13,\n            3.3022e-13, 2.4787e-13, 3.3029e-13, 2.8215e-13, 3.0238e-13, 3.0874e-13,\n            3.1393e-13, 3.3142e-13, 3.6732e-13, 3.2806e-13, 2.4967e-13, 2.3401e-13,\n            2.9350e-13, 2.7207e-13, 2.6255e-13, 2.3160e-13, 2.7440e-13, 3.1020e-13,\n            2.4695e-13, 2.5858e-13, 2.4888e-13, 3.0090e-13, 2.7600e-13, 3.2343e-13,\n            2.9870e-13, 2.3610e-13, 2.4076e-13, 3.0038e-13, 2.6521e-13, 2.4443e-13,\n            2.8722e-13, 3.3471e-13, 2.6270e-13, 2.4854e-13, 2.9358e-13, 3.0091e-13,\n            3.2637e-13, 3.6032e-13, 3.2102e-13, 3.4082e-13, 2.3564e-13, 3.0677e-13,\n            3.3372e-13, 2.8132e-13, 3.4262e-13, 3.9245e-13, 2.4915e-13, 2.3127e-13,\n            3.0769e-13, 2.9269e-13, 2.6101e-13, 3.5212e-13, 3.2401e-13, 3.1864e-13,\n            3.1441e-13, 3.0425e-13, 3.2952e-13, 3.1509e-13, 2.6926e-13, 2.8855e-13,\n            2.4811e-13, 3.2415e-13, 2.4786e-13, 2.9946e-13, 2.6825e-13, 2.6593e-13,\n            2.8475e-13, 2.9746e-13, 2.3782e-13, 2.1340e-13, 2.3069e-13, 2.3512e-13,\n            2.7876e-13, 2.6992e-13, 2.6468e-13, 2.4900e-13, 2.8983e-13, 2.6695e-13,\n            1.8479e-13, 2.9330e-13, 2.9725e-13, 2.6921e-13, 2.9823e-13, 3.1446e-13,\n            2.9315e-13, 3.0783e-13, 2.4604e-13, 2.7764e-13, 2.5903e-13, 2.3813e-13,\n            2.9277e-13, 2.6447e-13, 3.1631e-13, 2.7563e-13, 2.9574e-13, 3.4247e-13,\n            2.3198e-13, 3.4333e-13, 3.2127e-13, 3.5831e-13, 2.7129e-13, 2.9142e-13,\n            2.4509e-13, 2.7807e-13, 2.7110e-13, 1.9935e-13, 3.2208e-13, 2.8311e-13,\n            3.0032e-13, 3.1478e-13, 3.0291e-13, 3.1173e-13, 3.0649e-13, 2.4985e-13,\n            3.4738e-13, 3.2457e-13, 2.1427e-13, 2.6873e-13, 3.1129e-13, 3.1837e-13,\n            3.1656e-13, 3.1036e-13, 2.7376e-13, 3.0360e-13, 2.7547e-13, 2.8669e-13,\n            2.9970e-13, 3.2725e-13, 2.1336e-13, 2.6572e-13, 3.0042e-13, 2.9469e-13,\n            3.8877e-13, 3.2639e-13, 2.9716e-13, 2.9452e-13, 2.5729e-13, 3.2442e-13,\n            2.7345e-13, 2.8894e-13, 2.4006e-13, 2.8397e-13, 3.0417e-13, 3.5084e-13,\n            2.9397e-13, 2.5964e-13, 2.1358e-13, 3.2402e-13, 3.0030e-13, 2.8226e-13,\n            3.0135e-13, 2.8380e-13, 3.3333e-13, 2.8898e-13, 2.4947e-13, 2.8996e-13,\n            2.7892e-13, 2.9386e-13, 2.8263e-13, 2.9528e-13, 3.3022e-13, 3.0804e-13,\n            3.1496e-13, 2.5205e-13, 3.5470e-13, 2.1126e-13, 3.1788e-13, 2.1742e-13,\n            2.8079e-13, 2.7157e-13, 2.6214e-13, 2.8347e-13, 3.2510e-13, 2.9379e-13,\n            3.2849e-13, 3.0878e-13, 3.1771e-13, 2.3268e-13, 3.3374e-13, 2.9268e-13,\n            2.6873e-13, 2.9065e-13, 2.2054e-13, 3.1234e-13, 2.7493e-13, 2.1498e-13,\n            2.8242e-13, 2.8606e-13, 2.8744e-13, 3.2891e-13, 2.6031e-13, 2.4490e-13,\n            3.0735e-13, 2.7084e-13, 2.8363e-13, 2.8292e-13, 3.2186e-13, 3.1231e-13,\n            3.1587e-13, 3.0629e-13, 2.9369e-13, 2.9490e-13, 2.9313e-13, 2.4118e-13,\n            2.8875e-13, 2.9352e-13, 2.5038e-13, 3.4339e-13, 3.2515e-13, 2.7720e-13,\n            4.2832e-13, 2.6050e-13, 2.9509e-13, 3.0060e-13, 3.3241e-13, 2.2662e-13,\n            3.7578e-13, 3.1471e-13, 3.2765e-13, 2.1389e-13, 1.4422e-13, 3.0117e-13,\n            3.0704e-13, 2.4621e-13, 2.7580e-13, 3.3084e-13, 2.2933e-13, 3.0682e-13,\n            2.8136e-13, 2.8944e-13, 2.7377e-13, 3.2030e-13, 2.8373e-13, 3.1337e-13,\n            3.1254e-13, 3.2399e-13, 2.2442e-13, 2.6909e-13, 3.1223e-13, 2.7771e-13,\n            3.1626e-13, 2.2142e-13, 2.8337e-13, 2.5893e-13, 3.1003e-13, 2.7039e-13,\n            1.8717e-13, 3.0607e-13, 2.9181e-13, 2.4860e-13, 2.5410e-13, 2.6681e-13,\n            2.5623e-13, 3.0304e-13, 3.2839e-13, 2.4405e-13, 3.0089e-13, 2.9752e-13,\n            3.1705e-13, 2.1035e-13, 3.1269e-13, 3.2753e-13, 3.2064e-13, 2.8471e-13,\n            3.0421e-13, 2.6337e-13, 2.8105e-13, 2.7084e-13, 2.8533e-13, 2.1807e-13,\n            2.6002e-13, 3.8274e-13, 3.3908e-13, 2.8419e-13, 3.3478e-13, 2.2480e-13,\n            3.7184e-13, 3.5104e-13, 2.8204e-13, 3.1440e-13, 2.5279e-13, 1.6795e-13,\n            3.4688e-13, 3.1540e-13, 3.2541e-13, 2.9146e-13, 3.1409e-13, 2.2047e-13,\n            2.9674e-13, 2.1052e-13, 3.3322e-13, 3.3603e-13, 3.1122e-13, 2.9358e-13,\n            2.9190e-13, 2.3343e-13, 3.0940e-13, 2.9461e-13, 2.6568e-13, 2.8078e-13,\n            2.9064e-13, 3.4239e-13, 2.5431e-13, 2.2202e-13, 3.1229e-13, 2.8168e-13,\n            2.8984e-13, 3.2980e-13, 2.9163e-13, 2.6174e-13, 2.8897e-13, 3.0098e-13,\n            3.2134e-13, 3.3865e-13, 3.1253e-13, 2.1938e-13, 3.3974e-13, 2.9584e-13,\n            2.5725e-13, 2.7433e-13, 3.1694e-13, 2.7811e-13, 2.8265e-13, 2.7951e-13,\n            2.9615e-13, 3.0786e-13, 2.0311e-13, 3.0072e-13, 2.7332e-13, 2.8758e-13,\n            3.2766e-13, 3.5601e-13, 1.8337e-13, 3.3010e-13])},\n   107: {'exp_avg': tensor([[[[ 5.9945e-07,  1.8500e-06,  2.6058e-06,  ...,  2.9678e-06,\n                1.5110e-06,  9.3293e-07],\n              [-2.1619e-07,  1.2878e-06,  1.8547e-06,  ...,  2.2300e-06,\n                1.0558e-06,  5.2859e-07],\n              [-3.9098e-07,  1.0939e-06,  1.1124e-06,  ...,  1.7000e-06,\n                8.2388e-07,  3.9007e-07],\n              ...,\n              [ 8.2768e-07,  2.3606e-06,  1.4615e-06,  ...,  1.7155e-06,\n                2.0213e-06,  1.5334e-06],\n              [ 4.0259e-07,  2.8347e-06,  2.0645e-06,  ...,  1.0264e-06,\n                1.4838e-06,  1.0623e-06],\n              [ 1.1345e-07,  2.5679e-06,  2.4861e-06,  ...,  1.1446e-06,\n                1.2064e-06,  1.3109e-06]],\n    \n             [[ 1.2375e-07,  1.4762e-06,  2.2944e-06,  ...,  2.9802e-06,\n                1.9924e-06,  1.6385e-06],\n              [-6.3704e-07,  7.0737e-07,  1.3275e-06,  ...,  1.8844e-06,\n                1.1145e-06,  7.4700e-07],\n              [-8.4753e-07,  3.2693e-07,  3.3876e-07,  ...,  9.2578e-07,\n                3.2958e-07,  1.1834e-07],\n              ...,\n              [-2.3511e-07,  1.0875e-06,  3.3459e-07,  ...,  9.4351e-07,\n                1.3988e-06,  1.0275e-06],\n              [-5.5148e-07,  1.7091e-06,  1.0812e-06,  ...,  5.5005e-07,\n                9.8315e-07,  7.1977e-07],\n              [-6.5467e-07,  1.6474e-06,  1.7155e-06,  ...,  9.2175e-07,\n                1.0889e-06,  1.2271e-06]],\n    \n             [[-2.1117e-07,  1.1953e-06,  1.9505e-06,  ...,  2.0322e-06,\n                1.2397e-06,  8.1224e-07],\n              [-5.3852e-07,  6.0128e-07,  1.1994e-06,  ...,  1.1573e-06,\n                6.3274e-07,  1.7182e-07],\n              [-6.4443e-07,  2.2257e-07,  1.9947e-07,  ...,  4.5364e-07,\n                1.9417e-07, -1.5531e-07],\n              ...,\n              [-2.8926e-07,  8.5561e-07,  2.0276e-07,  ...,  7.2294e-07,\n                1.5382e-06,  1.0324e-06],\n              [-5.1282e-07,  1.5378e-06,  1.0081e-06,  ...,  5.9850e-07,\n                1.3589e-06,  1.0897e-06],\n              [-6.4233e-07,  1.5242e-06,  1.7177e-06,  ...,  1.0541e-06,\n                1.4699e-06,  1.6190e-06]]],\n    \n    \n            [[[-8.1266e-06, -8.3970e-06, -7.6765e-06,  ..., -7.2378e-06,\n               -6.4430e-06, -5.5007e-06],\n              [-6.5062e-06, -7.3235e-06, -6.1693e-06,  ..., -5.8172e-06,\n               -4.9024e-06, -4.3400e-06],\n              [-6.1785e-06, -6.8223e-06, -5.5642e-06,  ..., -5.0001e-06,\n               -4.1518e-06, -3.5414e-06],\n              ...,\n              [-3.8590e-06, -3.5889e-06, -2.9023e-06,  ..., -2.4028e-06,\n               -1.9708e-06, -2.0870e-06],\n              [-3.3193e-06, -3.5908e-06, -2.9358e-06,  ..., -3.3724e-06,\n               -3.0553e-06, -2.6178e-06],\n              [-3.1645e-06, -3.2824e-06, -2.6821e-06,  ..., -4.0134e-06,\n               -3.8174e-06, -2.6829e-06]],\n    \n             [[-5.3670e-06, -5.4934e-06, -4.7984e-06,  ..., -4.2724e-06,\n               -3.9099e-06, -3.0630e-06],\n              [-4.6095e-06, -5.2222e-06, -3.9312e-06,  ..., -3.4984e-06,\n               -3.1382e-06, -2.7284e-06],\n              [-4.7381e-06, -5.4293e-06, -4.0007e-06,  ..., -3.2978e-06,\n               -2.8655e-06, -2.2847e-06],\n              ...,\n              [-2.5304e-06, -2.7430e-06, -1.8762e-06,  ..., -1.4809e-06,\n               -1.4766e-06, -1.5088e-06],\n              [-2.7240e-06, -3.1741e-06, -2.3691e-06,  ..., -2.8683e-06,\n               -3.1147e-06, -2.6417e-06],\n              [-2.8511e-06, -2.7926e-06, -1.9398e-06,  ..., -2.8824e-06,\n               -3.4306e-06, -2.4112e-06]],\n    \n             [[-4.4963e-06, -4.2178e-06, -3.3991e-06,  ..., -2.5259e-06,\n               -2.5070e-06, -1.7345e-06],\n              [-4.8559e-06, -4.9201e-06, -3.4183e-06,  ..., -2.5993e-06,\n               -2.5879e-06, -2.3010e-06],\n              [-5.0644e-06, -5.2441e-06, -3.8259e-06,  ..., -2.6130e-06,\n               -2.3421e-06, -1.8668e-06],\n              ...,\n              [-2.4920e-06, -2.1698e-06, -1.7060e-06,  ..., -1.0690e-06,\n               -1.0665e-06, -1.3396e-06],\n              [-2.9829e-06, -2.9070e-06, -2.3946e-06,  ..., -2.5677e-06,\n               -2.8050e-06, -2.4912e-06],\n              [-2.9621e-06, -2.4913e-06, -1.8697e-06,  ..., -2.4136e-06,\n               -3.0238e-06, -2.2775e-06]]],\n    \n    \n            [[[ 5.4904e-06,  3.9979e-06,  3.3813e-06,  ...,  6.6331e-06,\n                8.8561e-06,  9.2442e-06],\n              [ 5.0216e-06,  3.0026e-06,  3.3844e-06,  ...,  6.8819e-06,\n                8.1240e-06,  9.2371e-06],\n              [ 3.9847e-06,  2.1160e-06,  2.9052e-06,  ...,  6.6234e-06,\n                7.4988e-06,  8.9907e-06],\n              ...,\n              [ 2.1076e-06,  2.4458e-06,  2.5484e-06,  ...,  6.0727e-06,\n                7.9636e-06,  8.7255e-06],\n              [ 1.6219e-06,  1.6784e-06,  2.1758e-06,  ...,  6.3591e-06,\n                8.7238e-06,  8.9515e-06],\n              [ 6.0438e-07,  5.7485e-07,  1.4942e-06,  ...,  6.7246e-06,\n                8.9804e-06,  8.5121e-06]],\n    \n             [[ 2.1899e-06,  1.0358e-06, -8.2945e-08,  ...,  3.4386e-06,\n                5.4226e-06,  5.2929e-06],\n              [ 2.0609e-06,  1.7538e-08, -2.2913e-08,  ...,  3.6745e-06,\n                4.8758e-06,  5.6997e-06],\n              [ 5.6462e-07, -1.3312e-06, -7.8189e-07,  ...,  3.0255e-06,\n                3.9947e-06,  5.2934e-06],\n              ...,\n              [-1.9514e-06, -1.4102e-06, -1.0820e-06,  ...,  2.0380e-06,\n                3.0938e-06,  4.3434e-06],\n              [-1.7779e-06, -1.1932e-06, -5.7136e-07,  ...,  2.7983e-06,\n                3.9304e-06,  4.5410e-06],\n              [-2.5992e-06, -2.0652e-06, -9.7230e-07,  ...,  3.0904e-06,\n                4.1488e-06,  3.5216e-06]],\n    \n             [[-3.0569e-06, -3.6900e-06, -4.4546e-06,  ..., -1.6737e-06,\n               -1.3375e-07, -8.3583e-07],\n              [-3.8208e-06, -5.0292e-06, -4.8190e-06,  ..., -2.8611e-06,\n               -2.3241e-06, -1.8954e-06],\n              [-4.7396e-06, -6.0574e-06, -5.6777e-06,  ..., -4.2621e-06,\n               -3.6645e-06, -2.5228e-06],\n              ...,\n              [-7.3504e-06, -6.6524e-06, -6.8944e-06,  ..., -5.8006e-06,\n               -4.6075e-06, -3.1969e-06],\n              [-7.1485e-06, -6.3902e-06, -5.9695e-06,  ..., -4.3484e-06,\n               -3.1533e-06, -2.4505e-06],\n              [-7.9838e-06, -7.1075e-06, -6.0833e-06,  ..., -3.2990e-06,\n               -2.0846e-06, -2.7806e-06]]],\n    \n    \n            ...,\n    \n    \n            [[[ 5.8713e-06,  5.9648e-06,  5.4196e-06,  ...,  3.3141e-06,\n                3.1704e-06,  4.8898e-06],\n              [ 6.3463e-06,  5.3921e-06,  4.9736e-06,  ...,  4.0183e-06,\n                4.2392e-06,  5.7675e-06],\n              [ 6.7444e-06,  5.9738e-06,  7.4650e-06,  ...,  5.4867e-06,\n                5.1164e-06,  6.8682e-06],\n              ...,\n              [ 9.8524e-06,  7.6387e-06,  7.9771e-06,  ...,  9.7282e-06,\n                6.9481e-06,  6.0990e-06],\n              [ 8.6047e-06,  8.2979e-06,  8.8260e-06,  ...,  9.2939e-06,\n                6.1967e-06,  5.5469e-06],\n              [ 7.3139e-06,  7.2695e-06,  8.1991e-06,  ...,  8.7891e-06,\n                5.9894e-06,  6.6078e-06]],\n    \n             [[ 5.4276e-06,  5.0348e-06,  4.2548e-06,  ...,  3.1288e-06,\n                2.8557e-06,  4.7890e-06],\n              [ 5.9723e-06,  4.2124e-06,  3.4594e-06,  ...,  3.4620e-06,\n                3.3813e-06,  4.9553e-06],\n              [ 5.8401e-06,  4.3980e-06,  5.4731e-06,  ...,  4.6226e-06,\n                4.2885e-06,  5.9409e-06],\n              ...,\n              [ 8.9222e-06,  6.7772e-06,  6.5330e-06,  ...,  8.8297e-06,\n                6.0394e-06,  5.4716e-06],\n              [ 8.8166e-06,  8.3823e-06,  7.9501e-06,  ...,  8.9378e-06,\n                5.6479e-06,  5.1322e-06],\n              [ 7.5543e-06,  7.7527e-06,  7.8202e-06,  ...,  8.8018e-06,\n                5.5253e-06,  6.0101e-06]],\n    \n             [[ 6.0438e-06,  5.3149e-06,  4.7439e-06,  ...,  2.8822e-06,\n                2.6688e-06,  4.8237e-06],\n              [ 6.8755e-06,  4.9924e-06,  4.3664e-06,  ...,  2.9097e-06,\n                2.8738e-06,  4.8968e-06],\n              [ 6.1871e-06,  5.0094e-06,  5.3913e-06,  ...,  2.7176e-06,\n                3.0773e-06,  5.0522e-06],\n              ...,\n              [ 8.4447e-06,  6.6747e-06,  5.6261e-06,  ...,  6.4259e-06,\n                4.6638e-06,  4.7102e-06],\n              [ 9.1009e-06,  8.7515e-06,  7.8233e-06,  ...,  7.2592e-06,\n                4.8015e-06,  4.3850e-06],\n              [ 8.1668e-06,  8.7617e-06,  8.7020e-06,  ...,  7.9652e-06,\n                5.0489e-06,  4.9883e-06]]],\n    \n    \n            [[[-2.3148e-05, -1.9287e-05, -2.0229e-05,  ..., -2.0502e-05,\n               -2.4399e-05, -2.3547e-05],\n              [-2.0000e-05, -1.2508e-05, -1.3857e-05,  ..., -1.3790e-05,\n               -1.8652e-05, -1.9154e-05],\n              [-1.4905e-05, -6.7664e-06, -9.8883e-06,  ..., -1.1211e-05,\n               -1.3296e-05, -1.6075e-05],\n              ...,\n              [-2.0149e-05, -1.2159e-05, -1.2130e-05,  ..., -9.6661e-06,\n               -1.1607e-05, -1.7004e-05],\n              [-1.9949e-05, -1.4029e-05, -1.1955e-05,  ..., -1.1028e-05,\n               -1.4547e-05, -1.6731e-05],\n              [-1.7759e-05, -1.5312e-05, -1.1695e-05,  ..., -9.1078e-06,\n               -1.1858e-05, -1.4277e-05]],\n    \n             [[-2.0255e-05, -1.3776e-05, -1.3210e-05,  ..., -1.3841e-05,\n               -1.6818e-05, -1.5698e-05],\n              [-1.6413e-05, -6.8251e-06, -6.9841e-06,  ..., -9.2196e-06,\n               -1.4147e-05, -1.4112e-05],\n              [-1.0937e-05, -1.3665e-06, -4.2222e-06,  ..., -5.3750e-06,\n               -1.0116e-05, -1.3393e-05],\n              ...,\n              [-1.0107e-05, -9.7190e-07, -3.3659e-06,  ..., -6.0739e-07,\n               -4.3849e-06, -1.1577e-05],\n              [-8.6353e-06, -1.9855e-06, -8.9009e-07,  ..., -1.0864e-06,\n               -4.5111e-06, -6.9753e-06],\n              [-6.4087e-06, -3.0972e-06,  1.1059e-07,  ...,  5.4831e-07,\n               -1.4649e-06, -2.5135e-06]],\n    \n             [[-2.5177e-05, -1.6906e-05, -1.6040e-05,  ..., -1.5506e-05,\n               -1.6376e-05, -1.4765e-05],\n              [-2.2055e-05, -1.1112e-05, -1.0253e-05,  ..., -1.1548e-05,\n               -1.4981e-05, -1.2684e-05],\n              [-1.7609e-05, -6.1862e-06, -8.0776e-06,  ..., -7.2084e-06,\n               -1.0754e-05, -1.2163e-05],\n              ...,\n              [-1.6957e-05, -5.1326e-06, -7.9424e-06,  ..., -3.5374e-06,\n               -5.0498e-06, -1.0873e-05],\n              [-1.6176e-05, -6.1901e-06, -5.0405e-06,  ..., -4.1127e-06,\n               -5.2016e-06, -7.4437e-06],\n              [-1.3996e-05, -6.6049e-06, -2.6372e-06,  ..., -1.2727e-06,\n               -3.5357e-06, -4.7755e-06]]],\n    \n    \n            [[[ 9.3971e-08,  2.5183e-06,  2.8146e-06,  ...,  3.8626e-06,\n                2.9115e-06,  1.4809e-06],\n              [-1.6872e-06,  9.4974e-07,  2.5278e-06,  ...,  2.9891e-06,\n                2.4077e-06,  1.8930e-06],\n              [-2.1727e-06,  6.7182e-09,  1.6084e-07,  ...,  3.6345e-07,\n               -6.1414e-08,  8.4727e-07],\n              ...,\n              [-2.7616e-07,  5.5279e-08,  4.3731e-07,  ..., -1.4020e-06,\n               -6.4639e-07,  2.5936e-06],\n              [ 2.6651e-07, -2.4522e-07, -9.2747e-07,  ..., -2.1223e-06,\n               -5.9172e-07,  2.4131e-06],\n              [ 6.8511e-07, -8.2989e-07, -1.5485e-06,  ..., -2.4587e-06,\n               -9.0181e-07,  1.2132e-06]],\n    \n             [[-2.9950e-06, -1.1594e-06, -1.1907e-06,  ...,  9.3753e-07,\n               -4.3979e-07, -1.5652e-06],\n              [-3.7738e-06, -1.8140e-06, -3.7438e-07,  ...,  8.7178e-07,\n               -3.7582e-07, -3.1606e-07],\n              [-4.5101e-06, -3.0462e-06, -2.5962e-06,  ..., -1.2826e-06,\n               -2.2575e-06, -7.7034e-07],\n              ...,\n              [-2.3024e-06, -2.1362e-06, -1.3711e-06,  ..., -1.7815e-06,\n               -1.9859e-06,  1.0035e-06],\n              [-1.6559e-06, -1.8286e-06, -1.9980e-06,  ..., -1.8546e-06,\n               -1.5031e-06,  9.5894e-07],\n              [-1.7245e-06, -2.6511e-06, -2.4600e-06,  ..., -2.7234e-06,\n               -2.2120e-06, -3.4425e-07]],\n    \n             [[-6.6003e-06, -3.7665e-06, -2.7237e-06,  ..., -8.7126e-07,\n               -2.2112e-06, -3.8722e-06],\n              [-6.9748e-06, -4.1282e-06, -1.6703e-06,  ..., -8.3768e-07,\n               -2.3086e-06, -2.6184e-06],\n              [-7.2346e-06, -5.1844e-06, -4.1099e-06,  ..., -2.9905e-06,\n               -3.9251e-06, -2.5061e-06],\n              ...,\n              [-5.4076e-06, -4.1787e-06, -3.4957e-06,  ..., -3.4792e-06,\n               -4.1497e-06, -1.3417e-06],\n              [-4.7072e-06, -3.6734e-06, -3.8792e-06,  ..., -4.1155e-06,\n               -4.2367e-06, -2.0513e-06],\n              [-4.9694e-06, -4.3716e-06, -3.8712e-06,  ..., -4.9559e-06,\n               -4.7953e-06, -3.0575e-06]]]]),\n    'exp_avg_sq': tensor([[[[8.1149e-11, 8.0798e-11, 7.8211e-11,  ..., 8.6749e-11,\n               9.1657e-11, 9.5602e-11],\n              [8.1776e-11, 7.8457e-11, 7.2117e-11,  ..., 8.5949e-11,\n               9.4259e-11, 9.9527e-11],\n              [8.0075e-11, 7.4564e-11, 6.7569e-11,  ..., 8.3422e-11,\n               9.4034e-11, 1.0017e-10],\n              ...,\n              [8.4934e-11, 7.8175e-11, 6.8518e-11,  ..., 8.1634e-11,\n               9.3829e-11, 1.0125e-10],\n              [8.6945e-11, 8.0831e-11, 7.2279e-11,  ..., 8.3794e-11,\n               9.6280e-11, 1.0339e-10],\n              [8.9102e-11, 8.5883e-11, 7.9403e-11,  ..., 8.9451e-11,\n               1.0001e-10, 1.0687e-10]],\n    \n             [[9.1778e-11, 9.5224e-11, 9.4877e-11,  ..., 9.8304e-11,\n               9.7113e-11, 9.9893e-11],\n              [9.5547e-11, 9.8972e-11, 9.6569e-11,  ..., 1.0099e-10,\n               1.0026e-10, 1.0333e-10],\n              [9.4317e-11, 9.7127e-11, 9.5575e-11,  ..., 9.9648e-11,\n               9.8578e-11, 1.0193e-10],\n              ...,\n              [9.3158e-11, 9.3232e-11, 9.2246e-11,  ..., 9.5313e-11,\n               9.2441e-11, 9.5963e-11],\n              [9.1852e-11, 9.0206e-11, 9.0128e-11,  ..., 9.4765e-11,\n               9.4243e-11, 9.7240e-11],\n              [9.3691e-11, 9.2809e-11, 9.3175e-11,  ..., 9.8995e-11,\n               9.8996e-11, 1.0182e-10]],\n    \n             [[1.0204e-10, 1.0882e-10, 1.0960e-10,  ..., 1.0845e-10,\n               1.0223e-10, 1.0327e-10],\n              [1.0820e-10, 1.1692e-10, 1.1764e-10,  ..., 1.1418e-10,\n               1.0665e-10, 1.0804e-10],\n              [1.0746e-10, 1.1709e-10, 1.2015e-10,  ..., 1.1347e-10,\n               1.0414e-10, 1.0602e-10],\n              ...,\n              [1.0098e-10, 1.0741e-10, 1.1363e-10,  ..., 1.0754e-10,\n               9.4106e-11, 9.4649e-11],\n              [9.7145e-11, 1.0003e-10, 1.0609e-10,  ..., 1.0466e-10,\n               9.4769e-11, 9.4467e-11],\n              [9.7739e-11, 1.0059e-10, 1.0515e-10,  ..., 1.0731e-10,\n               9.9517e-11, 9.9154e-11]]],\n    \n    \n            [[[3.3267e-10, 3.5042e-10, 3.4331e-10,  ..., 3.4360e-10,\n               3.3239e-10, 3.3628e-10],\n              [3.5022e-10, 3.6795e-10, 3.6109e-10,  ..., 3.5861e-10,\n               3.4770e-10, 3.5323e-10],\n              [3.4826e-10, 3.6604e-10, 3.5955e-10,  ..., 3.5626e-10,\n               3.4437e-10, 3.4906e-10],\n              ...,\n              [3.4164e-10, 3.5545e-10, 3.5904e-10,  ..., 3.6389e-10,\n               3.5191e-10, 3.5573e-10],\n              [3.2449e-10, 3.3249e-10, 3.3761e-10,  ..., 3.5139e-10,\n               3.4081e-10, 3.4548e-10],\n              [3.2676e-10, 3.3344e-10, 3.3907e-10,  ..., 3.5693e-10,\n               3.4642e-10, 3.5026e-10]],\n    \n             [[2.9253e-10, 3.0541e-10, 2.9548e-10,  ..., 2.9615e-10,\n               2.8926e-10, 2.9430e-10],\n              [3.0391e-10, 3.1712e-10, 3.0784e-10,  ..., 3.0402e-10,\n               2.9796e-10, 3.0380e-10],\n              [3.0092e-10, 3.1552e-10, 3.0752e-10,  ..., 3.0159e-10,\n               2.9413e-10, 2.9943e-10],\n              ...,\n              [2.8884e-10, 3.0131e-10, 3.0493e-10,  ..., 3.0832e-10,\n               3.0081e-10, 3.0399e-10],\n              [2.7264e-10, 2.8035e-10, 2.8706e-10,  ..., 3.0101e-10,\n               2.9554e-10, 2.9920e-10],\n              [2.7613e-10, 2.8196e-10, 2.8853e-10,  ..., 3.0724e-10,\n               3.0253e-10, 3.0683e-10]],\n    \n             [[3.2835e-10, 3.4999e-10, 3.3995e-10,  ..., 3.4416e-10,\n               3.3789e-10, 3.4336e-10],\n              [3.3949e-10, 3.6059e-10, 3.5201e-10,  ..., 3.5111e-10,\n               3.4668e-10, 3.5292e-10],\n              [3.3586e-10, 3.5894e-10, 3.5206e-10,  ..., 3.5032e-10,\n               3.4374e-10, 3.4973e-10],\n              ...,\n              [3.2166e-10, 3.4304e-10, 3.4635e-10,  ..., 3.5835e-10,\n               3.5024e-10, 3.5327e-10],\n              [2.9833e-10, 3.1431e-10, 3.2091e-10,  ..., 3.4231e-10,\n               3.3636e-10, 3.3819e-10],\n              [2.9850e-10, 3.1366e-10, 3.2081e-10,  ..., 3.4527e-10,\n               3.4100e-10, 3.4485e-10]]],\n    \n    \n            [[[1.0102e-09, 1.0906e-09, 1.0839e-09,  ..., 1.0745e-09,\n               1.0116e-09, 1.0032e-09],\n              [1.0458e-09, 1.1158e-09, 1.1029e-09,  ..., 1.0877e-09,\n               1.0197e-09, 1.0170e-09],\n              [1.0208e-09, 1.0817e-09, 1.0638e-09,  ..., 1.0396e-09,\n               9.8265e-10, 9.9038e-10],\n              ...,\n              [9.3356e-10, 9.8764e-10, 9.5550e-10,  ..., 9.1983e-10,\n               8.9272e-10, 9.2495e-10],\n              [8.9169e-10, 9.4338e-10, 9.1595e-10,  ..., 8.9126e-10,\n               8.6822e-10, 8.9494e-10],\n              [8.8841e-10, 9.4672e-10, 9.2736e-10,  ..., 9.0788e-10,\n               8.7747e-10, 9.0270e-10]],\n    \n             [[7.8349e-10, 8.3152e-10, 8.2606e-10,  ..., 8.1246e-10,\n               7.6796e-10, 7.5739e-10],\n              [8.0254e-10, 8.3555e-10, 8.2137e-10,  ..., 8.0558e-10,\n               7.5795e-10, 7.5154e-10],\n              [7.8576e-10, 8.1065e-10, 7.9048e-10,  ..., 7.6540e-10,\n               7.2583e-10, 7.2898e-10],\n              ...,\n              [7.1408e-10, 7.3005e-10, 6.9473e-10,  ..., 6.5856e-10,\n               6.4947e-10, 6.7171e-10],\n              [6.8960e-10, 7.0290e-10, 6.7186e-10,  ..., 6.4464e-10,\n               6.4041e-10, 6.6014e-10],\n              [6.8977e-10, 7.0854e-10, 6.8398e-10,  ..., 6.6269e-10,\n               6.5325e-10, 6.7528e-10]],\n    \n             [[8.1183e-10, 8.4673e-10, 8.3993e-10,  ..., 8.5446e-10,\n               8.2495e-10, 8.1313e-10],\n              [8.3286e-10, 8.5479e-10, 8.4023e-10,  ..., 8.5107e-10,\n               8.1526e-10, 8.1021e-10],\n              [8.2004e-10, 8.3526e-10, 8.1511e-10,  ..., 8.1159e-10,\n               7.8260e-10, 7.8477e-10],\n              ...,\n              [7.5745e-10, 7.5878e-10, 7.2735e-10,  ..., 7.1728e-10,\n               7.1621e-10, 7.2836e-10],\n              [7.4472e-10, 7.4654e-10, 7.2006e-10,  ..., 7.1729e-10,\n               7.1606e-10, 7.2222e-10],\n              [7.4542e-10, 7.5627e-10, 7.3649e-10,  ..., 7.3249e-10,\n               7.2649e-10, 7.3610e-10]]],\n    \n    \n            ...,\n    \n    \n            [[[1.6647e-09, 1.7466e-09, 1.7331e-09,  ..., 1.7470e-09,\n               1.6257e-09, 1.6184e-09],\n              [1.7035e-09, 1.7636e-09, 1.7231e-09,  ..., 1.7300e-09,\n               1.6307e-09, 1.6441e-09],\n              [1.7016e-09, 1.7589e-09, 1.7341e-09,  ..., 1.7675e-09,\n               1.6796e-09, 1.6748e-09],\n              ...,\n              [1.7279e-09, 1.8258e-09, 1.8389e-09,  ..., 1.8161e-09,\n               1.6931e-09, 1.6693e-09],\n              [1.6789e-09, 1.7505e-09, 1.7452e-09,  ..., 1.7339e-09,\n               1.6405e-09, 1.6432e-09],\n              [1.6496e-09, 1.7164e-09, 1.7098e-09,  ..., 1.7210e-09,\n               1.6400e-09, 1.6480e-09]],\n    \n             [[1.3775e-09, 1.4239e-09, 1.4028e-09,  ..., 1.4133e-09,\n               1.2914e-09, 1.2658e-09],\n              [1.3978e-09, 1.4176e-09, 1.3663e-09,  ..., 1.3581e-09,\n               1.2534e-09, 1.2521e-09],\n              [1.3830e-09, 1.3933e-09, 1.3503e-09,  ..., 1.3694e-09,\n               1.2782e-09, 1.2643e-09],\n              ...,\n              [1.3784e-09, 1.4189e-09, 1.4120e-09,  ..., 1.3873e-09,\n               1.2668e-09, 1.2405e-09],\n              [1.3206e-09, 1.3322e-09, 1.3066e-09,  ..., 1.3005e-09,\n               1.2096e-09, 1.2115e-09],\n              [1.3002e-09, 1.3110e-09, 1.2925e-09,  ..., 1.3026e-09,\n               1.2132e-09, 1.2191e-09]],\n    \n             [[1.4291e-09, 1.5069e-09, 1.5087e-09,  ..., 1.5514e-09,\n               1.4032e-09, 1.3660e-09],\n              [1.4660e-09, 1.5286e-09, 1.4999e-09,  ..., 1.5250e-09,\n               1.3868e-09, 1.3697e-09],\n              [1.4451e-09, 1.4981e-09, 1.4708e-09,  ..., 1.5212e-09,\n               1.3988e-09, 1.3780e-09],\n              ...,\n              [1.4169e-09, 1.4816e-09, 1.4879e-09,  ..., 1.5128e-09,\n               1.3707e-09, 1.3396e-09],\n              [1.3445e-09, 1.3866e-09, 1.3788e-09,  ..., 1.4149e-09,\n               1.3072e-09, 1.3049e-09],\n              [1.3275e-09, 1.3771e-09, 1.3732e-09,  ..., 1.4158e-09,\n               1.3066e-09, 1.3135e-09]]],\n    \n    \n            [[[8.9974e-09, 9.0670e-09, 8.9358e-09,  ..., 9.3082e-09,\n               9.1228e-09, 9.2286e-09],\n              [9.2276e-09, 9.2369e-09, 8.8996e-09,  ..., 9.0173e-09,\n               9.0883e-09, 9.2672e-09],\n              [9.2365e-09, 9.2731e-09, 8.7740e-09,  ..., 8.1136e-09,\n               8.4515e-09, 8.9246e-09],\n              ...,\n              [9.2786e-09, 9.3762e-09, 9.0450e-09,  ..., 8.0581e-09,\n               8.0349e-09, 8.7054e-09],\n              [8.7526e-09, 8.8753e-09, 8.6198e-09,  ..., 8.2395e-09,\n               8.0120e-09, 8.3650e-09],\n              [8.7778e-09, 8.9600e-09, 8.7943e-09,  ..., 8.6281e-09,\n               8.3656e-09, 8.5523e-09]],\n    \n             [[7.4933e-09, 7.4594e-09, 7.2610e-09,  ..., 7.4139e-09,\n               7.2323e-09, 7.3563e-09],\n              [7.5103e-09, 7.4568e-09, 7.0827e-09,  ..., 7.0974e-09,\n               7.0907e-09, 7.2957e-09],\n              [7.4639e-09, 7.4014e-09, 6.9495e-09,  ..., 6.6201e-09,\n               6.7141e-09, 7.0568e-09],\n              ...,\n              [7.5259e-09, 7.5059e-09, 7.1801e-09,  ..., 6.6417e-09,\n               6.5460e-09, 6.9360e-09],\n              [7.2493e-09, 7.2866e-09, 7.0002e-09,  ..., 6.6341e-09,\n               6.4580e-09, 6.7069e-09],\n              [7.3014e-09, 7.4165e-09, 7.1966e-09,  ..., 6.9297e-09,\n               6.7668e-09, 6.9228e-09]],\n    \n             [[9.1955e-09, 9.3998e-09, 9.2328e-09,  ..., 9.4031e-09,\n               9.1571e-09, 9.2367e-09],\n              [9.3755e-09, 9.6256e-09, 9.3208e-09,  ..., 9.5207e-09,\n               9.3583e-09, 9.4554e-09],\n              [9.2519e-09, 9.4837e-09, 9.1764e-09,  ..., 9.3783e-09,\n               9.1796e-09, 9.2846e-09],\n              ...,\n              [9.2537e-09, 9.5005e-09, 9.2745e-09,  ..., 9.4244e-09,\n               9.2140e-09, 9.2810e-09],\n              [8.9615e-09, 9.2856e-09, 9.0417e-09,  ..., 9.0400e-09,\n               8.8463e-09, 8.9256e-09],\n              [9.0078e-09, 9.4315e-09, 9.2192e-09,  ..., 9.1809e-09,\n               9.0241e-09, 9.0767e-09]]],\n    \n    \n            [[[2.0393e-09, 2.2117e-09, 2.2429e-09,  ..., 2.3562e-09,\n               2.2420e-09, 2.2313e-09],\n              [2.1108e-09, 2.2754e-09, 2.3036e-09,  ..., 2.4153e-09,\n               2.2885e-09, 2.2753e-09],\n              [2.1065e-09, 2.2651e-09, 2.2724e-09,  ..., 2.3803e-09,\n               2.2683e-09, 2.2635e-09],\n              ...,\n              [2.0791e-09, 2.2004e-09, 2.1604e-09,  ..., 2.2413e-09,\n               2.1845e-09, 2.2206e-09],\n              [2.0036e-09, 2.1196e-09, 2.0877e-09,  ..., 2.1943e-09,\n               2.1172e-09, 2.1548e-09],\n              [2.0079e-09, 2.1249e-09, 2.1089e-09,  ..., 2.2123e-09,\n               2.1252e-09, 2.1493e-09]],\n    \n             [[1.6974e-09, 1.8233e-09, 1.8402e-09,  ..., 1.9189e-09,\n               1.8417e-09, 1.8366e-09],\n              [1.7224e-09, 1.8401e-09, 1.8616e-09,  ..., 1.9344e-09,\n               1.8501e-09, 1.8432e-09],\n              [1.7037e-09, 1.8230e-09, 1.8384e-09,  ..., 1.9069e-09,\n               1.8314e-09, 1.8302e-09],\n              ...,\n              [1.6771e-09, 1.7667e-09, 1.7412e-09,  ..., 1.7723e-09,\n               1.7396e-09, 1.7778e-09],\n              [1.6299e-09, 1.7199e-09, 1.6942e-09,  ..., 1.7425e-09,\n               1.6918e-09, 1.7289e-09],\n              [1.6373e-09, 1.7357e-09, 1.7188e-09,  ..., 1.7690e-09,\n               1.7124e-09, 1.7361e-09]],\n    \n             [[1.8124e-09, 1.9694e-09, 1.9762e-09,  ..., 2.0439e-09,\n               1.9659e-09, 1.9597e-09],\n              [1.8889e-09, 2.0513e-09, 2.0548e-09,  ..., 2.1029e-09,\n               2.0174e-09, 2.0157e-09],\n              [1.8705e-09, 2.0364e-09, 2.0358e-09,  ..., 2.0783e-09,\n               1.9957e-09, 2.0027e-09],\n              ...,\n              [1.8482e-09, 1.9971e-09, 1.9677e-09,  ..., 1.9735e-09,\n               1.9129e-09, 1.9446e-09],\n              [1.7901e-09, 1.9342e-09, 1.9016e-09,  ..., 1.9222e-09,\n               1.8553e-09, 1.8853e-09],\n              [1.7906e-09, 1.9458e-09, 1.9205e-09,  ..., 1.9459e-09,\n               1.8776e-09, 1.8944e-09]]]])},\n   108: {'exp_avg': tensor([[[[-1.1170e-07]],\n    \n             [[-2.5744e-07]],\n    \n             [[-1.7128e-07]],\n    \n             ...,\n    \n             [[-4.4482e-07]],\n    \n             [[-2.0949e-07]],\n    \n             [[-3.1378e-07]]],\n    \n    \n            [[[ 1.7391e-07]],\n    \n             [[ 2.5406e-07]],\n    \n             [[ 5.5180e-07]],\n    \n             ...,\n    \n             [[ 3.0293e-07]],\n    \n             [[ 6.0440e-07]],\n    \n             [[ 3.3774e-07]]],\n    \n    \n            [[[ 1.3608e-08]],\n    \n             [[-2.9221e-08]],\n    \n             [[ 6.7227e-08]],\n    \n             ...,\n    \n             [[ 8.8139e-08]],\n    \n             [[-2.5178e-07]],\n    \n             [[-3.8815e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-1.4735e-07]],\n    \n             [[-1.5183e-07]],\n    \n             [[-2.9896e-07]],\n    \n             ...,\n    \n             [[ 6.2088e-08]],\n    \n             [[-2.8390e-07]],\n    \n             [[-1.4772e-07]]],\n    \n    \n            [[[-3.0356e-07]],\n    \n             [[ 8.6623e-08]],\n    \n             [[ 3.6813e-07]],\n    \n             ...,\n    \n             [[ 3.3487e-07]],\n    \n             [[ 6.9644e-08]],\n    \n             [[ 2.1146e-07]]],\n    \n    \n            [[[ 1.3207e-07]],\n    \n             [[ 1.2577e-07]],\n    \n             [[-3.7237e-07]],\n    \n             ...,\n    \n             [[-3.3270e-07]],\n    \n             [[-1.2159e-07]],\n    \n             [[ 1.9710e-07]]]]),\n    'exp_avg_sq': tensor([[[[1.7234e-12]],\n    \n             [[1.6631e-12]],\n    \n             [[2.7412e-12]],\n    \n             ...,\n    \n             [[1.7603e-12]],\n    \n             [[1.8893e-12]],\n    \n             [[2.5500e-12]]],\n    \n    \n            [[[1.1974e-12]],\n    \n             [[1.1019e-12]],\n    \n             [[1.9895e-12]],\n    \n             ...,\n    \n             [[1.6193e-12]],\n    \n             [[1.2893e-12]],\n    \n             [[2.2257e-12]]],\n    \n    \n            [[[7.8840e-13]],\n    \n             [[6.3917e-13]],\n    \n             [[1.1761e-12]],\n    \n             ...,\n    \n             [[7.1686e-13]],\n    \n             [[1.2329e-12]],\n    \n             [[9.7636e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[1.3506e-12]],\n    \n             [[8.9147e-13]],\n    \n             [[1.5387e-12]],\n    \n             ...,\n    \n             [[8.2899e-13]],\n    \n             [[1.4771e-12]],\n    \n             [[1.2191e-12]]],\n    \n    \n            [[[9.1795e-13]],\n    \n             [[1.1204e-12]],\n    \n             [[1.6649e-12]],\n    \n             ...,\n    \n             [[7.4157e-13]],\n    \n             [[1.2691e-12]],\n    \n             [[5.1944e-13]]],\n    \n    \n            [[[5.8447e-13]],\n    \n             [[9.4952e-13]],\n    \n             [[1.0934e-12]],\n    \n             ...,\n    \n             [[8.8460e-13]],\n    \n             [[9.7903e-13]],\n    \n             [[1.3186e-12]]]])},\n   109: {'exp_avg': tensor([[[[-5.4054e-08, -2.3388e-07,  4.8330e-08],\n              [-8.8031e-08, -1.7438e-07,  7.1641e-08],\n              [-8.9798e-08, -2.1445e-07,  1.3576e-07]],\n    \n             [[ 3.3188e-07,  2.3338e-07,  1.9777e-07],\n              [ 3.3671e-07,  2.7617e-07,  2.2753e-07],\n              [ 3.4892e-07,  3.1728e-07,  3.0435e-07]],\n    \n             [[-3.6181e-08, -1.0279e-07, -9.8868e-08],\n              [-3.6238e-08, -1.2774e-07, -1.6617e-07],\n              [-1.8811e-07, -1.8076e-07, -2.5821e-07]],\n    \n             ...,\n    \n             [[ 1.2320e-07,  7.7767e-08,  2.3919e-07],\n              [ 1.1099e-07,  6.5240e-08,  1.9632e-07],\n              [ 2.6464e-08,  1.4188e-07,  2.5072e-07]],\n    \n             [[ 3.2778e-07,  2.8366e-07,  3.1432e-07],\n              [ 3.3088e-07,  2.3082e-07,  2.9709e-07],\n              [ 1.1761e-07,  3.4011e-08,  8.9408e-08]],\n    \n             [[ 9.0488e-08,  9.9607e-08,  1.1406e-07],\n              [ 6.8453e-08,  1.0150e-07,  1.4957e-07],\n              [ 1.7153e-07,  1.2017e-07,  1.3808e-07]]],\n    \n    \n            [[[ 3.4714e-07,  1.7432e-07,  1.9012e-07],\n              [ 1.7953e-07,  6.3225e-08, -5.5506e-09],\n              [ 3.6119e-07,  1.7129e-07,  1.1707e-07]],\n    \n             [[ 7.6164e-08,  1.3052e-07,  1.5288e-07],\n              [-1.1859e-07, -6.0208e-08, -8.9313e-08],\n              [-2.7451e-08,  2.3812e-08,  7.0303e-08]],\n    \n             [[ 1.2855e-07,  7.4714e-08,  5.9197e-08],\n              [ 1.2535e-07,  1.2829e-07,  1.3999e-07],\n              [ 3.2631e-07,  3.1129e-07,  3.2257e-07]],\n    \n             ...,\n    \n             [[-1.6343e-07, -2.6339e-07, -1.5669e-07],\n              [-2.5442e-07, -2.2186e-07, -7.5618e-08],\n              [-1.1321e-07, -8.1926e-08,  5.0454e-08]],\n    \n             [[ 4.6719e-07,  3.8832e-07,  2.5291e-07],\n              [ 2.1691e-07,  3.0010e-07,  2.6640e-07],\n              [ 3.6822e-07,  4.9783e-07,  3.9913e-07]],\n    \n             [[ 1.2864e-07,  1.0827e-07, -3.4536e-08],\n              [ 1.1659e-07, -4.1005e-08, -1.3195e-07],\n              [ 1.0119e-07,  1.1819e-08, -1.1994e-07]]],\n    \n    \n            [[[ 2.0527e-08,  8.7734e-08,  1.4797e-08],\n              [ 2.1535e-08,  1.9597e-07,  1.8782e-08],\n              [-1.4881e-08,  1.7020e-07, -7.9834e-09]],\n    \n             [[ 2.4793e-07,  8.7354e-08,  1.5018e-07],\n              [ 2.6220e-07,  1.7490e-07,  2.4751e-07],\n              [ 2.4704e-07,  3.3151e-08,  3.3592e-08]],\n    \n             [[ 1.6255e-07,  1.0202e-07,  8.2561e-08],\n              [ 1.1984e-07,  7.2448e-08,  8.1235e-08],\n              [ 1.2376e-07, -4.5325e-09,  6.2816e-08]],\n    \n             ...,\n    \n             [[ 6.5892e-08,  1.5095e-07,  1.6608e-08],\n              [ 1.1079e-07, -7.0291e-10, -3.5549e-08],\n              [-2.6922e-08, -3.4671e-08, -1.2738e-07]],\n    \n             [[-1.5600e-08, -3.1989e-08,  8.4480e-08],\n              [-6.1098e-08, -7.9856e-08, -1.5206e-08],\n              [-2.4792e-08, -1.3014e-07, -7.8111e-08]],\n    \n             [[ 1.1877e-07,  1.3755e-07,  1.4512e-07],\n              [ 4.5120e-08,  7.8073e-08,  4.3558e-08],\n              [ 2.9334e-08,  4.3980e-09,  2.0135e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 4.7279e-08,  2.4063e-07,  9.6736e-08],\n              [-3.7129e-08,  3.6505e-07,  2.9961e-07],\n              [ 5.7201e-08,  4.5744e-07,  3.0982e-07]],\n    \n             [[ 8.2021e-08,  2.0756e-07,  1.5365e-07],\n              [ 6.9841e-08,  2.0809e-07,  5.8042e-08],\n              [ 9.8083e-08,  1.7281e-07,  6.0950e-08]],\n    \n             [[-1.7129e-07, -2.4883e-07, -2.0821e-07],\n              [-1.0370e-07, -1.9792e-07, -2.0248e-07],\n              [-1.5511e-07, -2.3848e-07, -1.8582e-07]],\n    \n             ...,\n    \n             [[-7.5586e-08, -3.4484e-08, -4.1424e-08],\n              [ 1.5373e-07,  1.6799e-07,  8.4983e-08],\n              [ 2.4223e-07,  2.8438e-07,  1.0811e-07]],\n    \n             [[-2.0731e-07,  3.0828e-08, -9.2116e-09],\n              [-2.4001e-07,  6.4382e-08,  2.4975e-08],\n              [ 1.2606e-08,  1.6648e-07,  1.1903e-07]],\n    \n             [[ 1.5301e-07,  1.6149e-07,  1.4505e-07],\n              [ 1.5375e-07,  2.3464e-07,  1.2261e-07],\n              [-2.0614e-08,  1.1091e-07,  8.5576e-08]]],\n    \n    \n            [[[ 6.2073e-08,  1.5641e-08,  6.8125e-08],\n              [ 9.2092e-08, -1.2468e-08,  7.0326e-08],\n              [ 2.6154e-08, -9.7877e-08,  4.9419e-08]],\n    \n             [[ 3.4954e-08, -1.2884e-07,  6.2174e-08],\n              [-3.6169e-08,  3.4158e-08,  4.7118e-09],\n              [ 9.7982e-08,  1.5130e-07,  8.4032e-08]],\n    \n             [[-1.5374e-08, -1.1632e-08,  4.1206e-08],\n              [ 1.2947e-08,  1.2424e-08,  1.5820e-07],\n              [ 5.4834e-08,  6.2442e-08,  1.4655e-07]],\n    \n             ...,\n    \n             [[ 1.0818e-07,  1.6910e-07,  4.1822e-08],\n              [-6.4327e-08,  6.2051e-08,  5.3709e-08],\n              [ 2.5671e-08,  8.0024e-08,  1.8983e-07]],\n    \n             [[-5.5643e-08, -2.2712e-07, -1.8551e-07],\n              [-1.1305e-07, -1.2159e-07, -1.9768e-07],\n              [-1.6904e-07, -1.8875e-07, -1.8835e-07]],\n    \n             [[ 5.0876e-08, -3.2080e-10,  1.8316e-08],\n              [ 6.4440e-08, -7.1447e-08, -6.1006e-08],\n              [ 3.3005e-08, -9.2743e-08, -5.0559e-08]]],\n    \n    \n            [[[ 2.6128e-07, -1.3699e-07, -1.5334e-07],\n              [ 1.3505e-07, -2.4103e-07, -1.2190e-07],\n              [ 1.2538e-07, -3.2025e-07, -4.0209e-08]],\n    \n             [[-1.1193e-07,  6.2012e-08, -4.1630e-08],\n              [-5.2429e-08,  1.1885e-08,  3.8681e-09],\n              [ 5.5661e-08,  1.4289e-07,  9.6183e-09]],\n    \n             [[ 1.6563e-07,  2.9648e-07,  1.3361e-07],\n              [ 2.4057e-07,  3.3157e-07,  7.4236e-08],\n              [ 2.8212e-07,  4.7567e-07,  1.0714e-07]],\n    \n             ...,\n    \n             [[-1.7077e-07, -1.3253e-07,  1.7498e-08],\n              [-7.0271e-08, -7.1202e-08,  2.9980e-08],\n              [-2.4975e-08,  7.4709e-08, -3.4805e-08]],\n    \n             [[-2.3355e-08, -1.1016e-07, -4.4229e-08],\n              [-8.5735e-08, -1.2063e-07, -1.4256e-07],\n              [-2.0114e-08, -1.5099e-07, -1.5806e-07]],\n    \n             [[ 6.4239e-08, -8.8384e-08,  3.8358e-08],\n              [ 1.4487e-07,  2.5771e-08,  1.1995e-07],\n              [ 2.1664e-08, -1.9428e-07, -9.5020e-08]]]]),\n    'exp_avg_sq': tensor([[[[2.5069e-13, 2.2909e-13, 2.5265e-13],\n              [2.8578e-13, 2.5709e-13, 2.8290e-13],\n              [2.3675e-13, 2.3659e-13, 3.0758e-13]],\n    \n             [[2.2094e-13, 2.3730e-13, 1.7728e-13],\n              [2.6303e-13, 2.6783e-13, 2.1997e-13],\n              [2.4223e-13, 2.4385e-13, 2.3296e-13]],\n    \n             [[4.4626e-13, 4.7873e-13, 4.3935e-13],\n              [4.3962e-13, 5.0777e-13, 4.8362e-13],\n              [4.0562e-13, 4.6880e-13, 4.5982e-13]],\n    \n             ...,\n    \n             [[5.4659e-13, 5.3261e-13, 5.0903e-13],\n              [5.4205e-13, 5.1529e-13, 5.0366e-13],\n              [5.7256e-13, 5.5837e-13, 5.3265e-13]],\n    \n             [[5.0291e-13, 5.3647e-13, 4.3004e-13],\n              [5.2502e-13, 5.8318e-13, 5.1224e-13],\n              [5.4954e-13, 5.7119e-13, 5.0648e-13]],\n    \n             [[2.7271e-13, 2.7980e-13, 2.7173e-13],\n              [2.9640e-13, 3.0540e-13, 2.8145e-13],\n              [3.0848e-13, 3.2357e-13, 3.1349e-13]]],\n    \n    \n            [[[8.4374e-13, 7.3593e-13, 4.2534e-13],\n              [6.3039e-13, 5.9667e-13, 4.7741e-13],\n              [5.4382e-13, 5.0285e-13, 4.6030e-13]],\n    \n             [[7.4286e-13, 7.5828e-13, 6.1886e-13],\n              [6.3106e-13, 5.6187e-13, 6.8192e-13],\n              [6.9444e-13, 5.8925e-13, 7.5131e-13]],\n    \n             [[1.4828e-12, 1.5946e-12, 1.4588e-12],\n              [1.3374e-12, 1.4618e-12, 1.3330e-12],\n              [1.2322e-12, 1.3568e-12, 1.2336e-12]],\n    \n             ...,\n    \n             [[1.2814e-12, 1.3806e-12, 1.3309e-12],\n              [1.2048e-12, 1.2193e-12, 1.2519e-12],\n              [1.1938e-12, 1.2809e-12, 1.3070e-12]],\n    \n             [[1.9933e-12, 2.1183e-12, 1.8106e-12],\n              [1.8284e-12, 1.7216e-12, 2.2334e-12],\n              [2.3520e-12, 2.3342e-12, 2.7048e-12]],\n    \n             [[1.1662e-12, 1.2131e-12, 8.8913e-13],\n              [1.0580e-12, 1.0427e-12, 7.9921e-13],\n              [9.0466e-13, 9.2369e-13, 9.3905e-13]]],\n    \n    \n            [[[3.5109e-13, 2.9488e-13, 2.9780e-13],\n              [3.2991e-13, 2.8456e-13, 2.9988e-13],\n              [3.0538e-13, 2.9223e-13, 3.0776e-13]],\n    \n             [[2.2522e-13, 1.9549e-13, 1.5533e-13],\n              [2.1775e-13, 2.0149e-13, 1.5493e-13],\n              [2.0593e-13, 1.9618e-13, 1.5991e-13]],\n    \n             [[4.9062e-13, 5.6156e-13, 5.2690e-13],\n              [5.1260e-13, 6.0278e-13, 5.6310e-13],\n              [4.9658e-13, 5.8270e-13, 5.4583e-13]],\n    \n             ...,\n    \n             [[5.5108e-13, 5.3840e-13, 5.3546e-13],\n              [5.5526e-13, 5.4738e-13, 5.4706e-13],\n              [5.6753e-13, 5.7476e-13, 5.6462e-13]],\n    \n             [[2.4649e-13, 2.6016e-13, 2.6646e-13],\n              [2.4005e-13, 2.5731e-13, 2.5764e-13],\n              [2.2613e-13, 2.4000e-13, 2.4774e-13]],\n    \n             [[2.6529e-13, 2.1768e-13, 2.3837e-13],\n              [2.2691e-13, 1.8347e-13, 1.8602e-13],\n              [2.3635e-13, 2.3358e-13, 2.2969e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[1.0282e-12, 8.9382e-13, 3.5310e-13],\n              [9.3494e-13, 9.7113e-13, 5.7634e-13],\n              [6.7675e-13, 8.4151e-13, 7.6253e-13]],\n    \n             [[7.4211e-13, 1.0033e-12, 6.1262e-13],\n              [9.7657e-13, 1.3262e-12, 7.5626e-13],\n              [5.9703e-13, 8.7641e-13, 6.0542e-13]],\n    \n             [[8.3714e-13, 9.3358e-13, 9.4571e-13],\n              [8.9666e-13, 9.0755e-13, 8.8985e-13],\n              [9.1966e-13, 8.9730e-13, 8.3602e-13]],\n    \n             ...,\n    \n             [[8.2096e-13, 8.2156e-13, 8.6745e-13],\n              [7.5968e-13, 7.7093e-13, 8.5926e-13],\n              [8.5579e-13, 8.8764e-13, 8.2351e-13]],\n    \n             [[1.9209e-12, 2.6917e-12, 1.7313e-12],\n              [2.0999e-12, 2.6303e-12, 1.6889e-12],\n              [1.4839e-12, 1.8200e-12, 1.3528e-12]],\n    \n             [[6.5913e-13, 7.3986e-13, 6.2195e-13],\n              [7.6653e-13, 8.5596e-13, 7.3502e-13],\n              [6.4572e-13, 7.4663e-13, 7.2725e-13]]],\n    \n    \n            [[[3.0755e-13, 3.4974e-13, 2.8777e-13],\n              [3.4980e-13, 4.0066e-13, 2.8920e-13],\n              [3.4112e-13, 3.5595e-13, 2.8100e-13]],\n    \n             [[2.3645e-13, 2.6020e-13, 2.0474e-13],\n              [2.7713e-13, 3.1979e-13, 2.2883e-13],\n              [2.3730e-13, 3.1217e-13, 2.3446e-13]],\n    \n             [[2.0301e-13, 2.3781e-13, 2.3466e-13],\n              [2.3955e-13, 2.8892e-13, 2.5668e-13],\n              [2.4131e-13, 2.8910e-13, 2.7545e-13]],\n    \n             ...,\n    \n             [[3.4883e-13, 3.7674e-13, 3.6246e-13],\n              [3.6177e-13, 3.8798e-13, 4.0086e-13],\n              [3.2945e-13, 3.5414e-13, 3.7216e-13]],\n    \n             [[2.6041e-13, 3.8728e-13, 3.0379e-13],\n              [4.2464e-13, 6.4115e-13, 4.2547e-13],\n              [3.7163e-13, 5.1999e-13, 3.7803e-13]],\n    \n             [[3.8461e-13, 4.1100e-13, 3.5278e-13],\n              [3.1945e-13, 3.4821e-13, 3.0319e-13],\n              [3.2187e-13, 3.4826e-13, 2.8253e-13]]],\n    \n    \n            [[[4.1643e-13, 3.2822e-13, 2.9530e-13],\n              [3.8105e-13, 3.4489e-13, 3.7454e-13],\n              [3.3246e-13, 3.5279e-13, 4.0919e-13]],\n    \n             [[3.4934e-13, 3.6277e-13, 3.2067e-13],\n              [3.6360e-13, 3.9641e-13, 3.4540e-13],\n              [3.4165e-13, 3.9583e-13, 3.5182e-13]],\n    \n             [[4.6890e-13, 5.0884e-13, 4.4245e-13],\n              [5.2810e-13, 6.1856e-13, 4.9449e-13],\n              [5.0366e-13, 6.1483e-13, 4.7652e-13]],\n    \n             ...,\n    \n             [[5.0048e-13, 5.0821e-13, 5.0685e-13],\n              [5.5868e-13, 5.9219e-13, 5.6074e-13],\n              [5.8607e-13, 6.4244e-13, 5.8266e-13]],\n    \n             [[6.1332e-13, 6.6115e-13, 6.3665e-13],\n              [6.9328e-13, 7.8935e-13, 7.3048e-13],\n              [6.5684e-13, 7.3426e-13, 6.6330e-13]],\n    \n             [[6.2723e-13, 6.4881e-13, 5.9962e-13],\n              [5.1452e-13, 5.3795e-13, 5.0082e-13],\n              [4.8479e-13, 4.7377e-13, 4.6296e-13]]]])},\n   110: {'exp_avg': tensor([[[[ 1.2798e-07]],\n    \n             [[-2.1787e-07]],\n    \n             [[ 2.2247e-08]],\n    \n             ...,\n    \n             [[-4.1346e-08]],\n    \n             [[ 8.9963e-08]],\n    \n             [[-1.2915e-07]]],\n    \n    \n            [[[ 1.4347e-07]],\n    \n             [[-2.2338e-07]],\n    \n             [[ 1.8496e-07]],\n    \n             ...,\n    \n             [[-1.2286e-07]],\n    \n             [[ 1.4283e-07]],\n    \n             [[-1.1200e-07]]],\n    \n    \n            [[[ 2.3438e-08]],\n    \n             [[ 8.3138e-08]],\n    \n             [[ 9.5355e-08]],\n    \n             ...,\n    \n             [[-8.3491e-10]],\n    \n             [[ 7.4140e-08]],\n    \n             [[-1.4698e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 4.2146e-07]],\n    \n             [[ 5.0416e-08]],\n    \n             [[ 1.8027e-07]],\n    \n             ...,\n    \n             [[-5.8737e-07]],\n    \n             [[ 6.8931e-07]],\n    \n             [[-2.9451e-08]]],\n    \n    \n            [[[ 5.8421e-08]],\n    \n             [[ 3.7926e-08]],\n    \n             [[-1.7529e-08]],\n    \n             ...,\n    \n             [[ 1.7759e-08]],\n    \n             [[-1.3718e-08]],\n    \n             [[-3.9801e-08]]],\n    \n    \n            [[[ 9.2666e-08]],\n    \n             [[ 1.4806e-08]],\n    \n             [[-9.9905e-08]],\n    \n             ...,\n    \n             [[-9.7834e-08]],\n    \n             [[-2.6317e-08]],\n    \n             [[ 1.6735e-07]]]]),\n    'exp_avg_sq': tensor([[[[2.8259e-13]],\n    \n             [[2.5024e-13]],\n    \n             [[2.0807e-13]],\n    \n             ...,\n    \n             [[1.1596e-13]],\n    \n             [[1.8196e-13]],\n    \n             [[2.5595e-13]]],\n    \n    \n            [[[2.0104e-12]],\n    \n             [[1.5801e-12]],\n    \n             [[1.5810e-12]],\n    \n             ...,\n    \n             [[1.1022e-12]],\n    \n             [[2.6042e-12]],\n    \n             [[2.0952e-12]]],\n    \n    \n            [[[1.2444e-13]],\n    \n             [[2.2121e-13]],\n    \n             [[6.0189e-14]],\n    \n             ...,\n    \n             [[6.9563e-14]],\n    \n             [[1.4727e-13]],\n    \n             [[1.4876e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[1.6301e-12]],\n    \n             [[9.7062e-13]],\n    \n             [[1.2505e-12]],\n    \n             ...,\n    \n             [[8.6523e-13]],\n    \n             [[1.2980e-12]],\n    \n             [[2.1413e-12]]],\n    \n    \n            [[[1.7189e-14]],\n    \n             [[1.0912e-14]],\n    \n             [[1.0765e-14]],\n    \n             ...,\n    \n             [[8.8198e-15]],\n    \n             [[1.8400e-14]],\n    \n             [[1.7981e-14]]],\n    \n    \n            [[[1.3754e-13]],\n    \n             [[1.5521e-13]],\n    \n             [[1.2794e-13]],\n    \n             ...,\n    \n             [[1.1982e-13]],\n    \n             [[2.4792e-13]],\n    \n             [[2.8864e-13]]]])},\n   111: {'exp_avg': tensor([[[[ 1.7968e-07]],\n    \n             [[ 1.0704e-07]],\n    \n             [[-8.8095e-08]],\n    \n             ...,\n    \n             [[ 1.1755e-07]],\n    \n             [[ 1.0799e-09]],\n    \n             [[ 1.8881e-07]]],\n    \n    \n            [[[ 5.7190e-07]],\n    \n             [[ 9.1704e-07]],\n    \n             [[ 1.1855e-06]],\n    \n             ...,\n    \n             [[ 7.8597e-07]],\n    \n             [[ 8.5022e-07]],\n    \n             [[ 1.0271e-06]]],\n    \n    \n            [[[ 1.4699e-07]],\n    \n             [[-8.4126e-08]],\n    \n             [[ 6.1098e-07]],\n    \n             ...,\n    \n             [[ 3.5407e-07]],\n    \n             [[ 1.8467e-07]],\n    \n             [[-2.1586e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[-1.8055e-07]],\n    \n             [[ 4.6409e-07]],\n    \n             [[-5.5484e-07]],\n    \n             ...,\n    \n             [[-1.8991e-07]],\n    \n             [[-5.3284e-08]],\n    \n             [[ 3.4545e-08]]],\n    \n    \n            [[[-6.1783e-07]],\n    \n             [[ 1.9560e-07]],\n    \n             [[ 5.4548e-08]],\n    \n             ...,\n    \n             [[ 1.3956e-07]],\n    \n             [[-3.4482e-07]],\n    \n             [[-2.7002e-07]]],\n    \n    \n            [[[-2.9393e-07]],\n    \n             [[-4.0476e-07]],\n    \n             [[-2.8448e-07]],\n    \n             ...,\n    \n             [[-2.8548e-07]],\n    \n             [[ 1.6912e-07]],\n    \n             [[-5.5428e-07]]]]),\n    'exp_avg_sq': tensor([[[[4.4468e-12]],\n    \n             [[1.7879e-12]],\n    \n             [[3.2672e-12]],\n    \n             ...,\n    \n             [[2.1548e-12]],\n    \n             [[4.0592e-12]],\n    \n             [[3.7730e-12]]],\n    \n    \n            [[[7.4197e-12]],\n    \n             [[7.3235e-12]],\n    \n             [[1.0080e-11]],\n    \n             ...,\n    \n             [[8.1664e-12]],\n    \n             [[1.0832e-11]],\n    \n             [[1.1137e-11]]],\n    \n    \n            [[[4.1829e-13]],\n    \n             [[5.1528e-13]],\n    \n             [[1.4906e-12]],\n    \n             ...,\n    \n             [[8.4542e-13]],\n    \n             [[9.4829e-13]],\n    \n             [[6.0171e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[3.6234e-12]],\n    \n             [[3.7051e-12]],\n    \n             [[6.3614e-12]],\n    \n             ...,\n    \n             [[3.5241e-12]],\n    \n             [[5.3709e-12]],\n    \n             [[4.8468e-12]]],\n    \n    \n            [[[3.0184e-12]],\n    \n             [[2.2712e-12]],\n    \n             [[3.1398e-12]],\n    \n             ...,\n    \n             [[9.5060e-13]],\n    \n             [[2.1310e-12]],\n    \n             [[4.0750e-12]]],\n    \n    \n            [[[3.0891e-12]],\n    \n             [[3.9776e-12]],\n    \n             [[5.8584e-12]],\n    \n             ...,\n    \n             [[5.1725e-12]],\n    \n             [[4.4681e-12]],\n    \n             [[5.5185e-12]]]])},\n   112: {'exp_avg': tensor([[[[ 6.5877e-08]],\n    \n             [[-1.7503e-07]],\n    \n             [[-1.1174e-07]],\n    \n             ...,\n    \n             [[-3.7397e-08]],\n    \n             [[-5.6365e-08]],\n    \n             [[ 1.4390e-07]]],\n    \n    \n            [[[ 2.3212e-08]],\n    \n             [[-3.2395e-07]],\n    \n             [[-7.2515e-08]],\n    \n             ...,\n    \n             [[ 1.2206e-07]],\n    \n             [[-3.7214e-08]],\n    \n             [[-1.6794e-07]]],\n    \n    \n            [[[-4.1652e-08]],\n    \n             [[-9.5851e-08]],\n    \n             [[-1.3542e-07]],\n    \n             ...,\n    \n             [[ 7.5926e-08]],\n    \n             [[ 1.6761e-07]],\n    \n             [[-3.2899e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[ 1.6576e-07]],\n    \n             [[ 5.0266e-07]],\n    \n             [[ 2.6106e-07]],\n    \n             ...,\n    \n             [[-2.5152e-07]],\n    \n             [[ 8.5752e-09]],\n    \n             [[ 5.3972e-07]]],\n    \n    \n            [[[-3.9260e-08]],\n    \n             [[-2.0076e-08]],\n    \n             [[ 5.1238e-08]],\n    \n             ...,\n    \n             [[ 6.5952e-08]],\n    \n             [[-5.1268e-08]],\n    \n             [[ 5.5292e-08]]],\n    \n    \n            [[[-6.7338e-08]],\n    \n             [[ 8.7324e-08]],\n    \n             [[-6.5994e-08]],\n    \n             ...,\n    \n             [[ 4.7945e-07]],\n    \n             [[ 5.6168e-08]],\n    \n             [[ 2.6924e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.8502e-13]],\n    \n             [[5.7030e-13]],\n    \n             [[2.8571e-13]],\n    \n             ...,\n    \n             [[5.4594e-13]],\n    \n             [[3.5181e-13]],\n    \n             [[6.1537e-13]]],\n    \n    \n            [[[1.0056e-13]],\n    \n             [[3.9078e-13]],\n    \n             [[2.7129e-13]],\n    \n             ...,\n    \n             [[2.4136e-13]],\n    \n             [[5.3076e-13]],\n    \n             [[3.9495e-13]]],\n    \n    \n            [[[1.3037e-13]],\n    \n             [[3.2478e-13]],\n    \n             [[2.1732e-13]],\n    \n             ...,\n    \n             [[2.8009e-13]],\n    \n             [[5.5098e-13]],\n    \n             [[3.4511e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[5.9053e-13]],\n    \n             [[2.4141e-12]],\n    \n             [[2.8883e-12]],\n    \n             ...,\n    \n             [[1.1050e-12]],\n    \n             [[4.8866e-12]],\n    \n             [[4.2810e-12]]],\n    \n    \n            [[[1.8718e-13]],\n    \n             [[3.1278e-13]],\n    \n             [[1.2065e-13]],\n    \n             ...,\n    \n             [[4.9820e-13]],\n    \n             [[2.6963e-13]],\n    \n             [[2.2876e-13]]],\n    \n    \n            [[[2.8809e-13]],\n    \n             [[5.1634e-13]],\n    \n             [[2.2402e-13]],\n    \n             ...,\n    \n             [[1.0509e-12]],\n    \n             [[4.5340e-13]],\n    \n             [[6.2714e-13]]]])},\n   113: {'exp_avg': tensor([[[[-2.6603e-07, -2.5393e-07, -6.8061e-08],\n              [-1.0235e-07, -1.0151e-07, -1.7420e-07],\n              [-1.1170e-07, -1.5257e-07, -2.3517e-07]],\n    \n             [[-9.4962e-08, -1.2588e-07,  4.7162e-08],\n              [-2.2762e-07, -9.9411e-08, -2.8936e-08],\n              [-2.9935e-07, -1.3226e-07,  3.8149e-08]],\n    \n             [[-1.8924e-08, -6.4298e-08, -1.5690e-08],\n              [-2.3230e-07, -9.5120e-08, -1.2742e-07],\n              [-1.3741e-07, -1.3461e-07, -9.5726e-08]],\n    \n             ...,\n    \n             [[-1.9740e-07, -3.9075e-08,  3.5808e-08],\n              [-7.8633e-09,  3.9285e-09, -3.6377e-08],\n              [-5.2212e-08,  3.6580e-08, -2.8194e-08]],\n    \n             [[ 2.6764e-07,  3.1974e-07,  3.1193e-07],\n              [ 2.3910e-07,  4.0524e-07,  2.2070e-07],\n              [ 1.6421e-07,  3.8897e-07,  4.0037e-07]],\n    \n             [[ 1.9555e-07, -5.2178e-08,  1.2300e-08],\n              [-7.3476e-08,  1.1230e-07,  6.6693e-08],\n              [-4.4818e-07, -1.9085e-07, -1.5147e-07]]],\n    \n    \n            [[[-1.3493e-07, -1.2200e-07, -9.4593e-08],\n              [-1.4778e-07, -3.7412e-08, -7.3645e-08],\n              [-1.4578e-07, -4.3388e-08, -1.2664e-07]],\n    \n             [[-3.4395e-07, -1.2168e-07, -2.1548e-10],\n              [-3.1153e-07, -1.7315e-07, -1.4052e-08],\n              [-4.1473e-07, -1.6500e-07, -7.8009e-08]],\n    \n             [[-1.5184e-07, -1.0819e-08,  1.1009e-07],\n              [-8.1690e-08, -4.6779e-08,  1.0460e-07],\n              [-1.9020e-07, -1.2989e-07, -7.0833e-08]],\n    \n             ...,\n    \n             [[-3.1862e-07, -3.3473e-07, -1.7199e-07],\n              [-2.5596e-07, -2.6428e-07, -2.0798e-07],\n              [-2.1962e-07, -2.7563e-07, -2.0823e-07]],\n    \n             [[ 2.9270e-07,  7.2347e-09, -1.8723e-07],\n              [-5.3786e-09, -9.1220e-08, -2.4233e-07],\n              [ 3.1282e-08,  3.8830e-08, -1.2141e-07]],\n    \n             [[ 4.6238e-08, -1.0327e-07, -2.0747e-07],\n              [-2.0173e-07, -2.2009e-07, -1.5922e-07],\n              [-2.6884e-07, -2.5777e-07, -1.1731e-07]]],\n    \n    \n            [[[ 9.0609e-08, -7.9795e-08, -1.0516e-07],\n              [-5.9303e-08, -9.5680e-08, -9.0976e-08],\n              [-2.9688e-10,  6.0150e-08,  1.7084e-07]],\n    \n             [[ 9.4899e-08,  5.9564e-08,  1.0628e-07],\n              [-6.4336e-08,  2.5679e-09,  8.5689e-09],\n              [ 2.5721e-08,  3.9055e-08,  9.7790e-08]],\n    \n             [[ 1.7969e-07,  2.7239e-07,  1.6541e-07],\n              [ 2.4197e-08,  2.0882e-07,  1.7375e-07],\n              [ 3.7887e-08,  1.4857e-07,  9.6900e-08]],\n    \n             ...,\n    \n             [[ 1.5342e-07,  1.9593e-07,  1.5225e-07],\n              [ 3.4650e-08,  1.4112e-07,  1.3669e-07],\n              [ 1.4114e-08,  1.6000e-07,  1.1170e-07]],\n    \n             [[-2.2180e-07, -4.0113e-08, -4.7217e-08],\n              [-3.1601e-07, -1.7133e-07, -1.3757e-07],\n              [-2.4005e-07, -2.5024e-07, -1.6130e-07]],\n    \n             [[-1.2721e-08,  1.5555e-07,  3.6599e-09],\n              [-1.2930e-07, -2.6153e-09, -5.8134e-09],\n              [ 4.5447e-08,  9.4886e-08,  3.5113e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 2.9606e-07,  5.5731e-07,  2.8873e-07],\n              [ 1.9743e-07,  3.8995e-07,  2.7351e-07],\n              [ 9.0272e-08,  2.4337e-07,  8.9458e-08]],\n    \n             [[ 3.4401e-07,  2.8017e-07,  1.1250e-07],\n              [ 1.9250e-07,  2.4035e-07,  8.6780e-08],\n              [ 2.5943e-07,  1.9357e-07,  1.0923e-07]],\n    \n             [[ 8.6727e-08,  2.1912e-08, -2.7627e-08],\n              [-4.5894e-08, -1.6400e-08, -4.7426e-08],\n              [-2.1155e-08, -7.1891e-08, -6.3368e-09]],\n    \n             ...,\n    \n             [[ 4.2466e-08, -3.6201e-08, -7.2654e-09],\n              [ 1.1182e-08, -1.3029e-07, -4.4603e-08],\n              [ 3.6423e-08, -2.1851e-08, -1.9143e-08]],\n    \n             [[-9.1324e-08,  3.7196e-08, -8.7749e-09],\n              [ 1.0310e-07,  1.5264e-07,  2.0239e-08],\n              [ 1.3136e-07,  6.9828e-08, -1.1062e-07]],\n    \n             [[ 3.2299e-07,  4.2183e-07,  2.1408e-07],\n              [ 2.4747e-07,  3.6261e-07,  1.4938e-07],\n              [ 1.9079e-07,  2.3863e-07,  1.0445e-07]]],\n    \n    \n            [[[ 1.0806e-07,  8.9939e-08,  4.4919e-08],\n              [-3.2899e-08, -6.4075e-08, -1.8322e-09],\n              [-7.5240e-08, -9.8504e-08, -1.1803e-07]],\n    \n             [[-8.8636e-08, -1.2050e-07, -2.2466e-08],\n              [-3.0907e-07, -3.0262e-07, -3.3443e-08],\n              [-3.4749e-07, -4.4317e-07, -1.6906e-07]],\n    \n             [[-2.8831e-08,  1.3177e-08,  8.9167e-08],\n              [-8.6542e-08, -9.1563e-08,  8.0979e-08],\n              [-2.0225e-07, -2.4139e-07, -1.6694e-08]],\n    \n             ...,\n    \n             [[-1.5191e-08,  3.0609e-08, -3.1136e-08],\n              [-1.1353e-07, -4.8682e-08,  2.3977e-09],\n              [-9.5844e-09, -1.3762e-09,  8.6093e-08]],\n    \n             [[ 1.2067e-07,  4.8126e-08,  5.0365e-08],\n              [ 2.7347e-07,  5.3673e-08, -1.1878e-07],\n              [ 2.6750e-07,  1.5462e-07,  7.0436e-08]],\n    \n             [[ 4.8742e-08,  1.4182e-08, -1.0069e-07],\n              [-6.0982e-10, -7.1064e-08, -2.9506e-07],\n              [-7.8837e-08, -1.2757e-07, -1.8638e-07]]],\n    \n    \n            [[[-8.9017e-08,  4.6435e-08,  4.0816e-08],\n              [ 3.2106e-10,  4.4732e-08, -5.8380e-09],\n              [ 3.0610e-08,  1.2934e-08, -9.8737e-08]],\n    \n             [[ 6.8936e-08,  1.8014e-07,  1.4503e-07],\n              [ 4.0021e-08,  5.0441e-08,  4.2565e-08],\n              [ 1.0936e-07,  8.1136e-08, -2.5165e-08]],\n    \n             [[ 1.6013e-07,  2.8592e-07,  2.2478e-07],\n              [ 9.2135e-08,  1.8496e-07,  1.7823e-07],\n              [ 1.3605e-07,  1.8976e-07,  1.8470e-07]],\n    \n             ...,\n    \n             [[ 6.3464e-08,  9.0489e-08,  9.2886e-08],\n              [ 5.2363e-08,  1.3696e-08,  7.7978e-08],\n              [ 5.3797e-08,  1.4560e-08,  6.6615e-08]],\n    \n             [[ 2.3949e-07,  1.2709e-07,  3.2860e-08],\n              [ 2.1200e-07,  1.0640e-07,  1.0627e-07],\n              [ 9.5032e-08,  3.3688e-08,  6.1418e-08]],\n    \n             [[-3.6816e-08,  1.0563e-08, -6.6812e-08],\n              [ 5.9139e-08,  9.0139e-08, -3.7072e-08],\n              [ 1.3439e-07,  6.7235e-08, -1.1919e-08]]]]),\n    'exp_avg_sq': tensor([[[[5.9205e-13, 6.1621e-13, 5.8995e-13],\n              [5.6876e-13, 6.3048e-13, 5.9857e-13],\n              [5.6418e-13, 6.0942e-13, 5.7750e-13]],\n    \n             [[5.7419e-13, 5.8690e-13, 6.2933e-13],\n              [6.0967e-13, 6.2897e-13, 6.2896e-13],\n              [6.0224e-13, 6.0851e-13, 6.2076e-13]],\n    \n             [[3.6883e-13, 3.5818e-13, 3.4538e-13],\n              [3.9664e-13, 4.4220e-13, 3.5633e-13],\n              [3.6394e-13, 3.8999e-13, 3.5271e-13]],\n    \n             ...,\n    \n             [[1.8738e-13, 1.6619e-13, 1.3901e-13],\n              [1.7531e-13, 1.8547e-13, 1.4509e-13],\n              [1.5126e-13, 1.5943e-13, 1.3256e-13]],\n    \n             [[8.2739e-13, 8.6708e-13, 8.2690e-13],\n              [8.0148e-13, 8.6020e-13, 8.2229e-13],\n              [8.2128e-13, 8.5034e-13, 8.3580e-13]],\n    \n             [[6.7703e-13, 6.5458e-13, 6.5652e-13],\n              [6.3364e-13, 6.5768e-13, 5.9412e-13],\n              [5.9777e-13, 6.2331e-13, 6.0531e-13]]],\n    \n    \n            [[[4.4879e-13, 4.8810e-13, 4.7842e-13],\n              [4.7688e-13, 5.2350e-13, 5.1855e-13],\n              [4.3670e-13, 4.4579e-13, 4.4449e-13]],\n    \n             [[4.5905e-13, 5.1340e-13, 4.6983e-13],\n              [5.0728e-13, 5.3845e-13, 5.0393e-13],\n              [4.9000e-13, 4.7659e-13, 4.6101e-13]],\n    \n             [[3.2286e-13, 3.0127e-13, 3.1795e-13],\n              [4.0245e-13, 3.9414e-13, 3.6391e-13],\n              [4.3230e-13, 4.3855e-13, 3.6636e-13]],\n    \n             ...,\n    \n             [[2.9302e-13, 3.1572e-13, 2.9297e-13],\n              [4.1939e-13, 5.0032e-13, 4.6010e-13],\n              [3.4762e-13, 4.2616e-13, 3.6450e-13]],\n    \n             [[7.4828e-13, 8.7969e-13, 7.6473e-13],\n              [8.5461e-13, 1.0718e-12, 8.6354e-13],\n              [6.9716e-13, 7.8819e-13, 6.6222e-13]],\n    \n             [[4.1170e-13, 5.0737e-13, 4.6920e-13],\n              [4.3740e-13, 5.3024e-13, 4.7040e-13],\n              [3.9165e-13, 4.4501e-13, 4.2857e-13]]],\n    \n    \n            [[[5.2600e-13, 6.2620e-13, 5.9503e-13],\n              [6.0753e-13, 6.6138e-13, 6.0617e-13],\n              [5.1422e-13, 5.1861e-13, 4.9208e-13]],\n    \n             [[5.1208e-13, 6.1007e-13, 6.3807e-13],\n              [4.8931e-13, 6.2770e-13, 6.9138e-13],\n              [4.9899e-13, 6.0808e-13, 6.6561e-13]],\n    \n             [[2.3528e-13, 3.4155e-13, 3.9402e-13],\n              [2.2316e-13, 3.6698e-13, 4.3110e-13],\n              [2.3672e-13, 3.7760e-13, 4.1383e-13]],\n    \n             ...,\n    \n             [[1.0701e-13, 1.2068e-13, 1.2052e-13],\n              [9.7400e-14, 1.1423e-13, 1.3091e-13],\n              [9.7752e-14, 1.2070e-13, 1.2580e-13]],\n    \n             [[8.7782e-13, 7.7222e-13, 6.6424e-13],\n              [8.8994e-13, 7.0082e-13, 5.9037e-13],\n              [8.3546e-13, 7.2153e-13, 6.3306e-13]],\n    \n             [[6.3059e-13, 6.1077e-13, 5.6661e-13],\n              [6.5068e-13, 5.8516e-13, 5.3915e-13],\n              [5.8908e-13, 5.5212e-13, 5.5697e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[4.3720e-13, 4.5109e-13, 4.4248e-13],\n              [4.5036e-13, 4.9285e-13, 5.0586e-13],\n              [4.1918e-13, 4.1258e-13, 4.5296e-13]],\n    \n             [[6.5212e-13, 6.4238e-13, 5.8590e-13],\n              [7.1978e-13, 6.9927e-13, 6.1543e-13],\n              [6.1259e-13, 6.0064e-13, 5.6650e-13]],\n    \n             [[3.5820e-13, 3.5185e-13, 3.0783e-13],\n              [5.2617e-13, 4.9170e-13, 3.7738e-13],\n              [3.7288e-13, 3.1643e-13, 2.5788e-13]],\n    \n             ...,\n    \n             [[9.0800e-13, 1.0992e-12, 7.2419e-13],\n              [1.1949e-12, 1.4129e-12, 8.5492e-13],\n              [6.7664e-13, 7.5029e-13, 4.9212e-13]],\n    \n             [[8.4439e-13, 9.6031e-13, 8.7486e-13],\n              [1.0154e-12, 1.2539e-12, 1.0625e-12],\n              [8.3231e-13, 9.3997e-13, 8.4193e-13]],\n    \n             [[5.7659e-13, 6.5477e-13, 5.8819e-13],\n              [5.8084e-13, 6.7137e-13, 6.3725e-13],\n              [5.7761e-13, 6.5169e-13, 6.2297e-13]]],\n    \n    \n            [[[4.1376e-13, 4.1598e-13, 3.9677e-13],\n              [4.3741e-13, 4.6291e-13, 4.2626e-13],\n              [4.0739e-13, 3.8724e-13, 3.6800e-13]],\n    \n             [[4.6865e-13, 5.2913e-13, 5.1199e-13],\n              [5.2852e-13, 5.3795e-13, 5.2102e-13],\n              [5.3934e-13, 5.3541e-13, 5.2772e-13]],\n    \n             [[3.3146e-13, 3.4291e-13, 3.1617e-13],\n              [3.5767e-13, 3.8173e-13, 3.3531e-13],\n              [3.9211e-13, 4.0865e-13, 3.6951e-13]],\n    \n             ...,\n    \n             [[3.0673e-13, 3.9148e-13, 3.4922e-13],\n              [3.7057e-13, 4.8418e-13, 3.9817e-13],\n              [3.5296e-13, 4.5709e-13, 3.7780e-13]],\n    \n             [[5.7510e-13, 5.5233e-13, 4.3910e-13],\n              [6.1101e-13, 5.3410e-13, 3.8740e-13],\n              [5.0170e-13, 3.8963e-13, 3.1332e-13]],\n    \n             [[4.1416e-13, 4.0563e-13, 3.0493e-13],\n              [4.3066e-13, 3.6596e-13, 2.7146e-13],\n              [3.7482e-13, 3.2223e-13, 2.8053e-13]]],\n    \n    \n            [[[1.8024e-13, 2.0208e-13, 2.0703e-13],\n              [1.5520e-13, 1.7699e-13, 2.0214e-13],\n              [1.2612e-13, 1.1955e-13, 1.4655e-13]],\n    \n             [[2.0406e-13, 2.5747e-13, 3.0114e-13],\n              [2.1483e-13, 2.7088e-13, 3.2834e-13],\n              [2.2720e-13, 2.5224e-13, 3.0635e-13]],\n    \n             [[3.0332e-13, 3.4460e-13, 2.9152e-13],\n              [3.6447e-13, 4.3565e-13, 3.4282e-13],\n              [3.6458e-13, 4.1173e-13, 3.3407e-13]],\n    \n             ...,\n    \n             [[1.8463e-13, 1.6947e-13, 8.6091e-14],\n              [2.3094e-13, 2.0946e-13, 9.9375e-14],\n              [1.9909e-13, 1.8971e-13, 8.9737e-14]],\n    \n             [[5.3053e-13, 5.0821e-13, 4.9463e-13],\n              [5.4855e-13, 5.4616e-13, 4.9935e-13],\n              [4.4303e-13, 4.2891e-13, 4.0327e-13]],\n    \n             [[3.1976e-13, 3.4970e-13, 3.2677e-13],\n              [3.0211e-13, 3.3556e-13, 3.0316e-13],\n              [2.8387e-13, 2.8276e-13, 2.5870e-13]]]])},\n   114: {'exp_avg': tensor([[[[ 7.1225e-09]],\n    \n             [[ 1.8946e-08]],\n    \n             [[-1.6083e-08]],\n    \n             ...,\n    \n             [[ 3.1160e-08]],\n    \n             [[ 5.4019e-08]],\n    \n             [[-3.5718e-08]]],\n    \n    \n            [[[ 1.5353e-07]],\n    \n             [[-1.3320e-08]],\n    \n             [[-1.5107e-08]],\n    \n             ...,\n    \n             [[ 1.4670e-07]],\n    \n             [[ 5.4479e-09]],\n    \n             [[-5.4832e-08]]],\n    \n    \n            [[[-1.2021e-07]],\n    \n             [[-1.1429e-07]],\n    \n             [[-1.3460e-08]],\n    \n             ...,\n    \n             [[-6.0444e-08]],\n    \n             [[ 3.8684e-08]],\n    \n             [[-9.6255e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-1.1728e-08]],\n    \n             [[ 3.3286e-07]],\n    \n             [[-7.7744e-09]],\n    \n             ...,\n    \n             [[ 2.4882e-07]],\n    \n             [[ 2.9665e-07]],\n    \n             [[-8.7855e-07]]],\n    \n    \n            [[[-1.5306e-07]],\n    \n             [[ 6.0343e-08]],\n    \n             [[ 6.4999e-08]],\n    \n             ...,\n    \n             [[ 3.1294e-07]],\n    \n             [[ 9.7939e-08]],\n    \n             [[-8.0127e-09]]],\n    \n    \n            [[[ 2.5376e-08]],\n    \n             [[-3.3540e-08]],\n    \n             [[ 1.5470e-08]],\n    \n             ...,\n    \n             [[-2.4387e-08]],\n    \n             [[-1.8081e-08]],\n    \n             [[-4.3437e-08]]]]),\n    'exp_avg_sq': tensor([[[[4.6571e-14]],\n    \n             [[1.7804e-14]],\n    \n             [[1.6694e-14]],\n    \n             ...,\n    \n             [[2.4810e-14]],\n    \n             [[1.5230e-14]],\n    \n             [[3.0760e-14]]],\n    \n    \n            [[[3.9749e-13]],\n    \n             [[1.3663e-13]],\n    \n             [[1.1850e-13]],\n    \n             ...,\n    \n             [[2.6884e-13]],\n    \n             [[1.5946e-13]],\n    \n             [[2.3446e-13]]],\n    \n    \n            [[[2.4547e-13]],\n    \n             [[8.9778e-14]],\n    \n             [[7.8061e-14]],\n    \n             ...,\n    \n             [[1.1550e-13]],\n    \n             [[1.5105e-13]],\n    \n             [[1.6371e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[3.1218e-12]],\n    \n             [[1.0211e-12]],\n    \n             [[1.0441e-12]],\n    \n             ...,\n    \n             [[1.6623e-12]],\n    \n             [[1.1015e-12]],\n    \n             [[1.8074e-12]]],\n    \n    \n            [[[6.4452e-13]],\n    \n             [[3.0889e-13]],\n    \n             [[3.4131e-13]],\n    \n             ...,\n    \n             [[3.8352e-13]],\n    \n             [[4.1296e-13]],\n    \n             [[6.5403e-13]]],\n    \n    \n            [[[6.0610e-14]],\n    \n             [[2.5388e-14]],\n    \n             [[2.3881e-14]],\n    \n             ...,\n    \n             [[3.5641e-14]],\n    \n             [[2.5061e-14]],\n    \n             [[3.3964e-14]]]])},\n   115: {'exp_avg': tensor([[[[-1.5329e-07]],\n    \n             [[ 2.2579e-07]],\n    \n             [[ 1.5419e-08]],\n    \n             ...,\n    \n             [[ 2.1791e-07]],\n    \n             [[-1.0120e-07]],\n    \n             [[ 8.2170e-08]]],\n    \n    \n            [[[ 4.7446e-08]],\n    \n             [[ 1.4432e-07]],\n    \n             [[ 9.5007e-08]],\n    \n             ...,\n    \n             [[-1.0198e-08]],\n    \n             [[ 8.4496e-08]],\n    \n             [[ 2.2630e-07]]],\n    \n    \n            [[[-1.7744e-07]],\n    \n             [[ 9.2764e-08]],\n    \n             [[-1.7333e-07]],\n    \n             ...,\n    \n             [[ 2.1941e-07]],\n    \n             [[-1.3480e-07]],\n    \n             [[ 7.2959e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-4.1835e-08]],\n    \n             [[ 2.0408e-07]],\n    \n             [[-4.0264e-08]],\n    \n             ...,\n    \n             [[ 1.1367e-07]],\n    \n             [[ 9.9680e-08]],\n    \n             [[ 2.3809e-07]]],\n    \n    \n            [[[-4.2666e-08]],\n    \n             [[ 1.6880e-07]],\n    \n             [[ 4.9339e-08]],\n    \n             ...,\n    \n             [[-2.8403e-08]],\n    \n             [[-1.8779e-09]],\n    \n             [[-8.0058e-08]]],\n    \n    \n            [[[-3.2852e-08]],\n    \n             [[ 1.0469e-08]],\n    \n             [[-1.5283e-09]],\n    \n             ...,\n    \n             [[-6.7868e-08]],\n    \n             [[-6.6765e-09]],\n    \n             [[ 1.2093e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.9219e-13]],\n    \n             [[4.1155e-13]],\n    \n             [[1.0455e-13]],\n    \n             ...,\n    \n             [[8.0665e-13]],\n    \n             [[4.4266e-13]],\n    \n             [[3.6566e-13]]],\n    \n    \n            [[[1.3906e-13]],\n    \n             [[7.4242e-13]],\n    \n             [[3.6515e-13]],\n    \n             ...,\n    \n             [[4.7501e-13]],\n    \n             [[4.7022e-13]],\n    \n             [[6.1798e-13]]],\n    \n    \n            [[[2.3400e-13]],\n    \n             [[3.0689e-13]],\n    \n             [[1.4593e-13]],\n    \n             ...,\n    \n             [[8.0160e-13]],\n    \n             [[5.6576e-13]],\n    \n             [[1.5474e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[1.6430e-13]],\n    \n             [[3.3016e-13]],\n    \n             [[1.1709e-13]],\n    \n             ...,\n    \n             [[5.6940e-13]],\n    \n             [[4.8274e-13]],\n    \n             [[5.0306e-13]]],\n    \n    \n            [[[9.5301e-14]],\n    \n             [[3.1321e-13]],\n    \n             [[2.0109e-13]],\n    \n             ...,\n    \n             [[6.3512e-13]],\n    \n             [[4.1626e-13]],\n    \n             [[3.8620e-13]]],\n    \n    \n            [[[1.5261e-13]],\n    \n             [[2.4252e-13]],\n    \n             [[8.4516e-14]],\n    \n             ...,\n    \n             [[5.9068e-13]],\n    \n             [[1.6420e-13]],\n    \n             [[2.3893e-13]]]])},\n   116: {'exp_avg': tensor([[[[-4.2125e-08, -6.4946e-08, -1.4223e-07],\n              [-1.4251e-07, -8.9297e-08, -4.5388e-08],\n              [-2.8698e-08,  8.3144e-09,  1.5883e-07]],\n    \n             [[ 1.3281e-08,  1.1543e-08,  8.8517e-08],\n              [ 6.6944e-08,  1.3029e-07,  1.4742e-07],\n              [ 1.0855e-07,  6.2947e-08,  3.6753e-08]],\n    \n             [[ 1.9877e-07,  2.2626e-07,  2.6678e-07],\n              [ 4.4887e-07,  4.5319e-07,  3.1818e-07],\n              [ 1.8394e-07,  1.2123e-07,  2.5338e-07]],\n    \n             ...,\n    \n             [[-5.0331e-08, -5.1400e-08, -1.2119e-07],\n              [-6.4306e-08, -9.8807e-08, -1.1150e-07],\n              [-1.6906e-07, -3.0109e-07, -2.5995e-07]],\n    \n             [[ 7.7707e-08,  1.6720e-07,  3.2870e-07],\n              [ 6.6361e-08,  2.5176e-07,  1.6883e-07],\n              [ 3.2198e-07,  1.7017e-07,  9.3742e-08]],\n    \n             [[-1.4026e-07, -2.0579e-07, -1.3492e-07],\n              [-1.1173e-07, -1.0394e-07, -1.9718e-07],\n              [-2.3848e-07, -3.3368e-07, -5.8484e-08]]],\n    \n    \n            [[[ 1.9010e-07,  1.8303e-07,  1.6911e-08],\n              [ 1.2245e-07,  1.4790e-07,  1.6801e-08],\n              [ 1.9834e-07,  1.0285e-07,  2.1259e-07]],\n    \n             [[ 1.0526e-07,  3.2779e-08,  1.1406e-07],\n              [ 4.8861e-08,  1.2472e-08,  4.4079e-08],\n              [-9.8469e-08, -1.5097e-08,  5.9484e-08]],\n    \n             [[-1.1028e-07, -1.5159e-07, -2.2049e-07],\n              [-6.1290e-08, -1.5998e-08, -2.1258e-07],\n              [-3.9810e-08, -2.1851e-08, -9.0349e-09]],\n    \n             ...,\n    \n             [[-9.7302e-09,  7.0418e-08,  2.2713e-08],\n              [-8.9116e-10,  2.3112e-08, -2.0609e-08],\n              [-1.4239e-08,  4.2084e-08, -5.0129e-08]],\n    \n             [[ 2.8371e-07,  2.9886e-07,  3.7348e-07],\n              [ 2.5245e-07,  2.9279e-07,  3.3339e-07],\n              [ 2.8578e-07,  2.7281e-07,  3.1149e-07]],\n    \n             [[ 3.5878e-08,  8.5566e-08, -2.2749e-08],\n              [-2.6108e-08, -9.3247e-08, -9.2270e-08],\n              [-1.5674e-08, -8.7334e-08, -5.7904e-08]]],\n    \n    \n            [[[ 4.8670e-08, -1.7202e-08, -8.8908e-08],\n              [-8.2368e-09,  2.9707e-08,  8.0410e-08],\n              [-5.9025e-08, -5.2974e-08, -1.5328e-08]],\n    \n             [[ 5.3695e-08, -2.7869e-08,  4.2185e-08],\n              [ 5.7003e-08, -1.5023e-07, -9.3668e-08],\n              [ 8.4119e-08, -9.6280e-08, -2.7856e-08]],\n    \n             [[-1.4551e-07, -3.0605e-07, -1.9666e-07],\n              [-3.6743e-09, -1.7131e-07, -1.8008e-07],\n              [-5.4847e-08, -1.9110e-07, -1.2295e-07]],\n    \n             ...,\n    \n             [[ 6.8117e-08,  6.8827e-08,  9.0096e-08],\n              [ 7.3618e-08,  4.3673e-08,  8.8085e-08],\n              [ 8.1139e-08,  2.2014e-08,  5.4933e-08]],\n    \n             [[-3.1580e-07, -3.0112e-07, -2.8532e-07],\n              [-2.5900e-07, -3.8896e-07, -3.8610e-07],\n              [-3.1818e-07, -3.9581e-07, -3.6512e-07]],\n    \n             [[-7.0243e-08, -2.1055e-08, -6.7007e-08],\n              [ 6.5113e-09,  3.9190e-08,  7.9005e-09],\n              [-9.6440e-09, -2.0901e-08, -8.1212e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-2.7368e-07, -1.2781e-07, -6.3969e-08],\n              [-1.7097e-07, -1.8082e-07, -3.2661e-08],\n              [-8.5238e-08, -1.3937e-07, -7.3168e-08]],\n    \n             [[-2.7092e-08,  6.1835e-08,  3.2024e-08],\n              [ 1.0539e-07,  9.0973e-08, -2.2412e-08],\n              [ 3.5900e-08, -7.7794e-08, -5.2632e-08]],\n    \n             [[ 1.6874e-08,  1.2257e-08,  1.9482e-07],\n              [ 1.4397e-07,  1.4968e-07,  2.9810e-07],\n              [ 9.9732e-08,  1.3896e-08,  1.3278e-07]],\n    \n             ...,\n    \n             [[-2.5309e-07, -1.5949e-07, -1.2614e-07],\n              [-1.0724e-07, -3.8185e-09,  4.8939e-08],\n              [-2.3230e-07, -1.5869e-07, -4.6644e-10]],\n    \n             [[-7.8430e-08, -3.9337e-08, -1.1723e-07],\n              [ 6.6101e-08,  4.8018e-08,  3.6175e-08],\n              [-4.7605e-08,  4.2370e-08,  4.0389e-08]],\n    \n             [[-4.0141e-08, -1.6346e-07, -6.3523e-08],\n              [ 1.4761e-07,  1.3333e-08, -3.3525e-08],\n              [ 1.5422e-07,  2.6460e-08, -7.5580e-08]]],\n    \n    \n            [[[-7.1787e-08, -6.8894e-08, -8.6174e-08],\n              [ 3.7155e-10, -3.7170e-08,  3.0111e-08],\n              [ 3.5776e-08,  5.4927e-08,  6.7166e-08]],\n    \n             [[-9.2796e-09,  3.8832e-08,  8.3374e-08],\n              [ 2.8091e-08,  1.3606e-07,  1.0427e-07],\n              [ 1.2585e-07,  1.5765e-07,  4.1323e-08]],\n    \n             [[ 6.0699e-08, -3.6366e-08, -4.3268e-08],\n              [ 9.5421e-08,  5.7184e-09,  3.6393e-09],\n              [-2.0299e-08, -5.1608e-09, -1.8279e-08]],\n    \n             ...,\n    \n             [[-3.8140e-08, -2.8315e-08, -2.1099e-08],\n              [-2.3552e-08,  2.2279e-08,  2.1160e-08],\n              [-1.4234e-07, -1.4727e-07, -2.2245e-08]],\n    \n             [[-8.2257e-08, -2.5803e-08, -1.4932e-07],\n              [-5.5278e-08,  3.8824e-08,  3.4468e-08],\n              [-3.2893e-08,  8.6409e-08,  3.3386e-08]],\n    \n             [[-6.6897e-08,  4.9628e-08,  1.7592e-08],\n              [-3.5701e-08,  4.5001e-08,  5.7938e-08],\n              [-1.8187e-07, -2.8492e-08,  2.7187e-08]]],\n    \n    \n            [[[ 1.8850e-07,  2.7044e-07,  3.3957e-07],\n              [ 7.4050e-08,  1.8534e-07,  2.0004e-07],\n              [ 9.1305e-08,  4.0724e-08,  1.6318e-07]],\n    \n             [[ 1.1584e-07,  6.5050e-09,  7.4098e-08],\n              [ 5.4957e-08,  6.9139e-08,  1.5233e-07],\n              [ 1.1150e-07,  7.1577e-08,  9.6956e-08]],\n    \n             [[-1.5261e-07, -5.2327e-08, -2.3263e-08],\n              [-1.1150e-07, -9.8692e-08, -1.4407e-07],\n              [-1.0426e-07, -1.2261e-07, -8.0139e-08]],\n    \n             ...,\n    \n             [[ 9.2770e-08,  1.6482e-07,  2.3721e-07],\n              [ 1.0525e-07,  1.0190e-07,  2.5188e-07],\n              [ 4.0381e-08,  1.2377e-07,  1.9590e-07]],\n    \n             [[ 2.6499e-08, -4.5547e-08,  2.6635e-08],\n              [ 5.0470e-08, -1.5804e-07, -1.1605e-07],\n              [ 1.6353e-07,  9.4783e-09, -2.0422e-08]],\n    \n             [[-2.7058e-08, -4.9581e-08,  1.2269e-08],\n              [-1.8097e-07, -8.4624e-08, -8.9469e-08],\n              [-2.3747e-07, -1.7366e-07, -8.5065e-08]]]]),\n    'exp_avg_sq': tensor([[[[5.3467e-13, 5.3107e-13, 5.0134e-13],\n              [5.2583e-13, 5.2653e-13, 4.9636e-13],\n              [5.8120e-13, 5.8411e-13, 5.1549e-13]],\n    \n             [[3.2463e-13, 2.4404e-13, 2.6156e-13],\n              [2.8012e-13, 2.9786e-13, 2.2614e-13],\n              [2.1395e-13, 1.6531e-13, 1.6331e-13]],\n    \n             [[6.2594e-13, 6.8544e-13, 6.6416e-13],\n              [7.2144e-13, 8.1818e-13, 7.8962e-13],\n              [6.5133e-13, 7.1039e-13, 6.8790e-13]],\n    \n             ...,\n    \n             [[4.7212e-13, 4.8224e-13, 4.2457e-13],\n              [4.5827e-13, 5.0334e-13, 4.5916e-13],\n              [4.2097e-13, 4.6278e-13, 4.0743e-13]],\n    \n             [[7.8313e-13, 8.4432e-13, 8.3563e-13],\n              [7.6212e-13, 8.4073e-13, 8.0401e-13],\n              [6.9365e-13, 7.0123e-13, 6.9512e-13]],\n    \n             [[4.3791e-13, 4.6869e-13, 4.6524e-13],\n              [4.6998e-13, 5.1869e-13, 4.7667e-13],\n              [4.7298e-13, 5.2027e-13, 4.9291e-13]]],\n    \n    \n            [[[2.5106e-13, 2.4171e-13, 2.3099e-13],\n              [2.3202e-13, 2.3714e-13, 2.1806e-13],\n              [2.4736e-13, 2.3864e-13, 2.1731e-13]],\n    \n             [[1.9487e-13, 2.0861e-13, 1.4971e-13],\n              [1.9282e-13, 2.1650e-13, 1.5225e-13],\n              [1.5437e-13, 1.9264e-13, 1.5752e-13]],\n    \n             [[2.3029e-13, 2.5219e-13, 2.7296e-13],\n              [2.0893e-13, 2.2832e-13, 2.6867e-13],\n              [1.7708e-13, 1.9492e-13, 2.3766e-13]],\n    \n             ...,\n    \n             [[3.8022e-13, 4.0233e-13, 4.1515e-13],\n              [3.7693e-13, 4.1886e-13, 4.2420e-13],\n              [3.6937e-13, 4.0770e-13, 4.1273e-13]],\n    \n             [[3.6788e-13, 4.1162e-13, 3.3326e-13],\n              [4.4400e-13, 4.9529e-13, 3.9307e-13],\n              [3.8913e-13, 4.4346e-13, 3.5589e-13]],\n    \n             [[1.7682e-13, 1.8454e-13, 1.9835e-13],\n              [1.7139e-13, 1.7585e-13, 1.8623e-13],\n              [1.9303e-13, 1.8727e-13, 1.7643e-13]]],\n    \n    \n            [[[4.1015e-13, 4.6020e-13, 4.7366e-13],\n              [3.0127e-13, 3.3010e-13, 3.5941e-13],\n              [3.1712e-13, 3.6268e-13, 3.7256e-13]],\n    \n             [[6.0098e-13, 8.1219e-13, 6.9006e-13],\n              [6.7591e-13, 1.0306e-12, 8.5707e-13],\n              [6.5290e-13, 9.6928e-13, 8.2680e-13]],\n    \n             [[4.7199e-13, 4.8424e-13, 4.2687e-13],\n              [3.9666e-13, 4.3378e-13, 4.1925e-13],\n              [3.3692e-13, 3.8908e-13, 4.1737e-13]],\n    \n             ...,\n    \n             [[5.2072e-13, 5.2496e-13, 6.0413e-13],\n              [5.1530e-13, 5.2204e-13, 6.3048e-13],\n              [5.0326e-13, 5.4578e-13, 6.1426e-13]],\n    \n             [[7.6005e-13, 8.8887e-13, 7.9547e-13],\n              [8.5284e-13, 1.0400e-12, 8.9668e-13],\n              [7.4069e-13, 9.1037e-13, 7.9718e-13]],\n    \n             [[3.0624e-13, 2.6152e-13, 2.6191e-13],\n              [2.8058e-13, 2.2930e-13, 2.1924e-13],\n              [3.0579e-13, 2.4722e-13, 2.2400e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[2.5110e-13, 2.5064e-13, 2.5462e-13],\n              [3.6763e-13, 3.4490e-13, 3.1405e-13],\n              [3.1586e-13, 3.0043e-13, 2.7487e-13]],\n    \n             [[3.5037e-13, 6.9273e-13, 5.9154e-13],\n              [5.3327e-13, 1.4729e-12, 1.1734e-12],\n              [4.6698e-13, 1.2790e-12, 1.1553e-12]],\n    \n             [[2.0732e-13, 2.2991e-13, 2.2341e-13],\n              [2.4921e-13, 2.7631e-13, 2.6440e-13],\n              [2.5769e-13, 2.9496e-13, 2.7001e-13]],\n    \n             ...,\n    \n             [[3.9337e-13, 3.8534e-13, 3.0386e-13],\n              [3.3699e-13, 3.1249e-13, 2.4586e-13],\n              [3.2413e-13, 2.9235e-13, 2.4371e-13]],\n    \n             [[4.1660e-13, 6.2245e-13, 4.9295e-13],\n              [5.4771e-13, 1.0074e-12, 7.7102e-13],\n              [4.0239e-13, 6.8697e-13, 5.5225e-13]],\n    \n             [[1.5621e-13, 2.1963e-13, 2.5535e-13],\n              [2.1599e-13, 3.2092e-13, 3.3698e-13],\n              [1.6712e-13, 2.4955e-13, 2.7924e-13]]],\n    \n    \n            [[[1.4147e-13, 1.5400e-13, 1.7060e-13],\n              [1.0988e-13, 1.1723e-13, 1.3070e-13],\n              [1.3620e-13, 1.4162e-13, 1.5394e-13]],\n    \n             [[1.8925e-13, 3.2679e-13, 2.7030e-13],\n              [2.6551e-13, 4.6732e-13, 3.5871e-13],\n              [2.4595e-13, 4.5107e-13, 3.5298e-13]],\n    \n             [[1.4464e-13, 1.5215e-13, 1.4712e-13],\n              [1.5756e-13, 1.6662e-13, 1.6885e-13],\n              [1.6163e-13, 1.7327e-13, 1.7447e-13]],\n    \n             ...,\n    \n             [[2.2661e-13, 2.3327e-13, 2.5861e-13],\n              [2.4058e-13, 2.4307e-13, 2.6289e-13],\n              [2.4546e-13, 2.5750e-13, 2.6199e-13]],\n    \n             [[2.8339e-13, 3.8520e-13, 3.4090e-13],\n              [3.6360e-13, 4.5769e-13, 4.0582e-13],\n              [3.1209e-13, 4.0548e-13, 3.6031e-13]],\n    \n             [[1.3162e-13, 1.1721e-13, 1.4419e-13],\n              [1.3562e-13, 1.0794e-13, 1.3306e-13],\n              [1.6532e-13, 1.4574e-13, 1.5102e-13]]],\n    \n    \n            [[[1.9836e-13, 2.2365e-13, 2.5471e-13],\n              [1.7189e-13, 1.7354e-13, 1.9062e-13],\n              [2.1258e-13, 2.1081e-13, 2.0349e-13]],\n    \n             [[4.9134e-13, 7.8980e-13, 5.7650e-13],\n              [6.0221e-13, 1.0864e-12, 7.5200e-13],\n              [4.7087e-13, 8.6061e-13, 6.2605e-13]],\n    \n             [[2.2296e-13, 1.9472e-13, 2.2533e-13],\n              [2.3181e-13, 2.0294e-13, 2.3672e-13],\n              [2.3215e-13, 2.3769e-13, 2.4585e-13]],\n    \n             ...,\n    \n             [[3.8853e-13, 4.4593e-13, 5.0154e-13],\n              [3.9159e-13, 4.3753e-13, 5.0969e-13],\n              [4.1904e-13, 4.5386e-13, 4.7582e-13]],\n    \n             [[6.7004e-13, 9.3839e-13, 7.2733e-13],\n              [7.4830e-13, 1.0654e-12, 8.5047e-13],\n              [5.4044e-13, 7.2614e-13, 6.1366e-13]],\n    \n             [[1.6057e-13, 1.3456e-13, 2.0550e-13],\n              [1.7775e-13, 1.4355e-13, 1.7651e-13],\n              [2.3530e-13, 2.0337e-13, 1.9781e-13]]]])},\n   117: {'exp_avg': tensor([[[[-6.5465e-08]],\n    \n             [[-3.5952e-08]],\n    \n             [[ 5.2687e-09]],\n    \n             ...,\n    \n             [[-7.5953e-08]],\n    \n             [[ 1.6569e-09]],\n    \n             [[-1.5848e-08]]],\n    \n    \n            [[[-4.4709e-08]],\n    \n             [[-1.0015e-07]],\n    \n             [[ 2.3683e-08]],\n    \n             ...,\n    \n             [[ 5.3643e-08]],\n    \n             [[ 1.5137e-08]],\n    \n             [[ 1.1276e-07]]],\n    \n    \n            [[[-3.0980e-08]],\n    \n             [[-1.0439e-07]],\n    \n             [[-7.8444e-09]],\n    \n             ...,\n    \n             [[-2.3219e-08]],\n    \n             [[-2.3562e-08]],\n    \n             [[-7.2178e-10]]],\n    \n    \n            ...,\n    \n    \n            [[[ 2.6151e-07]],\n    \n             [[-8.2900e-08]],\n    \n             [[-1.8058e-07]],\n    \n             ...,\n    \n             [[ 2.6709e-08]],\n    \n             [[-2.3705e-07]],\n    \n             [[ 1.0170e-07]]],\n    \n    \n            [[[ 1.9873e-07]],\n    \n             [[-5.4514e-08]],\n    \n             [[ 6.7138e-09]],\n    \n             ...,\n    \n             [[-1.0938e-08]],\n    \n             [[-2.1499e-09]],\n    \n             [[ 3.2656e-08]]],\n    \n    \n            [[[-4.5840e-08]],\n    \n             [[-9.5625e-09]],\n    \n             [[-1.1772e-08]],\n    \n             ...,\n    \n             [[ 7.5027e-08]],\n    \n             [[-1.3981e-07]],\n    \n             [[-5.5467e-08]]]]),\n    'exp_avg_sq': tensor([[[[7.0523e-14]],\n    \n             [[6.6929e-14]],\n    \n             [[5.0955e-14]],\n    \n             ...,\n    \n             [[5.1163e-14]],\n    \n             [[5.4627e-14]],\n    \n             [[5.9143e-14]]],\n    \n    \n            [[[2.3229e-13]],\n    \n             [[2.1460e-13]],\n    \n             [[1.6197e-13]],\n    \n             ...,\n    \n             [[1.8718e-13]],\n    \n             [[2.1109e-13]],\n    \n             [[1.9753e-13]]],\n    \n    \n            [[[4.8872e-14]],\n    \n             [[4.4878e-14]],\n    \n             [[4.4074e-14]],\n    \n             ...,\n    \n             [[6.5050e-14]],\n    \n             [[5.2427e-14]],\n    \n             [[4.4440e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[1.3199e-12]],\n    \n             [[1.0273e-12]],\n    \n             [[8.8343e-13]],\n    \n             ...,\n    \n             [[9.8305e-13]],\n    \n             [[8.0819e-13]],\n    \n             [[9.0185e-13]]],\n    \n    \n            [[[5.2051e-13]],\n    \n             [[3.8159e-13]],\n    \n             [[5.4123e-13]],\n    \n             ...,\n    \n             [[8.9348e-13]],\n    \n             [[4.2836e-13]],\n    \n             [[6.3548e-13]]],\n    \n    \n            [[[3.6279e-13]],\n    \n             [[3.1872e-13]],\n    \n             [[3.3142e-13]],\n    \n             ...,\n    \n             [[7.7728e-13]],\n    \n             [[3.7118e-13]],\n    \n             [[4.9986e-13]]]])},\n   118: {'exp_avg': tensor([[[[-2.3349e-08]],\n    \n             [[ 2.8175e-07]],\n    \n             [[-1.5950e-07]],\n    \n             ...,\n    \n             [[-2.5113e-07]],\n    \n             [[-2.4325e-08]],\n    \n             [[-4.0749e-08]]],\n    \n    \n            [[[ 1.7238e-07]],\n    \n             [[-2.0822e-07]],\n    \n             [[ 4.5409e-09]],\n    \n             ...,\n    \n             [[-7.6013e-07]],\n    \n             [[ 9.3418e-08]],\n    \n             [[-3.9980e-07]]],\n    \n    \n            [[[-2.0012e-07]],\n    \n             [[ 3.1072e-08]],\n    \n             [[-1.2530e-07]],\n    \n             ...,\n    \n             [[ 4.2183e-07]],\n    \n             [[-6.6848e-08]],\n    \n             [[ 2.6068e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[-5.6027e-08]],\n    \n             [[ 5.5886e-07]],\n    \n             [[ 3.2912e-07]],\n    \n             ...,\n    \n             [[-4.7844e-07]],\n    \n             [[ 1.3965e-07]],\n    \n             [[ 2.7155e-07]]],\n    \n    \n            [[[-4.1467e-10]],\n    \n             [[-1.3077e-07]],\n    \n             [[-6.0533e-08]],\n    \n             ...,\n    \n             [[-1.6392e-07]],\n    \n             [[ 6.7345e-08]],\n    \n             [[ 3.7069e-10]]],\n    \n    \n            [[[ 1.1773e-07]],\n    \n             [[ 1.0843e-09]],\n    \n             [[ 5.8279e-08]],\n    \n             ...,\n    \n             [[ 2.4151e-07]],\n    \n             [[ 4.3055e-08]],\n    \n             [[-8.0928e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.2512e-13]],\n    \n             [[6.3406e-13]],\n    \n             [[1.3550e-13]],\n    \n             ...,\n    \n             [[1.3106e-12]],\n    \n             [[4.7694e-13]],\n    \n             [[1.1414e-12]]],\n    \n    \n            [[[2.6211e-13]],\n    \n             [[1.1141e-12]],\n    \n             [[5.3660e-13]],\n    \n             ...,\n    \n             [[1.8276e-12]],\n    \n             [[7.6368e-13]],\n    \n             [[1.4608e-12]]],\n    \n    \n            [[[3.8682e-13]],\n    \n             [[5.0466e-13]],\n    \n             [[1.1532e-13]],\n    \n             ...,\n    \n             [[1.3984e-12]],\n    \n             [[4.2312e-13]],\n    \n             [[6.9219e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[1.0875e-12]],\n    \n             [[2.5230e-12]],\n    \n             [[9.9235e-13]],\n    \n             ...,\n    \n             [[5.2386e-12]],\n    \n             [[2.8935e-12]],\n    \n             [[3.8062e-12]]],\n    \n    \n            [[[2.6707e-13]],\n    \n             [[4.7633e-13]],\n    \n             [[1.9999e-13]],\n    \n             ...,\n    \n             [[1.1048e-12]],\n    \n             [[3.8672e-13]],\n    \n             [[6.8775e-13]]],\n    \n    \n            [[[3.2876e-13]],\n    \n             [[3.7979e-13]],\n    \n             [[1.4914e-13]],\n    \n             ...,\n    \n             [[1.1415e-12]],\n    \n             [[5.1356e-13]],\n    \n             [[4.9834e-13]]]])},\n   119: {'exp_avg': tensor([[[[ 2.7304e-08, -1.7845e-08,  6.0040e-08],\n              [ 8.6507e-08, -1.5309e-08,  1.0202e-07],\n              [ 1.0877e-07,  5.7129e-08,  1.1721e-07]],\n    \n             [[-2.6837e-08, -6.2378e-08, -1.9550e-08],\n              [-1.5886e-07, -1.1502e-07, -1.6513e-07],\n              [-2.0441e-07, -1.5507e-07, -4.8199e-08]],\n    \n             [[ 6.0998e-08,  1.1755e-07,  1.1782e-07],\n              [ 1.5482e-07,  1.7975e-07,  8.8623e-08],\n              [ 1.5993e-07,  1.0078e-07,  1.0899e-07]],\n    \n             ...,\n    \n             [[ 2.7206e-08,  1.2645e-07,  1.2116e-07],\n              [ 2.1566e-07,  4.6702e-08,  9.0679e-08],\n              [-6.7134e-08, -1.4004e-07, -5.1259e-08]],\n    \n             [[-1.0464e-08,  7.2891e-08,  9.1038e-08],\n              [ 7.2959e-10,  1.9150e-07,  1.9493e-08],\n              [-8.9437e-08,  1.9265e-08, -1.6473e-08]],\n    \n             [[-1.1674e-07, -1.6948e-07, -5.4582e-08],\n              [-1.9624e-08, -5.4674e-08,  5.2548e-09],\n              [ 1.4544e-07, -4.2280e-08,  1.5647e-07]]],\n    \n    \n            [[[ 2.5008e-07,  2.0020e-07,  1.5119e-07],\n              [ 1.2095e-07,  2.8056e-07,  8.6652e-08],\n              [ 5.6905e-08,  1.7496e-07,  1.1431e-07]],\n    \n             [[ 1.2794e-07,  8.3350e-08,  1.0773e-07],\n              [ 1.8742e-07,  4.8035e-08,  1.6982e-07],\n              [ 4.4353e-08, -1.2285e-08,  1.0527e-07]],\n    \n             [[ 1.5941e-07,  4.8313e-08,  9.0193e-08],\n              [ 1.7363e-07,  9.4277e-08,  1.8587e-07],\n              [ 1.1075e-07,  1.3441e-08,  2.6485e-07]],\n    \n             ...,\n    \n             [[-1.0587e-07, -2.6828e-10,  1.0749e-07],\n              [ 7.7169e-09, -2.2991e-08,  5.2717e-08],\n              [ 6.9467e-08,  9.2261e-08,  3.3701e-08]],\n    \n             [[ 2.0744e-07,  8.7848e-08,  1.9204e-07],\n              [ 1.1873e-07, -5.0696e-08,  1.2725e-07],\n              [ 5.3605e-08, -5.7946e-08,  7.9187e-08]],\n    \n             [[ 1.6494e-07,  1.1108e-07,  1.5493e-07],\n              [ 4.8784e-08,  3.0881e-08,  5.9093e-08],\n              [ 5.5819e-08,  3.5223e-08,  1.5892e-07]]],\n    \n    \n            [[[-9.5643e-08, -1.6839e-07, -7.4611e-08],\n              [ 1.0531e-07, -4.8693e-08,  5.9275e-08],\n              [-1.9922e-07, -2.2001e-07, -1.5570e-07]],\n    \n             [[-8.6862e-08,  1.3875e-08, -8.2525e-09],\n              [ 1.3155e-07,  5.0553e-08, -7.8692e-08],\n              [-1.6995e-07, -2.4366e-07, -2.5786e-07]],\n    \n             [[-1.3200e-07, -2.9180e-07, -2.0500e-07],\n              [-1.0236e-07, -1.5223e-07, -5.0902e-09],\n              [-8.1519e-08, -1.0243e-07,  2.6211e-08]],\n    \n             ...,\n    \n             [[ 8.1358e-09,  4.9199e-09, -1.4924e-07],\n              [ 1.3070e-07,  2.8121e-08, -2.0264e-08],\n              [ 2.0147e-07,  1.2786e-08, -5.1719e-08]],\n    \n             [[-1.0091e-07, -1.7727e-07, -2.5467e-09],\n              [ 1.5026e-08, -1.7135e-07,  4.5231e-09],\n              [-2.2924e-07, -2.4405e-07, -2.4654e-07]],\n    \n             [[-1.9711e-07, -9.6917e-08, -1.3675e-07],\n              [-1.2371e-08, -1.4552e-07, -2.3536e-07],\n              [-1.8868e-07, -2.0518e-07, -1.8702e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[ 4.2745e-08,  1.8923e-07,  1.8218e-07],\n              [ 1.5515e-08,  1.4105e-07,  9.6690e-08],\n              [ 1.8167e-07,  1.5657e-07,  2.2372e-07]],\n    \n             [[ 1.9242e-07,  1.9783e-07,  4.4633e-08],\n              [ 1.6416e-07,  1.0413e-07,  2.6202e-08],\n              [ 1.6671e-08, -4.2150e-08,  7.7876e-08]],\n    \n             [[-1.5139e-07,  7.0201e-08, -5.1494e-08],\n              [-2.5371e-07, -1.2661e-08,  7.0235e-08],\n              [-1.9410e-07, -2.7842e-08, -1.1958e-07]],\n    \n             ...,\n    \n             [[ 9.8380e-08,  1.3460e-07,  1.4626e-07],\n              [-1.0976e-07, -3.0637e-08,  1.8838e-08],\n              [ 4.5285e-08,  2.6968e-08,  7.3240e-08]],\n    \n             [[-3.2583e-08,  2.0078e-07,  1.3215e-07],\n              [-5.7522e-08,  1.7134e-07,  1.3387e-07],\n              [ 1.1759e-07,  1.3255e-07,  5.5115e-08]],\n    \n             [[-2.2548e-07, -1.9490e-07, -3.7134e-08],\n              [-3.2354e-07, -2.6172e-07, -2.4056e-07],\n              [-2.0807e-07, -1.6260e-07, -2.4646e-07]]],\n    \n    \n            [[[-8.4458e-08, -4.7891e-08,  1.6539e-07],\n              [-2.2473e-07, -1.9284e-07,  7.0094e-09],\n              [-1.6971e-07, -1.9166e-07,  1.0483e-07]],\n    \n             [[-5.6466e-09, -4.4050e-08, -7.5307e-08],\n              [-1.6113e-07,  9.9059e-08,  3.6241e-08],\n              [-2.9093e-07, -1.3285e-07, -1.0093e-07]],\n    \n             [[-1.6281e-07,  1.0528e-07,  9.6164e-08],\n              [-4.7651e-08,  1.9189e-07,  1.8694e-07],\n              [-3.6742e-08,  1.6642e-07,  1.0739e-07]],\n    \n             ...,\n    \n             [[ 1.2980e-08,  9.6444e-08,  6.0930e-08],\n              [-1.4431e-07, -8.6299e-08, -3.2526e-08],\n              [-3.0344e-08,  5.3887e-08,  1.7656e-08]],\n    \n             [[-1.2734e-07,  9.9311e-08,  3.1654e-08],\n              [-1.6094e-07,  3.2498e-08,  1.5885e-08],\n              [-2.4933e-07, -3.6595e-08, -2.6308e-08]],\n    \n             [[-9.7370e-08,  3.2323e-08,  1.4113e-07],\n              [-2.6224e-07, -2.1174e-07, -1.3354e-07],\n              [-1.7519e-07, -1.1065e-07, -8.9384e-08]]],\n    \n    \n            [[[-7.7701e-08, -1.0609e-07, -2.9420e-07],\n              [-1.3382e-07, -1.0460e-07, -1.9408e-07],\n              [-2.9358e-07, -1.0620e-07, -2.9548e-07]],\n    \n             [[-1.1916e-07,  8.1380e-08,  1.4294e-07],\n              [ 1.2648e-07,  1.5582e-07,  1.7691e-07],\n              [ 6.6508e-08,  1.8120e-07,  1.5555e-07]],\n    \n             [[-1.8302e-08, -1.5064e-07, -1.3509e-08],\n              [-1.2962e-07, -1.1880e-07,  3.8505e-08],\n              [ 2.7907e-09, -5.9690e-08,  4.1840e-08]],\n    \n             ...,\n    \n             [[-2.7604e-08,  3.0942e-09,  1.3909e-07],\n              [ 9.4282e-09,  2.3421e-08,  1.6549e-07],\n              [-1.0963e-07,  5.7204e-08,  1.0202e-07]],\n    \n             [[-1.7741e-07, -5.3396e-08,  1.4635e-08],\n              [-3.5967e-08,  2.2404e-08,  8.4576e-08],\n              [ 2.7911e-08, -2.6615e-09,  1.0815e-07]],\n    \n             [[ 1.9033e-08, -4.0826e-08, -5.6803e-08],\n              [ 9.0973e-08,  7.4234e-08,  2.5899e-08],\n              [-1.1141e-09,  1.0094e-08,  8.1967e-08]]]]),\n    'exp_avg_sq': tensor([[[[3.2536e-13, 3.1449e-13, 3.3165e-13],\n              [4.1893e-13, 3.7271e-13, 3.6859e-13],\n              [5.0116e-13, 5.0911e-13, 4.5383e-13]],\n    \n             [[3.3500e-13, 3.3194e-13, 2.6760e-13],\n              [4.0765e-13, 4.3356e-13, 3.6991e-13],\n              [4.0091e-13, 4.6571e-13, 4.4292e-13]],\n    \n             [[2.5511e-13, 2.4881e-13, 2.4526e-13],\n              [3.0818e-13, 2.9926e-13, 2.7198e-13],\n              [3.4434e-13, 3.2036e-13, 2.7756e-13]],\n    \n             ...,\n    \n             [[1.5230e-13, 1.6500e-13, 1.8569e-13],\n              [2.6307e-13, 2.7968e-13, 2.5506e-13],\n              [2.7137e-13, 3.0540e-13, 2.8882e-13]],\n    \n             [[2.8170e-13, 2.6513e-13, 2.4296e-13],\n              [3.3134e-13, 3.3235e-13, 3.0075e-13],\n              [3.1397e-13, 3.2603e-13, 3.2242e-13]],\n    \n             [[2.6097e-13, 2.8803e-13, 3.2604e-13],\n              [2.7039e-13, 2.6803e-13, 2.8875e-13],\n              [3.4246e-13, 3.3944e-13, 3.1266e-13]]],\n    \n    \n            [[[2.7351e-13, 2.8113e-13, 2.9136e-13],\n              [2.7374e-13, 3.0566e-13, 3.0584e-13],\n              [2.8238e-13, 3.0901e-13, 3.1984e-13]],\n    \n             [[2.0207e-13, 1.9809e-13, 2.0415e-13],\n              [2.0839e-13, 2.4568e-13, 2.2166e-13],\n              [2.1726e-13, 2.4810e-13, 2.5013e-13]],\n    \n             [[1.8678e-13, 1.8738e-13, 1.8026e-13],\n              [1.9359e-13, 2.0700e-13, 1.8366e-13],\n              [1.8698e-13, 1.9900e-13, 1.8591e-13]],\n    \n             ...,\n    \n             [[1.0796e-13, 1.1245e-13, 1.2769e-13],\n              [1.3136e-13, 1.5458e-13, 1.7105e-13],\n              [1.3996e-13, 1.6041e-13, 1.7372e-13]],\n    \n             [[1.9046e-13, 1.9048e-13, 1.8638e-13],\n              [1.9860e-13, 2.2226e-13, 2.1036e-13],\n              [1.9439e-13, 2.0438e-13, 1.9847e-13]],\n    \n             [[1.6763e-13, 1.8265e-13, 1.8910e-13],\n              [1.6885e-13, 1.9187e-13, 1.8740e-13],\n              [1.7893e-13, 1.9572e-13, 2.0417e-13]]],\n    \n    \n            [[[6.0117e-13, 6.7149e-13, 6.8480e-13],\n              [6.4919e-13, 7.1882e-13, 7.1542e-13],\n              [6.3087e-13, 7.2416e-13, 7.4946e-13]],\n    \n             [[4.3511e-13, 4.4998e-13, 4.5493e-13],\n              [4.4828e-13, 4.6176e-13, 4.3294e-13],\n              [4.4541e-13, 4.4086e-13, 4.2377e-13]],\n    \n             [[3.9007e-13, 4.2274e-13, 4.0656e-13],\n              [4.2118e-13, 4.2343e-13, 4.1386e-13],\n              [4.1070e-13, 4.0258e-13, 3.9708e-13]],\n    \n             ...,\n    \n             [[2.2089e-13, 2.7261e-13, 2.8829e-13],\n              [2.6021e-13, 3.4649e-13, 3.5750e-13],\n              [2.7642e-13, 3.0782e-13, 3.3456e-13]],\n    \n             [[3.7496e-13, 3.9371e-13, 3.9252e-13],\n              [3.9371e-13, 4.0509e-13, 3.9325e-13],\n              [3.8783e-13, 3.9870e-13, 3.7679e-13]],\n    \n             [[4.3224e-13, 5.0564e-13, 4.8622e-13],\n              [4.5883e-13, 5.1688e-13, 5.2848e-13],\n              [4.8390e-13, 5.2916e-13, 5.5358e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[3.0505e-13, 3.4653e-13, 3.4667e-13],\n              [3.7655e-13, 3.6113e-13, 3.2634e-13],\n              [4.2062e-13, 4.3397e-13, 3.7055e-13]],\n    \n             [[3.5351e-13, 3.6802e-13, 3.5808e-13],\n              [3.4354e-13, 4.7364e-13, 4.6395e-13],\n              [2.9057e-13, 3.5304e-13, 4.0899e-13]],\n    \n             [[2.5465e-13, 2.0990e-13, 2.0847e-13],\n              [2.6350e-13, 2.3475e-13, 2.4312e-13],\n              [2.6145e-13, 2.6140e-13, 2.6593e-13]],\n    \n             ...,\n    \n             [[3.9139e-13, 4.3152e-13, 4.0410e-13],\n              [4.3385e-13, 5.1743e-13, 5.0906e-13],\n              [3.7469e-13, 4.4881e-13, 4.8293e-13]],\n    \n             [[2.9969e-13, 3.0023e-13, 2.8189e-13],\n              [3.1126e-13, 3.2549e-13, 2.9537e-13],\n              [2.8213e-13, 3.1130e-13, 3.1811e-13]],\n    \n             [[2.5747e-13, 2.3754e-13, 2.2511e-13],\n              [2.9999e-13, 2.4024e-13, 2.0289e-13],\n              [3.2636e-13, 2.9906e-13, 2.7446e-13]]],\n    \n    \n            [[[3.6984e-13, 4.1189e-13, 4.1486e-13],\n              [3.9226e-13, 4.6702e-13, 4.7002e-13],\n              [3.5097e-13, 4.2525e-13, 4.0835e-13]],\n    \n             [[2.9317e-13, 2.9263e-13, 2.8737e-13],\n              [2.4915e-13, 2.1056e-13, 2.6607e-13],\n              [3.6332e-13, 3.5901e-13, 3.3461e-13]],\n    \n             [[2.5523e-13, 2.4200e-13, 2.4783e-13],\n              [2.5903e-13, 2.5013e-13, 2.6474e-13],\n              [2.8493e-13, 2.8950e-13, 2.7827e-13]],\n    \n             ...,\n    \n             [[1.9839e-13, 2.3908e-13, 2.4346e-13],\n              [2.3581e-13, 3.1782e-13, 3.0177e-13],\n              [2.1457e-13, 2.6768e-13, 2.7145e-13]],\n    \n             [[2.6454e-13, 2.8095e-13, 2.9199e-13],\n              [2.8182e-13, 3.0867e-13, 3.2491e-13],\n              [3.1197e-13, 3.6554e-13, 3.4813e-13]],\n    \n             [[2.9156e-13, 3.3515e-13, 3.2709e-13],\n              [3.1967e-13, 3.8659e-13, 3.5481e-13],\n              [3.0637e-13, 3.3614e-13, 3.4308e-13]]],\n    \n    \n            [[[2.6550e-13, 2.9907e-13, 3.1060e-13],\n              [2.6369e-13, 3.3160e-13, 3.4631e-13],\n              [2.7146e-13, 3.3748e-13, 3.5838e-13]],\n    \n             [[2.2992e-13, 2.7329e-13, 2.6630e-13],\n              [2.8444e-13, 3.0746e-13, 2.7225e-13],\n              [2.6694e-13, 2.6609e-13, 2.2857e-13]],\n    \n             [[1.7889e-13, 2.0939e-13, 2.1114e-13],\n              [2.0693e-13, 2.3967e-13, 2.2099e-13],\n              [2.0914e-13, 2.3624e-13, 2.2218e-13]],\n    \n             ...,\n    \n             [[1.3268e-13, 1.6355e-13, 1.6529e-13],\n              [1.8056e-13, 2.3338e-13, 2.1837e-13],\n              [1.8203e-13, 2.0498e-13, 2.2071e-13]],\n    \n             [[1.4854e-13, 1.4521e-13, 1.6151e-13],\n              [1.4939e-13, 1.6064e-13, 1.8779e-13],\n              [1.5044e-13, 1.7276e-13, 1.9434e-13]],\n    \n             [[1.9298e-13, 2.1031e-13, 2.0091e-13],\n              [2.1804e-13, 2.4433e-13, 2.3639e-13],\n              [2.3658e-13, 2.8663e-13, 2.7317e-13]]]])},\n   120: {'exp_avg': tensor([[[[-1.9140e-07]],\n    \n             [[-1.4383e-07]],\n    \n             [[-1.9792e-07]],\n    \n             ...,\n    \n             [[-2.3382e-07]],\n    \n             [[-1.0449e-07]],\n    \n             [[-1.0246e-07]]],\n    \n    \n            [[[ 3.2613e-08]],\n    \n             [[-1.3344e-07]],\n    \n             [[-1.4745e-08]],\n    \n             ...,\n    \n             [[ 2.5870e-08]],\n    \n             [[-1.0597e-07]],\n    \n             [[ 1.2159e-07]]],\n    \n    \n            [[[ 1.6318e-07]],\n    \n             [[ 1.0164e-07]],\n    \n             [[-1.8695e-07]],\n    \n             ...,\n    \n             [[ 5.5485e-08]],\n    \n             [[-7.9037e-08]],\n    \n             [[-1.9471e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[ 3.4230e-07]],\n    \n             [[ 7.6212e-08]],\n    \n             [[-1.3825e-07]],\n    \n             ...,\n    \n             [[ 1.7151e-07]],\n    \n             [[-1.2183e-07]],\n    \n             [[-6.0366e-08]]],\n    \n    \n            [[[-2.5179e-07]],\n    \n             [[-7.1763e-08]],\n    \n             [[ 2.4044e-07]],\n    \n             ...,\n    \n             [[-1.2186e-07]],\n    \n             [[-2.6087e-07]],\n    \n             [[ 2.5904e-08]]],\n    \n    \n            [[[-4.1769e-08]],\n    \n             [[ 1.2938e-08]],\n    \n             [[-1.1850e-09]],\n    \n             ...,\n    \n             [[-1.7211e-09]],\n    \n             [[ 6.9254e-09]],\n    \n             [[ 9.8271e-09]]]]),\n    'exp_avg_sq': tensor([[[[4.9934e-13]],\n    \n             [[7.0030e-13]],\n    \n             [[7.6025e-13]],\n    \n             ...,\n    \n             [[4.3846e-13]],\n    \n             [[4.6929e-13]],\n    \n             [[4.6619e-13]]],\n    \n    \n            [[[2.1038e-13]],\n    \n             [[2.2589e-13]],\n    \n             [[3.5686e-13]],\n    \n             ...,\n    \n             [[1.4965e-13]],\n    \n             [[1.8908e-13]],\n    \n             [[1.6370e-13]]],\n    \n    \n            [[[1.7070e-13]],\n    \n             [[2.5144e-13]],\n    \n             [[2.5521e-13]],\n    \n             ...,\n    \n             [[1.1798e-13]],\n    \n             [[1.8063e-13]],\n    \n             [[1.3567e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[3.7573e-13]],\n    \n             [[4.1025e-13]],\n    \n             [[5.5555e-13]],\n    \n             ...,\n    \n             [[2.6572e-13]],\n    \n             [[3.0226e-13]],\n    \n             [[2.5622e-13]]],\n    \n    \n            [[[8.6670e-13]],\n    \n             [[1.1931e-12]],\n    \n             [[1.6613e-12]],\n    \n             ...,\n    \n             [[7.2499e-13]],\n    \n             [[1.1272e-12]],\n    \n             [[8.9726e-13]]],\n    \n    \n            [[[5.1658e-15]],\n    \n             [[6.2060e-15]],\n    \n             [[9.8550e-15]],\n    \n             ...,\n    \n             [[4.1723e-15]],\n    \n             [[5.5908e-15]],\n    \n             [[4.4037e-15]]]])},\n   121: {'exp_avg': tensor([[[[ 6.0815e-08]],\n    \n             [[ 1.6342e-07]],\n    \n             [[ 1.7642e-08]],\n    \n             ...,\n    \n             [[ 4.4139e-08]],\n    \n             [[-2.8460e-08]],\n    \n             [[ 4.3998e-08]]],\n    \n    \n            [[[ 8.0679e-08]],\n    \n             [[-5.8632e-08]],\n    \n             [[ 1.0667e-07]],\n    \n             ...,\n    \n             [[-1.4281e-07]],\n    \n             [[ 2.2056e-07]],\n    \n             [[-1.1102e-07]]],\n    \n    \n            [[[-2.6391e-09]],\n    \n             [[-3.2453e-08]],\n    \n             [[ 1.5750e-07]],\n    \n             ...,\n    \n             [[ 2.4326e-07]],\n    \n             [[ 1.9784e-07]],\n    \n             [[ 4.0088e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-5.9476e-08]],\n    \n             [[ 6.8103e-08]],\n    \n             [[ 3.2840e-08]],\n    \n             ...,\n    \n             [[-6.7312e-08]],\n    \n             [[ 2.1354e-09]],\n    \n             [[ 8.2633e-08]]],\n    \n    \n            [[[-4.3414e-08]],\n    \n             [[ 2.3826e-07]],\n    \n             [[-2.2070e-08]],\n    \n             ...,\n    \n             [[-5.2655e-07]],\n    \n             [[ 6.1502e-08]],\n    \n             [[ 2.0515e-08]]],\n    \n    \n            [[[ 5.2701e-08]],\n    \n             [[-6.9956e-09]],\n    \n             [[-7.8111e-09]],\n    \n             ...,\n    \n             [[-2.8665e-07]],\n    \n             [[-1.6294e-07]],\n    \n             [[-2.2911e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.3686e-13]],\n    \n             [[2.0391e-13]],\n    \n             [[1.0799e-13]],\n    \n             ...,\n    \n             [[5.6288e-13]],\n    \n             [[3.5412e-13]],\n    \n             [[1.3307e-13]]],\n    \n    \n            [[[1.5166e-13]],\n    \n             [[2.9387e-13]],\n    \n             [[7.0524e-14]],\n    \n             ...,\n    \n             [[6.4568e-13]],\n    \n             [[3.1928e-13]],\n    \n             [[3.2291e-13]]],\n    \n    \n            [[[1.4914e-13]],\n    \n             [[2.5202e-13]],\n    \n             [[8.9210e-14]],\n    \n             ...,\n    \n             [[5.8639e-13]],\n    \n             [[2.5532e-13]],\n    \n             [[1.6316e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[1.3863e-13]],\n    \n             [[2.3544e-13]],\n    \n             [[6.5636e-14]],\n    \n             ...,\n    \n             [[5.9830e-13]],\n    \n             [[1.8806e-13]],\n    \n             [[1.8519e-13]]],\n    \n    \n            [[[3.6392e-13]],\n    \n             [[1.0367e-12]],\n    \n             [[2.3030e-13]],\n    \n             ...,\n    \n             [[1.6694e-12]],\n    \n             [[8.5668e-13]],\n    \n             [[1.0503e-12]]],\n    \n    \n            [[[2.0141e-13]],\n    \n             [[2.9281e-13]],\n    \n             [[6.9482e-14]],\n    \n             ...,\n    \n             [[6.8748e-13]],\n    \n             [[3.0444e-13]],\n    \n             [[3.1749e-13]]]])},\n   122: {'exp_avg': tensor([[[[ 2.7488e-08]],\n    \n             [[ 2.1704e-09]],\n    \n             [[-1.6530e-08]],\n    \n             ...,\n    \n             [[ 5.0617e-08]],\n    \n             [[ 6.9905e-08]],\n    \n             [[-1.9890e-09]]],\n    \n    \n            [[[ 1.2035e-07]],\n    \n             [[ 7.5436e-08]],\n    \n             [[ 1.9178e-08]],\n    \n             ...,\n    \n             [[ 1.3499e-07]],\n    \n             [[-9.8260e-08]],\n    \n             [[-1.1812e-08]]],\n    \n    \n            [[[-5.8728e-08]],\n    \n             [[ 5.8978e-08]],\n    \n             [[-7.9282e-08]],\n    \n             ...,\n    \n             [[ 6.8809e-08]],\n    \n             [[ 1.6823e-07]],\n    \n             [[ 1.6939e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 7.5470e-09]],\n    \n             [[-3.6635e-08]],\n    \n             [[-6.2225e-08]],\n    \n             ...,\n    \n             [[-1.0835e-07]],\n    \n             [[ 1.0438e-07]],\n    \n             [[-2.8229e-08]]],\n    \n    \n            [[[-5.2500e-08]],\n    \n             [[ 3.4225e-08]],\n    \n             [[-7.2283e-09]],\n    \n             ...,\n    \n             [[-7.1615e-08]],\n    \n             [[ 1.7980e-08]],\n    \n             [[-1.0480e-07]]],\n    \n    \n            [[[-9.0914e-09]],\n    \n             [[-3.3317e-08]],\n    \n             [[-1.3137e-08]],\n    \n             ...,\n    \n             [[ 4.1487e-08]],\n    \n             [[ 9.2475e-08]],\n    \n             [[ 4.3768e-08]]]]),\n    'exp_avg_sq': tensor([[[[8.2340e-14]],\n    \n             [[6.7834e-14]],\n    \n             [[3.3210e-14]],\n    \n             ...,\n    \n             [[6.0410e-14]],\n    \n             [[1.3426e-13]],\n    \n             [[4.3243e-14]]],\n    \n    \n            [[[1.9180e-13]],\n    \n             [[1.4052e-13]],\n    \n             [[1.8918e-13]],\n    \n             ...,\n    \n             [[1.5980e-13]],\n    \n             [[2.8243e-13]],\n    \n             [[1.1700e-13]]],\n    \n    \n            [[[7.5617e-14]],\n    \n             [[5.6121e-14]],\n    \n             [[2.9656e-14]],\n    \n             ...,\n    \n             [[6.2434e-14]],\n    \n             [[1.7382e-13]],\n    \n             [[5.2167e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[1.3539e-13]],\n    \n             [[9.6776e-14]],\n    \n             [[6.9580e-14]],\n    \n             ...,\n    \n             [[5.3029e-14]],\n    \n             [[1.8248e-13]],\n    \n             [[6.1709e-14]]],\n    \n    \n            [[[7.2142e-14]],\n    \n             [[8.4302e-14]],\n    \n             [[8.0929e-14]],\n    \n             ...,\n    \n             [[6.6251e-14]],\n    \n             [[9.6535e-14]],\n    \n             [[6.1757e-14]]],\n    \n    \n            [[[1.1060e-13]],\n    \n             [[8.5395e-14]],\n    \n             [[1.3503e-13]],\n    \n             ...,\n    \n             [[1.0108e-13]],\n    \n             [[1.4303e-13]],\n    \n             [[7.1289e-14]]]])},\n   123: {'exp_avg': tensor([[[[-3.0907e-10, -3.6331e-08, -1.8577e-08],\n              [ 1.7902e-08, -8.4584e-09, -3.0159e-08],\n              [-5.5588e-08, -5.1111e-08, -2.8048e-08]],\n    \n             [[-2.8706e-08,  6.4260e-08,  2.7459e-08],\n              [ 2.4302e-08,  6.8806e-08,  5.4823e-08],\n              [-3.0821e-08,  2.5580e-08, -2.6824e-08]],\n    \n             [[-2.4455e-08,  3.2045e-08, -2.4588e-08],\n              [-7.1647e-08, -4.5964e-09, -6.7150e-08],\n              [-8.5677e-08, -6.9179e-08, -8.4901e-08]],\n    \n             ...,\n    \n             [[ 7.4366e-11,  1.8310e-08,  5.9126e-10],\n              [ 1.2283e-08,  8.1539e-08,  2.7303e-08],\n              [-4.2905e-08, -7.9014e-08,  9.6168e-09]],\n    \n             [[ 5.9600e-08, -3.5130e-08, -1.1228e-08],\n              [ 5.4841e-08,  2.2963e-08,  1.5167e-08],\n              [ 8.1889e-08, -3.6637e-09,  2.3691e-10]],\n    \n             [[-5.1275e-09,  8.2767e-08,  6.5085e-08],\n              [ 4.2092e-09,  6.7400e-08,  1.0073e-07],\n              [ 6.8547e-08,  6.2086e-08,  4.7735e-08]]],\n    \n    \n            [[[ 6.7456e-08,  1.4122e-07,  7.5895e-08],\n              [-6.8762e-09,  5.8340e-09,  6.2488e-08],\n              [-4.2448e-08,  1.1206e-08,  4.0512e-08]],\n    \n             [[-1.0209e-07, -1.0564e-07, -1.2685e-07],\n              [-1.4860e-07, -1.8659e-07, -4.9425e-08],\n              [-1.2094e-07, -1.1458e-08,  1.0632e-07]],\n    \n             [[ 1.7028e-08,  6.2623e-08,  6.9432e-08],\n              [ 1.3805e-08, -1.1378e-08, -2.1410e-08],\n              [ 3.1563e-08,  8.3090e-08,  5.3431e-08]],\n    \n             ...,\n    \n             [[-6.3191e-08, -1.0080e-07, -4.4596e-08],\n              [-1.2844e-07, -9.5510e-08, -5.6532e-08],\n              [-1.1471e-07, -8.4979e-08, -1.3049e-07]],\n    \n             [[-8.3459e-09,  1.3931e-08,  3.1700e-08],\n              [-1.4992e-09,  2.3889e-08,  2.7737e-08],\n              [ 5.1129e-08,  3.3920e-08,  4.9427e-08]],\n    \n             [[-7.1403e-08, -6.8211e-10, -1.7033e-08],\n              [-6.2329e-08, -1.6745e-08, -8.4543e-08],\n              [-9.2188e-08, -1.2839e-08, -4.6641e-08]]],\n    \n    \n            [[[ 4.1564e-08,  5.8206e-08,  7.6063e-08],\n              [ 7.6267e-08, -7.4593e-08,  1.6200e-08],\n              [ 8.9391e-08, -7.7478e-09,  1.1182e-07]],\n    \n             [[ 9.4524e-08,  1.2466e-07,  3.0600e-07],\n              [ 5.6544e-08, -1.6571e-08, -1.7589e-08],\n              [ 8.6131e-09, -1.4970e-07,  5.8614e-08]],\n    \n             [[ 9.2596e-08,  2.3589e-08,  8.2638e-08],\n              [ 4.7532e-08, -2.3829e-08,  2.7388e-08],\n              [ 1.0588e-08, -1.1666e-07,  6.9463e-08]],\n    \n             ...,\n    \n             [[ 3.3683e-08,  2.9284e-08,  7.3756e-08],\n              [-6.2722e-08, -9.2891e-08, -2.4590e-08],\n              [-1.0149e-07, -1.7860e-07, -1.1803e-07]],\n    \n             [[ 4.0086e-08,  3.6685e-08,  8.6951e-08],\n              [ 4.4067e-08,  1.0247e-08,  5.3843e-08],\n              [ 4.5008e-08,  2.7434e-08,  7.0593e-08]],\n    \n             [[ 9.1896e-09,  2.7514e-08, -3.9560e-08],\n              [-3.3021e-08, -7.6827e-08,  2.4893e-08],\n              [-4.3471e-08, -4.1452e-08,  2.6028e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-9.7457e-09, -1.0726e-07,  6.4908e-09],\n              [ 6.2865e-08, -4.9290e-08,  2.4090e-08],\n              [-1.6412e-08, -5.0627e-08,  4.5689e-09]],\n    \n             [[ 1.1386e-07,  2.6351e-08,  3.1879e-08],\n              [ 1.6274e-07,  3.0900e-08, -1.7845e-08],\n              [-9.4861e-09, -3.1495e-08, -3.9565e-08]],\n    \n             [[-3.3833e-08, -6.6070e-08, -5.1182e-08],\n              [-5.0835e-08, -9.7178e-08, -6.3445e-08],\n              [-7.5753e-08, -1.2751e-07, -7.8162e-08]],\n    \n             ...,\n    \n             [[ 2.5607e-08,  1.5323e-07,  5.9668e-08],\n              [ 1.0383e-07,  1.0937e-07,  1.1261e-07],\n              [ 1.3693e-07,  1.4074e-07,  1.0584e-07]],\n    \n             [[-6.9618e-11,  2.4485e-08,  9.1340e-09],\n              [ 3.4186e-08, -2.5303e-09, -1.2065e-08],\n              [-1.3369e-08, -3.8272e-08, -2.3407e-08]],\n    \n             [[-3.7478e-08, -2.0558e-08,  4.8173e-08],\n              [ 1.6641e-08,  5.0464e-08,  3.4689e-08],\n              [ 6.1126e-08, -1.3693e-08,  5.1205e-08]]],\n    \n    \n            [[[ 3.6178e-08, -1.3503e-08,  3.6343e-08],\n              [ 6.6037e-08,  6.3086e-08, -2.7208e-09],\n              [-1.7240e-08,  1.3459e-08, -1.6075e-08]],\n    \n             [[-9.3944e-09, -8.7084e-08,  3.3551e-08],\n              [-6.4142e-09, -9.7359e-08,  5.1522e-08],\n              [-1.2131e-07, -1.4850e-07, -9.5163e-08]],\n    \n             [[-1.0601e-07, -1.6630e-07, -1.0200e-07],\n              [-8.7137e-08, -1.3337e-07, -1.1056e-07],\n              [-1.5882e-07, -2.1253e-07, -1.6390e-07]],\n    \n             ...,\n    \n             [[-5.0401e-09, -1.4853e-08, -1.8888e-08],\n              [ 1.5337e-07,  7.0422e-08,  7.7689e-08],\n              [ 4.1236e-08, -2.0381e-08, -2.8199e-08]],\n    \n             [[-1.0572e-08,  2.7048e-08,  7.5276e-08],\n              [ 9.6901e-08,  8.9370e-08,  9.9700e-08],\n              [ 5.9444e-08,  6.3758e-08,  9.1668e-09]],\n    \n             [[-7.0902e-08,  2.9880e-08,  9.2924e-08],\n              [ 9.1593e-09, -1.1723e-07,  6.9198e-08],\n              [ 3.0326e-08, -1.0318e-07, -6.6626e-08]]],\n    \n    \n            [[[-1.1337e-07, -3.1210e-08,  2.6801e-09],\n              [-9.1983e-08, -4.2656e-08, -1.7353e-08],\n              [-2.4628e-08,  6.0922e-09, -4.4461e-09]],\n    \n             [[-2.5994e-08,  3.1105e-08,  3.8230e-08],\n              [ 5.9258e-09,  9.0533e-08,  1.0082e-07],\n              [ 8.8066e-08, -5.2076e-08,  4.3774e-08]],\n    \n             [[ 8.7042e-08,  7.9785e-08,  9.6902e-08],\n              [ 8.3355e-08,  3.2548e-08,  1.3767e-07],\n              [ 2.5476e-08, -2.8827e-08,  5.4577e-08]],\n    \n             ...,\n    \n             [[ 9.4725e-08,  2.9084e-08, -1.4563e-08],\n              [ 3.5466e-08, -3.4763e-08,  4.6569e-08],\n              [ 7.5043e-08,  2.8600e-08, -1.5249e-08]],\n    \n             [[-8.5453e-08, -1.5867e-08, -1.1578e-08],\n              [-1.0475e-07, -3.3978e-08, -1.0002e-07],\n              [-1.1773e-07, -1.3540e-07, -8.6815e-08]],\n    \n             [[-7.0324e-08,  4.3215e-08, -1.0940e-07],\n              [ 4.1056e-08, -5.9814e-08, -8.9327e-08],\n              [ 4.3234e-09, -7.9928e-08, -5.2652e-08]]]]),\n    'exp_avg_sq': tensor([[[[8.9540e-14, 1.1043e-13, 9.4669e-14],\n              [1.0245e-13, 1.2625e-13, 1.0110e-13],\n              [9.5147e-14, 1.0419e-13, 9.0849e-14]],\n    \n             [[7.5725e-14, 1.2398e-13, 1.3602e-13],\n              [8.7828e-14, 1.1053e-13, 1.0561e-13],\n              [9.0821e-14, 8.8988e-14, 7.5768e-14]],\n    \n             [[1.1910e-13, 1.4329e-13, 1.1575e-13],\n              [1.3013e-13, 1.6378e-13, 1.3104e-13],\n              [1.0986e-13, 1.3833e-13, 1.1348e-13]],\n    \n             ...,\n    \n             [[8.8051e-14, 1.1952e-13, 1.1017e-13],\n              [1.1659e-13, 1.5914e-13, 1.3059e-13],\n              [9.6310e-14, 1.2723e-13, 1.0063e-13]],\n    \n             [[5.8100e-14, 6.5190e-14, 5.6601e-14],\n              [6.3421e-14, 7.4200e-14, 6.2027e-14],\n              [5.6075e-14, 6.3684e-14, 5.6734e-14]],\n    \n             [[8.4560e-14, 8.6742e-14, 8.3213e-14],\n              [9.2481e-14, 9.8681e-14, 9.3603e-14],\n              [8.5967e-14, 9.5605e-14, 8.6017e-14]]],\n    \n    \n            [[[1.0434e-13, 1.2918e-13, 1.1040e-13],\n              [1.1453e-13, 1.3473e-13, 1.1161e-13],\n              [8.7929e-14, 1.0015e-13, 8.7754e-14]],\n    \n             [[1.6698e-13, 2.2316e-13, 2.1278e-13],\n              [1.7037e-13, 2.0790e-13, 1.9431e-13],\n              [1.3508e-13, 1.3345e-13, 1.1536e-13]],\n    \n             [[1.6399e-13, 1.9349e-13, 1.5918e-13],\n              [1.4530e-13, 1.6588e-13, 1.4263e-13],\n              [1.1374e-13, 1.2705e-13, 1.1418e-13]],\n    \n             ...,\n    \n             [[1.2662e-13, 1.7881e-13, 1.3627e-13],\n              [1.2112e-13, 1.4947e-13, 1.1543e-13],\n              [8.7194e-14, 9.9820e-14, 8.1377e-14]],\n    \n             [[5.5324e-14, 6.2620e-14, 5.9180e-14],\n              [6.4930e-14, 7.8879e-14, 7.0373e-14],\n              [6.7923e-14, 7.5729e-14, 6.8853e-14]],\n    \n             [[8.4662e-14, 9.1539e-14, 8.3933e-14],\n              [9.4886e-14, 1.1319e-13, 9.7814e-14],\n              [1.1140e-13, 1.1667e-13, 1.0987e-13]]],\n    \n    \n            [[[1.6691e-13, 2.0841e-13, 1.6227e-13],\n              [1.7961e-13, 2.1680e-13, 1.6724e-13],\n              [1.3816e-13, 1.6472e-13, 1.5716e-13]],\n    \n             [[2.0985e-13, 3.2914e-13, 3.2333e-13],\n              [2.3022e-13, 2.8362e-13, 2.9281e-13],\n              [2.2661e-13, 2.7610e-13, 2.7665e-13]],\n    \n             [[1.7479e-13, 1.9336e-13, 1.6833e-13],\n              [1.9508e-13, 2.3854e-13, 1.9315e-13],\n              [1.8146e-13, 2.0707e-13, 1.8854e-13]],\n    \n             ...,\n    \n             [[8.2375e-14, 9.1273e-14, 9.6617e-14],\n              [1.0661e-13, 1.3671e-13, 1.1170e-13],\n              [1.1725e-13, 1.2449e-13, 1.0816e-13]],\n    \n             [[9.4192e-14, 1.0054e-13, 9.0386e-14],\n              [9.7498e-14, 1.0148e-13, 9.8644e-14],\n              [9.1540e-14, 1.0260e-13, 9.8382e-14]],\n    \n             [[1.5008e-13, 1.5647e-13, 1.5616e-13],\n              [1.6908e-13, 1.6636e-13, 1.5731e-13],\n              [1.7162e-13, 1.8566e-13, 1.5954e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[1.1183e-13, 1.2522e-13, 1.2309e-13],\n              [1.2145e-13, 1.4160e-13, 1.3022e-13],\n              [1.1379e-13, 1.1624e-13, 1.1538e-13]],\n    \n             [[8.7600e-14, 1.1825e-13, 1.2021e-13],\n              [1.0138e-13, 1.3953e-13, 1.3028e-13],\n              [9.0737e-14, 1.0096e-13, 9.4447e-14]],\n    \n             [[1.6610e-13, 1.9516e-13, 1.6264e-13],\n              [1.6866e-13, 2.0372e-13, 1.6509e-13],\n              [1.3862e-13, 1.5680e-13, 1.3680e-13]],\n    \n             ...,\n    \n             [[1.0575e-13, 1.5163e-13, 1.2152e-13],\n              [1.2925e-13, 1.7130e-13, 1.2480e-13],\n              [1.0056e-13, 1.2446e-13, 9.0568e-14]],\n    \n             [[5.7316e-14, 6.6365e-14, 6.2537e-14],\n              [6.8131e-14, 8.0318e-14, 7.4718e-14],\n              [6.7616e-14, 7.3631e-14, 6.6990e-14]],\n    \n             [[5.6993e-14, 5.3370e-14, 5.2564e-14],\n              [6.7454e-14, 6.8329e-14, 6.4659e-14],\n              [6.9482e-14, 6.9455e-14, 6.3045e-14]]],\n    \n    \n            [[[1.1519e-13, 1.2178e-13, 1.1129e-13],\n              [1.2942e-13, 1.4839e-13, 1.2757e-13],\n              [1.2091e-13, 1.3663e-13, 1.2281e-13]],\n    \n             [[1.4974e-13, 2.2353e-13, 1.9609e-13],\n              [1.6711e-13, 2.6070e-13, 2.6386e-13],\n              [1.2568e-13, 1.4655e-13, 1.6767e-13]],\n    \n             [[1.6223e-13, 1.9010e-13, 1.5635e-13],\n              [1.7438e-13, 2.0388e-13, 1.7977e-13],\n              [1.5176e-13, 1.6691e-13, 1.5118e-13]],\n    \n             ...,\n    \n             [[5.0292e-14, 6.1263e-14, 4.7658e-14],\n              [1.0359e-13, 1.2675e-13, 1.0269e-13],\n              [7.5615e-14, 1.0252e-13, 6.8762e-14]],\n    \n             [[5.0007e-14, 5.6174e-14, 5.2795e-14],\n              [4.9345e-14, 5.7310e-14, 5.5787e-14],\n              [4.5014e-14, 5.1308e-14, 5.2617e-14]],\n    \n             [[8.6955e-14, 1.0170e-13, 9.7063e-14],\n              [9.4374e-14, 1.1736e-13, 1.1255e-13],\n              [9.0929e-14, 1.1176e-13, 1.0692e-13]]],\n    \n    \n            [[[1.3860e-13, 1.6312e-13, 1.2735e-13],\n              [1.3344e-13, 1.4306e-13, 1.0936e-13],\n              [1.1922e-13, 1.2736e-13, 1.0703e-13]],\n    \n             [[2.1444e-13, 2.5128e-13, 2.5368e-13],\n              [1.9905e-13, 2.6568e-13, 2.6388e-13],\n              [1.6256e-13, 1.9976e-13, 2.0174e-13]],\n    \n             [[1.7136e-13, 1.8788e-13, 1.4475e-13],\n              [1.8226e-13, 2.0358e-13, 1.4327e-13],\n              [1.5867e-13, 1.6196e-13, 1.2118e-13]],\n    \n             ...,\n    \n             [[1.7032e-13, 2.0056e-13, 1.4983e-13],\n              [1.3517e-13, 1.6081e-13, 1.1411e-13],\n              [1.0328e-13, 9.8799e-14, 7.7117e-14]],\n    \n             [[7.3419e-14, 7.4745e-14, 7.2914e-14],\n              [7.6405e-14, 8.0244e-14, 8.1621e-14],\n              [7.2627e-14, 7.9974e-14, 8.3828e-14]],\n    \n             [[1.2513e-13, 1.2595e-13, 1.1824e-13],\n              [1.2982e-13, 1.2152e-13, 1.2955e-13],\n              [1.2778e-13, 1.3503e-13, 1.3454e-13]]]])},\n   124: {'exp_avg': tensor([[[[ 4.5808e-08]],\n    \n             [[ 5.9203e-08]],\n    \n             [[ 1.8483e-07]],\n    \n             ...,\n    \n             [[ 5.5043e-08]],\n    \n             [[ 4.7146e-08]],\n    \n             [[-9.5734e-08]]],\n    \n    \n            [[[ 6.2487e-10]],\n    \n             [[-6.8096e-09]],\n    \n             [[ 6.5627e-08]],\n    \n             ...,\n    \n             [[-1.3466e-08]],\n    \n             [[-2.4068e-08]],\n    \n             [[ 3.2058e-08]]],\n    \n    \n            [[[ 8.9629e-08]],\n    \n             [[-8.0454e-08]],\n    \n             [[-3.0855e-08]],\n    \n             ...,\n    \n             [[ 8.6638e-08]],\n    \n             [[-1.7146e-07]],\n    \n             [[ 6.2564e-09]]],\n    \n    \n            ...,\n    \n    \n            [[[ 4.8337e-08]],\n    \n             [[-1.7170e-07]],\n    \n             [[ 1.3837e-07]],\n    \n             ...,\n    \n             [[ 2.2757e-07]],\n    \n             [[ 3.4902e-08]],\n    \n             [[ 5.5980e-08]]],\n    \n    \n            [[[-3.3504e-08]],\n    \n             [[ 1.9563e-07]],\n    \n             [[ 8.7279e-08]],\n    \n             ...,\n    \n             [[-2.6264e-07]],\n    \n             [[ 1.4259e-07]],\n    \n             [[ 7.4413e-08]]],\n    \n    \n            [[[ 2.2303e-07]],\n    \n             [[ 4.7044e-08]],\n    \n             [[-9.3440e-08]],\n    \n             ...,\n    \n             [[-4.8543e-08]],\n    \n             [[-3.4760e-08]],\n    \n             [[-4.1412e-09]]]]),\n    'exp_avg_sq': tensor([[[[1.1461e-13]],\n    \n             [[8.7663e-14]],\n    \n             [[1.0250e-13]],\n    \n             ...,\n    \n             [[2.4340e-13]],\n    \n             [[9.5301e-14]],\n    \n             [[9.0348e-14]]],\n    \n    \n            [[[7.1815e-14]],\n    \n             [[7.3309e-14]],\n    \n             [[7.4160e-14]],\n    \n             ...,\n    \n             [[1.3495e-13]],\n    \n             [[7.5243e-14]],\n    \n             [[7.6197e-14]]],\n    \n    \n            [[[1.3848e-13]],\n    \n             [[1.0023e-13]],\n    \n             [[1.1842e-13]],\n    \n             ...,\n    \n             [[1.9721e-13]],\n    \n             [[1.0078e-13]],\n    \n             [[1.1203e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[3.9770e-13]],\n    \n             [[3.2874e-13]],\n    \n             [[3.4748e-13]],\n    \n             ...,\n    \n             [[7.3976e-13]],\n    \n             [[2.6546e-13]],\n    \n             [[3.2606e-13]]],\n    \n    \n            [[[3.2444e-13]],\n    \n             [[1.6440e-13]],\n    \n             [[2.2379e-13]],\n    \n             ...,\n    \n             [[5.8325e-13]],\n    \n             [[2.1303e-13]],\n    \n             [[2.3297e-13]]],\n    \n    \n            [[[3.1574e-13]],\n    \n             [[1.8827e-13]],\n    \n             [[2.2754e-13]],\n    \n             ...,\n    \n             [[6.1486e-13]],\n    \n             [[2.3843e-13]],\n    \n             [[2.3910e-13]]]])},\n   125: {'exp_avg': tensor([[[[-1.4281e-08]],\n    \n             [[-4.6855e-08]],\n    \n             [[-3.9464e-08]],\n    \n             ...,\n    \n             [[-6.1208e-08]],\n    \n             [[ 8.6811e-08]],\n    \n             [[-4.2426e-08]]],\n    \n    \n            [[[ 6.7752e-09]],\n    \n             [[ 4.8190e-08]],\n    \n             [[ 3.5483e-08]],\n    \n             ...,\n    \n             [[ 2.0174e-07]],\n    \n             [[-7.8997e-08]],\n    \n             [[-8.1813e-08]]],\n    \n    \n            [[[-6.5719e-08]],\n    \n             [[ 1.7539e-07]],\n    \n             [[-9.3475e-08]],\n    \n             ...,\n    \n             [[ 1.5635e-07]],\n    \n             [[-9.7635e-08]],\n    \n             [[-2.3497e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-5.8428e-09]],\n    \n             [[ 1.4217e-08]],\n    \n             [[ 8.2278e-08]],\n    \n             ...,\n    \n             [[ 5.2495e-08]],\n    \n             [[ 1.0264e-07]],\n    \n             [[-1.8458e-08]]],\n    \n    \n            [[[-4.3893e-09]],\n    \n             [[-5.3227e-09]],\n    \n             [[-1.8319e-08]],\n    \n             ...,\n    \n             [[ 9.6452e-08]],\n    \n             [[-3.7646e-08]],\n    \n             [[ 1.4282e-08]]],\n    \n    \n            [[[ 6.6223e-08]],\n    \n             [[-6.1040e-08]],\n    \n             [[ 1.5382e-07]],\n    \n             ...,\n    \n             [[ 5.6030e-08]],\n    \n             [[ 8.6830e-08]],\n    \n             [[-2.7572e-08]]]]),\n    'exp_avg_sq': tensor([[[[6.8410e-14]],\n    \n             [[8.9605e-14]],\n    \n             [[9.2398e-14]],\n    \n             ...,\n    \n             [[8.2654e-14]],\n    \n             [[1.1768e-13]],\n    \n             [[6.6550e-14]]],\n    \n    \n            [[[1.6465e-13]],\n    \n             [[2.2006e-13]],\n    \n             [[1.4297e-13]],\n    \n             ...,\n    \n             [[2.1878e-13]],\n    \n             [[3.1433e-13]],\n    \n             [[1.3120e-13]]],\n    \n    \n            [[[1.5613e-13]],\n    \n             [[1.3581e-13]],\n    \n             [[1.5557e-13]],\n    \n             ...,\n    \n             [[1.4995e-13]],\n    \n             [[2.4525e-13]],\n    \n             [[7.8094e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[8.3513e-14]],\n    \n             [[5.1484e-14]],\n    \n             [[5.0281e-14]],\n    \n             ...,\n    \n             [[5.1094e-14]],\n    \n             [[9.4003e-14]],\n    \n             [[2.6660e-14]]],\n    \n    \n            [[[1.0254e-13]],\n    \n             [[8.0676e-14]],\n    \n             [[1.3585e-13]],\n    \n             ...,\n    \n             [[1.4190e-13]],\n    \n             [[1.7538e-13]],\n    \n             [[7.8259e-14]]],\n    \n    \n            [[[1.7170e-13]],\n    \n             [[1.4153e-13]],\n    \n             [[1.6649e-13]],\n    \n             ...,\n    \n             [[1.2802e-13]],\n    \n             [[1.8971e-13]],\n    \n             [[9.2849e-14]]]])},\n   126: {'exp_avg': tensor([[[[-8.0599e-08, -9.3690e-09, -1.0922e-07],\n              [-3.0542e-08,  9.0090e-08,  1.1696e-08],\n              [-4.2157e-08,  7.7596e-08,  5.5578e-08]],\n    \n             [[-1.3528e-08, -1.5508e-08, -1.7798e-07],\n              [-8.0860e-08, -3.6616e-08, -1.9436e-07],\n              [-3.5994e-08,  7.6376e-08, -4.7513e-08]],\n    \n             [[-7.1496e-08, -4.9040e-08, -8.2315e-08],\n              [-1.9863e-07, -7.8446e-08, -1.2923e-07],\n              [-1.9424e-07, -1.2347e-07,  6.7971e-09]],\n    \n             ...,\n    \n             [[-2.7853e-09,  2.8573e-08,  9.3915e-09],\n              [-8.6722e-09,  7.2183e-09,  1.4891e-08],\n              [ 4.5235e-08,  3.8549e-08,  3.1498e-08]],\n    \n             [[-9.5817e-08, -5.4392e-08,  1.6644e-08],\n              [-1.1560e-07, -6.0790e-08,  5.9086e-09],\n              [-1.1150e-07, -2.4832e-08,  1.9065e-09]],\n    \n             [[-5.6869e-08, -1.9228e-08, -3.4477e-08],\n              [-1.0067e-07, -3.2126e-08, -1.5368e-07],\n              [-1.0039e-07, -5.9298e-08, -4.8685e-08]]],\n    \n    \n            [[[ 7.9229e-08,  1.3080e-07,  6.2205e-08],\n              [ 1.1783e-08,  5.3011e-09, -1.6731e-08],\n              [-3.6297e-08, -1.3337e-08, -3.8705e-08]],\n    \n             [[ 9.5855e-09, -7.8784e-08,  9.8472e-08],\n              [ 1.5249e-08,  3.8345e-08,  9.0280e-08],\n              [ 8.4088e-08,  7.0163e-08,  1.3540e-07]],\n    \n             [[ 4.9283e-08, -5.2458e-08,  4.0755e-08],\n              [ 1.9272e-08,  9.0350e-08,  8.2133e-08],\n              [ 3.1310e-08,  1.6594e-08,  1.7837e-07]],\n    \n             ...,\n    \n             [[ 4.4715e-09,  2.6125e-08,  8.5116e-09],\n              [-4.5324e-08, -1.9436e-08, -2.7626e-08],\n              [-4.8746e-08, -4.0993e-08,  1.4830e-08]],\n    \n             [[ 2.1288e-08,  8.5497e-10, -1.6185e-08],\n              [-3.4226e-08, -3.0052e-08, -7.1051e-08],\n              [-8.9580e-09, -2.6875e-08, -2.8967e-08]],\n    \n             [[ 9.8964e-08,  7.6250e-08,  2.8013e-09],\n              [ 1.9696e-07,  9.2112e-08,  3.6646e-08],\n              [ 1.3269e-07,  1.7651e-08,  1.4187e-08]]],\n    \n    \n            [[[-8.8086e-09, -7.8237e-08, -6.5774e-09],\n              [-2.4311e-08, -4.1675e-08,  4.7451e-09],\n              [ 6.3240e-08,  6.3529e-08,  9.4526e-09]],\n    \n             [[ 3.9165e-09, -1.2398e-07,  2.5716e-08],\n              [ 1.4668e-07, -1.1517e-07,  5.4805e-08],\n              [ 2.6607e-08,  3.1366e-09,  9.1800e-08]],\n    \n             [[-7.1520e-08,  1.6628e-08,  6.6889e-08],\n              [-3.1189e-09, -9.6317e-09,  7.3274e-08],\n              [ 3.0272e-08, -7.1746e-09,  9.0228e-08]],\n    \n             ...,\n    \n             [[ 7.0105e-08,  3.6212e-08,  6.5353e-08],\n              [ 4.3669e-08,  2.5482e-08,  7.3855e-08],\n              [ 9.7936e-08,  1.0441e-07,  8.6912e-08]],\n    \n             [[-2.2374e-08, -2.7707e-08, -4.6643e-08],\n              [-2.2562e-08, -2.4867e-08,  9.7478e-09],\n              [ 6.8425e-08,  5.9708e-08,  5.3444e-08]],\n    \n             [[ 2.2699e-08,  4.9446e-08,  8.8824e-08],\n              [ 3.0451e-08,  5.0720e-08,  1.6440e-07],\n              [-1.3554e-08,  1.9318e-08,  1.4720e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[ 8.7734e-08,  7.3998e-08,  1.0154e-07],\n              [ 8.0016e-08,  1.9951e-08,  4.5728e-08],\n              [ 5.3894e-08,  2.0754e-08,  1.2872e-07]],\n    \n             [[ 1.4886e-08, -4.1733e-08, -5.1726e-08],\n              [-4.6321e-08, -4.6357e-08, -1.2234e-08],\n              [-8.6674e-08, -3.8563e-08, -6.3456e-08]],\n    \n             [[ 1.2512e-08,  4.0416e-08,  1.3129e-07],\n              [ 7.8828e-08,  1.1547e-07,  1.0101e-07],\n              [-1.1300e-08,  5.3971e-08,  3.0392e-08]],\n    \n             ...,\n    \n             [[ 2.8742e-08,  8.9314e-09,  7.5814e-08],\n              [ 1.2181e-07,  4.7860e-08,  7.3063e-08],\n              [ 6.9541e-08,  5.8238e-08,  7.5535e-08]],\n    \n             [[-2.7856e-08,  4.0833e-08,  5.4959e-08],\n              [ 8.0323e-08,  8.5005e-08,  7.0477e-08],\n              [ 1.1176e-07,  7.8843e-08,  1.5595e-08]],\n    \n             [[ 2.5802e-08, -3.5466e-08, -7.2154e-08],\n              [-3.4848e-08, -5.4497e-08, -2.3091e-08],\n              [-1.3353e-07, -1.1315e-07, -8.7551e-08]]],\n    \n    \n            [[[-3.1234e-09,  4.6441e-09, -1.0272e-08],\n              [-8.0282e-09,  7.9112e-08, -9.6525e-08],\n              [ 1.3623e-08,  1.1008e-07, -2.5813e-08]],\n    \n             [[ 8.1693e-08,  4.3301e-08,  3.5797e-08],\n              [ 6.4261e-08,  9.9140e-08,  3.0180e-08],\n              [ 2.9684e-08,  3.5081e-08, -1.9910e-10]],\n    \n             [[ 2.0850e-07, -7.0632e-08, -7.4693e-08],\n              [ 1.6568e-07,  6.4063e-08, -5.0157e-08],\n              [ 1.1801e-07,  7.8121e-08,  2.4641e-08]],\n    \n             ...,\n    \n             [[ 4.5489e-08, -5.9909e-08,  1.6304e-08],\n              [ 4.2226e-08, -8.8820e-08,  2.9554e-08],\n              [ 3.9074e-09, -5.0217e-08,  7.8351e-09]],\n    \n             [[ 4.1123e-08, -5.3970e-08, -8.9075e-08],\n              [ 8.0711e-08,  2.3286e-08,  5.5413e-08],\n              [ 1.4165e-07,  1.7931e-07,  3.3140e-08]],\n    \n             [[ 1.8401e-07,  6.3075e-09,  4.6228e-08],\n              [ 1.1394e-07,  1.1069e-08, -2.1531e-09],\n              [ 1.3264e-07, -4.8075e-08,  8.7093e-09]]],\n    \n    \n            [[[ 1.7520e-08,  3.9776e-08, -7.0885e-08],\n              [-1.0572e-07, -3.6717e-09, -1.4840e-07],\n              [-7.9316e-08, -3.5772e-08, -1.1553e-07]],\n    \n             [[ 9.4955e-09,  3.7453e-08, -5.8605e-08],\n              [ 5.5707e-08, -1.4581e-08, -4.2425e-08],\n              [-3.6243e-08, -6.0135e-08, -8.6816e-08]],\n    \n             [[ 7.9370e-08,  8.6328e-08, -9.1406e-08],\n              [ 5.2880e-08,  1.3567e-08, -1.3151e-07],\n              [-2.5788e-08, -1.1586e-07, -1.5223e-07]],\n    \n             ...,\n    \n             [[-9.6407e-08, -7.9889e-08, -4.3608e-08],\n              [-7.0211e-09, -1.2571e-08, -3.5195e-08],\n              [-2.9108e-08, -7.8126e-08, -3.9945e-08]],\n    \n             [[ 2.4661e-09, -1.3240e-07, -1.4019e-07],\n              [-4.1183e-08, -1.2142e-07, -8.7826e-08],\n              [-4.3793e-08, -9.6728e-08, -9.1224e-08]],\n    \n             [[ 7.7863e-09,  2.8934e-08,  3.6805e-08],\n              [-2.6694e-08,  4.2679e-08,  7.3537e-08],\n              [-1.5235e-08, -2.1477e-08,  1.7433e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.1540e-13, 1.3080e-13, 1.4349e-13],\n              [1.3924e-13, 1.4896e-13, 1.5720e-13],\n              [1.1645e-13, 1.3210e-13, 1.3297e-13]],\n    \n             [[1.7128e-13, 2.0702e-13, 1.7334e-13],\n              [1.9764e-13, 2.6816e-13, 1.9386e-13],\n              [1.9914e-13, 2.3752e-13, 1.9470e-13]],\n    \n             [[1.4322e-13, 1.6989e-13, 1.4416e-13],\n              [1.4828e-13, 2.0187e-13, 1.5751e-13],\n              [1.4174e-13, 2.0173e-13, 1.5260e-13]],\n    \n             ...,\n    \n             [[3.8714e-14, 5.4795e-14, 3.3702e-14],\n              [4.6075e-14, 6.8401e-14, 4.0844e-14],\n              [3.5496e-14, 4.4949e-14, 2.9775e-14]],\n    \n             [[1.2987e-13, 1.1636e-13, 1.3869e-13],\n              [1.7442e-13, 1.9577e-13, 2.0490e-13],\n              [1.5197e-13, 1.4106e-13, 1.7303e-13]],\n    \n             [[1.1487e-13, 1.5977e-13, 1.2571e-13],\n              [1.2838e-13, 1.9254e-13, 1.3979e-13],\n              [1.2223e-13, 1.7405e-13, 1.2432e-13]]],\n    \n    \n            [[[1.1909e-13, 8.8188e-14, 1.2327e-13],\n              [1.4475e-13, 9.3145e-14, 1.5060e-13],\n              [1.1507e-13, 8.2009e-14, 1.1008e-13]],\n    \n             [[1.5378e-13, 1.6742e-13, 1.4819e-13],\n              [1.7775e-13, 2.1648e-13, 1.8509e-13],\n              [1.9169e-13, 2.4741e-13, 2.0169e-13]],\n    \n             [[1.6686e-13, 1.8264e-13, 1.7184e-13],\n              [1.9354e-13, 2.3606e-13, 2.0338e-13],\n              [1.7410e-13, 2.1184e-13, 1.8440e-13]],\n    \n             ...,\n    \n             [[5.0486e-14, 6.0087e-14, 4.3495e-14],\n              [6.0289e-14, 7.4604e-14, 4.8188e-14],\n              [4.2124e-14, 4.6963e-14, 3.2435e-14]],\n    \n             [[1.6203e-13, 1.6515e-13, 1.8177e-13],\n              [1.5248e-13, 1.4518e-13, 1.4827e-13],\n              [1.4535e-13, 1.2854e-13, 1.2606e-13]],\n    \n             [[9.0382e-14, 7.4147e-14, 7.6112e-14],\n              [1.1701e-13, 1.1370e-13, 9.8867e-14],\n              [1.0535e-13, 9.9852e-14, 9.5561e-14]]],\n    \n    \n            [[[9.6894e-14, 1.0015e-13, 9.9817e-14],\n              [9.3994e-14, 1.1160e-13, 1.1091e-13],\n              [7.9725e-14, 8.9429e-14, 8.4332e-14]],\n    \n             [[1.1618e-13, 1.3066e-13, 1.0602e-13],\n              [1.3931e-13, 1.7085e-13, 1.3734e-13],\n              [1.2972e-13, 1.6438e-13, 1.2775e-13]],\n    \n             [[1.1839e-13, 1.2330e-13, 1.3113e-13],\n              [1.2578e-13, 1.3111e-13, 1.4097e-13],\n              [9.7462e-14, 1.1007e-13, 1.1009e-13]],\n    \n             ...,\n    \n             [[4.2636e-14, 4.8390e-14, 3.4097e-14],\n              [4.7934e-14, 5.7326e-14, 3.3556e-14],\n              [3.5636e-14, 3.6901e-14, 2.7169e-14]],\n    \n             [[1.3114e-13, 1.4036e-13, 1.3882e-13],\n              [1.1608e-13, 1.1072e-13, 1.2857e-13],\n              [1.0116e-13, 1.0569e-13, 1.1348e-13]],\n    \n             [[9.0822e-14, 1.0716e-13, 1.0494e-13],\n              [1.1178e-13, 1.3958e-13, 1.3465e-13],\n              [8.8492e-14, 1.0529e-13, 1.0072e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[1.1238e-13, 1.3765e-13, 1.1087e-13],\n              [1.2313e-13, 1.5988e-13, 1.1866e-13],\n              [9.8636e-14, 1.3042e-13, 9.9993e-14]],\n    \n             [[1.4506e-13, 1.9111e-13, 1.6140e-13],\n              [1.3462e-13, 1.9122e-13, 1.6041e-13],\n              [1.1088e-13, 1.6595e-13, 1.3525e-13]],\n    \n             [[1.1366e-13, 1.2402e-13, 1.0664e-13],\n              [1.1039e-13, 1.3629e-13, 1.0342e-13],\n              [9.6634e-14, 1.2826e-13, 9.4213e-14]],\n    \n             ...,\n    \n             [[5.9160e-14, 7.2895e-14, 6.0937e-14],\n              [7.3812e-14, 9.1971e-14, 7.0875e-14],\n              [4.8334e-14, 5.5372e-14, 4.4075e-14]],\n    \n             [[1.1528e-13, 9.7033e-14, 1.1641e-13],\n              [1.1219e-13, 1.0540e-13, 1.1994e-13],\n              [1.1168e-13, 1.0880e-13, 1.1766e-13]],\n    \n             [[9.6262e-14, 1.3520e-13, 9.9291e-14],\n              [1.1267e-13, 1.5903e-13, 1.0781e-13],\n              [9.1465e-14, 1.3045e-13, 9.9870e-14]]],\n    \n    \n            [[[1.2731e-13, 1.1244e-13, 1.1585e-13],\n              [1.4891e-13, 1.3630e-13, 1.3695e-13],\n              [1.0978e-13, 1.2514e-13, 1.0777e-13]],\n    \n             [[1.5118e-13, 1.7172e-13, 1.5090e-13],\n              [1.6267e-13, 2.0439e-13, 1.7795e-13],\n              [1.7637e-13, 2.2482e-13, 1.8293e-13]],\n    \n             [[1.6491e-13, 2.2085e-13, 2.0453e-13],\n              [1.9587e-13, 2.5965e-13, 2.3753e-13],\n              [1.6875e-13, 2.1921e-13, 2.0174e-13]],\n    \n             ...,\n    \n             [[6.6547e-14, 9.0372e-14, 5.9574e-14],\n              [9.4523e-14, 1.3559e-13, 8.8433e-14],\n              [6.4024e-14, 8.5680e-14, 5.5291e-14]],\n    \n             [[1.8950e-13, 1.9464e-13, 2.0653e-13],\n              [1.4404e-13, 1.4420e-13, 1.5906e-13],\n              [1.4007e-13, 1.2201e-13, 1.4345e-13]],\n    \n             [[1.1276e-13, 1.4094e-13, 1.0237e-13],\n              [1.3685e-13, 1.8659e-13, 1.2661e-13],\n              [1.2336e-13, 1.8392e-13, 1.2834e-13]]],\n    \n    \n            [[[1.0081e-13, 9.7942e-14, 9.3835e-14],\n              [1.2165e-13, 1.2215e-13, 1.1331e-13],\n              [9.9951e-14, 1.0066e-13, 9.0037e-14]],\n    \n             [[1.2673e-13, 1.4463e-13, 1.2557e-13],\n              [1.2955e-13, 1.6168e-13, 1.3373e-13],\n              [1.2362e-13, 1.6404e-13, 1.2665e-13]],\n    \n             [[9.3182e-14, 1.1420e-13, 1.1012e-13],\n              [1.0999e-13, 1.2586e-13, 1.2955e-13],\n              [1.0414e-13, 1.3099e-13, 1.2542e-13]],\n    \n             ...,\n    \n             [[5.8956e-14, 8.1177e-14, 5.5389e-14],\n              [7.5482e-14, 1.1139e-13, 7.6649e-14],\n              [5.3864e-14, 7.0532e-14, 5.0985e-14]],\n    \n             [[1.3957e-13, 1.4011e-13, 1.2919e-13],\n              [1.3871e-13, 1.4161e-13, 1.3190e-13],\n              [1.2949e-13, 1.2060e-13, 1.1636e-13]],\n    \n             [[9.8729e-14, 1.2319e-13, 9.9797e-14],\n              [1.2073e-13, 1.5181e-13, 1.1259e-13],\n              [1.0247e-13, 1.3255e-13, 1.0162e-13]]]])},\n   127: {'exp_avg': tensor([[[[-2.1694e-07]],\n    \n             [[-3.1364e-07]],\n    \n             [[-2.3729e-08]],\n    \n             ...,\n    \n             [[ 1.0710e-07]],\n    \n             [[-3.3315e-08]],\n    \n             [[-1.4798e-07]]],\n    \n    \n            [[[ 4.8197e-08]],\n    \n             [[-2.4259e-08]],\n    \n             [[-1.1618e-08]],\n    \n             ...,\n    \n             [[-1.7937e-07]],\n    \n             [[-1.1730e-07]],\n    \n             [[-8.2495e-08]]],\n    \n    \n            [[[ 1.6532e-07]],\n    \n             [[-2.0578e-07]],\n    \n             [[ 1.3709e-07]],\n    \n             ...,\n    \n             [[ 1.1612e-07]],\n    \n             [[-4.5512e-08]],\n    \n             [[-1.3766e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[-7.1763e-08]],\n    \n             [[-7.3202e-08]],\n    \n             [[-6.0859e-08]],\n    \n             ...,\n    \n             [[ 2.2779e-08]],\n    \n             [[-5.3668e-08]],\n    \n             [[ 6.3316e-08]]],\n    \n    \n            [[[-4.5034e-08]],\n    \n             [[-2.0873e-07]],\n    \n             [[-1.1171e-08]],\n    \n             ...,\n    \n             [[-2.4494e-07]],\n    \n             [[ 2.5634e-07]],\n    \n             [[-4.8268e-08]]],\n    \n    \n            [[[ 7.2894e-08]],\n    \n             [[-3.9204e-08]],\n    \n             [[ 5.3695e-08]],\n    \n             ...,\n    \n             [[-4.1585e-08]],\n    \n             [[ 5.2365e-08]],\n    \n             [[ 1.4930e-07]]]]),\n    'exp_avg_sq': tensor([[[[2.9658e-13]],\n    \n             [[3.6692e-13]],\n    \n             [[3.6164e-13]],\n    \n             ...,\n    \n             [[2.6336e-13]],\n    \n             [[3.5194e-13]],\n    \n             [[4.1895e-13]]],\n    \n    \n            [[[1.4180e-13]],\n    \n             [[1.4514e-13]],\n    \n             [[1.5164e-13]],\n    \n             ...,\n    \n             [[1.5096e-13]],\n    \n             [[1.9761e-13]],\n    \n             [[2.5038e-13]]],\n    \n    \n            [[[1.4154e-13]],\n    \n             [[1.9671e-13]],\n    \n             [[1.6574e-13]],\n    \n             ...,\n    \n             [[1.4164e-13]],\n    \n             [[2.0410e-13]],\n    \n             [[2.7176e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[6.6936e-14]],\n    \n             [[8.6685e-14]],\n    \n             [[6.5428e-14]],\n    \n             ...,\n    \n             [[6.0815e-14]],\n    \n             [[9.6842e-14]],\n    \n             [[7.4944e-14]]],\n    \n    \n            [[[2.6573e-13]],\n    \n             [[4.5957e-13]],\n    \n             [[2.7067e-13]],\n    \n             ...,\n    \n             [[2.8775e-13]],\n    \n             [[3.0716e-13]],\n    \n             [[5.4537e-13]]],\n    \n    \n            [[[1.4384e-13]],\n    \n             [[1.9785e-13]],\n    \n             [[1.6755e-13]],\n    \n             ...,\n    \n             [[1.5554e-13]],\n    \n             [[2.0040e-13]],\n    \n             [[2.5193e-13]]]])},\n   128: {'exp_avg': tensor([[[[-6.2897e-09]],\n    \n             [[ 1.9593e-08]],\n    \n             [[-1.1087e-07]],\n    \n             ...,\n    \n             [[-5.5847e-08]],\n    \n             [[-1.5939e-07]],\n    \n             [[ 4.3053e-10]]],\n    \n    \n            [[[ 3.6010e-08]],\n    \n             [[ 1.3041e-07]],\n    \n             [[ 3.6108e-08]],\n    \n             ...,\n    \n             [[ 7.7255e-08]],\n    \n             [[-1.8359e-07]],\n    \n             [[-2.2919e-09]]],\n    \n    \n            [[[ 9.0326e-08]],\n    \n             [[ 8.6333e-08]],\n    \n             [[-1.9337e-09]],\n    \n             ...,\n    \n             [[ 1.0917e-08]],\n    \n             [[-8.2652e-09]],\n    \n             [[-1.8980e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 7.6618e-08]],\n    \n             [[ 1.2219e-08]],\n    \n             [[ 1.5690e-08]],\n    \n             ...,\n    \n             [[-3.3677e-08]],\n    \n             [[ 6.4085e-08]],\n    \n             [[-6.7709e-08]]],\n    \n    \n            [[[-9.7598e-08]],\n    \n             [[-1.3156e-07]],\n    \n             [[ 1.0029e-07]],\n    \n             ...,\n    \n             [[-1.6571e-07]],\n    \n             [[ 5.3551e-08]],\n    \n             [[-4.5540e-08]]],\n    \n    \n            [[[-2.9147e-08]],\n    \n             [[ 7.5893e-08]],\n    \n             [[ 1.8428e-09]],\n    \n             ...,\n    \n             [[ 1.9137e-07]],\n    \n             [[-1.8538e-08]],\n    \n             [[-3.4235e-08]]]]),\n    'exp_avg_sq': tensor([[[[2.4740e-13]],\n    \n             [[1.4613e-13]],\n    \n             [[1.5054e-13]],\n    \n             ...,\n    \n             [[2.3422e-13]],\n    \n             [[4.6102e-13]],\n    \n             [[1.2087e-13]]],\n    \n    \n            [[[1.6915e-13]],\n    \n             [[1.4580e-13]],\n    \n             [[1.8339e-13]],\n    \n             ...,\n    \n             [[1.5717e-13]],\n    \n             [[2.1649e-13]],\n    \n             [[1.0261e-13]]],\n    \n    \n            [[[8.6015e-14]],\n    \n             [[6.4801e-14]],\n    \n             [[4.9499e-14]],\n    \n             ...,\n    \n             [[8.4402e-14]],\n    \n             [[9.9057e-14]],\n    \n             [[5.5275e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[2.0306e-13]],\n    \n             [[1.6100e-13]],\n    \n             [[2.1190e-13]],\n    \n             ...,\n    \n             [[2.1753e-13]],\n    \n             [[2.1068e-13]],\n    \n             [[1.2581e-13]]],\n    \n    \n            [[[1.3100e-13]],\n    \n             [[1.2873e-13]],\n    \n             [[1.2777e-13]],\n    \n             ...,\n    \n             [[1.4018e-13]],\n    \n             [[1.9400e-13]],\n    \n             [[8.2989e-14]]],\n    \n    \n            [[[1.9909e-13]],\n    \n             [[2.0990e-13]],\n    \n             [[1.6396e-13]],\n    \n             ...,\n    \n             [[2.4526e-13]],\n    \n             [[3.8542e-13]],\n    \n             [[1.3144e-13]]]])},\n   129: {'exp_avg': tensor([[[[-8.6725e-08, -1.0647e-07,  1.2085e-08],\n              [ 1.5278e-08,  1.0216e-07,  7.0375e-08],\n              [-1.8058e-08, -7.1400e-09,  7.9450e-08]],\n    \n             [[ 1.0661e-08,  2.4674e-08,  8.3388e-08],\n              [-8.6714e-09,  2.7226e-08,  3.9295e-08],\n              [-1.4986e-08, -1.7318e-08,  1.2079e-07]],\n    \n             [[ 8.9898e-08,  7.6540e-08,  1.5522e-09],\n              [ 6.6058e-08,  5.2167e-08,  7.3056e-08],\n              [ 1.3595e-08,  1.0086e-08,  9.3768e-08]],\n    \n             ...,\n    \n             [[-9.7309e-09,  6.5147e-08, -8.9146e-09],\n              [-2.5486e-08, -3.8792e-08, -2.6146e-08],\n              [ 2.2399e-08,  6.3584e-08, -5.3613e-08]],\n    \n             [[-5.4028e-08,  2.2332e-08,  1.1596e-08],\n              [-7.6741e-08, -9.8651e-08,  1.5243e-08],\n              [-2.3806e-08, -5.8461e-08, -8.0243e-09]],\n    \n             [[ 6.9092e-08,  6.3155e-08, -3.2630e-08],\n              [ 5.5130e-08,  3.4770e-08,  1.9032e-08],\n              [-5.4790e-08, -5.2591e-08,  7.3771e-08]]],\n    \n    \n            [[[-1.5646e-07, -6.4199e-08, -8.6032e-08],\n              [-1.5149e-07, -7.2251e-08, -1.4130e-07],\n              [-1.3412e-07, -1.2059e-07, -1.2237e-07]],\n    \n             [[-3.6978e-08, -4.6391e-08,  6.5026e-08],\n              [-2.7704e-08, -2.5711e-08,  3.7169e-08],\n              [-4.4441e-09,  7.1853e-08,  3.7921e-09]],\n    \n             [[-5.6199e-08, -1.1359e-08, -1.1049e-08],\n              [-5.5926e-08,  5.0579e-08,  5.4085e-09],\n              [-4.0394e-08,  4.8670e-08, -1.7327e-08]],\n    \n             ...,\n    \n             [[-8.7223e-08, -8.8443e-08, -7.7740e-08],\n              [ 1.7995e-08, -4.2406e-08,  2.4651e-08],\n              [ 1.3104e-08,  3.7223e-08,  2.5011e-08]],\n    \n             [[-1.2479e-07, -1.1030e-07, -2.0385e-08],\n              [-9.5234e-08, -9.4302e-08, -9.7343e-08],\n              [-2.8913e-08, -1.1482e-08,  5.1981e-08]],\n    \n             [[-7.4637e-08,  1.5984e-09,  7.0333e-08],\n              [-4.7574e-08, -7.0851e-08,  3.2046e-08],\n              [ 2.5930e-08,  7.4936e-08,  5.5635e-08]]],\n    \n    \n            [[[ 2.1981e-08,  8.6799e-09,  4.2593e-08],\n              [-8.3133e-09, -1.1773e-07, -5.4906e-08],\n              [-6.3335e-08, -4.1144e-08, -6.4324e-08]],\n    \n             [[-5.8345e-09,  1.8226e-08,  5.0276e-08],\n              [ 2.0680e-08,  8.6867e-08,  6.7897e-08],\n              [ 5.3541e-08,  2.8246e-08,  1.8935e-08]],\n    \n             [[ 4.4161e-08, -5.5709e-09, -9.8024e-08],\n              [ 5.2500e-08,  5.7711e-08, -4.9465e-08],\n              [ 3.0438e-08,  5.8821e-08, -7.0995e-08]],\n    \n             ...,\n    \n             [[-9.8208e-08, -6.9050e-08,  3.2569e-08],\n              [-1.2448e-07, -1.3614e-07, -5.6849e-08],\n              [-1.8047e-07, -1.5793e-07,  9.7311e-09]],\n    \n             [[-4.6251e-08,  5.7220e-08,  3.1639e-08],\n              [-6.4644e-08, -1.7038e-08,  9.6693e-09],\n              [-2.8483e-08,  5.8188e-08,  4.7583e-08]],\n    \n             [[ 2.6269e-08,  3.7266e-08, -1.5100e-08],\n              [ 1.3877e-08, -5.4376e-08,  3.9176e-08],\n              [-2.7370e-08,  4.7963e-08,  3.6945e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-6.5854e-10, -1.8734e-07, -5.5309e-08],\n              [ 2.2448e-08,  1.8538e-07,  3.3870e-08],\n              [-1.0834e-08,  1.5941e-07,  8.0586e-08]],\n    \n             [[-8.5804e-08, -1.8150e-07, -1.9859e-07],\n              [-5.8040e-08, -1.4288e-07, -1.9702e-07],\n              [ 4.6487e-09, -1.4134e-07, -1.3423e-07]],\n    \n             [[-1.4683e-07, -1.4465e-07,  6.3279e-08],\n              [-1.3556e-07, -1.2275e-07, -2.3935e-08],\n              [-5.7769e-08, -1.8925e-07, -1.2419e-07]],\n    \n             ...,\n    \n             [[ 2.4688e-07,  9.5159e-08, -2.9071e-08],\n              [ 7.6256e-08, -1.2380e-08,  8.3650e-08],\n              [-2.3702e-08, -6.6124e-08, -4.2547e-08]],\n    \n             [[ 2.3348e-07,  2.0155e-08, -1.2732e-07],\n              [ 1.4423e-07, -1.0820e-07, -7.9621e-08],\n              [ 8.4383e-08, -6.2850e-08, -5.7792e-08]],\n    \n             [[-5.5614e-08, -6.5897e-08,  1.2844e-08],\n              [ 4.0711e-08,  1.4802e-08, -7.4098e-08],\n              [ 1.6157e-07,  5.6438e-08, -1.6425e-07]]],\n    \n    \n            [[[ 7.8440e-08, -5.3211e-09,  5.4146e-08],\n              [ 1.0284e-07,  9.1378e-09,  1.1027e-07],\n              [ 1.0051e-07,  9.4361e-09,  5.4082e-08]],\n    \n             [[ 6.7433e-08,  5.0501e-08,  4.9365e-08],\n              [ 9.9570e-08,  6.5749e-09, -9.2458e-09],\n              [ 4.1694e-08, -7.5120e-08,  9.7746e-09]],\n    \n             [[ 2.3363e-08,  3.1023e-08,  1.2853e-07],\n              [ 3.9577e-08, -6.8643e-09,  2.2741e-08],\n              [ 8.7011e-08,  1.2503e-07,  3.8695e-08]],\n    \n             ...,\n    \n             [[ 1.9609e-07,  4.4939e-08,  3.1580e-08],\n              [ 1.1303e-07, -1.2440e-07, -1.4100e-09],\n              [ 1.1750e-08, -7.0976e-08,  5.8923e-09]],\n    \n             [[ 1.0628e-07,  2.0869e-08,  3.9213e-08],\n              [ 1.3321e-08, -3.2782e-08,  6.3965e-09],\n              [ 2.3232e-08, -2.2164e-09,  2.2656e-08]],\n    \n             [[ 5.4509e-08, -4.8805e-08,  9.0933e-08],\n              [ 1.7597e-08, -1.8039e-07, -3.5327e-08],\n              [-9.2733e-08, -7.8862e-08,  9.7409e-08]]],\n    \n    \n            [[[-1.4052e-07, -1.4581e-08, -8.0709e-08],\n              [-1.3884e-07, -1.0745e-07, -1.0531e-07],\n              [-1.1031e-07, -5.0905e-08, -1.5938e-07]],\n    \n             [[-1.2983e-09,  9.7373e-08,  8.4410e-08],\n              [-4.0775e-08,  5.7974e-08,  5.4745e-08],\n              [ 5.3526e-08,  7.0467e-08,  9.1482e-08]],\n    \n             [[ 6.1293e-08,  8.3679e-08, -5.8447e-08],\n              [ 9.3334e-08,  9.4647e-08,  6.6165e-08],\n              [ 4.4976e-08,  6.8335e-08,  4.5395e-08]],\n    \n             ...,\n    \n             [[ 8.7390e-08, -7.2098e-08, -1.4764e-08],\n              [-4.4458e-08, -6.2344e-08, -9.8764e-08],\n              [-9.7267e-08, -1.2790e-08, -1.6888e-08]],\n    \n             [[ 5.0660e-08, -4.0036e-08, -1.6157e-09],\n              [-4.5865e-08,  8.9519e-10, -7.4381e-08],\n              [-1.0907e-07, -2.2750e-08, -1.0864e-08]],\n    \n             [[-1.9133e-08,  1.3367e-07, -4.0603e-08],\n              [-7.1866e-08, -8.6712e-08, -4.0638e-08],\n              [-8.6850e-08, -5.5071e-08,  2.9701e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.2408e-13, 1.6761e-13, 1.3581e-13],\n              [1.2261e-13, 1.7674e-13, 1.4254e-13],\n              [9.5225e-14, 1.2184e-13, 1.0052e-13]],\n    \n             [[7.4973e-14, 1.0870e-13, 8.3747e-14],\n              [7.8671e-14, 1.2767e-13, 8.2942e-14],\n              [6.8136e-14, 1.0370e-13, 7.9330e-14]],\n    \n             [[6.4177e-14, 6.9163e-14, 7.4171e-14],\n              [6.6133e-14, 7.3509e-14, 7.4569e-14],\n              [4.6778e-14, 6.1288e-14, 5.1702e-14]],\n    \n             ...,\n    \n             [[1.8253e-13, 1.4085e-13, 1.2837e-13],\n              [1.8832e-13, 1.6081e-13, 1.3436e-13],\n              [1.4440e-13, 1.3415e-13, 1.1944e-13]],\n    \n             [[6.5492e-14, 8.3578e-14, 7.0567e-14],\n              [7.5953e-14, 1.0287e-13, 8.9327e-14],\n              [5.8811e-14, 8.3507e-14, 7.2145e-14]],\n    \n             [[1.1456e-13, 1.2034e-13, 1.1294e-13],\n              [1.1394e-13, 1.2261e-13, 1.1434e-13],\n              [8.1656e-14, 1.0702e-13, 9.3516e-14]]],\n    \n    \n            [[[1.0449e-13, 1.5126e-13, 1.2782e-13],\n              [1.2147e-13, 1.9294e-13, 1.5507e-13],\n              [1.1363e-13, 1.7328e-13, 1.2717e-13]],\n    \n             [[8.8690e-14, 1.2609e-13, 1.0169e-13],\n              [1.4771e-13, 1.9854e-13, 1.5016e-13],\n              [1.2459e-13, 1.6964e-13, 1.3317e-13]],\n    \n             [[5.7891e-14, 7.0207e-14, 6.1061e-14],\n              [6.0097e-14, 7.2747e-14, 5.3033e-14],\n              [5.6325e-14, 7.8205e-14, 4.5816e-14]],\n    \n             ...,\n    \n             [[1.1246e-13, 9.4549e-14, 1.4465e-13],\n              [1.2763e-13, 9.8259e-14, 1.5968e-13],\n              [1.1955e-13, 9.7115e-14, 1.4265e-13]],\n    \n             [[4.7995e-14, 6.3534e-14, 7.1885e-14],\n              [7.4518e-14, 8.8843e-14, 1.0759e-13],\n              [6.6506e-14, 7.5363e-14, 8.8366e-14]],\n    \n             [[8.6338e-14, 1.1699e-13, 9.4128e-14],\n              [1.1220e-13, 1.5407e-13, 1.1908e-13],\n              [9.2715e-14, 1.3370e-13, 1.0469e-13]]],\n    \n    \n            [[[9.7796e-14, 1.2273e-13, 1.0366e-13],\n              [1.0076e-13, 1.2301e-13, 1.0715e-13],\n              [8.6626e-14, 1.0586e-13, 9.5409e-14]],\n    \n             [[1.1927e-13, 1.5646e-13, 1.1910e-13],\n              [1.5286e-13, 1.7997e-13, 1.3428e-13],\n              [1.3445e-13, 1.7569e-13, 1.2822e-13]],\n    \n             [[7.5575e-14, 9.4180e-14, 9.2872e-14],\n              [7.6376e-14, 9.3730e-14, 8.2635e-14],\n              [5.9334e-14, 8.2599e-14, 6.4673e-14]],\n    \n             ...,\n    \n             [[1.5919e-13, 1.5072e-13, 1.4839e-13],\n              [2.0119e-13, 1.6654e-13, 1.7580e-13],\n              [1.9237e-13, 1.6255e-13, 1.6976e-13]],\n    \n             [[6.7502e-14, 9.1256e-14, 7.7966e-14],\n              [8.3984e-14, 1.0031e-13, 9.4331e-14],\n              [7.9278e-14, 9.4829e-14, 8.4303e-14]],\n    \n             [[9.9140e-14, 1.3453e-13, 1.1542e-13],\n              [1.1038e-13, 1.3471e-13, 1.2022e-13],\n              [9.2474e-14, 1.4386e-13, 1.0441e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[1.8075e-13, 3.2342e-13, 2.7095e-13],\n              [1.8504e-13, 4.0420e-13, 2.8845e-13],\n              [1.7769e-13, 3.1454e-13, 1.9701e-13]],\n    \n             [[1.4590e-13, 2.5706e-13, 2.1325e-13],\n              [1.6134e-13, 3.5075e-13, 2.2863e-13],\n              [1.0082e-13, 1.7319e-13, 1.4883e-13]],\n    \n             [[1.3370e-13, 1.5357e-13, 1.5243e-13],\n              [1.4525e-13, 1.8336e-13, 1.5316e-13],\n              [1.1521e-13, 1.7416e-13, 1.3151e-13]],\n    \n             ...,\n    \n             [[6.7075e-13, 2.5941e-13, 3.1495e-13],\n              [7.5596e-13, 2.5598e-13, 3.4010e-13],\n              [5.0203e-13, 2.0834e-13, 2.6729e-13]],\n    \n             [[1.5140e-13, 1.3965e-13, 1.5400e-13],\n              [1.8691e-13, 1.4769e-13, 1.8242e-13],\n              [1.5614e-13, 1.2536e-13, 1.4799e-13]],\n    \n             [[1.7326e-13, 2.4636e-13, 2.0224e-13],\n              [1.9636e-13, 3.7079e-13, 2.5096e-13],\n              [1.6300e-13, 2.3224e-13, 1.9568e-13]]],\n    \n    \n            [[[1.3389e-13, 1.7610e-13, 1.4394e-13],\n              [1.4882e-13, 2.1212e-13, 1.2850e-13],\n              [1.2873e-13, 1.7317e-13, 1.1367e-13]],\n    \n             [[5.4793e-14, 6.8142e-14, 6.8613e-14],\n              [6.4490e-14, 8.4600e-14, 7.0713e-14],\n              [6.1174e-14, 6.5110e-14, 5.7834e-14]],\n    \n             [[4.6782e-14, 6.4537e-14, 8.8007e-14],\n              [5.1703e-14, 7.8411e-14, 8.5351e-14],\n              [5.2905e-14, 6.9689e-14, 7.0834e-14]],\n    \n             ...,\n    \n             [[1.6963e-13, 1.2519e-13, 1.5345e-13],\n              [2.0028e-13, 1.3516e-13, 1.4651e-13],\n              [1.9239e-13, 1.4676e-13, 1.4080e-13]],\n    \n             [[7.5275e-14, 7.8871e-14, 8.1406e-14],\n              [8.7783e-14, 9.1192e-14, 9.2046e-14],\n              [7.8137e-14, 7.6520e-14, 7.4103e-14]],\n    \n             [[9.7763e-14, 1.3028e-13, 1.2890e-13],\n              [1.0983e-13, 1.7318e-13, 1.2935e-13],\n              [9.7456e-14, 1.2892e-13, 1.0535e-13]]],\n    \n    \n            [[[1.5551e-13, 1.9731e-13, 1.6082e-13],\n              [1.7892e-13, 2.5158e-13, 2.0253e-13],\n              [1.6091e-13, 2.2429e-13, 1.7290e-13]],\n    \n             [[1.3175e-13, 1.8100e-13, 1.3010e-13],\n              [1.4288e-13, 2.1107e-13, 1.3979e-13],\n              [1.1554e-13, 1.5337e-13, 1.0998e-13]],\n    \n             [[7.0718e-14, 8.7158e-14, 7.9244e-14],\n              [7.1625e-14, 8.4080e-14, 7.2045e-14],\n              [5.2523e-14, 6.4784e-14, 5.2851e-14]],\n    \n             ...,\n    \n             [[2.1609e-13, 1.7173e-13, 2.1105e-13],\n              [2.0796e-13, 1.4882e-13, 2.0897e-13],\n              [1.9016e-13, 1.4350e-13, 1.7622e-13]],\n    \n             [[7.9434e-14, 1.0016e-13, 8.5225e-14],\n              [9.0193e-14, 1.1286e-13, 9.6563e-14],\n              [7.0479e-14, 1.0023e-13, 7.5545e-14]],\n    \n             [[1.2637e-13, 1.4547e-13, 1.2196e-13],\n              [1.2364e-13, 1.4808e-13, 1.2293e-13],\n              [9.8019e-14, 1.1734e-13, 9.1298e-14]]]])},\n   130: {'exp_avg': tensor([[[[ 2.3547e-07]],\n    \n             [[ 1.9895e-07]],\n    \n             [[-1.3927e-07]],\n    \n             ...,\n    \n             [[-3.3696e-08]],\n    \n             [[-1.2507e-07]],\n    \n             [[ 1.6259e-07]]],\n    \n    \n            [[[-2.2220e-10]],\n    \n             [[-8.6128e-09]],\n    \n             [[ 2.8945e-09]],\n    \n             ...,\n    \n             [[-4.6838e-09]],\n    \n             [[ 1.1846e-09]],\n    \n             [[ 4.7405e-09]]],\n    \n    \n            [[[-6.6273e-08]],\n    \n             [[ 3.8910e-08]],\n    \n             [[ 2.2791e-08]],\n    \n             ...,\n    \n             [[-1.4313e-08]],\n    \n             [[-3.5686e-08]],\n    \n             [[ 1.4636e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 2.8009e-08]],\n    \n             [[ 1.3532e-07]],\n    \n             [[ 1.2111e-07]],\n    \n             ...,\n    \n             [[-1.9659e-08]],\n    \n             [[ 1.4655e-07]],\n    \n             [[ 4.2263e-09]]],\n    \n    \n            [[[ 2.2301e-09]],\n    \n             [[-5.1372e-07]],\n    \n             [[-4.6942e-08]],\n    \n             ...,\n    \n             [[-1.5359e-08]],\n    \n             [[-1.0353e-08]],\n    \n             [[ 1.8897e-07]]],\n    \n    \n            [[[-1.8276e-08]],\n    \n             [[-1.5396e-09]],\n    \n             [[ 1.4423e-08]],\n    \n             ...,\n    \n             [[-2.5350e-09]],\n    \n             [[ 8.0537e-09]],\n    \n             [[ 8.4377e-09]]]]),\n    'exp_avg_sq': tensor([[[[4.3998e-13]],\n    \n             [[3.1876e-13]],\n    \n             [[2.8849e-13]],\n    \n             ...,\n    \n             [[2.2763e-13]],\n    \n             [[4.2461e-13]],\n    \n             [[4.9276e-13]]],\n    \n    \n            [[[2.3038e-16]],\n    \n             [[1.4012e-16]],\n    \n             [[1.6555e-16]],\n    \n             ...,\n    \n             [[1.1308e-16]],\n    \n             [[2.0609e-16]],\n    \n             [[2.1370e-16]]],\n    \n    \n            [[[1.2201e-14]],\n    \n             [[9.3580e-15]],\n    \n             [[9.1552e-15]],\n    \n             ...,\n    \n             [[6.7221e-15]],\n    \n             [[1.0298e-14]],\n    \n             [[1.3163e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[2.2925e-13]],\n    \n             [[2.1618e-13]],\n    \n             [[1.6847e-13]],\n    \n             ...,\n    \n             [[2.0635e-13]],\n    \n             [[2.1334e-13]],\n    \n             [[2.7862e-13]]],\n    \n    \n            [[[4.6663e-13]],\n    \n             [[4.9819e-13]],\n    \n             [[3.3474e-13]],\n    \n             ...,\n    \n             [[2.7546e-13]],\n    \n             [[6.0970e-13]],\n    \n             [[6.5629e-13]]],\n    \n    \n            [[[5.0755e-15]],\n    \n             [[4.8325e-15]],\n    \n             [[4.1217e-15]],\n    \n             ...,\n    \n             [[3.8823e-15]],\n    \n             [[3.9782e-15]],\n    \n             [[5.6305e-15]]]])},\n   131: {'exp_avg': tensor([[[[ 1.2453e-07]],\n    \n             [[ 2.3337e-07]],\n    \n             [[ 2.8733e-08]],\n    \n             ...,\n    \n             [[ 1.3505e-07]],\n    \n             [[ 3.1238e-08]],\n    \n             [[-8.7138e-10]]],\n    \n    \n            [[[-3.6526e-08]],\n    \n             [[-7.6276e-09]],\n    \n             [[ 6.3701e-08]],\n    \n             ...,\n    \n             [[ 1.0486e-07]],\n    \n             [[-1.1056e-07]],\n    \n             [[-4.5488e-08]]],\n    \n    \n            [[[-3.5617e-08]],\n    \n             [[ 1.6911e-08]],\n    \n             [[ 5.8295e-08]],\n    \n             ...,\n    \n             [[-4.5389e-08]],\n    \n             [[-1.5360e-07]],\n    \n             [[ 1.3068e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[-1.7733e-07]],\n    \n             [[-4.7281e-08]],\n    \n             [[-5.7686e-08]],\n    \n             ...,\n    \n             [[-9.7792e-08]],\n    \n             [[-9.3630e-08]],\n    \n             [[-1.4363e-08]]],\n    \n    \n            [[[-2.0001e-07]],\n    \n             [[ 5.1994e-08]],\n    \n             [[ 9.4433e-08]],\n    \n             ...,\n    \n             [[ 2.9245e-07]],\n    \n             [[ 1.3020e-07]],\n    \n             [[ 1.8069e-07]]],\n    \n    \n            [[[ 8.2078e-09]],\n    \n             [[-1.7921e-08]],\n    \n             [[ 8.9084e-09]],\n    \n             ...,\n    \n             [[-9.7636e-09]],\n    \n             [[-1.6696e-08]],\n    \n             [[-4.5298e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.6927e-13]],\n    \n             [[1.0831e-13]],\n    \n             [[1.0597e-13]],\n    \n             ...,\n    \n             [[1.6060e-13]],\n    \n             [[2.1556e-13]],\n    \n             [[7.4027e-14]]],\n    \n    \n            [[[1.9293e-13]],\n    \n             [[1.4610e-13]],\n    \n             [[1.5250e-13]],\n    \n             ...,\n    \n             [[3.0813e-13]],\n    \n             [[3.1898e-13]],\n    \n             [[1.1750e-13]]],\n    \n    \n            [[[3.5815e-13]],\n    \n             [[1.7076e-13]],\n    \n             [[1.7118e-13]],\n    \n             ...,\n    \n             [[2.9378e-13]],\n    \n             [[5.1981e-13]],\n    \n             [[1.3114e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[1.2763e-13]],\n    \n             [[7.7590e-14]],\n    \n             [[9.1860e-14]],\n    \n             ...,\n    \n             [[1.9749e-13]],\n    \n             [[1.0402e-13]],\n    \n             [[6.6348e-14]]],\n    \n    \n            [[[3.3447e-13]],\n    \n             [[2.1359e-13]],\n    \n             [[2.0351e-13]],\n    \n             ...,\n    \n             [[3.8055e-13]],\n    \n             [[2.1406e-13]],\n    \n             [[1.4593e-13]]],\n    \n    \n            [[[1.8143e-13]],\n    \n             [[1.0542e-13]],\n    \n             [[8.4225e-14]],\n    \n             ...,\n    \n             [[1.9111e-13]],\n    \n             [[3.2470e-13]],\n    \n             [[1.0602e-13]]]])},\n   132: {'exp_avg': tensor([[[[-8.8255e-08, -3.9205e-08, -2.3444e-08],\n              [-8.2683e-08, -3.8881e-08, -8.5344e-08],\n              [-4.6897e-08,  1.0457e-08, -4.3480e-10]],\n    \n             [[-7.5402e-08, -5.6821e-08,  9.3480e-11],\n              [-1.1211e-07, -7.7406e-08,  1.2752e-09],\n              [-6.4335e-08, -9.4116e-08, -5.8040e-09]],\n    \n             [[-7.5123e-08,  5.1694e-08, -6.9570e-08],\n              [-3.8779e-08,  1.4492e-07,  6.8866e-09],\n              [-2.3440e-08,  7.6077e-08, -8.2078e-08]],\n    \n             ...,\n    \n             [[ 4.9425e-08, -3.9127e-08,  8.0165e-08],\n              [ 2.6859e-08,  2.2310e-08,  1.2270e-08],\n              [ 4.0284e-08, -1.2388e-08,  1.1200e-08]],\n    \n             [[-1.5365e-07,  9.7640e-08, -3.6548e-08],\n              [-1.3508e-07,  1.2679e-08, -1.2847e-07],\n              [-4.8360e-08,  9.6331e-08, -5.6964e-08]],\n    \n             [[ 3.1885e-08,  7.6039e-08,  4.7438e-08],\n              [-1.6917e-08,  8.5762e-08,  7.6162e-08],\n              [ 3.8615e-08,  1.0710e-07,  1.1603e-07]]],\n    \n    \n            [[[-5.6985e-08, -6.0581e-08, -6.8493e-08],\n              [-1.1803e-07, -6.0228e-08, -8.2854e-08],\n              [-1.0865e-08,  4.1307e-08, -5.8881e-08]],\n    \n             [[-5.7396e-08, -1.6179e-07, -3.0907e-08],\n              [-8.2397e-08, -1.7707e-07, -2.3378e-08],\n              [ 1.7581e-08, -5.7062e-09, -1.3461e-08]],\n    \n             [[-4.6743e-08,  8.6581e-09, -6.4719e-08],\n              [ 6.8328e-08,  1.2207e-07,  2.3215e-08],\n              [ 9.0571e-08,  9.9406e-08,  6.8217e-08]],\n    \n             ...,\n    \n             [[-5.7849e-08, -2.3153e-08, -6.6704e-09],\n              [-1.1276e-07, -1.1446e-07, -1.5657e-07],\n              [-1.2160e-07, -1.8635e-07, -1.4100e-07]],\n    \n             [[-2.6075e-10, -2.0124e-08, -8.9915e-08],\n              [-6.4009e-08,  1.0632e-07, -3.5525e-08],\n              [ 1.9912e-08, -3.0678e-08, -5.3529e-08]],\n    \n             [[ 5.2264e-08,  9.9578e-08, -2.6697e-08],\n              [ 6.7292e-08,  4.5986e-08, -4.8193e-08],\n              [ 8.5586e-08,  5.2086e-08,  1.3760e-08]]],\n    \n    \n            [[[-4.6070e-09,  3.0127e-08, -9.5096e-08],\n              [ 6.0851e-08,  2.7097e-08, -9.2679e-09],\n              [ 6.0954e-08,  1.8533e-08,  5.0183e-08]],\n    \n             [[-6.1372e-08,  4.2896e-08, -3.0147e-08],\n              [ 9.4350e-08,  1.3972e-07,  6.4434e-08],\n              [ 1.4359e-08, -5.1734e-08,  1.4355e-08]],\n    \n             [[ 4.5120e-08,  3.3330e-08, -2.3844e-08],\n              [-3.8425e-08,  6.7595e-08,  3.1570e-08],\n              [ 8.9821e-08,  2.4921e-08, -2.4630e-08]],\n    \n             ...,\n    \n             [[-6.2589e-08, -5.0909e-08, -1.3069e-07],\n              [ 9.7111e-08,  5.0435e-08,  7.6850e-09],\n              [ 6.2399e-08,  7.3932e-09,  3.0217e-09]],\n    \n             [[-1.2753e-07, -1.7121e-07, -3.6686e-09],\n              [ 3.0228e-08, -7.3465e-08,  5.7200e-09],\n              [ 3.5164e-08, -1.6744e-08, -3.7625e-08]],\n    \n             [[-3.9540e-08, -1.3817e-08, -4.5218e-08],\n              [ 4.8396e-08,  1.5273e-09, -6.3489e-08],\n              [ 3.9450e-08,  1.0326e-07,  6.0119e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-7.1065e-10, -4.4313e-08, -1.4953e-08],\n              [-2.5317e-08, -1.2658e-07, -1.3774e-07],\n              [ 1.5519e-08, -1.0452e-07, -1.8114e-08]],\n    \n             [[ 8.3668e-09,  1.3455e-08, -1.2408e-07],\n              [-8.0723e-08, -1.5672e-07, -2.5835e-07],\n              [ 2.8497e-08, -2.7457e-08, -1.3636e-07]],\n    \n             [[ 7.3303e-09, -3.5716e-08, -4.3164e-08],\n              [-1.0659e-07,  4.2420e-08, -4.9795e-08],\n              [-1.1954e-07, -6.8176e-08, -9.3526e-08]],\n    \n             ...,\n    \n             [[ 1.7788e-08,  7.8081e-08,  4.3962e-08],\n              [ 3.6859e-08, -5.7817e-08,  1.5852e-08],\n              [-1.3317e-09, -1.8972e-08,  2.1746e-08]],\n    \n             [[ 2.3783e-08,  1.4847e-09,  8.6690e-08],\n              [-4.3801e-08, -1.0646e-07, -2.3540e-08],\n              [-5.1884e-08, -9.4515e-08, -3.0186e-08]],\n    \n             [[ 1.5901e-08, -3.9014e-08, -3.2391e-10],\n              [-5.5069e-08,  3.2818e-08,  4.8967e-09],\n              [-7.5645e-09, -3.4063e-08,  2.5263e-08]]],\n    \n    \n            [[[-4.4038e-08, -1.4030e-07, -8.5164e-08],\n              [-8.0991e-08, -1.9074e-07, -5.4498e-08],\n              [ 5.6984e-08, -2.5125e-09,  9.4357e-09]],\n    \n             [[ 9.6657e-09,  1.2792e-07,  8.7108e-09],\n              [-3.7308e-08, -1.0253e-07, -5.9733e-08],\n              [ 1.1003e-07,  8.0226e-08,  8.4844e-08]],\n    \n             [[ 6.5993e-08,  4.9930e-08, -4.6391e-08],\n              [ 5.5510e-08,  7.0571e-08, -8.0247e-08],\n              [-9.4020e-10,  4.1109e-08, -4.1574e-08]],\n    \n             ...,\n    \n             [[ 1.0562e-08, -6.2089e-09, -1.1550e-08],\n              [-8.6519e-08, -7.3176e-08, -3.5548e-08],\n              [-3.7299e-08, -3.2970e-08,  1.8850e-09]],\n    \n             [[ 1.2309e-07, -7.6827e-08,  1.8299e-08],\n              [ 2.9933e-08, -5.8305e-08, -4.9230e-08],\n              [ 2.4460e-08,  7.2072e-08, -1.5524e-08]],\n    \n             [[-8.3786e-08, -7.1138e-08, -3.3770e-08],\n              [-1.6825e-08, -9.7427e-08, -3.1042e-08],\n              [-5.3835e-08, -1.8787e-08, -3.7273e-08]]],\n    \n    \n            [[[ 1.3244e-07,  1.1588e-07,  5.5318e-08],\n              [ 6.2514e-09, -3.2571e-08,  5.0846e-08],\n              [ 1.0022e-07,  7.7658e-08,  5.5274e-08]],\n    \n             [[-1.6608e-08, -4.4082e-09,  1.2329e-08],\n              [ 6.9934e-09,  1.3947e-07,  8.7559e-08],\n              [ 4.2671e-08,  1.1319e-07,  1.1238e-07]],\n    \n             [[ 1.6321e-08,  2.8861e-08,  1.0137e-07],\n              [ 8.2170e-08,  3.7717e-08,  9.1301e-08],\n              [ 6.4563e-08,  1.0440e-07,  5.5408e-08]],\n    \n             ...,\n    \n             [[-8.0502e-08, -4.3144e-08, -1.4691e-08],\n              [-4.2932e-08, -1.0576e-07, -7.9904e-08],\n              [ 1.5860e-08,  1.0154e-08, -2.7191e-08]],\n    \n             [[ 1.2847e-07,  1.5132e-08,  1.6557e-08],\n              [ 1.1579e-07,  4.1096e-08,  1.5325e-08],\n              [ 7.2774e-08,  2.0096e-08,  4.3450e-08]],\n    \n             [[-6.6249e-08,  3.4364e-08,  1.0013e-07],\n              [-1.6771e-08, -2.7997e-08,  7.7399e-08],\n              [ 1.6632e-08,  5.1978e-08,  8.6503e-08]]]]),\n    'exp_avg_sq': tensor([[[[7.2801e-14, 9.9106e-14, 6.9883e-14],\n              [1.0490e-13, 1.5485e-13, 1.0067e-13],\n              [8.2825e-14, 1.1591e-13, 7.5429e-14]],\n    \n             [[6.8532e-14, 1.0799e-13, 7.4993e-14],\n              [9.8147e-14, 1.4022e-13, 1.0222e-13],\n              [6.8360e-14, 9.9917e-14, 6.7245e-14]],\n    \n             [[5.2008e-14, 7.4093e-14, 5.1206e-14],\n              [7.0702e-14, 1.0804e-13, 6.8063e-14],\n              [6.1550e-14, 8.5000e-14, 6.2332e-14]],\n    \n             ...,\n    \n             [[7.3857e-14, 1.3393e-13, 7.1809e-14],\n              [1.1066e-13, 2.0835e-13, 1.1940e-13],\n              [6.7284e-14, 1.3052e-13, 7.3689e-14]],\n    \n             [[7.3903e-14, 1.0620e-13, 7.0757e-14],\n              [1.0433e-13, 1.6515e-13, 1.0454e-13],\n              [7.9545e-14, 1.2687e-13, 8.0330e-14]],\n    \n             [[5.6309e-14, 8.8097e-14, 5.0176e-14],\n              [8.3742e-14, 1.3076e-13, 7.8640e-14],\n              [6.0049e-14, 9.9566e-14, 6.3239e-14]]],\n    \n    \n            [[[5.3090e-14, 7.9902e-14, 5.0510e-14],\n              [7.5478e-14, 1.2119e-13, 7.2442e-14],\n              [5.0620e-14, 7.7924e-14, 5.1017e-14]],\n    \n             [[6.1441e-14, 9.0324e-14, 5.8130e-14],\n              [8.9120e-14, 1.3185e-13, 8.0931e-14],\n              [5.4933e-14, 8.6051e-14, 5.4418e-14]],\n    \n             [[6.6278e-14, 8.2760e-14, 5.5563e-14],\n              [8.3725e-14, 1.0890e-13, 6.9369e-14],\n              [6.5081e-14, 9.8424e-14, 6.3616e-14]],\n    \n             ...,\n    \n             [[5.8766e-14, 1.0589e-13, 6.0616e-14],\n              [9.4751e-14, 1.8934e-13, 1.0045e-13],\n              [5.2388e-14, 1.0708e-13, 5.7207e-14]],\n    \n             [[5.8554e-14, 9.9832e-14, 5.5663e-14],\n              [6.8952e-14, 1.2153e-13, 7.0512e-14],\n              [4.6987e-14, 8.2366e-14, 4.8421e-14]],\n    \n             [[5.1186e-14, 7.8630e-14, 5.1106e-14],\n              [6.9507e-14, 1.1668e-13, 7.7944e-14],\n              [4.9452e-14, 8.1815e-14, 5.3515e-14]]],\n    \n    \n            [[[9.2204e-14, 1.3856e-13, 8.9970e-14],\n              [1.1610e-13, 1.6106e-13, 1.2140e-13],\n              [8.9377e-14, 1.2084e-13, 8.5508e-14]],\n    \n             [[8.3152e-14, 9.9480e-14, 7.7704e-14],\n              [1.2984e-13, 1.6175e-13, 1.2049e-13],\n              [1.0167e-13, 1.3109e-13, 1.0008e-13]],\n    \n             [[9.2009e-14, 1.1789e-13, 8.6235e-14],\n              [9.9886e-14, 1.3113e-13, 9.0941e-14],\n              [7.2222e-14, 9.0800e-14, 6.8781e-14]],\n    \n             ...,\n    \n             [[6.9490e-14, 1.0321e-13, 7.5305e-14],\n              [8.2747e-14, 1.1986e-13, 9.2261e-14],\n              [6.2576e-14, 8.8196e-14, 6.2794e-14]],\n    \n             [[9.6817e-14, 1.3561e-13, 9.1919e-14],\n              [1.2801e-13, 1.9731e-13, 1.1889e-13],\n              [8.6594e-14, 1.2840e-13, 8.4397e-14]],\n    \n             [[7.8072e-14, 1.0356e-13, 7.5056e-14],\n              [9.0919e-14, 1.1247e-13, 8.4287e-14],\n              [7.4020e-14, 9.3582e-14, 6.4252e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[5.9271e-14, 6.6078e-14, 3.9671e-14],\n              [8.1525e-14, 8.6951e-14, 5.2060e-14],\n              [5.7983e-14, 6.5308e-14, 3.9549e-14]],\n    \n             [[3.7792e-14, 8.1874e-14, 6.7127e-14],\n              [6.1075e-14, 9.6145e-14, 8.0846e-14],\n              [4.4472e-14, 6.8435e-14, 5.7173e-14]],\n    \n             [[4.0452e-14, 8.2338e-14, 7.1295e-14],\n              [5.2883e-14, 1.0394e-13, 8.9323e-14],\n              [4.2314e-14, 8.6333e-14, 7.1049e-14]],\n    \n             ...,\n    \n             [[4.5382e-14, 5.1786e-14, 3.1564e-14],\n              [6.1279e-14, 7.8260e-14, 5.5229e-14],\n              [3.6402e-14, 5.5650e-14, 3.8199e-14]],\n    \n             [[5.5532e-14, 7.8588e-14, 5.4418e-14],\n              [7.8837e-14, 9.4959e-14, 6.9239e-14],\n              [4.7096e-14, 7.2892e-14, 5.1106e-14]],\n    \n             [[3.8363e-14, 6.2173e-14, 4.5886e-14],\n              [4.8678e-14, 8.0719e-14, 6.2143e-14],\n              [3.5345e-14, 5.8501e-14, 4.7707e-14]]],\n    \n    \n            [[[5.0349e-14, 6.9142e-14, 4.8875e-14],\n              [5.3635e-14, 7.5031e-14, 5.4748e-14],\n              [3.0553e-14, 4.1930e-14, 3.3258e-14]],\n    \n             [[5.9742e-14, 7.9613e-14, 5.7064e-14],\n              [8.2109e-14, 1.0935e-13, 7.9368e-14],\n              [3.8488e-14, 5.5877e-14, 4.3008e-14]],\n    \n             [[7.7440e-14, 1.0706e-13, 7.8189e-14],\n              [7.6620e-14, 1.0174e-13, 8.4550e-14],\n              [4.0291e-14, 5.5375e-14, 4.3146e-14]],\n    \n             ...,\n    \n             [[2.4790e-14, 3.3404e-14, 2.7147e-14],\n              [5.3274e-14, 8.8076e-14, 5.6150e-14],\n              [3.3134e-14, 6.3535e-14, 4.0406e-14]],\n    \n             [[5.0860e-14, 7.3151e-14, 5.4020e-14],\n              [4.6448e-14, 6.6243e-14, 4.8689e-14],\n              [3.2984e-14, 4.7785e-14, 3.3912e-14]],\n    \n             [[4.3580e-14, 5.7772e-14, 4.3101e-14],\n              [4.9965e-14, 7.1048e-14, 5.2012e-14],\n              [3.3984e-14, 5.2430e-14, 3.7540e-14]]],\n    \n    \n            [[[5.2035e-14, 6.5532e-14, 3.7660e-14],\n              [6.1845e-14, 7.6568e-14, 5.1587e-14],\n              [3.6394e-14, 4.9696e-14, 3.4610e-14]],\n    \n             [[4.8044e-14, 5.5454e-14, 4.3325e-14],\n              [7.0647e-14, 8.2883e-14, 5.7311e-14],\n              [5.4121e-14, 6.0387e-14, 3.6663e-14]],\n    \n             [[7.6301e-14, 7.2671e-14, 3.0803e-14],\n              [8.8319e-14, 8.9381e-14, 4.1175e-14],\n              [6.7349e-14, 6.8317e-14, 3.8777e-14]],\n    \n             ...,\n    \n             [[2.5457e-14, 5.1728e-14, 4.7665e-14],\n              [3.5251e-14, 7.2502e-14, 5.9872e-14],\n              [2.0966e-14, 4.3427e-14, 3.7537e-14]],\n    \n             [[6.5022e-14, 7.5412e-14, 3.2744e-14],\n              [8.7484e-14, 9.6675e-14, 4.0832e-14],\n              [5.2666e-14, 6.0296e-14, 2.6658e-14]],\n    \n             [[4.9264e-14, 5.3467e-14, 3.2969e-14],\n              [5.4084e-14, 6.5525e-14, 4.0610e-14],\n              [3.6634e-14, 4.8819e-14, 3.2965e-14]]]])},\n   133: {'exp_avg': tensor([[[[ 9.8252e-08]],\n    \n             [[-3.1284e-08]],\n    \n             [[ 7.4126e-08]],\n    \n             ...,\n    \n             [[-7.3382e-08]],\n    \n             [[ 4.5737e-09]],\n    \n             [[ 1.4603e-08]]],\n    \n    \n            [[[ 6.1568e-08]],\n    \n             [[-6.0142e-08]],\n    \n             [[ 1.2510e-08]],\n    \n             ...,\n    \n             [[-2.4901e-08]],\n    \n             [[-7.9917e-08]],\n    \n             [[ 6.5413e-08]]],\n    \n    \n            [[[-1.7379e-08]],\n    \n             [[ 6.9181e-08]],\n    \n             [[-6.2090e-08]],\n    \n             ...,\n    \n             [[-5.1836e-08]],\n    \n             [[ 3.9007e-08]],\n    \n             [[ 3.3118e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 4.1220e-08]],\n    \n             [[ 1.6552e-07]],\n    \n             [[-5.7142e-08]],\n    \n             ...,\n    \n             [[-1.1841e-07]],\n    \n             [[ 6.5409e-08]],\n    \n             [[-9.1744e-08]]],\n    \n    \n            [[[-3.2174e-08]],\n    \n             [[-2.0964e-08]],\n    \n             [[-1.3027e-07]],\n    \n             ...,\n    \n             [[-6.3453e-08]],\n    \n             [[-1.3837e-07]],\n    \n             [[-2.3478e-08]]],\n    \n    \n            [[[-5.3333e-09]],\n    \n             [[-1.9481e-08]],\n    \n             [[-4.6651e-08]],\n    \n             ...,\n    \n             [[ 8.0643e-08]],\n    \n             [[ 5.8806e-08]],\n    \n             [[ 5.1885e-08]]]]),\n    'exp_avg_sq': tensor([[[[7.3535e-14]],\n    \n             [[1.1161e-13]],\n    \n             [[1.4282e-13]],\n    \n             ...,\n    \n             [[1.2012e-13]],\n    \n             [[1.6471e-13]],\n    \n             [[7.1835e-14]]],\n    \n    \n            [[[6.4019e-14]],\n    \n             [[7.9158e-14]],\n    \n             [[7.1422e-14]],\n    \n             ...,\n    \n             [[7.9676e-14]],\n    \n             [[8.3556e-14]],\n    \n             [[4.6343e-14]]],\n    \n    \n            [[[6.2362e-14]],\n    \n             [[6.3720e-14]],\n    \n             [[9.3889e-14]],\n    \n             ...,\n    \n             [[7.1523e-14]],\n    \n             [[5.7454e-14]],\n    \n             [[5.4780e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[1.8651e-13]],\n    \n             [[2.0852e-13]],\n    \n             [[3.4559e-13]],\n    \n             ...,\n    \n             [[2.7851e-13]],\n    \n             [[2.4509e-13]],\n    \n             [[1.7974e-13]]],\n    \n    \n            [[[1.3552e-13]],\n    \n             [[1.5783e-13]],\n    \n             [[1.6643e-13]],\n    \n             ...,\n    \n             [[1.6122e-13]],\n    \n             [[1.5945e-13]],\n    \n             [[8.7359e-14]]],\n    \n    \n            [[[6.6291e-14]],\n    \n             [[7.2919e-14]],\n    \n             [[8.2200e-14]],\n    \n             ...,\n    \n             [[4.5091e-14]],\n    \n             [[7.0234e-14]],\n    \n             [[3.4417e-14]]]])},\n   134: {'exp_avg': tensor([[[[-3.9891e-08]],\n    \n             [[-9.4538e-08]],\n    \n             [[ 4.1544e-09]],\n    \n             ...,\n    \n             [[ 5.7860e-08]],\n    \n             [[-2.0025e-08]],\n    \n             [[ 1.8098e-08]]],\n    \n    \n            [[[-1.6473e-08]],\n    \n             [[ 2.7992e-08]],\n    \n             [[ 2.7564e-08]],\n    \n             ...,\n    \n             [[-9.4256e-08]],\n    \n             [[ 9.8804e-08]],\n    \n             [[ 9.0694e-08]]],\n    \n    \n            [[[ 3.2834e-08]],\n    \n             [[-1.0733e-07]],\n    \n             [[-8.1205e-09]],\n    \n             ...,\n    \n             [[-4.9725e-08]],\n    \n             [[-5.9688e-08]],\n    \n             [[-1.8767e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 7.5728e-08]],\n    \n             [[ 1.3213e-08]],\n    \n             [[ 3.0454e-08]],\n    \n             ...,\n    \n             [[ 2.6756e-08]],\n    \n             [[-3.0051e-08]],\n    \n             [[ 3.4401e-08]]],\n    \n    \n            [[[-7.4258e-08]],\n    \n             [[ 1.0210e-08]],\n    \n             [[-6.1408e-08]],\n    \n             ...,\n    \n             [[-1.1372e-07]],\n    \n             [[-1.1313e-07]],\n    \n             [[-1.5726e-09]]],\n    \n    \n            [[[ 1.3051e-07]],\n    \n             [[-3.4614e-09]],\n    \n             [[-4.9244e-09]],\n    \n             ...,\n    \n             [[ 5.2745e-08]],\n    \n             [[ 2.0570e-08]],\n    \n             [[ 1.2538e-08]]]]),\n    'exp_avg_sq': tensor([[[[8.5191e-14]],\n    \n             [[4.2228e-14]],\n    \n             [[3.5165e-14]],\n    \n             ...,\n    \n             [[4.7673e-14]],\n    \n             [[1.1523e-13]],\n    \n             [[3.1875e-14]]],\n    \n    \n            [[[6.2313e-14]],\n    \n             [[4.3584e-14]],\n    \n             [[2.5711e-14]],\n    \n             ...,\n    \n             [[7.2119e-14]],\n    \n             [[1.0019e-13]],\n    \n             [[3.5796e-14]]],\n    \n    \n            [[[1.2898e-13]],\n    \n             [[1.1723e-13]],\n    \n             [[1.4478e-13]],\n    \n             ...,\n    \n             [[1.5426e-13]],\n    \n             [[1.8462e-13]],\n    \n             [[7.6470e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[6.2290e-14]],\n    \n             [[4.2964e-14]],\n    \n             [[5.0305e-14]],\n    \n             ...,\n    \n             [[5.6957e-14]],\n    \n             [[8.0550e-14]],\n    \n             [[3.0209e-14]]],\n    \n    \n            [[[1.2965e-13]],\n    \n             [[4.6091e-14]],\n    \n             [[5.7781e-14]],\n    \n             ...,\n    \n             [[1.3207e-13]],\n    \n             [[2.1466e-13]],\n    \n             [[5.8742e-14]]],\n    \n    \n            [[[6.5172e-14]],\n    \n             [[4.9645e-14]],\n    \n             [[3.4913e-14]],\n    \n             ...,\n    \n             [[6.5572e-14]],\n    \n             [[1.0796e-13]],\n    \n             [[3.2092e-14]]]])},\n   135: {'exp_avg': tensor([[[[ 1.2186e-07]],\n    \n             [[ 5.0856e-08]],\n    \n             [[-4.9795e-09]],\n    \n             ...,\n    \n             [[-4.1519e-08]],\n    \n             [[-4.1937e-08]],\n    \n             [[ 5.6553e-08]]],\n    \n    \n            [[[-5.0701e-08]],\n    \n             [[-1.4253e-08]],\n    \n             [[-2.5105e-08]],\n    \n             ...,\n    \n             [[ 4.1956e-09]],\n    \n             [[-1.8250e-08]],\n    \n             [[-3.3719e-08]]],\n    \n    \n            [[[ 7.2165e-09]],\n    \n             [[-5.2245e-08]],\n    \n             [[ 8.8319e-09]],\n    \n             ...,\n    \n             [[-4.7570e-09]],\n    \n             [[ 4.5207e-09]],\n    \n             [[-9.1653e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 2.3615e-08]],\n    \n             [[-3.1722e-08]],\n    \n             [[-5.3550e-08]],\n    \n             ...,\n    \n             [[ 3.8913e-08]],\n    \n             [[-3.1800e-09]],\n    \n             [[ 1.7692e-08]]],\n    \n    \n            [[[ 1.1282e-08]],\n    \n             [[-1.0499e-08]],\n    \n             [[-8.8966e-08]],\n    \n             ...,\n    \n             [[-2.9966e-08]],\n    \n             [[ 3.4761e-08]],\n    \n             [[-1.4578e-09]]],\n    \n    \n            [[[-9.8269e-09]],\n    \n             [[-1.9044e-08]],\n    \n             [[-5.8394e-09]],\n    \n             ...,\n    \n             [[ 5.3776e-09]],\n    \n             [[-8.2645e-08]],\n    \n             [[-1.0336e-07]]]]),\n    'exp_avg_sq': tensor([[[[6.0362e-14]],\n    \n             [[3.8115e-14]],\n    \n             [[8.5402e-14]],\n    \n             ...,\n    \n             [[3.4319e-14]],\n    \n             [[9.1935e-14]],\n    \n             [[6.5646e-14]]],\n    \n    \n            [[[2.7013e-14]],\n    \n             [[1.4507e-14]],\n    \n             [[8.5280e-14]],\n    \n             ...,\n    \n             [[2.9673e-14]],\n    \n             [[4.8168e-14]],\n    \n             [[1.9228e-14]]],\n    \n    \n            [[[5.4656e-14]],\n    \n             [[3.0218e-14]],\n    \n             [[9.5507e-14]],\n    \n             ...,\n    \n             [[2.1533e-14]],\n    \n             [[5.3510e-14]],\n    \n             [[5.3365e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[4.5613e-14]],\n    \n             [[2.7734e-14]],\n    \n             [[6.1748e-14]],\n    \n             ...,\n    \n             [[4.9603e-14]],\n    \n             [[6.6469e-14]],\n    \n             [[3.9835e-14]]],\n    \n    \n            [[[4.2578e-14]],\n    \n             [[2.4333e-14]],\n    \n             [[8.2553e-14]],\n    \n             ...,\n    \n             [[2.8811e-14]],\n    \n             [[4.6092e-14]],\n    \n             [[5.2673e-14]]],\n    \n    \n            [[[2.2225e-14]],\n    \n             [[2.2711e-14]],\n    \n             [[7.5206e-14]],\n    \n             ...,\n    \n             [[3.0526e-14]],\n    \n             [[6.6671e-14]],\n    \n             [[3.6795e-14]]]])},\n   136: {'exp_avg': tensor([[[[ 1.1556e-07,  3.0331e-08,  2.8427e-08],\n              [ 1.6724e-08,  3.3553e-08,  2.2642e-08],\n              [ 6.1006e-08,  4.8077e-08, -1.8349e-08]],\n    \n             [[-9.3337e-08, -1.5521e-07, -1.5749e-07],\n              [-4.8511e-09, -1.0782e-07, -1.4497e-07],\n              [-9.0303e-08, -1.8854e-07, -6.7457e-08]],\n    \n             [[ 9.2009e-08,  3.6987e-08,  3.3227e-09],\n              [-2.1781e-08, -4.1653e-08, -8.3639e-10],\n              [ 1.0785e-08, -2.3766e-08,  1.5112e-08]],\n    \n             ...,\n    \n             [[ 8.2368e-10, -3.5341e-08, -6.3469e-08],\n              [-2.1698e-08,  1.5595e-08, -1.3833e-07],\n              [ 2.7079e-09, -1.1956e-09, -9.2038e-08]],\n    \n             [[-2.2576e-08,  1.1698e-11, -9.8688e-09],\n              [-1.7074e-08,  7.7000e-09,  2.4300e-08],\n              [ 9.1417e-09,  4.8921e-08,  4.4612e-08]],\n    \n             [[ 7.0148e-08,  4.2636e-08,  2.9676e-08],\n              [ 5.6571e-08,  4.0356e-08,  3.4711e-08],\n              [ 4.0480e-09,  1.0043e-08,  8.6058e-09]]],\n    \n    \n            [[[ 4.6166e-08,  3.7805e-08,  6.6064e-08],\n              [ 1.1917e-08,  1.0539e-08,  6.6505e-08],\n              [ 4.6032e-08,  2.5869e-09,  4.6476e-08]],\n    \n             [[-6.5905e-08, -1.2175e-07, -4.7779e-08],\n              [ 8.4770e-08, -3.0570e-08, -2.6438e-08],\n              [ 4.6192e-08, -2.8557e-08, -2.5126e-08]],\n    \n             [[-1.9626e-08, -1.6572e-08, -2.3246e-09],\n              [-5.7657e-09,  1.8428e-08,  5.1022e-08],\n              [-1.8982e-09,  1.4090e-08,  1.4550e-07]],\n    \n             ...,\n    \n             [[-7.0751e-08, -4.1094e-08, -2.0071e-07],\n              [-2.0779e-08,  1.9397e-08, -8.5004e-08],\n              [-6.3305e-08, -3.4690e-08, -3.4022e-08]],\n    \n             [[ 1.3355e-08, -2.7768e-09,  2.7494e-09],\n              [ 1.7023e-07,  2.3421e-07,  7.8681e-08],\n              [ 5.0582e-08,  1.2338e-07,  8.6750e-08]],\n    \n             [[ 2.3621e-08,  3.9244e-08,  3.1722e-08],\n              [ 2.2146e-08,  7.9120e-08,  1.3484e-07],\n              [ 4.1959e-08,  1.0799e-07,  1.8101e-07]]],\n    \n    \n            [[[-4.3064e-09,  6.4132e-08, -1.2890e-08],\n              [-1.9799e-10,  2.3688e-08, -6.5845e-08],\n              [ 9.7674e-09, -1.4752e-08, -1.6534e-08]],\n    \n             [[ 7.7825e-08,  4.0967e-08,  1.6802e-08],\n              [ 1.2732e-07,  1.2210e-07,  1.1996e-07],\n              [ 3.7798e-08,  3.5886e-08,  7.5466e-08]],\n    \n             [[-5.7853e-08, -4.0920e-08, -1.5943e-08],\n              [-3.9150e-08, -1.1036e-07, -1.1911e-07],\n              [ 9.4615e-09, -6.8455e-08, -5.8863e-08]],\n    \n             ...,\n    \n             [[ 3.5556e-08,  4.9518e-08,  3.1797e-08],\n              [ 5.9624e-08,  1.0939e-07,  4.8130e-08],\n              [-8.7479e-09, -9.7066e-09, -5.3168e-09]],\n    \n             [[ 1.2128e-08, -2.0999e-08, -5.5690e-08],\n              [ 6.6714e-08, -3.3924e-09, -4.1137e-08],\n              [ 4.5996e-08, -3.9422e-08, -1.2237e-07]],\n    \n             [[ 6.4599e-09,  8.7781e-08,  9.1340e-09],\n              [ 3.3670e-08,  2.2181e-08,  3.4034e-08],\n              [ 7.9031e-09, -1.8861e-08, -3.5941e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 1.0637e-08,  7.6297e-08,  6.6509e-08],\n              [ 7.1440e-08,  7.7294e-08,  8.2111e-08],\n              [ 7.3772e-08,  5.5385e-08,  4.6676e-08]],\n    \n             [[-4.9914e-08, -4.3642e-08, -1.8024e-08],\n              [-6.3171e-08, -1.1042e-07, -6.0901e-08],\n              [-2.8199e-08, -1.1873e-07, -6.6255e-08]],\n    \n             [[-2.7619e-08, -6.6145e-08, -7.5544e-08],\n              [-3.5064e-08, -8.9756e-08, -2.1127e-08],\n              [ 2.0870e-08,  4.8051e-09,  2.3249e-08]],\n    \n             ...,\n    \n             [[ 1.1791e-07,  1.1612e-07,  9.1331e-08],\n              [ 1.0125e-07,  1.2619e-07,  8.5687e-08],\n              [ 2.2950e-09,  1.9486e-10, -1.9319e-08]],\n    \n             [[ 5.5462e-08, -4.0584e-08, -2.5707e-08],\n              [-1.9959e-08, -6.0267e-08,  1.2798e-08],\n              [ 3.7332e-08, -2.1270e-09,  2.4890e-08]],\n    \n             [[ 3.6675e-08, -1.2721e-08, -1.8340e-08],\n              [ 1.2827e-07, -1.3160e-08, -3.9076e-08],\n              [-3.5443e-08, -4.7268e-08, -5.2679e-08]]],\n    \n    \n            [[[ 1.1610e-07,  9.6825e-08,  1.0611e-07],\n              [-1.1805e-08,  6.2757e-08,  9.9483e-08],\n              [-4.3719e-08,  7.1614e-09,  5.2363e-08]],\n    \n             [[ 7.2627e-08,  1.0783e-07,  9.4098e-08],\n              [ 1.6562e-07,  1.6005e-07,  6.2789e-08],\n              [ 4.0555e-09,  3.2211e-08,  4.4191e-08]],\n    \n             [[-2.7264e-08, -2.7812e-08,  2.9804e-08],\n              [-3.3438e-09,  1.1132e-07,  9.1185e-08],\n              [ 1.4710e-08,  4.4073e-08,  3.4833e-08]],\n    \n             ...,\n    \n             [[-1.6139e-07, -1.5173e-07, -1.0690e-07],\n              [-1.0256e-07, -2.1993e-07, -1.7309e-07],\n              [-7.4055e-08, -1.0412e-07, -7.7189e-08]],\n    \n             [[-6.2039e-09,  4.6353e-08,  2.0927e-08],\n              [ 4.2281e-08,  4.6516e-08,  6.4871e-08],\n              [-1.7053e-08,  5.9177e-08,  1.0046e-07]],\n    \n             [[-5.0936e-08, -7.3733e-08, -4.5674e-08],\n              [-3.2069e-08, -5.4358e-09,  3.1795e-08],\n              [-4.3614e-08,  2.8360e-09,  5.8139e-08]]],\n    \n    \n            [[[ 8.7384e-08,  7.3868e-08,  3.6692e-08],\n              [ 8.4094e-08,  3.5958e-08,  1.6781e-08],\n              [ 5.1641e-08,  1.5675e-08,  1.7420e-08]],\n    \n             [[ 1.1477e-07,  8.1305e-08,  5.4334e-08],\n              [ 1.3493e-07,  1.4081e-07,  8.6934e-08],\n              [ 1.0259e-07,  1.5812e-07,  1.1477e-07]],\n    \n             [[ 1.2106e-07,  1.2672e-07,  7.9393e-08],\n              [ 1.6220e-08, -2.1551e-09, -2.5215e-08],\n              [-3.9388e-08, -9.5521e-08, -1.0182e-07]],\n    \n             ...,\n    \n             [[ 4.8712e-08,  6.1172e-08,  1.0208e-08],\n              [ 5.9554e-08,  4.8187e-08, -1.5791e-08],\n              [ 2.1641e-08,  2.6155e-08,  6.6495e-08]],\n    \n             [[ 4.7070e-08, -2.6482e-08, -4.2665e-08],\n              [ 3.0430e-08,  3.1236e-09, -4.2644e-08],\n              [ 1.3003e-08,  1.2356e-08, -2.6507e-10]],\n    \n             [[-8.0703e-10, -7.3080e-08, -3.5148e-08],\n              [ 9.8427e-09, -1.6472e-07, -1.1334e-07],\n              [-2.0383e-08, -8.8732e-08, -9.0669e-08]]]]),\n    'exp_avg_sq': tensor([[[[4.0427e-14, 4.6264e-14, 4.2436e-14],\n              [4.4975e-14, 4.8004e-14, 4.5112e-14],\n              [3.6815e-14, 3.9753e-14, 3.7262e-14]],\n    \n             [[5.7965e-14, 8.8964e-14, 6.2225e-14],\n              [7.2275e-14, 1.0265e-13, 8.0617e-14],\n              [5.6486e-14, 7.0788e-14, 5.3923e-14]],\n    \n             [[4.2811e-14, 5.3719e-14, 4.5560e-14],\n              [5.5356e-14, 6.7911e-14, 6.0667e-14],\n              [4.9616e-14, 6.4311e-14, 5.5057e-14]],\n    \n             ...,\n    \n             [[6.6310e-14, 1.0115e-13, 6.4778e-14],\n              [7.5753e-14, 1.3833e-13, 7.7866e-14],\n              [4.8760e-14, 7.5683e-14, 4.7678e-14]],\n    \n             [[3.9100e-14, 5.3008e-14, 4.0099e-14],\n              [4.7373e-14, 5.7427e-14, 4.3594e-14],\n              [3.4584e-14, 3.8726e-14, 3.1141e-14]],\n    \n             [[3.6932e-14, 5.0117e-14, 3.5893e-14],\n              [4.4841e-14, 6.6494e-14, 4.0586e-14],\n              [3.2070e-14, 4.1571e-14, 2.9600e-14]]],\n    \n    \n            [[[6.2232e-14, 6.0392e-14, 6.1512e-14],\n              [4.5140e-14, 4.0426e-14, 3.9912e-14],\n              [5.0400e-14, 5.0906e-14, 4.5436e-14]],\n    \n             [[8.5530e-14, 1.3094e-13, 8.0715e-14],\n              [9.5883e-14, 1.5421e-13, 9.5846e-14],\n              [6.0493e-14, 8.5568e-14, 6.2245e-14]],\n    \n             [[5.1081e-14, 5.7359e-14, 5.6048e-14],\n              [5.2620e-14, 5.8654e-14, 4.9778e-14],\n              [7.5579e-14, 9.4928e-14, 7.8627e-14]],\n    \n             ...,\n    \n             [[1.1457e-13, 1.8835e-13, 1.2503e-13],\n              [1.4136e-13, 2.9499e-13, 1.6227e-13],\n              [9.6891e-14, 1.7032e-13, 1.1394e-13]],\n    \n             [[5.9291e-14, 8.7667e-14, 5.8268e-14],\n              [7.0824e-14, 1.0147e-13, 6.4235e-14],\n              [4.7434e-14, 6.2484e-14, 4.7715e-14]],\n    \n             [[6.6833e-14, 9.1715e-14, 7.0834e-14],\n              [5.9299e-14, 8.8638e-14, 6.1054e-14],\n              [4.7517e-14, 6.1066e-14, 4.8764e-14]]],\n    \n    \n            [[[6.3895e-14, 7.4657e-14, 6.1010e-14],\n              [5.4282e-14, 6.3363e-14, 5.0322e-14],\n              [4.3135e-14, 5.6958e-14, 4.3073e-14]],\n    \n             [[5.8268e-14, 8.5864e-14, 7.2045e-14],\n              [7.8294e-14, 1.0448e-13, 8.5678e-14],\n              [5.6027e-14, 7.8004e-14, 6.3459e-14]],\n    \n             [[4.2646e-14, 5.7848e-14, 4.8597e-14],\n              [3.8534e-14, 5.8328e-14, 4.9675e-14],\n              [4.0928e-14, 6.0732e-14, 4.9199e-14]],\n    \n             ...,\n    \n             [[5.5278e-14, 8.5122e-14, 8.3139e-14],\n              [6.6756e-14, 1.0180e-13, 8.6812e-14],\n              [3.8409e-14, 5.1129e-14, 5.4511e-14]],\n    \n             [[3.8862e-14, 5.4714e-14, 4.5890e-14],\n              [4.5810e-14, 5.6928e-14, 5.1038e-14],\n              [3.0130e-14, 4.3610e-14, 3.6398e-14]],\n    \n             [[3.7049e-14, 5.2863e-14, 5.5846e-14],\n              [3.5004e-14, 5.0291e-14, 4.7888e-14],\n              [2.7896e-14, 3.5633e-14, 3.8538e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[6.6244e-14, 8.3839e-14, 6.5099e-14],\n              [6.8782e-14, 8.8111e-14, 6.8080e-14],\n              [5.2402e-14, 6.6379e-14, 5.2353e-14]],\n    \n             [[5.9583e-14, 8.1065e-14, 6.0213e-14],\n              [7.2916e-14, 1.0951e-13, 7.5212e-14],\n              [5.5459e-14, 8.1535e-14, 5.6445e-14]],\n    \n             [[5.1044e-14, 6.9403e-14, 5.9524e-14],\n              [6.1964e-14, 9.9335e-14, 7.5392e-14],\n              [5.9010e-14, 7.4301e-14, 6.5276e-14]],\n    \n             ...,\n    \n             [[6.2936e-14, 9.2781e-14, 6.7548e-14],\n              [7.2280e-14, 1.2862e-13, 7.9671e-14],\n              [4.8968e-14, 7.9224e-14, 5.5182e-14]],\n    \n             [[5.1757e-14, 6.7488e-14, 5.5205e-14],\n              [5.6055e-14, 7.6589e-14, 5.9653e-14],\n              [4.4165e-14, 5.8177e-14, 4.4559e-14]],\n    \n             [[5.9203e-14, 8.3876e-14, 6.8142e-14],\n              [6.5541e-14, 9.7027e-14, 7.5063e-14],\n              [4.8758e-14, 6.7151e-14, 5.4030e-14]]],\n    \n    \n            [[[5.7726e-14, 5.7114e-14, 5.3470e-14],\n              [4.6212e-14, 4.5928e-14, 4.0182e-14],\n              [4.2313e-14, 3.9154e-14, 3.6559e-14]],\n    \n             [[7.6381e-14, 9.8309e-14, 6.7672e-14],\n              [1.0175e-13, 1.4531e-13, 9.5830e-14],\n              [7.5568e-14, 9.9185e-14, 7.6414e-14]],\n    \n             [[5.2464e-14, 5.5814e-14, 5.1226e-14],\n              [3.8521e-14, 3.7704e-14, 4.1142e-14],\n              [4.7179e-14, 5.5520e-14, 5.1922e-14]],\n    \n             ...,\n    \n             [[9.1336e-14, 1.4944e-13, 9.3917e-14],\n              [1.2210e-13, 2.3717e-13, 1.2085e-13],\n              [8.2342e-14, 1.3864e-13, 8.7699e-14]],\n    \n             [[5.6914e-14, 7.0919e-14, 5.3812e-14],\n              [6.3624e-14, 8.9677e-14, 5.7351e-14],\n              [5.1764e-14, 6.3954e-14, 4.7826e-14]],\n    \n             [[6.4399e-14, 8.9304e-14, 6.0702e-14],\n              [8.0247e-14, 1.2579e-13, 7.9383e-14],\n              [6.4877e-14, 9.0435e-14, 6.0591e-14]]],\n    \n    \n            [[[7.4223e-14, 9.8717e-14, 7.4960e-14],\n              [7.7248e-14, 1.0546e-13, 7.4473e-14],\n              [5.5994e-14, 6.7568e-14, 5.0962e-14]],\n    \n             [[4.5696e-14, 6.2390e-14, 5.5618e-14],\n              [5.2403e-14, 7.5363e-14, 5.7330e-14],\n              [4.6346e-14, 5.9503e-14, 4.7839e-14]],\n    \n             [[4.5396e-14, 6.2182e-14, 5.3486e-14],\n              [5.6570e-14, 9.1712e-14, 6.5165e-14],\n              [4.3491e-14, 5.7867e-14, 4.6471e-14]],\n    \n             ...,\n    \n             [[5.2778e-14, 7.5135e-14, 6.7293e-14],\n              [5.0478e-14, 7.4169e-14, 6.3757e-14],\n              [3.9319e-14, 5.1607e-14, 4.6619e-14]],\n    \n             [[3.3183e-14, 4.2158e-14, 3.9368e-14],\n              [3.5775e-14, 4.7625e-14, 4.1049e-14],\n              [2.7635e-14, 3.3957e-14, 2.9132e-14]],\n    \n             [[4.2731e-14, 5.8495e-14, 5.0738e-14],\n              [5.6891e-14, 8.2081e-14, 6.0048e-14],\n              [3.5467e-14, 5.0510e-14, 4.1051e-14]]]])},\n   137: {'exp_avg': tensor([[[[-9.7446e-08]],\n    \n             [[ 9.7872e-08]],\n    \n             [[-1.9957e-07]],\n    \n             ...,\n    \n             [[-1.1310e-07]],\n    \n             [[-4.5270e-08]],\n    \n             [[-5.0271e-08]]],\n    \n    \n            [[[-6.4347e-08]],\n    \n             [[ 1.3639e-08]],\n    \n             [[ 4.9246e-08]],\n    \n             ...,\n    \n             [[ 1.0920e-07]],\n    \n             [[ 8.4261e-08]],\n    \n             [[-7.4744e-08]]],\n    \n    \n            [[[ 2.3364e-08]],\n    \n             [[-2.6954e-08]],\n    \n             [[-5.1168e-08]],\n    \n             ...,\n    \n             [[-1.9600e-07]],\n    \n             [[-2.0310e-07]],\n    \n             [[-4.7226e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 1.5409e-08]],\n    \n             [[-1.0339e-07]],\n    \n             [[-9.9306e-09]],\n    \n             ...,\n    \n             [[ 3.6091e-08]],\n    \n             [[ 3.4180e-08]],\n    \n             [[-9.8153e-09]]],\n    \n    \n            [[[ 1.1999e-07]],\n    \n             [[ 7.0823e-08]],\n    \n             [[ 7.1882e-09]],\n    \n             ...,\n    \n             [[-1.1725e-07]],\n    \n             [[ 1.0940e-07]],\n    \n             [[-1.1531e-08]]],\n    \n    \n            [[[-1.5147e-07]],\n    \n             [[ 8.2019e-08]],\n    \n             [[ 1.1434e-07]],\n    \n             ...,\n    \n             [[ 7.4281e-08]],\n    \n             [[-5.5261e-08]],\n    \n             [[ 2.5302e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.4582e-13]],\n    \n             [[1.6459e-13]],\n    \n             [[1.0907e-13]],\n    \n             ...,\n    \n             [[2.0668e-13]],\n    \n             [[1.9229e-13]],\n    \n             [[1.1028e-13]]],\n    \n    \n            [[[8.9445e-14]],\n    \n             [[9.1958e-14]],\n    \n             [[6.8500e-14]],\n    \n             ...,\n    \n             [[1.0842e-13]],\n    \n             [[9.8122e-14]],\n    \n             [[6.3909e-14]]],\n    \n    \n            [[[2.6629e-13]],\n    \n             [[3.0440e-13]],\n    \n             [[2.6368e-13]],\n    \n             ...,\n    \n             [[3.2594e-13]],\n    \n             [[3.9606e-13]],\n    \n             [[2.2200e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[3.5649e-14]],\n    \n             [[4.0587e-14]],\n    \n             [[2.9376e-14]],\n    \n             ...,\n    \n             [[4.4908e-14]],\n    \n             [[3.9537e-14]],\n    \n             [[3.2293e-14]]],\n    \n    \n            [[[1.4851e-13]],\n    \n             [[1.3777e-13]],\n    \n             [[1.0026e-13]],\n    \n             ...,\n    \n             [[1.7790e-13]],\n    \n             [[1.6104e-13]],\n    \n             [[1.1187e-13]]],\n    \n    \n            [[[9.6749e-14]],\n    \n             [[1.0737e-13]],\n    \n             [[8.5202e-14]],\n    \n             ...,\n    \n             [[1.2293e-13]],\n    \n             [[1.0080e-13]],\n    \n             [[9.8225e-14]]]])},\n   138: {'exp_avg': tensor([[[[ 7.3855e-08]],\n    \n             [[ 1.4181e-08]],\n    \n             [[-6.9056e-08]],\n    \n             ...,\n    \n             [[-6.5273e-08]],\n    \n             [[ 8.1308e-08]],\n    \n             [[ 2.3553e-08]]],\n    \n    \n            [[[-1.3008e-08]],\n    \n             [[-3.2383e-09]],\n    \n             [[-1.2277e-07]],\n    \n             ...,\n    \n             [[-1.9212e-08]],\n    \n             [[-3.5933e-08]],\n    \n             [[-3.0826e-08]]],\n    \n    \n            [[[-1.1633e-07]],\n    \n             [[ 7.5680e-09]],\n    \n             [[-9.8346e-08]],\n    \n             ...,\n    \n             [[ 3.9078e-08]],\n    \n             [[-6.1750e-08]],\n    \n             [[ 2.6483e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-3.1912e-08]],\n    \n             [[-1.7969e-08]],\n    \n             [[-7.4448e-08]],\n    \n             ...,\n    \n             [[ 1.2196e-07]],\n    \n             [[-1.0876e-07]],\n    \n             [[-1.7482e-09]]],\n    \n    \n            [[[ 1.1502e-08]],\n    \n             [[ 1.8260e-08]],\n    \n             [[ 4.7429e-08]],\n    \n             ...,\n    \n             [[ 5.5578e-09]],\n    \n             [[-6.7842e-08]],\n    \n             [[-2.8382e-08]]],\n    \n    \n            [[[ 2.0394e-08]],\n    \n             [[-2.0294e-08]],\n    \n             [[ 5.5523e-08]],\n    \n             ...,\n    \n             [[ 9.0353e-08]],\n    \n             [[-7.1813e-08]],\n    \n             [[-1.8593e-08]]]]),\n    'exp_avg_sq': tensor([[[[4.1466e-14]],\n    \n             [[3.4875e-14]],\n    \n             [[6.3646e-14]],\n    \n             ...,\n    \n             [[4.0019e-14]],\n    \n             [[5.1231e-14]],\n    \n             [[2.5554e-14]]],\n    \n    \n            [[[4.5089e-14]],\n    \n             [[2.4049e-14]],\n    \n             [[4.9642e-14]],\n    \n             ...,\n    \n             [[2.2755e-14]],\n    \n             [[3.8609e-14]],\n    \n             [[5.5366e-14]]],\n    \n    \n            [[[5.1625e-14]],\n    \n             [[3.0099e-14]],\n    \n             [[9.2554e-14]],\n    \n             ...,\n    \n             [[2.6704e-14]],\n    \n             [[3.4827e-14]],\n    \n             [[4.2806e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[5.7616e-14]],\n    \n             [[4.1433e-14]],\n    \n             [[8.8091e-14]],\n    \n             ...,\n    \n             [[2.8640e-14]],\n    \n             [[7.8420e-14]],\n    \n             [[5.8183e-14]]],\n    \n    \n            [[[5.2490e-14]],\n    \n             [[2.7093e-14]],\n    \n             [[9.6172e-14]],\n    \n             ...,\n    \n             [[4.2025e-14]],\n    \n             [[6.1938e-14]],\n    \n             [[4.6714e-14]]],\n    \n    \n            [[[3.3818e-14]],\n    \n             [[2.1483e-14]],\n    \n             [[9.9818e-14]],\n    \n             ...,\n    \n             [[3.6482e-14]],\n    \n             [[2.6562e-14]],\n    \n             [[2.7476e-14]]]])},\n   139: {'exp_avg': tensor([[[[ 2.0584e-08,  3.5361e-08, -8.0159e-09],\n              [ 5.3983e-08,  1.2781e-07,  4.8308e-08],\n              [ 7.1786e-08,  7.0875e-08,  5.4163e-08]],\n    \n             [[-2.3140e-08,  3.1143e-08,  1.0806e-08],\n              [-7.6327e-09,  4.7489e-08,  5.1344e-08],\n              [-4.2873e-09,  5.2746e-08,  6.1546e-08]],\n    \n             [[ 4.1117e-08,  3.7720e-08,  2.1475e-08],\n              [ 7.6951e-08,  3.9121e-08,  8.4202e-09],\n              [ 4.1685e-08,  2.7903e-08,  6.7627e-09]],\n    \n             ...,\n    \n             [[ 1.5565e-08,  3.6064e-08, -2.0382e-08],\n              [ 2.5016e-08,  2.2597e-08,  4.9279e-08],\n              [ 2.8586e-08,  4.1963e-08,  6.7916e-09]],\n    \n             [[-3.4120e-08, -8.3051e-08,  1.0329e-08],\n              [ 7.1129e-09,  4.3472e-08,  6.1992e-08],\n              [-3.0012e-08,  1.1122e-07,  1.6036e-07]],\n    \n             [[-2.2208e-08,  2.8856e-08,  1.2892e-08],\n              [-2.5276e-08,  4.4575e-08,  3.1502e-08],\n              [ 3.0403e-08,  4.3345e-09,  2.8396e-08]]],\n    \n    \n            [[[-1.2063e-08,  2.4143e-08,  7.5137e-08],\n              [ 1.3361e-08,  1.2288e-07,  1.1630e-07],\n              [ 1.1801e-07,  1.5552e-07,  1.5155e-07]],\n    \n             [[-1.7560e-08,  2.5639e-08, -2.2481e-08],\n              [-7.3769e-08,  3.0162e-08, -1.7535e-09],\n              [-1.4988e-07,  1.5164e-08,  5.8894e-09]],\n    \n             [[ 5.4994e-09,  5.9291e-08,  2.8225e-08],\n              [ 1.4108e-08,  2.9498e-08,  7.4664e-08],\n              [-1.2914e-08,  1.2624e-08,  4.9191e-08]],\n    \n             ...,\n    \n             [[-7.2953e-08,  1.0677e-10, -2.6450e-08],\n              [-7.1438e-08, -2.6928e-08, -1.2535e-07],\n              [-7.1506e-08, -2.1258e-08, -7.6625e-08]],\n    \n             [[ 1.7905e-08,  2.6098e-08, -3.4346e-08],\n              [ 3.5559e-08,  4.4460e-08, -3.9450e-08],\n              [-1.6094e-08,  1.0437e-07, -4.8242e-09]],\n    \n             [[-2.1473e-08,  1.0443e-07,  1.0239e-07],\n              [ 3.0482e-08,  1.3534e-07,  1.1545e-07],\n              [ 2.4749e-08,  1.1284e-07,  3.0832e-08]]],\n    \n    \n            [[[-4.3064e-08, -1.6489e-08,  8.0160e-08],\n              [ 5.4422e-10,  4.3856e-09,  2.3113e-08],\n              [ 5.5376e-08,  2.8214e-08,  4.7382e-08]],\n    \n             [[-5.0595e-08, -3.3908e-08, -3.9274e-09],\n              [ 1.2770e-07,  6.0154e-08,  6.5062e-09],\n              [ 3.9180e-08,  2.3828e-08,  3.5105e-08]],\n    \n             [[ 5.1925e-08,  1.1646e-07,  4.8391e-08],\n              [ 9.8523e-08,  1.6928e-07,  8.5373e-08],\n              [ 9.7182e-08,  1.4338e-07,  1.2113e-07]],\n    \n             ...,\n    \n             [[-4.3297e-09,  1.8963e-08, -2.9639e-08],\n              [ 7.8744e-08,  4.3608e-08, -3.8985e-08],\n              [ 9.1496e-08,  1.0362e-08, -4.8174e-08]],\n    \n             [[-1.0329e-08,  4.5589e-09, -1.3672e-08],\n              [ 9.2013e-08,  1.0582e-07, -4.5389e-09],\n              [-3.1578e-08,  6.9875e-09,  2.1088e-08]],\n    \n             [[ 1.6739e-07,  1.5121e-07,  1.1928e-07],\n              [ 2.8653e-08, -1.2869e-08,  1.4671e-07],\n              [ 6.9189e-08,  6.6827e-08,  7.7340e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-4.4554e-09, -3.8518e-08, -3.1974e-08],\n              [-8.6323e-09, -3.2973e-08, -3.3105e-08],\n              [-6.3907e-08, -3.2452e-08, -9.1932e-08]],\n    \n             [[ 1.3731e-08, -2.8635e-08, -3.2142e-08],\n              [ 1.8569e-08,  6.5878e-08,  5.2974e-08],\n              [ 1.4979e-08,  9.5556e-08, -1.3095e-08]],\n    \n             [[ 2.1446e-08, -1.5354e-08, -1.5465e-08],\n              [-2.1249e-08,  2.7146e-08,  1.9698e-08],\n              [ 4.3212e-09,  5.6416e-08,  1.1323e-07]],\n    \n             ...,\n    \n             [[ 3.5933e-08,  4.2670e-08,  1.3171e-08],\n              [ 2.8543e-08,  2.8920e-08,  2.6779e-08],\n              [ 3.9955e-08,  7.2789e-08,  3.8858e-08]],\n    \n             [[ 1.0575e-09,  1.6318e-08, -3.2476e-08],\n              [-1.0100e-08,  4.0823e-08, -3.7736e-08],\n              [-8.3424e-08, -3.3654e-08, -9.1217e-08]],\n    \n             [[ 5.4378e-08,  4.2143e-08,  2.6048e-08],\n              [-2.3645e-08, -5.4640e-08,  1.3588e-09],\n              [-4.6235e-08, -2.9210e-08, -2.9920e-08]]],\n    \n    \n            [[[-8.7282e-08,  7.7269e-09, -8.5869e-08],\n              [-1.1965e-08, -4.7708e-08, -6.1704e-08],\n              [ 8.1479e-08, -3.4331e-08,  1.0786e-08]],\n    \n             [[ 3.1751e-08, -5.1367e-08,  1.6188e-09],\n              [ 3.6948e-08,  4.8658e-08,  1.6265e-08],\n              [-2.0282e-08,  9.9770e-09, -1.0881e-07]],\n    \n             [[-2.2196e-08, -4.4467e-08, -3.5029e-08],\n              [-2.1817e-08,  2.7717e-09, -6.9646e-10],\n              [-1.2099e-07, -3.6814e-08, -5.6461e-09]],\n    \n             ...,\n    \n             [[ 2.7331e-08, -2.3669e-08, -1.7983e-08],\n              [ 1.2282e-07,  1.1782e-07,  2.6923e-08],\n              [-2.9639e-08,  6.4986e-08, -1.1846e-08]],\n    \n             [[ 1.0580e-07,  6.3160e-08,  7.8527e-08],\n              [ 1.1456e-07,  8.3204e-08,  2.0161e-08],\n              [-1.4082e-08,  5.7236e-09,  2.3029e-08]],\n    \n             [[-1.3852e-08,  1.9709e-08,  1.0075e-08],\n              [ 5.0625e-08,  1.1739e-07,  8.7225e-08],\n              [ 1.1561e-07,  1.0113e-07,  1.2890e-07]]],\n    \n    \n            [[[ 5.4963e-08, -2.6711e-08,  2.3333e-08],\n              [ 5.5460e-08,  7.0619e-08,  3.9453e-09],\n              [ 5.3786e-08,  7.5465e-08,  4.6626e-08]],\n    \n             [[-5.0308e-08, -3.0980e-08, -1.1156e-09],\n              [ 2.7662e-08,  3.0981e-08,  5.4825e-08],\n              [ 4.3978e-08,  1.1570e-07,  4.8899e-08]],\n    \n             [[-3.0026e-08, -3.1521e-08, -2.2074e-08],\n              [-7.2916e-09,  1.0188e-08,  2.7485e-08],\n              [ 6.8849e-09,  5.0638e-08,  2.9851e-08]],\n    \n             ...,\n    \n             [[-1.0228e-07, -1.2267e-07, -6.9132e-08],\n              [-5.0746e-08, -6.2109e-08, -4.3239e-08],\n              [-3.1386e-08,  1.5672e-08, -4.4625e-08]],\n    \n             [[ 4.1514e-08,  6.8441e-08,  3.0012e-08],\n              [-2.3543e-08,  3.8544e-09, -2.2390e-09],\n              [-4.5690e-08,  3.6778e-08, -3.9522e-09]],\n    \n             [[-5.0393e-08, -2.7456e-08, -2.9902e-08],\n              [ 2.5002e-08,  6.6419e-08, -5.1261e-09],\n              [ 2.9981e-08,  7.1733e-09,  3.3784e-08]]]]),\n    'exp_avg_sq': tensor([[[[3.6564e-14, 5.5127e-14, 4.1897e-14],\n              [4.5047e-14, 7.3617e-14, 5.0674e-14],\n              [3.4950e-14, 5.1030e-14, 4.0526e-14]],\n    \n             [[4.2551e-14, 6.1567e-14, 4.1890e-14],\n              [4.0581e-14, 6.0394e-14, 4.2866e-14],\n              [2.9299e-14, 4.6175e-14, 3.1768e-14]],\n    \n             [[3.9198e-14, 5.7078e-14, 4.7616e-14],\n              [4.5800e-14, 5.8588e-14, 5.9091e-14],\n              [3.8281e-14, 5.5081e-14, 5.9101e-14]],\n    \n             ...,\n    \n             [[6.0587e-14, 8.5013e-14, 6.0933e-14],\n              [6.0684e-14, 9.5016e-14, 6.8402e-14],\n              [4.4214e-14, 7.0750e-14, 5.4471e-14]],\n    \n             [[4.5654e-14, 7.0240e-14, 6.2735e-14],\n              [6.1515e-14, 9.6134e-14, 8.6523e-14],\n              [6.3070e-14, 8.7731e-14, 8.5157e-14]],\n    \n             [[4.0556e-14, 5.6026e-14, 5.2262e-14],\n              [4.7220e-14, 7.4752e-14, 6.7785e-14],\n              [3.2770e-14, 4.7529e-14, 4.6157e-14]]],\n    \n    \n            [[[5.0900e-14, 6.4681e-14, 5.1904e-14],\n              [6.6967e-14, 9.0317e-14, 7.2961e-14],\n              [6.5077e-14, 8.6530e-14, 7.2668e-14]],\n    \n             [[5.4096e-14, 6.9362e-14, 5.6305e-14],\n              [5.8360e-14, 7.8448e-14, 6.1639e-14],\n              [4.2307e-14, 5.8607e-14, 4.8578e-14]],\n    \n             [[4.6455e-14, 6.2256e-14, 5.4163e-14],\n              [5.8870e-14, 8.1240e-14, 7.5661e-14],\n              [6.4197e-14, 8.7715e-14, 8.2339e-14]],\n    \n             ...,\n    \n             [[7.0796e-14, 1.0088e-13, 8.0980e-14],\n              [8.3313e-14, 1.1954e-13, 9.7057e-14],\n              [6.4693e-14, 8.9445e-14, 8.0452e-14]],\n    \n             [[5.4302e-14, 8.1203e-14, 6.5198e-14],\n              [7.7221e-14, 1.1474e-13, 9.4156e-14],\n              [9.3286e-14, 1.3576e-13, 1.0878e-13]],\n    \n             [[4.8661e-14, 7.3803e-14, 5.8094e-14],\n              [6.0374e-14, 9.0517e-14, 7.3372e-14],\n              [4.9364e-14, 7.3452e-14, 5.9332e-14]]],\n    \n    \n            [[[6.4971e-14, 7.4799e-14, 6.1473e-14],\n              [7.6410e-14, 7.9405e-14, 8.8483e-14],\n              [6.5999e-14, 5.9145e-14, 6.2405e-14]],\n    \n             [[5.9141e-14, 6.1325e-14, 5.0534e-14],\n              [4.5771e-14, 6.0860e-14, 4.5262e-14],\n              [3.3588e-14, 4.2204e-14, 3.2985e-14]],\n    \n             [[5.1448e-14, 5.2821e-14, 3.7548e-14],\n              [6.3233e-14, 9.1045e-14, 4.3950e-14],\n              [5.1985e-14, 7.1517e-14, 4.4296e-14]],\n    \n             ...,\n    \n             [[7.9663e-14, 8.2849e-14, 7.2093e-14],\n              [8.2193e-14, 9.1049e-14, 9.1791e-14],\n              [5.2554e-14, 6.6360e-14, 6.7328e-14]],\n    \n             [[6.5344e-14, 8.0688e-14, 5.6558e-14],\n              [9.7581e-14, 1.1119e-13, 7.6580e-14],\n              [1.0517e-13, 1.2155e-13, 8.7484e-14]],\n    \n             [[5.8019e-14, 8.5467e-14, 4.9807e-14],\n              [6.9348e-14, 1.0170e-13, 6.1512e-14],\n              [4.7179e-14, 5.7120e-14, 4.2719e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[3.8173e-14, 4.8582e-14, 3.6588e-14],\n              [4.8668e-14, 6.4331e-14, 5.6882e-14],\n              [4.0395e-14, 6.0500e-14, 4.7216e-14]],\n    \n             [[4.1046e-14, 5.6892e-14, 4.2339e-14],\n              [3.9056e-14, 6.4750e-14, 4.4972e-14],\n              [2.5959e-14, 3.7299e-14, 2.6666e-14]],\n    \n             [[2.7539e-14, 3.9504e-14, 3.2966e-14],\n              [3.2715e-14, 4.6012e-14, 3.6603e-14],\n              [2.6400e-14, 3.2001e-14, 3.1339e-14]],\n    \n             ...,\n    \n             [[4.9485e-14, 7.1203e-14, 5.2908e-14],\n              [5.1684e-14, 8.4829e-14, 6.1455e-14],\n              [3.8090e-14, 5.7205e-14, 4.8000e-14]],\n    \n             [[5.3555e-14, 6.8707e-14, 5.6104e-14],\n              [8.1287e-14, 1.0328e-13, 8.0612e-14],\n              [7.0546e-14, 8.6882e-14, 7.7120e-14]],\n    \n             [[4.4911e-14, 5.1453e-14, 4.3506e-14],\n              [5.6013e-14, 7.1665e-14, 5.8639e-14],\n              [3.8819e-14, 5.6330e-14, 4.6874e-14]]],\n    \n    \n            [[[5.3257e-14, 6.2229e-14, 4.6431e-14],\n              [6.1288e-14, 9.2075e-14, 6.3359e-14],\n              [4.8532e-14, 6.6515e-14, 4.7676e-14]],\n    \n             [[5.2178e-14, 7.1206e-14, 5.3346e-14],\n              [5.9993e-14, 7.6232e-14, 6.2596e-14],\n              [3.1557e-14, 2.9363e-14, 3.5633e-14]],\n    \n             [[4.5740e-14, 5.8854e-14, 4.5659e-14],\n              [6.0096e-14, 7.7523e-14, 6.0120e-14],\n              [4.2073e-14, 4.9076e-14, 4.5686e-14]],\n    \n             ...,\n    \n             [[6.0380e-14, 8.3704e-14, 6.6989e-14],\n              [6.8164e-14, 9.0433e-14, 7.5320e-14],\n              [4.7135e-14, 5.3416e-14, 5.0056e-14]],\n    \n             [[6.1646e-14, 8.1701e-14, 7.1829e-14],\n              [8.7391e-14, 8.7598e-14, 8.9316e-14],\n              [6.5978e-14, 7.1382e-14, 7.0511e-14]],\n    \n             [[3.2392e-14, 5.1343e-14, 3.8531e-14],\n              [5.4086e-14, 9.8668e-14, 6.3698e-14],\n              [4.2036e-14, 7.8803e-14, 5.4699e-14]]],\n    \n    \n            [[[4.4855e-14, 6.8628e-14, 4.9938e-14],\n              [5.3219e-14, 7.9649e-14, 5.9724e-14],\n              [3.9358e-14, 5.7496e-14, 4.0589e-14]],\n    \n             [[3.8853e-14, 5.4009e-14, 3.8918e-14],\n              [4.2980e-14, 6.4240e-14, 4.8263e-14],\n              [2.9823e-14, 4.0140e-14, 3.1241e-14]],\n    \n             [[2.9690e-14, 3.7284e-14, 3.6165e-14],\n              [4.0788e-14, 5.1345e-14, 4.8320e-14],\n              [3.9927e-14, 5.0946e-14, 4.6143e-14]],\n    \n             ...,\n    \n             [[5.0420e-14, 6.3764e-14, 5.2625e-14],\n              [6.2426e-14, 9.5468e-14, 6.9881e-14],\n              [4.7731e-14, 6.7616e-14, 5.3144e-14]],\n    \n             [[5.4227e-14, 7.5991e-14, 6.5971e-14],\n              [7.5158e-14, 9.3671e-14, 8.2982e-14],\n              [7.5424e-14, 9.5197e-14, 8.4521e-14]],\n    \n             [[3.0786e-14, 4.5747e-14, 3.3108e-14],\n              [3.8900e-14, 5.8708e-14, 4.2272e-14],\n              [3.3178e-14, 4.2009e-14, 3.5899e-14]]]])},\n   140: {'exp_avg': tensor([[[[-1.0492e-07]],\n    \n             [[ 6.3009e-08]],\n    \n             [[-1.7607e-09]],\n    \n             ...,\n    \n             [[-8.8491e-08]],\n    \n             [[-3.2478e-08]],\n    \n             [[ 1.2452e-07]]],\n    \n    \n            [[[-1.2476e-07]],\n    \n             [[-8.8267e-08]],\n    \n             [[-1.8617e-07]],\n    \n             ...,\n    \n             [[ 1.4936e-07]],\n    \n             [[-4.2524e-08]],\n    \n             [[-9.3501e-08]]],\n    \n    \n            [[[-3.2660e-08]],\n    \n             [[ 9.0175e-09]],\n    \n             [[ 1.1152e-07]],\n    \n             ...,\n    \n             [[ 4.9053e-10]],\n    \n             [[-5.9975e-08]],\n    \n             [[-4.8838e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 1.4088e-09]],\n    \n             [[ 4.8630e-08]],\n    \n             [[-3.0918e-09]],\n    \n             ...,\n    \n             [[-1.6333e-08]],\n    \n             [[ 9.2878e-09]],\n    \n             [[-4.2521e-08]]],\n    \n    \n            [[[-3.4279e-08]],\n    \n             [[ 6.1082e-08]],\n    \n             [[ 4.3913e-08]],\n    \n             ...,\n    \n             [[-6.4934e-08]],\n    \n             [[ 2.6482e-08]],\n    \n             [[ 6.5737e-08]]],\n    \n    \n            [[[ 5.2371e-08]],\n    \n             [[-5.7503e-08]],\n    \n             [[ 8.3390e-08]],\n    \n             ...,\n    \n             [[ 5.0821e-08]],\n    \n             [[-6.4667e-08]],\n    \n             [[ 7.5661e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.2876e-13]],\n    \n             [[2.2412e-13]],\n    \n             [[1.6853e-13]],\n    \n             ...,\n    \n             [[2.3966e-13]],\n    \n             [[1.2676e-13]],\n    \n             [[1.6736e-13]]],\n    \n    \n            [[[1.1917e-13]],\n    \n             [[1.6415e-13]],\n    \n             [[1.3786e-13]],\n    \n             ...,\n    \n             [[2.0427e-13]],\n    \n             [[1.2598e-13]],\n    \n             [[1.4754e-13]]],\n    \n    \n            [[[8.1017e-14]],\n    \n             [[1.2087e-13]],\n    \n             [[1.0129e-13]],\n    \n             ...,\n    \n             [[1.4075e-13]],\n    \n             [[6.8195e-14]],\n    \n             [[7.3434e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[2.7149e-15]],\n    \n             [[4.1638e-15]],\n    \n             [[3.1248e-15]],\n    \n             ...,\n    \n             [[4.7181e-15]],\n    \n             [[2.4918e-15]],\n    \n             [[3.2334e-15]]],\n    \n    \n            [[[6.4019e-14]],\n    \n             [[8.7549e-14]],\n    \n             [[8.4351e-14]],\n    \n             ...,\n    \n             [[9.1802e-14]],\n    \n             [[5.2619e-14]],\n    \n             [[7.5176e-14]]],\n    \n    \n            [[[1.0729e-13]],\n    \n             [[1.3691e-13]],\n    \n             [[1.0542e-13]],\n    \n             ...,\n    \n             [[1.6896e-13]],\n    \n             [[8.2348e-14]],\n    \n             [[1.1471e-13]]]])},\n   141: {'exp_avg': tensor([[[[ 3.1620e-08]],\n    \n             [[ 1.8581e-08]],\n    \n             [[-4.6823e-08]],\n    \n             ...,\n    \n             [[ 2.4684e-08]],\n    \n             [[-7.3456e-08]],\n    \n             [[ 8.3147e-08]]],\n    \n    \n            [[[ 1.0238e-07]],\n    \n             [[ 8.3460e-08]],\n    \n             [[ 4.1071e-08]],\n    \n             ...,\n    \n             [[ 1.6951e-08]],\n    \n             [[ 6.9111e-08]],\n    \n             [[ 5.9613e-08]]],\n    \n    \n            [[[ 2.0304e-08]],\n    \n             [[ 3.0950e-08]],\n    \n             [[-6.3189e-09]],\n    \n             ...,\n    \n             [[ 6.1936e-08]],\n    \n             [[ 3.2470e-08]],\n    \n             [[ 3.9552e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 1.1293e-08]],\n    \n             [[-1.4950e-07]],\n    \n             [[-2.9819e-08]],\n    \n             ...,\n    \n             [[-4.9195e-08]],\n    \n             [[-9.4361e-08]],\n    \n             [[-2.2547e-08]]],\n    \n    \n            [[[-1.5588e-09]],\n    \n             [[ 8.5719e-08]],\n    \n             [[-5.7416e-09]],\n    \n             ...,\n    \n             [[-4.9632e-09]],\n    \n             [[-1.0956e-07]],\n    \n             [[-5.2812e-08]]],\n    \n    \n            [[[ 4.8540e-08]],\n    \n             [[ 7.0318e-08]],\n    \n             [[-4.2473e-09]],\n    \n             ...,\n    \n             [[-1.5676e-08]],\n    \n             [[ 8.2049e-09]],\n    \n             [[ 3.5778e-08]]]]),\n    'exp_avg_sq': tensor([[[[7.6272e-14]],\n    \n             [[4.7037e-14]],\n    \n             [[4.6434e-14]],\n    \n             ...,\n    \n             [[3.4703e-14]],\n    \n             [[5.6800e-14]],\n    \n             [[5.5819e-14]]],\n    \n    \n            [[[5.6310e-14]],\n    \n             [[6.9088e-14]],\n    \n             [[9.3780e-14]],\n    \n             ...,\n    \n             [[6.7106e-14]],\n    \n             [[9.8273e-14]],\n    \n             [[5.0015e-14]]],\n    \n    \n            [[[6.5315e-14]],\n    \n             [[5.0377e-14]],\n    \n             [[1.0504e-13]],\n    \n             ...,\n    \n             [[5.2372e-14]],\n    \n             [[7.7047e-14]],\n    \n             [[3.1143e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[6.4547e-14]],\n    \n             [[6.4069e-14]],\n    \n             [[8.8720e-14]],\n    \n             ...,\n    \n             [[5.6629e-14]],\n    \n             [[8.1023e-14]],\n    \n             [[5.7112e-14]]],\n    \n    \n            [[[5.9538e-14]],\n    \n             [[4.8480e-14]],\n    \n             [[8.5676e-14]],\n    \n             ...,\n    \n             [[4.1202e-14]],\n    \n             [[5.8424e-14]],\n    \n             [[5.3321e-14]]],\n    \n    \n            [[[7.1031e-14]],\n    \n             [[6.0440e-14]],\n    \n             [[9.7959e-14]],\n    \n             ...,\n    \n             [[5.8021e-14]],\n    \n             [[1.0141e-13]],\n    \n             [[5.3052e-14]]]])},\n   142: {'exp_avg': tensor([[[[ 3.3232e-08,  1.0987e-08, -2.7552e-08],\n              [-1.6850e-08, -1.5939e-08, -8.2423e-09],\n              [-4.1088e-08, -3.2608e-08, -3.7456e-08]],\n    \n             [[ 7.1413e-08,  9.5131e-08,  1.0735e-07],\n              [ 6.7218e-10, -2.9935e-08,  2.1545e-08],\n              [-5.9121e-08,  8.5951e-09,  5.5727e-08]],\n    \n             [[-2.2888e-08,  5.8866e-08,  5.3364e-08],\n              [-2.7187e-08,  7.6173e-08,  1.1996e-07],\n              [ 1.2749e-08,  5.8119e-09,  5.8630e-08]],\n    \n             ...,\n    \n             [[ 3.1242e-08, -1.2183e-08,  4.2923e-08],\n              [ 2.8294e-08, -3.9704e-08,  4.4992e-08],\n              [-1.7415e-08,  1.5800e-08,  6.9337e-08]],\n    \n             [[ 7.8333e-08,  6.7776e-08,  5.9717e-08],\n              [-1.6887e-08, -7.9384e-09,  1.9212e-08],\n              [-1.0830e-08,  1.9060e-08,  5.8170e-08]],\n    \n             [[-5.3513e-09, -3.1444e-08,  7.1785e-08],\n              [-3.3560e-08, -3.7184e-08,  8.6856e-08],\n              [-1.0731e-07, -1.4705e-07, -2.9176e-08]]],\n    \n    \n            [[[-1.1525e-08,  2.0576e-08,  2.8089e-08],\n              [-1.0271e-07, -2.6252e-08,  1.7508e-08],\n              [-4.1300e-08, -7.7050e-08, -7.4548e-08]],\n    \n             [[ 1.5105e-08, -2.0677e-08, -5.3634e-08],\n              [ 7.1778e-08,  9.1452e-09, -8.3635e-09],\n              [ 8.0258e-08,  4.5767e-09,  6.3145e-09]],\n    \n             [[ 3.8345e-08, -8.3387e-09, -1.2318e-08],\n              [ 5.0739e-08, -7.5154e-08, -5.0527e-08],\n              [ 3.5403e-08,  5.1486e-08,  7.8317e-08]],\n    \n             ...,\n    \n             [[-3.6313e-08, -6.5864e-08, -5.2691e-08],\n              [-2.7272e-08,  3.5501e-08, -4.5764e-09],\n              [ 3.4399e-08,  4.9119e-08,  1.1959e-07]],\n    \n             [[-1.8671e-08,  6.3966e-09,  4.8688e-08],\n              [-1.7274e-08,  2.3405e-08,  6.0679e-08],\n              [ 3.0670e-08,  5.2442e-08,  1.9978e-08]],\n    \n             [[-6.8543e-08, -1.3210e-07, -1.1671e-07],\n              [-1.2234e-07, -1.4215e-07, -1.3280e-07],\n              [-8.9618e-08, -6.5614e-08,  5.7673e-09]]],\n    \n    \n            [[[ 2.7313e-08, -1.0099e-08,  2.7435e-08],\n              [-4.9063e-08, -7.1267e-08, -7.7137e-08],\n              [-1.2865e-08, -3.5787e-09,  1.8858e-08]],\n    \n             [[-1.1835e-08, -2.5773e-08, -5.3462e-08],\n              [ 4.7844e-08, -4.8647e-08, -1.5730e-08],\n              [ 6.3624e-08,  9.5732e-08,  4.9805e-08]],\n    \n             [[-5.8743e-08,  3.2650e-08,  6.4903e-08],\n              [-4.9645e-09,  6.9787e-08,  1.0242e-07],\n              [ 1.8697e-08,  1.0925e-08,  6.1224e-08]],\n    \n             ...,\n    \n             [[-1.3625e-08, -4.7477e-08, -1.0736e-07],\n              [ 1.5752e-08, -1.6404e-09, -5.0506e-08],\n              [ 9.0418e-08,  5.8142e-08,  1.1098e-08]],\n    \n             [[ 1.3542e-07,  1.1158e-07,  1.4712e-07],\n              [ 6.5051e-08,  1.6092e-07,  1.7913e-07],\n              [ 6.3781e-08,  9.6100e-08,  1.1841e-07]],\n    \n             [[ 5.8123e-08,  6.4895e-08,  1.9116e-08],\n              [ 1.0069e-07,  7.6011e-08,  8.6300e-09],\n              [ 8.7783e-08,  7.1931e-08, -2.5622e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-9.1199e-08, -1.5687e-08,  1.8513e-10],\n              [ 3.1991e-08,  7.9347e-08,  6.4156e-08],\n              [-2.4509e-08,  4.8070e-08, -1.8560e-09]],\n    \n             [[-3.7222e-08, -6.4300e-08, -3.2494e-09],\n              [ 6.1997e-08,  3.2032e-08,  1.2995e-07],\n              [ 9.1341e-09,  1.1240e-07,  3.9811e-08]],\n    \n             [[-5.0027e-08, -6.3858e-08, -2.0831e-08],\n              [ 5.9058e-08,  1.1479e-07,  9.5822e-08],\n              [ 3.2578e-08, -4.1756e-09,  6.3997e-08]],\n    \n             ...,\n    \n             [[-1.0498e-07, -7.5006e-08,  4.3057e-08],\n              [-9.6228e-08, -7.7965e-08,  1.4670e-07],\n              [-7.4012e-08, -1.4968e-08,  3.2295e-08]],\n    \n             [[-1.1475e-07, -4.3903e-08, -5.9606e-08],\n              [-6.6921e-08,  2.8168e-08, -1.5583e-08],\n              [-5.7085e-08,  3.5655e-08, -2.7733e-08]],\n    \n             [[-9.0461e-08, -6.3615e-08, -1.1099e-08],\n              [-1.0943e-07, -4.2617e-08,  5.9480e-08],\n              [-5.5578e-08,  9.2174e-09,  1.8129e-08]]],\n    \n    \n            [[[-3.2304e-08,  3.4884e-09, -1.8295e-08],\n              [-2.6255e-08, -4.0777e-08,  4.1768e-09],\n              [-6.6566e-08, -3.4326e-08, -9.8585e-09]],\n    \n             [[-6.9516e-08, -5.1245e-09, -3.5838e-08],\n              [ 1.1903e-08, -1.0459e-08, -1.4185e-08],\n              [-3.4839e-09, -3.7773e-08, -1.9009e-08]],\n    \n             [[-5.3079e-08, -4.9184e-08,  1.2573e-08],\n              [-8.7834e-08,  3.6918e-08, -6.4427e-08],\n              [-3.1658e-08,  3.8861e-08,  1.5179e-08]],\n    \n             ...,\n    \n             [[-4.5564e-08, -5.2440e-08, -1.1594e-07],\n              [ 2.4338e-08, -3.2121e-08, -8.2614e-08],\n              [-4.4856e-08, -1.3962e-09, -5.4651e-08]],\n    \n             [[-6.6557e-08, -5.8884e-08, -4.8627e-08],\n              [ 1.2341e-08,  4.5815e-08,  6.0513e-08],\n              [ 2.7131e-08,  4.1601e-08,  6.5195e-08]],\n    \n             [[-8.8173e-08, -2.0137e-07, -1.2375e-07],\n              [ 1.2337e-08, -1.1019e-07, -1.0578e-07],\n              [-3.5967e-08, -9.9334e-08, -1.7310e-08]]],\n    \n    \n            [[[ 4.7830e-08,  8.8992e-08,  1.0230e-07],\n              [ 1.6935e-08,  1.0582e-07,  1.1770e-07],\n              [-7.0072e-09,  8.8360e-08,  1.3206e-07]],\n    \n             [[ 9.1454e-08,  8.5109e-08,  1.1663e-09],\n              [ 2.1001e-08,  1.0179e-07,  4.0333e-08],\n              [ 4.0024e-08,  1.2601e-08,  3.7258e-08]],\n    \n             [[ 1.1296e-09, -1.7370e-08, -3.4655e-08],\n              [-1.0574e-07, -2.6806e-08, -9.8289e-08],\n              [-3.8424e-08, -3.2087e-08, -4.5694e-08]],\n    \n             ...,\n    \n             [[ 7.2047e-08,  1.8101e-07,  8.7026e-08],\n              [ 1.5805e-08,  8.3076e-08,  9.7895e-08],\n              [-1.4794e-08, -3.6658e-08,  2.3548e-09]],\n    \n             [[-3.5167e-08,  6.6206e-08,  9.6796e-08],\n              [-4.2428e-08,  3.2150e-08,  2.1005e-08],\n              [ 6.1460e-08,  7.1620e-08,  8.0358e-08]],\n    \n             [[ 1.6375e-07,  1.8184e-07,  8.4039e-08],\n              [ 9.2395e-08,  1.0277e-07,  1.4816e-07],\n              [ 7.9405e-08,  7.0419e-09,  5.4917e-08]]]]),\n    'exp_avg_sq': tensor([[[[2.1518e-14, 3.1903e-14, 2.2489e-14],\n              [3.3312e-14, 4.5919e-14, 3.8211e-14],\n              [2.8442e-14, 4.0648e-14, 3.6864e-14]],\n    \n             [[4.1871e-14, 6.4942e-14, 4.7570e-14],\n              [5.6264e-14, 8.9358e-14, 6.9721e-14],\n              [4.4447e-14, 7.5776e-14, 5.8424e-14]],\n    \n             [[4.0453e-14, 4.2305e-14, 3.7193e-14],\n              [5.5531e-14, 7.0594e-14, 6.2202e-14],\n              [4.8487e-14, 7.1569e-14, 5.9671e-14]],\n    \n             ...,\n    \n             [[3.7493e-14, 5.7416e-14, 4.4499e-14],\n              [5.4964e-14, 9.5843e-14, 7.0554e-14],\n              [4.0600e-14, 7.3303e-14, 5.4869e-14]],\n    \n             [[4.3005e-14, 7.1858e-14, 5.4403e-14],\n              [5.4599e-14, 8.9550e-14, 7.0419e-14],\n              [3.4542e-14, 5.8590e-14, 4.9902e-14]],\n    \n             [[4.6176e-14, 6.1583e-14, 5.0578e-14],\n              [6.8733e-14, 9.0671e-14, 7.0067e-14],\n              [6.0062e-14, 8.7445e-14, 7.1858e-14]]],\n    \n    \n            [[[2.8179e-14, 3.2090e-14, 2.9259e-14],\n              [3.8065e-14, 6.5917e-14, 4.9182e-14],\n              [3.6548e-14, 5.2003e-14, 4.4515e-14]],\n    \n             [[4.5816e-14, 5.7018e-14, 3.9511e-14],\n              [6.4232e-14, 7.4348e-14, 4.5035e-14],\n              [5.8407e-14, 7.7272e-14, 5.4291e-14]],\n    \n             [[5.2460e-14, 6.8311e-14, 4.8537e-14],\n              [6.9492e-14, 7.7132e-14, 5.3768e-14],\n              [6.1635e-14, 7.0982e-14, 4.9562e-14]],\n    \n             ...,\n    \n             [[4.3335e-14, 5.6914e-14, 3.6282e-14],\n              [6.2419e-14, 8.6155e-14, 5.5866e-14],\n              [5.1668e-14, 8.6505e-14, 6.2036e-14]],\n    \n             [[4.2777e-14, 6.7142e-14, 5.4691e-14],\n              [4.4532e-14, 6.9076e-14, 5.3699e-14],\n              [3.4656e-14, 5.3555e-14, 4.3542e-14]],\n    \n             [[5.6138e-14, 6.7703e-14, 4.8066e-14],\n              [7.8926e-14, 8.7075e-14, 6.4352e-14],\n              [6.9769e-14, 8.7956e-14, 6.4455e-14]]],\n    \n    \n            [[[2.8312e-14, 3.3176e-14, 2.9151e-14],\n              [3.8173e-14, 5.3962e-14, 4.6215e-14],\n              [3.3517e-14, 4.7785e-14, 4.1215e-14]],\n    \n             [[4.0357e-14, 5.8688e-14, 4.8532e-14],\n              [4.4795e-14, 7.0697e-14, 5.8573e-14],\n              [2.9811e-14, 5.8054e-14, 5.0980e-14]],\n    \n             [[3.9260e-14, 6.3646e-14, 5.6801e-14],\n              [4.9871e-14, 7.9564e-14, 7.8434e-14],\n              [3.4139e-14, 6.1799e-14, 5.6857e-14]],\n    \n             ...,\n    \n             [[3.9299e-14, 6.1795e-14, 5.3000e-14],\n              [4.9300e-14, 8.5720e-14, 6.8318e-14],\n              [2.7143e-14, 5.0654e-14, 4.3175e-14]],\n    \n             [[4.1279e-14, 6.6537e-14, 5.9102e-14],\n              [4.8768e-14, 8.1025e-14, 6.9863e-14],\n              [3.6549e-14, 6.1050e-14, 5.0475e-14]],\n    \n             [[5.0097e-14, 7.5705e-14, 6.9222e-14],\n              [5.8229e-14, 9.4457e-14, 9.0348e-14],\n              [3.7426e-14, 7.2775e-14, 7.0086e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[3.6935e-14, 4.8207e-14, 3.7381e-14],\n              [5.7120e-14, 8.5075e-14, 6.2812e-14],\n              [3.3712e-14, 4.9777e-14, 3.9211e-14]],\n    \n             [[4.1114e-14, 5.4549e-14, 4.2668e-14],\n              [5.8689e-14, 7.7008e-14, 6.1655e-14],\n              [5.4110e-14, 7.0747e-14, 5.9574e-14]],\n    \n             [[3.7640e-14, 4.9300e-14, 3.4662e-14],\n              [6.4316e-14, 8.8624e-14, 6.0865e-14],\n              [6.5425e-14, 9.7495e-14, 6.7978e-14]],\n    \n             ...,\n    \n             [[3.8189e-14, 5.3119e-14, 4.2106e-14],\n              [7.0328e-14, 9.7661e-14, 8.4620e-14],\n              [5.4676e-14, 7.6426e-14, 6.8387e-14]],\n    \n             [[4.6210e-14, 7.1358e-14, 5.0315e-14],\n              [6.4549e-14, 1.0226e-13, 8.1078e-14],\n              [4.1475e-14, 6.5795e-14, 5.2822e-14]],\n    \n             [[4.5652e-14, 5.3443e-14, 4.5926e-14],\n              [7.1064e-14, 9.4640e-14, 7.3363e-14],\n              [7.4303e-14, 9.7058e-14, 7.3270e-14]]],\n    \n    \n            [[[3.2856e-14, 4.2093e-14, 3.5799e-14],\n              [4.1471e-14, 6.0965e-14, 4.9392e-14],\n              [3.8257e-14, 5.9155e-14, 5.0219e-14]],\n    \n             [[4.4865e-14, 6.7032e-14, 5.5547e-14],\n              [4.7552e-14, 7.0502e-14, 6.5018e-14],\n              [3.4932e-14, 5.6784e-14, 4.8942e-14]],\n    \n             [[5.4488e-14, 8.6614e-14, 6.2668e-14],\n              [5.5848e-14, 9.9153e-14, 7.9496e-14],\n              [2.9295e-14, 4.8414e-14, 4.1817e-14]],\n    \n             ...,\n    \n             [[5.2001e-14, 8.4265e-14, 6.1600e-14],\n              [4.9130e-14, 7.4580e-14, 5.6472e-14],\n              [3.1625e-14, 5.1887e-14, 4.3998e-14]],\n    \n             [[4.6210e-14, 6.2155e-14, 5.5456e-14],\n              [3.9756e-14, 4.8932e-14, 4.0483e-14],\n              [2.9959e-14, 3.8468e-14, 3.2188e-14]],\n    \n             [[6.8441e-14, 9.5529e-14, 7.5084e-14],\n              [7.7773e-14, 1.1652e-13, 9.2534e-14],\n              [4.8181e-14, 7.3800e-14, 6.0493e-14]]],\n    \n    \n            [[[3.7356e-14, 4.8395e-14, 3.7689e-14],\n              [4.5619e-14, 6.9252e-14, 5.6704e-14],\n              [4.1337e-14, 5.8504e-14, 5.1131e-14]],\n    \n             [[5.1808e-14, 7.9609e-14, 6.6635e-14],\n              [7.2461e-14, 1.0665e-13, 8.0655e-14],\n              [4.9510e-14, 6.2609e-14, 5.1578e-14]],\n    \n             [[4.4421e-14, 6.6170e-14, 6.3348e-14],\n              [7.0049e-14, 1.0779e-13, 8.5386e-14],\n              [6.0227e-14, 9.1625e-14, 7.5256e-14]],\n    \n             ...,\n    \n             [[5.7997e-14, 8.1808e-14, 5.9669e-14],\n              [7.2454e-14, 1.0104e-13, 7.1372e-14],\n              [4.2294e-14, 6.7940e-14, 4.9766e-14]],\n    \n             [[6.5032e-14, 9.5016e-14, 6.6365e-14],\n              [5.5947e-14, 7.6831e-14, 5.9274e-14],\n              [3.4628e-14, 4.2293e-14, 3.3965e-14]],\n    \n             [[7.1833e-14, 1.0653e-13, 9.1158e-14],\n              [9.2850e-14, 1.4641e-13, 1.1386e-13],\n              [6.8761e-14, 9.6666e-14, 7.7375e-14]]]])},\n   143: {'exp_avg': tensor([[[[-6.7586e-08]],\n    \n             [[ 2.5511e-08]],\n    \n             [[ 1.9633e-08]],\n    \n             ...,\n    \n             [[ 9.7130e-09]],\n    \n             [[-5.9838e-08]],\n    \n             [[-5.4631e-08]]],\n    \n    \n            [[[ 1.1367e-07]],\n    \n             [[-1.3978e-07]],\n    \n             [[-1.2085e-07]],\n    \n             ...,\n    \n             [[ 7.6069e-08]],\n    \n             [[ 8.9566e-08]],\n    \n             [[ 9.6135e-08]]],\n    \n    \n            [[[-6.9551e-10]],\n    \n             [[-7.6581e-09]],\n    \n             [[-1.0098e-09]],\n    \n             ...,\n    \n             [[-1.0120e-08]],\n    \n             [[ 1.5011e-08]],\n    \n             [[-1.9964e-09]]],\n    \n    \n            ...,\n    \n    \n            [[[ 2.8123e-08]],\n    \n             [[ 8.7406e-09]],\n    \n             [[ 2.3212e-08]],\n    \n             ...,\n    \n             [[-4.6191e-08]],\n    \n             [[-2.8019e-08]],\n    \n             [[-4.2392e-08]]],\n    \n    \n            [[[-2.0632e-08]],\n    \n             [[ 1.2002e-08]],\n    \n             [[ 7.1798e-08]],\n    \n             ...,\n    \n             [[-1.1368e-07]],\n    \n             [[ 2.6966e-08]],\n    \n             [[-1.4145e-07]]],\n    \n    \n            [[[-4.7221e-08]],\n    \n             [[ 6.1478e-09]],\n    \n             [[-5.0941e-08]],\n    \n             ...,\n    \n             [[-4.9266e-08]],\n    \n             [[ 1.2188e-07]],\n    \n             [[ 6.4652e-08]]]]),\n    'exp_avg_sq': tensor([[[[9.5052e-14]],\n    \n             [[7.3172e-14]],\n    \n             [[7.2431e-14]],\n    \n             ...,\n    \n             [[8.0756e-14]],\n    \n             [[9.7240e-14]],\n    \n             [[8.3098e-14]]],\n    \n    \n            [[[1.4918e-13]],\n    \n             [[1.0540e-13]],\n    \n             [[1.0432e-13]],\n    \n             ...,\n    \n             [[1.2978e-13]],\n    \n             [[1.4299e-13]],\n    \n             [[1.2843e-13]]],\n    \n    \n            [[[1.1041e-15]],\n    \n             [[8.9940e-16]],\n    \n             [[9.0110e-16]],\n    \n             ...,\n    \n             [[7.8230e-16]],\n    \n             [[1.4318e-15]],\n    \n             [[1.0515e-15]]],\n    \n    \n            ...,\n    \n    \n            [[[5.7067e-14]],\n    \n             [[4.0131e-14]],\n    \n             [[3.8835e-14]],\n    \n             ...,\n    \n             [[4.1647e-14]],\n    \n             [[5.7056e-14]],\n    \n             [[4.5871e-14]]],\n    \n    \n            [[[9.0551e-14]],\n    \n             [[6.4898e-14]],\n    \n             [[6.9366e-14]],\n    \n             ...,\n    \n             [[6.2989e-14]],\n    \n             [[1.1300e-13]],\n    \n             [[8.8500e-14]]],\n    \n    \n            [[[9.2716e-14]],\n    \n             [[5.7322e-14]],\n    \n             [[6.8956e-14]],\n    \n             ...,\n    \n             [[8.8450e-14]],\n    \n             [[1.1947e-13]],\n    \n             [[7.5100e-14]]]])},\n   144: {'exp_avg': tensor([[[[ 4.3902e-08]],\n    \n             [[ 3.7057e-08]],\n    \n             [[-3.6965e-08]],\n    \n             ...,\n    \n             [[ 2.7321e-08]],\n    \n             [[-1.2032e-08]],\n    \n             [[-5.4064e-08]]],\n    \n    \n            [[[ 7.7408e-08]],\n    \n             [[-1.0202e-07]],\n    \n             [[ 1.4796e-08]],\n    \n             ...,\n    \n             [[-2.8368e-09]],\n    \n             [[-1.0688e-07]],\n    \n             [[-3.5090e-08]]],\n    \n    \n            [[[ 7.2378e-08]],\n    \n             [[-2.3282e-08]],\n    \n             [[-1.2876e-07]],\n    \n             ...,\n    \n             [[ 4.6036e-08]],\n    \n             [[ 1.2388e-07]],\n    \n             [[ 1.0650e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[ 6.6145e-08]],\n    \n             [[-2.0968e-08]],\n    \n             [[-1.5253e-07]],\n    \n             ...,\n    \n             [[-6.4880e-08]],\n    \n             [[ 2.0743e-08]],\n    \n             [[-2.8105e-08]]],\n    \n    \n            [[[-5.9625e-08]],\n    \n             [[ 7.1628e-08]],\n    \n             [[ 5.7811e-08]],\n    \n             ...,\n    \n             [[-7.1619e-09]],\n    \n             [[ 4.2017e-08]],\n    \n             [[-3.6215e-08]]],\n    \n    \n            [[[-5.2624e-09]],\n    \n             [[ 1.4681e-09]],\n    \n             [[-3.7702e-08]],\n    \n             ...,\n    \n             [[ 8.0516e-08]],\n    \n             [[ 5.1874e-08]],\n    \n             [[ 3.7666e-08]]]]),\n    'exp_avg_sq': tensor([[[[7.3175e-14]],\n    \n             [[6.1264e-14]],\n    \n             [[1.1480e-13]],\n    \n             ...,\n    \n             [[4.4650e-14]],\n    \n             [[7.2602e-14]],\n    \n             [[5.9427e-14]]],\n    \n    \n            [[[8.8425e-14]],\n    \n             [[1.0223e-13]],\n    \n             [[7.8694e-14]],\n    \n             ...,\n    \n             [[5.4682e-14]],\n    \n             [[1.0316e-13]],\n    \n             [[8.2019e-14]]],\n    \n    \n            [[[7.7276e-14]],\n    \n             [[7.3842e-14]],\n    \n             [[9.7994e-14]],\n    \n             ...,\n    \n             [[5.3956e-14]],\n    \n             [[9.0507e-14]],\n    \n             [[7.3716e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[9.3780e-14]],\n    \n             [[1.0981e-13]],\n    \n             [[1.4766e-13]],\n    \n             ...,\n    \n             [[6.4934e-14]],\n    \n             [[1.4409e-13]],\n    \n             [[9.1153e-14]]],\n    \n    \n            [[[6.1891e-14]],\n    \n             [[5.6264e-14]],\n    \n             [[6.3043e-14]],\n    \n             ...,\n    \n             [[2.0340e-14]],\n    \n             [[5.1576e-14]],\n    \n             [[7.4979e-14]]],\n    \n    \n            [[[6.3579e-14]],\n    \n             [[7.1858e-14]],\n    \n             [[6.0911e-14]],\n    \n             ...,\n    \n             [[3.1103e-14]],\n    \n             [[8.1394e-14]],\n    \n             [[7.9966e-14]]]])},\n   145: {'exp_avg': tensor([[[[ 5.6075e-08,  3.0282e-08,  1.6650e-08],\n              [ 6.4636e-08,  4.3347e-08,  1.3754e-07],\n              [ 2.7249e-08,  1.9045e-08,  1.1067e-08]],\n    \n             [[-6.8126e-08, -5.9741e-08, -2.9513e-08],\n              [-1.3937e-07, -1.4427e-07, -1.7653e-07],\n              [-3.3177e-08, -1.3180e-07, -6.6708e-08]],\n    \n             [[ 2.4901e-09, -6.4667e-08, -3.7449e-08],\n              [ 8.5834e-09,  1.2001e-08, -6.3545e-08],\n              [-2.4343e-08, -8.8433e-08,  8.2745e-09]],\n    \n             ...,\n    \n             [[ 5.8050e-08, -2.9012e-08,  5.9026e-08],\n              [ 4.0782e-08,  4.1301e-08, -1.1369e-08],\n              [ 3.5592e-08,  1.7032e-08, -1.0648e-07]],\n    \n             [[ 5.5232e-08,  3.9314e-08,  1.6590e-08],\n              [ 2.3293e-08,  6.1952e-08,  4.1746e-08],\n              [-2.8876e-08,  1.9857e-08,  4.1626e-08]],\n    \n             [[ 6.1422e-08,  3.5992e-08,  2.3889e-08],\n              [ 1.1380e-08, -1.5024e-08,  4.9515e-08],\n              [ 3.4078e-09,  2.2736e-08,  2.7742e-08]]],\n    \n    \n            [[[ 2.2099e-08,  3.9980e-08,  7.0003e-08],\n              [-1.0419e-08, -2.3240e-08,  4.4392e-08],\n              [ 1.0115e-07,  4.0423e-08,  3.0229e-08]],\n    \n             [[-2.5440e-08, -1.0542e-07, -3.0486e-08],\n              [-9.2565e-08, -1.2239e-07, -5.6499e-08],\n              [-4.1947e-08, -5.5434e-08,  4.6789e-08]],\n    \n             [[ 8.7338e-08,  5.9070e-08,  4.6852e-08],\n              [-5.7166e-09, -2.9617e-09, -5.9725e-08],\n              [-4.7898e-08,  5.9731e-08,  8.8353e-09]],\n    \n             ...,\n    \n             [[ 7.6427e-08, -8.7501e-11,  8.0245e-08],\n              [ 3.2315e-08,  1.6257e-08,  3.5489e-08],\n              [ 5.7198e-08,  9.9039e-08,  1.3081e-07]],\n    \n             [[-9.7965e-09, -1.3633e-07, -2.7842e-08],\n              [-6.0096e-09, -4.8598e-08,  7.2910e-09],\n              [-3.9328e-08, -3.6634e-08, -3.2250e-09]],\n    \n             [[ 2.0877e-08, -1.0860e-08,  1.3832e-08],\n              [ 3.5246e-08, -6.5116e-08, -3.2018e-09],\n              [ 4.5545e-08, -3.1721e-08, -5.6312e-08]]],\n    \n    \n            [[[ 1.4426e-08,  6.3739e-10,  3.3024e-08],\n              [ 3.3975e-08,  2.4652e-08,  7.4819e-08],\n              [ 8.2028e-08,  7.9094e-08,  4.3777e-08]],\n    \n             [[-1.0272e-07, -1.0553e-07, -4.8882e-08],\n              [-6.4265e-08, -1.1951e-07, -1.4780e-07],\n              [-4.3870e-09, -4.7744e-08, -4.6385e-08]],\n    \n             [[-4.1616e-08,  1.2315e-08, -2.3996e-09],\n              [ 5.2653e-08,  7.6707e-08,  1.2717e-07],\n              [ 3.3295e-08,  7.8624e-08,  1.2992e-07]],\n    \n             ...,\n    \n             [[ 1.3362e-08, -3.2572e-09,  1.5092e-08],\n              [ 5.8950e-08, -1.0781e-07, -4.5127e-08],\n              [-9.7246e-09, -2.7101e-08, -3.3107e-08]],\n    \n             [[ 3.0172e-08, -6.6128e-09,  4.1263e-08],\n              [ 2.7460e-08, -3.4705e-09, -1.4800e-09],\n              [ 4.8120e-08,  1.3058e-08,  3.8954e-08]],\n    \n             [[-4.7548e-08, -2.7970e-08,  4.3103e-08],\n              [-2.2368e-08,  3.9071e-08,  7.5462e-08],\n              [ 3.3141e-08,  9.3502e-08,  9.7163e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-1.9016e-08, -1.5677e-08, -3.2702e-08],\n              [-2.0199e-08,  3.9264e-08, -4.4903e-08],\n              [-2.1157e-08, -2.0060e-08, -1.0024e-08]],\n    \n             [[ 2.4436e-08,  1.0153e-07,  1.0363e-07],\n              [ 4.2810e-08,  1.4473e-07,  1.4321e-07],\n              [ 4.8987e-08,  1.2136e-07,  1.6551e-07]],\n    \n             [[-3.1136e-08, -9.2185e-09, -6.7705e-09],\n              [-3.8191e-08, -7.7837e-09, -1.5480e-08],\n              [-5.2596e-09,  7.3878e-09,  3.8333e-08]],\n    \n             ...,\n    \n             [[-3.7884e-09, -7.8140e-08, -3.4161e-08],\n              [ 1.6514e-08,  1.2410e-09,  6.6321e-08],\n              [ 4.7609e-08,  5.5412e-08,  7.3479e-08]],\n    \n             [[-6.4631e-08, -7.1703e-08, -7.3926e-08],\n              [-3.4987e-08, -9.7833e-08, -4.9119e-08],\n              [-2.3862e-08, -8.0666e-08, -5.2482e-08]],\n    \n             [[-4.9225e-08, -6.3232e-08, -6.1380e-08],\n              [-2.4145e-08,  1.1960e-09,  3.4730e-08],\n              [-5.3296e-10,  1.6900e-08,  1.7279e-10]]],\n    \n    \n            [[[ 3.4622e-08,  1.0055e-07,  8.4489e-08],\n              [ 2.2558e-08,  1.1106e-07,  9.4005e-08],\n              [ 5.4639e-08, -2.3530e-08, -1.9064e-08]],\n    \n             [[ 1.4874e-08, -2.2138e-08, -1.2507e-08],\n              [ 6.8996e-08, -6.9267e-08, -1.3690e-08],\n              [ 1.1618e-07,  3.0766e-09,  1.0369e-07]],\n    \n             [[ 6.3384e-09, -1.6047e-09,  4.1130e-08],\n              [ 3.6489e-08,  5.3501e-08, -3.2262e-08],\n              [ 5.8323e-08,  2.4074e-08,  7.9882e-08]],\n    \n             ...,\n    \n             [[ 7.5915e-08, -6.4025e-09,  5.2661e-08],\n              [ 7.6982e-08, -4.2291e-08,  2.7801e-08],\n              [ 5.9716e-08,  2.3063e-08,  2.6643e-08]],\n    \n             [[-4.4289e-08, -1.5211e-07, -1.6127e-07],\n              [ 3.1411e-08, -2.2508e-08, -3.5616e-08],\n              [ 1.2812e-08,  1.9886e-08,  4.3573e-08]],\n    \n             [[-4.5476e-08, -9.0117e-08, -3.6912e-08],\n              [ 3.3510e-08,  2.4636e-08,  3.5085e-08],\n              [ 4.8858e-08,  2.9915e-08,  6.8190e-08]]],\n    \n    \n            [[[ 1.1636e-08,  5.6891e-09, -9.8409e-09],\n              [ 3.9433e-08, -4.1387e-08,  5.1082e-08],\n              [ 8.4240e-08,  9.7548e-08,  1.0506e-07]],\n    \n             [[-6.0861e-08, -5.2031e-08,  8.8989e-09],\n              [-4.4929e-09, -9.0780e-08, -4.2373e-09],\n              [-4.3872e-09, -1.0550e-07,  4.3524e-09]],\n    \n             [[ 8.8135e-09, -1.8121e-08,  3.9005e-09],\n              [ 4.9282e-08,  4.2033e-08,  4.3947e-08],\n              [ 8.0721e-08, -1.5612e-08,  4.6779e-08]],\n    \n             ...,\n    \n             [[-4.7548e-08, -8.1168e-08,  2.9632e-08],\n              [ 3.6142e-08,  2.5748e-08,  3.7416e-08],\n              [ 3.6267e-08,  5.9359e-08,  1.2242e-07]],\n    \n             [[ 1.9365e-09, -9.3535e-09,  5.3320e-08],\n              [ 5.0440e-09, -5.7463e-08,  1.7747e-08],\n              [ 3.4158e-08,  9.1711e-09,  6.5803e-08]],\n    \n             [[-1.0754e-08, -4.8866e-08, -2.8625e-08],\n              [ 4.1363e-08,  4.2836e-08,  1.4738e-08],\n              [ 7.1490e-08,  1.7088e-08, -8.0794e-09]]]]),\n    'exp_avg_sq': tensor([[[[3.4746e-14, 5.2362e-14, 3.6779e-14],\n              [5.8932e-14, 9.5472e-14, 7.0203e-14],\n              [5.4855e-14, 9.1567e-14, 7.6834e-14]],\n    \n             [[5.0984e-14, 7.5115e-14, 5.7779e-14],\n              [5.4538e-14, 8.6916e-14, 6.7436e-14],\n              [4.1408e-14, 6.8776e-14, 5.7949e-14]],\n    \n             [[3.1836e-14, 4.6460e-14, 4.7583e-14],\n              [5.1829e-14, 7.7350e-14, 6.9037e-14],\n              [5.9272e-14, 8.7210e-14, 7.4432e-14]],\n    \n             ...,\n    \n             [[3.2552e-14, 4.9947e-14, 4.7197e-14],\n              [4.5671e-14, 7.1811e-14, 7.5042e-14],\n              [4.5713e-14, 7.7315e-14, 7.8314e-14]],\n    \n             [[4.1085e-14, 6.5906e-14, 5.6209e-14],\n              [3.4704e-14, 5.3742e-14, 4.9807e-14],\n              [2.3863e-14, 3.9981e-14, 3.9964e-14]],\n    \n             [[3.2252e-14, 4.7825e-14, 3.9872e-14],\n              [4.6874e-14, 7.7119e-14, 5.9653e-14],\n              [4.4534e-14, 7.7740e-14, 6.6796e-14]]],\n    \n    \n            [[[1.9715e-14, 3.1895e-14, 2.2849e-14],\n              [4.7664e-14, 7.4843e-14, 6.0862e-14],\n              [5.5717e-14, 8.6984e-14, 6.8330e-14]],\n    \n             [[3.8623e-14, 6.1195e-14, 4.3623e-14],\n              [6.5019e-14, 1.0832e-13, 7.8173e-14],\n              [5.2127e-14, 9.3417e-14, 7.0520e-14]],\n    \n             [[2.3908e-14, 4.1168e-14, 3.5032e-14],\n              [4.9355e-14, 9.1583e-14, 7.9943e-14],\n              [5.9945e-14, 9.6040e-14, 8.4395e-14]],\n    \n             ...,\n    \n             [[2.6244e-14, 4.4464e-14, 3.8224e-14],\n              [4.6270e-14, 9.0374e-14, 7.9044e-14],\n              [4.4597e-14, 9.4024e-14, 8.8418e-14]],\n    \n             [[4.6613e-14, 6.1867e-14, 5.0432e-14],\n              [4.8408e-14, 7.6827e-14, 6.6508e-14],\n              [3.0251e-14, 4.9540e-14, 4.2945e-14]],\n    \n             [[1.9152e-14, 2.6430e-14, 2.0265e-14],\n              [3.0606e-14, 5.2686e-14, 4.1906e-14],\n              [3.5777e-14, 5.7564e-14, 4.8921e-14]]],\n    \n    \n            [[[2.2539e-14, 3.7074e-14, 2.9544e-14],\n              [4.5977e-14, 7.2907e-14, 6.6709e-14],\n              [5.8773e-14, 8.5365e-14, 6.8735e-14]],\n    \n             [[3.5103e-14, 5.6611e-14, 3.8249e-14],\n              [5.2027e-14, 8.5017e-14, 5.5242e-14],\n              [4.8163e-14, 7.3862e-14, 5.3736e-14]],\n    \n             [[2.2505e-14, 3.6391e-14, 3.2234e-14],\n              [4.5059e-14, 6.7317e-14, 5.5324e-14],\n              [5.1700e-14, 8.5967e-14, 6.8152e-14]],\n    \n             ...,\n    \n             [[3.4653e-14, 6.1967e-14, 4.8405e-14],\n              [5.8460e-14, 9.3044e-14, 7.5844e-14],\n              [5.4509e-14, 8.8907e-14, 6.9184e-14]],\n    \n             [[3.7577e-14, 5.4582e-14, 4.8821e-14],\n              [4.7913e-14, 7.1092e-14, 6.4926e-14],\n              [2.9356e-14, 4.8320e-14, 4.2619e-14]],\n    \n             [[3.1324e-14, 5.1893e-14, 4.0856e-14],\n              [5.1677e-14, 9.1026e-14, 6.9682e-14],\n              [4.7123e-14, 8.3423e-14, 7.2360e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[2.7100e-14, 5.5511e-14, 4.3583e-14],\n              [4.4194e-14, 1.1374e-13, 1.0265e-13],\n              [4.3837e-14, 1.0411e-13, 1.0168e-13]],\n    \n             [[3.6033e-14, 7.7031e-14, 6.4658e-14],\n              [4.4281e-14, 9.7997e-14, 8.5555e-14],\n              [3.5734e-14, 6.3821e-14, 5.9203e-14]],\n    \n             [[2.0556e-14, 4.7497e-14, 5.2801e-14],\n              [3.5467e-14, 7.4170e-14, 9.5090e-14],\n              [4.0984e-14, 7.9054e-14, 9.2121e-14]],\n    \n             ...,\n    \n             [[2.2172e-14, 6.7520e-14, 7.3496e-14],\n              [2.6493e-14, 9.2644e-14, 1.2482e-13],\n              [2.6651e-14, 7.9620e-14, 9.2810e-14]],\n    \n             [[5.5137e-14, 6.5568e-14, 5.3582e-14],\n              [5.9609e-14, 7.2863e-14, 5.2926e-14],\n              [3.9502e-14, 4.6356e-14, 3.3974e-14]],\n    \n             [[3.3754e-14, 3.8718e-14, 2.9413e-14],\n              [5.4017e-14, 8.3077e-14, 5.3771e-14],\n              [5.2362e-14, 8.2552e-14, 6.4663e-14]]],\n    \n    \n            [[[3.4909e-14, 5.8535e-14, 4.4233e-14],\n              [5.8312e-14, 9.0047e-14, 7.1340e-14],\n              [6.0341e-14, 8.8142e-14, 7.4650e-14]],\n    \n             [[6.8908e-14, 1.0513e-13, 7.6547e-14],\n              [7.5071e-14, 1.2370e-13, 8.6922e-14],\n              [4.8427e-14, 7.9952e-14, 6.2127e-14]],\n    \n             [[3.4933e-14, 5.7385e-14, 4.9047e-14],\n              [5.7883e-14, 9.5299e-14, 7.9338e-14],\n              [5.8310e-14, 8.3046e-14, 7.7351e-14]],\n    \n             ...,\n    \n             [[4.7205e-14, 8.0954e-14, 6.9734e-14],\n              [5.0007e-14, 9.3822e-14, 8.0615e-14],\n              [4.9500e-14, 8.2977e-14, 7.8102e-14]],\n    \n             [[4.0483e-14, 5.1122e-14, 5.9158e-14],\n              [3.4324e-14, 4.5966e-14, 4.8247e-14],\n              [3.0332e-14, 4.3246e-14, 4.0742e-14]],\n    \n             [[3.0273e-14, 4.2423e-14, 4.1057e-14],\n              [4.9579e-14, 8.5310e-14, 6.8216e-14],\n              [5.7240e-14, 1.0151e-13, 8.8133e-14]]],\n    \n    \n            [[[1.9409e-14, 2.8029e-14, 1.8575e-14],\n              [3.9982e-14, 5.7914e-14, 4.4067e-14],\n              [4.1747e-14, 6.1019e-14, 4.6983e-14]],\n    \n             [[2.2383e-14, 3.3844e-14, 2.0417e-14],\n              [5.5116e-14, 8.5819e-14, 5.2328e-14],\n              [4.6695e-14, 7.6237e-14, 5.0278e-14]],\n    \n             [[1.5077e-14, 2.5094e-14, 2.3057e-14],\n              [3.5002e-14, 5.5588e-14, 4.5439e-14],\n              [3.9862e-14, 6.0520e-14, 5.0330e-14]],\n    \n             ...,\n    \n             [[2.1864e-14, 3.3182e-14, 3.3315e-14],\n              [5.7774e-14, 8.7418e-14, 7.7548e-14],\n              [4.9612e-14, 8.5477e-14, 7.6861e-14]],\n    \n             [[3.2371e-14, 4.3932e-14, 4.7661e-14],\n              [4.8292e-14, 6.9077e-14, 6.9276e-14],\n              [2.6819e-14, 4.2375e-14, 4.0560e-14]],\n    \n             [[2.2214e-14, 2.9861e-14, 1.9871e-14],\n              [4.4368e-14, 5.9620e-14, 4.6222e-14],\n              [3.6680e-14, 5.3099e-14, 4.4868e-14]]]])},\n   146: {'exp_avg': tensor([[[[-7.1096e-08]],\n    \n             [[-1.1688e-08]],\n    \n             [[ 4.5424e-08]],\n    \n             ...,\n    \n             [[ 1.9993e-08]],\n    \n             [[-3.3278e-08]],\n    \n             [[ 3.7763e-08]]],\n    \n    \n            [[[-3.9535e-08]],\n    \n             [[-6.3457e-08]],\n    \n             [[-2.5745e-08]],\n    \n             ...,\n    \n             [[-3.4564e-08]],\n    \n             [[-3.4014e-08]],\n    \n             [[ 5.4473e-08]]],\n    \n    \n            [[[ 1.7442e-08]],\n    \n             [[ 1.8980e-07]],\n    \n             [[-3.3327e-08]],\n    \n             ...,\n    \n             [[ 8.6346e-08]],\n    \n             [[ 2.0496e-08]],\n    \n             [[-6.2157e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-3.5645e-08]],\n    \n             [[-1.7245e-07]],\n    \n             [[-4.6959e-08]],\n    \n             ...,\n    \n             [[-1.0708e-07]],\n    \n             [[-3.3708e-08]],\n    \n             [[ 2.7295e-08]]],\n    \n    \n            [[[ 1.1964e-07]],\n    \n             [[ 5.1431e-09]],\n    \n             [[-5.4272e-08]],\n    \n             ...,\n    \n             [[ 6.3117e-09]],\n    \n             [[ 1.2743e-07]],\n    \n             [[ 6.2623e-09]]],\n    \n    \n            [[[-4.6586e-08]],\n    \n             [[-2.6305e-08]],\n    \n             [[-6.9299e-08]],\n    \n             ...,\n    \n             [[-3.6034e-08]],\n    \n             [[-6.3842e-08]],\n    \n             [[-1.5847e-08]]]]),\n    'exp_avg_sq': tensor([[[[6.3300e-14]],\n    \n             [[5.7491e-14]],\n    \n             [[5.4965e-14]],\n    \n             ...,\n    \n             [[3.3914e-14]],\n    \n             [[5.2038e-14]],\n    \n             [[4.1561e-14]]],\n    \n    \n            [[[9.2134e-14]],\n    \n             [[1.0143e-13]],\n    \n             [[8.0912e-14]],\n    \n             ...,\n    \n             [[5.7711e-14]],\n    \n             [[7.8712e-14]],\n    \n             [[6.2591e-14]]],\n    \n    \n            [[[1.2036e-13]],\n    \n             [[1.2665e-13]],\n    \n             [[9.7943e-14]],\n    \n             ...,\n    \n             [[8.3732e-14]],\n    \n             [[1.1318e-13]],\n    \n             [[7.6037e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[2.3143e-13]],\n    \n             [[2.7433e-13]],\n    \n             [[2.5152e-13]],\n    \n             ...,\n    \n             [[1.6743e-13]],\n    \n             [[2.5666e-13]],\n    \n             [[1.8373e-13]]],\n    \n    \n            [[[1.2530e-13]],\n    \n             [[1.4490e-13]],\n    \n             [[1.1364e-13]],\n    \n             ...,\n    \n             [[9.5537e-14]],\n    \n             [[1.3483e-13]],\n    \n             [[9.2731e-14]]],\n    \n    \n            [[[1.2845e-13]],\n    \n             [[1.2241e-13]],\n    \n             [[9.7531e-14]],\n    \n             ...,\n    \n             [[8.2100e-14]],\n    \n             [[1.2429e-13]],\n    \n             [[7.9647e-14]]]])},\n   147: {'exp_avg': tensor([[[[-4.2196e-09]],\n    \n             [[-3.8099e-08]],\n    \n             [[ 2.4231e-08]],\n    \n             ...,\n    \n             [[ 3.5925e-10]],\n    \n             [[ 2.4843e-08]],\n    \n             [[ 6.8390e-08]]],\n    \n    \n            [[[ 5.4088e-08]],\n    \n             [[ 3.3502e-08]],\n    \n             [[-1.6883e-08]],\n    \n             ...,\n    \n             [[ 1.3310e-07]],\n    \n             [[ 1.2401e-08]],\n    \n             [[ 9.9046e-08]]],\n    \n    \n            [[[ 8.0509e-08]],\n    \n             [[ 5.0650e-08]],\n    \n             [[-1.2645e-07]],\n    \n             ...,\n    \n             [[ 6.8348e-08]],\n    \n             [[ 1.6071e-07]],\n    \n             [[ 2.2130e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-1.8110e-08]],\n    \n             [[ 7.6965e-08]],\n    \n             [[ 4.3987e-09]],\n    \n             ...,\n    \n             [[ 1.6753e-08]],\n    \n             [[-2.4178e-07]],\n    \n             [[ 3.8667e-08]]],\n    \n    \n            [[[-6.4424e-09]],\n    \n             [[ 2.9087e-08]],\n    \n             [[ 4.9047e-08]],\n    \n             ...,\n    \n             [[ 6.1640e-08]],\n    \n             [[-1.7405e-08]],\n    \n             [[-3.0841e-08]]],\n    \n    \n            [[[-2.7373e-08]],\n    \n             [[ 8.9777e-08]],\n    \n             [[ 8.1189e-09]],\n    \n             ...,\n    \n             [[ 1.0681e-08]],\n    \n             [[ 1.1403e-08]],\n    \n             [[ 8.7231e-08]]]]),\n    'exp_avg_sq': tensor([[[[6.8118e-14]],\n    \n             [[7.3971e-14]],\n    \n             [[8.2023e-14]],\n    \n             ...,\n    \n             [[8.1259e-14]],\n    \n             [[1.1203e-13]],\n    \n             [[9.2283e-14]]],\n    \n    \n            [[[7.3086e-14]],\n    \n             [[6.0825e-14]],\n    \n             [[7.6114e-14]],\n    \n             ...,\n    \n             [[7.5353e-14]],\n    \n             [[8.4140e-14]],\n    \n             [[8.3262e-14]]],\n    \n    \n            [[[5.4037e-14]],\n    \n             [[5.7646e-14]],\n    \n             [[6.9244e-14]],\n    \n             ...,\n    \n             [[7.0311e-14]],\n    \n             [[9.0645e-14]],\n    \n             [[6.7261e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[7.3269e-14]],\n    \n             [[8.4725e-14]],\n    \n             [[1.3838e-13]],\n    \n             ...,\n    \n             [[8.8700e-14]],\n    \n             [[1.2469e-13]],\n    \n             [[9.2282e-14]]],\n    \n    \n            [[[6.1802e-14]],\n    \n             [[6.1783e-14]],\n    \n             [[9.6986e-14]],\n    \n             ...,\n    \n             [[8.0602e-14]],\n    \n             [[8.8142e-14]],\n    \n             [[5.2488e-14]]],\n    \n    \n            [[[8.5619e-14]],\n    \n             [[7.3595e-14]],\n    \n             [[1.1456e-13]],\n    \n             ...,\n    \n             [[9.9538e-14]],\n    \n             [[1.0840e-13]],\n    \n             [[9.0925e-14]]]])},\n   148: {'exp_avg': tensor([[[[ 3.0225e-08, -9.9360e-13,  2.9192e-08],\n              [ 4.6264e-08,  9.5815e-09,  8.0099e-08],\n              [ 3.9708e-08,  1.1031e-08,  5.4369e-08]],\n    \n             [[-1.4643e-08, -2.5464e-08, -3.2842e-08],\n              [ 5.9940e-08, -1.0218e-08, -6.6287e-09],\n              [ 4.5010e-08,  8.9536e-09,  6.1645e-08]],\n    \n             [[ 8.8413e-08,  1.7774e-09, -5.5606e-09],\n              [ 8.2119e-08,  3.1172e-08,  4.8649e-08],\n              [ 7.1599e-08,  9.8142e-08,  1.0887e-07]],\n    \n             ...,\n    \n             [[-9.2161e-08, -1.4686e-07, -9.4579e-08],\n              [-1.1226e-07, -1.3189e-07, -1.2502e-07],\n              [-3.5577e-08, -2.5334e-08,  1.4412e-08]],\n    \n             [[ 7.6915e-08,  3.6608e-08, -2.2238e-08],\n              [ 2.1592e-08,  1.6679e-08, -3.7010e-08],\n              [-2.5698e-09, -2.1101e-08, -1.3471e-08]],\n    \n             [[ 5.6045e-08,  9.4638e-08,  6.0944e-08],\n              [ 6.7399e-08,  6.8949e-08,  1.0843e-07],\n              [-1.3973e-08,  1.8387e-08,  5.3814e-08]]],\n    \n    \n            [[[-1.4691e-07, -1.5300e-07, -1.4733e-07],\n              [-8.7848e-09, -1.1364e-08, -2.7656e-08],\n              [-3.2425e-09,  9.6952e-09, -3.8546e-08]],\n    \n             [[-5.8803e-08, -5.6411e-08, -2.3793e-08],\n              [-1.3027e-08, -5.0832e-08, -1.4591e-08],\n              [-5.2838e-08, -1.9272e-08, -1.1174e-08]],\n    \n             [[-1.1595e-07, -1.5237e-07, -1.0007e-07],\n              [-5.2788e-08, -3.2870e-08, -6.9278e-08],\n              [ 6.6950e-08,  7.4732e-08,  1.1698e-08]],\n    \n             ...,\n    \n             [[-7.2978e-08, -1.1856e-07, -1.6024e-08],\n              [-3.7711e-08, -2.6886e-08,  6.8494e-08],\n              [-1.2706e-08, -4.4130e-08, -1.9549e-08]],\n    \n             [[-1.7177e-08,  2.3126e-09,  6.9380e-08],\n              [-2.3165e-08, -1.6341e-08,  1.0233e-08],\n              [ 3.4879e-11, -9.8830e-09,  3.9869e-09]],\n    \n             [[-1.4842e-08,  6.1173e-09,  1.1530e-08],\n              [-1.9498e-08,  9.3111e-08,  8.9753e-08],\n              [ 2.6448e-08,  4.6752e-08,  3.7647e-08]]],\n    \n    \n            [[[-1.7664e-07, -1.9761e-07, -1.2583e-07],\n              [-1.1730e-07, -8.8840e-08, -8.9171e-08],\n              [-8.8727e-08, -8.1272e-08, -1.2333e-07]],\n    \n             [[-1.5034e-08, -4.7912e-08, -7.9372e-08],\n              [-2.4275e-08,  1.9765e-08, -4.9014e-08],\n              [-1.2168e-07, -9.6112e-08, -8.9129e-08]],\n    \n             [[-6.4557e-08, -1.1820e-07,  3.7044e-08],\n              [-1.0288e-07, -1.1339e-07, -7.0945e-08],\n              [ 2.1299e-08, -7.4378e-08, -7.2493e-08]],\n    \n             ...,\n    \n             [[ 4.3834e-08,  8.8055e-08,  3.3543e-08],\n              [ 1.0825e-08,  1.8500e-08,  7.2385e-08],\n              [ 7.5898e-08,  4.2732e-08,  6.7107e-08]],\n    \n             [[-1.4074e-08,  1.6972e-08,  2.3778e-08],\n              [ 5.7558e-08,  2.7856e-08, -2.8299e-08],\n              [ 2.0637e-08, -4.6539e-09, -6.9227e-08]],\n    \n             [[ 2.6254e-08,  6.4996e-08,  1.5789e-08],\n              [-5.4062e-08,  1.7230e-08,  4.0918e-08],\n              [-3.1115e-08, -1.9817e-08, -4.8168e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-8.8625e-09,  6.7017e-09, -4.9455e-08],\n              [ 4.0880e-08, -2.4497e-08, -1.0196e-08],\n              [ 4.1285e-08,  2.1874e-08,  3.3747e-08]],\n    \n             [[-2.0984e-08,  1.4095e-08,  1.8313e-08],\n              [-3.1747e-08, -5.2722e-08,  1.1528e-08],\n              [-3.8424e-08, -9.1601e-08, -5.9097e-08]],\n    \n             [[-2.2117e-08, -1.6735e-08, -4.4609e-08],\n              [-5.7570e-08, -7.4467e-08, -8.2408e-08],\n              [-5.3882e-08, -1.2362e-07, -8.4176e-08]],\n    \n             ...,\n    \n             [[ 5.0812e-09, -3.1024e-08, -1.8495e-08],\n              [ 4.5862e-08, -4.8140e-08,  6.2583e-08],\n              [ 7.4800e-08,  1.1108e-07,  1.4154e-07]],\n    \n             [[ 1.3222e-07,  3.8547e-08,  1.3029e-08],\n              [ 6.7673e-08, -4.2451e-08,  2.5958e-09],\n              [-4.8873e-08, -7.9666e-08, -6.3598e-08]],\n    \n             [[-8.8652e-09,  3.6129e-08,  2.3796e-08],\n              [ 4.8987e-08,  1.5223e-08,  5.4643e-09],\n              [ 3.1315e-09,  6.1031e-10,  8.0232e-09]]],\n    \n    \n            [[[ 3.0292e-09, -9.5502e-08, -9.0147e-08],\n              [ 6.3772e-09, -9.3305e-08, -5.5219e-08],\n              [-2.9512e-08, -6.0922e-08,  9.4928e-09]],\n    \n             [[ 6.2137e-08, -3.4963e-08,  8.4768e-08],\n              [ 2.9366e-08, -2.8771e-08,  5.9224e-08],\n              [-2.0604e-09, -1.0576e-07,  9.4236e-09]],\n    \n             [[-3.5674e-08, -2.8069e-08, -9.1916e-09],\n              [ 8.8332e-08,  2.3693e-08,  8.6654e-08],\n              [ 7.6220e-08,  7.3353e-08,  7.6785e-08]],\n    \n             ...,\n    \n             [[-2.9013e-08, -6.4970e-08, -3.5667e-08],\n              [-7.6441e-08, -6.9890e-08, -5.1007e-08],\n              [-3.9410e-08, -1.0586e-07,  5.7784e-09]],\n    \n             [[-6.7377e-08, -7.6559e-08, -4.6739e-08],\n              [-2.8718e-08, -6.7660e-08,  5.5396e-08],\n              [ 4.4573e-10,  4.9819e-08,  1.1078e-07]],\n    \n             [[ 5.3817e-09, -2.4829e-08,  8.1291e-09],\n              [ 1.6609e-08,  5.8416e-08,  2.1972e-08],\n              [ 2.5122e-08, -1.0599e-07, -1.3519e-08]]],\n    \n    \n            [[[-5.3828e-09, -9.4447e-08, -1.1179e-07],\n              [ 7.4700e-08, -8.9195e-09,  1.9224e-08],\n              [ 2.0797e-08, -7.8001e-08, -6.4924e-08]],\n    \n             [[-3.9957e-08, -3.5226e-08, -4.3561e-08],\n              [-2.8242e-08,  4.0409e-08, -2.2770e-08],\n              [ 1.3624e-08, -3.8295e-08, -1.7417e-10]],\n    \n             [[-1.1813e-07, -1.7913e-07, -7.1491e-08],\n              [ 3.1253e-08, -1.1876e-08, -7.4129e-09],\n              [ 5.8447e-08, -4.3615e-08, -4.7747e-08]],\n    \n             ...,\n    \n             [[-4.9489e-08, -6.5777e-08, -9.2796e-08],\n              [-1.0219e-07, -8.3188e-08, -1.0618e-07],\n              [-7.5952e-08, -9.3991e-08, -1.5243e-07]],\n    \n             [[-2.6011e-08, -4.9419e-08, -4.0725e-08],\n              [ 4.9612e-08,  3.9390e-08,  6.6942e-08],\n              [ 3.1432e-08, -3.6692e-08, -4.1023e-08]],\n    \n             [[-3.9889e-08, -3.0350e-08, -1.0630e-07],\n              [ 7.3287e-09,  4.0600e-08, -5.1022e-08],\n              [-1.5464e-08, -3.1839e-10, -1.7956e-08]]]]),\n    'exp_avg_sq': tensor([[[[3.8849e-14, 6.8127e-14, 5.7194e-14],\n              [5.4033e-14, 1.1155e-13, 8.8001e-14],\n              [3.8659e-14, 7.3651e-14, 6.3867e-14]],\n    \n             [[2.3354e-14, 4.6429e-14, 3.7796e-14],\n              [3.4581e-14, 6.3901e-14, 5.8654e-14],\n              [3.2497e-14, 6.8110e-14, 7.0395e-14]],\n    \n             [[3.7173e-14, 6.0729e-14, 4.0906e-14],\n              [5.0254e-14, 9.2506e-14, 6.2579e-14],\n              [3.5285e-14, 5.6134e-14, 3.7461e-14]],\n    \n             ...,\n    \n             [[2.5717e-14, 4.2802e-14, 2.4869e-14],\n              [4.2560e-14, 8.8310e-14, 4.9788e-14],\n              [2.9271e-14, 6.0477e-14, 3.9177e-14]],\n    \n             [[3.5005e-14, 3.9935e-14, 3.9071e-14],\n              [4.4788e-14, 5.8987e-14, 5.2217e-14],\n              [3.8450e-14, 4.4363e-14, 3.9222e-14]],\n    \n             [[2.4318e-14, 2.8204e-14, 2.5336e-14],\n              [3.3312e-14, 4.4830e-14, 3.6480e-14],\n              [3.2422e-14, 5.1790e-14, 4.3163e-14]]],\n    \n    \n            [[[5.7361e-14, 8.8434e-14, 7.1631e-14],\n              [6.1532e-14, 1.0380e-13, 8.1081e-14],\n              [3.7270e-14, 6.4816e-14, 5.2024e-14]],\n    \n             [[3.3708e-14, 5.9122e-14, 4.6962e-14],\n              [4.4808e-14, 7.7905e-14, 6.6962e-14],\n              [4.6268e-14, 8.8098e-14, 8.4498e-14]],\n    \n             [[6.6793e-14, 1.0823e-13, 7.1257e-14],\n              [7.4932e-14, 1.3605e-13, 9.3296e-14],\n              [3.7137e-14, 7.4779e-14, 5.1282e-14]],\n    \n             ...,\n    \n             [[4.8028e-14, 8.5565e-14, 5.2635e-14],\n              [6.8950e-14, 1.4723e-13, 8.7382e-14],\n              [3.5684e-14, 7.0340e-14, 5.3896e-14]],\n    \n             [[6.2156e-14, 7.3190e-14, 5.6712e-14],\n              [6.5179e-14, 8.1026e-14, 6.6692e-14],\n              [3.9729e-14, 5.2271e-14, 5.3024e-14]],\n    \n             [[5.2409e-14, 7.9539e-14, 5.8048e-14],\n              [6.1364e-14, 1.0287e-13, 7.9885e-14],\n              [4.1285e-14, 7.6881e-14, 6.3883e-14]]],\n    \n    \n            [[[5.5401e-14, 8.5737e-14, 6.6181e-14],\n              [7.0413e-14, 1.1598e-13, 9.2993e-14],\n              [5.0122e-14, 8.1652e-14, 6.6239e-14]],\n    \n             [[2.9262e-14, 5.0091e-14, 4.1959e-14],\n              [4.6871e-14, 7.0771e-14, 6.6145e-14],\n              [4.6971e-14, 8.1695e-14, 8.9988e-14]],\n    \n             [[5.5001e-14, 9.3286e-14, 6.1895e-14],\n              [7.6421e-14, 1.4089e-13, 8.6579e-14],\n              [4.8067e-14, 8.4139e-14, 5.4710e-14]],\n    \n             ...,\n    \n             [[3.5605e-14, 6.1919e-14, 3.7534e-14],\n              [5.5117e-14, 1.1774e-13, 6.8439e-14],\n              [3.6568e-14, 7.2015e-14, 4.8992e-14]],\n    \n             [[5.4172e-14, 7.6994e-14, 6.2737e-14],\n              [8.4089e-14, 1.1657e-13, 8.5454e-14],\n              [6.9607e-14, 9.2208e-14, 7.7569e-14]],\n    \n             [[3.8496e-14, 6.0568e-14, 5.0144e-14],\n              [6.3828e-14, 1.0344e-13, 8.5951e-14],\n              [5.3412e-14, 9.1607e-14, 7.5915e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[4.8445e-14, 6.8149e-14, 5.2037e-14],\n              [7.9163e-14, 1.3309e-13, 9.7167e-14],\n              [6.6978e-14, 1.0674e-13, 8.8663e-14]],\n    \n             [[2.3126e-14, 3.8810e-14, 3.5118e-14],\n              [4.1272e-14, 8.0019e-14, 6.4939e-14],\n              [4.0291e-14, 7.4567e-14, 7.5775e-14]],\n    \n             [[5.3053e-14, 8.2468e-14, 5.4548e-14],\n              [8.4245e-14, 1.4318e-13, 8.7790e-14],\n              [6.3979e-14, 1.1087e-13, 6.5696e-14]],\n    \n             ...,\n    \n             [[4.1919e-14, 7.3325e-14, 4.6583e-14],\n              [7.1545e-14, 1.6390e-13, 9.0549e-14],\n              [4.8956e-14, 9.1322e-14, 6.1630e-14]],\n    \n             [[4.8059e-14, 5.8580e-14, 5.2151e-14],\n              [6.2460e-14, 8.5211e-14, 7.2920e-14],\n              [6.6534e-14, 8.9298e-14, 8.0039e-14]],\n    \n             [[4.9676e-14, 7.9002e-14, 6.3661e-14],\n              [7.8440e-14, 1.2555e-13, 9.8563e-14],\n              [6.6996e-14, 1.0799e-13, 8.6497e-14]]],\n    \n    \n            [[[6.5842e-14, 1.0837e-13, 8.7706e-14],\n              [6.6592e-14, 1.0326e-13, 8.5747e-14],\n              [3.8395e-14, 5.4575e-14, 5.3082e-14]],\n    \n             [[2.9745e-14, 5.3376e-14, 4.9355e-14],\n              [4.4741e-14, 7.3862e-14, 7.5170e-14],\n              [4.8292e-14, 8.8627e-14, 8.5292e-14]],\n    \n             [[6.3391e-14, 1.1879e-13, 8.0562e-14],\n              [7.8613e-14, 1.5540e-13, 1.0221e-13],\n              [4.2313e-14, 7.7465e-14, 5.3516e-14]],\n    \n             ...,\n    \n             [[4.6816e-14, 8.9363e-14, 5.7373e-14],\n              [7.3936e-14, 1.5225e-13, 8.8236e-14],\n              [4.3823e-14, 8.2595e-14, 5.8121e-14]],\n    \n             [[5.8862e-14, 8.5920e-14, 6.8597e-14],\n              [8.0862e-14, 1.1920e-13, 9.6614e-14],\n              [5.6667e-14, 6.6616e-14, 5.5140e-14]],\n    \n             [[5.3083e-14, 7.8941e-14, 6.6727e-14],\n              [7.0992e-14, 1.0831e-13, 9.1445e-14],\n              [5.3515e-14, 8.9213e-14, 7.9462e-14]]],\n    \n    \n            [[[4.3189e-14, 6.7065e-14, 5.2681e-14],\n              [7.0795e-14, 1.2956e-13, 9.5455e-14],\n              [5.8600e-14, 9.4640e-14, 7.7754e-14]],\n    \n             [[2.5525e-14, 4.6761e-14, 4.0454e-14],\n              [4.7671e-14, 8.4128e-14, 8.0214e-14],\n              [4.9379e-14, 9.1322e-14, 9.0381e-14]],\n    \n             [[4.8589e-14, 8.6364e-14, 5.4257e-14],\n              [7.4214e-14, 1.4735e-13, 9.9157e-14],\n              [5.7691e-14, 1.0530e-13, 7.4028e-14]],\n    \n             ...,\n    \n             [[3.4202e-14, 6.3801e-14, 3.6811e-14],\n              [5.9753e-14, 1.3220e-13, 7.6552e-14],\n              [4.2803e-14, 8.5892e-14, 6.0933e-14]],\n    \n             [[3.9689e-14, 5.5212e-14, 4.6118e-14],\n              [6.9686e-14, 9.3836e-14, 7.7057e-14],\n              [7.5334e-14, 8.7566e-14, 8.0451e-14]],\n    \n             [[3.6169e-14, 5.5803e-14, 4.3630e-14],\n              [5.8790e-14, 9.4748e-14, 8.0666e-14],\n              [5.3103e-14, 9.0694e-14, 8.0321e-14]]]])},\n   149: {'exp_avg': tensor([[[[ 1.9371e-08]],\n    \n             [[ 6.5328e-08]],\n    \n             [[-1.0157e-07]],\n    \n             ...,\n    \n             [[-1.7776e-08]],\n    \n             [[ 2.9069e-08]],\n    \n             [[ 2.6010e-08]]],\n    \n    \n            [[[-2.2215e-07]],\n    \n             [[-5.7888e-08]],\n    \n             [[ 2.5593e-08]],\n    \n             ...,\n    \n             [[ 3.8845e-08]],\n    \n             [[-9.2390e-08]],\n    \n             [[-1.2911e-07]]],\n    \n    \n            [[[ 3.2942e-08]],\n    \n             [[-1.5985e-07]],\n    \n             [[ 9.9195e-08]],\n    \n             ...,\n    \n             [[-1.6583e-07]],\n    \n             [[-3.6388e-08]],\n    \n             [[ 1.7660e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[-1.2109e-08]],\n    \n             [[ 1.1127e-08]],\n    \n             [[-1.2452e-08]],\n    \n             ...,\n    \n             [[-1.4254e-08]],\n    \n             [[ 4.1691e-08]],\n    \n             [[-3.8146e-08]]],\n    \n    \n            [[[-2.9888e-08]],\n    \n             [[-6.9396e-08]],\n    \n             [[ 1.3911e-07]],\n    \n             ...,\n    \n             [[ 3.5122e-08]],\n    \n             [[-2.7144e-08]],\n    \n             [[ 1.4320e-08]]],\n    \n    \n            [[[ 6.6178e-08]],\n    \n             [[-9.9733e-08]],\n    \n             [[-5.7003e-08]],\n    \n             ...,\n    \n             [[ 4.4102e-08]],\n    \n             [[ 6.0913e-08]],\n    \n             [[-1.7044e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.3600e-13]],\n    \n             [[1.0754e-13]],\n    \n             [[1.4044e-13]],\n    \n             ...,\n    \n             [[1.4914e-13]],\n    \n             [[1.2104e-13]],\n    \n             [[1.4645e-13]]],\n    \n    \n            [[[1.7421e-13]],\n    \n             [[1.3159e-13]],\n    \n             [[2.1487e-13]],\n    \n             ...,\n    \n             [[1.7156e-13]],\n    \n             [[1.5537e-13]],\n    \n             [[2.0481e-13]]],\n    \n    \n            [[[1.5936e-13]],\n    \n             [[1.9422e-13]],\n    \n             [[1.6379e-13]],\n    \n             ...,\n    \n             [[2.0237e-13]],\n    \n             [[2.2337e-13]],\n    \n             [[1.9931e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[3.3440e-14]],\n    \n             [[3.2119e-14]],\n    \n             [[3.7878e-14]],\n    \n             ...,\n    \n             [[3.6960e-14]],\n    \n             [[4.1201e-14]],\n    \n             [[3.3888e-14]]],\n    \n    \n            [[[1.4916e-13]],\n    \n             [[1.1079e-13]],\n    \n             [[1.4296e-13]],\n    \n             ...,\n    \n             [[1.8685e-13]],\n    \n             [[1.4590e-13]],\n    \n             [[1.2584e-13]]],\n    \n    \n            [[[8.6013e-14]],\n    \n             [[7.3127e-14]],\n    \n             [[9.6622e-14]],\n    \n             ...,\n    \n             [[1.1149e-13]],\n    \n             [[1.1283e-13]],\n    \n             [[9.3843e-14]]]])},\n   150: {'exp_avg': tensor([[[[-3.5393e-08]],\n    \n             [[ 9.1808e-08]],\n    \n             [[-1.3434e-07]],\n    \n             ...,\n    \n             [[ 1.4063e-07]],\n    \n             [[ 1.3125e-07]],\n    \n             [[-4.6324e-08]]],\n    \n    \n            [[[-5.0613e-09]],\n    \n             [[ 3.2752e-08]],\n    \n             [[-3.6738e-08]],\n    \n             ...,\n    \n             [[-6.1637e-08]],\n    \n             [[ 1.3840e-08]],\n    \n             [[ 2.5671e-08]]],\n    \n    \n            [[[-1.0184e-07]],\n    \n             [[-1.0912e-08]],\n    \n             [[ 2.0871e-08]],\n    \n             ...,\n    \n             [[ 6.6132e-08]],\n    \n             [[-1.5597e-07]],\n    \n             [[-5.7169e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 1.1475e-07]],\n    \n             [[ 3.1021e-08]],\n    \n             [[-1.8845e-07]],\n    \n             ...,\n    \n             [[-9.9442e-08]],\n    \n             [[-6.5592e-08]],\n    \n             [[-3.9138e-08]]],\n    \n    \n            [[[-2.6640e-08]],\n    \n             [[ 1.1083e-07]],\n    \n             [[ 2.8013e-08]],\n    \n             ...,\n    \n             [[ 7.0402e-08]],\n    \n             [[-1.4993e-08]],\n    \n             [[-8.6960e-08]]],\n    \n    \n            [[[-3.4717e-08]],\n    \n             [[-4.2506e-08]],\n    \n             [[-8.3514e-08]],\n    \n             ...,\n    \n             [[-1.4149e-08]],\n    \n             [[-4.8855e-08]],\n    \n             [[ 9.2540e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.0140e-13]],\n    \n             [[1.0546e-13]],\n    \n             [[1.3553e-13]],\n    \n             ...,\n    \n             [[7.6292e-14]],\n    \n             [[1.4313e-13]],\n    \n             [[1.0540e-13]]],\n    \n    \n            [[[8.7184e-14]],\n    \n             [[8.3244e-14]],\n    \n             [[8.7444e-14]],\n    \n             ...,\n    \n             [[4.7446e-14]],\n    \n             [[8.4119e-14]],\n    \n             [[1.0585e-13]]],\n    \n    \n            [[[1.4610e-13]],\n    \n             [[1.4013e-13]],\n    \n             [[1.2653e-13]],\n    \n             ...,\n    \n             [[8.0621e-14]],\n    \n             [[1.3633e-13]],\n    \n             [[1.3846e-13]]],\n    \n    \n            ...,\n    \n    \n            [[[9.0966e-14]],\n    \n             [[1.0662e-13]],\n    \n             [[1.1582e-13]],\n    \n             ...,\n    \n             [[7.8382e-14]],\n    \n             [[1.1244e-13]],\n    \n             [[9.0555e-14]]],\n    \n    \n            [[[1.0079e-13]],\n    \n             [[1.0085e-13]],\n    \n             [[7.2746e-14]],\n    \n             ...,\n    \n             [[5.8625e-14]],\n    \n             [[1.1218e-13]],\n    \n             [[9.5798e-14]]],\n    \n    \n            [[[1.0915e-13]],\n    \n             [[1.1931e-13]],\n    \n             [[1.6060e-13]],\n    \n             ...,\n    \n             [[8.0387e-14]],\n    \n             [[9.5454e-14]],\n    \n             [[9.3030e-14]]]])},\n   151: {'exp_avg': tensor([[[[ 1.1393e-08, -4.2964e-08, -1.2957e-08],\n              [ 5.9882e-08,  3.2649e-08,  6.3117e-09],\n              [ 2.4242e-08,  3.1663e-08,  3.6806e-08]],\n    \n             [[ 2.5297e-08,  1.2603e-08,  2.2668e-08],\n              [ 4.2622e-08, -1.1618e-08,  1.9838e-08],\n              [ 3.3805e-08,  6.0367e-09,  3.3787e-08]],\n    \n             [[-5.7018e-08, -4.9232e-08, -6.7572e-08],\n              [-1.7705e-08, -9.8805e-08, -6.1775e-08],\n              [-5.1264e-08, -3.7734e-08, -1.7631e-08]],\n    \n             ...,\n    \n             [[-2.5498e-08, -5.2271e-08, -7.6362e-08],\n              [-2.7862e-08, -6.5682e-08, -7.5484e-08],\n              [-5.0139e-08, -5.5992e-08, -7.8864e-08]],\n    \n             [[-3.5125e-08, -4.8842e-08, -2.2190e-08],\n              [-8.9978e-08, -1.0773e-07, -3.6436e-08],\n              [-6.5025e-08, -9.2862e-08, -7.6983e-08]],\n    \n             [[ 5.0713e-08,  1.0622e-07,  7.7092e-08],\n              [-3.5185e-09,  4.8922e-08,  3.8133e-08],\n              [ 1.1104e-08,  6.1615e-08,  3.0517e-08]]],\n    \n    \n            [[[-5.7010e-08, -5.0930e-08, -5.4357e-08],\n              [-1.5146e-08, -7.4708e-08, -5.1970e-08],\n              [-1.9227e-08, -1.9428e-08, -4.6231e-08]],\n    \n             [[-2.6258e-08, -1.0667e-08,  4.2987e-09],\n              [-2.5215e-08,  3.4336e-09,  1.2818e-08],\n              [ 5.3291e-08,  2.3616e-09,  4.1508e-08]],\n    \n             [[-3.6322e-08,  1.9411e-09,  2.2493e-08],\n              [-1.7128e-08,  1.5690e-08, -2.0300e-09],\n              [-3.7363e-08, -3.4385e-08, -6.0780e-08]],\n    \n             ...,\n    \n             [[ 6.1309e-08,  5.7848e-08,  6.2325e-08],\n              [ 2.4124e-08,  1.5204e-08,  3.4926e-08],\n              [ 6.1660e-08,  1.3218e-08,  5.1270e-08]],\n    \n             [[ 2.5843e-08,  3.5863e-08,  2.9319e-08],\n              [ 2.5651e-08,  2.2174e-08, -1.0050e-08],\n              [-1.2453e-10,  6.5944e-08,  1.1291e-08]],\n    \n             [[ 1.3652e-08,  3.7032e-09, -3.2969e-08],\n              [ 2.2756e-08,  5.5574e-08, -5.0448e-08],\n              [-1.2141e-08, -2.4280e-08, -6.3868e-08]]],\n    \n    \n            [[[ 4.7939e-09,  2.5589e-08,  6.2908e-09],\n              [ 1.2842e-08,  3.4721e-08,  1.3963e-08],\n              [-6.1558e-08, -8.8597e-08, -4.8219e-08]],\n    \n             [[ 4.0674e-08,  4.9029e-08,  5.0937e-08],\n              [-2.3228e-08, -8.5192e-08,  4.0587e-08],\n              [ 5.1063e-08, -1.6707e-08,  5.0469e-08]],\n    \n             [[-2.3032e-08, -2.1413e-08, -3.3304e-08],\n              [-7.0910e-08, -1.0405e-08, -7.8043e-08],\n              [-8.0287e-09, -3.5110e-08, -6.3679e-08]],\n    \n             ...,\n    \n             [[-4.6819e-09, -2.5677e-08, -6.7965e-08],\n              [ 3.2367e-08,  1.0367e-08, -6.4185e-08],\n              [-4.3994e-09, -6.9122e-09, -5.2889e-08]],\n    \n             [[ 2.9680e-08,  9.3544e-09,  2.5265e-08],\n              [-1.3453e-08, -5.8273e-08, -2.6674e-08],\n              [-1.3541e-08, -2.1843e-09, -2.9722e-08]],\n    \n             [[-4.4371e-08, -9.2324e-08, -7.8049e-08],\n              [-5.9767e-08, -9.8221e-08, -1.0519e-07],\n              [-3.9260e-08, -1.0881e-07, -1.3913e-07]]],\n    \n    \n            ...,\n    \n    \n            [[[ 2.1648e-08,  2.4105e-08, -8.7187e-09],\n              [ 6.4638e-09,  8.6100e-08,  1.1126e-08],\n              [-2.5783e-08, -4.1167e-08, -2.7535e-08]],\n    \n             [[-9.8903e-10,  2.2948e-08, -5.1832e-09],\n              [-1.4158e-08,  2.3027e-08, -2.3483e-08],\n              [-1.9683e-08,  5.7151e-09, -1.1233e-08]],\n    \n             [[ 2.2900e-08,  7.2904e-08,  3.7812e-08],\n              [ 5.0866e-08,  1.5815e-07,  1.3233e-07],\n              [ 2.8684e-08,  1.6908e-07,  8.8253e-08]],\n    \n             ...,\n    \n             [[ 3.5272e-09,  2.0128e-10, -7.2588e-09],\n              [ 3.5870e-08,  4.6158e-08,  2.9845e-08],\n              [ 3.4321e-08,  5.7742e-08,  2.6720e-08]],\n    \n             [[ 6.4918e-09, -5.0905e-08,  1.4078e-08],\n              [ 4.3692e-09, -2.3810e-08,  1.3342e-08],\n              [ 2.6606e-08, -1.8928e-08,  2.7103e-08]],\n    \n             [[-5.8301e-08, -7.6506e-08, -7.1180e-08],\n              [-1.0281e-07, -1.0562e-07, -5.8862e-08],\n              [-4.7317e-08, -6.1523e-08, -8.2827e-08]]],\n    \n    \n            [[[ 9.4048e-10, -5.5966e-09, -3.2985e-08],\n              [ 2.7686e-08, -6.1590e-08, -9.8903e-08],\n              [ 2.1967e-08, -1.4093e-08, -3.6714e-08]],\n    \n             [[-2.8160e-08,  1.6833e-08, -5.5796e-09],\n              [-4.5860e-08, -2.6376e-08, -5.4779e-08],\n              [-2.5218e-08,  1.7620e-08, -2.2513e-08]],\n    \n             [[-1.7084e-08, -1.4492e-08, -5.8686e-09],\n              [-2.7357e-08, -1.1345e-08,  5.0915e-08],\n              [-4.5430e-08, -2.4894e-08,  2.1517e-08]],\n    \n             ...,\n    \n             [[-4.5220e-08, -5.4863e-08, -5.7676e-08],\n              [-3.2135e-08, -1.9591e-08, -1.1536e-08],\n              [-6.8954e-10, -2.1526e-08, -3.3137e-08]],\n    \n             [[-4.3817e-08, -6.9941e-08, -3.3438e-08],\n              [-7.2727e-10, -6.9794e-08, -4.1373e-08],\n              [-3.5176e-08, -1.0523e-07, -2.2436e-08]],\n    \n             [[-6.0809e-10, -2.5590e-08, -1.9408e-08],\n              [-2.6874e-08, -4.5467e-08, -5.2112e-08],\n              [-1.0517e-08, -5.3426e-08, -1.9705e-08]]],\n    \n    \n            [[[ 4.5650e-08,  5.0255e-08,  5.0711e-08],\n              [ 1.6528e-07,  2.0987e-07,  1.5466e-07],\n              [ 2.2379e-08,  1.4215e-08, -1.2948e-08]],\n    \n             [[ 4.1998e-08,  6.9036e-08,  2.9161e-08],\n              [ 7.7338e-08,  6.5646e-08,  1.1810e-08],\n              [ 5.2871e-08,  3.5781e-08,  3.9304e-08]],\n    \n             [[ 1.7891e-08,  6.8340e-08,  1.0601e-08],\n              [ 1.2195e-08,  7.8069e-08,  1.3076e-08],\n              [ 5.2446e-08,  1.2216e-07,  1.1661e-07]],\n    \n             ...,\n    \n             [[-2.0604e-08,  3.0723e-08, -2.9688e-08],\n              [-4.4966e-08, -3.1816e-08, -6.6381e-08],\n              [-3.7495e-08, -1.7304e-09, -4.2872e-08]],\n    \n             [[-3.4327e-08, -8.7933e-08, -3.2339e-08],\n              [-7.9412e-08, -9.2456e-08, -1.1580e-07],\n              [-2.2564e-08, -6.9783e-08, -5.5252e-08]],\n    \n             [[ 1.7222e-08, -1.0640e-08, -3.4379e-08],\n              [ 4.7357e-09, -4.5388e-09, -1.8507e-08],\n              [ 1.5072e-08, -1.1884e-08, -3.0678e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.1455e-14, 2.5120e-14, 1.3333e-14],\n              [2.8059e-14, 6.7553e-14, 3.4150e-14],\n              [1.2717e-14, 2.8401e-14, 1.6136e-14]],\n    \n             [[6.7117e-15, 1.3728e-14, 1.0244e-14],\n              [1.6231e-14, 3.4046e-14, 2.5317e-14],\n              [1.7265e-14, 3.3418e-14, 2.4804e-14]],\n    \n             [[8.6793e-15, 2.2009e-14, 1.3608e-14],\n              [2.0405e-14, 6.3300e-14, 4.1293e-14],\n              [1.6254e-14, 4.7276e-14, 3.5409e-14]],\n    \n             ...,\n    \n             [[1.2977e-14, 2.7313e-14, 2.0387e-14],\n              [2.4182e-14, 5.8899e-14, 4.4524e-14],\n              [2.0538e-14, 5.1856e-14, 3.8601e-14]],\n    \n             [[6.4795e-15, 1.5958e-14, 8.6268e-15],\n              [1.7751e-14, 4.4305e-14, 2.5123e-14],\n              [1.3433e-14, 2.7718e-14, 1.9577e-14]],\n    \n             [[1.4709e-14, 3.8220e-14, 2.2733e-14],\n              [3.3173e-14, 1.0036e-13, 5.5954e-14],\n              [2.0707e-14, 6.1020e-14, 4.0902e-14]]],\n    \n    \n            [[[1.9289e-14, 4.2531e-14, 2.0545e-14],\n              [4.9390e-14, 1.1693e-13, 5.3220e-14],\n              [2.5694e-14, 5.7654e-14, 2.8908e-14]],\n    \n             [[1.1715e-14, 2.4415e-14, 1.8211e-14],\n              [2.9498e-14, 6.0858e-14, 4.3432e-14],\n              [2.8289e-14, 5.2276e-14, 3.9111e-14]],\n    \n             [[1.6574e-14, 3.9667e-14, 2.5592e-14],\n              [3.5174e-14, 9.1295e-14, 5.9449e-14],\n              [2.5439e-14, 6.1657e-14, 5.4399e-14]],\n    \n             ...,\n    \n             [[1.8109e-14, 2.3268e-14, 2.0447e-14],\n              [3.3845e-14, 4.9972e-14, 4.0678e-14],\n              [3.8281e-14, 5.8984e-14, 4.5380e-14]],\n    \n             [[1.0933e-14, 2.6586e-14, 1.4238e-14],\n              [3.5182e-14, 9.0982e-14, 5.2129e-14],\n              [2.3765e-14, 5.2203e-14, 3.5306e-14]],\n    \n             [[1.4344e-14, 3.5998e-14, 2.0444e-14],\n              [3.7366e-14, 1.0605e-13, 5.5522e-14],\n              [2.7071e-14, 6.9706e-14, 4.8499e-14]]],\n    \n    \n            [[[1.4758e-14, 3.7378e-14, 2.1718e-14],\n              [4.3082e-14, 1.2856e-13, 6.8597e-14],\n              [2.4493e-14, 6.2515e-14, 3.4255e-14]],\n    \n             [[1.2347e-14, 2.5103e-14, 1.8843e-14],\n              [2.8879e-14, 6.1899e-14, 4.8391e-14],\n              [2.8767e-14, 5.9710e-14, 4.4396e-14]],\n    \n             [[1.5398e-14, 4.3371e-14, 2.4737e-14],\n              [3.8702e-14, 1.2245e-13, 6.8620e-14],\n              [2.6113e-14, 7.7765e-14, 5.4283e-14]],\n    \n             ...,\n    \n             [[1.5647e-14, 2.8299e-14, 2.4860e-14],\n              [2.8767e-14, 5.8705e-14, 5.4159e-14],\n              [2.9120e-14, 5.8058e-14, 5.0471e-14]],\n    \n             [[1.1614e-14, 2.8597e-14, 1.6361e-14],\n              [3.3435e-14, 1.0071e-13, 5.4104e-14],\n              [2.4239e-14, 5.5009e-14, 3.7749e-14]],\n    \n             [[1.5347e-14, 4.4345e-14, 2.4923e-14],\n              [3.8804e-14, 1.2660e-13, 6.5156e-14],\n              [2.3468e-14, 7.4464e-14, 5.1024e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[1.2101e-14, 2.8220e-14, 1.5908e-14],\n              [3.1405e-14, 8.6286e-14, 4.8001e-14],\n              [1.6005e-14, 3.9437e-14, 2.4008e-14]],\n    \n             [[7.4715e-15, 1.4623e-14, 1.1400e-14],\n              [1.8268e-14, 3.5421e-14, 2.7851e-14],\n              [1.9095e-14, 3.4030e-14, 2.6897e-14]],\n    \n             [[8.1761e-15, 2.4811e-14, 1.5802e-14],\n              [2.2364e-14, 7.3714e-14, 4.7729e-14],\n              [1.9427e-14, 5.7610e-14, 4.3523e-14]],\n    \n             ...,\n    \n             [[1.3411e-14, 2.3819e-14, 1.8885e-14],\n              [2.5002e-14, 4.7797e-14, 4.1434e-14],\n              [2.3461e-14, 4.5588e-14, 3.6519e-14]],\n    \n             [[9.0970e-15, 2.4004e-14, 1.2550e-14],\n              [2.6725e-14, 7.9158e-14, 4.4070e-14],\n              [1.9475e-14, 4.8291e-14, 2.9672e-14]],\n    \n             [[1.4220e-14, 3.6782e-14, 2.0731e-14],\n              [3.5143e-14, 1.0370e-13, 5.6220e-14],\n              [2.2322e-14, 6.5813e-14, 4.4661e-14]]],\n    \n    \n            [[[1.7924e-14, 4.9713e-14, 2.3885e-14],\n              [4.2489e-14, 1.2002e-13, 6.0083e-14],\n              [2.0357e-14, 5.6443e-14, 3.0699e-14]],\n    \n             [[1.2176e-14, 2.7003e-14, 1.8107e-14],\n              [2.7352e-14, 5.5497e-14, 3.9297e-14],\n              [2.6093e-14, 4.8773e-14, 3.4508e-14]],\n    \n             [[1.4841e-14, 3.6655e-14, 2.5817e-14],\n              [2.9443e-14, 8.4770e-14, 5.5450e-14],\n              [2.3489e-14, 6.6134e-14, 5.2364e-14]],\n    \n             ...,\n    \n             [[1.3556e-14, 2.2934e-14, 1.8458e-14],\n              [2.1926e-14, 4.0599e-14, 3.3552e-14],\n              [2.0403e-14, 3.8473e-14, 3.0497e-14]],\n    \n             [[8.4268e-15, 2.1627e-14, 1.1059e-14],\n              [2.1692e-14, 5.7970e-14, 3.1044e-14],\n              [1.6667e-14, 3.6501e-14, 2.1711e-14]],\n    \n             [[1.4256e-14, 3.7890e-14, 2.1850e-14],\n              [3.0415e-14, 8.6266e-14, 4.8238e-14],\n              [1.7810e-14, 5.3258e-14, 3.6518e-14]]],\n    \n    \n            [[[1.8936e-14, 5.1697e-14, 2.5094e-14],\n              [3.6997e-14, 1.1926e-13, 5.7151e-14],\n              [1.5236e-14, 4.5408e-14, 2.5096e-14]],\n    \n             [[1.0463e-14, 2.7459e-14, 1.9539e-14],\n              [2.5706e-14, 7.1220e-14, 5.0784e-14],\n              [2.5917e-14, 5.7753e-14, 4.6391e-14]],\n    \n             [[1.0881e-14, 3.4191e-14, 2.0662e-14],\n              [2.8977e-14, 1.0916e-13, 6.5135e-14],\n              [2.5148e-14, 8.1560e-14, 6.1813e-14]],\n    \n             ...,\n    \n             [[1.1999e-14, 2.1562e-14, 2.0236e-14],\n              [2.1170e-14, 4.3692e-14, 4.1993e-14],\n              [2.3690e-14, 5.0777e-14, 4.4683e-14]],\n    \n             [[9.6067e-15, 2.5992e-14, 1.4332e-14],\n              [2.9969e-14, 8.3301e-14, 4.8657e-14],\n              [2.2692e-14, 5.5444e-14, 3.5599e-14]],\n    \n             [[1.2943e-14, 3.6605e-14, 1.8990e-14],\n              [2.8722e-14, 1.0521e-13, 4.7802e-14],\n              [1.8256e-14, 6.3336e-14, 4.2096e-14]]]])},\n   152: {'exp_avg': tensor([[[[ 3.6342e-08]],\n    \n             [[ 7.5718e-08]],\n    \n             [[ 8.4465e-08]],\n    \n             ...,\n    \n             [[ 2.8066e-08]],\n    \n             [[-2.0509e-08]],\n    \n             [[ 1.2338e-08]]],\n    \n    \n            [[[ 6.9906e-09]],\n    \n             [[-4.7603e-08]],\n    \n             [[-2.9304e-08]],\n    \n             ...,\n    \n             [[ 1.2732e-07]],\n    \n             [[-3.9195e-08]],\n    \n             [[ 4.3471e-08]]],\n    \n    \n            [[[-2.5430e-08]],\n    \n             [[-1.8955e-08]],\n    \n             [[ 1.8303e-08]],\n    \n             ...,\n    \n             [[ 8.0116e-09]],\n    \n             [[-3.7366e-08]],\n    \n             [[-7.5993e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 1.3373e-08]],\n    \n             [[ 8.5067e-10]],\n    \n             [[ 3.6206e-08]],\n    \n             ...,\n    \n             [[ 2.0233e-08]],\n    \n             [[-2.8085e-08]],\n    \n             [[ 1.1944e-08]]],\n    \n    \n            [[[ 1.2814e-08]],\n    \n             [[-2.5339e-08]],\n    \n             [[ 1.1965e-07]],\n    \n             ...,\n    \n             [[ 3.6890e-08]],\n    \n             [[ 2.7115e-08]],\n    \n             [[-1.1021e-08]]],\n    \n    \n            [[[-2.7937e-08]],\n    \n             [[-3.2791e-08]],\n    \n             [[ 6.7766e-08]],\n    \n             ...,\n    \n             [[ 1.3640e-08]],\n    \n             [[-7.8819e-09]],\n    \n             [[-1.1505e-08]]]]),\n    'exp_avg_sq': tensor([[[[3.0040e-14]],\n    \n             [[3.6224e-14]],\n    \n             [[4.9931e-14]],\n    \n             ...,\n    \n             [[5.0311e-14]],\n    \n             [[4.7438e-14]],\n    \n             [[6.4396e-14]]],\n    \n    \n            [[[3.0938e-14]],\n    \n             [[3.5123e-14]],\n    \n             [[3.1297e-14]],\n    \n             ...,\n    \n             [[5.0964e-14]],\n    \n             [[2.7106e-14]],\n    \n             [[8.2107e-14]]],\n    \n    \n            [[[1.1903e-14]],\n    \n             [[1.6749e-14]],\n    \n             [[1.7228e-14]],\n    \n             ...,\n    \n             [[2.3016e-14]],\n    \n             [[2.0855e-14]],\n    \n             [[2.3909e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[3.9802e-15]],\n    \n             [[4.1808e-15]],\n    \n             [[5.2134e-15]],\n    \n             ...,\n    \n             [[7.1682e-15]],\n    \n             [[5.2367e-15]],\n    \n             [[7.6410e-15]]],\n    \n    \n            [[[2.0048e-14]],\n    \n             [[2.4591e-14]],\n    \n             [[4.1845e-14]],\n    \n             ...,\n    \n             [[3.9544e-14]],\n    \n             [[3.3941e-14]],\n    \n             [[5.1144e-14]]],\n    \n    \n            [[[1.1727e-14]],\n    \n             [[1.5746e-14]],\n    \n             [[2.4373e-14]],\n    \n             ...,\n    \n             [[2.1831e-14]],\n    \n             [[1.9594e-14]],\n    \n             [[1.9011e-14]]]])},\n   153: {'exp_avg': tensor([[[[ 2.0658e-08]],\n    \n             [[-3.3047e-08]],\n    \n             [[-1.4790e-08]],\n    \n             ...,\n    \n             [[ 7.6742e-08]],\n    \n             [[ 1.0971e-07]],\n    \n             [[ 1.2256e-07]]],\n    \n    \n            [[[ 1.7781e-08]],\n    \n             [[-3.5756e-08]],\n    \n             [[ 2.3515e-09]],\n    \n             ...,\n    \n             [[ 1.1497e-08]],\n    \n             [[ 2.0894e-08]],\n    \n             [[ 2.4601e-08]]],\n    \n    \n            [[[-1.1465e-07]],\n    \n             [[ 1.2530e-08]],\n    \n             [[ 1.4972e-08]],\n    \n             ...,\n    \n             [[-3.0492e-08]],\n    \n             [[-1.0727e-07]],\n    \n             [[-4.8459e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-3.2769e-08]],\n    \n             [[-6.2669e-09]],\n    \n             [[ 3.3369e-08]],\n    \n             ...,\n    \n             [[-1.0220e-08]],\n    \n             [[-3.0428e-08]],\n    \n             [[ 5.5522e-09]]],\n    \n    \n            [[[-1.5706e-08]],\n    \n             [[ 5.8872e-08]],\n    \n             [[-5.0928e-08]],\n    \n             ...,\n    \n             [[-4.6174e-08]],\n    \n             [[-6.1908e-08]],\n    \n             [[ 2.0431e-08]]],\n    \n    \n            [[[ 7.7815e-08]],\n    \n             [[-3.9981e-08]],\n    \n             [[-1.9767e-08]],\n    \n             ...,\n    \n             [[ 6.3645e-08]],\n    \n             [[-6.8377e-08]],\n    \n             [[-2.8525e-08]]]]),\n    'exp_avg_sq': tensor([[[[4.1031e-14]],\n    \n             [[5.3234e-14]],\n    \n             [[5.0887e-14]],\n    \n             ...,\n    \n             [[3.3169e-14]],\n    \n             [[6.9417e-14]],\n    \n             [[4.5329e-14]]],\n    \n    \n            [[[4.1185e-14]],\n    \n             [[5.9783e-14]],\n    \n             [[4.1960e-14]],\n    \n             ...,\n    \n             [[3.3990e-14]],\n    \n             [[5.8126e-14]],\n    \n             [[4.3838e-14]]],\n    \n    \n            [[[4.4951e-14]],\n    \n             [[4.7032e-14]],\n    \n             [[4.4270e-14]],\n    \n             ...,\n    \n             [[3.5372e-14]],\n    \n             [[6.2161e-14]],\n    \n             [[6.4762e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[3.0464e-14]],\n    \n             [[4.4121e-14]],\n    \n             [[3.6767e-14]],\n    \n             ...,\n    \n             [[2.3273e-14]],\n    \n             [[4.8907e-14]],\n    \n             [[3.4394e-14]]],\n    \n    \n            [[[3.4410e-14]],\n    \n             [[4.3795e-14]],\n    \n             [[3.2439e-14]],\n    \n             ...,\n    \n             [[2.2019e-14]],\n    \n             [[4.7141e-14]],\n    \n             [[4.3471e-14]]],\n    \n    \n            [[[3.6324e-14]],\n    \n             [[4.7830e-14]],\n    \n             [[3.7310e-14]],\n    \n             ...,\n    \n             [[3.0638e-14]],\n    \n             [[5.4498e-14]],\n    \n             [[3.4973e-14]]]])},\n   154: {'exp_avg': tensor([[[[-3.7470e-08]],\n    \n             [[-1.8779e-09]],\n    \n             [[-1.5618e-08]],\n    \n             ...,\n    \n             [[-4.5067e-08]],\n    \n             [[-1.8373e-08]],\n    \n             [[ 1.8592e-08]]],\n    \n    \n            [[[ 1.0001e-07]],\n    \n             [[ 7.0141e-08]],\n    \n             [[ 6.8086e-09]],\n    \n             ...,\n    \n             [[ 6.8172e-08]],\n    \n             [[ 5.5517e-08]],\n    \n             [[ 8.4435e-08]]],\n    \n    \n            [[[-5.0797e-08]],\n    \n             [[-6.2109e-09]],\n    \n             [[ 2.8693e-09]],\n    \n             ...,\n    \n             [[-5.4304e-08]],\n    \n             [[-6.1979e-08]],\n    \n             [[-8.2991e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 8.3828e-08]],\n    \n             [[ 6.8314e-08]],\n    \n             [[-2.0770e-08]],\n    \n             ...,\n    \n             [[ 2.2036e-08]],\n    \n             [[ 1.0357e-08]],\n    \n             [[ 4.9515e-08]]],\n    \n    \n            [[[-8.4010e-09]],\n    \n             [[ 9.9206e-08]],\n    \n             [[-7.1535e-08]],\n    \n             ...,\n    \n             [[ 8.2614e-09]],\n    \n             [[-5.4353e-09]],\n    \n             [[-6.4033e-08]]],\n    \n    \n            [[[ 7.5513e-09]],\n    \n             [[-1.9338e-08]],\n    \n             [[-3.1935e-08]],\n    \n             ...,\n    \n             [[ 5.3958e-10]],\n    \n             [[ 1.0863e-07]],\n    \n             [[ 6.9112e-08]]]]),\n    'exp_avg_sq': tensor([[[[3.9959e-14]],\n    \n             [[6.0496e-14]],\n    \n             [[4.9752e-14]],\n    \n             ...,\n    \n             [[2.0472e-14]],\n    \n             [[5.8612e-14]],\n    \n             [[5.0814e-14]]],\n    \n    \n            [[[5.7681e-14]],\n    \n             [[6.1697e-14]],\n    \n             [[5.8134e-14]],\n    \n             ...,\n    \n             [[2.8170e-14]],\n    \n             [[4.2616e-14]],\n    \n             [[5.8326e-14]]],\n    \n    \n            [[[6.3271e-14]],\n    \n             [[5.2151e-14]],\n    \n             [[5.9164e-14]],\n    \n             ...,\n    \n             [[2.5796e-14]],\n    \n             [[5.8904e-14]],\n    \n             [[5.6670e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[5.4501e-14]],\n    \n             [[6.2115e-14]],\n    \n             [[5.0776e-14]],\n    \n             ...,\n    \n             [[2.4210e-14]],\n    \n             [[4.6538e-14]],\n    \n             [[4.2467e-14]]],\n    \n    \n            [[[5.5716e-14]],\n    \n             [[6.1353e-14]],\n    \n             [[4.8507e-14]],\n    \n             ...,\n    \n             [[2.7905e-14]],\n    \n             [[5.2361e-14]],\n    \n             [[4.0066e-14]]],\n    \n    \n            [[[4.8749e-14]],\n    \n             [[7.2581e-14]],\n    \n             [[4.5840e-14]],\n    \n             ...,\n    \n             [[3.1271e-14]],\n    \n             [[8.0214e-14]],\n    \n             [[4.4583e-14]]]])},\n   155: {'exp_avg': tensor([[[[-6.5135e-10, -3.8292e-08, -1.3240e-08],\n              [-6.8243e-08, -1.4818e-07, -5.9066e-08],\n              [-3.8943e-08, -1.0085e-07, -3.9991e-08]],\n    \n             [[ 1.2468e-08,  6.0944e-08,  1.5717e-08],\n              [-3.7039e-08, -1.1251e-07, -1.0387e-07],\n              [-3.3861e-08, -9.1555e-08, -6.2792e-08]],\n    \n             [[ 1.5659e-08, -6.4776e-09,  7.8607e-09],\n              [ 1.2203e-08,  1.0528e-08,  5.1291e-08],\n              [ 2.9425e-08,  3.0329e-08,  3.1113e-08]],\n    \n             ...,\n    \n             [[-9.9741e-09, -1.3273e-08, -4.9592e-09],\n              [-1.8096e-09, -1.2432e-07, -2.0981e-08],\n              [-3.6637e-08, -2.3039e-08,  2.5063e-08]],\n    \n             [[-4.3651e-08, -1.0174e-07, -3.6400e-08],\n              [-5.3521e-08, -1.0121e-07,  2.2114e-08],\n              [-2.4905e-08, -1.2424e-08, -6.4462e-10]],\n    \n             [[-2.2244e-08, -5.8641e-08,  1.4541e-09],\n              [-2.8412e-08, -1.1250e-07, -5.2216e-08],\n              [-3.2696e-08, -4.7164e-08,  1.8794e-08]]],\n    \n    \n            [[[-5.2013e-09, -5.7525e-08, -2.3463e-08],\n              [ 7.9759e-09, -4.6119e-08, -1.2731e-08],\n              [-7.5595e-09,  5.1020e-09, -7.7038e-09]],\n    \n             [[ 8.7560e-09, -2.5121e-08, -1.3681e-08],\n              [ 3.2816e-08,  1.8096e-08,  3.8171e-09],\n              [ 3.7290e-08, -1.1047e-08, -1.7363e-08]],\n    \n             [[-1.5253e-08, -1.1145e-07, -3.0727e-08],\n              [-5.1694e-09, -1.5150e-07, -1.0495e-07],\n              [-2.6801e-08, -7.0960e-08, -6.2586e-08]],\n    \n             ...,\n    \n             [[-1.6424e-08,  1.5890e-08,  2.9725e-08],\n              [-2.3470e-08,  5.1011e-08,  6.2245e-08],\n              [-2.3821e-08,  4.3738e-08,  4.4593e-08]],\n    \n             [[ 2.6326e-08,  3.1309e-08,  1.7170e-08],\n              [ 2.6945e-08,  5.2504e-10, -3.6362e-09],\n              [-3.0288e-08, -3.1458e-08, -1.2510e-08]],\n    \n             [[ 6.9773e-09,  5.6038e-08,  3.4325e-08],\n              [ 1.3550e-08,  9.1102e-08,  4.4619e-08],\n              [-9.9104e-09,  8.9708e-09,  8.7939e-09]]],\n    \n    \n            [[[-3.2026e-08, -4.5306e-08, -2.0137e-08],\n              [-2.7324e-08, -6.6498e-08, -1.4873e-09],\n              [ 4.0625e-09, -2.5578e-08, -2.2405e-08]],\n    \n             [[-3.4459e-08, -5.5078e-08, -2.5550e-08],\n              [-8.6968e-08, -6.8284e-08, -3.9078e-08],\n              [-4.7092e-08, -5.5863e-08, -1.3738e-08]],\n    \n             [[ 7.8489e-09,  2.2372e-08,  1.5649e-08],\n              [-6.0864e-09, -3.9956e-08, -5.6962e-09],\n              [-1.2844e-08,  2.1766e-09,  1.6791e-08]],\n    \n             ...,\n    \n             [[-3.1618e-09,  1.0443e-08,  9.8240e-09],\n              [-3.2871e-08, -1.9806e-08,  4.4238e-08],\n              [-8.8762e-09,  1.9445e-08,  2.7042e-08]],\n    \n             [[ 1.3715e-08,  4.3723e-08,  2.4258e-08],\n              [ 1.8476e-08,  3.9060e-08, -6.5469e-09],\n              [ 2.9677e-08,  2.4763e-08, -3.9315e-09]],\n    \n             [[ 2.2306e-08,  7.6737e-08,  3.7001e-08],\n              [ 3.5061e-08,  1.4525e-07,  8.7146e-08],\n              [ 1.7285e-09,  3.4676e-08,  4.0167e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[-1.2723e-08, -1.3102e-07, -1.0183e-07],\n              [-3.4651e-08, -1.0395e-07, -1.1165e-07],\n              [-2.4339e-08, -5.0342e-08, -4.0959e-08]],\n    \n             [[-2.7400e-08, -1.0918e-07, -5.3264e-08],\n              [-3.3400e-08, -1.8224e-07, -1.4496e-07],\n              [-5.6625e-09, -5.8884e-08, -5.9700e-08]],\n    \n             [[ 6.8534e-09, -5.2568e-08, -4.3539e-08],\n              [ 7.9686e-08,  1.7976e-08, -5.9384e-08],\n              [ 3.7166e-08,  2.5880e-08, -5.6477e-09]],\n    \n             ...,\n    \n             [[-2.3591e-09, -3.6949e-08, -2.6631e-08],\n              [-2.6152e-08,  8.7360e-09, -2.2392e-08],\n              [ 4.7208e-09,  1.5125e-08,  2.5112e-08]],\n    \n             [[-1.5334e-08, -1.0178e-07, -9.5204e-08],\n              [-1.8604e-08, -2.6601e-08,  2.2132e-08],\n              [ 2.5335e-08,  3.8571e-08,  3.2469e-08]],\n    \n             [[-8.6864e-09, -3.3343e-08, -1.2857e-08],\n              [ 1.9896e-08, -4.4456e-08, -4.1918e-08],\n              [ 1.9233e-08, -4.0273e-08, -9.4696e-09]]],\n    \n    \n            [[[-2.0930e-08, -1.9090e-09,  1.9384e-08],\n              [ 4.3269e-08,  2.7769e-08,  9.1478e-10],\n              [ 2.2615e-08,  6.5703e-08,  1.1687e-08]],\n    \n             [[-2.8504e-08,  1.1047e-09,  5.2617e-08],\n              [-6.2191e-09,  9.3187e-08,  8.0469e-08],\n              [ 5.9385e-08,  7.9401e-08,  3.3200e-08]],\n    \n             [[ 3.2262e-09,  1.0299e-08, -5.9244e-09],\n              [ 5.0862e-08,  1.4369e-07,  2.5239e-08],\n              [ 3.9501e-08,  5.7658e-08,  4.0461e-08]],\n    \n             ...,\n    \n             [[ 1.0628e-08,  3.2567e-08, -2.1773e-08],\n              [ 2.2548e-09,  2.9477e-08, -3.9046e-08],\n              [ 5.2132e-08,  6.1081e-08,  9.8783e-09]],\n    \n             [[-2.7210e-08, -5.9575e-08, -3.0727e-08],\n              [-3.4351e-08, -1.2217e-07, -6.9034e-08],\n              [ 3.8637e-09, -7.5070e-09, -2.1811e-10]],\n    \n             [[-3.7718e-08, -2.3784e-08,  4.3440e-08],\n              [ 5.4434e-08,  1.5645e-07,  1.1540e-07],\n              [ 5.9982e-08,  9.6816e-08,  4.9126e-08]]],\n    \n    \n            [[[-8.0402e-10, -3.3534e-08,  2.1354e-08],\n              [-1.1354e-08, -3.1272e-08,  1.1942e-08],\n              [ 1.7864e-08,  1.4818e-08, -1.3797e-08]],\n    \n             [[ 1.8153e-08,  2.2231e-08,  3.6217e-08],\n              [ 1.2423e-08,  4.1841e-08,  6.7395e-08],\n              [-1.4957e-08, -3.7150e-08,  7.6463e-09]],\n    \n             [[ 2.3029e-08,  1.8465e-08,  1.5049e-08],\n              [ 1.8674e-08,  2.5728e-08,  3.5635e-08],\n              [-2.8196e-08, -4.2107e-08,  2.7306e-08]],\n    \n             ...,\n    \n             [[ 1.4221e-08,  1.9243e-08,  9.6209e-09],\n              [-3.5361e-08,  4.0393e-09,  3.0576e-08],\n              [-1.6811e-08, -2.8572e-08, -9.2746e-09]],\n    \n             [[ 1.2063e-08,  1.4903e-08, -1.3557e-08],\n              [-2.3207e-09,  7.8976e-09, -2.7665e-09],\n              [ 9.2089e-09,  1.7652e-08,  3.2032e-09]],\n    \n             [[ 1.0054e-08,  3.8106e-09,  3.3234e-08],\n              [ 2.9310e-08,  2.2884e-08,  4.3361e-08],\n              [-1.0508e-08, -8.8943e-08,  3.5785e-09]]]]),\n    'exp_avg_sq': tensor([[[[2.3865e-14, 6.8827e-14, 2.7701e-14],\n              [3.9133e-14, 1.2871e-13, 5.0441e-14],\n              [1.2270e-14, 4.1129e-14, 1.6278e-14]],\n    \n             [[2.4127e-14, 6.7693e-14, 2.4423e-14],\n              [6.0474e-14, 1.7247e-13, 6.5923e-14],\n              [2.2393e-14, 6.5393e-14, 2.5947e-14]],\n    \n             [[2.0035e-14, 5.1818e-14, 1.7956e-14],\n              [4.7831e-14, 1.3083e-13, 4.7138e-14],\n              [2.0649e-14, 5.4288e-14, 2.0888e-14]],\n    \n             ...,\n    \n             [[1.6340e-14, 4.6344e-14, 2.0371e-14],\n              [4.0330e-14, 1.1177e-13, 4.8417e-14],\n              [1.7501e-14, 5.0376e-14, 2.2013e-14]],\n    \n             [[2.8167e-14, 6.5047e-14, 2.2846e-14],\n              [5.6613e-14, 1.2175e-13, 4.2739e-14],\n              [1.9038e-14, 3.9452e-14, 1.4287e-14]],\n    \n             [[3.2141e-14, 8.8035e-14, 3.3834e-14],\n              [5.6616e-14, 1.5374e-13, 5.7188e-14],\n              [1.9511e-14, 4.9573e-14, 1.7147e-14]]],\n    \n    \n            [[[1.0654e-14, 3.4069e-14, 1.3467e-14],\n              [2.3653e-14, 7.4597e-14, 2.7364e-14],\n              [8.0925e-15, 2.5142e-14, 1.0877e-14]],\n    \n             [[6.8453e-15, 1.9054e-14, 7.1918e-15],\n              [1.7867e-14, 5.3962e-14, 2.1196e-14],\n              [8.0396e-15, 2.2005e-14, 1.0206e-14]],\n    \n             [[1.3006e-14, 3.4545e-14, 1.2076e-14],\n              [3.5364e-14, 1.0821e-13, 3.6017e-14],\n              [1.3596e-14, 4.2658e-14, 1.6282e-14]],\n    \n             ...,\n    \n             [[7.7397e-15, 2.6369e-14, 1.0920e-14],\n              [2.3662e-14, 8.4160e-14, 3.1904e-14],\n              [1.0090e-14, 3.3408e-14, 1.3956e-14]],\n    \n             [[7.3713e-15, 1.7610e-14, 7.0439e-15],\n              [1.8787e-14, 4.5718e-14, 1.6556e-14],\n              [8.5617e-15, 2.1107e-14, 7.4166e-15]],\n    \n             [[1.2467e-14, 3.2639e-14, 1.2919e-14],\n              [2.4263e-14, 7.3614e-14, 2.7866e-14],\n              [8.6022e-15, 2.3353e-14, 9.0356e-15]]],\n    \n    \n            [[[9.7814e-15, 3.1270e-14, 1.2160e-14],\n              [1.8255e-14, 5.8652e-14, 2.4241e-14],\n              [6.2048e-15, 1.9896e-14, 9.6162e-15]],\n    \n             [[9.0608e-15, 2.9210e-14, 1.1517e-14],\n              [2.6184e-14, 8.8728e-14, 3.4817e-14],\n              [1.2071e-14, 3.9480e-14, 1.8101e-14]],\n    \n             [[1.1226e-14, 2.9846e-14, 1.0014e-14],\n              [3.1139e-14, 9.1482e-14, 3.2468e-14],\n              [1.3822e-14, 4.2210e-14, 1.6417e-14]],\n    \n             ...,\n    \n             [[6.3604e-15, 2.1796e-14, 9.5372e-15],\n              [1.6672e-14, 6.2643e-14, 2.7084e-14],\n              [7.6102e-15, 2.7740e-14, 1.3667e-14]],\n    \n             [[1.1561e-14, 2.8494e-14, 1.0368e-14],\n              [2.6107e-14, 6.6658e-14, 2.4732e-14],\n              [1.0336e-14, 2.9033e-14, 1.1032e-14]],\n    \n             [[1.2973e-14, 3.4041e-14, 1.2308e-14],\n              [2.3351e-14, 6.4399e-14, 2.4462e-14],\n              [7.7674e-15, 2.2363e-14, 8.9215e-15]]],\n    \n    \n            ...,\n    \n    \n            [[[1.2453e-14, 3.8341e-14, 1.8352e-14],\n              [2.4008e-14, 8.0499e-14, 3.5221e-14],\n              [8.0964e-15, 2.9826e-14, 1.2706e-14]],\n    \n             [[1.0539e-14, 3.0290e-14, 1.3853e-14],\n              [3.0160e-14, 9.2436e-14, 4.3855e-14],\n              [1.4176e-14, 4.4152e-14, 1.9265e-14]],\n    \n             [[1.3114e-14, 3.5166e-14, 1.3468e-14],\n              [3.4382e-14, 1.0137e-13, 4.0720e-14],\n              [1.3742e-14, 3.7871e-14, 1.6294e-14]],\n    \n             ...,\n    \n             [[6.6658e-15, 2.1915e-14, 1.1343e-14],\n              [2.0506e-14, 7.3653e-14, 3.5563e-14],\n              [9.0363e-15, 3.2469e-14, 1.5896e-14]],\n    \n             [[1.5437e-14, 3.9823e-14, 1.5656e-14],\n              [3.5471e-14, 8.8026e-14, 3.3096e-14],\n              [1.3459e-14, 3.1604e-14, 1.2348e-14]],\n    \n             [[1.4223e-14, 3.2992e-14, 1.5297e-14],\n              [2.2154e-14, 6.3149e-14, 2.5782e-14],\n              [7.0427e-15, 2.1273e-14, 8.0116e-15]]],\n    \n    \n            [[[1.6471e-14, 5.3050e-14, 1.9797e-14],\n              [2.5954e-14, 8.8636e-14, 3.5287e-14],\n              [8.2357e-15, 2.6412e-14, 1.3003e-14]],\n    \n             [[1.2824e-14, 3.3901e-14, 1.1861e-14],\n              [3.1682e-14, 8.6518e-14, 3.3384e-14],\n              [1.2715e-14, 3.8917e-14, 2.0240e-14]],\n    \n             [[1.6188e-14, 4.3674e-14, 1.4814e-14],\n              [4.3967e-14, 1.3769e-13, 5.0526e-14],\n              [1.7826e-14, 5.0745e-14, 2.1414e-14]],\n    \n             ...,\n    \n             [[1.1964e-14, 3.8906e-14, 1.4874e-14],\n              [2.4901e-14, 8.9728e-14, 3.9213e-14],\n              [1.0875e-14, 3.6222e-14, 2.0182e-14]],\n    \n             [[2.0675e-14, 4.9225e-14, 1.6413e-14],\n              [4.1444e-14, 1.0350e-13, 3.7794e-14],\n              [1.4236e-14, 3.7717e-14, 1.5099e-14]],\n    \n             [[2.4361e-14, 6.0174e-14, 2.1754e-14],\n              [3.4649e-14, 9.4059e-14, 3.7461e-14],\n              [1.1572e-14, 3.2161e-14, 1.4212e-14]]],\n    \n    \n            [[[9.0827e-15, 2.9211e-14, 1.5365e-14],\n              [1.9097e-14, 6.3830e-14, 3.0222e-14],\n              [7.6154e-15, 2.4382e-14, 1.0609e-14]],\n    \n             [[1.0636e-14, 3.1882e-14, 1.2921e-14],\n              [2.8554e-14, 9.1160e-14, 4.0982e-14],\n              [1.1054e-14, 3.3916e-14, 1.7061e-14]],\n    \n             [[1.0094e-14, 2.7738e-14, 1.1745e-14],\n              [2.6892e-14, 8.0052e-14, 3.7447e-14],\n              [1.3381e-14, 3.9581e-14, 1.8974e-14]],\n    \n             ...,\n    \n             [[6.9449e-15, 2.3654e-14, 1.1288e-14],\n              [1.9299e-14, 7.1924e-14, 3.7581e-14],\n              [9.5727e-15, 3.3724e-14, 1.7546e-14]],\n    \n             [[1.4022e-14, 3.5828e-14, 1.5319e-14],\n              [2.8229e-14, 7.6943e-14, 3.2348e-14],\n              [1.1927e-14, 3.1386e-14, 1.2420e-14]],\n    \n             [[1.6102e-14, 4.4339e-14, 1.7673e-14],\n              [2.8589e-14, 8.1422e-14, 3.3582e-14],\n              [1.0162e-14, 2.9375e-14, 1.3031e-14]]]])},\n   156: {'exp_avg': tensor([[[[ 2.0475e-09]],\n    \n             [[-2.1530e-08]],\n    \n             [[ 4.0867e-08]],\n    \n             ...,\n    \n             [[ 2.6930e-08]],\n    \n             [[-7.0610e-08]],\n    \n             [[-4.9771e-08]]],\n    \n    \n            [[[-5.1903e-08]],\n    \n             [[ 4.9630e-08]],\n    \n             [[ 3.4412e-08]],\n    \n             ...,\n    \n             [[ 1.6021e-08]],\n    \n             [[-1.1030e-08]],\n    \n             [[ 4.7132e-08]]],\n    \n    \n            [[[-3.5407e-08]],\n    \n             [[ 3.8120e-08]],\n    \n             [[ 2.3015e-08]],\n    \n             ...,\n    \n             [[-1.3857e-08]],\n    \n             [[ 3.7143e-08]],\n    \n             [[ 4.7986e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 1.4081e-08]],\n    \n             [[-3.2855e-09]],\n    \n             [[ 1.7545e-09]],\n    \n             ...,\n    \n             [[ 1.2635e-09]],\n    \n             [[ 1.9359e-09]],\n    \n             [[ 3.1792e-09]]],\n    \n    \n            [[[-1.9707e-08]],\n    \n             [[ 2.1626e-08]],\n    \n             [[ 2.1400e-08]],\n    \n             ...,\n    \n             [[-2.3932e-08]],\n    \n             [[ 2.9854e-08]],\n    \n             [[-1.6030e-09]]],\n    \n    \n            [[[ 1.4474e-08]],\n    \n             [[ 4.9862e-09]],\n    \n             [[ 2.5103e-08]],\n    \n             ...,\n    \n             [[-1.3117e-08]],\n    \n             [[-2.9631e-08]],\n    \n             [[-3.9394e-09]]]]),\n    'exp_avg_sq': tensor([[[[3.3526e-14]],\n    \n             [[4.5474e-14]],\n    \n             [[4.4036e-14]],\n    \n             ...,\n    \n             [[3.2438e-14]],\n    \n             [[3.8010e-14]],\n    \n             [[2.8801e-14]]],\n    \n    \n            [[[2.4874e-14]],\n    \n             [[2.9032e-14]],\n    \n             [[2.7856e-14]],\n    \n             ...,\n    \n             [[1.9509e-14]],\n    \n             [[2.1926e-14]],\n    \n             [[1.7582e-14]]],\n    \n    \n            [[[1.5563e-14]],\n    \n             [[1.7562e-14]],\n    \n             [[1.7119e-14]],\n    \n             ...,\n    \n             [[1.4295e-14]],\n    \n             [[1.5856e-14]],\n    \n             [[1.4513e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[7.0078e-16]],\n    \n             [[1.0922e-15]],\n    \n             [[8.8500e-16]],\n    \n             ...,\n    \n             [[5.8904e-16]],\n    \n             [[7.7838e-16]],\n    \n             [[5.6959e-16]]],\n    \n    \n            [[[2.7551e-14]],\n    \n             [[3.4977e-14]],\n    \n             [[3.0001e-14]],\n    \n             ...,\n    \n             [[2.2090e-14]],\n    \n             [[2.6644e-14]],\n    \n             [[2.0459e-14]]],\n    \n    \n            [[[1.0457e-14]],\n    \n             [[1.2820e-14]],\n    \n             [[1.0838e-14]],\n    \n             ...,\n    \n             [[8.7011e-15]],\n    \n             [[8.5663e-15]],\n    \n             [[7.4226e-15]]]])},\n   157: {'exp_avg': tensor([[[[ 1.1088e-07]],\n    \n             [[ 2.5354e-08]],\n    \n             [[-3.7848e-08]],\n    \n             ...,\n    \n             [[-1.2123e-08]],\n    \n             [[ 1.9566e-08]],\n    \n             [[-9.7572e-09]]],\n    \n    \n            [[[ 3.2756e-08]],\n    \n             [[-6.8034e-08]],\n    \n             [[-6.4065e-08]],\n    \n             ...,\n    \n             [[ 3.8994e-08]],\n    \n             [[ 2.4401e-08]],\n    \n             [[-1.9365e-08]]],\n    \n    \n            [[[ 8.0385e-08]],\n    \n             [[ 2.3365e-08]],\n    \n             [[ 2.2180e-08]],\n    \n             ...,\n    \n             [[ 2.9588e-08]],\n    \n             [[-7.8929e-09]],\n    \n             [[ 5.1588e-09]]],\n    \n    \n            ...,\n    \n    \n            [[[ 7.9044e-09]],\n    \n             [[-1.9636e-08]],\n    \n             [[-6.0276e-08]],\n    \n             ...,\n    \n             [[ 3.2661e-08]],\n    \n             [[ 3.5364e-08]],\n    \n             [[ 4.2904e-08]]],\n    \n    \n            [[[ 1.5869e-08]],\n    \n             [[-1.0512e-08]],\n    \n             [[-2.7044e-08]],\n    \n             ...,\n    \n             [[-4.1556e-08]],\n    \n             [[ 1.0759e-07]],\n    \n             [[ 5.2584e-08]]],\n    \n    \n            [[[ 2.1435e-08]],\n    \n             [[ 5.6327e-08]],\n    \n             [[-1.9563e-08]],\n    \n             ...,\n    \n             [[ 6.9422e-08]],\n    \n             [[ 1.4719e-09]],\n    \n             [[-1.7216e-09]]]]),\n    'exp_avg_sq': tensor([[[[4.8261e-14]],\n    \n             [[4.7009e-14]],\n    \n             [[2.9456e-14]],\n    \n             ...,\n    \n             [[1.8042e-14]],\n    \n             [[4.7475e-14]],\n    \n             [[4.1412e-14]]],\n    \n    \n            [[[2.7164e-14]],\n    \n             [[4.8839e-14]],\n    \n             [[3.5083e-14]],\n    \n             ...,\n    \n             [[1.7954e-14]],\n    \n             [[3.5456e-14]],\n    \n             [[2.2699e-14]]],\n    \n    \n            [[[4.8442e-14]],\n    \n             [[4.0740e-14]],\n    \n             [[3.8702e-14]],\n    \n             ...,\n    \n             [[2.1529e-14]],\n    \n             [[3.1367e-14]],\n    \n             [[3.3827e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[4.4332e-14]],\n    \n             [[5.1990e-14]],\n    \n             [[4.3267e-14]],\n    \n             ...,\n    \n             [[2.1823e-14]],\n    \n             [[3.5061e-14]],\n    \n             [[3.5573e-14]]],\n    \n    \n            [[[6.0447e-14]],\n    \n             [[4.8883e-14]],\n    \n             [[3.8233e-14]],\n    \n             ...,\n    \n             [[2.7119e-14]],\n    \n             [[5.1669e-14]],\n    \n             [[4.5441e-14]]],\n    \n    \n            [[[3.7108e-14]],\n    \n             [[5.3853e-14]],\n    \n             [[4.1689e-14]],\n    \n             ...,\n    \n             [[1.9528e-14]],\n    \n             [[4.2418e-14]],\n    \n             [[2.3330e-14]]]])},\n   158: {'exp_avg': tensor([[[[ 1.8227e-08,  8.3328e-09, -1.1386e-08],\n              [ 3.7187e-09, -2.2996e-08, -2.2318e-08],\n              [ 8.7333e-09,  7.8500e-09, -2.4627e-09]],\n    \n             [[ 4.5016e-09,  1.0874e-08, -3.3826e-09],\n              [-1.1855e-08,  1.0451e-08,  2.2100e-10],\n              [-4.5132e-08, -3.5116e-08, -3.5568e-08]],\n    \n             [[ 1.7171e-08,  3.9851e-08,  1.8209e-08],\n              [ 5.2480e-10, -2.7270e-08, -2.5766e-08],\n              [-5.1170e-08, -9.9110e-08, -4.7741e-08]],\n    \n             ...,\n    \n             [[ 2.1069e-09,  7.3582e-09, -1.3002e-08],\n              [-2.6490e-08, -3.4006e-09,  3.7561e-08],\n              [-1.2690e-08,  4.7441e-09,  1.8492e-08]],\n    \n             [[ 2.0039e-08,  1.9891e-08,  6.0649e-09],\n              [-9.2212e-09,  5.2593e-09,  2.4916e-08],\n              [-3.9298e-08, -2.5696e-08,  6.3131e-09]],\n    \n             [[-6.7900e-09,  1.2135e-08, -7.2803e-09],\n              [-1.3612e-08,  1.3267e-08, -2.6217e-09],\n              [-9.2870e-09, -9.4053e-09,  2.8024e-09]]],\n    \n    \n            [[[-5.1690e-08, -5.5412e-08, -8.8924e-09],\n              [-4.5224e-08, -4.2695e-08, -4.9695e-09],\n              [-6.7960e-09, -2.4282e-08, -5.0941e-09]],\n    \n             [[-7.0385e-09, -1.7210e-08, -6.7601e-09],\n              [ 7.5881e-09,  1.1365e-08, -5.0127e-10],\n              [ 1.4691e-08,  2.1212e-08, -1.1539e-08]],\n    \n             [[ 1.0623e-08,  3.1646e-08,  1.0660e-08],\n              [ 4.2649e-08,  9.4310e-08,  4.1555e-08],\n              [ 3.6284e-08,  9.5285e-08,  4.9466e-08]],\n    \n             ...,\n    \n             [[-9.7230e-09,  6.0784e-09,  1.9039e-08],\n              [-4.4522e-08, -5.3771e-08,  4.6057e-09],\n              [-2.2663e-08, -5.6401e-08, -1.9821e-08]],\n    \n             [[ 1.7266e-08,  2.2880e-08,  2.2266e-08],\n              [ 1.0470e-08, -1.1607e-08,  1.8421e-08],\n              [ 6.0266e-10, -8.0034e-09, -2.9346e-09]],\n    \n             [[ 1.0139e-08,  8.5490e-09, -1.3410e-08],\n              [-1.1454e-08, -1.7552e-08, -3.0984e-08],\n              [ 7.6393e-09, -5.8543e-09, -1.8312e-08]]],\n    \n    \n            [[[ 6.2594e-08,  1.1831e-07,  2.4472e-08],\n              [ 1.2454e-07,  1.9781e-07,  5.9392e-08],\n              [ 6.5081e-08,  1.0165e-07,  3.7749e-08]],\n    \n             [[ 7.4807e-10,  1.0661e-08,  3.2142e-08],\n              [ 2.6487e-08,  6.7961e-08,  4.2140e-08],\n              [ 2.0977e-08,  2.3675e-08,  3.0814e-08]],\n    \n             [[ 3.7906e-08,  4.2951e-08,  1.4140e-08],\n              [ 3.7063e-08,  8.4215e-08,  4.2812e-08],\n              [-6.6455e-09,  6.0138e-08,  3.6044e-08]],\n    \n             ...,\n    \n             [[-5.6381e-09,  2.6477e-08,  1.8536e-08],\n              [ 1.8879e-08,  1.1530e-07,  9.7559e-08],\n              [ 2.2294e-08,  1.0035e-07,  5.7790e-08]],\n    \n             [[-2.9947e-09, -8.0533e-09, -1.4807e-08],\n              [ 7.8901e-09, -4.8906e-08, -2.6591e-08],\n              [-1.3005e-08, -3.9194e-08, -1.4998e-08]],\n    \n             [[-1.8479e-08, -2.4633e-08,  8.9210e-09],\n              [-2.8206e-08, -1.7311e-08,  1.9089e-08],\n              [-1.3958e-09,  2.4086e-09,  2.3347e-08]]],\n    \n    \n            ...,\n    \n    \n            [[[ 7.4724e-09,  4.7377e-08,  4.4853e-08],\n              [ 3.2645e-08,  1.0360e-07,  7.9817e-08],\n              [ 1.9123e-08,  4.5846e-08,  3.8391e-08]],\n    \n             [[-1.2793e-08, -2.5931e-08, -7.5855e-09],\n              [ 1.0607e-11,  1.1782e-09, -2.3181e-08],\n              [ 4.3883e-09,  8.9694e-09, -3.3397e-09]],\n    \n             [[-1.4997e-08, -3.4838e-08, -2.9532e-08],\n              [ 2.3023e-08, -1.3133e-08, -2.9520e-08],\n              [ 6.1850e-08,  6.1197e-08,  2.9605e-10]],\n    \n             ...,\n    \n             [[-1.1049e-08, -5.3694e-08, -3.0109e-08],\n              [-4.0032e-08, -1.2620e-07, -7.1359e-08],\n              [-4.2991e-08, -9.0857e-08, -4.2074e-08]],\n    \n             [[-3.2431e-08, -3.0240e-08, -9.8668e-09],\n              [-3.2482e-08, -2.8662e-08, -2.2311e-08],\n              [-1.3976e-08, -7.6249e-09, -8.3911e-09]],\n    \n             [[-5.1898e-08, -5.5292e-08, -1.6606e-08],\n              [-7.1134e-08, -8.3205e-08, -2.6857e-08],\n              [-4.6162e-08, -6.3946e-08, -1.7117e-08]]],\n    \n    \n            [[[-2.4763e-08, -4.2549e-09,  9.2239e-09],\n              [-2.1205e-08, -3.7414e-08, -2.1594e-09],\n              [-2.2650e-08, -6.8142e-08, -2.3257e-08]],\n    \n             [[ 2.7851e-08,  3.2139e-08,  3.0542e-08],\n              [ 4.9877e-08,  6.4988e-08,  2.4267e-08],\n              [ 3.5441e-08,  5.4833e-08,  1.5342e-08]],\n    \n             [[-1.2680e-08, -1.8378e-08,  7.6742e-10],\n              [ 6.2275e-09, -2.5274e-08, -1.4489e-08],\n              [ 1.3967e-08,  9.4646e-09,  8.4942e-09]],\n    \n             ...,\n    \n             [[ 6.2934e-09, -1.9611e-08, -2.1249e-08],\n              [-2.0791e-08, -1.2014e-08, -3.2930e-08],\n              [-1.7507e-08, -2.5475e-08, -9.9366e-09]],\n    \n             [[ 7.5971e-09, -6.2621e-09, -1.1220e-08],\n              [ 4.6442e-08, -1.4624e-08, -3.5660e-08],\n              [ 2.6652e-08, -1.7898e-08, -2.6661e-08]],\n    \n             [[ 1.1461e-09,  4.4664e-09,  1.2193e-08],\n              [ 1.4396e-08,  6.6149e-08,  4.6100e-08],\n              [ 2.8549e-08,  5.0277e-08,  1.2597e-08]]],\n    \n    \n            [[[-8.9998e-09, -4.2626e-08, -2.3566e-08],\n              [ 9.0135e-09,  5.1698e-09, -5.7873e-09],\n              [ 3.6594e-09,  2.4576e-08,  1.5890e-08]],\n    \n             [[-1.2354e-09, -6.2673e-09,  8.3377e-09],\n              [ 3.1503e-08, -5.7620e-09, -3.0617e-08],\n              [ 2.0952e-08, -2.4274e-09, -1.8878e-08]],\n    \n             [[-1.3936e-08, -2.5863e-08,  3.9020e-09],\n              [-3.7930e-08, -3.7857e-08, -2.6448e-08],\n              [ 1.1770e-09, -1.0956e-08, -1.4674e-08]],\n    \n             ...,\n    \n             [[-7.8257e-09,  1.4177e-08,  2.4187e-08],\n              [-1.9888e-08, -3.6597e-08,  6.8740e-10],\n              [-1.0259e-08, -2.7647e-08, -1.5728e-08]],\n    \n             [[-2.7580e-08, -8.6518e-08, -4.2201e-08],\n              [-3.0508e-08, -1.5488e-07, -8.7495e-08],\n              [ 1.0828e-08, -3.6254e-08, -4.1721e-08]],\n    \n             [[-3.5380e-08, -1.9754e-08, -8.7667e-09],\n              [-3.3259e-08, -4.8720e-08, -2.8890e-08],\n              [ 2.0381e-09, -1.1326e-08, -8.1691e-09]]]]),\n    'exp_avg_sq': tensor([[[[9.9524e-15, 2.5693e-14, 7.9124e-15],\n              [2.8056e-14, 8.0698e-14, 2.3581e-14],\n              [1.0291e-14, 2.9501e-14, 1.0292e-14]],\n    \n             [[7.5273e-15, 2.1429e-14, 9.0197e-15],\n              [2.8629e-14, 8.3478e-14, 3.4016e-14],\n              [1.5903e-14, 4.9777e-14, 2.0605e-14]],\n    \n             [[6.3433e-15, 1.7945e-14, 6.9675e-15],\n              [2.1217e-14, 6.2709e-14, 2.4492e-14],\n              [1.0852e-14, 3.1691e-14, 1.2543e-14]],\n    \n             ...,\n    \n             [[6.1401e-15, 1.8129e-14, 7.2786e-15],\n              [1.9997e-14, 6.2044e-14, 2.5507e-14],\n              [9.9278e-15, 2.8624e-14, 1.3597e-14]],\n    \n             [[8.6955e-15, 2.5180e-14, 9.1854e-15],\n              [2.9671e-14, 8.6890e-14, 2.9951e-14],\n              [1.2997e-14, 3.6897e-14, 1.3574e-14]],\n    \n             [[1.0973e-14, 2.9777e-14, 1.1844e-14],\n              [3.4066e-14, 9.4085e-14, 3.9121e-14],\n              [1.5975e-14, 5.0057e-14, 2.2446e-14]]],\n    \n    \n            [[[9.9428e-15, 2.9045e-14, 9.0531e-15],\n              [2.9098e-14, 9.0219e-14, 2.6837e-14],\n              [1.0673e-14, 3.3059e-14, 1.0843e-14]],\n    \n             [[5.3133e-15, 1.4320e-14, 5.1801e-15],\n              [2.0730e-14, 5.9123e-14, 2.1629e-14],\n              [1.0766e-14, 3.2851e-14, 1.3508e-14]],\n    \n             [[4.9199e-15, 1.4046e-14, 4.9328e-15],\n              [1.7595e-14, 5.8253e-14, 2.0566e-14],\n              [9.5270e-15, 3.1625e-14, 1.1816e-14]],\n    \n             ...,\n    \n             [[5.7132e-15, 1.7955e-14, 6.9266e-15],\n              [1.8965e-14, 6.1557e-14, 2.2367e-14],\n              [8.7101e-15, 2.9759e-14, 1.1933e-14]],\n    \n             [[8.5396e-15, 2.3634e-14, 8.1347e-15],\n              [2.8681e-14, 8.0788e-14, 2.8793e-14],\n              [1.3016e-14, 3.9120e-14, 1.4582e-14]],\n    \n             [[3.8839e-15, 9.8492e-15, 3.6903e-15],\n              [1.2095e-14, 3.3341e-14, 1.3568e-14],\n              [5.2993e-15, 1.5986e-14, 8.0655e-15]]],\n    \n    \n            [[[1.6237e-14, 4.7322e-14, 1.4318e-14],\n              [4.8281e-14, 1.4251e-13, 4.3661e-14],\n              [1.6354e-14, 4.8394e-14, 1.6701e-14]],\n    \n             [[5.2904e-15, 1.5140e-14, 6.1613e-15],\n              [1.9046e-14, 6.0109e-14, 2.3919e-14],\n              [1.0201e-14, 3.2885e-14, 1.4108e-14]],\n    \n             [[6.7145e-15, 2.0474e-14, 7.7966e-15],\n              [2.1444e-14, 7.1749e-14, 2.7014e-14],\n              [1.0529e-14, 3.5268e-14, 1.3786e-14]],\n    \n             ...,\n    \n             [[8.3336e-15, 2.5679e-14, 9.5888e-15],\n              [2.7698e-14, 9.5791e-14, 3.2893e-14],\n              [1.1878e-14, 4.0579e-14, 1.4977e-14]],\n    \n             [[1.0002e-14, 2.9171e-14, 1.0467e-14],\n              [3.5230e-14, 1.0875e-13, 3.8297e-14],\n              [1.5375e-14, 4.6681e-14, 1.8600e-14]],\n    \n             [[8.2506e-15, 2.2186e-14, 8.5237e-15],\n              [2.3832e-14, 6.7250e-14, 2.7438e-14],\n              [9.6505e-15, 3.0269e-14, 1.3116e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[8.7417e-15, 2.2754e-14, 7.2026e-15],\n              [2.5428e-14, 7.4083e-14, 2.0957e-14],\n              [9.1905e-15, 2.6313e-14, 8.5251e-15]],\n    \n             [[4.8948e-15, 1.3967e-14, 5.6166e-15],\n              [1.8669e-14, 5.7617e-14, 2.1473e-14],\n              [9.6010e-15, 2.8658e-14, 1.1212e-14]],\n    \n             [[6.1763e-15, 1.8374e-14, 6.6958e-15],\n              [1.8655e-14, 5.4912e-14, 1.9103e-14],\n              [7.8151e-15, 2.2494e-14, 8.2435e-15]],\n    \n             ...,\n    \n             [[6.2446e-15, 1.9956e-14, 7.5153e-15],\n              [1.9463e-14, 5.7152e-14, 2.1219e-14],\n              [8.4520e-15, 2.4767e-14, 9.6739e-15]],\n    \n             [[6.3401e-15, 1.7274e-14, 6.1103e-15],\n              [1.8504e-14, 5.1213e-14, 1.8587e-14],\n              [8.0609e-15, 2.2257e-14, 8.3937e-15]],\n    \n             [[9.5495e-15, 2.4882e-14, 9.9418e-15],\n              [2.5768e-14, 6.6723e-14, 3.2672e-14],\n              [1.0607e-14, 2.9765e-14, 1.3365e-14]]],\n    \n    \n            [[[9.3493e-15, 2.7118e-14, 8.9115e-15],\n              [2.3133e-14, 7.1853e-14, 2.2958e-14],\n              [8.7836e-15, 2.5351e-14, 8.6488e-15]],\n    \n             [[8.9546e-15, 2.5876e-14, 1.0077e-14],\n              [3.2595e-14, 1.0374e-13, 3.8917e-14],\n              [1.4437e-14, 4.3182e-14, 1.6857e-14]],\n    \n             [[7.0236e-15, 2.1022e-14, 8.5243e-15],\n              [2.2209e-14, 6.5969e-14, 2.4262e-14],\n              [9.5606e-15, 2.8157e-14, 1.0956e-14]],\n    \n             ...,\n    \n             [[7.1315e-15, 2.4567e-14, 9.3311e-15],\n              [2.2491e-14, 7.8436e-14, 3.0293e-14],\n              [9.5548e-15, 3.0505e-14, 1.2924e-14]],\n    \n             [[8.8496e-15, 2.5850e-14, 9.2803e-15],\n              [2.4539e-14, 6.7120e-14, 2.2908e-14],\n              [1.0101e-14, 2.6836e-14, 9.4617e-15]],\n    \n             [[1.2064e-14, 3.4793e-14, 1.4813e-14],\n              [3.8153e-14, 1.1528e-13, 4.9104e-14],\n              [1.3504e-14, 4.2925e-14, 1.8837e-14]]],\n    \n    \n            [[[9.5779e-15, 2.5115e-14, 8.6285e-15],\n              [2.3260e-14, 6.5202e-14, 2.3297e-14],\n              [7.8741e-15, 2.1904e-14, 9.0866e-15]],\n    \n             [[9.5915e-15, 2.7692e-14, 1.1034e-14],\n              [3.2864e-14, 1.0512e-13, 4.0172e-14],\n              [1.5504e-14, 4.9102e-14, 1.9391e-14]],\n    \n             [[8.4375e-15, 2.5511e-14, 9.2018e-15],\n              [2.4508e-14, 7.8634e-14, 2.8361e-14],\n              [9.3296e-15, 2.8550e-14, 1.1193e-14]],\n    \n             ...,\n    \n             [[9.6273e-15, 2.8238e-14, 1.0668e-14],\n              [2.8938e-14, 9.1561e-14, 3.3648e-14],\n              [1.0838e-14, 3.5001e-14, 1.4114e-14]],\n    \n             [[1.1170e-14, 3.0487e-14, 1.0626e-14],\n              [3.0360e-14, 8.0131e-14, 3.0729e-14],\n              [1.0635e-14, 2.9147e-14, 1.2934e-14]],\n    \n             [[1.0016e-14, 2.9558e-14, 1.0261e-14],\n              [2.8724e-14, 9.9990e-14, 3.6246e-14],\n              [1.1016e-14, 3.8569e-14, 1.5719e-14]]]])},\n   159: {'exp_avg': tensor([[[[ 2.0134e-08]],\n    \n             [[-2.0140e-08]],\n    \n             [[ 3.6893e-08]],\n    \n             ...,\n    \n             [[-4.0229e-08]],\n    \n             [[ 5.3832e-08]],\n    \n             [[-4.4814e-09]]],\n    \n    \n            [[[-1.7080e-08]],\n    \n             [[ 1.9517e-08]],\n    \n             [[ 4.6835e-08]],\n    \n             ...,\n    \n             [[ 8.6201e-09]],\n    \n             [[-5.3456e-08]],\n    \n             [[ 2.5897e-08]]],\n    \n    \n            [[[-4.6743e-08]],\n    \n             [[ 2.9767e-08]],\n    \n             [[ 1.0042e-08]],\n    \n             ...,\n    \n             [[-2.0854e-08]],\n    \n             [[-2.5010e-10]],\n    \n             [[ 4.0851e-09]]],\n    \n    \n            ...,\n    \n    \n            [[[-1.3071e-09]],\n    \n             [[ 1.8891e-09]],\n    \n             [[-2.8983e-11]],\n    \n             ...,\n    \n             [[ 1.3670e-09]],\n    \n             [[ 1.1730e-09]],\n    \n             [[-1.2366e-09]]],\n    \n    \n            [[[ 4.0201e-08]],\n    \n             [[-1.5618e-08]],\n    \n             [[ 3.1198e-08]],\n    \n             ...,\n    \n             [[ 2.9086e-08]],\n    \n             [[ 1.2468e-09]],\n    \n             [[-2.2588e-08]]],\n    \n    \n            [[[ 4.8932e-10]],\n    \n             [[-3.4290e-09]],\n    \n             [[-3.9728e-08]],\n    \n             ...,\n    \n             [[ 2.6076e-08]],\n    \n             [[-6.0563e-09]],\n    \n             [[-2.3989e-08]]]]),\n    'exp_avg_sq': tensor([[[[1.8870e-14]],\n    \n             [[1.8399e-14]],\n    \n             [[2.1275e-14]],\n    \n             ...,\n    \n             [[1.6253e-14]],\n    \n             [[1.8886e-14]],\n    \n             [[1.9232e-14]]],\n    \n    \n            [[[1.4323e-14]],\n    \n             [[1.1588e-14]],\n    \n             [[1.5957e-14]],\n    \n             ...,\n    \n             [[1.2650e-14]],\n    \n             [[1.6992e-14]],\n    \n             [[1.6578e-14]]],\n    \n    \n            [[[1.8258e-14]],\n    \n             [[1.3322e-14]],\n    \n             [[1.7602e-14]],\n    \n             ...,\n    \n             [[1.5321e-14]],\n    \n             [[2.0218e-14]],\n    \n             [[1.7329e-14]]],\n    \n    \n            ...,\n    \n    \n            [[[2.6047e-17]],\n    \n             [[2.1152e-17]],\n    \n             [[2.7266e-17]],\n    \n             ...,\n    \n             [[2.5205e-17]],\n    \n             [[2.4322e-17]],\n    \n             [[2.7537e-17]]],\n    \n    \n            [[[2.0312e-14]],\n    \n             [[1.7833e-14]],\n    \n             [[2.2635e-14]],\n    \n             ...,\n    \n             [[1.8544e-14]],\n    \n             [[2.0664e-14]],\n    \n             [[2.0035e-14]]],\n    \n    \n            [[[9.8113e-15]],\n    \n             [[1.0698e-14]],\n    \n             [[1.1775e-14]],\n    \n             ...,\n    \n             [[9.0811e-15]],\n    \n             [[1.0485e-14]],\n    \n             [[1.0251e-14]]]])},\n   160: {'exp_avg': tensor([[-7.9250e-08, -1.2468e-07, -1.7468e-07,  ..., -1.4416e-08,\n             -2.1073e-07, -5.5214e-08],\n            [ 8.9082e-08,  4.6188e-08, -1.5225e-08,  ...,  5.8741e-09,\n             -2.3992e-08, -3.3590e-09],\n            [ 8.1399e-08,  1.7666e-07, -1.1241e-08,  ...,  3.1948e-08,\n             -4.9386e-08, -2.7662e-08],\n            ...,\n            [-4.4929e-09,  5.9071e-09, -2.2912e-07,  ...,  2.4906e-08,\n             -2.7380e-08, -3.4340e-08],\n            [ 3.0346e-08, -6.4665e-08, -9.5521e-08,  ..., -2.6701e-08,\n             -9.3272e-08, -4.3430e-08],\n            [ 9.1122e-09,  5.2699e-08,  5.5816e-08,  ...,  6.6910e-08,\n              4.7143e-08,  7.4957e-08]]),\n    'exp_avg_sq': tensor([[1.1528e-13, 4.0114e-13, 4.2496e-13,  ..., 4.2134e-14, 4.8021e-13,\n             1.5634e-13],\n            [2.8836e-13, 6.4168e-13, 3.6751e-13,  ..., 3.6208e-14, 4.2488e-13,\n             1.1029e-13],\n            [3.5331e-13, 6.1409e-13, 4.0866e-13,  ..., 3.8646e-14, 5.8862e-13,\n             1.4989e-13],\n            ...,\n            [3.1463e-13, 3.6437e-13, 2.7628e-13,  ..., 6.2991e-14, 2.6643e-13,\n             1.6632e-13],\n            [1.7366e-13, 1.3495e-13, 8.2187e-14,  ..., 6.5734e-14, 1.7331e-13,\n             1.3830e-13],\n            [6.2168e-13, 5.7807e-13, 2.8164e-13,  ..., 8.2288e-14, 5.3805e-13,\n             3.0892e-13]])}},\n  'param_groups': [{'weight_decay': 0.0,\n    'lr': 9.517294753398064e-05,\n    'bias_correction': True,\n    'betas': (0.9, 0.999),\n    'eps': 1e-06,\n    'grad_averaging': True,\n    'max_grad_norm': 1.0,\n    'trust_clip': False,\n    'always_adapt': False,\n    'initial_lr': 0.002,\n    'step': 13572,\n    'params': [0,\n     1,\n     2,\n     3,\n     4,\n     5,\n     6,\n     7,\n     8,\n     9,\n     10,\n     11,\n     12,\n     13,\n     14,\n     15,\n     16,\n     17,\n     18,\n     19,\n     20,\n     21,\n     22,\n     23,\n     24,\n     25,\n     26,\n     27,\n     28,\n     29,\n     30,\n     31,\n     32,\n     33,\n     34,\n     35,\n     36,\n     37,\n     38,\n     39,\n     40,\n     41,\n     42,\n     43,\n     44,\n     45,\n     46,\n     47,\n     48,\n     49,\n     50,\n     51,\n     52,\n     53,\n     54,\n     55,\n     56,\n     57,\n     58,\n     59,\n     60,\n     61,\n     62,\n     63,\n     64,\n     65,\n     66,\n     67,\n     68,\n     69,\n     70,\n     71,\n     72,\n     73,\n     74,\n     75,\n     76,\n     77,\n     78,\n     79,\n     80,\n     81,\n     82,\n     83,\n     84,\n     85,\n     86,\n     87,\n     88,\n     89,\n     90,\n     91,\n     92,\n     93,\n     94,\n     95,\n     96,\n     97,\n     98,\n     99,\n     100,\n     101,\n     102,\n     103,\n     104,\n     105,\n     106]},\n   {'weight_decay': 0.02,\n    'lr': 9.517294753398064e-05,\n    'bias_correction': True,\n    'betas': (0.9, 0.999),\n    'eps': 1e-06,\n    'grad_averaging': True,\n    'max_grad_norm': 1.0,\n    'trust_clip': False,\n    'always_adapt': False,\n    'initial_lr': 0.002,\n    'step': 13572,\n    'params': [107,\n     108,\n     109,\n     110,\n     111,\n     112,\n     113,\n     114,\n     115,\n     116,\n     117,\n     118,\n     119,\n     120,\n     121,\n     122,\n     123,\n     124,\n     125,\n     126,\n     127,\n     128,\n     129,\n     130,\n     131,\n     132,\n     133,\n     134,\n     135,\n     136,\n     137,\n     138,\n     139,\n     140,\n     141,\n     142,\n     143,\n     144,\n     145,\n     146,\n     147,\n     148,\n     149,\n     150,\n     151,\n     152,\n     153,\n     154,\n     155,\n     156,\n     157,\n     158,\n     159,\n     160]}]},\n 'version': 2,\n 'args': Namespace(data='Imagenet64', data_dir='Imagenet64', dataset='', train_split='train', val_split='val', dataset_download=False, class_map='', model='resnet50', pretrained=False, pretrained_path=None, initial_checkpoint='', resume='', no_resume_opt=False, num_classes=1000, gp=None, img_size=56, in_chans=None, input_size=None, crop_pct=0.95, mean=None, std=None, interpolation='', batch_size=4096, validation_batch_size=None, channels_last=False, fuser='', grad_accum_steps=1, grad_checkpointing=False, fast_norm=False, model_kwargs={}, head_init_scale=None, head_init_bias=None, torchscript=False, torchcompile=None, opt='lamb', opt_eps=None, opt_betas=None, momentum=0.9, weight_decay=0.02, clip_grad=None, clip_mode='norm', layer_decay=None, opt_kwargs={}, sched='cosine', sched_on_updates=False, lr=0.002, lr_base=0.1, lr_base_size=256, lr_base_scale='', lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_decay=0.5, lr_cycle_limit=1, lr_k_decay=1.0, warmup_lr=1e-05, min_lr=0, epochs=100, epoch_repeats=0.0, start_epoch=None, decay_milestones=[90, 180, 270], decay_epochs=90, warmup_epochs=5, warmup_prefix=False, cooldown_epochs=0, patience_epochs=10, decay_rate=0.1, no_aug=False, scale=[0.2, 1.0], ratio=[0.75, 1.3333333333333333], hflip=0.5, vflip=0.0, color_jitter=0.0, aa=None, aug_repeats=0, aug_splits=0, jsd_loss=False, bce_loss=True, bce_sum=False, bce_target_thresh=None, bce_pos_weight=None, reprob=0.0, remode='pixel', recount=1, resplit=False, mixup=0.1, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, smoothing=0.0, train_interpolation='random', drop=0.0, drop_connect=None, drop_path=None, drop_block=None, bn_momentum=None, bn_eps=None, sync_bn=False, dist_bn='reduce', split_bn=False, model_ema=False, model_ema_force_cpu=False, model_ema_decay=0.9998, seed=42, worker_seeding='all', log_interval=50, recovery_interval=0, checkpoint_hist=10, workers=32, save_images=False, amp=True, amp_dtype='float16', amp_impl='native', no_ddp_bb=False, synchronize_step=False, pin_mem=False, no_prefetcher=False, output='', experiment='', eval_metric='top1', tta=0, local_rank=0, use_multi_epochs_loader=False, log_wandb=True, prefetcher=True, distributed=False, world_size=1, rank=0, device='cuda:0'),\n 'amp_scaler': {'scale': 4194304.0,\n  'growth_factor': 2.0,\n  'backoff_factor': 0.5,\n  'growth_interval': 2000,\n  '_growth_tracker': 1572},\n 'metric': 41.02800000366211}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision.io\n",
    "\n",
    "ckpt = torch.load(\"/home/doved/Downloads/checkpoint-86.pth.tar\", map_location=\"cpu\")\n",
    "ckpt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T12:51:54.640113474Z",
     "start_time": "2024-01-06T12:51:51.537105385Z"
    }
   },
   "id": "99d9779170e3a374"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"state_dict\"].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T12:52:17.528219155Z",
     "start_time": "2024-01-06T12:52:16.957836587Z"
    }
   },
   "id": "be1227018bd1768a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "NpzFile '/home/doved/Data/Imagenet64_train/train_data_batch_1.npz' with keys: data, mean, labels"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "b = np.load(\"/home/doved/Data/Imagenet64_train/train_data_batch_1.npz\")\n",
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T07:09:13.667299362Z",
     "start_time": "2024-01-06T07:09:13.385062254Z"
    }
   },
   "id": "d7733742a3e3db8d",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img1 = b[\"data\"][10000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T07:09:25.397918978Z",
     "start_time": "2024-01-06T07:09:14.372298625Z"
    }
   },
   "id": "5d0455341498c6f3",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f678828a910>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:54:16.885856442Z",
     "start_time": "2024-01-06T06:54:16.148351051Z"
    }
   },
   "id": "4858a519923c4db3",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 128116/128116 [01:39<00:00, 1284.70it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "labels = b[\"labels\"]\n",
    "data = b[\"data\"]\n",
    "filenames = {}\n",
    "dest = Path(\"/home/doved/Data/Imagenet64/train\")\n",
    "for i in tqdm(range(len(labels))):\n",
    "    img = data[i]\n",
    "    label = labels[i] - 1\n",
    "    if label not in filenames:\n",
    "        filenames[label] = 0\n",
    "        os.mkdir(dest/f\"{label}\")\n",
    "    p = dest/f\"{label}\"/f\"{filenames[label]}.png\"\n",
    "    filenames[label] += 1\n",
    "    torchvision.io.write_png(torch.tensor(img.reshape(3, 64, 64)), str(p))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T07:18:20.844430684Z",
     "start_time": "2024-01-06T07:16:27.380184344Z"
    }
   },
   "id": "9eab518ee9eeb727",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 128116/128116 [01:46<00:00, 1207.74it/s]\n",
      "100%|| 128116/128116 [01:44<00:00, 1223.03it/s]\n",
      "100%|| 128116/128116 [01:41<00:00, 1257.11it/s]\n",
      "100%|| 128116/128116 [01:38<00:00, 1296.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in range(2, 6):\n",
    "    b = np.load(f\"/home/doved/Data/Imagenet64_train/train_data_batch_{batch}.npz\")\n",
    "    labels = b[\"labels\"]\n",
    "    data = b[\"data\"]\n",
    "    dest = Path(\"/home/doved/Data/Imagenet64/train\")\n",
    "    for i in tqdm(range(len(labels))):\n",
    "        img = data[i]\n",
    "        label = labels[i] - 1\n",
    "        if label not in filenames:\n",
    "            filenames[label] = 0\n",
    "            os.mkdir(dest/f\"{label}\")\n",
    "        p = dest/f\"{label}\"/f\"{filenames[label]}.png\"\n",
    "        filenames[label] += 1\n",
    "        torchvision.io.write_png(torch.tensor(img.reshape(3, 64, 64)), str(p))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T07:26:27.918222158Z",
     "start_time": "2024-01-06T07:18:20.927484527Z"
    }
   },
   "id": "1514f975a5e98335",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 50000/50000 [00:37<00:00, 1323.68it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "b = np.load(f\"/home/doved/Data/Imagenet64_val/val_data.npz\")\n",
    "labels = b[\"labels\"]\n",
    "data = b[\"data\"]\n",
    "val_filenames = {}\n",
    "dest = Path(\"/home/doved/Data/Imagenet64/val\")\n",
    "for i in tqdm(range(len(labels))):\n",
    "    img = data[i]\n",
    "    label = labels[i] - 1\n",
    "    if label not in val_filenames:\n",
    "        val_filenames[label] = 0\n",
    "        os.mkdir(dest/f\"{label}\")\n",
    "    p = dest/f\"{label}\"/f\"{val_filenames[label]}.png\"\n",
    "    val_filenames[label] += 1\n",
    "    torchvision.io.write_png(torch.tensor(img.reshape(3, 64, 64)), str(p))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T07:27:16.960765876Z",
     "start_time": "2024-01-06T07:26:27.926375060Z"
    }
   },
   "id": "abbcb83b5e80ba46",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 64, 64)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = img1.reshape(3, 64, 64)\n",
    "img1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:50:37.552964577Z",
     "start_time": "2024-01-06T06:50:37.069902976Z"
    }
   },
   "id": "e788601cb25a23ae",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(64, 64, 3)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = np.transpose(img1, (1, 2, 0))\n",
    "img1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:52:15.030933822Z",
     "start_time": "2024-01-06T06:52:14.669347466Z"
    }
   },
   "id": "fc3897fc60572f4f",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img1 = np.ascontiguousarray(img1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:52:38.645485693Z",
     "start_time": "2024-01-06T06:52:38.383461634Z"
    }
   },
   "id": "84e567795fb456b3",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'abcdef'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"aaabcdef\".removeprefix(\"aa\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T08:59:22.656858134Z",
     "start_time": "2024-01-04T08:59:22.406325632Z"
    }
   },
   "id": "4f867675b48d3a69",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'123'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"123.jpeg\"[:-5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T10:26:29.296074458Z",
     "start_time": "2024-01-04T10:26:29.022594246Z"
    }
   },
   "id": "911fb2c57892e220",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 14.,  16.,  39.],\n        [ 14.,  17.,  40.],\n        [ 14.,  17.,  41.],\n        ...,\n        [ 28.,  18.,  14.],\n        [ 29.,  17.,  13.],\n        [ 25.,  15.,  11.]],\n\n       [[ 13.,  17.,  39.],\n        [ 14.,  17.,  40.],\n        [ 13.,  17.,  42.],\n        ...,\n        [ 16.,   7.,   5.],\n        [ 19.,   7.,   5.],\n        [ 11.,   4.,   3.]],\n\n       [[ 14.,  16.,  39.],\n        [ 14.,  17.,  41.],\n        [ 14.,  17.,  43.],\n        ...,\n        [ 19.,   7.,   5.],\n        [ 19.,   7.,   5.],\n        [  8.,   3.,   3.]],\n\n       ...,\n\n       [[ 16.,   5.,   3.],\n        [ 19.,   6.,   4.],\n        [ 85.,  57.,  61.],\n        ...,\n        [116.,   8.,  22.],\n        [129.,  13.,  28.],\n        [140.,  17.,  33.]],\n\n       [[ 15.,   5.,   3.],\n        [ 17.,   5.,   4.],\n        [ 25.,  12.,  13.],\n        ...,\n        [131.,  16.,  31.],\n        [123.,  13.,  26.],\n        [132.,  19.,  32.]],\n\n       [[ 15.,   4.,   3.],\n        [ 17.,   4.,   3.],\n        [ 17.,   5.,   4.],\n        ...,\n        [109.,   8.,  19.],\n        [106.,   4.,  13.],\n        [118.,   7.,  19.]]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:53:19.343140834Z",
     "start_time": "2024-01-06T06:53:19.041513816Z"
    }
   },
   "id": "f1d300e7c4e51e3a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "['resnet50']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "timm.list_models(\"resnet50\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:38:41.633630500Z",
     "start_time": "2023-12-28T15:38:36.543484400Z"
    }
   },
   "id": "889b9df4bf280ee1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "resnet50 = timm.create_model(\"resnet50\")\n",
    "efficientnet_b0 = timm.create_model(\"efficientnet_b0\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:38:42.347685500Z",
     "start_time": "2023-12-28T15:38:41.639597200Z"
    }
   },
   "id": "66aa8a3baf33ba77"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "24.373085021972656"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) / 1024 / 1024\n",
    "\n",
    "count_parameters(resnet50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:19.488872Z",
     "start_time": "2023-12-28T10:43:19.475873600Z"
    }
   },
   "id": "c38ddb077a6572d5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "5.043552398681641"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(efficientnet_b0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:19.562905400Z",
     "start_time": "2023-12-28T10:43:19.489870500Z"
    }
   },
   "id": "f17f24f07ec7178b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(12, 3, 224, 224)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:38:42.347685500Z",
     "start_time": "2023-12-28T15:38:42.059690100Z"
    }
   },
   "id": "d55a864e50c9eb57"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927 ms  19 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit resnet50(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:27.346869Z",
     "start_time": "2023-12-28T10:43:19.536869700Z"
    }
   },
   "id": "462d84c5248568d3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "efficientnet_v2 = timm.create_model(\"efficientnetv2_s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:27.750871500Z",
     "start_time": "2023-12-28T10:43:27.348872500Z"
    }
   },
   "id": "60928451764ed32a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "20.46440887451172"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(efficientnet_v2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:27.768882500Z",
     "start_time": "2023-12-28T10:43:27.754873300Z"
    }
   },
   "id": "de27b3a492232949"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22 s  28.5 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit efficientnet_v2(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:37.745914Z",
     "start_time": "2023-12-28T10:43:27.770873800Z"
    }
   },
   "id": "9d54053da6f776b8"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "8.687967300415039"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_b2 = timm.create_model(\"efficientnet_b2\")\n",
    "count_parameters(efficientnet_b2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:37.989905100Z",
     "start_time": "2023-12-28T10:43:37.748905700Z"
    }
   },
   "id": "28328e00e90edf95"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839 ms  27.3 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit efficientnet_b2(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:44.751420800Z",
     "start_time": "2023-12-28T10:43:37.976905100Z"
    }
   },
   "id": "f3f33a50a5da8172"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:52.528613600Z",
     "start_time": "2023-12-28T10:43:52.497573600Z"
    }
   },
   "id": "452c0fb3bbb399f1"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['T_destination',\n '__annotations__',\n '__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattr__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_apply',\n '_backward_hooks',\n '_backward_pre_hooks',\n '_buffers',\n '_call_impl',\n '_compiled_call_impl',\n '_forward_hooks',\n '_forward_hooks_always_called',\n '_forward_hooks_with_kwargs',\n '_forward_pre_hooks',\n '_forward_pre_hooks_with_kwargs',\n '_get_backward_hooks',\n '_get_backward_pre_hooks',\n '_get_name',\n '_is_full_backward_hook',\n '_load_from_state_dict',\n '_load_state_dict_post_hooks',\n '_load_state_dict_pre_hooks',\n '_maybe_warn_non_full_backward_hook',\n '_modules',\n '_named_members',\n '_non_persistent_buffers_set',\n '_parameters',\n '_register_load_state_dict_pre_hook',\n '_register_state_dict_hook',\n '_replicate_for_data_parallel',\n '_save_to_state_dict',\n '_slow_forward',\n '_state_dict_hooks',\n '_state_dict_pre_hooks',\n '_version',\n '_wrapped_call_impl',\n 'act1',\n 'add_module',\n 'apply',\n 'bfloat16',\n 'bn1',\n 'buffers',\n 'call_super_init',\n 'children',\n 'compile',\n 'conv1',\n 'cpu',\n 'cuda',\n 'default_cfg',\n 'double',\n 'drop_rate',\n 'dump_patches',\n 'eval',\n 'extra_repr',\n 'fc',\n 'feature_info',\n 'float',\n 'forward',\n 'forward_features',\n 'forward_head',\n 'get_buffer',\n 'get_classifier',\n 'get_extra_state',\n 'get_parameter',\n 'get_submodule',\n 'global_pool',\n 'grad_checkpointing',\n 'group_matcher',\n 'half',\n 'init_weights',\n 'ipu',\n 'layer1',\n 'layer2',\n 'layer3',\n 'layer4',\n 'load_state_dict',\n 'maxpool',\n 'modules',\n 'named_buffers',\n 'named_children',\n 'named_modules',\n 'named_parameters',\n 'num_classes',\n 'num_features',\n 'parameters',\n 'pretrained_cfg',\n 'register_backward_hook',\n 'register_buffer',\n 'register_forward_hook',\n 'register_forward_pre_hook',\n 'register_full_backward_hook',\n 'register_full_backward_pre_hook',\n 'register_load_state_dict_post_hook',\n 'register_module',\n 'register_parameter',\n 'register_state_dict_pre_hook',\n 'requires_grad_',\n 'reset_classifier',\n 'set_extra_state',\n 'set_grad_checkpointing',\n 'share_memory',\n 'state_dict',\n 'to',\n 'to_empty',\n 'train',\n 'training',\n 'type',\n 'xpu',\n 'zero_grad']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(resnet50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:44:10.274677800Z",
     "start_time": "2023-12-28T10:44:10.151648900Z"
    }
   },
   "id": "86a345dfa58b7f6e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['conv1.weight',\n 'bn1.weight',\n 'bn1.bias',\n 'layer1.0.conv1.weight',\n 'layer1.0.bn1.weight',\n 'layer1.0.bn1.bias',\n 'layer1.0.conv2.weight',\n 'layer1.0.bn2.weight',\n 'layer1.0.bn2.bias',\n 'layer1.0.conv3.weight',\n 'layer1.0.bn3.weight',\n 'layer1.0.bn3.bias',\n 'layer1.0.downsample.0.weight',\n 'layer1.0.downsample.1.weight',\n 'layer1.0.downsample.1.bias',\n 'layer1.1.conv1.weight',\n 'layer1.1.bn1.weight',\n 'layer1.1.bn1.bias',\n 'layer1.1.conv2.weight',\n 'layer1.1.bn2.weight',\n 'layer1.1.bn2.bias',\n 'layer1.1.conv3.weight',\n 'layer1.1.bn3.weight',\n 'layer1.1.bn3.bias',\n 'layer1.2.conv1.weight',\n 'layer1.2.bn1.weight',\n 'layer1.2.bn1.bias',\n 'layer1.2.conv2.weight',\n 'layer1.2.bn2.weight',\n 'layer1.2.bn2.bias',\n 'layer1.2.conv3.weight',\n 'layer1.2.bn3.weight',\n 'layer1.2.bn3.bias',\n 'layer2.0.conv1.weight',\n 'layer2.0.bn1.weight',\n 'layer2.0.bn1.bias',\n 'layer2.0.conv2.weight',\n 'layer2.0.bn2.weight',\n 'layer2.0.bn2.bias',\n 'layer2.0.conv3.weight',\n 'layer2.0.bn3.weight',\n 'layer2.0.bn3.bias',\n 'layer2.0.downsample.0.weight',\n 'layer2.0.downsample.1.weight',\n 'layer2.0.downsample.1.bias',\n 'layer2.1.conv1.weight',\n 'layer2.1.bn1.weight',\n 'layer2.1.bn1.bias',\n 'layer2.1.conv2.weight',\n 'layer2.1.bn2.weight',\n 'layer2.1.bn2.bias',\n 'layer2.1.conv3.weight',\n 'layer2.1.bn3.weight',\n 'layer2.1.bn3.bias',\n 'layer2.2.conv1.weight',\n 'layer2.2.bn1.weight',\n 'layer2.2.bn1.bias',\n 'layer2.2.conv2.weight',\n 'layer2.2.bn2.weight',\n 'layer2.2.bn2.bias',\n 'layer2.2.conv3.weight',\n 'layer2.2.bn3.weight',\n 'layer2.2.bn3.bias',\n 'layer2.3.conv1.weight',\n 'layer2.3.bn1.weight',\n 'layer2.3.bn1.bias',\n 'layer2.3.conv2.weight',\n 'layer2.3.bn2.weight',\n 'layer2.3.bn2.bias',\n 'layer2.3.conv3.weight',\n 'layer2.3.bn3.weight',\n 'layer2.3.bn3.bias',\n 'layer3.0.conv1.weight',\n 'layer3.0.bn1.weight',\n 'layer3.0.bn1.bias',\n 'layer3.0.conv2.weight',\n 'layer3.0.bn2.weight',\n 'layer3.0.bn2.bias',\n 'layer3.0.conv3.weight',\n 'layer3.0.bn3.weight',\n 'layer3.0.bn3.bias',\n 'layer3.0.downsample.0.weight',\n 'layer3.0.downsample.1.weight',\n 'layer3.0.downsample.1.bias',\n 'layer3.1.conv1.weight',\n 'layer3.1.bn1.weight',\n 'layer3.1.bn1.bias',\n 'layer3.1.conv2.weight',\n 'layer3.1.bn2.weight',\n 'layer3.1.bn2.bias',\n 'layer3.1.conv3.weight',\n 'layer3.1.bn3.weight',\n 'layer3.1.bn3.bias',\n 'layer3.2.conv1.weight',\n 'layer3.2.bn1.weight',\n 'layer3.2.bn1.bias',\n 'layer3.2.conv2.weight',\n 'layer3.2.bn2.weight',\n 'layer3.2.bn2.bias',\n 'layer3.2.conv3.weight',\n 'layer3.2.bn3.weight',\n 'layer3.2.bn3.bias',\n 'layer3.3.conv1.weight',\n 'layer3.3.bn1.weight',\n 'layer3.3.bn1.bias',\n 'layer3.3.conv2.weight',\n 'layer3.3.bn2.weight',\n 'layer3.3.bn2.bias',\n 'layer3.3.conv3.weight',\n 'layer3.3.bn3.weight',\n 'layer3.3.bn3.bias',\n 'layer3.4.conv1.weight',\n 'layer3.4.bn1.weight',\n 'layer3.4.bn1.bias',\n 'layer3.4.conv2.weight',\n 'layer3.4.bn2.weight',\n 'layer3.4.bn2.bias',\n 'layer3.4.conv3.weight',\n 'layer3.4.bn3.weight',\n 'layer3.4.bn3.bias',\n 'layer3.5.conv1.weight',\n 'layer3.5.bn1.weight',\n 'layer3.5.bn1.bias',\n 'layer3.5.conv2.weight',\n 'layer3.5.bn2.weight',\n 'layer3.5.bn2.bias',\n 'layer3.5.conv3.weight',\n 'layer3.5.bn3.weight',\n 'layer3.5.bn3.bias',\n 'layer4.0.conv1.weight',\n 'layer4.0.bn1.weight',\n 'layer4.0.bn1.bias',\n 'layer4.0.conv2.weight',\n 'layer4.0.bn2.weight',\n 'layer4.0.bn2.bias',\n 'layer4.0.conv3.weight',\n 'layer4.0.bn3.weight',\n 'layer4.0.bn3.bias',\n 'layer4.0.downsample.0.weight',\n 'layer4.0.downsample.1.weight',\n 'layer4.0.downsample.1.bias',\n 'layer4.1.conv1.weight',\n 'layer4.1.bn1.weight',\n 'layer4.1.bn1.bias',\n 'layer4.1.conv2.weight',\n 'layer4.1.bn2.weight',\n 'layer4.1.bn2.bias',\n 'layer4.1.conv3.weight',\n 'layer4.1.bn3.weight',\n 'layer4.1.bn3.bias',\n 'layer4.2.conv1.weight',\n 'layer4.2.bn1.weight',\n 'layer4.2.bn1.bias',\n 'layer4.2.conv2.weight',\n 'layer4.2.bn2.weight',\n 'layer4.2.bn2.bias',\n 'layer4.2.conv3.weight',\n 'layer4.2.bn3.weight',\n 'layer4.2.bn3.bias',\n 'fc.weight',\n 'fc.bias']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in resnet50.named_parameters()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T11:04:18.949743400Z",
     "start_time": "2023-12-28T11:04:18.827744600Z"
    }
   },
   "id": "bc2688a6216df11c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['H',\n 'T',\n '__abs__',\n '__add__',\n '__and__',\n '__array__',\n '__array_priority__',\n '__array_wrap__',\n '__bool__',\n '__class__',\n '__complex__',\n '__contains__',\n '__deepcopy__',\n '__delattr__',\n '__delitem__',\n '__dict__',\n '__dir__',\n '__div__',\n '__dlpack__',\n '__dlpack_device__',\n '__doc__',\n '__eq__',\n '__float__',\n '__floordiv__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__iand__',\n '__idiv__',\n '__ifloordiv__',\n '__ilshift__',\n '__imod__',\n '__imul__',\n '__index__',\n '__init__',\n '__init_subclass__',\n '__int__',\n '__invert__',\n '__ior__',\n '__ipow__',\n '__irshift__',\n '__isub__',\n '__iter__',\n '__itruediv__',\n '__ixor__',\n '__le__',\n '__len__',\n '__long__',\n '__lshift__',\n '__lt__',\n '__matmul__',\n '__mod__',\n '__module__',\n '__mul__',\n '__ne__',\n '__neg__',\n '__new__',\n '__nonzero__',\n '__or__',\n '__pos__',\n '__pow__',\n '__radd__',\n '__rand__',\n '__rdiv__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rfloordiv__',\n '__rlshift__',\n '__rmatmul__',\n '__rmod__',\n '__rmul__',\n '__ror__',\n '__rpow__',\n '__rrshift__',\n '__rshift__',\n '__rsub__',\n '__rtruediv__',\n '__rxor__',\n '__setattr__',\n '__setitem__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__sub__',\n '__subclasshook__',\n '__torch_dispatch__',\n '__torch_function__',\n '__truediv__',\n '__weakref__',\n '__xor__',\n '_addmm_activation',\n '_autocast_to_full_precision',\n '_autocast_to_reduced_precision',\n '_backward_hooks',\n '_base',\n '_cdata',\n '_coalesced_',\n '_conj',\n '_conj_physical',\n '_dimI',\n '_dimV',\n '_fix_weakref',\n '_grad',\n '_grad_fn',\n '_has_symbolic_sizes_strides',\n '_indices',\n '_is_all_true',\n '_is_any_true',\n '_is_view',\n '_is_zerotensor',\n '_make_subclass',\n '_make_wrapper_subclass',\n '_neg_view',\n '_nested_tensor_size',\n '_nested_tensor_storage_offsets',\n '_nested_tensor_strides',\n '_nnz',\n '_post_accumulate_grad_hooks',\n '_python_dispatch',\n '_reduce_ex_internal',\n '_sparse_mask_projection',\n '_to_dense',\n '_to_sparse',\n '_to_sparse_bsc',\n '_to_sparse_bsr',\n '_to_sparse_csc',\n '_to_sparse_csr',\n '_typed_storage',\n '_update_names',\n '_values',\n '_version',\n '_view_func',\n 'abs',\n 'abs_',\n 'absolute',\n 'absolute_',\n 'acos',\n 'acos_',\n 'acosh',\n 'acosh_',\n 'add',\n 'add_',\n 'addbmm',\n 'addbmm_',\n 'addcdiv',\n 'addcdiv_',\n 'addcmul',\n 'addcmul_',\n 'addmm',\n 'addmm_',\n 'addmv',\n 'addmv_',\n 'addr',\n 'addr_',\n 'adjoint',\n 'align_as',\n 'align_to',\n 'all',\n 'allclose',\n 'amax',\n 'amin',\n 'aminmax',\n 'angle',\n 'any',\n 'apply_',\n 'arccos',\n 'arccos_',\n 'arccosh',\n 'arccosh_',\n 'arcsin',\n 'arcsin_',\n 'arcsinh',\n 'arcsinh_',\n 'arctan',\n 'arctan2',\n 'arctan2_',\n 'arctan_',\n 'arctanh',\n 'arctanh_',\n 'argmax',\n 'argmin',\n 'argsort',\n 'argwhere',\n 'as_strided',\n 'as_strided_',\n 'as_strided_scatter',\n 'as_subclass',\n 'asin',\n 'asin_',\n 'asinh',\n 'asinh_',\n 'atan',\n 'atan2',\n 'atan2_',\n 'atan_',\n 'atanh',\n 'atanh_',\n 'backward',\n 'baddbmm',\n 'baddbmm_',\n 'bernoulli',\n 'bernoulli_',\n 'bfloat16',\n 'bincount',\n 'bitwise_and',\n 'bitwise_and_',\n 'bitwise_left_shift',\n 'bitwise_left_shift_',\n 'bitwise_not',\n 'bitwise_not_',\n 'bitwise_or',\n 'bitwise_or_',\n 'bitwise_right_shift',\n 'bitwise_right_shift_',\n 'bitwise_xor',\n 'bitwise_xor_',\n 'bmm',\n 'bool',\n 'broadcast_to',\n 'byte',\n 'cauchy_',\n 'ccol_indices',\n 'cdouble',\n 'ceil',\n 'ceil_',\n 'cfloat',\n 'chalf',\n 'char',\n 'cholesky',\n 'cholesky_inverse',\n 'cholesky_solve',\n 'chunk',\n 'clamp',\n 'clamp_',\n 'clamp_max',\n 'clamp_max_',\n 'clamp_min',\n 'clamp_min_',\n 'clip',\n 'clip_',\n 'clone',\n 'coalesce',\n 'col_indices',\n 'conj',\n 'conj_physical',\n 'conj_physical_',\n 'contiguous',\n 'copy_',\n 'copysign',\n 'copysign_',\n 'corrcoef',\n 'cos',\n 'cos_',\n 'cosh',\n 'cosh_',\n 'count_nonzero',\n 'cov',\n 'cpu',\n 'cross',\n 'crow_indices',\n 'cuda',\n 'cummax',\n 'cummin',\n 'cumprod',\n 'cumprod_',\n 'cumsum',\n 'cumsum_',\n 'data',\n 'data_ptr',\n 'deg2rad',\n 'deg2rad_',\n 'dense_dim',\n 'dequantize',\n 'det',\n 'detach',\n 'detach_',\n 'device',\n 'diag',\n 'diag_embed',\n 'diagflat',\n 'diagonal',\n 'diagonal_scatter',\n 'diff',\n 'digamma',\n 'digamma_',\n 'dim',\n 'dim_order',\n 'dist',\n 'div',\n 'div_',\n 'divide',\n 'divide_',\n 'dot',\n 'double',\n 'dsplit',\n 'dtype',\n 'eig',\n 'element_size',\n 'eq',\n 'eq_',\n 'equal',\n 'erf',\n 'erf_',\n 'erfc',\n 'erfc_',\n 'erfinv',\n 'erfinv_',\n 'exp',\n 'exp2',\n 'exp2_',\n 'exp_',\n 'expand',\n 'expand_as',\n 'expm1',\n 'expm1_',\n 'exponential_',\n 'fill_',\n 'fill_diagonal_',\n 'fix',\n 'fix_',\n 'flatten',\n 'flip',\n 'fliplr',\n 'flipud',\n 'float',\n 'float_power',\n 'float_power_',\n 'floor',\n 'floor_',\n 'floor_divide',\n 'floor_divide_',\n 'fmax',\n 'fmin',\n 'fmod',\n 'fmod_',\n 'frac',\n 'frac_',\n 'frexp',\n 'gather',\n 'gcd',\n 'gcd_',\n 'ge',\n 'ge_',\n 'geometric_',\n 'geqrf',\n 'ger',\n 'get_device',\n 'grad',\n 'grad_fn',\n 'greater',\n 'greater_',\n 'greater_equal',\n 'greater_equal_',\n 'gt',\n 'gt_',\n 'half',\n 'hardshrink',\n 'has_names',\n 'heaviside',\n 'heaviside_',\n 'histc',\n 'histogram',\n 'hsplit',\n 'hypot',\n 'hypot_',\n 'i0',\n 'i0_',\n 'igamma',\n 'igamma_',\n 'igammac',\n 'igammac_',\n 'imag',\n 'index_add',\n 'index_add_',\n 'index_copy',\n 'index_copy_',\n 'index_fill',\n 'index_fill_',\n 'index_put',\n 'index_put_',\n 'index_reduce',\n 'index_reduce_',\n 'index_select',\n 'indices',\n 'inner',\n 'int',\n 'int_repr',\n 'inverse',\n 'ipu',\n 'is_coalesced',\n 'is_complex',\n 'is_conj',\n 'is_contiguous',\n 'is_cpu',\n 'is_cuda',\n 'is_distributed',\n 'is_floating_point',\n 'is_inference',\n 'is_ipu',\n 'is_leaf',\n 'is_meta',\n 'is_mkldnn',\n 'is_mps',\n 'is_neg',\n 'is_nested',\n 'is_nonzero',\n 'is_ort',\n 'is_pinned',\n 'is_quantized',\n 'is_same_size',\n 'is_set_to',\n 'is_shared',\n 'is_signed',\n 'is_sparse',\n 'is_sparse_csr',\n 'is_vulkan',\n 'is_xla',\n 'is_xpu',\n 'isclose',\n 'isfinite',\n 'isinf',\n 'isnan',\n 'isneginf',\n 'isposinf',\n 'isreal',\n 'istft',\n 'item',\n 'itemsize',\n 'kron',\n 'kthvalue',\n 'layout',\n 'lcm',\n 'lcm_',\n 'ldexp',\n 'ldexp_',\n 'le',\n 'le_',\n 'lerp',\n 'lerp_',\n 'less',\n 'less_',\n 'less_equal',\n 'less_equal_',\n 'lgamma',\n 'lgamma_',\n 'log',\n 'log10',\n 'log10_',\n 'log1p',\n 'log1p_',\n 'log2',\n 'log2_',\n 'log_',\n 'log_normal_',\n 'log_softmax',\n 'logaddexp',\n 'logaddexp2',\n 'logcumsumexp',\n 'logdet',\n 'logical_and',\n 'logical_and_',\n 'logical_not',\n 'logical_not_',\n 'logical_or',\n 'logical_or_',\n 'logical_xor',\n 'logical_xor_',\n 'logit',\n 'logit_',\n 'logsumexp',\n 'long',\n 'lstsq',\n 'lt',\n 'lt_',\n 'lu',\n 'lu_solve',\n 'mH',\n 'mT',\n 'map2_',\n 'map_',\n 'masked_fill',\n 'masked_fill_',\n 'masked_scatter',\n 'masked_scatter_',\n 'masked_select',\n 'matmul',\n 'matrix_exp',\n 'matrix_power',\n 'max',\n 'maximum',\n 'mean',\n 'median',\n 'min',\n 'minimum',\n 'mm',\n 'mode',\n 'moveaxis',\n 'movedim',\n 'msort',\n 'mul',\n 'mul_',\n 'multinomial',\n 'multiply',\n 'multiply_',\n 'mv',\n 'mvlgamma',\n 'mvlgamma_',\n 'name',\n 'names',\n 'nan_to_num',\n 'nan_to_num_',\n 'nanmean',\n 'nanmedian',\n 'nanquantile',\n 'nansum',\n 'narrow',\n 'narrow_copy',\n 'nbytes',\n 'ndim',\n 'ndimension',\n 'ne',\n 'ne_',\n 'neg',\n 'neg_',\n 'negative',\n 'negative_',\n 'nelement',\n 'new',\n 'new_empty',\n 'new_empty_strided',\n 'new_full',\n 'new_ones',\n 'new_tensor',\n 'new_zeros',\n 'nextafter',\n 'nextafter_',\n 'nonzero',\n 'nonzero_static',\n 'norm',\n 'normal_',\n 'not_equal',\n 'not_equal_',\n 'numel',\n 'numpy',\n 'orgqr',\n 'ormqr',\n 'outer',\n 'output_nr',\n 'permute',\n 'pin_memory',\n 'pinverse',\n 'polygamma',\n 'polygamma_',\n 'positive',\n 'pow',\n 'pow_',\n 'prelu',\n 'prod',\n 'put',\n 'put_',\n 'q_per_channel_axis',\n 'q_per_channel_scales',\n 'q_per_channel_zero_points',\n 'q_scale',\n 'q_zero_point',\n 'qr',\n 'qscheme',\n 'quantile',\n 'rad2deg',\n 'rad2deg_',\n 'random_',\n 'ravel',\n 'real',\n 'reciprocal',\n 'reciprocal_',\n 'record_stream',\n 'refine_names',\n 'register_hook',\n 'register_post_accumulate_grad_hook',\n 'reinforce',\n 'relu',\n 'relu_',\n 'remainder',\n 'remainder_',\n 'rename',\n 'rename_',\n 'renorm',\n 'renorm_',\n 'repeat',\n 'repeat_interleave',\n 'requires_grad',\n 'requires_grad_',\n 'reshape',\n 'reshape_as',\n 'resize',\n 'resize_',\n 'resize_as',\n 'resize_as_',\n 'resize_as_sparse_',\n 'resolve_conj',\n 'resolve_neg',\n 'retain_grad',\n 'retains_grad',\n 'roll',\n 'rot90',\n 'round',\n 'round_',\n 'row_indices',\n 'rsqrt',\n 'rsqrt_',\n 'scatter',\n 'scatter_',\n 'scatter_add',\n 'scatter_add_',\n 'scatter_reduce',\n 'scatter_reduce_',\n 'select',\n 'select_scatter',\n 'set_',\n 'sgn',\n 'sgn_',\n 'shape',\n 'share_memory_',\n 'short',\n 'sigmoid',\n 'sigmoid_',\n 'sign',\n 'sign_',\n 'signbit',\n 'sin',\n 'sin_',\n 'sinc',\n 'sinc_',\n 'sinh',\n 'sinh_',\n 'size',\n 'slice_scatter',\n 'slogdet',\n 'smm',\n 'softmax',\n 'solve',\n 'sort',\n 'sparse_dim',\n 'sparse_mask',\n 'sparse_resize_',\n 'sparse_resize_and_clear_',\n 'split',\n 'split_with_sizes',\n 'sqrt',\n 'sqrt_',\n 'square',\n 'square_',\n 'squeeze',\n 'squeeze_',\n 'sspaddmm',\n 'std',\n 'stft',\n 'storage',\n 'storage_offset',\n 'storage_type',\n 'stride',\n 'sub',\n 'sub_',\n 'subtract',\n 'subtract_',\n 'sum',\n 'sum_to_size',\n 'svd',\n 'swapaxes',\n 'swapaxes_',\n 'swapdims',\n 'swapdims_',\n 'symeig',\n 't',\n 't_',\n 'take',\n 'take_along_dim',\n 'tan',\n 'tan_',\n 'tanh',\n 'tanh_',\n 'tensor_split',\n 'tile',\n 'to',\n 'to_dense',\n 'to_mkldnn',\n 'to_padded_tensor',\n 'to_sparse',\n 'to_sparse_bsc',\n 'to_sparse_bsr',\n 'to_sparse_coo',\n 'to_sparse_csc',\n 'to_sparse_csr',\n 'tolist',\n 'topk',\n 'trace',\n 'transpose',\n 'transpose_',\n 'triangular_solve',\n 'tril',\n 'tril_',\n 'triu',\n 'triu_',\n 'true_divide',\n 'true_divide_',\n 'trunc',\n 'trunc_',\n 'type',\n 'type_as',\n 'unbind',\n 'unflatten',\n 'unfold',\n 'uniform_',\n 'unique',\n 'unique_consecutive',\n 'unsafe_chunk',\n 'unsafe_split',\n 'unsafe_split_with_sizes',\n 'unsqueeze',\n 'unsqueeze_',\n 'untyped_storage',\n 'values',\n 'var',\n 'vdot',\n 'view',\n 'view_as',\n 'vsplit',\n 'where',\n 'xlogy',\n 'xlogy_',\n 'xpu',\n 'zero_']"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(next(resnet50.named_parameters())[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T11:05:54.236405500Z",
     "start_time": "2023-12-28T11:05:54.006430900Z"
    }
   },
   "id": "f2c3e1b5b834317"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 10])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((10, 10))\n",
    "a[:5].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T18:05:34.980586Z",
     "start_time": "2023-12-28T18:05:33.924508200Z"
    }
   },
   "id": "bcdfa5eeb76ae993"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12, 2048, 7, 7])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = resnet50.forward_features(x)\n",
    "x1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:14:09.087456Z",
     "start_time": "2023-12-28T13:14:07.941931200Z"
    }
   },
   "id": "75abe02f8fe1eced"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12, 2048])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.global_pool(x1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:14:15.630462800Z",
     "start_time": "2023-12-28T13:14:15.394465400Z"
    }
   },
   "id": "d0e6cf75fc0b1f41"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "2048"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.num_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:15:37.774278300Z",
     "start_time": "2023-12-28T13:15:37.666562600Z"
    }
   },
   "id": "2b0678883d27eb7b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['conv1.weight',\n 'bn1.weight',\n 'bn1.bias',\n 'layer1.0.conv1.weight',\n 'layer1.0.bn1.weight',\n 'layer1.0.bn1.bias',\n 'layer1.0.conv2.weight',\n 'layer1.0.bn2.weight',\n 'layer1.0.bn2.bias',\n 'layer1.0.conv3.weight',\n 'layer1.0.bn3.weight',\n 'layer1.0.bn3.bias',\n 'layer1.0.downsample.0.weight',\n 'layer1.0.downsample.1.weight',\n 'layer1.0.downsample.1.bias',\n 'layer1.1.conv1.weight',\n 'layer1.1.bn1.weight',\n 'layer1.1.bn1.bias',\n 'layer1.1.conv2.weight',\n 'layer1.1.bn2.weight',\n 'layer1.1.bn2.bias',\n 'layer1.1.conv3.weight',\n 'layer1.1.bn3.weight',\n 'layer1.1.bn3.bias',\n 'layer1.2.conv1.weight',\n 'layer1.2.bn1.weight',\n 'layer1.2.bn1.bias',\n 'layer1.2.conv2.weight',\n 'layer1.2.bn2.weight',\n 'layer1.2.bn2.bias',\n 'layer1.2.conv3.weight',\n 'layer1.2.bn3.weight',\n 'layer1.2.bn3.bias',\n 'layer2.0.conv1.weight',\n 'layer2.0.bn1.weight',\n 'layer2.0.bn1.bias',\n 'layer2.0.conv2.weight',\n 'layer2.0.bn2.weight',\n 'layer2.0.bn2.bias',\n 'layer2.0.conv3.weight',\n 'layer2.0.bn3.weight',\n 'layer2.0.bn3.bias',\n 'layer2.0.downsample.0.weight',\n 'layer2.0.downsample.1.weight',\n 'layer2.0.downsample.1.bias',\n 'layer2.1.conv1.weight',\n 'layer2.1.bn1.weight',\n 'layer2.1.bn1.bias',\n 'layer2.1.conv2.weight',\n 'layer2.1.bn2.weight',\n 'layer2.1.bn2.bias',\n 'layer2.1.conv3.weight',\n 'layer2.1.bn3.weight',\n 'layer2.1.bn3.bias',\n 'layer2.2.conv1.weight',\n 'layer2.2.bn1.weight',\n 'layer2.2.bn1.bias',\n 'layer2.2.conv2.weight',\n 'layer2.2.bn2.weight',\n 'layer2.2.bn2.bias',\n 'layer2.2.conv3.weight',\n 'layer2.2.bn3.weight',\n 'layer2.2.bn3.bias',\n 'layer2.3.conv1.weight',\n 'layer2.3.bn1.weight',\n 'layer2.3.bn1.bias',\n 'layer2.3.conv2.weight',\n 'layer2.3.bn2.weight',\n 'layer2.3.bn2.bias',\n 'layer2.3.conv3.weight',\n 'layer2.3.bn3.weight',\n 'layer2.3.bn3.bias',\n 'layer3.0.conv1.weight',\n 'layer3.0.bn1.weight',\n 'layer3.0.bn1.bias',\n 'layer3.0.conv2.weight',\n 'layer3.0.bn2.weight',\n 'layer3.0.bn2.bias',\n 'layer3.0.conv3.weight',\n 'layer3.0.bn3.weight',\n 'layer3.0.bn3.bias',\n 'layer3.0.downsample.0.weight',\n 'layer3.0.downsample.1.weight',\n 'layer3.0.downsample.1.bias',\n 'layer3.1.conv1.weight',\n 'layer3.1.bn1.weight',\n 'layer3.1.bn1.bias',\n 'layer3.1.conv2.weight',\n 'layer3.1.bn2.weight',\n 'layer3.1.bn2.bias',\n 'layer3.1.conv3.weight',\n 'layer3.1.bn3.weight',\n 'layer3.1.bn3.bias',\n 'layer3.2.conv1.weight',\n 'layer3.2.bn1.weight',\n 'layer3.2.bn1.bias',\n 'layer3.2.conv2.weight',\n 'layer3.2.bn2.weight',\n 'layer3.2.bn2.bias',\n 'layer3.2.conv3.weight',\n 'layer3.2.bn3.weight',\n 'layer3.2.bn3.bias',\n 'layer3.3.conv1.weight',\n 'layer3.3.bn1.weight',\n 'layer3.3.bn1.bias',\n 'layer3.3.conv2.weight',\n 'layer3.3.bn2.weight',\n 'layer3.3.bn2.bias',\n 'layer3.3.conv3.weight',\n 'layer3.3.bn3.weight',\n 'layer3.3.bn3.bias',\n 'layer3.4.conv1.weight',\n 'layer3.4.bn1.weight',\n 'layer3.4.bn1.bias',\n 'layer3.4.conv2.weight',\n 'layer3.4.bn2.weight',\n 'layer3.4.bn2.bias',\n 'layer3.4.conv3.weight',\n 'layer3.4.bn3.weight',\n 'layer3.4.bn3.bias',\n 'layer3.5.conv1.weight',\n 'layer3.5.bn1.weight',\n 'layer3.5.bn1.bias',\n 'layer3.5.conv2.weight',\n 'layer3.5.bn2.weight',\n 'layer3.5.bn2.bias',\n 'layer3.5.conv3.weight',\n 'layer3.5.bn3.weight',\n 'layer3.5.bn3.bias',\n 'layer4.0.conv1.weight',\n 'layer4.0.bn1.weight',\n 'layer4.0.bn1.bias',\n 'layer4.0.conv2.weight',\n 'layer4.0.bn2.weight',\n 'layer4.0.bn2.bias',\n 'layer4.0.conv3.weight',\n 'layer4.0.bn3.weight',\n 'layer4.0.bn3.bias',\n 'layer4.0.downsample.0.weight',\n 'layer4.0.downsample.1.weight',\n 'layer4.0.downsample.1.bias',\n 'layer4.1.conv1.weight',\n 'layer4.1.bn1.weight',\n 'layer4.1.bn1.bias',\n 'layer4.1.conv2.weight',\n 'layer4.1.bn2.weight',\n 'layer4.1.bn2.bias',\n 'layer4.1.conv3.weight',\n 'layer4.1.bn3.weight',\n 'layer4.1.bn3.bias',\n 'layer4.2.conv1.weight',\n 'layer4.2.bn1.weight',\n 'layer4.2.bn1.bias',\n 'layer4.2.conv2.weight',\n 'layer4.2.bn2.weight',\n 'layer4.2.bn2.bias',\n 'layer4.2.conv3.weight',\n 'layer4.2.bn3.weight',\n 'layer4.2.bn3.bias',\n 'fc.weight',\n 'fc.bias']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m, k in resnet50.named_parameters()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T14:31:39.288373100Z",
     "start_time": "2023-12-28T14:31:38.837268300Z"
    }
   },
   "id": "3585eabc1e883d38"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[('',\n  ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n  )),\n ('conv1',\n  Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)),\n ('bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('act1', ReLU(inplace=True)),\n ('maxpool',\n  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)),\n ('layer1',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer1.0',\n  Bottleneck(\n    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer1.0.conv1',\n  Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.act1', ReLU(inplace=True)),\n ('layer1.0.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.0.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.drop_block', Identity()),\n ('layer1.0.act2', ReLU(inplace=True)),\n ('layer1.0.aa', Identity()),\n ('layer1.0.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.act3', ReLU(inplace=True)),\n ('layer1.0.downsample',\n  Sequential(\n    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer1.0.downsample.0',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.downsample.1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1',\n  Bottleneck(\n    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer1.1.conv1',\n  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.1.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.act1', ReLU(inplace=True)),\n ('layer1.1.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.1.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.drop_block', Identity()),\n ('layer1.1.act2', ReLU(inplace=True)),\n ('layer1.1.aa', Identity()),\n ('layer1.1.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.1.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.act3', ReLU(inplace=True)),\n ('layer1.2',\n  Bottleneck(\n    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer1.2.conv1',\n  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.2.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.act1', ReLU(inplace=True)),\n ('layer1.2.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.2.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.drop_block', Identity()),\n ('layer1.2.act2', ReLU(inplace=True)),\n ('layer1.2.aa', Identity()),\n ('layer1.2.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.2.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.act3', ReLU(inplace=True)),\n ('layer2',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer2.0',\n  Bottleneck(\n    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer2.0.conv1',\n  Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.0.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.act1', ReLU(inplace=True)),\n ('layer2.0.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer2.0.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.drop_block', Identity()),\n ('layer2.0.act2', ReLU(inplace=True)),\n ('layer2.0.aa', Identity()),\n ('layer2.0.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.0.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.act3', ReLU(inplace=True)),\n ('layer2.0.downsample',\n  Sequential(\n    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer2.0.downsample.0',\n  Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer2.0.downsample.1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.1.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.1.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.act1', ReLU(inplace=True)),\n ('layer2.1.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.1.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.drop_block', Identity()),\n ('layer2.1.act2', ReLU(inplace=True)),\n ('layer2.1.aa', Identity()),\n ('layer2.1.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.1.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.act3', ReLU(inplace=True)),\n ('layer2.2',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.2.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.2.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.act1', ReLU(inplace=True)),\n ('layer2.2.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.2.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.drop_block', Identity()),\n ('layer2.2.act2', ReLU(inplace=True)),\n ('layer2.2.aa', Identity()),\n ('layer2.2.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.2.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.act3', ReLU(inplace=True)),\n ('layer2.3',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.3.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.3.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.act1', ReLU(inplace=True)),\n ('layer2.3.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.3.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.drop_block', Identity()),\n ('layer2.3.act2', ReLU(inplace=True)),\n ('layer2.3.aa', Identity()),\n ('layer2.3.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.3.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.act3', ReLU(inplace=True)),\n ('layer3',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer3.0',\n  Bottleneck(\n    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer3.0.conv1',\n  Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.0.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.act1', ReLU(inplace=True)),\n ('layer3.0.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer3.0.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.drop_block', Identity()),\n ('layer3.0.act2', ReLU(inplace=True)),\n ('layer3.0.aa', Identity()),\n ('layer3.0.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.0.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.act3', ReLU(inplace=True)),\n ('layer3.0.downsample',\n  Sequential(\n    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer3.0.downsample.0',\n  Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer3.0.downsample.1',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.1.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.1.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.act1', ReLU(inplace=True)),\n ('layer3.1.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.1.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.drop_block', Identity()),\n ('layer3.1.act2', ReLU(inplace=True)),\n ('layer3.1.aa', Identity()),\n ('layer3.1.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.1.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.act3', ReLU(inplace=True)),\n ('layer3.2',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.2.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.2.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.act1', ReLU(inplace=True)),\n ('layer3.2.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.2.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.drop_block', Identity()),\n ('layer3.2.act2', ReLU(inplace=True)),\n ('layer3.2.aa', Identity()),\n ('layer3.2.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.2.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.act3', ReLU(inplace=True)),\n ('layer3.3',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.3.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.3.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.act1', ReLU(inplace=True)),\n ('layer3.3.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.3.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.drop_block', Identity()),\n ('layer3.3.act2', ReLU(inplace=True)),\n ('layer3.3.aa', Identity()),\n ('layer3.3.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.3.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.act3', ReLU(inplace=True)),\n ('layer3.4',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.4.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.4.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.act1', ReLU(inplace=True)),\n ('layer3.4.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.4.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.drop_block', Identity()),\n ('layer3.4.act2', ReLU(inplace=True)),\n ('layer3.4.aa', Identity()),\n ('layer3.4.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.4.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.act3', ReLU(inplace=True)),\n ('layer3.5',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.5.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.5.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.act1', ReLU(inplace=True)),\n ('layer3.5.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.5.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.drop_block', Identity()),\n ('layer3.5.act2', ReLU(inplace=True)),\n ('layer3.5.aa', Identity()),\n ('layer3.5.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.5.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.act3', ReLU(inplace=True)),\n ('layer4',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer4.0',\n  Bottleneck(\n    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer4.0.conv1',\n  Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.0.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.act1', ReLU(inplace=True)),\n ('layer4.0.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer4.0.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.drop_block', Identity()),\n ('layer4.0.act2', ReLU(inplace=True)),\n ('layer4.0.aa', Identity()),\n ('layer4.0.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.0.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.act3', ReLU(inplace=True)),\n ('layer4.0.downsample',\n  Sequential(\n    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer4.0.downsample.0',\n  Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer4.0.downsample.1',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1',\n  Bottleneck(\n    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer4.1.conv1',\n  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.1.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.act1', ReLU(inplace=True)),\n ('layer4.1.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer4.1.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.drop_block', Identity()),\n ('layer4.1.act2', ReLU(inplace=True)),\n ('layer4.1.aa', Identity()),\n ('layer4.1.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.1.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.act3', ReLU(inplace=True)),\n ('layer4.2',\n  Bottleneck(\n    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer4.2.conv1',\n  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.2.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.act1', ReLU(inplace=True)),\n ('layer4.2.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer4.2.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.drop_block', Identity()),\n ('layer4.2.act2', ReLU(inplace=True)),\n ('layer4.2.aa', Identity()),\n ('layer4.2.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.2.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.act3', ReLU(inplace=True)),\n ('global_pool',\n  SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))),\n ('global_pool.pool', AdaptiveAvgPool2d(output_size=1)),\n ('global_pool.flatten', Flatten(start_dim=1, end_dim=-1)),\n ('fc', Linear(in_features=2048, out_features=1000, bias=True))]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(m, k) for m, k in resnet50.named_modules()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:11:40.874466Z",
     "start_time": "2023-12-28T15:11:40.486874400Z"
    }
   },
   "id": "9cf4be64c4cdd3f6"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "['T_destination',\n '__annotations__',\n '__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattr__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_apply',\n '_backward_hooks',\n '_backward_pre_hooks',\n '_buffers',\n '_call_impl',\n '_compiled_call_impl',\n '_forward_hooks',\n '_forward_hooks_always_called',\n '_forward_hooks_with_kwargs',\n '_forward_pre_hooks',\n '_forward_pre_hooks_with_kwargs',\n '_get_backward_hooks',\n '_get_backward_pre_hooks',\n '_get_name',\n '_is_full_backward_hook',\n '_load_from_state_dict',\n '_load_state_dict_post_hooks',\n '_load_state_dict_pre_hooks',\n '_maybe_warn_non_full_backward_hook',\n '_modules',\n '_named_members',\n '_non_persistent_buffers_set',\n '_parameters',\n '_register_load_state_dict_pre_hook',\n '_register_state_dict_hook',\n '_replicate_for_data_parallel',\n '_save_to_state_dict',\n '_slow_forward',\n '_state_dict_hooks',\n '_state_dict_pre_hooks',\n '_version',\n '_wrapped_call_impl',\n 'act1',\n 'add_module',\n 'apply',\n 'bfloat16',\n 'bn1',\n 'buffers',\n 'call_super_init',\n 'children',\n 'compile',\n 'conv1',\n 'cpu',\n 'cuda',\n 'default_cfg',\n 'double',\n 'drop_rate',\n 'dump_patches',\n 'eval',\n 'extra_repr',\n 'fc',\n 'feature_info',\n 'float',\n 'forward',\n 'forward_features',\n 'forward_head',\n 'get_buffer',\n 'get_classifier',\n 'get_extra_state',\n 'get_parameter',\n 'get_submodule',\n 'global_pool',\n 'grad_checkpointing',\n 'group_matcher',\n 'half',\n 'init_weights',\n 'ipu',\n 'layer1',\n 'layer2',\n 'layer3',\n 'layer4',\n 'load_state_dict',\n 'maxpool',\n 'modules',\n 'named_buffers',\n 'named_children',\n 'named_modules',\n 'named_parameters',\n 'num_classes',\n 'num_features',\n 'parameters',\n 'pretrained_cfg',\n 'register_backward_hook',\n 'register_buffer',\n 'register_forward_hook',\n 'register_forward_pre_hook',\n 'register_full_backward_hook',\n 'register_full_backward_pre_hook',\n 'register_load_state_dict_post_hook',\n 'register_module',\n 'register_parameter',\n 'register_state_dict_pre_hook',\n 'requires_grad_',\n 'reset_classifier',\n 'set_extra_state',\n 'set_grad_checkpointing',\n 'share_memory',\n 'state_dict',\n 'to',\n 'to_empty',\n 'train',\n 'training',\n 'type',\n 'xpu',\n 'zero_grad']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(resnet50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:11:16.406114700Z",
     "start_time": "2023-12-28T15:11:16.030064400Z"
    }
   },
   "id": "ef30b8d4f11871c0"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[('',\n  ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n  )),\n ('conv1',\n  Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)),\n ('bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('act1', ReLU(inplace=True)),\n ('maxpool',\n  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)),\n ('layer1',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer1.0',\n  Bottleneck(\n    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer1.0.conv1',\n  Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.act1', ReLU(inplace=True)),\n ('layer1.0.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.0.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.drop_block', Identity()),\n ('layer1.0.act2', ReLU(inplace=True)),\n ('layer1.0.aa', Identity()),\n ('layer1.0.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.act3', ReLU(inplace=True)),\n ('layer1.0.downsample',\n  Sequential(\n    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer1.0.downsample.0',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.downsample.1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1',\n  Bottleneck(\n    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer1.1.conv1',\n  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.1.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.act1', ReLU(inplace=True)),\n ('layer1.1.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.1.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.drop_block', Identity()),\n ('layer1.1.act2', ReLU(inplace=True)),\n ('layer1.1.aa', Identity()),\n ('layer1.1.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.1.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.act3', ReLU(inplace=True)),\n ('layer1.2',\n  Bottleneck(\n    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer1.2.conv1',\n  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.2.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.act1', ReLU(inplace=True)),\n ('layer1.2.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.2.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.drop_block', Identity()),\n ('layer1.2.act2', ReLU(inplace=True)),\n ('layer1.2.aa', Identity()),\n ('layer1.2.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.2.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.act3', ReLU(inplace=True)),\n ('layer2',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer2.0',\n  Bottleneck(\n    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer2.0.conv1',\n  Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.0.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.act1', ReLU(inplace=True)),\n ('layer2.0.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer2.0.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.drop_block', Identity()),\n ('layer2.0.act2', ReLU(inplace=True)),\n ('layer2.0.aa', Identity()),\n ('layer2.0.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.0.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.act3', ReLU(inplace=True)),\n ('layer2.0.downsample',\n  Sequential(\n    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer2.0.downsample.0',\n  Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer2.0.downsample.1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.1.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.1.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.act1', ReLU(inplace=True)),\n ('layer2.1.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.1.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.drop_block', Identity()),\n ('layer2.1.act2', ReLU(inplace=True)),\n ('layer2.1.aa', Identity()),\n ('layer2.1.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.1.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.act3', ReLU(inplace=True)),\n ('layer2.2',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.2.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.2.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.act1', ReLU(inplace=True)),\n ('layer2.2.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.2.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.drop_block', Identity()),\n ('layer2.2.act2', ReLU(inplace=True)),\n ('layer2.2.aa', Identity()),\n ('layer2.2.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.2.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.act3', ReLU(inplace=True)),\n ('layer2.3',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.3.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.3.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.act1', ReLU(inplace=True)),\n ('layer2.3.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.3.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.drop_block', Identity()),\n ('layer2.3.act2', ReLU(inplace=True)),\n ('layer2.3.aa', Identity()),\n ('layer2.3.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.3.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.act3', ReLU(inplace=True)),\n ('layer3',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer3.0',\n  Bottleneck(\n    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer3.0.conv1',\n  Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.0.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.act1', ReLU(inplace=True)),\n ('layer3.0.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer3.0.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.drop_block', Identity()),\n ('layer3.0.act2', ReLU(inplace=True)),\n ('layer3.0.aa', Identity()),\n ('layer3.0.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.0.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.act3', ReLU(inplace=True)),\n ('layer3.0.downsample',\n  Sequential(\n    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer3.0.downsample.0',\n  Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer3.0.downsample.1',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.1.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.1.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.act1', ReLU(inplace=True)),\n ('layer3.1.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.1.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.drop_block', Identity()),\n ('layer3.1.act2', ReLU(inplace=True)),\n ('layer3.1.aa', Identity()),\n ('layer3.1.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.1.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.act3', ReLU(inplace=True)),\n ('layer3.2',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.2.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.2.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.act1', ReLU(inplace=True)),\n ('layer3.2.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.2.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.drop_block', Identity()),\n ('layer3.2.act2', ReLU(inplace=True)),\n ('layer3.2.aa', Identity()),\n ('layer3.2.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.2.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.act3', ReLU(inplace=True)),\n ('layer3.3',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.3.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.3.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.act1', ReLU(inplace=True)),\n ('layer3.3.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.3.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.drop_block', Identity()),\n ('layer3.3.act2', ReLU(inplace=True)),\n ('layer3.3.aa', Identity()),\n ('layer3.3.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.3.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.act3', ReLU(inplace=True)),\n ('layer3.4',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.4.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.4.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.act1', ReLU(inplace=True)),\n ('layer3.4.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.4.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.drop_block', Identity()),\n ('layer3.4.act2', ReLU(inplace=True)),\n ('layer3.4.aa', Identity()),\n ('layer3.4.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.4.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.act3', ReLU(inplace=True)),\n ('layer3.5',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.5.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.5.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.act1', ReLU(inplace=True)),\n ('layer3.5.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.5.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.drop_block', Identity()),\n ('layer3.5.act2', ReLU(inplace=True)),\n ('layer3.5.aa', Identity()),\n ('layer3.5.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.5.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.act3', ReLU(inplace=True)),\n ('layer4',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer4.0',\n  Bottleneck(\n    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer4.0.conv1',\n  Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.0.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.act1', ReLU(inplace=True)),\n ('layer4.0.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer4.0.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.drop_block', Identity()),\n ('layer4.0.act2', ReLU(inplace=True)),\n ('layer4.0.aa', Identity()),\n ('layer4.0.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.0.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.act3', ReLU(inplace=True)),\n ('layer4.0.downsample',\n  Sequential(\n    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer4.0.downsample.0',\n  Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer4.0.downsample.1',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1',\n  Bottleneck(\n    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer4.1.conv1',\n  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.1.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.act1', ReLU(inplace=True)),\n ('layer4.1.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer4.1.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.drop_block', Identity()),\n ('layer4.1.act2', ReLU(inplace=True)),\n ('layer4.1.aa', Identity()),\n ('layer4.1.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.1.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.act3', ReLU(inplace=True)),\n ('layer4.2',\n  Bottleneck(\n    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer4.2.conv1',\n  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.2.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.act1', ReLU(inplace=True)),\n ('layer4.2.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer4.2.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.drop_block', Identity()),\n ('layer4.2.act2', ReLU(inplace=True)),\n ('layer4.2.aa', Identity()),\n ('layer4.2.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.2.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.act3', ReLU(inplace=True)),\n ('global_pool',\n  SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))),\n ('global_pool.pool', AdaptiveAvgPool2d(output_size=1)),\n ('global_pool.flatten', Flatten(start_dim=1, end_dim=-1)),\n ('fc', Linear(in_features=2048, out_features=1000, bias=True))]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, m) for name, m in resnet50.named_modules()][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:17:40.421823700Z",
     "start_time": "2023-12-28T15:17:39.981823900Z"
    }
   },
   "id": "742f27bdba1c5676"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[('conv1.weight',\n  Parameter containing:\n  tensor([[[[ 2.0205e-02, -2.3905e-03, -2.0692e-03,  ..., -2.1685e-02,\n             -2.6140e-02,  3.5137e-02],\n            [ 1.1919e-02, -3.9269e-02,  1.0223e-02,  ...,  1.5147e-02,\n              2.0462e-02,  3.0057e-02],\n            [-5.4055e-06,  3.5655e-02, -3.1106e-02,  ...,  2.5908e-02,\n             -8.2757e-03,  9.2408e-03],\n            ...,\n            [ 3.1922e-03, -2.9917e-02, -6.8023e-04,  ...,  8.9421e-03,\n              2.0288e-02, -1.6921e-02],\n            [ 9.2214e-03,  2.8107e-02, -3.1560e-03,  ...,  5.4679e-02,\n              4.0747e-02,  7.1635e-03],\n            [-1.4354e-02,  1.2380e-02,  3.8668e-03,  ...,  1.0404e-02,\n              2.7850e-03, -2.4757e-02]],\n  \n           [[ 1.5083e-02, -4.7006e-02,  1.2246e-03,  ..., -1.4765e-02,\n              4.3166e-02,  1.3303e-02],\n            [ 3.0001e-02, -1.1653e-02,  2.1985e-02,  ..., -1.8013e-03,\n              1.0435e-02, -1.1959e-02],\n            [ 7.8141e-03, -1.2133e-02,  1.5068e-02,  ...,  3.5813e-02,\n             -1.2394e-02,  1.2446e-02],\n            ...,\n            [ 8.6308e-03,  2.7011e-02,  4.3209e-03,  ..., -2.6139e-02,\n             -3.6308e-02, -5.5036e-03],\n            [-2.3940e-02,  2.6287e-03, -2.3679e-03,  ...,  2.8741e-02,\n              4.8739e-02,  1.8239e-02],\n            [-8.5269e-03, -3.5215e-02,  2.1482e-02,  ...,  4.1576e-02,\n              1.9360e-02,  1.3195e-02]],\n  \n           [[ 3.1602e-02, -2.4201e-02, -3.5680e-03,  ..., -1.5726e-02,\n              2.6034e-02, -7.8508e-03],\n            [-1.5276e-02,  1.1890e-02, -1.4376e-03,  ..., -5.4867e-03,\n              2.0695e-03,  2.8955e-02],\n            [-2.2527e-02, -5.8025e-04,  2.0670e-02,  ...,  3.4252e-02,\n             -2.5036e-03, -1.2419e-02],\n            ...,\n            [ 2.7202e-03,  1.5048e-02, -1.5641e-02,  ..., -1.0753e-02,\n              1.1381e-02,  5.9074e-02],\n            [ 2.0294e-02, -3.4114e-02, -1.4550e-03,  ..., -8.5207e-03,\n              3.1333e-02,  3.1698e-02],\n            [-3.4379e-02, -1.2889e-02,  3.1761e-02,  ...,  3.4554e-02,\n              2.3809e-02, -1.6432e-02]]],\n  \n  \n          [[[ 5.7036e-03,  7.0347e-03,  6.1319e-02,  ...,  2.7848e-02,\n             -6.6134e-03,  1.3288e-02],\n            [ 1.1711e-02, -1.4123e-02,  5.0940e-02,  ..., -8.8190e-03,\n              5.8778e-03, -1.8456e-02],\n            [ 1.4140e-02,  2.3809e-02,  1.8546e-02,  ..., -5.7463e-03,\n              1.2362e-03,  1.6378e-02],\n            ...,\n            [-1.6107e-02, -2.9566e-03,  3.8190e-02,  ...,  3.5610e-02,\n             -2.1969e-02, -4.0934e-02],\n            [ 3.9458e-02,  4.3749e-02, -7.5573e-03,  ..., -1.4327e-03,\n             -1.9045e-02,  2.3340e-02],\n            [ 3.1615e-02, -3.2027e-02,  9.8964e-03,  ...,  3.8477e-02,\n             -2.0704e-02,  1.5991e-02]],\n  \n           [[ 5.5651e-02, -5.1981e-02,  5.8360e-03,  ..., -2.8437e-02,\n              2.1817e-02,  3.8454e-02],\n            [-5.1833e-03, -4.1325e-03,  6.5840e-03,  ..., -1.6406e-02,\n              2.7683e-02,  1.2991e-02],\n            [ 3.0617e-02,  6.3705e-02,  1.4437e-03,  ..., -1.6320e-03,\n             -1.5508e-02, -1.4128e-02],\n            ...,\n            [-2.9388e-02, -1.7309e-02, -2.9122e-02,  ...,  1.4107e-02,\n              2.8365e-02,  8.2677e-03],\n            [ 1.3414e-02,  1.0735e-02, -3.2278e-03,  ...,  9.1359e-03,\n             -3.9283e-02, -2.0034e-02],\n            [ 1.7134e-02, -1.7056e-02, -2.5197e-02,  ...,  2.5079e-03,\n              2.1150e-02, -3.2634e-02]],\n  \n           [[ 1.1848e-02, -2.5567e-03,  1.3417e-02,  ..., -1.1782e-02,\n             -6.7100e-03,  1.3251e-02],\n            [-1.3709e-02,  2.0225e-02,  3.3524e-02,  ..., -4.2197e-03,\n              1.0391e-02, -1.3892e-02],\n            [-1.0397e-02, -4.1764e-02,  4.0211e-02,  ...,  2.9085e-02,\n             -2.0469e-02, -7.0829e-03],\n            ...,\n            [ 5.4001e-02,  5.0901e-02, -1.8122e-02,  ...,  1.6229e-02,\n             -4.9057e-02,  7.3125e-03],\n            [ 3.6255e-02, -1.1498e-02, -3.0255e-03,  ...,  4.9947e-02,\n              7.9241e-03,  2.1390e-02],\n            [-1.1954e-02,  2.5755e-02, -4.2196e-03,  ..., -9.7114e-03,\n             -4.3517e-02, -2.1725e-02]]],\n  \n  \n          [[[ 1.9441e-02, -6.3138e-03, -2.8066e-02,  ...,  2.0818e-02,\n              2.8176e-03, -2.0657e-02],\n            [-1.0248e-02,  2.3290e-02, -2.1973e-04,  ..., -3.7387e-03,\n             -9.0462e-03, -5.1965e-02],\n            [ 1.7139e-03, -9.5017e-04,  2.7556e-02,  ..., -1.3388e-03,\n             -4.5942e-02, -6.7081e-03],\n            ...,\n            [-5.5261e-03,  1.1537e-02, -3.7207e-03,  ...,  5.0064e-03,\n              2.3429e-02,  1.4456e-02],\n            [ 5.1691e-02, -6.1622e-03, -9.1988e-04,  ...,  2.5942e-02,\n             -6.2018e-02, -1.5029e-02],\n            [-2.8239e-02, -9.4054e-03, -4.7031e-03,  ..., -5.9704e-02,\n             -2.1722e-02,  1.6728e-02]],\n  \n           [[ 1.2953e-02, -2.1262e-02, -1.7656e-02,  ..., -3.3261e-02,\n              8.1959e-03,  1.2398e-02],\n            [-1.0173e-02, -1.6911e-02,  1.0614e-02,  ...,  3.2688e-02,\n             -1.8414e-02, -3.5086e-02],\n            [ 2.2271e-02, -4.4208e-02,  1.1553e-02,  ...,  7.8297e-03,\n             -3.5210e-02, -2.1322e-02],\n            ...,\n            [-5.5005e-02,  8.4252e-03,  1.1382e-02,  ..., -3.5067e-02,\n             -2.5263e-03, -4.1092e-02],\n            [ 4.4021e-02,  3.7711e-02,  2.5611e-02,  ..., -1.7772e-02,\n             -3.4644e-02, -2.7270e-02],\n            [-1.9713e-02, -9.6579e-03, -4.4251e-03,  ...,  2.3424e-03,\n             -1.6846e-02,  2.0349e-04]],\n  \n           [[ 4.1014e-02,  3.1967e-03, -1.5065e-02,  ..., -2.9923e-02,\n              2.3460e-02,  8.7633e-03],\n            [-1.1828e-02, -3.9624e-02,  1.0316e-02,  ...,  1.6076e-02,\n              3.1923e-03, -8.4323e-03],\n            [ 2.0841e-02,  1.8511e-02, -1.8693e-02,  ...,  1.8843e-02,\n              1.4783e-02, -8.2095e-03],\n            ...,\n            [-8.6175e-03,  4.2012e-03, -2.5294e-02,  ...,  5.6677e-03,\n             -5.6201e-02,  1.2731e-02],\n            [-4.8295e-03,  2.1909e-02,  4.9577e-03,  ..., -4.0834e-03,\n              2.8378e-02,  5.1507e-02],\n            [ 1.2024e-02,  2.4257e-02, -1.7502e-02,  ..., -2.4755e-02,\n              6.6706e-03, -1.9776e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 1.6508e-02,  3.0904e-02, -2.9062e-02,  ..., -2.9244e-02,\n              2.9432e-02,  5.0518e-03],\n            [ 1.1300e-02,  2.7522e-02,  2.7583e-02,  ..., -4.9017e-02,\n              4.5015e-02,  1.4122e-03],\n            [-2.9580e-02, -2.1407e-02,  3.4995e-02,  ..., -4.8124e-03,\n             -1.2429e-02, -1.6051e-02],\n            ...,\n            [-5.2089e-02, -2.6876e-02, -2.0504e-02,  ..., -2.5680e-03,\n             -3.0872e-04,  2.9511e-02],\n            [-1.3734e-02, -6.4345e-03,  1.1440e-02,  ..., -2.9836e-02,\n             -1.4929e-02,  1.2519e-02],\n            [-2.3012e-03,  3.5196e-02, -3.6532e-03,  ...,  1.9822e-02,\n             -2.1415e-02, -9.7333e-03]],\n  \n           [[ 1.2571e-02, -4.4891e-02, -5.0075e-03,  ...,  2.1384e-02,\n             -2.4733e-02,  5.5107e-03],\n            [ 1.2609e-02,  9.9834e-03,  7.1271e-03,  ..., -1.7604e-02,\n              1.4591e-02, -1.1797e-02],\n            [-3.5269e-02,  8.7674e-03,  3.6029e-02,  ..., -8.4927e-03,\n             -3.3031e-02, -5.0926e-02],\n            ...,\n            [-4.1607e-02,  1.7718e-02, -4.0338e-02,  ...,  1.0660e-02,\n             -5.8099e-02,  1.2495e-02],\n            [ 3.3713e-02,  2.1249e-02,  1.0700e-02,  ..., -7.9082e-02,\n             -2.9711e-02, -1.7088e-02],\n            [ 1.6588e-02,  3.4100e-02, -1.5876e-02,  ...,  3.2419e-02,\n             -2.8723e-02, -4.2624e-02]],\n  \n           [[-1.7437e-02,  3.9583e-02,  2.4515e-02,  ...,  2.8756e-02,\n             -2.3897e-02,  1.3300e-03],\n            [-8.8991e-03, -2.0622e-02, -2.3253e-02,  ...,  9.0366e-03,\n              2.7050e-04, -1.0827e-02],\n            [ 2.2254e-02,  2.3756e-02,  3.3088e-03,  ..., -1.7154e-02,\n             -1.8019e-02,  2.2955e-02],\n            ...,\n            [ 1.0251e-02, -3.0935e-02,  3.1150e-03,  ..., -1.1252e-02,\n              1.0673e-03,  2.5444e-02],\n            [ 8.2619e-03, -2.6377e-02,  2.7242e-02,  ..., -3.0989e-03,\n             -2.5490e-02,  3.0521e-02],\n            [-2.6266e-02,  3.0251e-02,  9.1010e-03,  ...,  1.5956e-02,\n             -4.6953e-03, -2.0908e-02]]],\n  \n  \n          [[[-7.4897e-03,  3.2680e-02,  2.0491e-02,  ...,  5.9584e-02,\n             -1.9463e-02,  3.4768e-02],\n            [-6.7759e-03, -2.4649e-02, -2.3188e-02,  ..., -3.0446e-03,\n              5.9373e-02,  4.3334e-03],\n            [-1.9322e-02,  4.4271e-02,  1.3837e-02,  ..., -2.4099e-02,\n             -5.0359e-03, -3.8554e-03],\n            ...,\n            [ 1.3820e-02, -7.0580e-03,  1.6318e-03,  ...,  1.6081e-02,\n             -3.8098e-02,  1.2108e-02],\n            [ 2.7690e-03, -1.7610e-02, -3.5126e-02,  ...,  4.7488e-03,\n             -5.1283e-02, -2.3960e-02],\n            [ 2.0676e-02, -1.5036e-02,  2.5873e-02,  ..., -3.0309e-02,\n             -1.1146e-02,  1.2897e-02]],\n  \n           [[-1.8908e-02, -6.6267e-03, -1.5720e-02,  ...,  5.6900e-02,\n              5.7605e-03,  2.0269e-02],\n            [-1.2481e-02, -2.2107e-03, -5.7907e-02,  ..., -1.1214e-03,\n             -3.9593e-02,  1.6617e-02],\n            [ 1.6587e-02,  1.6491e-02, -3.6589e-03,  ...,  2.4241e-02,\n             -1.0081e-02,  4.5497e-02],\n            ...,\n            [ 6.1241e-03, -1.5664e-02, -2.1847e-02,  ..., -1.9028e-02,\n              1.3661e-02, -1.2527e-02],\n            [ 1.8520e-02,  3.0073e-02, -1.5109e-02,  ..., -4.1136e-03,\n             -2.4439e-02,  2.8699e-02],\n            [ 8.1089e-03,  3.7619e-02, -1.2772e-02,  ...,  2.7639e-02,\n             -3.7560e-02, -5.0457e-02]],\n  \n           [[ 5.3597e-02, -3.0653e-02,  9.3787e-03,  ..., -2.6674e-02,\n              1.8336e-02,  6.6573e-03],\n            [ 2.6618e-02, -5.0091e-02,  1.4210e-03,  ..., -2.7360e-02,\n             -1.8585e-02,  1.0534e-03],\n            [-2.5282e-02, -2.2415e-02, -4.4411e-03,  ..., -8.7972e-03,\n              2.6992e-02, -9.2498e-03],\n            ...,\n            [-1.4720e-02,  1.8461e-02,  2.7196e-02,  ...,  2.1060e-02,\n             -1.9724e-02,  1.9480e-02],\n            [ 4.9876e-02,  1.5148e-03, -1.0424e-02,  ..., -2.8956e-02,\n             -1.0594e-02,  7.2250e-03],\n            [ 4.2594e-03,  6.1981e-03,  1.1039e-02,  ..., -5.8941e-03,\n             -5.8101e-03,  7.1369e-03]]],\n  \n  \n          [[[ 2.4372e-02,  1.5509e-02, -2.0794e-02,  ...,  3.9159e-02,\n             -3.8332e-02, -1.8619e-02],\n            [-3.7797e-02, -3.6067e-02,  2.2466e-02,  ...,  3.8821e-03,\n              6.1536e-03,  4.1941e-02],\n            [-1.6141e-03, -1.2965e-03,  1.1418e-03,  ..., -3.4387e-03,\n             -4.2280e-03, -1.7032e-02],\n            ...,\n            [ 2.2596e-02, -4.5576e-03, -3.6427e-02,  ..., -1.7975e-02,\n             -2.9819e-02,  3.0867e-02],\n            [-1.3974e-02, -2.3854e-02, -2.4647e-02,  ..., -2.7752e-02,\n             -6.6875e-02,  7.4949e-03],\n            [-4.1861e-02,  1.9089e-02,  2.2661e-02,  ..., -1.0697e-02,\n             -2.7676e-03,  1.0051e-02]],\n  \n           [[-2.9766e-02,  1.9077e-02,  1.0466e-02,  ...,  1.8746e-02,\n              3.3052e-02, -3.3485e-02],\n            [ 4.4829e-02, -1.3520e-02,  2.8138e-02,  ...,  6.1510e-03,\n             -6.1483e-03, -1.9508e-02],\n            [ 1.9231e-02,  1.9132e-02, -2.1079e-02,  ...,  8.7133e-03,\n              1.5779e-02, -2.4805e-02],\n            ...,\n            [ 3.6441e-02, -4.4241e-02,  8.3280e-03,  ..., -2.9894e-02,\n             -2.7145e-02, -2.3498e-02],\n            [-7.5467e-03, -1.9729e-02, -1.3039e-03,  ...,  3.5926e-03,\n             -1.6647e-03, -3.0189e-02],\n            [ 4.7935e-03,  2.0252e-02, -2.7340e-02,  ...,  4.3277e-03,\n              1.8503e-02,  4.7513e-02]],\n  \n           [[-6.1403e-02,  1.4447e-02, -2.9383e-02,  ...,  2.0712e-03,\n             -3.2192e-02, -9.2196e-03],\n            [ 2.5356e-03, -2.8008e-02,  6.3749e-03,  ...,  1.0467e-03,\n             -2.9662e-02,  3.6803e-02],\n            [-1.5732e-02, -4.8111e-04,  6.4498e-03,  ..., -1.5811e-02,\n              4.2455e-03, -3.5927e-03],\n            ...,\n            [ 9.1832e-03,  3.7838e-03, -1.3741e-03,  ..., -1.8789e-03,\n             -3.0376e-03,  2.7973e-02],\n            [ 1.1624e-02,  2.0685e-02, -8.5090e-03,  ...,  5.1945e-03,\n             -3.5213e-02, -1.0521e-02],\n            [ 1.4765e-02, -2.5245e-02, -2.3807e-02,  ...,  9.2163e-03,\n             -1.8324e-02, -1.8349e-02]]]], requires_grad=True)),\n ('bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.0.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.2290]],\n  \n           [[ 0.3313]],\n  \n           [[ 0.2362]],\n  \n           ...,\n  \n           [[-0.1768]],\n  \n           [[-0.1309]],\n  \n           [[-0.0832]]],\n  \n  \n          [[[-0.3692]],\n  \n           [[ 0.0679]],\n  \n           [[-0.0160]],\n  \n           ...,\n  \n           [[-0.3867]],\n  \n           [[-0.0800]],\n  \n           [[ 0.0887]]],\n  \n  \n          [[[ 0.0321]],\n  \n           [[ 0.0199]],\n  \n           [[ 0.1873]],\n  \n           ...,\n  \n           [[-0.0699]],\n  \n           [[-0.0163]],\n  \n           [[-0.1113]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.1393]],\n  \n           [[-0.4019]],\n  \n           [[-0.3346]],\n  \n           ...,\n  \n           [[-0.2075]],\n  \n           [[ 0.0176]],\n  \n           [[ 0.0399]]],\n  \n  \n          [[[-0.0983]],\n  \n           [[ 0.0173]],\n  \n           [[-0.1739]],\n  \n           ...,\n  \n           [[-0.0412]],\n  \n           [[-0.1317]],\n  \n           [[-0.1213]]],\n  \n  \n          [[[-0.3507]],\n  \n           [[ 0.1722]],\n  \n           [[ 0.0333]],\n  \n           ...,\n  \n           [[-0.1155]],\n  \n           [[-0.0241]],\n  \n           [[ 0.0263]]]], requires_grad=True)),\n ('layer1.0.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.0.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.0.conv2.weight',\n  Parameter containing:\n  tensor([[[[-8.5353e-02,  4.2442e-02, -1.9138e-03],\n            [-1.4604e-02, -8.3252e-02, -1.5588e-02],\n            [-2.2293e-02,  7.0880e-03, -2.1843e-02]],\n  \n           [[ 1.2756e-02, -5.8847e-02, -2.8348e-02],\n            [ 4.7153e-02, -9.5202e-02,  1.3774e-01],\n            [-6.3986e-02,  1.3814e-01,  4.2420e-02]],\n  \n           [[ 4.5159e-02,  9.7097e-02,  1.9015e-02],\n            [-1.1463e-01,  1.5932e-02, -5.9595e-02],\n            [-2.8581e-02, -6.7515e-02, -8.0742e-02]],\n  \n           ...,\n  \n           [[ 1.3945e-01, -3.7596e-02, -8.4238e-02],\n            [ 9.0191e-02,  3.0739e-02, -8.3794e-03],\n            [-2.9000e-03,  2.9931e-03,  9.9263e-02]],\n  \n           [[-9.4439e-02, -7.9937e-02,  1.1385e-01],\n            [ 1.0231e-02, -5.5462e-02, -3.1065e-02],\n            [-2.7779e-02,  8.5615e-04, -2.8768e-02]],\n  \n           [[ 5.6608e-02, -3.2057e-03, -5.5263e-02],\n            [-8.3164e-02, -4.3020e-03,  2.5182e-02],\n            [-4.3467e-02, -1.0800e-01, -3.3470e-02]]],\n  \n  \n          [[[ 6.6404e-02, -1.4066e-02,  6.1656e-02],\n            [-2.8239e-02,  3.9282e-02,  4.5282e-02],\n            [ 9.5756e-02,  4.7193e-02, -3.2316e-02]],\n  \n           [[-4.0710e-02, -4.9333e-02, -5.9756e-02],\n            [-8.1629e-02, -2.4763e-02, -3.1091e-02],\n            [-3.9833e-03, -4.6530e-02,  9.1292e-03]],\n  \n           [[-1.1391e-02,  2.1991e-02, -6.1529e-03],\n            [-5.5138e-02,  7.5181e-03,  3.8683e-02],\n            [-8.3326e-03, -4.9492e-02,  1.4074e-01]],\n  \n           ...,\n  \n           [[-9.3771e-02,  1.0060e-02, -4.4185e-02],\n            [ 1.1426e-02, -4.9989e-02,  5.2989e-02],\n            [-3.5208e-02, -8.4469e-02,  2.2738e-02]],\n  \n           [[-9.3101e-03,  5.8356e-02, -6.1444e-03],\n            [-2.3899e-02, -9.9446e-03, -1.6147e-03],\n            [-1.1913e-01, -6.7731e-04,  6.3689e-02]],\n  \n           [[ 5.8050e-02,  1.0001e-01, -2.0225e-02],\n            [ 8.8134e-04,  3.7452e-02, -6.9153e-02],\n            [ 6.8750e-02, -4.4218e-02,  4.4150e-02]]],\n  \n  \n          [[[ 6.8471e-02, -3.5197e-02, -1.4969e-02],\n            [-6.3379e-02,  1.0913e-01, -4.1560e-02],\n            [ 2.6482e-02,  4.8737e-02, -2.8062e-02]],\n  \n           [[-5.5004e-02,  9.2907e-03,  1.2454e-02],\n            [ 1.4338e-02, -8.4946e-02,  5.0657e-02],\n            [-5.1343e-02, -1.8879e-02,  6.4731e-02]],\n  \n           [[-1.2408e-03,  7.7626e-02, -2.3187e-02],\n            [-3.9377e-03, -3.2439e-02, -4.1149e-03],\n            [ 5.1900e-02, -7.4798e-02,  2.9986e-02]],\n  \n           ...,\n  \n           [[ 8.0931e-02,  1.2289e-01, -8.4175e-03],\n            [ 7.5686e-02,  3.4618e-03, -5.7763e-03],\n            [-9.1568e-02, -6.6277e-02,  8.0384e-02]],\n  \n           [[-2.8032e-02,  1.3912e-02, -3.4598e-02],\n            [ 2.5609e-03, -1.0839e-01,  6.4283e-02],\n            [-2.4107e-03,  2.2428e-02, -1.7362e-02]],\n  \n           [[ 2.9961e-02,  2.0006e-02, -5.3228e-03],\n            [ 4.6292e-03, -8.1682e-02, -5.6117e-03],\n            [ 8.6949e-02,  2.0804e-02,  1.1615e-01]]],\n  \n  \n          ...,\n  \n  \n          [[[ 1.4988e-02,  1.5524e-01, -1.2087e-01],\n            [-2.7630e-02, -5.5988e-02, -4.6526e-02],\n            [-1.5355e-01, -4.5186e-02, -1.0135e-01]],\n  \n           [[ 5.7352e-03, -4.8523e-02,  1.6264e-01],\n            [-7.0921e-02,  7.9327e-03, -2.5498e-02],\n            [ 4.3608e-02, -3.4504e-02,  4.2297e-02]],\n  \n           [[ 1.6033e-02, -8.8280e-03,  2.7813e-02],\n            [ 4.6721e-02,  4.7857e-02, -4.3148e-02],\n            [-4.4466e-04, -6.5594e-02,  1.7914e-02]],\n  \n           ...,\n  \n           [[-1.0129e-02, -2.9319e-02,  4.2583e-02],\n            [-1.2842e-01,  1.3437e-04, -5.2542e-02],\n            [ 9.0520e-02,  2.2589e-02, -3.6202e-02]],\n  \n           [[ 5.1656e-02, -8.9629e-02,  8.8598e-02],\n            [ 2.6451e-02,  7.1046e-02, -8.4856e-03],\n            [-1.0367e-01,  8.8904e-02, -3.7408e-02]],\n  \n           [[ 4.7444e-02,  2.9483e-02,  1.0843e-01],\n            [ 1.4208e-01,  3.0472e-02, -3.7760e-03],\n            [ 2.1232e-02,  2.1296e-03,  1.0800e-02]]],\n  \n  \n          [[[-7.9437e-02, -4.7137e-02,  3.2004e-02],\n            [ 3.4575e-03, -8.6786e-02, -1.1978e-01],\n            [-1.0690e-01, -1.7928e-02, -2.0724e-02]],\n  \n           [[-5.8107e-02, -5.7194e-02,  1.7888e-01],\n            [ 4.1697e-02,  5.3274e-02, -1.0917e-01],\n            [ 3.3153e-02, -4.3406e-03,  2.8869e-02]],\n  \n           [[-1.0578e-01,  2.4505e-02, -3.9027e-02],\n            [ 1.0042e-01,  1.8018e-02, -6.0525e-02],\n            [-3.1232e-02,  2.0422e-02,  3.9941e-02]],\n  \n           ...,\n  \n           [[-8.5304e-03,  1.2059e-01,  1.0680e-02],\n            [-3.6759e-02,  6.6216e-03, -6.9169e-02],\n            [-3.9427e-02,  4.9240e-02, -7.6128e-02]],\n  \n           [[-2.2726e-03, -3.5626e-02, -4.9596e-02],\n            [-9.9419e-02, -2.6064e-02,  3.2886e-02],\n            [ 3.7754e-02, -4.9676e-02,  3.7577e-02]],\n  \n           [[ 1.1832e-01,  4.5453e-03,  4.4521e-02],\n            [ 5.2852e-02, -1.2235e-02, -3.3951e-02],\n            [-2.3239e-02,  4.8260e-02,  5.4950e-02]]],\n  \n  \n          [[[ 9.1501e-03,  4.3327e-04,  6.2598e-02],\n            [-1.3631e-02, -1.3479e-01,  1.0200e-01],\n            [-1.6141e-02,  3.0046e-02,  6.8658e-02]],\n  \n           [[ 2.1715e-02,  7.0487e-02,  9.3667e-02],\n            [ 1.1754e-02, -5.1640e-02, -1.1317e-02],\n            [ 2.0853e-03, -3.5191e-02, -2.5556e-02]],\n  \n           [[ 1.1396e-01, -1.7334e-02,  1.1268e-01],\n            [ 2.0064e-02,  1.0131e-01, -1.1123e-01],\n            [-9.5416e-02, -8.4598e-02,  9.5427e-02]],\n  \n           ...,\n  \n           [[ 1.1394e-01,  2.4958e-02, -8.8216e-03],\n            [ 6.2458e-02, -1.2677e-02, -4.4292e-02],\n            [-1.2797e-01,  6.6629e-04, -8.6260e-02]],\n  \n           [[ 6.5938e-03, -6.4041e-02,  2.2439e-02],\n            [-2.1487e-03,  5.1897e-02,  8.9510e-02],\n            [ 3.5998e-02,  4.4589e-02,  1.1359e-02]],\n  \n           [[ 1.3785e-02, -4.7691e-02,  1.1545e-01],\n            [ 8.9681e-02,  1.9578e-02,  1.0743e-02],\n            [ 1.7497e-02,  1.4757e-02, -8.0502e-02]]]], requires_grad=True)),\n ('layer1.0.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.0.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.0.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0413]],\n  \n           [[ 0.0872]],\n  \n           [[-0.1247]],\n  \n           ...,\n  \n           [[-0.1366]],\n  \n           [[-0.0578]],\n  \n           [[ 0.0542]]],\n  \n  \n          [[[-0.0034]],\n  \n           [[ 0.1183]],\n  \n           [[ 0.0281]],\n  \n           ...,\n  \n           [[-0.1057]],\n  \n           [[ 0.0387]],\n  \n           [[ 0.0256]]],\n  \n  \n          [[[ 0.0482]],\n  \n           [[-0.0497]],\n  \n           [[-0.0084]],\n  \n           ...,\n  \n           [[-0.0399]],\n  \n           [[-0.0327]],\n  \n           [[-0.0984]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.1554]],\n  \n           [[ 0.1927]],\n  \n           [[ 0.0380]],\n  \n           ...,\n  \n           [[-0.0671]],\n  \n           [[-0.0318]],\n  \n           [[-0.0181]]],\n  \n  \n          [[[ 0.0598]],\n  \n           [[ 0.0496]],\n  \n           [[ 0.0455]],\n  \n           ...,\n  \n           [[-0.0472]],\n  \n           [[ 0.1054]],\n  \n           [[ 0.0357]]],\n  \n  \n          [[[ 0.0682]],\n  \n           [[ 0.0668]],\n  \n           [[ 0.1178]],\n  \n           ...,\n  \n           [[ 0.0272]],\n  \n           [[ 0.0508]],\n  \n           [[ 0.0411]]]], requires_grad=True)),\n ('layer1.0.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.0.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.0.downsample.0.weight',\n  Parameter containing:\n  tensor([[[[ 0.2302]],\n  \n           [[ 0.0115]],\n  \n           [[ 0.3872]],\n  \n           ...,\n  \n           [[ 0.0548]],\n  \n           [[ 0.1249]],\n  \n           [[-0.0445]]],\n  \n  \n          [[[ 0.1131]],\n  \n           [[ 0.0776]],\n  \n           [[ 0.0465]],\n  \n           ...,\n  \n           [[ 0.0942]],\n  \n           [[-0.0379]],\n  \n           [[-0.0159]]],\n  \n  \n          [[[ 0.0495]],\n  \n           [[ 0.1434]],\n  \n           [[-0.0829]],\n  \n           ...,\n  \n           [[ 0.0878]],\n  \n           [[-0.0151]],\n  \n           [[ 0.0321]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.1055]],\n  \n           [[-0.2234]],\n  \n           [[ 0.0616]],\n  \n           ...,\n  \n           [[ 0.0533]],\n  \n           [[ 0.0322]],\n  \n           [[ 0.0866]]],\n  \n  \n          [[[-0.1012]],\n  \n           [[-0.0883]],\n  \n           [[ 0.1247]],\n  \n           ...,\n  \n           [[-0.0140]],\n  \n           [[ 0.1246]],\n  \n           [[ 0.0889]]],\n  \n  \n          [[[-0.0217]],\n  \n           [[-0.2150]],\n  \n           [[-0.1290]],\n  \n           ...,\n  \n           [[-0.0731]],\n  \n           [[-0.0035]],\n  \n           [[ 0.0307]]]], requires_grad=True)),\n ('layer1.0.downsample.1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer1.0.downsample.1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.1.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.2611]],\n  \n           [[ 0.1386]],\n  \n           [[-0.0270]],\n  \n           ...,\n  \n           [[ 0.1107]],\n  \n           [[ 0.2469]],\n  \n           [[-0.2767]]],\n  \n  \n          [[[-0.0702]],\n  \n           [[ 0.2575]],\n  \n           [[-0.1334]],\n  \n           ...,\n  \n           [[-0.0319]],\n  \n           [[ 0.1562]],\n  \n           [[-0.0166]]],\n  \n  \n          [[[-0.0584]],\n  \n           [[ 0.0050]],\n  \n           [[-0.0705]],\n  \n           ...,\n  \n           [[-0.0733]],\n  \n           [[-0.0407]],\n  \n           [[ 0.0555]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.4171]],\n  \n           [[ 0.1203]],\n  \n           [[-0.0161]],\n  \n           ...,\n  \n           [[ 0.0299]],\n  \n           [[ 0.0792]],\n  \n           [[-0.1504]]],\n  \n  \n          [[[ 0.1538]],\n  \n           [[ 0.4424]],\n  \n           [[-0.2124]],\n  \n           ...,\n  \n           [[ 0.0160]],\n  \n           [[-0.0894]],\n  \n           [[-0.0954]]],\n  \n  \n          [[[ 0.2508]],\n  \n           [[ 0.0981]],\n  \n           [[ 0.1517]],\n  \n           ...,\n  \n           [[-0.0328]],\n  \n           [[ 0.0270]],\n  \n           [[-0.5096]]]], requires_grad=True)),\n ('layer1.1.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.1.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.1.conv2.weight',\n  Parameter containing:\n  tensor([[[[-0.0761, -0.0680,  0.1190],\n            [-0.0220,  0.0170,  0.1041],\n            [-0.1102, -0.0218,  0.0276]],\n  \n           [[-0.0449,  0.0087, -0.0510],\n            [ 0.0544,  0.0295, -0.0865],\n            [ 0.0440, -0.0022,  0.0425]],\n  \n           [[ 0.0111, -0.0058, -0.0094],\n            [-0.0358, -0.0008,  0.1008],\n            [-0.1092, -0.0342, -0.0803]],\n  \n           ...,\n  \n           [[-0.0304, -0.0038,  0.0153],\n            [-0.0090, -0.0025,  0.1180],\n            [ 0.0202, -0.0396,  0.0919]],\n  \n           [[ 0.0480, -0.0301,  0.0307],\n            [ 0.0235,  0.0152,  0.0921],\n            [-0.0579,  0.0070, -0.0962]],\n  \n           [[-0.0308, -0.0284,  0.0663],\n            [-0.1260,  0.0022,  0.0029],\n            [ 0.0653,  0.0226, -0.0320]]],\n  \n  \n          [[[ 0.0536,  0.0759,  0.0370],\n            [ 0.0595,  0.0877, -0.1594],\n            [ 0.0149,  0.0525,  0.1823]],\n  \n           [[ 0.0306, -0.0366,  0.0387],\n            [-0.0209, -0.0651, -0.0072],\n            [ 0.1328,  0.0492,  0.0556]],\n  \n           [[ 0.0480, -0.0496, -0.1207],\n            [-0.0277, -0.0344, -0.0428],\n            [-0.1035, -0.0300,  0.0669]],\n  \n           ...,\n  \n           [[ 0.0179,  0.0032,  0.0266],\n            [ 0.0428, -0.0178, -0.0024],\n            [ 0.0625,  0.0131,  0.0136]],\n  \n           [[ 0.0190, -0.0036,  0.1004],\n            [-0.1120, -0.0176,  0.0060],\n            [-0.0099, -0.1138, -0.0483]],\n  \n           [[-0.0273,  0.0170,  0.0589],\n            [-0.0367, -0.0033,  0.0358],\n            [ 0.0008, -0.1269,  0.0433]]],\n  \n  \n          [[[-0.0309,  0.0196,  0.0111],\n            [-0.0149,  0.0639,  0.0440],\n            [-0.0299, -0.0455, -0.0161]],\n  \n           [[ 0.1299,  0.0826,  0.0206],\n            [-0.0026, -0.0634, -0.0422],\n            [-0.0221,  0.0322,  0.0217]],\n  \n           [[-0.0822,  0.0262, -0.0140],\n            [-0.1324, -0.0146, -0.0364],\n            [ 0.0331, -0.0344,  0.0996]],\n  \n           ...,\n  \n           [[-0.0180, -0.0299,  0.0010],\n            [-0.0444, -0.0364,  0.0259],\n            [-0.0607, -0.0079, -0.0413]],\n  \n           [[-0.0712, -0.0613, -0.0099],\n            [-0.0326,  0.0697, -0.1162],\n            [ 0.0466, -0.0305,  0.0081]],\n  \n           [[-0.0030, -0.0225,  0.0573],\n            [-0.0579,  0.0566, -0.0257],\n            [ 0.0212, -0.0669,  0.0343]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0075,  0.0533, -0.0252],\n            [-0.0002,  0.0185, -0.0457],\n            [ 0.0575, -0.0279, -0.0231]],\n  \n           [[-0.0025, -0.0967, -0.0964],\n            [ 0.0077, -0.0874,  0.0063],\n            [ 0.0214, -0.0251,  0.0103]],\n  \n           [[-0.1013,  0.0515,  0.0510],\n            [ 0.0216,  0.0175, -0.0474],\n            [-0.0415,  0.0455, -0.0269]],\n  \n           ...,\n  \n           [[ 0.0778, -0.0191, -0.0706],\n            [ 0.0573,  0.0219, -0.0233],\n            [ 0.0186,  0.0261, -0.0428]],\n  \n           [[-0.0150,  0.0065,  0.1109],\n            [ 0.0983, -0.0402, -0.0577],\n            [ 0.0291,  0.0630,  0.0320]],\n  \n           [[ 0.1271,  0.0369, -0.0152],\n            [ 0.0477,  0.0073, -0.0525],\n            [-0.0083,  0.0534, -0.0394]]],\n  \n  \n          [[[ 0.0219,  0.0118, -0.0518],\n            [-0.0484, -0.0842,  0.0487],\n            [-0.0443,  0.0006, -0.0173]],\n  \n           [[-0.0271, -0.0089,  0.0509],\n            [ 0.0078, -0.0025, -0.0208],\n            [-0.0011, -0.0077, -0.0575]],\n  \n           [[ 0.0249, -0.0075, -0.0122],\n            [ 0.0842,  0.0048, -0.0334],\n            [ 0.0288,  0.0258,  0.0602]],\n  \n           ...,\n  \n           [[ 0.1379, -0.0036,  0.0563],\n            [-0.0203, -0.0756,  0.0138],\n            [-0.0086, -0.0492, -0.0315]],\n  \n           [[-0.0203,  0.0524,  0.0591],\n            [ 0.0119, -0.0162,  0.0316],\n            [-0.0638, -0.0052, -0.0103]],\n  \n           [[ 0.0402,  0.0109,  0.0299],\n            [ 0.0133,  0.0444,  0.0548],\n            [ 0.0247, -0.1040,  0.0890]]],\n  \n  \n          [[[-0.0281, -0.0561,  0.0212],\n            [ 0.0479,  0.0497, -0.0372],\n            [-0.0873,  0.0718, -0.0501]],\n  \n           [[-0.0032, -0.0296,  0.0230],\n            [-0.0203, -0.0180,  0.0390],\n            [ 0.1703,  0.0383,  0.1231]],\n  \n           [[-0.0237,  0.0717,  0.0343],\n            [ 0.0196, -0.0072,  0.0537],\n            [ 0.0045,  0.0019, -0.0254]],\n  \n           ...,\n  \n           [[-0.0180,  0.0322,  0.0653],\n            [-0.0365,  0.0197,  0.0718],\n            [-0.0059,  0.0274,  0.0364]],\n  \n           [[ 0.0402, -0.1024,  0.0109],\n            [-0.1263,  0.0491,  0.0409],\n            [-0.0649,  0.1100,  0.0808]],\n  \n           [[ 0.0184, -0.1448, -0.0140],\n            [-0.0274,  0.0083, -0.0272],\n            [ 0.0826, -0.0148, -0.0603]]]], requires_grad=True)),\n ('layer1.1.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.1.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.1.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0495]],\n  \n           [[ 0.1060]],\n  \n           [[ 0.0348]],\n  \n           ...,\n  \n           [[ 0.0021]],\n  \n           [[ 0.0008]],\n  \n           [[-0.0600]]],\n  \n  \n          [[[-0.0754]],\n  \n           [[ 0.0518]],\n  \n           [[-0.1467]],\n  \n           ...,\n  \n           [[ 0.0112]],\n  \n           [[ 0.1063]],\n  \n           [[-0.1654]]],\n  \n  \n          [[[-0.0530]],\n  \n           [[ 0.1251]],\n  \n           [[ 0.0805]],\n  \n           ...,\n  \n           [[ 0.0032]],\n  \n           [[ 0.0285]],\n  \n           [[ 0.0513]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.1960]],\n  \n           [[ 0.0398]],\n  \n           [[ 0.0405]],\n  \n           ...,\n  \n           [[-0.0247]],\n  \n           [[ 0.0511]],\n  \n           [[ 0.1070]]],\n  \n  \n          [[[ 0.0446]],\n  \n           [[ 0.0621]],\n  \n           [[ 0.1272]],\n  \n           ...,\n  \n           [[-0.0241]],\n  \n           [[ 0.0305]],\n  \n           [[ 0.0363]]],\n  \n  \n          [[[-0.2069]],\n  \n           [[ 0.0013]],\n  \n           [[-0.1190]],\n  \n           ...,\n  \n           [[-0.0037]],\n  \n           [[-0.0831]],\n  \n           [[-0.1900]]]], requires_grad=True)),\n ('layer1.1.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.1.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.2.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.1843]],\n  \n           [[-0.1826]],\n  \n           [[-0.2861]],\n  \n           ...,\n  \n           [[ 0.0362]],\n  \n           [[ 0.2487]],\n  \n           [[-0.1056]]],\n  \n  \n          [[[-0.1508]],\n  \n           [[-0.2946]],\n  \n           [[ 0.1051]],\n  \n           ...,\n  \n           [[ 0.1143]],\n  \n           [[ 0.1828]],\n  \n           [[-0.1549]]],\n  \n  \n          [[[ 0.0008]],\n  \n           [[-0.4955]],\n  \n           [[ 0.0088]],\n  \n           ...,\n  \n           [[-0.0345]],\n  \n           [[ 0.2328]],\n  \n           [[ 0.1095]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0046]],\n  \n           [[ 0.0422]],\n  \n           [[ 0.1480]],\n  \n           ...,\n  \n           [[-0.3768]],\n  \n           [[ 0.1282]],\n  \n           [[-0.1075]]],\n  \n  \n          [[[ 0.0360]],\n  \n           [[-0.0755]],\n  \n           [[-0.0259]],\n  \n           ...,\n  \n           [[ 0.0494]],\n  \n           [[-0.3663]],\n  \n           [[ 0.0763]]],\n  \n  \n          [[[ 0.0492]],\n  \n           [[ 0.0731]],\n  \n           [[-0.0499]],\n  \n           ...,\n  \n           [[-0.1093]],\n  \n           [[ 0.1039]],\n  \n           [[-0.0451]]]], requires_grad=True)),\n ('layer1.2.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.2.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.2.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 2.7623e-02, -2.4443e-02,  4.5454e-02],\n            [ 8.7865e-02,  2.6252e-02,  6.0390e-03],\n            [ 6.4354e-02,  1.5069e-02,  2.8763e-02]],\n  \n           [[ 1.0857e-01,  9.5209e-03, -3.1717e-02],\n            [-8.3909e-02,  3.4287e-02, -1.4324e-02],\n            [-5.9549e-03, -1.5819e-02, -3.5980e-02]],\n  \n           [[-8.5880e-02,  1.6646e-02,  1.2425e-01],\n            [-2.6203e-02, -5.9565e-02, -3.9389e-02],\n            [-2.6639e-02, -4.4188e-02, -1.3339e-03]],\n  \n           ...,\n  \n           [[-2.4837e-02,  5.7556e-02, -3.5952e-02],\n            [ 1.8752e-02,  3.6821e-02, -5.4847e-02],\n            [-2.1440e-02,  3.2884e-02,  3.4099e-02]],\n  \n           [[-3.2155e-02, -8.0906e-02,  1.5429e-02],\n            [ 1.9014e-02,  3.3896e-03,  6.8020e-02],\n            [ 9.0992e-02,  1.3429e-01,  3.1759e-02]],\n  \n           [[ 2.1567e-02,  3.0925e-02, -7.6576e-02],\n            [-1.1861e-02,  8.9780e-02, -5.2691e-03],\n            [-7.9270e-02, -2.1960e-02, -2.5949e-02]]],\n  \n  \n          [[[-9.3808e-02, -3.4036e-02,  7.0871e-02],\n            [-3.6460e-02,  2.6389e-02,  1.2293e-02],\n            [-3.4808e-02, -8.4648e-02, -2.3852e-02]],\n  \n           [[-9.1580e-02, -1.3380e-01,  1.0249e-01],\n            [-3.5538e-02, -8.9153e-02,  7.2105e-02],\n            [-9.4974e-02,  1.1773e-01,  1.0579e-02]],\n  \n           [[ 9.7100e-03, -1.3482e-02,  1.0436e-01],\n            [-4.5951e-02,  1.1003e-02, -9.9243e-05],\n            [-5.9685e-02, -1.0033e-01, -4.7110e-02]],\n  \n           ...,\n  \n           [[ 1.0462e-02,  1.0273e-02,  5.1620e-02],\n            [-2.6795e-02,  2.0875e-02, -5.0219e-02],\n            [-1.6426e-01, -7.4874e-02, -1.2192e-01]],\n  \n           [[-5.0368e-03,  3.4347e-02, -8.3174e-02],\n            [ 9.7084e-02,  8.0580e-02, -8.3466e-02],\n            [-5.2946e-03, -8.7937e-02,  6.9336e-02]],\n  \n           [[ 7.6833e-02, -3.7339e-02,  3.1383e-02],\n            [-4.4461e-02, -1.7069e-02,  4.0680e-02],\n            [ 5.5677e-02,  8.6088e-02, -9.6315e-02]]],\n  \n  \n          [[[ 7.4762e-02, -7.1960e-02, -2.5068e-02],\n            [ 3.5040e-02, -2.2360e-02, -4.9041e-02],\n            [-7.8669e-03,  2.9328e-02,  6.2925e-02]],\n  \n           [[ 3.2424e-02, -5.5091e-02,  4.0217e-03],\n            [ 2.4502e-02,  1.2622e-02, -1.3791e-02],\n            [ 2.5224e-02,  2.3484e-02,  2.0312e-02]],\n  \n           [[-2.2768e-02,  8.3269e-02, -3.7646e-02],\n            [-5.0028e-02,  5.5880e-02,  5.2385e-02],\n            [-1.2832e-02, -2.7209e-02,  3.0309e-02]],\n  \n           ...,\n  \n           [[ 8.0386e-02, -2.6481e-02, -3.0677e-02],\n            [-5.6881e-02,  9.4150e-03, -4.5432e-02],\n            [-6.4330e-02,  6.6453e-02, -2.4158e-03]],\n  \n           [[ 1.8041e-02, -2.0965e-02,  6.2920e-02],\n            [ 5.2443e-02, -1.3662e-01,  2.3951e-02],\n            [ 2.3993e-02, -4.7842e-02,  1.8909e-02]],\n  \n           [[-2.2260e-02, -2.1502e-02, -1.3355e-04],\n            [ 1.4345e-01, -1.4556e-03,  9.0243e-02],\n            [ 2.6895e-02, -1.3526e-02, -9.9742e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[-4.0446e-02,  4.8274e-02, -1.0063e-01],\n            [-5.6964e-02,  1.8800e-02,  6.5169e-02],\n            [ 1.3205e-01,  4.2361e-02,  4.9500e-02]],\n  \n           [[-6.9711e-02, -9.0528e-02,  5.0771e-02],\n            [-3.9869e-02,  6.1646e-03,  1.4484e-02],\n            [ 2.3159e-02, -8.5628e-03, -1.9791e-02]],\n  \n           [[-6.9742e-02, -8.4354e-02,  2.0633e-02],\n            [ 4.0481e-02, -4.6717e-02, -3.5373e-02],\n            [ 6.4515e-02,  1.0619e-01, -4.2886e-02]],\n  \n           ...,\n  \n           [[ 2.9073e-04, -9.5342e-02,  1.1611e-01],\n            [-3.4193e-02, -5.3242e-02, -6.3283e-02],\n            [-2.5843e-02,  9.4612e-03, -5.5869e-02]],\n  \n           [[ 6.6120e-02, -5.6313e-02,  1.4887e-01],\n            [-1.7104e-04, -1.5355e-02, -2.9736e-02],\n            [ 3.9859e-02,  7.0039e-02, -8.8858e-02]],\n  \n           [[-7.3081e-03,  9.9355e-03,  1.4254e-02],\n            [ 2.2108e-03, -6.6447e-02, -1.1148e-02],\n            [ 6.7862e-02, -3.3462e-02, -4.2591e-02]]],\n  \n  \n          [[[-1.3626e-02, -1.2138e-01,  5.2448e-02],\n            [-7.2336e-03,  1.5065e-02,  7.5403e-02],\n            [-1.0493e-01, -2.1835e-02, -3.9315e-03]],\n  \n           [[ 1.2141e-02, -7.1064e-02, -6.8463e-02],\n            [-6.7753e-02,  2.4702e-02, -1.7162e-01],\n            [ 8.9272e-02,  3.0368e-02, -4.8349e-02]],\n  \n           [[ 9.4632e-02, -1.1466e-02,  2.5121e-03],\n            [ 1.7472e-02,  1.3335e-02,  2.6825e-02],\n            [ 1.3707e-02, -6.1328e-02, -7.7781e-02]],\n  \n           ...,\n  \n           [[ 2.6461e-02,  5.7461e-02, -3.1987e-03],\n            [ 1.1933e-02,  3.9273e-02,  5.4511e-02],\n            [-9.3806e-02,  5.2417e-03, -1.4411e-02]],\n  \n           [[-2.6175e-02,  4.1200e-02,  5.7196e-02],\n            [-7.8570e-04, -1.5683e-02, -2.3434e-02],\n            [ 2.1435e-02,  2.2791e-02,  4.6291e-02]],\n  \n           [[-8.0804e-02,  3.7061e-02, -3.3381e-02],\n            [ 3.4563e-02, -4.9236e-02,  5.5186e-02],\n            [ 6.3069e-02, -1.0868e-01,  5.3660e-02]]],\n  \n  \n          [[[ 1.2605e-01,  6.6433e-02,  8.8640e-02],\n            [ 8.5893e-03, -3.3182e-02,  6.5961e-02],\n            [ 7.2643e-03, -1.8267e-02, -1.8358e-02]],\n  \n           [[ 2.4428e-02,  8.6418e-03, -5.2183e-04],\n            [ 6.5911e-02, -7.1729e-02, -1.8189e-02],\n            [-2.8079e-02,  2.0210e-02, -4.4632e-02]],\n  \n           [[-6.8029e-02, -8.9508e-02,  6.0479e-02],\n            [-4.0031e-02,  3.7867e-02, -8.2941e-02],\n            [-1.1101e-01,  2.2200e-02,  3.4795e-03]],\n  \n           ...,\n  \n           [[-8.1502e-04, -1.7430e-02, -1.3901e-02],\n            [-6.0020e-02, -3.3643e-02, -1.5537e-02],\n            [ 5.1050e-03,  9.4597e-02, -2.7701e-02]],\n  \n           [[-7.1083e-03,  6.4714e-02, -1.9855e-02],\n            [ 6.6565e-02,  1.0231e-01,  3.2664e-02],\n            [-9.1783e-02,  6.9543e-02, -2.8385e-02]],\n  \n           [[ 1.5205e-02,  9.6691e-02,  4.7726e-02],\n            [-2.0648e-02, -8.0649e-02, -1.5861e-01],\n            [-3.9811e-02,  7.8259e-02,  2.6619e-02]]]], requires_grad=True)),\n ('layer1.2.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.2.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.2.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0306]],\n  \n           [[ 0.0725]],\n  \n           [[ 0.0381]],\n  \n           ...,\n  \n           [[ 0.0420]],\n  \n           [[ 0.0278]],\n  \n           [[ 0.0542]]],\n  \n  \n          [[[ 0.0608]],\n  \n           [[ 0.0121]],\n  \n           [[ 0.0613]],\n  \n           ...,\n  \n           [[ 0.0566]],\n  \n           [[-0.0026]],\n  \n           [[-0.1931]]],\n  \n  \n          [[[-0.0136]],\n  \n           [[-0.1026]],\n  \n           [[ 0.0474]],\n  \n           ...,\n  \n           [[ 0.1794]],\n  \n           [[-0.0550]],\n  \n           [[ 0.0323]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0182]],\n  \n           [[-0.0238]],\n  \n           [[ 0.0016]],\n  \n           ...,\n  \n           [[ 0.0263]],\n  \n           [[ 0.0003]],\n  \n           [[ 0.0154]]],\n  \n  \n          [[[ 0.0377]],\n  \n           [[ 0.1148]],\n  \n           [[ 0.1470]],\n  \n           ...,\n  \n           [[ 0.1437]],\n  \n           [[-0.0267]],\n  \n           [[-0.3001]]],\n  \n  \n          [[[-0.1186]],\n  \n           [[ 0.1915]],\n  \n           [[-0.1796]],\n  \n           ...,\n  \n           [[-0.1408]],\n  \n           [[ 0.1165]],\n  \n           [[ 0.0756]]]], requires_grad=True)),\n ('layer1.2.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.2.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer2.0.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0222]],\n  \n           [[ 0.2770]],\n  \n           [[ 0.1094]],\n  \n           ...,\n  \n           [[ 0.1907]],\n  \n           [[-0.0701]],\n  \n           [[-0.1194]]],\n  \n  \n          [[[-0.0121]],\n  \n           [[ 0.0138]],\n  \n           [[ 0.2060]],\n  \n           ...,\n  \n           [[-0.2114]],\n  \n           [[ 0.0572]],\n  \n           [[-0.0050]]],\n  \n  \n          [[[ 0.1011]],\n  \n           [[-0.1271]],\n  \n           [[-0.1459]],\n  \n           ...,\n  \n           [[-0.1627]],\n  \n           [[-0.1899]],\n  \n           [[ 0.1883]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0880]],\n  \n           [[ 0.1103]],\n  \n           [[-0.0390]],\n  \n           ...,\n  \n           [[-0.1149]],\n  \n           [[-0.0555]],\n  \n           [[-0.1955]]],\n  \n  \n          [[[ 0.1186]],\n  \n           [[ 0.1267]],\n  \n           [[ 0.0955]],\n  \n           ...,\n  \n           [[ 0.0880]],\n  \n           [[ 0.0887]],\n  \n           [[-0.2007]]],\n  \n  \n          [[[ 0.0411]],\n  \n           [[ 0.0024]],\n  \n           [[ 0.1000]],\n  \n           ...,\n  \n           [[-0.0377]],\n  \n           [[-0.0060]],\n  \n           [[-0.0530]]]], requires_grad=True)),\n ('layer2.0.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.0.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.0.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 0.0459, -0.0034, -0.0008],\n            [-0.0396, -0.0395,  0.0005],\n            [-0.0316, -0.0243, -0.0672]],\n  \n           [[ 0.0192, -0.0147,  0.0301],\n            [ 0.1093,  0.0164,  0.0399],\n            [ 0.0598,  0.0002,  0.0135]],\n  \n           [[ 0.0201,  0.0344,  0.0135],\n            [ 0.0144, -0.0456,  0.0735],\n            [-0.0339,  0.0573,  0.0477]],\n  \n           ...,\n  \n           [[ 0.0435, -0.0236, -0.0284],\n            [ 0.0211,  0.0043,  0.0005],\n            [-0.0228, -0.0126,  0.0513]],\n  \n           [[ 0.0647, -0.0524, -0.0100],\n            [ 0.0410,  0.0557,  0.0147],\n            [-0.0017,  0.0921,  0.0840]],\n  \n           [[ 0.0164,  0.1197, -0.0890],\n            [-0.0572, -0.0042, -0.0885],\n            [-0.0037,  0.0158, -0.0699]]],\n  \n  \n          [[[ 0.0265,  0.0215, -0.0373],\n            [ 0.0767,  0.0298,  0.0485],\n            [ 0.0372, -0.0689, -0.0186]],\n  \n           [[-0.0938,  0.0625,  0.0155],\n            [ 0.0498,  0.0062,  0.0048],\n            [-0.0567,  0.0217, -0.0220]],\n  \n           [[ 0.0081, -0.0235,  0.0215],\n            [-0.0356, -0.0169, -0.0391],\n            [ 0.0068,  0.0768,  0.0498]],\n  \n           ...,\n  \n           [[-0.0472,  0.0282,  0.0278],\n            [-0.0012, -0.0464,  0.0440],\n            [ 0.0007, -0.0512,  0.0297]],\n  \n           [[-0.0236,  0.0265,  0.0195],\n            [-0.0392, -0.0330,  0.0327],\n            [-0.0023,  0.0147,  0.0240]],\n  \n           [[ 0.0101,  0.0304, -0.0005],\n            [ 0.0485, -0.0303, -0.0300],\n            [-0.0166, -0.0461,  0.0785]]],\n  \n  \n          [[[-0.0284,  0.0963,  0.0404],\n            [-0.0235, -0.0824, -0.0377],\n            [-0.0293, -0.0681, -0.0122]],\n  \n           [[ 0.0284, -0.0063,  0.0279],\n            [ 0.0388, -0.0102, -0.0715],\n            [-0.0182, -0.0489, -0.0375]],\n  \n           [[-0.0382, -0.0039,  0.0391],\n            [ 0.0471, -0.0328, -0.0249],\n            [ 0.0348,  0.0374,  0.0814]],\n  \n           ...,\n  \n           [[-0.0059,  0.0133,  0.0117],\n            [ 0.0089,  0.0103, -0.0292],\n            [-0.0197, -0.0197, -0.0087]],\n  \n           [[ 0.0375, -0.0097, -0.0687],\n            [-0.0213,  0.0612,  0.0328],\n            [-0.0070, -0.0330, -0.0250]],\n  \n           [[-0.0470, -0.0106, -0.0020],\n            [-0.0389,  0.0292,  0.0454],\n            [ 0.0285,  0.0224,  0.0723]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0314, -0.0212, -0.0029],\n            [ 0.0197,  0.0302, -0.0148],\n            [ 0.0212, -0.0400,  0.0698]],\n  \n           [[ 0.0419,  0.0249,  0.0140],\n            [ 0.0248,  0.0332, -0.0442],\n            [ 0.0208,  0.0679, -0.0792]],\n  \n           [[ 0.0793, -0.0401, -0.0305],\n            [ 0.0447,  0.0551,  0.0005],\n            [-0.0061,  0.0462, -0.0102]],\n  \n           ...,\n  \n           [[-0.0075,  0.0076, -0.0007],\n            [-0.0213, -0.0259, -0.0432],\n            [ 0.0091, -0.0829, -0.0728]],\n  \n           [[ 0.0095, -0.0104,  0.0188],\n            [-0.0384,  0.0506, -0.0284],\n            [-0.0421,  0.0226, -0.0147]],\n  \n           [[-0.0179,  0.0427,  0.0326],\n            [-0.0329, -0.1014,  0.0071],\n            [-0.0402,  0.0005,  0.0096]]],\n  \n  \n          [[[-0.0064,  0.0191, -0.0647],\n            [-0.0410, -0.0393,  0.0005],\n            [-0.0262,  0.0384,  0.0445]],\n  \n           [[ 0.0269, -0.0841,  0.0206],\n            [ 0.0238, -0.0238, -0.0691],\n            [ 0.0919,  0.0441, -0.0491]],\n  \n           [[ 0.0330, -0.0181,  0.0003],\n            [-0.0159, -0.0187, -0.0862],\n            [ 0.0613,  0.0316,  0.0280]],\n  \n           ...,\n  \n           [[-0.0695,  0.0080,  0.0633],\n            [-0.0551, -0.0281, -0.0252],\n            [ 0.0252,  0.1216,  0.0565]],\n  \n           [[-0.0836, -0.0271, -0.0065],\n            [-0.0389,  0.0459, -0.0051],\n            [-0.0039,  0.0881, -0.0274]],\n  \n           [[-0.0313,  0.0383,  0.0551],\n            [-0.0350, -0.0206,  0.0670],\n            [-0.0388, -0.0122, -0.0261]]],\n  \n  \n          [[[ 0.0081, -0.0048,  0.0090],\n            [ 0.0304,  0.0288, -0.0414],\n            [ 0.1180,  0.0236, -0.0033]],\n  \n           [[-0.0795,  0.0286,  0.0035],\n            [-0.0153, -0.0263,  0.0210],\n            [ 0.0239,  0.0126, -0.0494]],\n  \n           [[ 0.0545,  0.0846, -0.0489],\n            [-0.0914,  0.0092,  0.0175],\n            [ 0.0086, -0.0188, -0.0282]],\n  \n           ...,\n  \n           [[-0.0406, -0.0584,  0.0323],\n            [ 0.0215,  0.0307,  0.0278],\n            [-0.0338, -0.0218, -0.0216]],\n  \n           [[-0.0008,  0.0049,  0.0406],\n            [-0.0054, -0.0384, -0.0151],\n            [ 0.0143,  0.0061,  0.0194]],\n  \n           [[-0.0364,  0.0218, -0.0532],\n            [ 0.0114, -0.0278,  0.0892],\n            [ 0.0109,  0.0297, -0.0421]]]], requires_grad=True)),\n ('layer2.0.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.0.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.0.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0322]],\n  \n           [[-0.0207]],\n  \n           [[ 0.0017]],\n  \n           ...,\n  \n           [[-0.0589]],\n  \n           [[-0.0791]],\n  \n           [[ 0.0407]]],\n  \n  \n          [[[-0.0468]],\n  \n           [[-0.1143]],\n  \n           [[-0.0532]],\n  \n           ...,\n  \n           [[ 0.0797]],\n  \n           [[ 0.0507]],\n  \n           [[ 0.0112]]],\n  \n  \n          [[[-0.0296]],\n  \n           [[ 0.1012]],\n  \n           [[-0.0236]],\n  \n           ...,\n  \n           [[ 0.0637]],\n  \n           [[ 0.0361]],\n  \n           [[-0.0102]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0948]],\n  \n           [[ 0.0369]],\n  \n           [[ 0.0102]],\n  \n           ...,\n  \n           [[ 0.0161]],\n  \n           [[-0.0379]],\n  \n           [[-0.0404]]],\n  \n  \n          [[[-0.0224]],\n  \n           [[-0.0473]],\n  \n           [[ 0.0513]],\n  \n           ...,\n  \n           [[-0.0477]],\n  \n           [[ 0.1113]],\n  \n           [[-0.0506]]],\n  \n  \n          [[[ 0.0291]],\n  \n           [[-0.0379]],\n  \n           [[-0.0768]],\n  \n           ...,\n  \n           [[ 0.0835]],\n  \n           [[ 0.0320]],\n  \n           [[ 0.0158]]]], requires_grad=True)),\n ('layer2.0.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.0.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.0.downsample.0.weight',\n  Parameter containing:\n  tensor([[[[ 0.0449]],\n  \n           [[-0.0063]],\n  \n           [[ 0.0182]],\n  \n           ...,\n  \n           [[-0.1253]],\n  \n           [[ 0.1364]],\n  \n           [[-0.0247]]],\n  \n  \n          [[[-0.0724]],\n  \n           [[ 0.0317]],\n  \n           [[ 0.0669]],\n  \n           ...,\n  \n           [[ 0.0403]],\n  \n           [[-0.0421]],\n  \n           [[-0.0267]]],\n  \n  \n          [[[-0.0560]],\n  \n           [[ 0.0098]],\n  \n           [[-0.0215]],\n  \n           ...,\n  \n           [[-0.1559]],\n  \n           [[-0.0150]],\n  \n           [[ 0.0436]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.1543]],\n  \n           [[ 0.0630]],\n  \n           [[ 0.0007]],\n  \n           ...,\n  \n           [[ 0.0226]],\n  \n           [[ 0.0238]],\n  \n           [[ 0.0149]]],\n  \n  \n          [[[ 0.0068]],\n  \n           [[-0.0364]],\n  \n           [[ 0.1170]],\n  \n           ...,\n  \n           [[-0.1112]],\n  \n           [[-0.0013]],\n  \n           [[-0.0032]]],\n  \n  \n          [[[-0.1066]],\n  \n           [[-0.0325]],\n  \n           [[-0.0539]],\n  \n           ...,\n  \n           [[ 0.0266]],\n  \n           [[ 0.0531]],\n  \n           [[-0.0026]]]], requires_grad=True)),\n ('layer2.0.downsample.1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer2.0.downsample.1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.1.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.1880]],\n  \n           [[-0.0538]],\n  \n           [[-0.2180]],\n  \n           ...,\n  \n           [[-0.1800]],\n  \n           [[-0.0178]],\n  \n           [[-0.1162]]],\n  \n  \n          [[[-0.1225]],\n  \n           [[ 0.2978]],\n  \n           [[ 0.1373]],\n  \n           ...,\n  \n           [[ 0.2007]],\n  \n           [[-0.0082]],\n  \n           [[-0.0192]]],\n  \n  \n          [[[-0.0777]],\n  \n           [[-0.0042]],\n  \n           [[-0.0100]],\n  \n           ...,\n  \n           [[-0.0537]],\n  \n           [[-0.2876]],\n  \n           [[-0.1438]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0339]],\n  \n           [[-0.1204]],\n  \n           [[ 0.0436]],\n  \n           ...,\n  \n           [[ 0.0552]],\n  \n           [[ 0.0879]],\n  \n           [[-0.0777]]],\n  \n  \n          [[[ 0.0013]],\n  \n           [[ 0.0958]],\n  \n           [[-0.0824]],\n  \n           ...,\n  \n           [[ 0.0171]],\n  \n           [[-0.2543]],\n  \n           [[-0.2877]]],\n  \n  \n          [[[ 0.0900]],\n  \n           [[-0.0857]],\n  \n           [[-0.0475]],\n  \n           ...,\n  \n           [[-0.0014]],\n  \n           [[ 0.0152]],\n  \n           [[-0.1122]]]], requires_grad=True)),\n ('layer2.1.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.1.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.1.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 0.0697, -0.0207,  0.0424],\n            [-0.0059,  0.0507, -0.0814],\n            [-0.0417, -0.0154,  0.0132]],\n  \n           [[-0.0258, -0.0465, -0.0457],\n            [ 0.0372, -0.0680, -0.0374],\n            [-0.0301, -0.0081, -0.0351]],\n  \n           [[-0.0193, -0.0110, -0.0002],\n            [-0.0390,  0.0357,  0.0522],\n            [-0.0389,  0.0299,  0.0367]],\n  \n           ...,\n  \n           [[-0.1265, -0.0454, -0.0114],\n            [ 0.0473,  0.0496, -0.0003],\n            [-0.0332,  0.0307, -0.0427]],\n  \n           [[-0.0225, -0.0058, -0.0834],\n            [ 0.0620,  0.0053, -0.0505],\n            [ 0.0710, -0.0108,  0.0254]],\n  \n           [[-0.0273, -0.0076, -0.0290],\n            [ 0.0241,  0.0014,  0.0442],\n            [-0.0790, -0.0174, -0.0151]]],\n  \n  \n          [[[-0.0019,  0.0191, -0.0472],\n            [ 0.0267,  0.0205,  0.0074],\n            [ 0.0248,  0.0130, -0.0469]],\n  \n           [[-0.0381, -0.0643,  0.0027],\n            [ 0.0258,  0.0631, -0.0204],\n            [-0.0046,  0.0454,  0.0085]],\n  \n           [[ 0.0311,  0.0633,  0.0191],\n            [-0.0072,  0.0212, -0.0019],\n            [-0.0466,  0.0196,  0.0286]],\n  \n           ...,\n  \n           [[-0.0078,  0.0295, -0.0582],\n            [ 0.0045,  0.0275, -0.0264],\n            [-0.0286,  0.0302, -0.0584]],\n  \n           [[ 0.0498,  0.0007, -0.0533],\n            [ 0.0945,  0.0666, -0.0047],\n            [ 0.1063,  0.0066,  0.0272]],\n  \n           [[ 0.0832, -0.0737,  0.0477],\n            [ 0.0309,  0.0125,  0.0192],\n            [ 0.0421, -0.0530,  0.0883]]],\n  \n  \n          [[[ 0.0365, -0.0164, -0.0016],\n            [ 0.0158, -0.0202,  0.0894],\n            [ 0.1136, -0.0163,  0.0893]],\n  \n           [[-0.0863, -0.0738, -0.0006],\n            [-0.0699,  0.0486,  0.0100],\n            [ 0.0218,  0.0386, -0.0201]],\n  \n           [[-0.0002, -0.0538, -0.0078],\n            [-0.0222,  0.0270,  0.0419],\n            [ 0.0388,  0.0020,  0.0384]],\n  \n           ...,\n  \n           [[ 0.0267, -0.0315, -0.0036],\n            [-0.0022, -0.0926, -0.0231],\n            [ 0.0106, -0.0011, -0.0009]],\n  \n           [[-0.0474, -0.0170,  0.0376],\n            [-0.0174,  0.0227, -0.0525],\n            [-0.0545,  0.0113,  0.0588]],\n  \n           [[ 0.0293, -0.0805,  0.0377],\n            [-0.0455, -0.0063,  0.0448],\n            [ 0.0345,  0.0225,  0.0062]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0295, -0.0362, -0.0464],\n            [ 0.0396, -0.0192,  0.0273],\n            [ 0.0292, -0.0852, -0.0028]],\n  \n           [[-0.0506, -0.0345, -0.0019],\n            [-0.0079, -0.1070,  0.0582],\n            [ 0.0787,  0.0382, -0.0125]],\n  \n           [[-0.0539,  0.0216, -0.0077],\n            [ 0.0373, -0.0785,  0.0263],\n            [ 0.0144, -0.0461, -0.0421]],\n  \n           ...,\n  \n           [[-0.0006, -0.0576, -0.0467],\n            [ 0.1064,  0.0119,  0.0112],\n            [ 0.0612,  0.0200,  0.0106]],\n  \n           [[-0.0252,  0.0513, -0.0062],\n            [ 0.0400, -0.0129, -0.0335],\n            [-0.0027, -0.0090, -0.0146]],\n  \n           [[-0.0305, -0.0492, -0.0475],\n            [ 0.0320,  0.0528, -0.0613],\n            [-0.0368, -0.0261,  0.0014]]],\n  \n  \n          [[[-0.0793, -0.0052,  0.0399],\n            [-0.0179, -0.0864, -0.0072],\n            [-0.0391,  0.0013, -0.0240]],\n  \n           [[-0.0257,  0.0225,  0.0207],\n            [-0.0646, -0.0004,  0.0172],\n            [-0.0188,  0.0042, -0.0151]],\n  \n           [[-0.0744,  0.0360, -0.0780],\n            [ 0.0219, -0.0330, -0.0226],\n            [ 0.0457, -0.0446,  0.0450]],\n  \n           ...,\n  \n           [[-0.0271,  0.0807, -0.0412],\n            [ 0.0576,  0.0096,  0.0036],\n            [ 0.0467,  0.0229, -0.0051]],\n  \n           [[ 0.0264, -0.0025,  0.0217],\n            [-0.0352,  0.0220,  0.0567],\n            [-0.0093, -0.0367,  0.0265]],\n  \n           [[ 0.0039,  0.0721,  0.0782],\n            [-0.0299, -0.0014, -0.0043],\n            [-0.0312,  0.0334,  0.0384]]],\n  \n  \n          [[[ 0.0109, -0.0010,  0.0662],\n            [ 0.0110, -0.0225,  0.0210],\n            [-0.0561,  0.0550,  0.0840]],\n  \n           [[-0.0490,  0.0154, -0.0172],\n            [-0.0187,  0.0792, -0.0032],\n            [-0.0927,  0.0010, -0.0085]],\n  \n           [[ 0.0193, -0.0105,  0.0865],\n            [ 0.0297,  0.0200,  0.0195],\n            [ 0.0324, -0.0830,  0.0709]],\n  \n           ...,\n  \n           [[ 0.1229, -0.0067,  0.0117],\n            [-0.0083, -0.0332,  0.0481],\n            [ 0.0130, -0.0207,  0.0043]],\n  \n           [[-0.0346, -0.0098, -0.0292],\n            [ 0.0550, -0.0351,  0.0193],\n            [-0.0082, -0.0281,  0.0923]],\n  \n           [[ 0.0032,  0.0028, -0.0271],\n            [-0.0214,  0.0660, -0.0070],\n            [-0.0941,  0.0405, -0.0653]]]], requires_grad=True)),\n ('layer2.1.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.1.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.1.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0560]],\n  \n           [[-0.1670]],\n  \n           [[-0.0752]],\n  \n           ...,\n  \n           [[ 0.1228]],\n  \n           [[ 0.0277]],\n  \n           [[-0.0409]]],\n  \n  \n          [[[ 0.1189]],\n  \n           [[-0.0691]],\n  \n           [[ 0.1002]],\n  \n           ...,\n  \n           [[-0.0274]],\n  \n           [[ 0.0465]],\n  \n           [[ 0.0040]]],\n  \n  \n          [[[-0.0044]],\n  \n           [[ 0.1422]],\n  \n           [[ 0.1064]],\n  \n           ...,\n  \n           [[-0.0558]],\n  \n           [[ 0.0187]],\n  \n           [[-0.0482]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0750]],\n  \n           [[-0.0004]],\n  \n           [[ 0.0955]],\n  \n           ...,\n  \n           [[-0.0196]],\n  \n           [[ 0.1160]],\n  \n           [[ 0.0207]]],\n  \n  \n          [[[-0.0193]],\n  \n           [[ 0.0702]],\n  \n           [[ 0.0392]],\n  \n           ...,\n  \n           [[ 0.0019]],\n  \n           [[ 0.0543]],\n  \n           [[ 0.0146]]],\n  \n  \n          [[[ 0.0219]],\n  \n           [[ 0.1291]],\n  \n           [[ 0.0310]],\n  \n           ...,\n  \n           [[-0.0031]],\n  \n           [[-0.0277]],\n  \n           [[-0.0419]]]], requires_grad=True)),\n ('layer2.1.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.1.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.2.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0384]],\n  \n           [[ 0.1299]],\n  \n           [[ 0.0837]],\n  \n           ...,\n  \n           [[ 0.0894]],\n  \n           [[-0.0530]],\n  \n           [[ 0.0014]]],\n  \n  \n          [[[ 0.0026]],\n  \n           [[-0.1249]],\n  \n           [[-0.1714]],\n  \n           ...,\n  \n           [[-0.0187]],\n  \n           [[ 0.0268]],\n  \n           [[ 0.0785]]],\n  \n  \n          [[[ 0.0553]],\n  \n           [[-0.0484]],\n  \n           [[-0.0217]],\n  \n           ...,\n  \n           [[-0.0288]],\n  \n           [[ 0.0248]],\n  \n           [[-0.0360]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0118]],\n  \n           [[ 0.0336]],\n  \n           [[-0.0985]],\n  \n           ...,\n  \n           [[ 0.1601]],\n  \n           [[-0.0942]],\n  \n           [[-0.1221]]],\n  \n  \n          [[[-0.2731]],\n  \n           [[-0.0064]],\n  \n           [[ 0.1716]],\n  \n           ...,\n  \n           [[ 0.0496]],\n  \n           [[-0.0848]],\n  \n           [[-0.2240]]],\n  \n  \n          [[[ 0.0347]],\n  \n           [[-0.0766]],\n  \n           [[-0.1705]],\n  \n           ...,\n  \n           [[-0.1784]],\n  \n           [[ 0.2293]],\n  \n           [[ 0.0554]]]], requires_grad=True)),\n ('layer2.2.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.2.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.2.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 0.0283, -0.0086, -0.0251],\n            [ 0.0379,  0.0064, -0.0373],\n            [ 0.0057,  0.0254,  0.0114]],\n  \n           [[-0.0042,  0.0328,  0.0400],\n            [-0.0651, -0.0091, -0.0554],\n            [ 0.0600,  0.0040, -0.0140]],\n  \n           [[-0.0101,  0.0116, -0.0645],\n            [ 0.0504, -0.0051,  0.0361],\n            [-0.0397,  0.0335,  0.0076]],\n  \n           ...,\n  \n           [[-0.0962, -0.0075,  0.0111],\n            [ 0.0313, -0.1087,  0.0211],\n            [-0.0724,  0.0631, -0.0254]],\n  \n           [[-0.0311,  0.0312, -0.0380],\n            [-0.0102,  0.0101,  0.0551],\n            [ 0.0347,  0.0022,  0.0444]],\n  \n           [[ 0.0020,  0.0667,  0.0252],\n            [-0.0106, -0.0077, -0.0387],\n            [-0.0065,  0.0677, -0.0109]]],\n  \n  \n          [[[-0.0504,  0.0417, -0.0186],\n            [-0.0630,  0.0230,  0.0427],\n            [-0.0606,  0.0079, -0.0260]],\n  \n           [[ 0.1051, -0.0155,  0.0787],\n            [ 0.0057, -0.0031,  0.0214],\n            [-0.0173,  0.0480, -0.0346]],\n  \n           [[ 0.0376, -0.0142, -0.0480],\n            [ 0.0172, -0.0145, -0.0020],\n            [-0.0701, -0.0420, -0.0118]],\n  \n           ...,\n  \n           [[-0.0969, -0.0152, -0.0184],\n            [ 0.0343, -0.0159,  0.0073],\n            [ 0.0414,  0.0106,  0.0629]],\n  \n           [[-0.0123, -0.0211, -0.0688],\n            [ 0.0630, -0.0037, -0.0073],\n            [ 0.0103, -0.0098, -0.0576]],\n  \n           [[ 0.0090, -0.1192,  0.0524],\n            [-0.0284, -0.0032,  0.0520],\n            [-0.0287, -0.0519, -0.0449]]],\n  \n  \n          [[[ 0.0029, -0.0154, -0.0670],\n            [-0.0440,  0.0343, -0.0365],\n            [ 0.0011, -0.0143,  0.0193]],\n  \n           [[-0.0285, -0.0358, -0.0228],\n            [ 0.0019,  0.0353,  0.0193],\n            [ 0.0438, -0.0138, -0.0229]],\n  \n           [[-0.0375,  0.0184,  0.0193],\n            [ 0.0020,  0.0197, -0.0362],\n            [-0.0333,  0.0209, -0.0349]],\n  \n           ...,\n  \n           [[-0.0027, -0.0524, -0.0370],\n            [-0.0046,  0.0526, -0.0067],\n            [ 0.0699, -0.0392,  0.0017]],\n  \n           [[ 0.0294,  0.0721,  0.0472],\n            [ 0.1187,  0.0225,  0.0294],\n            [ 0.0083, -0.0029,  0.0037]],\n  \n           [[ 0.0320, -0.0643,  0.0195],\n            [ 0.0228, -0.0562,  0.0468],\n            [ 0.0328,  0.0985,  0.0232]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0738, -0.0710,  0.0809],\n            [-0.0434, -0.0367,  0.0057],\n            [-0.0123, -0.0829, -0.0476]],\n  \n           [[ 0.0291,  0.0154,  0.0456],\n            [ 0.0028,  0.0174, -0.0142],\n            [-0.0321, -0.0878, -0.0010]],\n  \n           [[-0.0370,  0.0556, -0.1078],\n            [ 0.0193, -0.0553, -0.0638],\n            [ 0.0655,  0.0499, -0.0274]],\n  \n           ...,\n  \n           [[ 0.0242,  0.0300,  0.0074],\n            [ 0.0274,  0.1339, -0.0017],\n            [-0.0769,  0.0013, -0.0217]],\n  \n           [[-0.0350, -0.0242, -0.0117],\n            [ 0.0550,  0.0094, -0.0628],\n            [-0.0487, -0.0520,  0.0693]],\n  \n           [[-0.0263, -0.0601,  0.0016],\n            [ 0.0156,  0.0512, -0.0267],\n            [-0.0325,  0.0731,  0.0257]]],\n  \n  \n          [[[ 0.0271,  0.0446,  0.1001],\n            [-0.0054, -0.0047, -0.0456],\n            [ 0.0371, -0.0517,  0.1276]],\n  \n           [[-0.0575,  0.0331, -0.0117],\n            [-0.0017, -0.0364, -0.0445],\n            [ 0.0034,  0.0205, -0.0380]],\n  \n           [[-0.0173,  0.0739, -0.0237],\n            [-0.0091,  0.0360, -0.0104],\n            [-0.0084,  0.0452,  0.0560]],\n  \n           ...,\n  \n           [[ 0.0254,  0.0016, -0.0377],\n            [ 0.0135,  0.0478, -0.0337],\n            [-0.0415,  0.0179,  0.0147]],\n  \n           [[ 0.0534,  0.0890,  0.0614],\n            [ 0.0066, -0.0319,  0.0080],\n            [ 0.0287, -0.1043,  0.0457]],\n  \n           [[-0.0073,  0.0077, -0.0046],\n            [-0.0071, -0.0004, -0.0222],\n            [ 0.0181,  0.0302, -0.0201]]],\n  \n  \n          [[[-0.0232,  0.0041, -0.0263],\n            [-0.0091, -0.0048, -0.0287],\n            [ 0.0334,  0.0379,  0.0182]],\n  \n           [[-0.0761, -0.0387,  0.0591],\n            [-0.0179, -0.0439,  0.0401],\n            [ 0.0172, -0.0011,  0.0724]],\n  \n           [[-0.0144, -0.0295, -0.0064],\n            [ 0.0074,  0.0074, -0.0048],\n            [ 0.0519, -0.0245, -0.0054]],\n  \n           ...,\n  \n           [[ 0.0578, -0.0086, -0.0474],\n            [ 0.1343,  0.0067,  0.0305],\n            [ 0.0289, -0.0083,  0.0291]],\n  \n           [[ 0.0026,  0.0274,  0.0551],\n            [-0.0163, -0.0592,  0.0110],\n            [-0.0158,  0.0292, -0.0385]],\n  \n           [[-0.0391, -0.0098,  0.0770],\n            [-0.0342, -0.0147,  0.0069],\n            [-0.0116,  0.0462,  0.0754]]]], requires_grad=True)),\n ('layer2.2.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.2.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.2.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0363]],\n  \n           [[ 0.0423]],\n  \n           [[ 0.0530]],\n  \n           ...,\n  \n           [[-0.1036]],\n  \n           [[ 0.0047]],\n  \n           [[-0.0443]]],\n  \n  \n          [[[ 0.1291]],\n  \n           [[-0.0241]],\n  \n           [[-0.0485]],\n  \n           ...,\n  \n           [[-0.0795]],\n  \n           [[ 0.0691]],\n  \n           [[ 0.0883]]],\n  \n  \n          [[[-0.0461]],\n  \n           [[ 0.0429]],\n  \n           [[-0.0257]],\n  \n           ...,\n  \n           [[-0.1092]],\n  \n           [[-0.0334]],\n  \n           [[ 0.0070]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0474]],\n  \n           [[-0.0008]],\n  \n           [[-0.0384]],\n  \n           ...,\n  \n           [[-0.0271]],\n  \n           [[ 0.0627]],\n  \n           [[-0.0937]]],\n  \n  \n          [[[-0.0280]],\n  \n           [[-0.0236]],\n  \n           [[ 0.0240]],\n  \n           ...,\n  \n           [[-0.0514]],\n  \n           [[-0.1152]],\n  \n           [[ 0.0925]]],\n  \n  \n          [[[-0.0773]],\n  \n           [[-0.0597]],\n  \n           [[-0.0563]],\n  \n           ...,\n  \n           [[-0.0086]],\n  \n           [[ 0.0817]],\n  \n           [[-0.0288]]]], requires_grad=True)),\n ('layer2.2.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.2.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.3.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.1351]],\n  \n           [[-0.0165]],\n  \n           [[ 0.0364]],\n  \n           ...,\n  \n           [[ 0.1438]],\n  \n           [[ 0.1376]],\n  \n           [[ 0.0278]]],\n  \n  \n          [[[-0.0258]],\n  \n           [[-0.1271]],\n  \n           [[-0.0459]],\n  \n           ...,\n  \n           [[-0.0265]],\n  \n           [[-0.0015]],\n  \n           [[ 0.0292]]],\n  \n  \n          [[[ 0.0698]],\n  \n           [[ 0.0084]],\n  \n           [[ 0.0487]],\n  \n           ...,\n  \n           [[ 0.1092]],\n  \n           [[-0.0199]],\n  \n           [[-0.0309]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0391]],\n  \n           [[-0.0047]],\n  \n           [[ 0.0156]],\n  \n           ...,\n  \n           [[-0.1524]],\n  \n           [[-0.0501]],\n  \n           [[ 0.0380]]],\n  \n  \n          [[[ 0.0221]],\n  \n           [[ 0.1337]],\n  \n           [[ 0.0129]],\n  \n           ...,\n  \n           [[ 0.0332]],\n  \n           [[-0.0457]],\n  \n           [[ 0.0148]]],\n  \n  \n          [[[ 0.2395]],\n  \n           [[-0.0683]],\n  \n           [[-0.1396]],\n  \n           ...,\n  \n           [[-0.1805]],\n  \n           [[-0.1780]],\n  \n           [[ 0.1194]]]], requires_grad=True)),\n ('layer2.3.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.3.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.3.conv2.weight',\n  Parameter containing:\n  tensor([[[[-0.0073,  0.0520,  0.0548],\n            [ 0.0040,  0.0403,  0.0211],\n            [-0.0578,  0.0497,  0.0180]],\n  \n           [[ 0.0189,  0.0223,  0.0626],\n            [ 0.0312,  0.0362,  0.0353],\n            [-0.0422, -0.0257, -0.0790]],\n  \n           [[-0.0327, -0.0641, -0.0637],\n            [-0.0511, -0.0103,  0.0735],\n            [ 0.0605,  0.0090, -0.0300]],\n  \n           ...,\n  \n           [[-0.0444,  0.0627,  0.0221],\n            [-0.0393,  0.0187,  0.0006],\n            [-0.0093,  0.0199, -0.0565]],\n  \n           [[-0.0045,  0.0320,  0.0038],\n            [ 0.0013, -0.0049, -0.0257],\n            [-0.0081,  0.0301,  0.0079]],\n  \n           [[ 0.0277, -0.0151,  0.0886],\n            [-0.0095,  0.0878,  0.0358],\n            [ 0.0305, -0.0608, -0.0559]]],\n  \n  \n          [[[ 0.0010,  0.0141, -0.0225],\n            [-0.0602,  0.0477, -0.0099],\n            [ 0.0131,  0.0205, -0.0037]],\n  \n           [[-0.0206, -0.0359, -0.0222],\n            [-0.0702, -0.0584,  0.0468],\n            [ 0.0012, -0.0727,  0.0528]],\n  \n           [[-0.0695,  0.0403, -0.0044],\n            [ 0.0875,  0.0189, -0.0036],\n            [ 0.0501,  0.0033, -0.0536]],\n  \n           ...,\n  \n           [[ 0.0326,  0.0822, -0.0254],\n            [ 0.0017,  0.0460, -0.0290],\n            [-0.0508,  0.0129, -0.0162]],\n  \n           [[-0.0657, -0.0051, -0.0715],\n            [-0.0045, -0.0377, -0.0350],\n            [-0.0570, -0.0265, -0.0569]],\n  \n           [[ 0.0020, -0.0142, -0.0388],\n            [ 0.0353, -0.0005, -0.0785],\n            [ 0.0823,  0.0712,  0.0533]]],\n  \n  \n          [[[ 0.0128, -0.0433,  0.0540],\n            [-0.0595,  0.0259, -0.0504],\n            [-0.0454, -0.0084, -0.0523]],\n  \n           [[-0.0467, -0.0532, -0.0509],\n            [-0.0811,  0.0432, -0.0183],\n            [ 0.0647,  0.0472, -0.0170]],\n  \n           [[ 0.0592, -0.0101,  0.0119],\n            [-0.0629,  0.0740, -0.0644],\n            [-0.0277, -0.0129,  0.0175]],\n  \n           ...,\n  \n           [[-0.0039,  0.0180,  0.0230],\n            [ 0.0606, -0.0631, -0.0547],\n            [ 0.0126,  0.0264, -0.0034]],\n  \n           [[ 0.0862, -0.0133,  0.0045],\n            [-0.0723, -0.0645,  0.0223],\n            [-0.0339,  0.0375,  0.0730]],\n  \n           [[ 0.0141,  0.0063,  0.0485],\n            [ 0.0263,  0.0067, -0.0128],\n            [-0.0127, -0.0401,  0.0715]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0315, -0.0157, -0.0132],\n            [ 0.0126, -0.0006, -0.0056],\n            [ 0.0032, -0.0068,  0.0433]],\n  \n           [[ 0.0019,  0.0576,  0.0565],\n            [ 0.0407, -0.0128,  0.0261],\n            [-0.0354,  0.0435, -0.0025]],\n  \n           [[ 0.0320, -0.0250, -0.0632],\n            [-0.0817, -0.0318, -0.0892],\n            [ 0.0732,  0.0240, -0.0044]],\n  \n           ...,\n  \n           [[ 0.0030, -0.0015,  0.0322],\n            [-0.0061,  0.0394, -0.0152],\n            [ 0.0132,  0.0190,  0.0827]],\n  \n           [[-0.0328,  0.0581, -0.1011],\n            [-0.0410,  0.0429,  0.0073],\n            [ 0.0265, -0.0546, -0.0213]],\n  \n           [[-0.0333,  0.0039, -0.0616],\n            [-0.0069, -0.0302,  0.1083],\n            [ 0.0170,  0.0722,  0.0251]]],\n  \n  \n          [[[-0.0253,  0.0277,  0.0622],\n            [-0.0139,  0.0313,  0.0236],\n            [ 0.0577, -0.0536, -0.0909]],\n  \n           [[-0.0404,  0.0462,  0.0667],\n            [-0.0343, -0.0044, -0.0513],\n            [ 0.0028, -0.0044,  0.0319]],\n  \n           [[-0.0820, -0.0195,  0.0255],\n            [ 0.0844,  0.0114, -0.0194],\n            [-0.0471, -0.0683, -0.0249]],\n  \n           ...,\n  \n           [[-0.0422,  0.0309,  0.0158],\n            [ 0.0096,  0.0806, -0.0519],\n            [-0.0339, -0.0548, -0.0273]],\n  \n           [[ 0.0053, -0.0002, -0.0454],\n            [ 0.0202,  0.0161, -0.0682],\n            [ 0.0171, -0.0238,  0.0222]],\n  \n           [[-0.0357, -0.0057,  0.0194],\n            [-0.0502,  0.0502, -0.0157],\n            [-0.0215,  0.0491, -0.0350]]],\n  \n  \n          [[[ 0.0306,  0.0423, -0.0321],\n            [ 0.0886,  0.0168,  0.0512],\n            [-0.0074,  0.0351,  0.0989]],\n  \n           [[-0.0089, -0.0338,  0.0168],\n            [-0.0595, -0.0074,  0.0128],\n            [-0.0228,  0.0381, -0.0301]],\n  \n           [[ 0.0143, -0.0234,  0.0008],\n            [-0.0219,  0.0162,  0.0315],\n            [ 0.0114, -0.0047,  0.0579]],\n  \n           ...,\n  \n           [[-0.0654, -0.0516, -0.0372],\n            [ 0.0358,  0.0456,  0.0205],\n            [-0.0522,  0.0409,  0.0256]],\n  \n           [[ 0.0075, -0.0188, -0.0007],\n            [-0.0089,  0.0377, -0.0398],\n            [-0.0165, -0.0047,  0.0945]],\n  \n           [[ 0.0698,  0.0023,  0.0263],\n            [-0.0633,  0.0509,  0.0175],\n            [ 0.0969, -0.0350, -0.0396]]]], requires_grad=True)),\n ('layer2.3.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.3.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.3.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0659]],\n  \n           [[-0.0745]],\n  \n           [[-0.0380]],\n  \n           ...,\n  \n           [[-0.0046]],\n  \n           [[-0.0849]],\n  \n           [[-0.0789]]],\n  \n  \n          [[[ 0.0376]],\n  \n           [[-0.0662]],\n  \n           [[ 0.0721]],\n  \n           ...,\n  \n           [[-0.0350]],\n  \n           [[-0.0621]],\n  \n           [[-0.0565]]],\n  \n  \n          [[[-0.0551]],\n  \n           [[ 0.0231]],\n  \n           [[ 0.0595]],\n  \n           ...,\n  \n           [[ 0.0934]],\n  \n           [[ 0.0222]],\n  \n           [[ 0.0139]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0666]],\n  \n           [[-0.0092]],\n  \n           [[-0.0635]],\n  \n           ...,\n  \n           [[-0.0297]],\n  \n           [[ 0.0985]],\n  \n           [[-0.0780]]],\n  \n  \n          [[[ 0.0325]],\n  \n           [[ 0.1274]],\n  \n           [[ 0.0181]],\n  \n           ...,\n  \n           [[ 0.0114]],\n  \n           [[ 0.0021]],\n  \n           [[-0.0567]]],\n  \n  \n          [[[-0.0292]],\n  \n           [[ 0.0744]],\n  \n           [[-0.0323]],\n  \n           ...,\n  \n           [[-0.1086]],\n  \n           [[ 0.0314]],\n  \n           [[ 0.0771]]]], requires_grad=True)),\n ('layer2.3.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.3.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer3.0.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.0845]],\n  \n           [[ 0.0102]],\n  \n           [[ 0.0012]],\n  \n           ...,\n  \n           [[-0.1678]],\n  \n           [[-0.0670]],\n  \n           [[ 0.0408]]],\n  \n  \n          [[[-0.0171]],\n  \n           [[ 0.0401]],\n  \n           [[-0.0633]],\n  \n           ...,\n  \n           [[ 0.0030]],\n  \n           [[-0.0883]],\n  \n           [[-0.0824]]],\n  \n  \n          [[[-0.0342]],\n  \n           [[ 0.0686]],\n  \n           [[-0.0105]],\n  \n           ...,\n  \n           [[ 0.1833]],\n  \n           [[-0.0033]],\n  \n           [[ 0.1529]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0085]],\n  \n           [[ 0.0042]],\n  \n           [[ 0.0311]],\n  \n           ...,\n  \n           [[ 0.1536]],\n  \n           [[-0.0888]],\n  \n           [[-0.0247]]],\n  \n  \n          [[[-0.0876]],\n  \n           [[-0.1136]],\n  \n           [[ 0.1498]],\n  \n           ...,\n  \n           [[ 0.1551]],\n  \n           [[ 0.0631]],\n  \n           [[ 0.0742]]],\n  \n  \n          [[[ 0.1216]],\n  \n           [[-0.0451]],\n  \n           [[-0.1252]],\n  \n           ...,\n  \n           [[ 0.2079]],\n  \n           [[ 0.0335]],\n  \n           [[-0.0232]]]], requires_grad=True)),\n ('layer3.0.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.0.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.0.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 0.0054, -0.0260, -0.0133],\n            [-0.0465, -0.0140, -0.0472],\n            [-0.0405,  0.0130,  0.0056]],\n  \n           [[ 0.0220,  0.0407, -0.0025],\n            [ 0.0508,  0.0268, -0.0190],\n            [ 0.0133,  0.0175,  0.0226]],\n  \n           [[ 0.0222, -0.0246,  0.0335],\n            [-0.0154, -0.0267, -0.0054],\n            [ 0.0276,  0.0136, -0.0168]],\n  \n           ...,\n  \n           [[-0.0054, -0.0477, -0.0600],\n            [-0.0005, -0.0187,  0.0213],\n            [ 0.0345,  0.0113, -0.0234]],\n  \n           [[ 0.0102,  0.0144, -0.0012],\n            [-0.0023,  0.0300, -0.0282],\n            [-0.0173, -0.0372,  0.0399]],\n  \n           [[ 0.0396, -0.0156,  0.0292],\n            [-0.0092, -0.0046,  0.0060],\n            [-0.0300, -0.0011, -0.0062]]],\n  \n  \n          [[[ 0.0107,  0.0487, -0.0230],\n            [ 0.0641,  0.0255,  0.0138],\n            [-0.0256, -0.0052, -0.0233]],\n  \n           [[ 0.0314, -0.0036, -0.0070],\n            [-0.0024, -0.0479,  0.0019],\n            [ 0.0074,  0.0068, -0.0608]],\n  \n           [[-0.0187, -0.0072,  0.0091],\n            [-0.0052,  0.0140, -0.0011],\n            [ 0.0081,  0.0171, -0.0402]],\n  \n           ...,\n  \n           [[ 0.0009, -0.0404,  0.0238],\n            [ 0.0034, -0.0412,  0.0418],\n            [ 0.0213,  0.0003,  0.0007]],\n  \n           [[-0.0129,  0.0403,  0.0498],\n            [-0.0462,  0.0423,  0.0315],\n            [-0.0382,  0.0109, -0.0138]],\n  \n           [[ 0.0412,  0.0036,  0.0171],\n            [ 0.0204, -0.0161,  0.0444],\n            [ 0.0504,  0.0005, -0.0174]]],\n  \n  \n          [[[-0.0145, -0.0327, -0.0086],\n            [-0.0458,  0.0330, -0.0358],\n            [-0.0094, -0.0360,  0.0425]],\n  \n           [[-0.0657,  0.0022,  0.0333],\n            [ 0.0245, -0.0385,  0.0436],\n            [ 0.0133, -0.0165, -0.0262]],\n  \n           [[ 0.0351, -0.0199,  0.0338],\n            [-0.0155, -0.0337,  0.0400],\n            [-0.0282, -0.0275, -0.0318]],\n  \n           ...,\n  \n           [[ 0.0278, -0.0112,  0.0329],\n            [ 0.0502, -0.0210,  0.0336],\n            [ 0.0124,  0.0124,  0.0531]],\n  \n           [[-0.0016,  0.0408,  0.0217],\n            [ 0.0054,  0.0088,  0.0254],\n            [ 0.0151, -0.0240,  0.0151]],\n  \n           [[ 0.0216, -0.0051,  0.0314],\n            [ 0.0353,  0.0032,  0.0223],\n            [-0.0267, -0.0099, -0.0234]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0210, -0.0026, -0.0172],\n            [-0.0343,  0.0718,  0.0502],\n            [-0.0075, -0.0264,  0.0600]],\n  \n           [[ 0.0394,  0.0233, -0.0046],\n            [ 0.0189,  0.0276, -0.0078],\n            [ 0.0299,  0.0374, -0.0133]],\n  \n           [[-0.0130,  0.0592, -0.0115],\n            [-0.0140,  0.0114, -0.0427],\n            [ 0.0023,  0.0143, -0.0040]],\n  \n           ...,\n  \n           [[ 0.0712, -0.0429,  0.0040],\n            [-0.0558, -0.0347,  0.0403],\n            [ 0.0137, -0.0193,  0.0369]],\n  \n           [[ 0.0283,  0.0017,  0.0157],\n            [ 0.0405,  0.0147,  0.0313],\n            [ 0.0185,  0.0040, -0.0031]],\n  \n           [[ 0.0103, -0.0265,  0.0189],\n            [-0.0207,  0.0019, -0.0503],\n            [ 0.0391,  0.0102, -0.0204]]],\n  \n  \n          [[[-0.0681,  0.0341,  0.0467],\n            [-0.0279, -0.0049,  0.0164],\n            [ 0.0105,  0.0570, -0.0042]],\n  \n           [[-0.0522, -0.0258, -0.0114],\n            [-0.0650,  0.0012, -0.0082],\n            [-0.0170,  0.0125,  0.0222]],\n  \n           [[-0.0010, -0.0199,  0.0739],\n            [ 0.0021, -0.0230,  0.0196],\n            [ 0.0085,  0.0183,  0.0127]],\n  \n           ...,\n  \n           [[-0.0054,  0.0165,  0.0731],\n            [ 0.0181, -0.0219,  0.0036],\n            [ 0.0333, -0.0221,  0.0187]],\n  \n           [[ 0.0410, -0.0073, -0.0103],\n            [-0.0206, -0.0148, -0.0488],\n            [-0.0231, -0.0477, -0.0302]],\n  \n           [[ 0.0091, -0.0188,  0.0103],\n            [-0.0295,  0.0108, -0.0184],\n            [-0.0366,  0.0315, -0.0020]]],\n  \n  \n          [[[-0.0297,  0.0054,  0.0063],\n            [-0.0064, -0.0519,  0.0216],\n            [-0.0371,  0.0482,  0.0331]],\n  \n           [[-0.0189, -0.0559, -0.0614],\n            [ 0.0205, -0.0413, -0.0164],\n            [-0.0263,  0.0695, -0.0307]],\n  \n           [[-0.0307, -0.0036,  0.0779],\n            [ 0.0348, -0.0336, -0.0329],\n            [ 0.0415,  0.0250, -0.0442]],\n  \n           ...,\n  \n           [[ 0.0043, -0.0138, -0.0417],\n            [-0.0288, -0.0027,  0.0415],\n            [ 0.0207,  0.0294, -0.0172]],\n  \n           [[ 0.0451,  0.0013, -0.0203],\n            [-0.0031, -0.0159,  0.0105],\n            [-0.0259,  0.0246, -0.0105]],\n  \n           [[-0.0049,  0.0738,  0.0085],\n            [ 0.0742, -0.0125,  0.0289],\n            [-0.0108,  0.0175,  0.0288]]]], requires_grad=True)),\n ('layer3.0.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.0.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.0.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0686]],\n  \n           [[-0.0283]],\n  \n           [[ 0.0097]],\n  \n           ...,\n  \n           [[ 0.0343]],\n  \n           [[-0.0661]],\n  \n           [[-0.0526]]],\n  \n  \n          [[[-0.0218]],\n  \n           [[-0.0132]],\n  \n           [[-0.0259]],\n  \n           ...,\n  \n           [[ 0.0197]],\n  \n           [[ 0.0984]],\n  \n           [[-0.0743]]],\n  \n  \n          [[[-0.0377]],\n  \n           [[-0.0789]],\n  \n           [[ 0.0198]],\n  \n           ...,\n  \n           [[ 0.0414]],\n  \n           [[-0.0558]],\n  \n           [[-0.0468]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0251]],\n  \n           [[-0.0536]],\n  \n           [[ 0.0254]],\n  \n           ...,\n  \n           [[ 0.0134]],\n  \n           [[-0.0759]],\n  \n           [[-0.0472]]],\n  \n  \n          [[[ 0.1082]],\n  \n           [[-0.0331]],\n  \n           [[ 0.0160]],\n  \n           ...,\n  \n           [[ 0.0087]],\n  \n           [[-0.0622]],\n  \n           [[-0.0590]]],\n  \n  \n          [[[ 0.0456]],\n  \n           [[ 0.0003]],\n  \n           [[ 0.0144]],\n  \n           ...,\n  \n           [[-0.0242]],\n  \n           [[-0.0136]],\n  \n           [[ 0.0080]]]], requires_grad=True)),\n ('layer3.0.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.0.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.0.downsample.0.weight',\n  Parameter containing:\n  tensor([[[[-0.0418]],\n  \n           [[-0.0208]],\n  \n           [[-0.0206]],\n  \n           ...,\n  \n           [[ 0.0169]],\n  \n           [[ 0.0099]],\n  \n           [[-0.0694]]],\n  \n  \n          [[[ 0.0275]],\n  \n           [[-0.0150]],\n  \n           [[ 0.0252]],\n  \n           ...,\n  \n           [[-0.0361]],\n  \n           [[ 0.0399]],\n  \n           [[ 0.0184]]],\n  \n  \n          [[[-0.0298]],\n  \n           [[-0.0082]],\n  \n           [[-0.0231]],\n  \n           ...,\n  \n           [[-0.0983]],\n  \n           [[-0.0073]],\n  \n           [[-0.0450]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0242]],\n  \n           [[-0.0659]],\n  \n           [[ 0.0390]],\n  \n           ...,\n  \n           [[-0.0169]],\n  \n           [[ 0.0065]],\n  \n           [[-0.0043]]],\n  \n  \n          [[[-0.0112]],\n  \n           [[ 0.0470]],\n  \n           [[-0.1091]],\n  \n           ...,\n  \n           [[-0.0556]],\n  \n           [[ 0.0504]],\n  \n           [[ 0.0536]]],\n  \n  \n          [[[ 0.0255]],\n  \n           [[-0.0391]],\n  \n           [[-0.0058]],\n  \n           ...,\n  \n           [[ 0.0461]],\n  \n           [[ 0.0224]],\n  \n           [[-0.0092]]]], requires_grad=True)),\n ('layer3.0.downsample.1.weight',\n  Parameter containing:\n  tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)),\n ('layer3.0.downsample.1.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.1.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0826]],\n  \n           [[ 0.0453]],\n  \n           [[-0.0682]],\n  \n           ...,\n  \n           [[-0.0298]],\n  \n           [[-0.1112]],\n  \n           [[ 0.0268]]],\n  \n  \n          [[[-0.1231]],\n  \n           [[ 0.0271]],\n  \n           [[ 0.0273]],\n  \n           ...,\n  \n           [[-0.0921]],\n  \n           [[-0.0240]],\n  \n           [[-0.1141]]],\n  \n  \n          [[[ 0.0228]],\n  \n           [[-0.0395]],\n  \n           [[-0.0694]],\n  \n           ...,\n  \n           [[ 0.0231]],\n  \n           [[ 0.0933]],\n  \n           [[-0.1104]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.1635]],\n  \n           [[-0.0216]],\n  \n           [[ 0.0367]],\n  \n           ...,\n  \n           [[-0.0508]],\n  \n           [[-0.0599]],\n  \n           [[-0.1261]]],\n  \n  \n          [[[-0.0671]],\n  \n           [[-0.0695]],\n  \n           [[ 0.0251]],\n  \n           ...,\n  \n           [[ 0.0852]],\n  \n           [[-0.0611]],\n  \n           [[ 0.1764]]],\n  \n  \n          [[[ 0.0020]],\n  \n           [[ 0.0262]],\n  \n           [[-0.0006]],\n  \n           ...,\n  \n           [[ 0.1464]],\n  \n           [[ 0.1554]],\n  \n           [[-0.0512]]]], requires_grad=True)),\n ('layer3.1.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.1.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.1.conv2.weight',\n  Parameter containing:\n  tensor([[[[-1.5791e-02, -3.6361e-02,  2.9642e-02],\n            [ 4.9116e-02, -2.8563e-03,  1.4321e-02],\n            [-3.7315e-02, -6.8900e-03, -2.3771e-02]],\n  \n           [[ 1.1476e-02,  7.3049e-02, -7.8586e-03],\n            [-6.6519e-03,  2.4986e-03,  1.2868e-02],\n            [-1.7880e-02,  3.4451e-02,  4.1237e-04]],\n  \n           [[-4.0590e-02,  4.2409e-03, -4.9967e-02],\n            [-3.6613e-02,  3.5440e-02, -3.6613e-03],\n            [ 9.1528e-03, -2.2696e-02, -3.6998e-02]],\n  \n           ...,\n  \n           [[ 3.0958e-02, -3.3448e-02, -4.8575e-02],\n            [ 7.4950e-03, -3.9495e-02,  1.4678e-02],\n            [ 2.3532e-02, -2.0511e-02, -8.3222e-05]],\n  \n           [[-3.5708e-02,  2.7490e-02, -2.7328e-03],\n            [ 2.3998e-02, -4.3742e-02, -6.2410e-02],\n            [-4.2915e-02,  2.9370e-02, -1.4159e-02]],\n  \n           [[-4.6807e-02, -1.4428e-02,  6.3704e-04],\n            [ 3.2704e-03, -4.0851e-02,  5.5261e-03],\n            [ 1.1192e-03, -5.5855e-02,  2.0870e-02]]],\n  \n  \n          [[[-2.5382e-02,  1.8127e-02, -1.8301e-02],\n            [ 1.4928e-02, -4.1463e-02, -5.0125e-02],\n            [-3.9927e-02, -2.2737e-02,  3.5403e-02]],\n  \n           [[ 3.9119e-02,  3.0162e-02,  9.6497e-03],\n            [ 5.0243e-03, -1.9404e-02, -4.6817e-02],\n            [-1.9546e-02,  1.5879e-02,  4.2258e-02]],\n  \n           [[ 1.5648e-02, -2.4402e-02,  2.8837e-02],\n            [ 6.7391e-02, -1.7979e-03,  4.9645e-02],\n            [-2.4509e-02,  2.5692e-02, -1.3416e-02]],\n  \n           ...,\n  \n           [[-4.5968e-02, -3.2238e-02,  2.5851e-02],\n            [-2.7755e-02, -2.5351e-03,  1.6848e-02],\n            [-1.1841e-02, -2.2025e-02, -1.0079e-02]],\n  \n           [[ 2.9096e-02, -5.6588e-03, -3.7430e-02],\n            [ 2.3139e-02, -6.1421e-03,  5.3547e-03],\n            [-3.5642e-02, -1.6272e-02,  1.2680e-03]],\n  \n           [[-4.5059e-02,  3.0672e-02,  4.1950e-02],\n            [-3.3552e-03, -2.1627e-02, -1.8304e-02],\n            [ 9.7815e-03, -4.3939e-02, -2.8075e-02]]],\n  \n  \n          [[[-1.4995e-02, -2.7266e-03, -7.6974e-04],\n            [ 1.1558e-02,  3.4109e-02,  3.4308e-02],\n            [-2.4849e-03,  3.8366e-02,  2.5413e-02]],\n  \n           [[ 2.0227e-02,  2.9320e-02, -4.8138e-02],\n            [-3.1481e-02, -2.1374e-03,  6.6066e-03],\n            [ 6.3341e-03, -2.5838e-02, -4.0143e-02]],\n  \n           [[ 3.6880e-02, -1.2170e-02, -2.0159e-02],\n            [-1.0906e-02, -4.5360e-02,  2.1248e-02],\n            [-2.9780e-02,  4.0236e-02, -2.9158e-02]],\n  \n           ...,\n  \n           [[ 2.1072e-02,  6.1683e-02, -3.5969e-02],\n            [ 2.0307e-02, -5.4780e-05, -3.4308e-02],\n            [ 5.5149e-03,  4.9749e-02, -3.7749e-02]],\n  \n           [[-2.1034e-02,  3.4420e-02,  7.1253e-03],\n            [ 2.7329e-02,  1.1216e-02, -2.1896e-03],\n            [ 3.3569e-02,  2.1730e-02, -3.6669e-03]],\n  \n           [[ 1.6961e-03,  3.6973e-02, -7.8023e-03],\n            [-5.6584e-02,  3.8111e-02, -2.6280e-02],\n            [ 6.2532e-02,  3.7533e-02,  3.0196e-03]]],\n  \n  \n          ...,\n  \n  \n          [[[ 3.9798e-02, -2.5715e-02, -6.7929e-03],\n            [-2.5687e-02, -2.9894e-02, -2.9725e-02],\n            [-3.3797e-02,  1.5095e-02, -8.6130e-05]],\n  \n           [[-2.6542e-02,  7.6514e-02, -1.1748e-02],\n            [ 1.8552e-02, -2.5801e-02, -3.7192e-02],\n            [ 5.4452e-03, -2.2453e-02, -7.8372e-02]],\n  \n           [[ 6.4529e-02, -2.0579e-02,  4.7808e-02],\n            [ 6.1085e-02,  1.8428e-02, -1.3527e-02],\n            [-7.4832e-03, -2.5188e-02, -2.2736e-02]],\n  \n           ...,\n  \n           [[ 2.4293e-02, -1.3172e-02,  1.1246e-02],\n            [-4.3928e-02, -7.9775e-04,  1.1975e-02],\n            [-2.3470e-03,  1.9584e-02,  3.1799e-02]],\n  \n           [[-2.1593e-02,  3.2263e-02,  4.5072e-02],\n            [ 3.0098e-02, -4.5587e-02, -2.7600e-02],\n            [-1.0876e-02, -5.4578e-02,  2.8274e-02]],\n  \n           [[-3.1220e-02, -1.4101e-03,  5.1790e-03],\n            [-5.8895e-02,  1.5052e-02,  6.7957e-04],\n            [-4.6669e-02,  4.0789e-03,  8.4386e-03]]],\n  \n  \n          [[[ 2.6818e-02, -3.3355e-02,  7.3886e-04],\n            [ 6.5702e-02, -2.5676e-02,  1.6238e-02],\n            [-5.5273e-02, -6.3716e-03, -1.3914e-02]],\n  \n           [[ 4.4987e-02, -2.3497e-03, -2.8143e-02],\n            [ 2.5779e-02,  1.8882e-02, -6.3830e-04],\n            [-1.8685e-03,  3.3612e-02,  9.3307e-04]],\n  \n           [[-2.6406e-02,  3.5219e-03,  3.4773e-02],\n            [ 6.8522e-02,  8.3221e-03,  9.4333e-03],\n            [-4.6144e-02, -2.4965e-02, -4.1377e-03]],\n  \n           ...,\n  \n           [[-7.3474e-02, -5.5011e-02,  1.3724e-02],\n            [ 1.0802e-01,  2.9984e-02,  1.5933e-02],\n            [ 3.7104e-02, -1.3888e-02, -4.6466e-02]],\n  \n           [[ 6.0294e-03,  2.2019e-02, -4.4663e-04],\n            [ 1.8679e-02,  4.0528e-02, -1.1986e-02],\n            [ 6.0598e-02, -1.6437e-02, -3.0676e-03]],\n  \n           [[-5.7882e-02, -3.4872e-02, -2.6283e-02],\n            [-7.6126e-03,  2.7011e-03, -8.8197e-02],\n            [-4.4718e-02, -1.0295e-02, -2.9779e-02]]],\n  \n  \n          [[[-5.5724e-03,  2.0327e-02, -1.6305e-02],\n            [ 4.9112e-02,  2.2103e-02,  1.1756e-02],\n            [-1.9243e-03,  1.9718e-02,  2.5022e-02]],\n  \n           [[-4.6871e-03, -4.9651e-03, -4.6574e-02],\n            [-1.7458e-03, -2.3545e-02,  2.3278e-02],\n            [-1.1229e-02,  1.1368e-02,  4.2316e-02]],\n  \n           [[-2.7840e-02,  2.2139e-02, -1.5531e-02],\n            [-1.1877e-02,  3.0877e-02, -1.0118e-02],\n            [-1.2845e-02, -3.0826e-02,  1.8834e-02]],\n  \n           ...,\n  \n           [[ 1.8303e-02,  9.5048e-03, -3.5328e-03],\n            [-1.1956e-03,  1.1421e-03, -3.7856e-02],\n            [-1.9882e-02,  3.0404e-02, -3.0646e-02]],\n  \n           [[ 1.1251e-02,  4.9189e-02, -2.7675e-02],\n            [ 1.1346e-02,  3.6158e-02, -3.9763e-02],\n            [ 5.1055e-03,  3.1012e-03, -2.1895e-03]],\n  \n           [[ 1.7851e-03, -3.0441e-03, -4.1181e-02],\n            [-2.7162e-02,  1.8100e-02, -3.1112e-02],\n            [ 3.1842e-02,  3.9658e-02,  5.6591e-03]]]], requires_grad=True)),\n ('layer3.1.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.1.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.1.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0280]],\n  \n           [[-0.0096]],\n  \n           [[-0.0810]],\n  \n           ...,\n  \n           [[-0.0509]],\n  \n           [[-0.0823]],\n  \n           [[-0.0097]]],\n  \n  \n          [[[-0.0252]],\n  \n           [[ 0.0282]],\n  \n           [[ 0.0197]],\n  \n           ...,\n  \n           [[ 0.0006]],\n  \n           [[-0.0064]],\n  \n           [[-0.0242]]],\n  \n  \n          [[[ 0.0306]],\n  \n           [[-0.0208]],\n  \n           [[ 0.0482]],\n  \n           ...,\n  \n           [[-0.0822]],\n  \n           [[ 0.0428]],\n  \n           [[-0.1039]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0301]],\n  \n           [[-0.0662]],\n  \n           [[ 0.0129]],\n  \n           ...,\n  \n           [[-0.0420]],\n  \n           [[-0.0155]],\n  \n           [[-0.0484]]],\n  \n  \n          [[[ 0.0248]],\n  \n           [[-0.0137]],\n  \n           [[ 0.0189]],\n  \n           ...,\n  \n           [[ 0.0184]],\n  \n           [[-0.0066]],\n  \n           [[ 0.0409]]],\n  \n  \n          [[[ 0.0030]],\n  \n           [[ 0.0016]],\n  \n           [[ 0.0436]],\n  \n           ...,\n  \n           [[-0.0076]],\n  \n           [[ 0.0018]],\n  \n           [[ 0.0217]]]], requires_grad=True)),\n ('layer3.1.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.1.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.2.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.0200]],\n  \n           [[-0.0951]],\n  \n           [[ 0.0186]],\n  \n           ...,\n  \n           [[ 0.0646]],\n  \n           [[-0.0765]],\n  \n           [[ 0.0731]]],\n  \n  \n          [[[ 0.0588]],\n  \n           [[ 0.0336]],\n  \n           [[ 0.0448]],\n  \n           ...,\n  \n           [[ 0.0682]],\n  \n           [[ 0.0963]],\n  \n           [[-0.0980]]],\n  \n  \n          [[[ 0.0687]],\n  \n           [[-0.0813]],\n  \n           [[ 0.0295]],\n  \n           ...,\n  \n           [[ 0.0353]],\n  \n           [[-0.0588]],\n  \n           [[ 0.0658]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0363]],\n  \n           [[-0.1020]],\n  \n           [[-0.0139]],\n  \n           ...,\n  \n           [[-0.0637]],\n  \n           [[ 0.0578]],\n  \n           [[ 0.0608]]],\n  \n  \n          [[[-0.0602]],\n  \n           [[-0.0510]],\n  \n           [[ 0.0497]],\n  \n           ...,\n  \n           [[-0.0003]],\n  \n           [[ 0.1302]],\n  \n           [[-0.0945]]],\n  \n  \n          [[[-0.1196]],\n  \n           [[-0.0980]],\n  \n           [[ 0.0038]],\n  \n           ...,\n  \n           [[-0.0067]],\n  \n           [[-0.0103]],\n  \n           [[-0.1775]]]], requires_grad=True)),\n ('layer3.2.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.2.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.2.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 8.2847e-03,  1.6677e-02,  1.4527e-02],\n            [ 8.5915e-03,  3.2973e-02,  3.9604e-02],\n            [-2.2169e-02,  2.9133e-02, -1.6774e-02]],\n  \n           [[ 6.0294e-02, -7.1674e-04,  5.5939e-02],\n            [-1.6964e-02,  3.9841e-02,  3.5852e-02],\n            [-5.3230e-02,  1.4253e-03, -1.3850e-02]],\n  \n           [[ 1.2236e-02,  2.6060e-02,  1.7525e-02],\n            [-1.4547e-02,  3.9906e-02,  4.2274e-02],\n            [ 6.9792e-03,  1.1519e-02,  2.4149e-02]],\n  \n           ...,\n  \n           [[-3.5614e-02,  3.8915e-02,  4.9838e-02],\n            [-2.1771e-03,  1.3593e-03,  1.4572e-02],\n            [ 7.1951e-03, -2.3047e-03, -3.0261e-02]],\n  \n           [[-9.3531e-02,  1.9502e-02,  2.6046e-03],\n            [-2.3474e-02, -1.7514e-02,  5.2145e-02],\n            [-9.6907e-03,  8.5393e-03,  3.5762e-03]],\n  \n           [[-5.7824e-02,  2.0054e-02,  7.4115e-03],\n            [ 2.0059e-02, -9.7816e-03,  2.3132e-02],\n            [ 8.6665e-03, -3.3068e-02,  3.7214e-02]]],\n  \n  \n          [[[-3.9028e-03, -3.0342e-02, -1.8745e-02],\n            [-4.9580e-02,  2.6396e-02, -4.0269e-02],\n            [ 6.8253e-03,  1.0314e-02,  1.0629e-02]],\n  \n           [[ 4.6180e-03,  8.9664e-03,  4.6218e-02],\n            [-1.8667e-02, -2.8731e-03, -2.9544e-02],\n            [ 2.3982e-03,  1.7261e-02,  2.0615e-02]],\n  \n           [[ 1.8091e-02, -5.8626e-02,  4.2836e-02],\n            [ 2.5931e-02, -2.0920e-02, -1.0538e-02],\n            [ 6.1750e-02,  1.1744e-02,  1.6510e-02]],\n  \n           ...,\n  \n           [[ 5.6912e-02, -3.3634e-02,  1.4816e-02],\n            [-1.0799e-02,  2.3500e-02, -6.9046e-03],\n            [ 1.4270e-02,  1.3251e-02, -3.0396e-02]],\n  \n           [[-1.5597e-02, -3.4988e-02, -9.9426e-03],\n            [ 1.0084e-02,  8.3798e-03,  3.8586e-02],\n            [-1.0141e-02,  3.6370e-02, -2.6960e-02]],\n  \n           [[ 3.6252e-02, -6.7878e-03, -9.2819e-03],\n            [-1.2435e-02, -1.6956e-02, -2.3464e-02],\n            [-2.8971e-02, -1.4484e-05,  3.7100e-02]]],\n  \n  \n          [[[-2.5472e-02, -2.5646e-02, -2.1588e-02],\n            [-1.3794e-02,  1.1192e-02,  6.3307e-02],\n            [-5.5175e-02,  2.9825e-02,  2.8346e-02]],\n  \n           [[ 4.7922e-03,  3.2381e-02, -1.5673e-03],\n            [ 4.4095e-02,  3.4130e-02, -1.7086e-02],\n            [-2.2049e-02, -5.9746e-02,  3.4687e-03]],\n  \n           [[ 6.0871e-02, -6.0833e-04, -2.8201e-02],\n            [ 4.7908e-03, -5.3538e-03,  1.3398e-02],\n            [ 3.1056e-02,  2.8855e-02, -3.5163e-02]],\n  \n           ...,\n  \n           [[ 1.0334e-02, -3.4671e-03, -1.7009e-03],\n            [-2.0201e-02, -1.5973e-02,  2.5389e-02],\n            [-1.7292e-02,  2.6464e-02, -2.5394e-02]],\n  \n           [[ 2.3953e-02,  6.2547e-03, -1.8064e-02],\n            [-3.7268e-02, -5.1822e-03, -2.7933e-02],\n            [ 1.8027e-02, -7.2723e-02,  4.3008e-02]],\n  \n           [[-4.5355e-02, -2.9464e-02, -8.1841e-02],\n            [ 6.5791e-02, -2.8992e-04,  3.5616e-03],\n            [ 9.5372e-03, -1.0692e-02,  1.9527e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 7.9685e-02,  2.1810e-02, -1.2611e-02],\n            [ 1.5779e-02, -1.1464e-02,  1.2943e-02],\n            [-1.7995e-02,  6.5461e-04,  1.9755e-02]],\n  \n           [[-9.7413e-03, -3.7014e-02, -2.2684e-02],\n            [-8.1871e-04,  2.7409e-02, -5.0674e-02],\n            [-4.7077e-02,  2.6810e-02,  3.0313e-02]],\n  \n           [[ 7.2511e-04,  5.1719e-02,  1.1566e-02],\n            [ 1.9188e-02,  1.9353e-02,  2.7462e-02],\n            [-3.1201e-02, -5.0842e-02, -1.8247e-02]],\n  \n           ...,\n  \n           [[-1.1175e-02, -9.0107e-03, -5.1530e-03],\n            [-2.3717e-03,  1.6803e-02, -6.9798e-03],\n            [-6.2794e-02, -2.5733e-03,  8.0564e-03]],\n  \n           [[ 1.8738e-02, -1.4322e-02, -3.4469e-03],\n            [-1.6180e-02, -2.6044e-02, -1.2323e-03],\n            [-2.8622e-02, -7.4329e-03,  3.1876e-02]],\n  \n           [[ 5.2834e-03, -5.2158e-02, -3.3926e-02],\n            [-4.6468e-02, -1.6522e-02, -3.6937e-02],\n            [ 2.2631e-02,  1.9870e-02,  4.0593e-02]]],\n  \n  \n          [[[ 1.1668e-02, -2.8983e-02,  2.4513e-02],\n            [ 2.0327e-02, -7.9667e-03, -8.2108e-04],\n            [-3.1045e-02, -5.6449e-02,  3.2075e-02]],\n  \n           [[ 1.0411e-02,  3.6846e-02,  7.3951e-03],\n            [ 2.1491e-02,  6.4708e-02, -2.9158e-02],\n            [-6.7655e-02, -2.1640e-02,  5.0303e-02]],\n  \n           [[ 4.8983e-02, -1.9326e-02,  1.9924e-02],\n            [-6.5550e-03, -1.5009e-03, -4.5588e-02],\n            [ 2.6072e-02,  6.3135e-03, -5.3702e-02]],\n  \n           ...,\n  \n           [[-3.1809e-02,  1.3491e-02, -3.8330e-03],\n            [-1.1270e-02, -1.9763e-03, -2.2435e-02],\n            [-2.6880e-02,  2.4187e-03,  5.1126e-02]],\n  \n           [[ 9.4548e-03, -3.6026e-02,  1.1095e-02],\n            [-1.4757e-02, -4.6296e-02,  2.3856e-02],\n            [ 4.1071e-02,  1.4884e-03, -1.1488e-02]],\n  \n           [[ 9.8374e-03,  3.3745e-02,  1.5055e-02],\n            [ 1.5424e-03,  2.4750e-02, -2.0943e-03],\n            [-2.7401e-02,  2.8452e-02, -6.6456e-03]]],\n  \n  \n          [[[-2.9554e-02,  3.1573e-02, -2.3323e-02],\n            [ 3.2860e-02, -1.2010e-02,  1.3053e-02],\n            [-1.4563e-02,  9.4927e-02,  8.4784e-03]],\n  \n           [[-3.6402e-02, -3.7391e-03, -3.7304e-03],\n            [ 2.9706e-02, -2.2957e-02, -4.3798e-02],\n            [-2.5277e-02, -1.9728e-02, -2.7168e-02]],\n  \n           [[-4.5600e-02, -2.5123e-02, -8.5362e-03],\n            [-1.6403e-02,  3.8167e-02, -2.2246e-02],\n            [-3.2903e-02,  1.8067e-02, -1.4901e-02]],\n  \n           ...,\n  \n           [[ 2.8575e-02, -4.0251e-02,  5.1598e-02],\n            [ 1.3479e-02, -4.8410e-03, -2.1953e-02],\n            [-2.7338e-03,  2.0802e-02, -5.1434e-03]],\n  \n           [[ 5.2211e-02,  4.5468e-03, -9.3347e-03],\n            [-2.8731e-02,  2.1231e-02, -8.6606e-03],\n            [-1.4195e-03, -6.0878e-03, -6.8584e-03]],\n  \n           [[-3.1122e-02, -2.3617e-03,  8.3305e-03],\n            [ 3.9178e-02,  9.4839e-03,  4.7496e-02],\n            [ 1.4776e-02, -5.1577e-02,  1.2084e-02]]]], requires_grad=True)),\n ('layer3.2.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.2.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.2.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0144]],\n  \n           [[-0.0766]],\n  \n           [[-0.0167]],\n  \n           ...,\n  \n           [[ 0.0017]],\n  \n           [[ 0.0279]],\n  \n           [[-0.0447]]],\n  \n  \n          [[[ 0.0170]],\n  \n           [[ 0.0075]],\n  \n           [[-0.0095]],\n  \n           ...,\n  \n           [[-0.0002]],\n  \n           [[ 0.0174]],\n  \n           [[ 0.0018]]],\n  \n  \n          [[[-0.0367]],\n  \n           [[-0.0542]],\n  \n           [[ 0.0189]],\n  \n           ...,\n  \n           [[ 0.0402]],\n  \n           [[ 0.0316]],\n  \n           [[ 0.0284]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0132]],\n  \n           [[ 0.0141]],\n  \n           [[ 0.0675]],\n  \n           ...,\n  \n           [[-0.0287]],\n  \n           [[ 0.0613]],\n  \n           [[ 0.0924]]],\n  \n  \n          [[[-0.1017]],\n  \n           [[ 0.0018]],\n  \n           [[-0.0132]],\n  \n           ...,\n  \n           [[ 0.0532]],\n  \n           [[-0.1004]],\n  \n           [[ 0.0086]]],\n  \n  \n          [[[ 0.0274]],\n  \n           [[ 0.0686]],\n  \n           [[ 0.0411]],\n  \n           ...,\n  \n           [[-0.0363]],\n  \n           [[-0.0396]],\n  \n           [[-0.0070]]]], requires_grad=True)),\n ('layer3.2.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.2.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.3.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0488]],\n  \n           [[-0.0243]],\n  \n           [[-0.0953]],\n  \n           ...,\n  \n           [[-0.0322]],\n  \n           [[-0.0006]],\n  \n           [[-0.0957]]],\n  \n  \n          [[[-0.0568]],\n  \n           [[ 0.0433]],\n  \n           [[-0.0657]],\n  \n           ...,\n  \n           [[-0.0415]],\n  \n           [[-0.0010]],\n  \n           [[ 0.0810]]],\n  \n  \n          [[[ 0.1400]],\n  \n           [[ 0.0629]],\n  \n           [[ 0.1938]],\n  \n           ...,\n  \n           [[ 0.1159]],\n  \n           [[ 0.0375]],\n  \n           [[ 0.0372]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.1325]],\n  \n           [[ 0.0417]],\n  \n           [[-0.0262]],\n  \n           ...,\n  \n           [[-0.0167]],\n  \n           [[ 0.0747]],\n  \n           [[ 0.1331]]],\n  \n  \n          [[[-0.0194]],\n  \n           [[-0.0361]],\n  \n           [[-0.0088]],\n  \n           ...,\n  \n           [[ 0.0381]],\n  \n           [[ 0.0449]],\n  \n           [[ 0.0604]]],\n  \n  \n          [[[-0.0150]],\n  \n           [[-0.1971]],\n  \n           [[-0.0012]],\n  \n           ...,\n  \n           [[-0.1198]],\n  \n           [[-0.1358]],\n  \n           [[-0.0544]]]], requires_grad=True)),\n ('layer3.3.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.3.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.3.conv2.weight',\n  Parameter containing:\n  tensor([[[[-1.7035e-02,  7.1942e-03, -2.3327e-02],\n            [ 3.0909e-02, -1.5759e-02, -2.3324e-02],\n            [-4.2068e-02,  2.5518e-02,  1.0073e-03]],\n  \n           [[-3.2041e-02, -3.4009e-02,  2.2773e-03],\n            [-1.1814e-03,  2.7857e-02, -2.1206e-03],\n            [ 1.4320e-02, -1.8606e-02,  1.5336e-02]],\n  \n           [[-3.9873e-02, -9.1911e-02,  1.8274e-02],\n            [ 1.7043e-02, -1.7755e-02,  1.6855e-02],\n            [-2.9968e-02,  2.0778e-03, -1.6478e-02]],\n  \n           ...,\n  \n           [[ 6.2308e-03,  4.4974e-03,  1.6540e-03],\n            [-3.1207e-04, -2.8205e-02, -1.2350e-02],\n            [-4.7715e-02,  4.8100e-02,  2.9551e-02]],\n  \n           [[ 4.1786e-02,  2.6159e-02,  3.3757e-05],\n            [-1.9367e-03, -5.1768e-02, -2.2192e-02],\n            [-4.4027e-02,  4.4060e-03,  5.0508e-03]],\n  \n           [[ 8.0665e-03,  8.1101e-03, -2.4044e-02],\n            [ 9.0603e-02,  2.6511e-02,  1.3938e-02],\n            [ 6.0320e-02,  3.4512e-02,  1.7849e-02]]],\n  \n  \n          [[[-4.5262e-03, -2.4455e-02, -4.6461e-03],\n            [ 8.6930e-03, -3.7523e-02, -5.4648e-02],\n            [-1.1002e-02,  1.0499e-02,  5.3224e-03]],\n  \n           [[ 2.7643e-02,  6.7480e-02,  2.0328e-02],\n            [-2.5531e-02,  5.3490e-03, -1.1315e-03],\n            [ 3.4711e-02,  5.3466e-03,  4.2625e-02]],\n  \n           [[-5.5408e-02,  3.7122e-02,  3.8803e-03],\n            [-7.6885e-03,  1.8007e-02,  6.5030e-02],\n            [ 2.5908e-02,  1.4660e-02,  1.3991e-02]],\n  \n           ...,\n  \n           [[ 4.5448e-02, -3.2369e-02,  1.1668e-02],\n            [ 3.6233e-02,  1.4623e-02,  7.5676e-03],\n            [-2.7893e-02, -1.9312e-02,  3.4560e-02]],\n  \n           [[ 1.9561e-02,  8.9970e-03,  3.8577e-02],\n            [ 1.3902e-02,  8.7593e-03,  2.5725e-02],\n            [-5.0444e-02, -1.2465e-02, -1.6791e-02]],\n  \n           [[-3.4285e-02, -3.7859e-02, -7.1149e-03],\n            [-2.8030e-02, -6.5988e-03,  1.1789e-02],\n            [ 1.9973e-02,  1.3128e-02,  3.1544e-03]]],\n  \n  \n          [[[ 2.5615e-02,  1.0154e-02, -2.3357e-02],\n            [ 1.2082e-02, -1.0405e-02,  9.1418e-02],\n            [ 4.5012e-02,  3.9455e-03,  4.8355e-03]],\n  \n           [[ 6.4426e-03,  3.4305e-02, -5.1241e-02],\n            [-1.9072e-02,  5.6626e-02, -9.7465e-03],\n            [-1.6924e-02, -1.7575e-03, -5.0027e-02]],\n  \n           [[ 3.5558e-02, -9.8706e-02, -2.6702e-03],\n            [-3.5161e-02,  4.7312e-02,  6.4126e-04],\n            [-1.0879e-02, -2.1216e-03, -4.9678e-02]],\n  \n           ...,\n  \n           [[-8.8431e-03,  2.0539e-02,  4.1600e-02],\n            [-3.6894e-02,  1.4730e-02,  7.6153e-02],\n            [-1.3843e-02, -3.8007e-02, -5.1604e-03]],\n  \n           [[ 5.7732e-02,  1.3151e-02,  1.9315e-02],\n            [ 4.6730e-02, -4.4377e-04, -1.0353e-03],\n            [-2.1472e-02,  1.0628e-02, -9.6998e-03]],\n  \n           [[-3.5218e-02, -1.4437e-02, -3.3259e-03],\n            [-3.1088e-02,  3.3845e-02,  3.7010e-02],\n            [ 1.1174e-02,  2.2558e-02,  2.0674e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 2.5338e-02, -2.6722e-02, -8.1347e-03],\n            [ 1.2231e-03,  2.1782e-02, -4.9276e-02],\n            [ 1.1718e-02, -3.4569e-02, -2.3134e-02]],\n  \n           [[ 6.3636e-03, -4.6785e-02, -1.6028e-03],\n            [-2.7843e-02, -6.6190e-02, -3.0660e-02],\n            [ 5.2333e-02,  4.4412e-02,  5.4673e-02]],\n  \n           [[ 4.3816e-02,  1.5387e-02, -1.3446e-02],\n            [-2.1582e-04, -6.0563e-03,  2.0600e-02],\n            [ 2.2070e-02,  1.6775e-02, -6.0009e-03]],\n  \n           ...,\n  \n           [[-7.2384e-03,  1.2649e-03, -6.6799e-04],\n            [-4.5331e-02, -1.3192e-03, -2.7107e-02],\n            [ 3.7801e-02, -3.7307e-02, -3.4440e-02]],\n  \n           [[-6.8024e-03,  5.5347e-03, -1.6108e-02],\n            [-1.6065e-02,  1.2956e-02,  3.1415e-02],\n            [-3.7788e-02, -3.1853e-03,  8.8218e-03]],\n  \n           [[ 3.5222e-02, -1.8286e-02, -5.8837e-02],\n            [ 3.2023e-03,  4.7753e-02, -1.7863e-02],\n            [-2.6978e-03, -2.7018e-02,  1.1348e-02]]],\n  \n  \n          [[[ 9.4646e-03, -4.9642e-02, -1.4083e-02],\n            [-1.0439e-02,  3.7155e-03, -1.7208e-02],\n            [ 4.4904e-02,  1.2062e-02, -1.2025e-03]],\n  \n           [[-2.1972e-04, -1.9514e-02,  1.8675e-03],\n            [ 3.9539e-02, -1.5473e-02, -2.4104e-02],\n            [ 3.5305e-02, -2.2602e-02, -6.8348e-02]],\n  \n           [[ 1.4678e-02, -3.6212e-02, -4.3677e-02],\n            [ 2.9750e-02,  1.2638e-02,  2.7216e-02],\n            [ 5.3793e-03,  1.8831e-02, -3.7095e-02]],\n  \n           ...,\n  \n           [[ 5.4385e-02,  3.5083e-02, -1.3416e-02],\n            [-3.0418e-02, -2.1716e-02, -2.4747e-02],\n            [-7.4251e-03,  5.8676e-03,  9.7599e-03]],\n  \n           [[-3.6018e-02,  2.9550e-02, -4.3119e-02],\n            [ 8.5634e-03, -9.1419e-03, -7.5138e-03],\n            [ 1.6382e-02,  1.7247e-02, -3.1261e-02]],\n  \n           [[ 3.4712e-02, -3.8684e-03, -9.7017e-03],\n            [ 5.6648e-03,  1.0028e-02,  5.2526e-03],\n            [-5.8685e-02, -8.2147e-03,  1.2674e-02]]],\n  \n  \n          [[[-5.3166e-02, -4.8768e-02, -1.3591e-02],\n            [-2.5855e-02,  8.6810e-04, -2.0275e-02],\n            [ 1.8711e-02,  1.5382e-02, -5.1489e-02]],\n  \n           [[-1.1853e-02,  3.2730e-03, -1.4702e-02],\n            [-7.4826e-03, -7.2251e-03, -1.0603e-02],\n            [ 3.5157e-02, -4.1526e-02,  1.2648e-02]],\n  \n           [[-2.7885e-03, -4.7841e-04,  1.1337e-02],\n            [-1.6938e-03,  1.7197e-02,  5.8655e-03],\n            [-5.3049e-02,  4.3308e-02, -1.4599e-02]],\n  \n           ...,\n  \n           [[ 5.3726e-02, -4.4607e-02,  2.9851e-03],\n            [-4.1750e-03,  2.4736e-02, -4.1434e-02],\n            [-1.0675e-02, -3.2776e-02,  1.7287e-02]],\n  \n           [[-1.0569e-02,  1.8271e-02, -4.7659e-02],\n            [ 2.5124e-02, -7.7333e-03,  1.0467e-02],\n            [ 3.2057e-02,  1.7390e-02, -4.6390e-02]],\n  \n           [[-1.0176e-02, -2.4395e-03,  1.9234e-02],\n            [ 3.9036e-02, -3.5639e-02, -7.3514e-02],\n            [-1.5681e-03, -6.2660e-02, -1.1289e-02]]]], requires_grad=True)),\n ('layer3.3.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.3.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.3.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0740]],\n  \n           [[ 0.0006]],\n  \n           [[-0.0194]],\n  \n           ...,\n  \n           [[-0.0347]],\n  \n           [[ 0.0174]],\n  \n           [[-0.0092]]],\n  \n  \n          [[[-0.0247]],\n  \n           [[-0.0448]],\n  \n           [[ 0.0328]],\n  \n           ...,\n  \n           [[-0.0049]],\n  \n           [[ 0.0437]],\n  \n           [[-0.0303]]],\n  \n  \n          [[[ 0.0682]],\n  \n           [[ 0.0395]],\n  \n           [[ 0.0420]],\n  \n           ...,\n  \n           [[-0.1273]],\n  \n           [[-0.0295]],\n  \n           [[-0.0332]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0200]],\n  \n           [[ 0.0546]],\n  \n           [[-0.0362]],\n  \n           ...,\n  \n           [[ 0.0198]],\n  \n           [[-0.0488]],\n  \n           [[-0.0178]]],\n  \n  \n          [[[-0.0435]],\n  \n           [[ 0.0261]],\n  \n           [[ 0.0481]],\n  \n           ...,\n  \n           [[-0.0055]],\n  \n           [[-0.0137]],\n  \n           [[ 0.0312]]],\n  \n  \n          [[[ 0.0020]],\n  \n           [[ 0.0494]],\n  \n           [[ 0.0359]],\n  \n           ...,\n  \n           [[ 0.0071]],\n  \n           [[ 0.0292]],\n  \n           [[-0.0646]]]], requires_grad=True)),\n ('layer3.3.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.3.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.4.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0251]],\n  \n           [[-0.0959]],\n  \n           [[-0.0428]],\n  \n           ...,\n  \n           [[ 0.0545]],\n  \n           [[ 0.0474]],\n  \n           [[-0.0231]]],\n  \n  \n          [[[ 0.0412]],\n  \n           [[-0.1001]],\n  \n           [[ 0.0165]],\n  \n           ...,\n  \n           [[ 0.1040]],\n  \n           [[-0.0598]],\n  \n           [[-0.0018]]],\n  \n  \n          [[[-0.0410]],\n  \n           [[ 0.0863]],\n  \n           [[-0.0144]],\n  \n           ...,\n  \n           [[ 0.0507]],\n  \n           [[-0.0472]],\n  \n           [[ 0.0432]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0558]],\n  \n           [[-0.0153]],\n  \n           [[ 0.0689]],\n  \n           ...,\n  \n           [[-0.0202]],\n  \n           [[ 0.0411]],\n  \n           [[-0.0481]]],\n  \n  \n          [[[-0.1581]],\n  \n           [[-0.0546]],\n  \n           [[ 0.0222]],\n  \n           ...,\n  \n           [[ 0.1405]],\n  \n           [[ 0.0790]],\n  \n           [[ 0.1383]]],\n  \n  \n          [[[ 0.0294]],\n  \n           [[-0.0496]],\n  \n           [[-0.0059]],\n  \n           ...,\n  \n           [[ 0.0113]],\n  \n           [[-0.1224]],\n  \n           [[ 0.0432]]]], requires_grad=True)),\n ('layer3.4.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.4.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.4.conv2.weight',\n  Parameter containing:\n  tensor([[[[-1.6009e-03,  1.0269e-02, -5.2161e-02],\n            [ 4.0043e-02,  5.0708e-02,  3.5235e-02],\n            [-4.4591e-03,  5.7668e-02,  1.2324e-02]],\n  \n           [[ 1.7627e-02, -5.0328e-03,  3.8007e-02],\n            [ 5.7972e-03,  2.1237e-02,  1.4645e-02],\n            [-4.7255e-03, -3.0667e-02, -2.1673e-02]],\n  \n           [[ 4.2580e-02, -3.6451e-02, -2.9569e-02],\n            [ 3.6061e-02, -2.0741e-02, -1.8165e-02],\n            [ 1.2687e-02,  4.9119e-02,  1.5015e-02]],\n  \n           ...,\n  \n           [[-2.4219e-02, -9.8479e-03, -7.3977e-04],\n            [-5.5825e-03,  3.7482e-02,  9.6175e-02],\n            [-2.9165e-03, -1.0624e-02,  1.8222e-03]],\n  \n           [[-2.1274e-02,  2.4935e-02,  2.8950e-02],\n            [ 1.9929e-02, -1.7737e-03, -1.8487e-02],\n            [-4.3933e-02,  2.1108e-02, -4.5799e-02]],\n  \n           [[ 1.1021e-02,  1.3842e-02, -1.2138e-02],\n            [-1.2067e-02, -3.7539e-02,  1.2205e-02],\n            [-3.8640e-03,  1.6865e-02, -1.5869e-02]]],\n  \n  \n          [[[-1.8228e-02,  8.5102e-03, -4.2277e-02],\n            [ 2.7811e-02, -9.1877e-03, -9.5644e-03],\n            [ 4.9165e-02, -2.2988e-02, -2.8005e-02]],\n  \n           [[-2.4615e-02,  1.2243e-02, -1.7397e-02],\n            [-9.8779e-03, -1.8880e-02, -3.1017e-02],\n            [-5.1766e-03,  9.8683e-04, -2.7243e-02]],\n  \n           [[-2.0895e-02,  1.9797e-02, -2.2411e-02],\n            [ 4.9098e-02,  2.3675e-02,  3.6758e-02],\n            [ 1.2734e-02,  3.8140e-02,  1.9758e-02]],\n  \n           ...,\n  \n           [[ 1.6472e-02,  3.2317e-02,  2.5021e-02],\n            [-2.8711e-03, -4.5026e-03,  1.7441e-02],\n            [-1.1909e-02,  3.7979e-02,  1.5970e-02]],\n  \n           [[-6.0905e-02,  5.1312e-03, -9.7965e-03],\n            [ 8.7254e-03, -3.2012e-03, -2.3571e-02],\n            [ 7.9624e-03, -2.2770e-02, -6.2757e-02]],\n  \n           [[ 4.7039e-02, -2.2488e-02, -6.6792e-03],\n            [ 6.7790e-03,  4.0642e-02, -1.3390e-02],\n            [-3.8539e-02,  1.9785e-02, -2.8096e-02]]],\n  \n  \n          [[[ 5.2986e-03, -2.1664e-03,  3.4332e-03],\n            [-2.6189e-03,  1.5890e-02,  1.0145e-03],\n            [ 5.5392e-02,  2.1408e-02, -1.4123e-02]],\n  \n           [[-7.2157e-02, -3.6886e-02, -2.3648e-02],\n            [ 8.3747e-03,  2.3851e-02,  5.2880e-02],\n            [-6.5505e-03,  4.4400e-02, -1.0688e-02]],\n  \n           [[ 1.8727e-03, -1.2892e-02, -3.4563e-02],\n            [ 2.2497e-02,  3.0416e-02,  7.0525e-02],\n            [ 4.2641e-02, -3.7020e-02, -3.0178e-02]],\n  \n           ...,\n  \n           [[ 5.7191e-02,  3.1901e-02,  4.9941e-03],\n            [-2.8775e-02,  2.8710e-02,  4.5303e-03],\n            [-1.4885e-02, -1.9145e-02, -2.7643e-02]],\n  \n           [[ 4.5434e-02,  7.0119e-02,  2.6029e-02],\n            [-1.6961e-02, -7.6769e-03,  9.0082e-03],\n            [ 2.6719e-02,  2.9827e-02, -2.4014e-02]],\n  \n           [[ 3.0025e-02, -3.5443e-02, -1.6958e-02],\n            [ 3.8376e-02,  8.3631e-04,  9.9465e-06],\n            [-2.8835e-02, -2.2292e-02, -2.1455e-03]]],\n  \n  \n          ...,\n  \n  \n          [[[-2.4478e-03,  5.2327e-02, -1.5298e-02],\n            [ 3.0101e-02, -2.9548e-03, -1.0679e-02],\n            [-7.3549e-03, -7.6644e-03, -1.7683e-02]],\n  \n           [[-1.2216e-02,  1.4038e-02, -2.3639e-02],\n            [ 3.0317e-02, -4.1579e-02,  1.3884e-02],\n            [-6.9711e-03,  1.9289e-02,  8.7853e-03]],\n  \n           [[-2.6694e-02, -1.8092e-02, -4.2012e-02],\n            [-5.6319e-02, -1.3250e-03, -2.4169e-02],\n            [-2.7920e-03, -4.9812e-02,  6.0940e-03]],\n  \n           ...,\n  \n           [[-5.1009e-02,  1.3664e-03,  1.2903e-02],\n            [ 6.9633e-02, -2.9692e-02, -3.7569e-02],\n            [ 3.9885e-02,  9.6930e-03,  6.6237e-02]],\n  \n           [[ 2.0155e-02,  1.4155e-02, -7.7627e-03],\n            [-1.8187e-02, -4.0251e-02, -5.8297e-03],\n            [ 1.9117e-02, -3.6646e-02, -3.6978e-02]],\n  \n           [[ 2.1382e-03, -1.4589e-02, -4.1422e-03],\n            [ 1.9308e-02,  3.1649e-02, -8.0743e-02],\n            [ 4.4503e-03,  2.0663e-02, -7.0815e-03]]],\n  \n  \n          [[[-2.5216e-02, -2.2953e-02, -1.3140e-02],\n            [-1.6166e-02, -1.2077e-02, -1.1348e-02],\n            [ 1.8164e-02, -1.7068e-02, -5.5312e-03]],\n  \n           [[ 3.0465e-02,  9.5054e-03,  3.3812e-02],\n            [ 5.7187e-03, -6.4852e-02,  3.7219e-02],\n            [-6.3665e-02,  1.0682e-03,  7.9524e-03]],\n  \n           [[-1.7826e-02,  1.2793e-02, -4.0524e-02],\n            [-2.8849e-02, -3.3858e-02, -1.7214e-02],\n            [-9.2936e-03, -9.0694e-02, -3.7321e-02]],\n  \n           ...,\n  \n           [[ 9.3909e-03,  1.5924e-02,  1.3192e-02],\n            [ 1.8454e-02, -2.0455e-03, -5.9107e-03],\n            [ 4.5423e-03, -1.0603e-02, -4.8922e-02]],\n  \n           [[-3.7442e-02,  5.2821e-03,  4.7385e-02],\n            [ 4.8794e-02, -4.3371e-02, -1.0199e-02],\n            [ 2.6104e-02, -1.3963e-03, -8.6061e-03]],\n  \n           [[ 3.2018e-03, -5.4097e-02,  1.0782e-02],\n            [-3.4256e-02, -1.1275e-02,  4.7361e-02],\n            [ 1.7762e-02,  2.0964e-02,  1.8498e-02]]],\n  \n  \n          [[[-3.8928e-03, -2.7141e-03,  8.0282e-02],\n            [ 1.6840e-02,  2.1849e-02, -4.4947e-03],\n            [-2.5872e-03,  1.0124e-02,  2.5470e-02]],\n  \n           [[-4.5082e-02,  1.4184e-02,  6.2454e-02],\n            [ 1.8772e-02, -2.7898e-02,  3.7316e-02],\n            [ 1.5929e-02,  4.5841e-02,  1.2856e-03]],\n  \n           [[ 4.1949e-05, -4.5213e-03, -4.3752e-02],\n            [ 2.5881e-02,  3.6509e-02, -3.6787e-02],\n            [-7.6144e-04,  2.6140e-02, -7.2909e-03]],\n  \n           ...,\n  \n           [[ 2.7576e-02,  2.2081e-04,  4.4722e-02],\n            [ 1.4542e-02, -1.9347e-02, -8.7500e-03],\n            [-3.3666e-02, -8.7216e-03,  6.1050e-02]],\n  \n           [[ 4.8506e-02,  8.1524e-03, -3.0751e-02],\n            [-9.4473e-03,  4.5495e-02, -2.2727e-02],\n            [-1.4064e-02,  3.7462e-02, -3.3589e-02]],\n  \n           [[ 3.8455e-02,  2.5547e-02, -7.7607e-02],\n            [-2.1535e-02,  3.7851e-02, -1.8051e-02],\n            [-1.2138e-02, -1.1708e-02,  7.7128e-02]]]], requires_grad=True)),\n ('layer3.4.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.4.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.4.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0045]],\n  \n           [[ 0.0044]],\n  \n           [[-0.0911]],\n  \n           ...,\n  \n           [[-0.0347]],\n  \n           [[-0.0436]],\n  \n           [[ 0.0638]]],\n  \n  \n          [[[-0.0112]],\n  \n           [[ 0.0490]],\n  \n           [[ 0.0046]],\n  \n           ...,\n  \n           [[ 0.0429]],\n  \n           [[ 0.0371]],\n  \n           [[-0.0258]]],\n  \n  \n          [[[-0.0271]],\n  \n           [[-0.0352]],\n  \n           [[-0.0645]],\n  \n           ...,\n  \n           [[ 0.0979]],\n  \n           [[-0.0059]],\n  \n           [[-0.0179]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0250]],\n  \n           [[-0.0537]],\n  \n           [[-0.0432]],\n  \n           ...,\n  \n           [[-0.0911]],\n  \n           [[-0.0098]],\n  \n           [[-0.0308]]],\n  \n  \n          [[[-0.0220]],\n  \n           [[-0.0425]],\n  \n           [[ 0.0297]],\n  \n           ...,\n  \n           [[ 0.0403]],\n  \n           [[ 0.0201]],\n  \n           [[ 0.0108]]],\n  \n  \n          [[[ 0.0364]],\n  \n           [[-0.0380]],\n  \n           [[-0.0156]],\n  \n           ...,\n  \n           [[-0.0154]],\n  \n           [[-0.0092]],\n  \n           [[ 0.0012]]]], requires_grad=True)),\n ('layer3.4.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.4.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.5.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.0043]],\n  \n           [[ 0.0350]],\n  \n           [[ 0.0014]],\n  \n           ...,\n  \n           [[ 0.0885]],\n  \n           [[ 0.0438]],\n  \n           [[ 0.0069]]],\n  \n  \n          [[[ 0.0312]],\n  \n           [[ 0.0504]],\n  \n           [[-0.0351]],\n  \n           ...,\n  \n           [[-0.0128]],\n  \n           [[ 0.1635]],\n  \n           [[ 0.0118]]],\n  \n  \n          [[[-0.2543]],\n  \n           [[ 0.1250]],\n  \n           [[ 0.1887]],\n  \n           ...,\n  \n           [[ 0.0169]],\n  \n           [[ 0.0846]],\n  \n           [[-0.0082]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0547]],\n  \n           [[ 0.0112]],\n  \n           [[-0.0782]],\n  \n           ...,\n  \n           [[ 0.1330]],\n  \n           [[ 0.0309]],\n  \n           [[ 0.0876]]],\n  \n  \n          [[[-0.0116]],\n  \n           [[ 0.0339]],\n  \n           [[-0.1773]],\n  \n           ...,\n  \n           [[ 0.0444]],\n  \n           [[ 0.0096]],\n  \n           [[ 0.1220]]],\n  \n  \n          [[[ 0.1451]],\n  \n           [[-0.0023]],\n  \n           [[ 0.2502]],\n  \n           ...,\n  \n           [[ 0.0243]],\n  \n           [[ 0.0253]],\n  \n           [[-0.0036]]]], requires_grad=True)),\n ('layer3.5.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.5.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.5.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 2.6434e-02, -2.1836e-02, -1.1234e-02],\n            [-9.2392e-03, -2.2462e-02, -2.0102e-02],\n            [ 2.2414e-02,  5.0330e-03,  6.6964e-03]],\n  \n           [[ 1.4137e-02, -1.0181e-02, -1.3095e-02],\n            [ 5.3328e-02,  6.4189e-03,  5.4357e-02],\n            [-5.3178e-03, -1.9453e-04,  1.8373e-02]],\n  \n           [[ 4.0453e-02,  3.8967e-02, -1.7597e-02],\n            [ 3.0030e-03,  2.7744e-02,  3.4714e-02],\n            [ 2.8372e-02,  2.6899e-02, -4.4800e-03]],\n  \n           ...,\n  \n           [[-4.0310e-03,  2.1234e-02, -3.4657e-02],\n            [ 5.2988e-03,  1.5898e-02,  4.7074e-02],\n            [-1.9815e-02,  2.8434e-03,  2.2006e-02]],\n  \n           [[ 1.0875e-02, -1.6967e-02, -1.9532e-02],\n            [-4.0627e-02,  5.3548e-02, -4.6134e-02],\n            [-4.3328e-02, -3.8583e-03, -5.8635e-03]],\n  \n           [[ 1.4780e-02, -3.6662e-02, -3.4554e-02],\n            [ 6.2814e-02, -4.1860e-03,  6.5860e-02],\n            [ 4.0634e-02,  2.6404e-02,  1.5064e-02]]],\n  \n  \n          [[[-2.0236e-02,  9.2149e-03, -4.0874e-02],\n            [-3.3153e-02, -8.2559e-03,  4.0984e-02],\n            [-9.6066e-03,  1.7085e-02,  2.8705e-03]],\n  \n           [[ 1.9451e-02,  3.7758e-02, -1.4316e-02],\n            [-4.3537e-02, -2.0956e-02,  3.6915e-02],\n            [-2.2385e-02,  3.3081e-02, -4.8114e-02]],\n  \n           [[ 8.5790e-03, -1.5657e-02,  6.7200e-04],\n            [-4.1046e-02, -6.8384e-02, -7.5918e-02],\n            [-6.0541e-03,  7.8350e-02, -2.0818e-02]],\n  \n           ...,\n  \n           [[ 3.8658e-02,  5.2896e-03,  4.3779e-03],\n            [-2.7270e-04,  1.8343e-02, -3.5445e-02],\n            [ 2.0636e-02,  2.6610e-02,  2.4861e-02]],\n  \n           [[-5.4595e-02,  9.0047e-03, -3.9797e-02],\n            [ 1.2457e-02,  3.4872e-02, -6.6128e-05],\n            [-3.3244e-03, -2.1983e-02,  1.8678e-02]],\n  \n           [[-1.7539e-02,  1.9651e-02,  1.3256e-02],\n            [-1.0192e-02,  1.4562e-02, -1.1938e-02],\n            [-9.4854e-03,  3.0962e-02,  3.0916e-02]]],\n  \n  \n          [[[-1.0523e-02, -1.3421e-02, -1.8469e-02],\n            [ 1.8604e-02, -1.6417e-02, -7.9428e-03],\n            [ 2.4185e-02, -1.2071e-02, -1.8940e-02]],\n  \n           [[-1.4024e-02,  9.8398e-04,  2.4521e-02],\n            [ 1.6701e-02,  4.2594e-03,  2.7685e-03],\n            [ 1.5224e-02,  7.2711e-02,  7.4280e-03]],\n  \n           [[ 2.2856e-02,  1.0961e-02,  2.5747e-02],\n            [-5.4889e-02, -3.6458e-02, -3.4843e-02],\n            [-1.7421e-02, -4.4129e-04, -1.1286e-02]],\n  \n           ...,\n  \n           [[ 1.6951e-02,  3.0037e-02,  6.9573e-03],\n            [ 2.0069e-02, -4.4338e-02,  7.7577e-02],\n            [ 4.6790e-02, -2.1949e-02, -3.5002e-03]],\n  \n           [[-1.6753e-02,  2.6515e-02,  1.1000e-02],\n            [ 9.3577e-05,  4.5227e-02,  2.1505e-03],\n            [ 2.4821e-02,  3.4910e-02,  4.2795e-02]],\n  \n           [[ 2.3439e-02,  7.7976e-04, -7.4422e-03],\n            [ 1.3590e-02, -5.2847e-03, -7.2529e-02],\n            [-7.6659e-03, -2.2971e-03, -3.8417e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[-1.2381e-02, -8.4840e-03,  4.2581e-02],\n            [ 2.9181e-02,  1.8611e-02, -4.6999e-02],\n            [-1.2886e-02,  8.5311e-03,  8.8962e-03]],\n  \n           [[-4.0055e-03,  1.9318e-03, -2.8455e-03],\n            [ 7.4364e-03,  1.3394e-02,  3.2150e-02],\n            [-6.1572e-03,  6.0423e-03,  3.2564e-02]],\n  \n           [[-2.4173e-02,  2.2617e-02, -5.6635e-03],\n            [-7.6475e-02, -7.8061e-03, -3.7392e-02],\n            [ 6.2541e-04, -1.5019e-02,  4.4601e-02]],\n  \n           ...,\n  \n           [[ 1.8854e-02,  4.6594e-03,  4.2575e-02],\n            [-3.2127e-02,  3.9457e-02,  8.4578e-03],\n            [ 1.3317e-02,  1.1770e-03,  1.5734e-02]],\n  \n           [[-1.2903e-02, -2.4881e-02,  2.8543e-02],\n            [ 9.3455e-03,  2.5847e-02,  7.2611e-03],\n            [ 1.4907e-02, -3.8168e-02, -1.2744e-02]],\n  \n           [[-1.4446e-02,  2.7135e-02,  2.6066e-03],\n            [ 1.4309e-02, -1.3428e-02,  1.0472e-02],\n            [-3.1630e-02,  2.6150e-02,  1.5644e-02]]],\n  \n  \n          [[[ 1.9963e-03, -9.8211e-03,  5.2271e-02],\n            [ 9.1818e-03,  3.4334e-02,  1.0121e-02],\n            [ 2.7377e-02,  1.0128e-02, -3.7383e-02]],\n  \n           [[-4.0218e-03, -1.2025e-02, -2.3390e-02],\n            [ 9.1903e-03,  1.9955e-02, -1.5659e-02],\n            [ 1.2404e-02, -1.3599e-03,  2.1699e-02]],\n  \n           [[ 2.7179e-02,  7.3579e-03,  1.6134e-02],\n            [ 4.0107e-02,  4.0452e-02,  1.3144e-02],\n            [-4.6361e-02, -1.8972e-02, -1.0145e-02]],\n  \n           ...,\n  \n           [[ 1.9948e-02,  2.5877e-02, -2.9555e-02],\n            [-2.8426e-02, -3.3010e-02,  3.1103e-03],\n            [ 6.9286e-03,  5.1598e-02,  4.4639e-02]],\n  \n           [[ 2.7256e-02,  2.2442e-02,  6.6776e-02],\n            [ 2.8108e-02,  3.2509e-02, -3.1326e-02],\n            [ 5.3454e-02,  7.9991e-04,  3.6430e-02]],\n  \n           [[ 1.9641e-02, -5.8673e-03,  2.1618e-02],\n            [ 1.3525e-03,  2.2246e-02,  2.6140e-02],\n            [ 3.5949e-02,  3.2162e-02,  1.0413e-02]]],\n  \n  \n          [[[ 2.9142e-02, -6.8248e-03,  3.1984e-02],\n            [ 2.3306e-02, -1.9535e-02, -2.3457e-02],\n            [ 9.2808e-03, -2.5361e-02, -1.4000e-03]],\n  \n           [[ 2.4940e-02,  4.6259e-03, -1.6168e-02],\n            [ 3.3114e-02,  5.0440e-02, -3.0993e-02],\n            [ 5.6596e-02,  7.1922e-02,  8.3012e-04]],\n  \n           [[ 3.7307e-02,  5.3811e-02,  1.0921e-02],\n            [-4.1824e-03, -2.0072e-04, -4.2779e-02],\n            [-9.4249e-03, -2.5234e-03, -8.4463e-02]],\n  \n           ...,\n  \n           [[ 3.8850e-02, -2.5920e-02, -8.6630e-03],\n            [-2.9257e-02, -1.6580e-02, -1.1036e-02],\n            [-3.2739e-03,  4.8092e-02, -2.6990e-03]],\n  \n           [[-2.1638e-02, -2.6557e-02, -6.0524e-02],\n            [-5.2343e-02,  5.4182e-03, -2.1419e-02],\n            [-3.0394e-02, -3.8983e-02, -1.6648e-02]],\n  \n           [[-4.8174e-03, -1.9662e-02, -4.5180e-02],\n            [-4.0188e-02,  1.3924e-02, -2.0476e-02],\n            [ 3.9147e-02,  7.4245e-03,  4.7037e-02]]]], requires_grad=True)),\n ('layer3.5.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.5.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.5.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0615]],\n  \n           [[ 0.0263]],\n  \n           [[ 0.0758]],\n  \n           ...,\n  \n           [[-0.0147]],\n  \n           [[ 0.0666]],\n  \n           [[ 0.0276]]],\n  \n  \n          [[[ 0.0117]],\n  \n           [[-0.0110]],\n  \n           [[-0.0161]],\n  \n           ...,\n  \n           [[ 0.0337]],\n  \n           [[-0.0308]],\n  \n           [[-0.0739]]],\n  \n  \n          [[[-0.0050]],\n  \n           [[ 0.0043]],\n  \n           [[-0.0038]],\n  \n           ...,\n  \n           [[-0.0171]],\n  \n           [[-0.0593]],\n  \n           [[-0.0623]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0822]],\n  \n           [[ 0.0019]],\n  \n           [[-0.0674]],\n  \n           ...,\n  \n           [[-0.0398]],\n  \n           [[-0.0516]],\n  \n           [[-0.0331]]],\n  \n  \n          [[[-0.0094]],\n  \n           [[-0.0401]],\n  \n           [[ 0.0197]],\n  \n           ...,\n  \n           [[-0.0362]],\n  \n           [[ 0.0016]],\n  \n           [[-0.0070]]],\n  \n  \n          [[[ 0.0430]],\n  \n           [[ 0.0288]],\n  \n           [[ 0.0055]],\n  \n           ...,\n  \n           [[-0.0367]],\n  \n           [[-0.0204]],\n  \n           [[-0.0331]]]], requires_grad=True)),\n ('layer3.5.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.5.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.0.conv1.weight',\n  Parameter containing:\n  tensor([[[[-5.9745e-02]],\n  \n           [[-7.4324e-02]],\n  \n           [[-4.4100e-02]],\n  \n           ...,\n  \n           [[ 1.5265e-03]],\n  \n           [[ 6.9681e-02]],\n  \n           [[ 6.4814e-02]]],\n  \n  \n          [[[ 9.4036e-02]],\n  \n           [[-5.6925e-02]],\n  \n           [[ 4.6335e-02]],\n  \n           ...,\n  \n           [[ 5.5958e-02]],\n  \n           [[-7.8256e-02]],\n  \n           [[-5.1269e-02]]],\n  \n  \n          [[[-2.4896e-02]],\n  \n           [[ 7.1292e-02]],\n  \n           [[ 8.5281e-02]],\n  \n           ...,\n  \n           [[ 9.0233e-02]],\n  \n           [[-5.7452e-02]],\n  \n           [[ 6.2677e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 9.4506e-02]],\n  \n           [[ 1.0230e-01]],\n  \n           [[ 1.0362e-01]],\n  \n           ...,\n  \n           [[-1.6433e-02]],\n  \n           [[ 1.5824e-02]],\n  \n           [[ 2.1363e-02]]],\n  \n  \n          [[[ 4.4766e-02]],\n  \n           [[ 8.4423e-06]],\n  \n           [[ 2.3952e-02]],\n  \n           ...,\n  \n           [[-8.0248e-02]],\n  \n           [[ 2.3833e-03]],\n  \n           [[-1.2434e-01]]],\n  \n  \n          [[[ 1.0772e-01]],\n  \n           [[-9.4413e-02]],\n  \n           [[ 4.4412e-02]],\n  \n           ...,\n  \n           [[-2.1047e-02]],\n  \n           [[ 4.6554e-03]],\n  \n           [[-4.9911e-02]]]], requires_grad=True)),\n ('layer4.0.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.0.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.0.conv2.weight',\n  Parameter containing:\n  tensor([[[[-3.8304e-03,  2.0046e-03, -2.7439e-02],\n            [ 2.7892e-02, -2.0464e-02, -4.3362e-03],\n            [-2.5856e-02, -5.1440e-03,  8.1045e-03]],\n  \n           [[-2.8010e-02, -9.9120e-03,  6.1674e-03],\n            [-1.8060e-02,  2.3548e-02, -1.8937e-03],\n            [ 3.3644e-03,  4.2877e-03,  1.9253e-03]],\n  \n           [[-1.0331e-02, -3.2050e-02, -1.2061e-02],\n            [-6.5353e-03,  2.3804e-03, -2.7365e-03],\n            [ 2.2381e-02, -1.9510e-02,  2.5892e-02]],\n  \n           ...,\n  \n           [[-1.1943e-02,  2.3960e-02,  5.1885e-02],\n            [-5.3831e-03, -1.0590e-03, -1.4592e-02],\n            [ 2.0945e-03,  4.8015e-02, -1.5303e-02]],\n  \n           [[-1.7354e-03,  1.1883e-02,  1.1044e-02],\n            [ 1.5336e-03, -2.9820e-03,  2.1448e-02],\n            [ 1.9597e-02, -1.4044e-02, -1.7430e-02]],\n  \n           [[ 1.1387e-02,  9.9918e-03, -4.7555e-03],\n            [-1.8673e-02, -1.7513e-02, -1.8200e-03],\n            [ 8.1278e-03, -3.9202e-03,  2.1658e-02]]],\n  \n  \n          [[[ 2.8501e-02,  3.0649e-03, -1.6597e-02],\n            [ 4.4866e-02, -4.0526e-03, -4.5529e-04],\n            [-2.2344e-02,  3.5199e-02, -5.6911e-03]],\n  \n           [[ 2.5598e-03, -2.3868e-02, -2.4421e-03],\n            [-2.8201e-02, -3.8168e-02, -1.9877e-02],\n            [ 8.1070e-03,  2.6183e-02,  1.4152e-02]],\n  \n           [[ 3.0290e-02, -5.1524e-02,  3.9259e-02],\n            [-2.3437e-02, -2.1343e-02,  5.6372e-03],\n            [-6.6533e-03, -4.1233e-02, -1.4518e-02]],\n  \n           ...,\n  \n           [[-2.4665e-02, -3.3341e-02, -1.4408e-02],\n            [ 1.8418e-03, -1.1030e-03, -2.3373e-02],\n            [ 4.1626e-02,  2.6753e-02,  1.1980e-02]],\n  \n           [[ 2.3877e-02, -1.9031e-02, -2.6479e-02],\n            [-1.0980e-03,  1.3448e-02, -6.7551e-03],\n            [-9.5208e-03, -1.1656e-02,  1.0237e-02]],\n  \n           [[-1.0321e-02,  1.7482e-02,  4.3014e-02],\n            [-4.0213e-03, -3.8233e-02, -1.4208e-02],\n            [-4.1915e-03, -6.1718e-03, -6.7788e-03]]],\n  \n  \n          [[[-1.9105e-02,  3.1632e-02,  7.9245e-03],\n            [ 3.2457e-03, -5.9955e-03, -2.9531e-02],\n            [ 3.0654e-03, -3.3552e-02, -1.2069e-02]],\n  \n           [[-7.8934e-03, -3.6186e-03, -1.0570e-02],\n            [-1.8258e-02,  6.7459e-03,  1.1433e-02],\n            [-2.4231e-02,  4.5846e-03,  2.6002e-02]],\n  \n           [[ 7.8882e-03,  5.1516e-03,  2.4427e-02],\n            [ 1.9511e-02,  4.8677e-03,  2.5931e-02],\n            [ 7.1875e-03,  1.0486e-02, -8.4402e-03]],\n  \n           ...,\n  \n           [[-2.1804e-03, -2.2392e-02, -1.4152e-02],\n            [ 1.7224e-02, -3.8805e-02, -4.0450e-02],\n            [-3.3390e-02, -3.5384e-04, -2.2877e-02]],\n  \n           [[ 2.3938e-02,  4.4311e-05, -4.7773e-02],\n            [ 2.8038e-02,  1.3672e-02,  1.8736e-02],\n            [-1.4882e-02,  1.4046e-02, -1.2547e-02]],\n  \n           [[-4.0174e-02, -1.7367e-02, -2.2264e-02],\n            [-2.5122e-03, -2.5608e-02, -9.6666e-03],\n            [-2.7492e-02, -2.4944e-02, -1.7466e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 1.5336e-03,  1.0210e-02,  2.9918e-02],\n            [ 3.6739e-02, -1.6524e-02, -1.1422e-02],\n            [ 2.4231e-02,  1.1863e-04,  2.0878e-02]],\n  \n           [[-2.1000e-02,  5.3396e-03,  2.7090e-02],\n            [-1.4960e-02,  2.7985e-02,  2.7828e-03],\n            [ 3.9340e-03, -4.5147e-03, -4.6418e-02]],\n  \n           [[-1.6133e-03, -2.2086e-02, -2.9943e-02],\n            [ 2.8666e-02,  4.4507e-02, -7.9303e-03],\n            [-1.2702e-02,  2.7493e-03,  5.3313e-02]],\n  \n           ...,\n  \n           [[ 4.7325e-03, -3.9084e-03, -5.6850e-03],\n            [ 1.5464e-02, -5.0315e-02, -1.5982e-02],\n            [ 2.8746e-02, -4.8295e-02,  1.4566e-03]],\n  \n           [[ 1.0323e-02, -3.1141e-02, -2.1491e-02],\n            [-6.4892e-03, -6.0506e-03,  3.8508e-02],\n            [-2.7322e-02,  1.5664e-02,  3.0606e-02]],\n  \n           [[ 1.7488e-02,  1.1108e-02, -8.0003e-03],\n            [-2.5927e-02,  4.9017e-02, -4.0043e-02],\n            [ 2.6868e-02, -3.2086e-02, -2.8714e-03]]],\n  \n  \n          [[[ 3.6620e-03, -2.9163e-02, -1.8104e-02],\n            [ 8.2524e-03,  1.1828e-02,  3.4014e-02],\n            [ 2.2276e-02,  1.8918e-02,  2.0629e-02]],\n  \n           [[ 8.2328e-03,  1.8445e-02,  2.2128e-02],\n            [-2.3662e-02, -4.4555e-03, -2.7564e-02],\n            [-1.8956e-03, -2.8180e-02, -1.0048e-02]],\n  \n           [[ 1.6084e-02, -2.4208e-02,  2.2892e-02],\n            [ 5.5978e-03, -5.1475e-02, -1.7993e-02],\n            [-5.7298e-03, -9.5657e-03, -6.6069e-03]],\n  \n           ...,\n  \n           [[-1.8728e-02, -3.3384e-02,  3.2787e-02],\n            [ 7.3618e-03,  7.6472e-03,  6.7767e-03],\n            [-3.5113e-03,  3.9306e-03,  1.6094e-03]],\n  \n           [[ 5.9951e-03,  5.4963e-03, -2.2865e-02],\n            [-6.9230e-03, -6.2176e-03, -1.6691e-02],\n            [ 1.5921e-02, -7.2493e-03,  3.4725e-02]],\n  \n           [[-1.9864e-02,  7.7958e-03,  1.8141e-02],\n            [ 2.3738e-02,  9.3161e-03,  3.5635e-03],\n            [-3.9675e-03,  4.7543e-03,  7.5388e-03]]],\n  \n  \n          [[[ 1.0158e-02, -8.2707e-03, -1.8857e-02],\n            [-4.6163e-03,  6.1191e-03,  2.7733e-03],\n            [ 3.3697e-02,  3.5186e-02,  8.1448e-03]],\n  \n           [[ 1.4247e-03,  1.9141e-03,  1.6456e-02],\n            [ 2.4840e-02, -3.0980e-02,  1.6093e-02],\n            [-1.1054e-02,  6.7501e-03,  3.0667e-02]],\n  \n           [[ 7.5286e-03,  6.5059e-03,  6.3152e-04],\n            [ 1.4788e-02, -6.2009e-03, -4.0890e-02],\n            [-1.0598e-02,  5.4706e-04, -1.0918e-02]],\n  \n           ...,\n  \n           [[ 2.1269e-02, -1.7388e-02, -4.3288e-02],\n            [-3.0102e-03, -6.4838e-03,  1.1306e-02],\n            [ 2.9644e-02,  1.6322e-02,  1.9997e-02]],\n  \n           [[-3.4962e-02,  1.4516e-02,  1.0152e-03],\n            [-4.5765e-02, -1.6689e-02,  3.4970e-02],\n            [ 2.0386e-02,  2.8021e-03, -3.2868e-02]],\n  \n           [[ 3.2117e-03, -3.6542e-02, -3.9330e-03],\n            [-1.0898e-02,  5.8171e-03,  9.4409e-03],\n            [ 1.2874e-02, -8.5553e-04, -2.1420e-02]]]], requires_grad=True)),\n ('layer4.0.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.0.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.0.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0046]],\n  \n           [[-0.0008]],\n  \n           [[-0.0233]],\n  \n           ...,\n  \n           [[-0.0107]],\n  \n           [[-0.0437]],\n  \n           [[-0.0185]]],\n  \n  \n          [[[ 0.0070]],\n  \n           [[ 0.0212]],\n  \n           [[ 0.0024]],\n  \n           ...,\n  \n           [[ 0.0335]],\n  \n           [[-0.0535]],\n  \n           [[-0.0604]]],\n  \n  \n          [[[-0.0353]],\n  \n           [[-0.0117]],\n  \n           [[-0.0006]],\n  \n           ...,\n  \n           [[ 0.0195]],\n  \n           [[ 0.0140]],\n  \n           [[-0.0113]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0137]],\n  \n           [[ 0.0049]],\n  \n           [[-0.0327]],\n  \n           ...,\n  \n           [[-0.0119]],\n  \n           [[ 0.0281]],\n  \n           [[ 0.0484]]],\n  \n  \n          [[[-0.0099]],\n  \n           [[-0.0086]],\n  \n           [[-0.0018]],\n  \n           ...,\n  \n           [[-0.0190]],\n  \n           [[-0.0030]],\n  \n           [[-0.0048]]],\n  \n  \n          [[[-0.0155]],\n  \n           [[ 0.0632]],\n  \n           [[-0.0235]],\n  \n           ...,\n  \n           [[-0.0011]],\n  \n           [[-0.0269]],\n  \n           [[ 0.0105]]]], requires_grad=True)),\n ('layer4.0.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.0.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.0.downsample.0.weight',\n  Parameter containing:\n  tensor([[[[ 0.0083]],\n  \n           [[-0.0228]],\n  \n           [[-0.0358]],\n  \n           ...,\n  \n           [[ 0.0407]],\n  \n           [[ 0.0470]],\n  \n           [[ 0.0972]]],\n  \n  \n          [[[-0.0314]],\n  \n           [[-0.0021]],\n  \n           [[-0.0051]],\n  \n           ...,\n  \n           [[ 0.0472]],\n  \n           [[-0.0119]],\n  \n           [[ 0.0029]]],\n  \n  \n          [[[-0.0372]],\n  \n           [[-0.0418]],\n  \n           [[-0.0275]],\n  \n           ...,\n  \n           [[-0.0457]],\n  \n           [[ 0.0187]],\n  \n           [[ 0.0087]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0391]],\n  \n           [[ 0.0145]],\n  \n           [[ 0.0012]],\n  \n           ...,\n  \n           [[ 0.0104]],\n  \n           [[-0.0364]],\n  \n           [[ 0.0500]]],\n  \n  \n          [[[ 0.0189]],\n  \n           [[ 0.0402]],\n  \n           [[-0.0187]],\n  \n           ...,\n  \n           [[-0.0638]],\n  \n           [[ 0.0278]],\n  \n           [[-0.0170]]],\n  \n  \n          [[[-0.0285]],\n  \n           [[-0.0459]],\n  \n           [[ 0.0076]],\n  \n           ...,\n  \n           [[-0.0510]],\n  \n           [[-0.0109]],\n  \n           [[-0.0272]]]], requires_grad=True)),\n ('layer4.0.downsample.1.weight',\n  Parameter containing:\n  tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)),\n ('layer4.0.downsample.1.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.1.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.1204]],\n  \n           [[ 0.0467]],\n  \n           [[ 0.0948]],\n  \n           ...,\n  \n           [[-0.0150]],\n  \n           [[ 0.0605]],\n  \n           [[-0.0105]]],\n  \n  \n          [[[-0.0534]],\n  \n           [[-0.0625]],\n  \n           [[-0.1042]],\n  \n           ...,\n  \n           [[ 0.1123]],\n  \n           [[-0.0423]],\n  \n           [[ 0.0004]]],\n  \n  \n          [[[ 0.0787]],\n  \n           [[ 0.0911]],\n  \n           [[-0.0282]],\n  \n           ...,\n  \n           [[ 0.0347]],\n  \n           [[ 0.0323]],\n  \n           [[-0.0826]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0602]],\n  \n           [[ 0.0721]],\n  \n           [[ 0.0858]],\n  \n           ...,\n  \n           [[-0.0578]],\n  \n           [[-0.0190]],\n  \n           [[ 0.0481]]],\n  \n  \n          [[[ 0.1233]],\n  \n           [[ 0.0088]],\n  \n           [[ 0.0011]],\n  \n           ...,\n  \n           [[-0.0653]],\n  \n           [[ 0.0105]],\n  \n           [[-0.0348]]],\n  \n  \n          [[[-0.0663]],\n  \n           [[ 0.0027]],\n  \n           [[ 0.1578]],\n  \n           ...,\n  \n           [[ 0.0338]],\n  \n           [[-0.0268]],\n  \n           [[ 0.0397]]]], requires_grad=True)),\n ('layer4.1.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.1.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.1.conv2.weight',\n  Parameter containing:\n  tensor([[[[-1.4875e-02,  3.2817e-02,  2.0309e-03],\n            [ 2.7361e-02,  1.7980e-02,  4.7771e-03],\n            [ 8.3609e-03,  1.9908e-03, -2.1515e-02]],\n  \n           [[ 1.5472e-02, -1.8721e-02, -1.5944e-02],\n            [ 1.0105e-02, -1.6259e-02,  4.2593e-03],\n            [-1.4311e-02, -2.1756e-02, -3.5767e-02]],\n  \n           [[-2.0048e-03,  2.5163e-02,  2.1553e-03],\n            [ 7.1713e-03, -1.5705e-02,  6.5028e-03],\n            [-2.8759e-04,  1.9339e-02,  1.1133e-02]],\n  \n           ...,\n  \n           [[ 1.9712e-02, -1.4370e-02,  1.4445e-02],\n            [ 1.0048e-03,  7.7705e-03,  3.4548e-03],\n            [ 4.1120e-02, -2.0746e-02,  1.8221e-02]],\n  \n           [[-3.8585e-02,  1.9015e-05,  2.3851e-02],\n            [ 2.2705e-02, -1.2875e-02, -4.3378e-02],\n            [-1.0224e-03, -1.1943e-02, -5.5919e-02]],\n  \n           [[ 2.7346e-03,  5.4173e-03,  1.4899e-02],\n            [-2.9461e-02, -6.3389e-03, -2.5316e-02],\n            [-8.9263e-04, -2.2314e-02, -1.3692e-03]]],\n  \n  \n          [[[-2.3572e-02,  1.3061e-02,  8.1310e-03],\n            [-3.3054e-02,  3.7524e-03, -8.4084e-03],\n            [ 2.0152e-02,  9.5777e-03, -3.0059e-02]],\n  \n           [[ 2.0882e-02, -3.3932e-04, -2.1867e-02],\n            [-5.7642e-03, -2.5067e-02, -3.2238e-02],\n            [-3.9565e-03,  9.7498e-03, -7.4497e-03]],\n  \n           [[-4.2966e-03,  1.1454e-02,  9.1774e-03],\n            [-4.3429e-03, -9.5762e-04, -2.8221e-04],\n            [-2.4145e-03,  5.8480e-03, -6.3342e-03]],\n  \n           ...,\n  \n           [[ 1.5185e-02,  1.7225e-02, -1.3493e-02],\n            [ 1.8122e-02, -2.5433e-02, -8.0547e-03],\n            [-3.2391e-03,  3.1090e-03,  2.7796e-02]],\n  \n           [[ 2.5820e-02, -2.0805e-03,  3.1768e-02],\n            [-4.5366e-03,  2.5713e-03, -5.1541e-02],\n            [ 2.7077e-02,  2.4704e-02,  2.3425e-02]],\n  \n           [[ 1.0992e-02, -4.3989e-03, -2.9784e-02],\n            [-3.8059e-02, -3.4452e-03,  1.6183e-02],\n            [-2.3624e-02,  3.6482e-03, -3.8072e-03]]],\n  \n  \n          [[[-2.5082e-02, -2.1973e-02,  2.4752e-02],\n            [ 8.6584e-03, -4.8067e-03,  3.2572e-02],\n            [ 3.1512e-02, -1.4320e-02,  4.2325e-03]],\n  \n           [[-2.4489e-03,  7.2891e-03, -4.3926e-02],\n            [-3.4502e-03, -3.2062e-03,  2.8278e-02],\n            [ 2.1744e-03, -1.1845e-04,  3.5486e-02]],\n  \n           [[-1.5193e-02,  3.4429e-02,  1.2551e-02],\n            [-1.3719e-02,  1.1010e-02, -1.6960e-02],\n            [-4.3950e-04, -7.7311e-03,  1.3521e-02]],\n  \n           ...,\n  \n           [[ 4.4235e-04, -1.6710e-02,  2.8953e-02],\n            [ 2.0065e-02,  9.1982e-03, -3.5463e-02],\n            [ 1.7301e-02, -1.9391e-02, -2.4868e-02]],\n  \n           [[ 1.7814e-02, -5.5200e-03, -2.2634e-02],\n            [-3.7579e-03,  1.1860e-02, -5.0001e-04],\n            [-5.1746e-03, -1.8023e-02, -5.7977e-03]],\n  \n           [[ 2.3632e-02,  2.4088e-02, -1.4406e-02],\n            [ 4.4347e-03, -1.2388e-02, -3.5370e-02],\n            [ 3.0446e-02,  5.7332e-03,  2.2244e-04]]],\n  \n  \n          ...,\n  \n  \n          [[[-2.5161e-03, -1.5265e-02, -2.7160e-02],\n            [ 1.5742e-02,  1.2813e-02, -4.9171e-03],\n            [ 3.2447e-02,  3.7092e-02,  2.4212e-03]],\n  \n           [[ 1.2892e-02, -5.6578e-03,  4.0294e-03],\n            [-1.8055e-02, -2.5514e-02,  4.1187e-03],\n            [-4.0521e-02, -1.6409e-02,  2.2845e-02]],\n  \n           [[-1.1588e-02, -6.1483e-03,  2.0049e-02],\n            [-3.7533e-03,  2.4134e-02,  5.8985e-03],\n            [ 1.6091e-02,  4.1375e-02, -1.1914e-03]],\n  \n           ...,\n  \n           [[-1.8447e-02,  2.1346e-02, -2.0074e-02],\n            [ 4.4945e-02,  8.4388e-03, -4.4124e-03],\n            [-3.5401e-02,  1.3727e-02, -3.0955e-02]],\n  \n           [[-8.4029e-03, -6.6551e-03, -1.2266e-02],\n            [ 2.0679e-02,  4.7484e-02, -3.3798e-04],\n            [ 1.6623e-02, -2.4894e-02, -3.1041e-02]],\n  \n           [[-9.0618e-03, -2.8014e-03, -2.0485e-03],\n            [ 1.0627e-02, -5.7895e-03, -1.2222e-02],\n            [-3.6892e-03,  1.8226e-02,  3.0287e-03]]],\n  \n  \n          [[[-1.4413e-02, -2.5413e-02,  1.1292e-02],\n            [-1.8975e-02,  4.7378e-04,  2.7890e-02],\n            [-5.3665e-03,  6.1852e-03,  1.8250e-02]],\n  \n           [[-2.0131e-02, -4.0751e-02, -7.6659e-03],\n            [-2.9683e-02, -1.3461e-02,  4.4304e-03],\n            [-4.3538e-02, -2.5943e-02,  3.9320e-02]],\n  \n           [[ 1.4356e-02, -3.6358e-04,  1.3382e-03],\n            [-1.8499e-02,  4.6870e-04,  1.2708e-06],\n            [-1.0194e-02,  2.3945e-02, -2.1767e-02]],\n  \n           ...,\n  \n           [[-1.2497e-02, -2.6169e-03, -2.8204e-02],\n            [-1.1539e-02,  9.4762e-03,  2.0115e-02],\n            [ 3.3677e-02, -1.7105e-02,  1.4507e-02]],\n  \n           [[-1.3053e-02, -2.8408e-02, -4.0868e-02],\n            [-2.8236e-02,  6.2103e-03, -4.6452e-03],\n            [ 4.4288e-03,  1.4584e-02, -3.8451e-03]],\n  \n           [[ 2.6254e-02,  1.8147e-02,  3.6901e-02],\n            [ 1.7411e-02, -3.1215e-02,  5.8578e-03],\n            [-4.6043e-02,  7.0331e-02, -2.2305e-02]]],\n  \n  \n          [[[ 6.3843e-03, -2.6831e-02, -1.0774e-02],\n            [ 1.4541e-02,  9.5206e-03, -6.6421e-03],\n            [ 2.6314e-02,  1.0686e-02,  1.6661e-03]],\n  \n           [[ 1.4916e-02, -1.0201e-02,  1.5558e-02],\n            [ 1.7815e-03,  1.8692e-02, -2.5806e-02],\n            [ 1.0424e-02,  3.0308e-02,  1.9223e-02]],\n  \n           [[ 3.0190e-02,  1.5153e-02, -7.5506e-03],\n            [ 1.0196e-02,  9.0764e-03,  1.5230e-02],\n            [ 2.2625e-02,  1.7294e-02,  1.0638e-02]],\n  \n           ...,\n  \n           [[ 1.1707e-02,  1.8566e-02, -1.4157e-02],\n            [-8.9678e-03,  2.0868e-02,  1.1559e-02],\n            [ 7.8745e-04,  3.0270e-02,  1.4833e-02]],\n  \n           [[-5.7109e-03, -1.2130e-02, -2.7492e-02],\n            [-4.6356e-03,  3.6730e-02,  1.3568e-02],\n            [ 4.1427e-02, -7.8176e-03, -7.0532e-03]],\n  \n           [[ 4.5137e-03,  1.3893e-02, -2.5502e-02],\n            [ 3.4937e-02, -9.3189e-03,  1.8159e-02],\n            [-1.0250e-02,  4.7569e-04, -1.2051e-02]]]], requires_grad=True)),\n ('layer4.1.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.1.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.1.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0697]],\n  \n           [[ 0.0180]],\n  \n           [[-0.0302]],\n  \n           ...,\n  \n           [[ 0.0276]],\n  \n           [[ 0.0211]],\n  \n           [[-0.0052]]],\n  \n  \n          [[[ 0.0008]],\n  \n           [[-0.0202]],\n  \n           [[ 0.0040]],\n  \n           ...,\n  \n           [[-0.0055]],\n  \n           [[-0.0018]],\n  \n           [[ 0.0169]]],\n  \n  \n          [[[ 0.0036]],\n  \n           [[-0.0117]],\n  \n           [[-0.0001]],\n  \n           ...,\n  \n           [[-0.0088]],\n  \n           [[ 0.0150]],\n  \n           [[-0.0107]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0468]],\n  \n           [[ 0.0299]],\n  \n           [[-0.0465]],\n  \n           ...,\n  \n           [[ 0.0008]],\n  \n           [[ 0.0666]],\n  \n           [[-0.0275]]],\n  \n  \n          [[[-0.0167]],\n  \n           [[-0.0299]],\n  \n           [[-0.0457]],\n  \n           ...,\n  \n           [[ 0.0287]],\n  \n           [[-0.1034]],\n  \n           [[ 0.0131]]],\n  \n  \n          [[[ 0.0016]],\n  \n           [[-0.0029]],\n  \n           [[ 0.0188]],\n  \n           ...,\n  \n           [[ 0.0329]],\n  \n           [[-0.0163]],\n  \n           [[-0.0215]]]], requires_grad=True)),\n ('layer4.1.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.1.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.2.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0869]],\n  \n           [[ 0.0008]],\n  \n           [[-0.0862]],\n  \n           ...,\n  \n           [[-0.0899]],\n  \n           [[ 0.0431]],\n  \n           [[ 0.0210]]],\n  \n  \n          [[[-0.0638]],\n  \n           [[ 0.0383]],\n  \n           [[-0.0071]],\n  \n           ...,\n  \n           [[ 0.0776]],\n  \n           [[ 0.0079]],\n  \n           [[-0.0025]]],\n  \n  \n          [[[-0.0752]],\n  \n           [[ 0.0471]],\n  \n           [[ 0.0177]],\n  \n           ...,\n  \n           [[-0.0676]],\n  \n           [[ 0.0094]],\n  \n           [[-0.0518]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0063]],\n  \n           [[-0.0471]],\n  \n           [[-0.0583]],\n  \n           ...,\n  \n           [[ 0.0199]],\n  \n           [[-0.0632]],\n  \n           [[-0.0098]]],\n  \n  \n          [[[ 0.0009]],\n  \n           [[-0.0451]],\n  \n           [[-0.0351]],\n  \n           ...,\n  \n           [[ 0.0193]],\n  \n           [[ 0.0237]],\n  \n           [[-0.0408]]],\n  \n  \n          [[[ 0.1019]],\n  \n           [[ 0.0358]],\n  \n           [[-0.0502]],\n  \n           ...,\n  \n           [[-0.0375]],\n  \n           [[ 0.0198]],\n  \n           [[ 0.0104]]]], requires_grad=True)),\n ('layer4.2.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.2.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.2.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 4.0372e-03,  9.6009e-03,  5.7336e-03],\n            [ 3.6475e-03,  1.3929e-03, -4.3581e-02],\n            [ 1.8282e-02,  2.6522e-02, -4.4680e-03]],\n  \n           [[ 1.8466e-03, -2.1687e-02,  3.2666e-02],\n            [-1.1404e-03,  4.9626e-03,  2.6408e-02],\n            [ 7.1162e-03,  1.9486e-02, -2.4696e-02]],\n  \n           [[-1.1102e-02, -3.2891e-03,  1.2114e-02],\n            [-3.5552e-02,  1.5232e-02,  3.2585e-02],\n            [-2.1484e-02,  3.1279e-02,  1.4156e-02]],\n  \n           ...,\n  \n           [[-2.5637e-03,  2.4398e-03, -3.0658e-03],\n            [-1.1979e-02,  1.6302e-02,  2.3396e-03],\n            [ 8.2219e-03,  6.6287e-02, -7.6532e-03]],\n  \n           [[-2.9873e-03,  3.1535e-03, -3.0700e-03],\n            [ 3.1522e-02, -3.0844e-02, -2.4698e-02],\n            [ 2.0255e-02, -5.4907e-03,  7.8847e-03]],\n  \n           [[-4.5566e-02, -3.2117e-04, -2.9282e-02],\n            [ 2.1581e-02,  3.1376e-02, -6.7348e-03],\n            [ 3.3176e-02, -1.7408e-02, -1.2875e-03]]],\n  \n  \n          [[[ 9.0611e-03, -7.6816e-04, -1.9904e-02],\n            [-7.1802e-03,  1.6015e-02, -1.7035e-02],\n            [ 8.4524e-03,  2.4376e-02, -1.3405e-02]],\n  \n           [[ 1.3314e-03, -3.2731e-02, -2.7464e-02],\n            [ 3.4712e-02, -1.2054e-02, -1.3446e-02],\n            [ 1.7766e-03,  6.2005e-02, -3.8113e-02]],\n  \n           [[ 4.3504e-02,  8.5865e-04,  7.6798e-04],\n            [-1.7990e-02,  1.2751e-02, -7.5429e-03],\n            [ 1.0408e-02,  3.8950e-02, -1.0803e-02]],\n  \n           ...,\n  \n           [[-4.2192e-02,  3.7597e-02,  1.2419e-03],\n            [-1.1473e-02, -2.0376e-02,  1.3651e-02],\n            [ 1.8838e-02, -1.9380e-02, -1.4051e-02]],\n  \n           [[-3.3401e-03, -1.8234e-03,  1.1112e-02],\n            [ 2.3838e-02, -7.7340e-03,  1.4265e-03],\n            [-3.9946e-03, -4.3768e-02, -1.4484e-03]],\n  \n           [[-1.8119e-02,  2.5660e-02,  3.8637e-03],\n            [ 5.3056e-04, -1.4192e-02, -1.6952e-02],\n            [ 1.3493e-02, -1.7834e-02,  2.4105e-02]]],\n  \n  \n          [[[ 1.4504e-02,  1.2735e-02,  2.6928e-03],\n            [ 4.2135e-03,  4.0163e-03,  3.3633e-02],\n            [ 1.4109e-02,  2.5378e-02,  3.2268e-03]],\n  \n           [[-4.0881e-02,  2.9987e-02, -6.7412e-03],\n            [-1.3335e-03,  9.1620e-03, -3.5123e-04],\n            [-2.5886e-02,  1.2616e-02,  1.3708e-02]],\n  \n           [[-2.6507e-03, -2.2557e-02,  3.2115e-02],\n            [-2.4336e-02, -3.8428e-03, -2.8200e-02],\n            [-1.9067e-02,  2.4719e-02, -5.3098e-02]],\n  \n           ...,\n  \n           [[ 1.3047e-02, -4.6418e-02,  1.8212e-02],\n            [ 1.8339e-02,  2.4303e-03,  1.7478e-02],\n            [ 1.5208e-02, -8.4832e-03,  3.6281e-02]],\n  \n           [[-1.3485e-02,  6.7969e-03,  2.2060e-02],\n            [ 3.4260e-02,  3.5324e-03, -2.3624e-02],\n            [-1.1581e-02, -1.8611e-02, -1.7838e-02]],\n  \n           [[-2.5433e-03,  2.6012e-02,  1.2603e-02],\n            [ 2.5943e-02,  1.4686e-02, -2.8406e-03],\n            [-1.1629e-02,  1.8200e-02,  2.5403e-03]]],\n  \n  \n          ...,\n  \n  \n          [[[ 2.7300e-02,  1.0148e-02,  3.8089e-02],\n            [-3.7646e-02, -2.8380e-02,  6.6293e-03],\n            [-1.4086e-02, -2.3508e-02,  3.8443e-02]],\n  \n           [[-3.1648e-02,  2.7956e-04, -4.5027e-03],\n            [-3.5491e-02,  4.1126e-02, -3.2401e-02],\n            [ 2.2612e-02, -1.0945e-02, -4.6242e-03]],\n  \n           [[-2.6057e-02,  5.9616e-03, -2.8074e-02],\n            [ 1.2896e-02,  1.8758e-02, -1.3279e-02],\n            [ 9.2041e-03, -5.8497e-03, -1.0998e-02]],\n  \n           ...,\n  \n           [[-9.1234e-03,  6.9578e-03, -2.1609e-02],\n            [ 1.9468e-03,  1.8515e-02, -1.8667e-04],\n            [ 3.8241e-02, -1.6975e-02,  2.9781e-02]],\n  \n           [[ 3.0355e-02, -8.8759e-04, -2.8915e-02],\n            [ 1.3347e-02,  3.3460e-03,  7.2086e-03],\n            [-2.0003e-02,  1.0483e-02,  1.0230e-02]],\n  \n           [[ 1.1430e-03, -2.5290e-02, -7.6073e-03],\n            [ 1.6937e-02,  8.2370e-03,  2.9507e-02],\n            [ 1.3583e-02, -1.5253e-02, -2.7242e-02]]],\n  \n  \n          [[[-7.6098e-04,  3.9051e-03,  1.8709e-02],\n            [-1.1853e-02, -3.9333e-03, -2.3217e-02],\n            [ 1.3281e-02,  6.7374e-03, -1.1190e-02]],\n  \n           [[-1.4907e-02, -2.2079e-02, -5.1073e-03],\n            [ 8.6738e-03,  2.5048e-02,  3.1550e-02],\n            [ 1.2738e-02,  1.1874e-02,  7.4871e-03]],\n  \n           [[-1.3418e-02, -1.6440e-02,  2.0048e-03],\n            [ 3.3758e-02,  1.7985e-02, -7.6593e-03],\n            [ 1.0501e-02, -1.1576e-02,  1.1482e-02]],\n  \n           ...,\n  \n           [[-3.9476e-02,  4.3286e-02, -1.4864e-02],\n            [ 1.0187e-02,  3.5476e-03, -2.0036e-03],\n            [ 2.8613e-02,  5.0859e-03,  1.9285e-02]],\n  \n           [[ 2.6005e-02, -9.6460e-03,  1.4698e-02],\n            [ 1.5942e-02, -6.0562e-03,  5.4321e-03],\n            [ 1.8563e-02,  2.8981e-02, -4.2562e-02]],\n  \n           [[ 6.3422e-03, -8.8243e-03,  1.2056e-02],\n            [-8.7140e-03, -7.0939e-03,  4.0304e-02],\n            [-1.3844e-02, -1.5328e-02,  1.6865e-02]]],\n  \n  \n          [[[ 9.2547e-03, -2.0169e-02, -2.6993e-02],\n            [ 2.2630e-02, -9.1510e-03,  2.9532e-03],\n            [ 1.5936e-02, -1.2428e-02, -1.1674e-02]],\n  \n           [[-6.4904e-03, -2.4222e-02,  3.2656e-04],\n            [-7.8919e-03, -2.1352e-02,  1.6693e-02],\n            [ 1.6575e-02,  3.7735e-03, -3.0243e-02]],\n  \n           [[ 7.2092e-03,  3.3445e-02,  3.1266e-02],\n            [ 3.0373e-03, -4.3604e-02,  1.2334e-02],\n            [ 1.8124e-02, -1.6813e-02, -3.5622e-02]],\n  \n           ...,\n  \n           [[-5.3451e-04, -7.1725e-04,  3.3224e-02],\n            [ 3.2404e-02,  2.0535e-02,  3.7013e-02],\n            [ 1.8017e-02, -4.6330e-03, -7.2671e-05]],\n  \n           [[-2.1402e-02, -1.5603e-02, -2.9944e-02],\n            [ 2.2587e-02, -2.3721e-02,  1.6249e-02],\n            [ 2.3000e-02,  1.2225e-02, -2.4762e-02]],\n  \n           [[-7.1571e-03,  5.2951e-03, -6.9071e-03],\n            [ 1.3710e-02, -1.1639e-02, -2.1029e-02],\n            [-2.8345e-02, -9.9142e-03,  1.6903e-02]]]], requires_grad=True)),\n ('layer4.2.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.2.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.2.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 1.2131e-02]],\n  \n           [[ 5.8428e-02]],\n  \n           [[ 2.0046e-02]],\n  \n           ...,\n  \n           [[ 1.2015e-03]],\n  \n           [[-5.0296e-04]],\n  \n           [[ 2.0999e-03]]],\n  \n  \n          [[[-3.1696e-03]],\n  \n           [[ 1.6836e-02]],\n  \n           [[-4.9158e-02]],\n  \n           ...,\n  \n           [[ 2.1881e-02]],\n  \n           [[ 1.6721e-02]],\n  \n           [[-1.4479e-02]]],\n  \n  \n          [[[ 1.4656e-02]],\n  \n           [[-1.9131e-02]],\n  \n           [[-1.2144e-02]],\n  \n           ...,\n  \n           [[ 2.0264e-02]],\n  \n           [[-6.3847e-02]],\n  \n           [[-1.8942e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 5.3712e-05]],\n  \n           [[ 3.9394e-02]],\n  \n           [[ 4.2408e-03]],\n  \n           ...,\n  \n           [[ 1.0187e-02]],\n  \n           [[-3.4083e-02]],\n  \n           [[ 3.9114e-02]]],\n  \n  \n          [[[ 1.5032e-02]],\n  \n           [[-9.2758e-03]],\n  \n           [[-1.4523e-02]],\n  \n           ...,\n  \n           [[-6.3346e-04]],\n  \n           [[ 8.7917e-03]],\n  \n           [[-3.3098e-02]]],\n  \n  \n          [[[-5.7945e-03]],\n  \n           [[ 2.6874e-02]],\n  \n           [[-3.3141e-02]],\n  \n           ...,\n  \n           [[ 1.7235e-02]],\n  \n           [[-9.5212e-03]],\n  \n           [[-2.5897e-02]]]], requires_grad=True)),\n ('layer4.2.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.2.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('fc.weight',\n  Parameter containing:\n  tensor([[ 0.0066,  0.0131, -0.0071,  ..., -0.0081, -0.0121, -0.0037],\n          [ 0.0060,  0.0119,  0.0071,  ..., -0.0145,  0.0127, -0.0213],\n          [-0.0149, -0.0186, -0.0024,  ..., -0.0134, -0.0213,  0.0144],\n          ...,\n          [ 0.0178,  0.0139,  0.0033,  ..., -0.0196, -0.0128, -0.0092],\n          [ 0.0086, -0.0037, -0.0164,  ...,  0.0169,  0.0027, -0.0115],\n          [ 0.0034,  0.0171,  0.0171,  ...,  0.0028,  0.0152,  0.0161]],\n         requires_grad=True)),\n ('fc.bias',\n  Parameter containing:\n  tensor([-4.9517e-03, -2.5835e-03,  2.0803e-02,  9.4650e-03,  3.3053e-03,\n          -5.6519e-03,  1.9817e-02,  2.0498e-02, -1.6693e-02,  2.1255e-02,\n          -9.7826e-04, -9.4811e-03,  1.1158e-02,  5.8161e-04,  1.3158e-02,\n           2.0398e-02, -1.5821e-02,  1.4266e-02,  7.0510e-03, -3.6685e-03,\n          -1.7214e-02, -1.4209e-02, -3.0199e-03,  1.0627e-02,  6.5157e-03,\n           9.4924e-04,  1.0380e-02,  3.8509e-03, -5.7467e-03,  1.5026e-02,\n          -5.9394e-03, -8.6701e-03,  1.6169e-02,  4.5708e-03, -2.0653e-02,\n          -1.5963e-03,  6.8233e-03,  1.7060e-02, -1.3947e-02, -3.4503e-03,\n          -1.1365e-02, -1.2223e-02,  1.2113e-02, -2.4736e-04,  1.3549e-02,\n          -2.0833e-02, -1.6784e-02, -1.9889e-02, -4.5695e-03,  7.6254e-03,\n          -4.5849e-03,  1.6212e-02, -1.9736e-03,  1.7916e-02, -1.5456e-03,\n          -1.7383e-02, -6.6034e-03,  4.0540e-03, -1.6151e-02,  2.4600e-03,\n          -7.5390e-03, -1.7564e-02,  8.3464e-03, -5.7819e-03,  9.3517e-03,\n          -1.0946e-02, -1.9944e-02, -9.4418e-03,  2.0330e-02, -8.0082e-03,\n          -2.0544e-02,  1.6829e-02,  1.4149e-02, -1.4097e-03,  1.5277e-02,\n           2.0283e-02, -6.3989e-03, -5.1823e-03, -3.7406e-05,  1.3873e-02,\n          -1.6744e-02, -2.1233e-02, -3.0119e-03,  1.9213e-02,  1.0302e-02,\n          -5.7545e-03, -5.6215e-03,  6.3183e-03, -1.5332e-02, -1.8230e-02,\n           5.7956e-03, -2.2010e-02, -2.3797e-03,  1.1589e-02, -2.0739e-02,\n          -4.9881e-03,  6.2564e-03, -2.0244e-02,  8.1927e-03,  2.0681e-02,\n          -7.8505e-03, -1.7218e-02,  1.0768e-02, -1.2801e-02, -1.3541e-02,\n          -1.2043e-02, -2.1172e-02, -1.4716e-02, -5.4089e-03,  2.0620e-02,\n           2.0371e-02, -2.1446e-02, -2.1623e-02,  4.9458e-03, -2.0032e-02,\n           1.3742e-02,  2.7540e-03,  1.0424e-02, -9.8711e-04,  2.9598e-03,\n          -1.5282e-02, -2.5758e-03, -1.8975e-02, -1.8392e-02, -2.3569e-03,\n          -1.9854e-02, -1.6204e-02,  1.5703e-02,  1.4556e-02, -5.1735e-03,\n           1.5252e-02,  1.8951e-02, -8.9992e-03,  1.9383e-02, -3.2948e-03,\n          -1.0476e-02, -7.5083e-03,  3.5340e-03,  9.8979e-03, -1.5054e-02,\n          -2.0320e-02, -6.3631e-03,  2.0043e-02,  1.9830e-02,  1.3094e-02,\n          -1.5390e-02, -7.6599e-03,  1.3593e-02,  1.0336e-02,  1.0929e-02,\n           2.0372e-04,  1.1107e-04,  1.0213e-02,  3.6813e-03, -1.6412e-02,\n           1.1802e-03,  8.4597e-03, -9.2707e-03, -5.4170e-03,  1.9675e-02,\n          -8.5243e-03, -1.1558e-02,  1.6129e-02, -1.3405e-02,  4.6223e-04,\n          -1.8774e-02, -2.9299e-03,  7.3921e-03,  2.8056e-03, -1.2501e-03,\n           7.3736e-03, -1.4411e-03, -1.7926e-02,  1.0428e-03,  2.0704e-02,\n           1.0374e-02, -1.8622e-02, -1.9445e-04,  2.8512e-03, -9.0790e-03,\n          -2.2082e-02,  4.1009e-03,  1.2553e-02, -2.1904e-02,  1.1606e-02,\n          -5.5057e-03,  1.7030e-02, -1.4541e-02, -1.8824e-03,  3.1945e-03,\n          -2.0524e-02, -8.5445e-03,  1.2024e-02,  1.8271e-02, -1.3442e-02,\n           9.6984e-03, -1.7566e-02, -1.5033e-02,  8.0769e-03, -1.9867e-02,\n          -2.1866e-03,  5.9113e-03,  9.7809e-03, -2.0488e-02, -1.3959e-03,\n          -9.7055e-03, -9.8444e-03,  7.6046e-03, -1.1191e-02,  9.0376e-03,\n          -5.9319e-03,  1.2340e-03, -1.5603e-02, -1.1446e-02, -1.2420e-02,\n          -1.6465e-02, -2.1580e-02,  1.1416e-02, -1.8703e-02, -5.5200e-03,\n           1.4327e-02, -9.4115e-03, -6.8531e-03, -7.7144e-03, -1.8033e-02,\n           1.2368e-02,  1.2903e-02,  2.1552e-02,  1.7600e-02, -2.2058e-02,\n          -1.4971e-02,  9.7099e-03, -1.6501e-02,  3.2777e-03, -1.6091e-02,\n          -5.1584e-03, -1.9415e-02,  7.5102e-03, -1.9682e-04,  2.1740e-02,\n           1.1847e-02, -7.9145e-03, -1.2820e-02,  4.5116e-03, -1.3666e-02,\n          -6.1617e-03,  6.9369e-03, -1.5905e-02, -2.1222e-02, -2.0794e-02,\n           6.3799e-03, -8.7952e-03,  3.8081e-03,  4.8792e-03, -1.3953e-02,\n           1.5906e-02, -1.2821e-02, -1.5098e-02,  1.1480e-02, -1.5811e-02,\n          -9.0970e-03,  1.3753e-02, -1.7108e-02, -8.2053e-03,  8.0987e-03,\n          -2.1263e-02, -1.6520e-03,  5.0387e-03, -1.2997e-02,  1.8601e-02,\n          -1.2021e-02,  3.5198e-03,  1.0363e-02, -1.8617e-02,  1.9091e-02,\n           4.8841e-03, -3.8488e-03,  1.0711e-02,  1.1413e-02,  1.8473e-02,\n           1.3143e-02, -1.2351e-02,  1.7619e-02,  2.1178e-02, -7.2509e-03,\n           1.7539e-03,  8.9103e-03,  6.8085e-03, -1.8319e-02, -6.9452e-03,\n          -9.7860e-03,  1.2727e-02,  6.6076e-03,  1.7720e-02,  1.4674e-02,\n          -1.2926e-02, -1.6900e-02, -1.1140e-02,  1.4983e-02, -1.1368e-02,\n           9.4286e-03,  1.4835e-02, -1.5095e-02,  1.0321e-02,  1.3902e-02,\n          -1.7476e-02, -1.6859e-02, -1.0545e-02, -1.1084e-02, -1.1835e-02,\n          -1.1957e-02, -8.5929e-03, -1.3127e-02, -1.3736e-02,  1.3488e-02,\n          -2.0739e-02,  2.0337e-02,  5.7911e-03, -6.8449e-03,  1.3518e-02,\n          -8.1384e-04, -1.8692e-02,  9.2392e-03,  1.1783e-02, -1.8160e-02,\n          -1.9098e-02, -1.1255e-02, -1.0805e-02,  8.0050e-03, -1.8007e-02,\n          -1.5128e-02, -2.1591e-02, -2.1274e-02, -1.1624e-02,  1.9031e-02,\n          -4.1611e-03,  1.0402e-02, -6.3048e-03, -2.2016e-03,  1.0273e-02,\n          -9.4744e-03, -1.1790e-03,  1.9104e-02,  2.1342e-02, -3.6236e-03,\n          -1.0277e-03,  1.5656e-02, -1.3345e-02, -1.1322e-03, -1.7586e-02,\n           4.8012e-03,  1.5300e-02,  4.5882e-03,  2.1683e-02, -2.1033e-02,\n          -1.5027e-02, -6.3138e-03,  2.1747e-02, -2.1445e-02,  1.0298e-02,\n          -2.2789e-03, -6.4715e-03,  1.9718e-02, -4.3231e-03, -1.1430e-02,\n          -1.5865e-04, -1.4925e-02,  1.5791e-02,  1.3199e-02, -1.4581e-05,\n          -1.4061e-02,  5.8062e-03, -3.1722e-03, -1.6711e-02, -4.6809e-04,\n          -4.7077e-03,  1.9770e-03,  2.1560e-02,  5.8819e-03,  8.6811e-03,\n          -1.3900e-02,  1.2796e-02,  1.1072e-02, -1.9871e-02, -2.1805e-02,\n          -6.9476e-03,  4.2047e-03,  1.1786e-02, -1.2602e-02,  2.0011e-02,\n          -2.0960e-02, -2.0632e-02,  1.9798e-02, -1.8500e-02,  1.4066e-02,\n           9.7893e-03, -1.4190e-02, -1.2838e-02, -8.0358e-03,  9.5744e-03,\n          -2.1932e-02,  1.7855e-02,  8.4145e-03,  1.7016e-02,  1.1687e-02,\n          -3.4172e-03,  1.6287e-02,  5.0397e-03,  1.7872e-02,  1.1479e-02,\n           2.1969e-02,  1.0821e-02, -7.9417e-03,  7.1654e-03,  2.1060e-02,\n          -8.3020e-03, -1.8638e-02, -9.3095e-04, -7.7715e-03, -8.2957e-03,\n          -1.3282e-02, -1.9109e-02, -1.2374e-02,  9.7353e-04, -8.1837e-03,\n          -1.4622e-02,  1.1454e-02,  1.0515e-02, -1.9166e-02, -6.8525e-03,\n          -1.8575e-02,  5.7142e-03,  1.4394e-03,  8.9292e-03,  5.1929e-03,\n          -1.2240e-02, -2.2635e-03,  1.3791e-02, -2.4685e-03, -7.2995e-03,\n          -1.4123e-02,  1.6297e-02, -3.3858e-03, -4.4183e-03,  1.8000e-02,\n          -1.4335e-02,  4.5018e-03,  1.5483e-02,  2.5999e-04, -1.1335e-03,\n           8.6351e-03,  7.0153e-03,  1.8897e-02, -1.5894e-02,  4.6480e-03,\n          -1.9323e-02,  1.5131e-02,  1.7955e-02,  4.6175e-03, -1.0162e-02,\n          -2.1903e-02, -1.3536e-02,  2.1272e-02,  1.2172e-02,  1.5229e-02,\n           1.5017e-02, -6.5936e-04,  9.1162e-03,  1.1969e-02,  3.7553e-03,\n           2.5052e-03, -7.1500e-03, -1.2421e-02, -7.1459e-03, -4.2322e-03,\n           1.3768e-02,  1.4648e-02,  1.5209e-02,  1.9892e-02,  7.9093e-03,\n           4.3179e-03, -1.3151e-02, -2.3440e-04,  3.3739e-03,  1.0237e-04,\n           1.8864e-02,  1.2870e-02, -9.9585e-04, -2.1991e-02, -1.4360e-02,\n           3.7434e-03, -7.6701e-03, -1.1384e-02,  1.6661e-02,  1.9187e-02,\n          -2.0348e-02, -1.4835e-02, -1.5876e-02, -1.6566e-02, -1.7361e-02,\n          -8.1709e-03, -1.3951e-02, -7.7663e-03,  1.7139e-02, -1.2510e-03,\n           2.1167e-02,  1.2276e-02,  1.5110e-02,  1.6990e-02, -1.9665e-02,\n           1.3673e-02, -9.1360e-03,  8.1295e-03,  1.7129e-02,  1.0140e-02,\n          -5.9856e-03, -7.5962e-03,  1.6340e-02, -1.9074e-02,  1.3153e-02,\n           7.5182e-03, -5.6618e-03,  1.2192e-02,  2.4147e-03,  2.1047e-02,\n          -1.1521e-02, -1.0900e-02, -2.1034e-02,  1.3398e-02, -1.0785e-02,\n           1.8369e-03,  1.5977e-02,  1.2432e-02, -7.9101e-05,  1.1572e-02,\n           1.2245e-02, -6.3671e-03, -1.4696e-02, -1.6340e-02,  1.5202e-02,\n          -1.2289e-02, -2.7069e-03, -7.0397e-03,  2.1084e-02, -8.9272e-03,\n          -1.2174e-02, -3.4679e-03,  1.3586e-02,  1.8469e-02,  1.1128e-02,\n          -1.4652e-02, -1.4174e-03, -2.5736e-03, -1.5123e-02,  8.1012e-03,\n          -2.0349e-02,  1.0656e-02, -2.0199e-02, -1.1416e-02, -9.7104e-03,\n           2.0190e-02,  1.2100e-02, -3.8040e-03,  1.1001e-02,  5.2912e-03,\n          -4.6104e-03,  1.0243e-02,  1.3352e-02,  2.1053e-02, -6.2129e-03,\n          -2.0363e-02,  1.6866e-02,  1.1901e-02,  8.1996e-03,  1.5963e-03,\n          -1.7059e-02,  1.5045e-02, -1.8559e-02,  1.3757e-02, -1.8632e-02,\n          -2.2015e-02,  2.0504e-02,  1.5887e-02, -1.2357e-02, -1.8150e-02,\n           1.1014e-02, -1.2420e-02,  1.7391e-02,  1.2971e-02,  1.7690e-02,\n           2.1935e-02,  3.9169e-03,  1.3033e-02, -1.6934e-02,  1.5721e-02,\n           1.1105e-02, -1.5463e-02,  1.5717e-02,  1.6165e-02,  1.9766e-02,\n           8.9036e-03,  5.6378e-03, -8.1526e-03, -8.4512e-03, -2.0250e-02,\n           1.2077e-02,  7.5124e-03, -2.1096e-02,  1.3698e-03, -1.3093e-02,\n           1.3279e-02,  6.6738e-03,  1.8701e-02, -6.9794e-03,  1.0992e-02,\n           1.5188e-03, -4.6861e-03,  7.2525e-03, -1.2847e-02,  1.9655e-02,\n          -1.5097e-02, -2.0911e-03, -9.8533e-03, -7.6127e-03, -9.8279e-03,\n           8.1965e-03,  8.5138e-03, -1.6099e-02, -1.5560e-02, -6.0219e-03,\n          -2.1577e-02, -1.4375e-02,  9.0273e-03, -4.5386e-03,  2.0099e-02,\n           1.0280e-02,  4.0028e-04, -1.7355e-02, -3.2309e-03,  5.0577e-03,\n          -1.9788e-02, -1.6672e-02,  9.0755e-04,  3.9617e-03, -1.6378e-02,\n           1.4650e-02,  1.9184e-02,  2.2063e-02,  3.0684e-03,  3.6840e-03,\n           1.5183e-02,  6.2177e-03, -8.0125e-03,  2.0416e-02,  6.6802e-03,\n           1.9526e-02, -7.2869e-03, -1.6115e-02,  1.6575e-02, -2.1773e-02,\n           1.4647e-02, -1.1335e-03,  1.1754e-02,  7.4279e-03,  2.1790e-02,\n           9.7781e-03, -1.1670e-02,  1.8610e-02, -9.9980e-03,  2.0379e-02,\n           2.0725e-02,  3.3085e-03,  1.8963e-02,  6.0999e-03,  9.5618e-03,\n          -1.7002e-04,  6.4194e-03, -1.9245e-02, -1.2431e-02, -2.1172e-02,\n          -1.8921e-03, -1.3325e-02, -3.3971e-03, -1.1584e-02, -1.7310e-02,\n          -6.4643e-03,  3.3318e-03, -1.2277e-02,  1.5242e-02,  1.1760e-02,\n          -1.6007e-02,  2.0333e-03, -7.5641e-03,  8.6426e-03, -1.3459e-02,\n           7.0664e-03,  1.2533e-02, -1.9227e-02, -1.3475e-02, -1.4893e-02,\n           5.8377e-03, -1.1470e-02, -3.8911e-03,  2.1943e-02, -5.3640e-03,\n          -1.2865e-02,  3.3044e-03,  2.0893e-02, -1.3921e-05,  1.5204e-02,\n           3.6257e-03,  1.7901e-02,  1.0070e-02,  6.9632e-03, -1.9174e-03,\n           1.6392e-02, -9.9775e-03,  1.8044e-02, -1.5411e-02, -1.3273e-02,\n          -1.7880e-02, -7.8289e-03,  2.2550e-03,  6.3893e-03,  3.5462e-03,\n           6.9925e-03, -2.5911e-03, -1.0612e-02,  1.4826e-02,  1.3884e-02,\n          -1.4000e-03,  1.5987e-03, -4.6452e-03, -1.1618e-02, -2.0149e-02,\n          -1.3772e-02, -1.7160e-02, -8.4254e-03, -7.1950e-03, -4.1100e-03,\n          -1.2062e-02, -1.7413e-02,  1.5985e-02, -8.4590e-03, -1.4495e-02,\n          -5.3490e-03,  8.3093e-03, -4.2371e-03,  1.6793e-02, -1.3310e-02,\n           3.6993e-03,  1.3885e-02, -1.0712e-02,  2.4818e-03,  1.4337e-02,\n           2.0618e-02, -8.4925e-03, -1.8957e-02, -1.8900e-03,  1.9504e-02,\n           1.3275e-02,  1.1105e-02, -1.4725e-02,  3.2079e-03, -1.6973e-02,\n           3.6681e-03,  7.1125e-04,  6.5027e-03, -1.7414e-02,  8.2018e-03,\n          -1.3817e-02,  1.2712e-02, -1.5307e-02, -6.0227e-03,  1.5489e-02,\n           7.1236e-03,  2.3681e-03,  6.0732e-03, -4.2783e-03,  1.2268e-02,\n          -8.3375e-03,  2.0609e-02, -8.2188e-03,  1.4331e-02,  1.7850e-02,\n           1.5566e-02,  1.8160e-03, -5.8200e-03,  1.7657e-02,  1.9558e-02,\n          -1.7277e-02,  2.1292e-02, -1.2465e-02, -1.7991e-02, -2.0505e-02,\n          -1.3503e-02, -4.1113e-03, -1.1449e-02,  2.4823e-03, -1.1202e-02,\n          -6.9809e-04, -1.8982e-02, -5.3955e-04,  9.1083e-04, -1.5664e-02,\n          -1.8429e-02,  1.0945e-02, -1.2788e-02,  4.6081e-03, -5.5316e-03,\n          -1.2816e-02,  3.8990e-03,  1.6105e-02, -5.4946e-03,  5.6768e-03,\n           1.5971e-02,  2.6038e-03, -8.8425e-03, -1.7558e-03,  9.6863e-03,\n          -1.2111e-02, -5.9780e-03,  7.3771e-03,  1.1320e-02,  2.1157e-02,\n          -9.7849e-03, -1.3291e-02,  1.4207e-02,  3.2374e-03,  2.0961e-02,\n           7.2693e-03,  5.8949e-04, -9.8841e-03,  3.5098e-03,  1.6390e-02,\n          -1.0017e-02, -3.1970e-04, -5.9094e-03, -6.4119e-03,  5.3413e-03,\n           7.1157e-03,  6.4619e-03,  1.1393e-02, -7.1464e-03,  5.1133e-03,\n           9.0641e-03,  9.6438e-03,  9.0189e-05,  1.0883e-02, -3.7932e-03,\n           2.5017e-03, -1.7825e-02, -1.4203e-02, -1.7710e-03, -7.1340e-04,\n          -4.0021e-03, -9.6363e-03, -5.5243e-03, -7.0829e-03,  1.0999e-02,\n           1.1586e-02,  2.4833e-03,  1.5734e-02,  1.1409e-02,  8.6240e-04,\n          -1.7745e-02,  1.2150e-02,  1.3793e-02,  1.9770e-02, -3.3163e-03,\n           1.5077e-02,  1.6411e-02, -4.1076e-03,  8.8523e-03, -1.1404e-02,\n          -9.1464e-03,  4.6428e-03,  3.9873e-03, -3.1982e-03,  2.0111e-02,\n          -1.5999e-02, -1.7787e-03,  3.6124e-03,  4.0629e-03, -4.5407e-03,\n           8.6281e-03, -1.3185e-02,  1.2544e-03,  5.6449e-03,  2.0068e-03,\n          -6.1967e-03,  3.6230e-03, -1.5569e-02, -9.3001e-03,  2.0333e-03,\n          -1.3977e-02, -1.3309e-02, -1.3870e-02, -4.3964e-03, -7.7488e-03,\n          -1.3162e-02,  8.4607e-03, -1.7212e-02,  2.7149e-03,  1.3080e-02,\n          -1.4455e-02, -1.9062e-02,  1.3224e-02, -4.5129e-03,  3.6081e-03,\n           2.7577e-03,  4.0550e-03, -1.6445e-02, -1.1008e-02,  1.6174e-02,\n          -7.7051e-03,  6.3677e-03, -1.3266e-02, -7.3469e-03,  1.4390e-02,\n          -3.2118e-03, -8.6737e-03,  1.5162e-02,  1.0866e-02,  6.9447e-03,\n           1.0797e-02, -1.7845e-02,  6.7007e-03, -1.9287e-02, -2.1862e-02,\n           1.9741e-02, -1.9081e-02, -1.4026e-02,  1.1471e-02,  1.7169e-02,\n          -1.9041e-02,  7.0727e-03,  2.2238e-03, -9.9619e-03,  1.3220e-02,\n          -3.2950e-04,  1.2184e-02,  1.7468e-02,  2.2058e-02, -1.5459e-03,\n           6.7954e-03, -1.2202e-02, -2.0387e-03, -1.5792e-03,  6.3441e-03,\n          -1.1300e-02, -6.2397e-03, -1.8822e-03,  1.4816e-02,  6.6225e-03,\n           9.9826e-03, -8.7119e-03,  3.0391e-03, -2.8649e-03, -1.3948e-02,\n           2.0792e-02,  1.0017e-02, -3.1149e-03, -1.7141e-02,  1.1803e-02,\n          -4.2656e-03,  1.6982e-02,  5.9842e-04, -2.0265e-02,  4.7678e-03,\n           5.1757e-03,  1.6460e-02, -1.7625e-02,  9.2040e-03,  1.4852e-02,\n          -3.9193e-03,  1.7594e-02, -9.7115e-03,  5.8997e-03, -5.5003e-03,\n          -1.6391e-02,  2.0805e-02, -1.4473e-02, -1.5498e-02, -2.1715e-02,\n          -1.8653e-02, -1.0868e-02,  3.8331e-04,  1.8159e-02, -1.8092e-02,\n          -1.1388e-02,  5.8366e-03,  1.1091e-02, -2.1615e-02, -4.4408e-03,\n          -1.0165e-02, -8.3646e-03,  1.6342e-02, -1.0834e-02,  8.9725e-03],\n         requires_grad=True))]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet50.named_parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:19:28.072850900Z",
     "start_time": "2023-12-28T15:19:27.593846300Z"
    }
   },
   "id": "8559cbb60513de6f"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = nn.BatchNorm2d(123)\n",
    "list(bn.named_children())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:25:54.756517500Z",
     "start_time": "2023-12-28T15:25:54.287998400Z"
    }
   },
   "id": "f86c8c6a79ff7280"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[[4], [4], [4]]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [[]] * 3\n",
    "l[0].append(4)\n",
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:28:43.916532100Z",
     "start_time": "2023-12-28T15:28:43.500455600Z"
    }
   },
   "id": "c11963e7398038cc"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def bn_filter(module_name, module, param_name, param):\n",
    "    return isinstance(module, (nn.InstanceNorm1d, nn.InstanceNorm2d, nn.InstanceNorm3d, nn.LazyInstanceNorm1d, nn.LazyInstanceNorm2d, nn.LazyInstanceNorm3d, nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.LazyBatchNorm1d, nn.LazyBatchNorm2d, nn.LazyBatchNorm3d))\n",
    "\n",
    "def bias_filter(module_name, module, param_name, param):\n",
    "    return param_name == \"bias\"\n",
    "\n",
    "def bn_or_bias_filter(module_name, module, param_name, param):\n",
    "    return bn_filter(module_name, module, param_name, param) or bias_filter(module_name, module, param_name, param)\n",
    "\n",
    "def pass_all_filter(module_name, module, param_name, param):\n",
    "    return True\n",
    "\n",
    "def split_params(model: nn.Module, filters, prefix=\"\"):\n",
    "    results = []\n",
    "    for i in range(len(filters)):\n",
    "        results.append([])\n",
    "    for module_name, module in model.named_children():\n",
    "        full_module_name = prefix + module_name\n",
    "        for param_name, param in module.named_parameters(recurse=False):\n",
    "            for i, f in enumerate(filters):\n",
    "                if f(full_module_name, module, param_name, param):\n",
    "                    results[i].append(param)\n",
    "                    break\n",
    "        module_results = split_params(module, filters, full_module_name + \".\")\n",
    "        for i in range(len(filters)):\n",
    "            results[i] += module_results[i]\n",
    "    return results\n",
    "\n",
    "def add_weight_decay(\n",
    "        model, \n",
    "        weight_decay=1e-5):\n",
    "    params = split_params(model, [bn_or_bias_filter, pass_all_filter])\n",
    "    return [\n",
    "        {'params': params[0], 'weight_decay': 0.},\n",
    "        {'params': params[1], 'weight_decay': weight_decay}]\n",
    "\n",
    "# result = split_params(resnet50, [bn_or_bias_filter, pass_all_filter])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:41:44.195483800Z",
     "start_time": "2023-12-28T15:41:43.867304400Z"
    }
   },
   "id": "ec23306805f75690"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0.0\n\nParameter Group 1\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 1e-05\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "AdamW(add_weight_decay(resnet50), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:47:09.046264400Z",
     "start_time": "2023-12-28T15:47:08.624713300Z"
    }
   },
   "id": "82548b81b1582efd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "21d97eda78138f48"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['conv1.weight',\n 'layer1.0.conv1.weight',\n 'layer1.0.conv2.weight',\n 'layer1.0.conv3.weight',\n 'layer1.0.downsample.0.weight',\n 'layer1.1.conv1.weight',\n 'layer1.1.conv2.weight',\n 'layer1.1.conv3.weight',\n 'layer1.2.conv1.weight',\n 'layer1.2.conv2.weight',\n 'layer1.2.conv3.weight',\n 'layer2.0.conv1.weight',\n 'layer2.0.conv2.weight',\n 'layer2.0.conv3.weight',\n 'layer2.0.downsample.0.weight',\n 'layer2.1.conv1.weight',\n 'layer2.1.conv2.weight',\n 'layer2.1.conv3.weight',\n 'layer2.2.conv1.weight',\n 'layer2.2.conv2.weight',\n 'layer2.2.conv3.weight',\n 'layer2.3.conv1.weight',\n 'layer2.3.conv2.weight',\n 'layer2.3.conv3.weight',\n 'layer3.0.conv1.weight',\n 'layer3.0.conv2.weight',\n 'layer3.0.conv3.weight',\n 'layer3.0.downsample.0.weight',\n 'layer3.1.conv1.weight',\n 'layer3.1.conv2.weight',\n 'layer3.1.conv3.weight',\n 'layer3.2.conv1.weight',\n 'layer3.2.conv2.weight',\n 'layer3.2.conv3.weight',\n 'layer3.3.conv1.weight',\n 'layer3.3.conv2.weight',\n 'layer3.3.conv3.weight',\n 'layer3.4.conv1.weight',\n 'layer3.4.conv2.weight',\n 'layer3.4.conv3.weight',\n 'layer3.5.conv1.weight',\n 'layer3.5.conv2.weight',\n 'layer3.5.conv3.weight',\n 'layer4.0.conv1.weight',\n 'layer4.0.conv2.weight',\n 'layer4.0.conv3.weight',\n 'layer4.0.downsample.0.weight',\n 'layer4.1.conv1.weight',\n 'layer4.1.conv2.weight',\n 'layer4.1.conv3.weight',\n 'layer4.2.conv1.weight',\n 'layer4.2.conv2.weight',\n 'layer4.2.conv3.weight',\n 'fc.weight']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m[0] for m in result[1]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:39:12.810111100Z",
     "start_time": "2023-12-28T15:39:12.276111400Z"
    }
   },
   "id": "35ade6e993f711cc"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet50.named_parameters(recurse=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:30:12.117268200Z",
     "start_time": "2023-12-28T15:30:11.397982700Z"
    }
   },
   "id": "1b44c44915a148e9"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "['.conv1.weight',\n '.bn1.weight',\n '.bn1.bias',\n '.layer1.0.conv1.weight',\n '.layer1.0.bn1.weight',\n '.layer1.0.bn1.bias',\n '.layer1.0.conv2.weight',\n '.layer1.0.bn2.weight',\n '.layer1.0.bn2.bias',\n '.layer1.0.conv3.weight',\n '.layer1.0.bn3.weight',\n '.layer1.0.bn3.bias',\n '.layer1.0.downsample.0.weight',\n '.layer1.0.downsample.1.weight',\n '.layer1.0.downsample.1.bias',\n '.layer1.1.conv1.weight',\n '.layer1.1.bn1.weight',\n '.layer1.1.bn1.bias',\n '.layer1.1.conv2.weight',\n '.layer1.1.bn2.weight',\n '.layer1.1.bn2.bias',\n '.layer1.1.conv3.weight',\n '.layer1.1.bn3.weight',\n '.layer1.1.bn3.bias',\n '.layer1.2.conv1.weight',\n '.layer1.2.bn1.weight',\n '.layer1.2.bn1.bias',\n '.layer1.2.conv2.weight',\n '.layer1.2.bn2.weight',\n '.layer1.2.bn2.bias',\n '.layer1.2.conv3.weight',\n '.layer1.2.bn3.weight',\n '.layer1.2.bn3.bias',\n '.layer2.0.conv1.weight',\n '.layer2.0.bn1.weight',\n '.layer2.0.bn1.bias',\n '.layer2.0.conv2.weight',\n '.layer2.0.bn2.weight',\n '.layer2.0.bn2.bias',\n '.layer2.0.conv3.weight',\n '.layer2.0.bn3.weight',\n '.layer2.0.bn3.bias',\n '.layer2.0.downsample.0.weight',\n '.layer2.0.downsample.1.weight',\n '.layer2.0.downsample.1.bias',\n '.layer2.1.conv1.weight',\n '.layer2.1.bn1.weight',\n '.layer2.1.bn1.bias',\n '.layer2.1.conv2.weight',\n '.layer2.1.bn2.weight',\n '.layer2.1.bn2.bias',\n '.layer2.1.conv3.weight',\n '.layer2.1.bn3.weight',\n '.layer2.1.bn3.bias',\n '.layer2.2.conv1.weight',\n '.layer2.2.bn1.weight',\n '.layer2.2.bn1.bias',\n '.layer2.2.conv2.weight',\n '.layer2.2.bn2.weight',\n '.layer2.2.bn2.bias',\n '.layer2.2.conv3.weight',\n '.layer2.2.bn3.weight',\n '.layer2.2.bn3.bias',\n '.layer2.3.conv1.weight',\n '.layer2.3.bn1.weight',\n '.layer2.3.bn1.bias',\n '.layer2.3.conv2.weight',\n '.layer2.3.bn2.weight',\n '.layer2.3.bn2.bias',\n '.layer2.3.conv3.weight',\n '.layer2.3.bn3.weight',\n '.layer2.3.bn3.bias',\n '.layer3.0.conv1.weight',\n '.layer3.0.bn1.weight',\n '.layer3.0.bn1.bias',\n '.layer3.0.conv2.weight',\n '.layer3.0.bn2.weight',\n '.layer3.0.bn2.bias',\n '.layer3.0.conv3.weight',\n '.layer3.0.bn3.weight',\n '.layer3.0.bn3.bias',\n '.layer3.0.downsample.0.weight',\n '.layer3.0.downsample.1.weight',\n '.layer3.0.downsample.1.bias',\n '.layer3.1.conv1.weight',\n '.layer3.1.bn1.weight',\n '.layer3.1.bn1.bias',\n '.layer3.1.conv2.weight',\n '.layer3.1.bn2.weight',\n '.layer3.1.bn2.bias',\n '.layer3.1.conv3.weight',\n '.layer3.1.bn3.weight',\n '.layer3.1.bn3.bias',\n '.layer3.2.conv1.weight',\n '.layer3.2.bn1.weight',\n '.layer3.2.bn1.bias',\n '.layer3.2.conv2.weight',\n '.layer3.2.bn2.weight',\n '.layer3.2.bn2.bias',\n '.layer3.2.conv3.weight',\n '.layer3.2.bn3.weight',\n '.layer3.2.bn3.bias',\n '.layer3.3.conv1.weight',\n '.layer3.3.bn1.weight',\n '.layer3.3.bn1.bias',\n '.layer3.3.conv2.weight',\n '.layer3.3.bn2.weight',\n '.layer3.3.bn2.bias',\n '.layer3.3.conv3.weight',\n '.layer3.3.bn3.weight',\n '.layer3.3.bn3.bias',\n '.layer3.4.conv1.weight',\n '.layer3.4.bn1.weight',\n '.layer3.4.bn1.bias',\n '.layer3.4.conv2.weight',\n '.layer3.4.bn2.weight',\n '.layer3.4.bn2.bias',\n '.layer3.4.conv3.weight',\n '.layer3.4.bn3.weight',\n '.layer3.4.bn3.bias',\n '.layer3.5.conv1.weight',\n '.layer3.5.bn1.weight',\n '.layer3.5.bn1.bias',\n '.layer3.5.conv2.weight',\n '.layer3.5.bn2.weight',\n '.layer3.5.bn2.bias',\n '.layer3.5.conv3.weight',\n '.layer3.5.bn3.weight',\n '.layer3.5.bn3.bias',\n '.layer4.0.conv1.weight',\n '.layer4.0.bn1.weight',\n '.layer4.0.bn1.bias',\n '.layer4.0.conv2.weight',\n '.layer4.0.bn2.weight',\n '.layer4.0.bn2.bias',\n '.layer4.0.conv3.weight',\n '.layer4.0.bn3.weight',\n '.layer4.0.bn3.bias',\n '.layer4.0.downsample.0.weight',\n '.layer4.0.downsample.1.weight',\n '.layer4.0.downsample.1.bias',\n '.layer4.1.conv1.weight',\n '.layer4.1.bn1.weight',\n '.layer4.1.bn1.bias',\n '.layer4.1.conv2.weight',\n '.layer4.1.bn2.weight',\n '.layer4.1.bn2.bias',\n '.layer4.1.conv3.weight',\n '.layer4.1.bn3.weight',\n '.layer4.1.bn3.bias',\n '.layer4.2.conv1.weight',\n '.layer4.2.bn1.weight',\n '.layer4.2.bn1.bias',\n '.layer4.2.conv2.weight',\n '.layer4.2.bn2.weight',\n '.layer4.2.bn2.bias',\n '.layer4.2.conv3.weight',\n '.layer4.2.bn3.weight',\n '.layer4.2.bn3.bias',\n '.fc.weight',\n '.fc.bias',\n 'conv1.weight',\n 'layer1.0.conv1.weight',\n 'layer1.0.bn1.weight',\n 'layer1.0.bn1.bias',\n 'layer1.0.conv2.weight',\n 'layer1.0.bn2.weight',\n 'layer1.0.bn2.bias',\n 'layer1.0.conv3.weight',\n 'layer1.0.bn3.weight',\n 'layer1.0.bn3.bias',\n 'layer1.0.downsample.0.weight',\n 'layer1.0.downsample.1.weight',\n 'layer1.0.downsample.1.bias',\n 'layer1.1.conv1.weight',\n 'layer1.1.bn1.weight',\n 'layer1.1.bn1.bias',\n 'layer1.1.conv2.weight',\n 'layer1.1.bn2.weight',\n 'layer1.1.bn2.bias',\n 'layer1.1.conv3.weight',\n 'layer1.1.bn3.weight',\n 'layer1.1.bn3.bias',\n 'layer1.2.conv1.weight',\n 'layer1.2.bn1.weight',\n 'layer1.2.bn1.bias',\n 'layer1.2.conv2.weight',\n 'layer1.2.bn2.weight',\n 'layer1.2.bn2.bias',\n 'layer1.2.conv3.weight',\n 'layer1.2.bn3.weight',\n 'layer1.2.bn3.bias',\n 'layer1.0.conv1.weight',\n 'layer1.0.bn1.weight',\n 'layer1.0.bn1.bias',\n 'layer1.0.conv2.weight',\n 'layer1.0.bn2.weight',\n 'layer1.0.bn2.bias',\n 'layer1.0.conv3.weight',\n 'layer1.0.bn3.weight',\n 'layer1.0.bn3.bias',\n 'layer1.0.downsample.0.weight',\n 'layer1.0.downsample.1.weight',\n 'layer1.0.downsample.1.bias',\n 'layer1.0.conv1.weight',\n 'layer1.0.conv2.weight',\n 'layer1.0.conv3.weight',\n 'layer1.0.downsample.0.weight',\n 'layer1.0.downsample.1.weight',\n 'layer1.0.downsample.1.bias',\n 'layer1.0.downsample.0.weight',\n 'layer1.1.conv1.weight',\n 'layer1.1.bn1.weight',\n 'layer1.1.bn1.bias',\n 'layer1.1.conv2.weight',\n 'layer1.1.bn2.weight',\n 'layer1.1.bn2.bias',\n 'layer1.1.conv3.weight',\n 'layer1.1.bn3.weight',\n 'layer1.1.bn3.bias',\n 'layer1.1.conv1.weight',\n 'layer1.1.conv2.weight',\n 'layer1.1.conv3.weight',\n 'layer1.2.conv1.weight',\n 'layer1.2.bn1.weight',\n 'layer1.2.bn1.bias',\n 'layer1.2.conv2.weight',\n 'layer1.2.bn2.weight',\n 'layer1.2.bn2.bias',\n 'layer1.2.conv3.weight',\n 'layer1.2.bn3.weight',\n 'layer1.2.bn3.bias',\n 'layer1.2.conv1.weight',\n 'layer1.2.conv2.weight',\n 'layer1.2.conv3.weight',\n 'layer2.0.conv1.weight',\n 'layer2.0.bn1.weight',\n 'layer2.0.bn1.bias',\n 'layer2.0.conv2.weight',\n 'layer2.0.bn2.weight',\n 'layer2.0.bn2.bias',\n 'layer2.0.conv3.weight',\n 'layer2.0.bn3.weight',\n 'layer2.0.bn3.bias',\n 'layer2.0.downsample.0.weight',\n 'layer2.0.downsample.1.weight',\n 'layer2.0.downsample.1.bias',\n 'layer2.1.conv1.weight',\n 'layer2.1.bn1.weight',\n 'layer2.1.bn1.bias',\n 'layer2.1.conv2.weight',\n 'layer2.1.bn2.weight',\n 'layer2.1.bn2.bias',\n 'layer2.1.conv3.weight',\n 'layer2.1.bn3.weight',\n 'layer2.1.bn3.bias',\n 'layer2.2.conv1.weight',\n 'layer2.2.bn1.weight',\n 'layer2.2.bn1.bias',\n 'layer2.2.conv2.weight',\n 'layer2.2.bn2.weight',\n 'layer2.2.bn2.bias',\n 'layer2.2.conv3.weight',\n 'layer2.2.bn3.weight',\n 'layer2.2.bn3.bias',\n 'layer2.3.conv1.weight',\n 'layer2.3.bn1.weight',\n 'layer2.3.bn1.bias',\n 'layer2.3.conv2.weight',\n 'layer2.3.bn2.weight',\n 'layer2.3.bn2.bias',\n 'layer2.3.conv3.weight',\n 'layer2.3.bn3.weight',\n 'layer2.3.bn3.bias',\n 'layer2.0.conv1.weight',\n 'layer2.0.bn1.weight',\n 'layer2.0.bn1.bias',\n 'layer2.0.conv2.weight',\n 'layer2.0.bn2.weight',\n 'layer2.0.bn2.bias',\n 'layer2.0.conv3.weight',\n 'layer2.0.bn3.weight',\n 'layer2.0.bn3.bias',\n 'layer2.0.downsample.0.weight',\n 'layer2.0.downsample.1.weight',\n 'layer2.0.downsample.1.bias',\n 'layer2.0.conv1.weight',\n 'layer2.0.conv2.weight',\n 'layer2.0.conv3.weight',\n 'layer2.0.downsample.0.weight',\n 'layer2.0.downsample.1.weight',\n 'layer2.0.downsample.1.bias',\n 'layer2.0.downsample.0.weight',\n 'layer2.1.conv1.weight',\n 'layer2.1.bn1.weight',\n 'layer2.1.bn1.bias',\n 'layer2.1.conv2.weight',\n 'layer2.1.bn2.weight',\n 'layer2.1.bn2.bias',\n 'layer2.1.conv3.weight',\n 'layer2.1.bn3.weight',\n 'layer2.1.bn3.bias',\n 'layer2.1.conv1.weight',\n 'layer2.1.conv2.weight',\n 'layer2.1.conv3.weight',\n 'layer2.2.conv1.weight',\n 'layer2.2.bn1.weight',\n 'layer2.2.bn1.bias',\n 'layer2.2.conv2.weight',\n 'layer2.2.bn2.weight',\n 'layer2.2.bn2.bias',\n 'layer2.2.conv3.weight',\n 'layer2.2.bn3.weight',\n 'layer2.2.bn3.bias',\n 'layer2.2.conv1.weight',\n 'layer2.2.conv2.weight',\n 'layer2.2.conv3.weight',\n 'layer2.3.conv1.weight',\n 'layer2.3.bn1.weight',\n 'layer2.3.bn1.bias',\n 'layer2.3.conv2.weight',\n 'layer2.3.bn2.weight',\n 'layer2.3.bn2.bias',\n 'layer2.3.conv3.weight',\n 'layer2.3.bn3.weight',\n 'layer2.3.bn3.bias',\n 'layer2.3.conv1.weight',\n 'layer2.3.conv2.weight',\n 'layer2.3.conv3.weight',\n 'layer3.0.conv1.weight',\n 'layer3.0.bn1.weight',\n 'layer3.0.bn1.bias',\n 'layer3.0.conv2.weight',\n 'layer3.0.bn2.weight',\n 'layer3.0.bn2.bias',\n 'layer3.0.conv3.weight',\n 'layer3.0.bn3.weight',\n 'layer3.0.bn3.bias',\n 'layer3.0.downsample.0.weight',\n 'layer3.0.downsample.1.weight',\n 'layer3.0.downsample.1.bias',\n 'layer3.1.conv1.weight',\n 'layer3.1.bn1.weight',\n 'layer3.1.bn1.bias',\n 'layer3.1.conv2.weight',\n 'layer3.1.bn2.weight',\n 'layer3.1.bn2.bias',\n 'layer3.1.conv3.weight',\n 'layer3.1.bn3.weight',\n 'layer3.1.bn3.bias',\n 'layer3.2.conv1.weight',\n 'layer3.2.bn1.weight',\n 'layer3.2.bn1.bias',\n 'layer3.2.conv2.weight',\n 'layer3.2.bn2.weight',\n 'layer3.2.bn2.bias',\n 'layer3.2.conv3.weight',\n 'layer3.2.bn3.weight',\n 'layer3.2.bn3.bias',\n 'layer3.3.conv1.weight',\n 'layer3.3.bn1.weight',\n 'layer3.3.bn1.bias',\n 'layer3.3.conv2.weight',\n 'layer3.3.bn2.weight',\n 'layer3.3.bn2.bias',\n 'layer3.3.conv3.weight',\n 'layer3.3.bn3.weight',\n 'layer3.3.bn3.bias',\n 'layer3.4.conv1.weight',\n 'layer3.4.bn1.weight',\n 'layer3.4.bn1.bias',\n 'layer3.4.conv2.weight',\n 'layer3.4.bn2.weight',\n 'layer3.4.bn2.bias',\n 'layer3.4.conv3.weight',\n 'layer3.4.bn3.weight',\n 'layer3.4.bn3.bias',\n 'layer3.5.conv1.weight',\n 'layer3.5.bn1.weight',\n 'layer3.5.bn1.bias',\n 'layer3.5.conv2.weight',\n 'layer3.5.bn2.weight',\n 'layer3.5.bn2.bias',\n 'layer3.5.conv3.weight',\n 'layer3.5.bn3.weight',\n 'layer3.5.bn3.bias',\n 'layer3.0.conv1.weight',\n 'layer3.0.bn1.weight',\n 'layer3.0.bn1.bias',\n 'layer3.0.conv2.weight',\n 'layer3.0.bn2.weight',\n 'layer3.0.bn2.bias',\n 'layer3.0.conv3.weight',\n 'layer3.0.bn3.weight',\n 'layer3.0.bn3.bias',\n 'layer3.0.downsample.0.weight',\n 'layer3.0.downsample.1.weight',\n 'layer3.0.downsample.1.bias',\n 'layer3.0.conv1.weight',\n 'layer3.0.conv2.weight',\n 'layer3.0.conv3.weight',\n 'layer3.0.downsample.0.weight',\n 'layer3.0.downsample.1.weight',\n 'layer3.0.downsample.1.bias',\n 'layer3.0.downsample.0.weight',\n 'layer3.1.conv1.weight',\n 'layer3.1.bn1.weight',\n 'layer3.1.bn1.bias',\n 'layer3.1.conv2.weight',\n 'layer3.1.bn2.weight',\n 'layer3.1.bn2.bias',\n 'layer3.1.conv3.weight',\n 'layer3.1.bn3.weight',\n 'layer3.1.bn3.bias',\n 'layer3.1.conv1.weight',\n 'layer3.1.conv2.weight',\n 'layer3.1.conv3.weight',\n 'layer3.2.conv1.weight',\n 'layer3.2.bn1.weight',\n 'layer3.2.bn1.bias',\n 'layer3.2.conv2.weight',\n 'layer3.2.bn2.weight',\n 'layer3.2.bn2.bias',\n 'layer3.2.conv3.weight',\n 'layer3.2.bn3.weight',\n 'layer3.2.bn3.bias',\n 'layer3.2.conv1.weight',\n 'layer3.2.conv2.weight',\n 'layer3.2.conv3.weight',\n 'layer3.3.conv1.weight',\n 'layer3.3.bn1.weight',\n 'layer3.3.bn1.bias',\n 'layer3.3.conv2.weight',\n 'layer3.3.bn2.weight',\n 'layer3.3.bn2.bias',\n 'layer3.3.conv3.weight',\n 'layer3.3.bn3.weight',\n 'layer3.3.bn3.bias',\n 'layer3.3.conv1.weight',\n 'layer3.3.conv2.weight',\n 'layer3.3.conv3.weight',\n 'layer3.4.conv1.weight',\n 'layer3.4.bn1.weight',\n 'layer3.4.bn1.bias',\n 'layer3.4.conv2.weight',\n 'layer3.4.bn2.weight',\n 'layer3.4.bn2.bias',\n 'layer3.4.conv3.weight',\n 'layer3.4.bn3.weight',\n 'layer3.4.bn3.bias',\n 'layer3.4.conv1.weight',\n 'layer3.4.conv2.weight',\n 'layer3.4.conv3.weight',\n 'layer3.5.conv1.weight',\n 'layer3.5.bn1.weight',\n 'layer3.5.bn1.bias',\n 'layer3.5.conv2.weight',\n 'layer3.5.bn2.weight',\n 'layer3.5.bn2.bias',\n 'layer3.5.conv3.weight',\n 'layer3.5.bn3.weight',\n 'layer3.5.bn3.bias',\n 'layer3.5.conv1.weight',\n 'layer3.5.conv2.weight',\n 'layer3.5.conv3.weight',\n 'layer4.0.conv1.weight',\n 'layer4.0.bn1.weight',\n 'layer4.0.bn1.bias',\n 'layer4.0.conv2.weight',\n 'layer4.0.bn2.weight',\n 'layer4.0.bn2.bias',\n 'layer4.0.conv3.weight',\n 'layer4.0.bn3.weight',\n 'layer4.0.bn3.bias',\n 'layer4.0.downsample.0.weight',\n 'layer4.0.downsample.1.weight',\n 'layer4.0.downsample.1.bias',\n 'layer4.1.conv1.weight',\n 'layer4.1.bn1.weight',\n 'layer4.1.bn1.bias',\n 'layer4.1.conv2.weight',\n 'layer4.1.bn2.weight',\n 'layer4.1.bn2.bias',\n 'layer4.1.conv3.weight',\n 'layer4.1.bn3.weight',\n 'layer4.1.bn3.bias',\n 'layer4.2.conv1.weight',\n 'layer4.2.bn1.weight',\n 'layer4.2.bn1.bias',\n 'layer4.2.conv2.weight',\n 'layer4.2.bn2.weight',\n 'layer4.2.bn2.bias',\n 'layer4.2.conv3.weight',\n 'layer4.2.bn3.weight',\n 'layer4.2.bn3.bias',\n 'layer4.0.conv1.weight',\n 'layer4.0.bn1.weight',\n 'layer4.0.bn1.bias',\n 'layer4.0.conv2.weight',\n 'layer4.0.bn2.weight',\n 'layer4.0.bn2.bias',\n 'layer4.0.conv3.weight',\n 'layer4.0.bn3.weight',\n 'layer4.0.bn3.bias',\n 'layer4.0.downsample.0.weight',\n 'layer4.0.downsample.1.weight',\n 'layer4.0.downsample.1.bias',\n 'layer4.0.conv1.weight',\n 'layer4.0.conv2.weight',\n 'layer4.0.conv3.weight',\n 'layer4.0.downsample.0.weight',\n 'layer4.0.downsample.1.weight',\n 'layer4.0.downsample.1.bias',\n 'layer4.0.downsample.0.weight',\n 'layer4.1.conv1.weight',\n 'layer4.1.bn1.weight',\n 'layer4.1.bn1.bias',\n 'layer4.1.conv2.weight',\n 'layer4.1.bn2.weight',\n 'layer4.1.bn2.bias',\n 'layer4.1.conv3.weight',\n 'layer4.1.bn3.weight',\n 'layer4.1.bn3.bias',\n 'layer4.1.conv1.weight',\n 'layer4.1.conv2.weight',\n 'layer4.1.conv3.weight',\n 'layer4.2.conv1.weight',\n 'layer4.2.bn1.weight',\n 'layer4.2.bn1.bias',\n 'layer4.2.conv2.weight',\n 'layer4.2.bn2.weight',\n 'layer4.2.bn2.bias',\n 'layer4.2.conv3.weight',\n 'layer4.2.bn3.weight',\n 'layer4.2.bn3.bias',\n 'layer4.2.conv1.weight',\n 'layer4.2.conv2.weight',\n 'layer4.2.conv3.weight',\n 'fc.weight',\n 'fc.bias']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1][\"param_names\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:25:01.278893700Z",
     "start_time": "2023-12-28T15:25:01.237707400Z"
    }
   },
   "id": "fe9f389eac666f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-2.)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(12, 100)\n",
    "y = x * 10\n",
    "x_norm = torch.linalg.norm(x, ord=2, dim=1)\n",
    "y_norm = torch.linalg.norm(y, ord=2, dim=1)\n",
    "-2 * torch.mean(torch.sum(x * y, dim=1) / (x_norm * y_norm))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:03:58.838708200Z",
     "start_time": "2023-12-28T19:03:57.001062300Z"
    }
   },
   "id": "15dd58c60e3c864d"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step 0142/2356 - loss 4.558164:   0%|          | 0/10 [00:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 150\u001B[0m\n\u001B[0;32m    147\u001B[0m resnet50 \u001B[38;5;241m=\u001B[39m timm\u001B[38;5;241m.\u001B[39mcreate_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresnet50\u001B[39m\u001B[38;5;124m\"\u001B[39m, pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    148\u001B[0m backbone \u001B[38;5;241m=\u001B[39m _Backbone(resnet50)\n\u001B[1;32m--> 150\u001B[0m \u001B[43mcallback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbackbone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2048\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[31], line 66\u001B[0m, in \u001B[0;36mClassificationCallback.eval_model\u001B[1;34m(self, backbone, backbone_output_size)\u001B[0m\n\u001B[0;32m     64\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 66\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[43mbackbone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimage\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m logits \u001B[38;5;241m=\u001B[39m fc(features)\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtclip:\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[31], line 143\u001B[0m, in \u001B[0;36m_Backbone.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m--> 143\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackbone\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    144\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackbone\u001B[38;5;241m.\u001B[39mglobal_pool(x)\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\timm\\models\\resnet.py:568\u001B[0m, in \u001B[0;36mResNet.forward_features\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    566\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer2(x)\n\u001B[0;32m    567\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer3(x)\n\u001B[1;32m--> 568\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer4\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\timm\\models\\resnet.py:227\u001B[0m, in \u001B[0;36mBottleneck.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    224\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact2(x)\n\u001B[0;32m    225\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maa(x)\n\u001B[1;32m--> 227\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    228\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn3(x)\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mse \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models\n",
    "import utils\n",
    "from datamodules import Task1Datamodule\n",
    "\n",
    "\n",
    "class ClassificationCallback(pl.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        datamodule: Task1Datamodule,\n",
    "        num_epochs: int = 80,\n",
    "        lr: List[float] = None,\n",
    "        tclip: bool = True,\n",
    "        tclip_alpha: float = 10.0,\n",
    "        weight_decay: float = 1e-2,\n",
    "        early_stopping: int = 10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if lr is None:\n",
    "            lr = [1e-3]\n",
    "\n",
    "        self.datamodule = datamodule\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.tclip = tclip\n",
    "        self.tclip_alpha = tclip_alpha\n",
    "        self.weight_decay = weight_decay\n",
    "        self.early_stopping = early_stopping\n",
    "\n",
    "    def eval_model(self, backbone: nn.Module, backbone_output_size: int):\n",
    "        acc = torchmetrics.Accuracy(\"multiclass\", num_classes=models.NUM_CLASSES)\n",
    "        ap = torchmetrics.AveragePrecision(\"multiclass\", num_classes=models.NUM_CLASSES)\n",
    "        best_loss = -1000000\n",
    "        best_lr = None\n",
    "        best_epoch = None\n",
    "        best_acc = None\n",
    "        best_ap = None\n",
    "        for lr in self.lr:\n",
    "            fc = nn.Linear(backbone_output_size, models.NUM_CLASSES)\n",
    "            opt = torch.optim.AdamW(\n",
    "                utils.add_weight_decay(fc, self.weight_decay), lr=lr\n",
    "            )\n",
    "            best_lr_loss = -1000000\n",
    "            best_lr_epoch = -1\n",
    "\n",
    "            train_dataloader = self.datamodule.train_dataloader()\n",
    "            val_dataloader = self.datamodule.val_dataloader()\n",
    "            if isinstance(val_dataloader, list):\n",
    "                assert len(val_dataloader) == 1\n",
    "                val_dataloader = val_dataloader[0]\n",
    "            tq = tqdm(range(self.num_epochs))\n",
    "            for epoch in tq:\n",
    "                num_batches = 0\n",
    "                for data, labels in train_dataloader:\n",
    "                    num_batches += 1\n",
    "                    opt.zero_grad()\n",
    "                    with torch.no_grad():\n",
    "                        features = backbone(data[\"image\"])\n",
    "                    logits = fc(features)\n",
    "                    if self.tclip:\n",
    "                        logits = self.tclip_alpha * torch.tanh(\n",
    "                            logits / self.tclip_alpha\n",
    "                        )\n",
    "                    loss = F.cross_entropy(logits, labels)\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "                    tq.set_description(\n",
    "                        f\"Train step {num_batches:04d}/{len(train_dataloader):04d} - loss {loss:.6f}\"\n",
    "                    )\n",
    "\n",
    "                loss = 0\n",
    "                num_batches = 0\n",
    "                for data, labels in val_dataloader:\n",
    "                    num_batches += 1\n",
    "                    with torch.no_grad():\n",
    "                        features = backbone(data[\"image\"])\n",
    "                        logits = fc(features)\n",
    "                        if self.tclip:\n",
    "                            logits = self.tclip_alpha * torch.tanh(\n",
    "                                logits / self.tclip_alpha\n",
    "                            )\n",
    "                        loss += F.cross_entropy(logits, labels)\n",
    "                        acc.update(logits, labels)\n",
    "                        ap.update(logits, labels)\n",
    "                    tq.set_description(\n",
    "                        f\"Eval step {num_batches:04d}/{len(val_dataloader):04d} - loss {loss:.6f}\"\n",
    "                    )\n",
    "                val_loss = loss / num_batches\n",
    "                val_acc = acc.compute()\n",
    "                val_ap = ap.compute()\n",
    "                acc.reset()\n",
    "                ap.reset()\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_lr = lr\n",
    "                    best_epoch = epoch\n",
    "                    best_acc = val_acc\n",
    "                    best_ap = val_ap\n",
    "                if val_loss < best_lr_loss:\n",
    "                    best_lr_loss = val_loss\n",
    "                    best_lr_epoch = epoch\n",
    "                elif epoch - best_lr_epoch > self.early_stopping:\n",
    "                    break\n",
    "        return {\n",
    "            \"loss\": best_loss,\n",
    "            \"lr\": best_lr,\n",
    "            \"epoch\": best_epoch,\n",
    "            \"acc\": best_acc,\n",
    "            \"ap\": best_ap,\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(\n",
    "        self, trainer: pl.Trainer, pl_module: pl.LightningModule\n",
    "    ):\n",
    "        backbone = nn.Sequential(pl_module.online_backbone, pl_module.global_pool)\n",
    "\n",
    "        logs = self.eval_model(backbone, pl_module.hparams.mlp_out_size)\n",
    "\n",
    "        pl_module.log_dict({f\"classification/{k}\": v for k, v in logs.items()})\n",
    "        print(f\"Classification {logs}\")\n",
    "\n",
    "import datamodules\n",
    "\n",
    "datamodule = datamodules.Task1Datamodule(\"C:/Data/AAIT/task1\", num_train_workers=0, num_val_workers=0, num_test_workers=0, batch_size=64, labeled=True, unlabeled=False, val_size=0.2, train_dataset_replicas=2)\n",
    "datamodule.setup(\"fit\")\n",
    "\n",
    "callback = ClassificationCallback(datamodule, num_epochs=10, lr=[0.001], tclip=True, tclip_alpha=10., weight_decay=1e-2, early_stopping=10)\n",
    "\n",
    "class _Backbone(nn.Module):\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.backbone = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.forward_features(x)\n",
    "        x = self.backbone.global_pool(x)\n",
    "        return x\n",
    "\n",
    "resnet50 = timm.create_model(\"resnet50\", pretrained=True)\n",
    "backbone = _Backbone(resnet50)\n",
    "\n",
    "callback.eval_model(backbone, 2048)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T20:07:48.573508100Z",
     "start_time": "2023-12-28T20:07:19.413410700Z"
    }
   },
   "id": "61652c228373ab5e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x1000 and 2048x100)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 20\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[0;32m     18\u001B[0m backbone \u001B[38;5;241m=\u001B[39m _Backbone(resnet50)\n\u001B[1;32m---> 20\u001B[0m \u001B[43mcallback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresnet50\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2048\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[24], line 67\u001B[0m, in \u001B[0;36mClassificationCallback.eval_model\u001B[1;34m(self, backbone, backbone_output_size)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     66\u001B[0m     features \u001B[38;5;241m=\u001B[39m backbone(data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m---> 67\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mfc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtclip:\n\u001B[0;32m     69\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtclip_alpha \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mtanh(\n\u001B[0;32m     70\u001B[0m         features \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtclip_alpha\n\u001B[0;32m     71\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (16x1000 and 2048x100)"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T20:01:46.273059Z",
     "start_time": "2023-12-28T20:01:43.201449700Z"
    }
   },
   "id": "4ba638c352ebdf67"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n = 23555\n",
    "m = 2048\n",
    "X = np.random.randn(n, m) * 10 + np.random.randn(n, m) * 5 + 8\n",
    "y = np.random.randint(0, 100, (n,)).astype(int)\n",
    "# y_sampled = y\n",
    "# y_binarized = np.zeros((y.size, 100))\n",
    "# y_binarized[np.arange(y.size), y] = 1\n",
    "# y = y_binarized\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:37:20.354795400Z",
     "start_time": "2024-01-03T20:37:17.279227500Z"
    }
   },
   "id": "99ed0691fab4f91c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "labels = np.arange(100)\n",
    "def train_test(algo, pca_n_comp=2048, knn_n_neighbors=20):\n",
    "    global X_train, X_test, y_train, y_test, labels\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_transformed = scaler.fit_transform(X_train)\n",
    "    X_test_transformed = scaler.transform(X_test)\n",
    "    \n",
    "    if pca_n_comp != X_train.shape[1]:\n",
    "        pca = PCA(n_components=pca_n_comp)\n",
    "        X_train_transformed = pca.fit_transform(X_train_transformed)\n",
    "        X_test_transformed = pca.transform(X_test_transformed)\n",
    "    \n",
    "    if algo == \"knn\":\n",
    "        knn = KNeighborsClassifier(n_neighbors=knn_n_neighbors)\n",
    "        knn.fit(X_train_transformed, y_train)\n",
    "        y_proba = knn.predict_proba(X_test_transformed)\n",
    "    elif algo == \"randomforest\":\n",
    "        model = RandomForestClassifier(class_weight=\"balanced_subsample\")\n",
    "        model.fit(X_train_transformed, y_train)\n",
    "        y_proba = model.predict_proba(X_test_transformed)\n",
    "    elif algo == \"xgb\":\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"unknown algo\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T18:10:04.526256500Z",
     "start_time": "2024-01-03T18:10:04.523278200Z"
    }
   },
   "id": "558c25ea3947cb25"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2 s  609 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_test(algo=\"knn\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:49:15.420583700Z",
     "start_time": "2024-01-03T17:48:42.059890600Z"
    }
   },
   "id": "a7e39bb57430e422"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%timeit train_test(algo=\"randomforest\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-03T17:49:55.511538400Z"
    }
   },
   "id": "3c5b0fd5692135c2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(class_weight=\"balanced_subsample\", n_jobs=12)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T18:10:11.248599900Z",
     "start_time": "2024-01-03T18:10:11.231520800Z"
    }
   },
   "id": "7cc4dfa0b18e9bdb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(class_weight='balanced_subsample', n_jobs=12)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_jobs=12)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_jobs=12)</pre></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_transformed, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T18:13:27.909838700Z",
     "start_time": "2024-01-03T18:10:12.548518300Z"
    }
   },
   "id": "bf21f4a76010466b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y_proba = model.predict_proba(X_test_transformed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T18:13:28.195837300Z",
     "start_time": "2024-01-03T18:13:27.913838100Z"
    }
   },
   "id": "f6c00d7d1d06d5e8"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=256)\n",
    "X_train_transformed = pca.fit_transform(X_train_transformed)\n",
    "X_test_transformed = pca.transform(X_test_transformed)\n",
    "\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "xgb = XGBClassifier(early_stopping_rounds=10, tree_method=\"hist\", max_depth=4, n_estimators=100, device=\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:37:37.301640900Z",
     "start_time": "2024-01-03T20:37:30.170418100Z"
    }
   },
   "id": "657de4bff7b623b3"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:4.61183\n",
      "[1]\tvalidation_0-mlogloss:4.61640\n",
      "[2]\tvalidation_0-mlogloss:4.62094\n",
      "[3]\tvalidation_0-mlogloss:4.62685\n",
      "[4]\tvalidation_0-mlogloss:4.63390\n",
      "[5]\tvalidation_0-mlogloss:4.63917\n",
      "[6]\tvalidation_0-mlogloss:4.64556\n",
      "[7]\tvalidation_0-mlogloss:4.65126\n",
      "[8]\tvalidation_0-mlogloss:4.65507\n",
      "[9]\tvalidation_0-mlogloss:4.66272\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device='cuda', early_stopping_rounds=10,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softprob', ...)",
      "text/html": "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=10,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=10,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train_transformed, y_train, eval_set=[(X_test_transformed, y_test)], verbose=True, sample_weight=sample_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:37:48.219437200Z",
     "start_time": "2024-01-03T20:37:37.304644400Z"
    }
   },
   "id": "24a50c88d1f55549"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "(4711, 100)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = xgb.predict_proba(X_test_transformed)\n",
    "y_proba.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:44:17.644611Z",
     "start_time": "2024-01-03T20:44:16.762541200Z"
    }
   },
   "id": "1c0d02caf4a7417e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from xgboost import DMatrix\n",
    "\n",
    "DMatrix()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48a3f4574bbefe42"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "['T_destination',\n '__annotations__',\n '__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattr__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_apply',\n '_backward_hooks',\n '_backward_pre_hooks',\n '_buffers',\n '_call_impl',\n '_compiled_call_impl',\n '_forward_hooks',\n '_forward_hooks_always_called',\n '_forward_hooks_with_kwargs',\n '_forward_pre_hooks',\n '_forward_pre_hooks_with_kwargs',\n '_get_backward_hooks',\n '_get_backward_pre_hooks',\n '_get_name',\n '_is_full_backward_hook',\n '_load_from_state_dict',\n '_load_state_dict_post_hooks',\n '_load_state_dict_pre_hooks',\n '_maybe_warn_non_full_backward_hook',\n '_modules',\n '_named_members',\n '_non_persistent_buffers_set',\n '_parameters',\n '_register_load_state_dict_pre_hook',\n '_register_state_dict_hook',\n '_replicate_for_data_parallel',\n '_save_to_state_dict',\n '_slow_forward',\n '_state_dict_hooks',\n '_state_dict_pre_hooks',\n '_version',\n '_wrapped_call_impl',\n 'act1',\n 'add_module',\n 'apply',\n 'bfloat16',\n 'bn1',\n 'buffers',\n 'call_super_init',\n 'children',\n 'compile',\n 'conv1',\n 'cpu',\n 'cuda',\n 'default_cfg',\n 'double',\n 'drop_rate',\n 'dump_patches',\n 'eval',\n 'extra_repr',\n 'fc',\n 'feature_info',\n 'float',\n 'forward',\n 'forward_features',\n 'forward_head',\n 'get_buffer',\n 'get_classifier',\n 'get_extra_state',\n 'get_parameter',\n 'get_submodule',\n 'global_pool',\n 'grad_checkpointing',\n 'group_matcher',\n 'half',\n 'init_weights',\n 'ipu',\n 'layer1',\n 'layer2',\n 'layer3',\n 'layer4',\n 'load_state_dict',\n 'maxpool',\n 'modules',\n 'named_buffers',\n 'named_children',\n 'named_modules',\n 'named_parameters',\n 'num_classes',\n 'num_features',\n 'parameters',\n 'pretrained_cfg',\n 'register_backward_hook',\n 'register_buffer',\n 'register_forward_hook',\n 'register_forward_pre_hook',\n 'register_full_backward_hook',\n 'register_full_backward_pre_hook',\n 'register_load_state_dict_post_hook',\n 'register_module',\n 'register_parameter',\n 'register_state_dict_pre_hook',\n 'requires_grad_',\n 'reset_classifier',\n 'set_extra_state',\n 'set_grad_checkpointing',\n 'share_memory',\n 'state_dict',\n 'to',\n 'to_empty',\n 'train',\n 'training',\n 'type',\n 'xpu',\n 'zero_grad']"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "m = timm.create_model(\"resnet34\", pretrained=False)\n",
    "dir(m)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:09:39.184103200Z",
     "start_time": "2024-01-03T20:09:37.840851400Z"
    }
   },
   "id": "3c323215df105d95"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[70], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1694\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1695\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'ResNet' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "m.device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:09:47.493697Z",
     "start_time": "2024-01-03T20:09:46.350697200Z"
    }
   },
   "id": "6225b924eace6e9c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.01011109, 0.00971837, 0.00985839, ..., 0.00944635, 0.01012211,\n        0.00957291],\n       [0.00997305, 0.00958568, 0.00972379, ..., 0.00931739, 0.00964165,\n        0.0103318 ],\n       [0.01025263, 0.0098544 , 0.00999638, ..., 0.00957858, 0.00991193,\n        0.00970691],\n       ...,\n       [0.01017627, 0.00978102, 0.00992194, ..., 0.00950725, 0.00903583,\n        0.00963462],\n       [0.01016838, 0.00977342, 0.00991424, ..., 0.00949987, 0.00983048,\n        0.00962714],\n       [0.01022303, 0.00982595, 0.00996752, ..., 0.01263243, 0.00988332,\n        0.00967888]], dtype=float32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.predict_proba(X_test_transformed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T18:24:45.446062700Z",
     "start_time": "2024-01-03T18:24:44.654997Z"
    }
   },
   "id": "6ebee0aa37f62d76"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_proba = knn.predict(X_test)\n",
    "y_proba"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:44:44.195782500Z",
     "start_time": "2024-01-03T17:44:40.631226300Z"
    }
   },
   "id": "1a617590c70fb537"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1.])"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_proba)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:44:54.787316800Z",
     "start_time": "2024-01-03T17:44:54.280781600Z"
    }
   },
   "id": "5a89acb0f78d43bd"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "(4711, 199)"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(y_proba, axis=1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:41:36.195819300Z",
     "start_time": "2024-01-03T17:41:36.140716800Z"
    }
   },
   "id": "9ccee69ff745720b"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "[(4711, 1),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2)]"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.shape for a in y_proba]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:41:36.219745800Z",
     "start_time": "2024-01-03T17:41:36.153715700Z"
    }
   },
   "id": "9bed6461b363d42c"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.],\n       [1.],\n       [1.],\n       ...,\n       [1.],\n       [1.],\n       [1.]])"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:41:49.197773900Z",
     "start_time": "2024-01-03T17:41:48.244710200Z"
    }
   },
   "id": "34b441a0fcfc2674"
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1. , 0. ],\n       [0.8, 0.2],\n       [1. , 0. ],\n       ...,\n       [1. , 0. ],\n       [1. , 0. ],\n       [1. , 0. ]])"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba[16]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:42:36.318791Z",
     "start_time": "2024-01-03T17:42:35.765660800Z"
    }
   },
   "id": "46314b91cc007fae"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[113], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtimeit\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain_test(algo=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mknn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2417\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[1;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[0;32m   2415\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[0;32m   2416\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m-> 2417\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2419\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[0;32m   2420\u001B[0m \u001B[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001B[39;00m\n\u001B[0;32m   2421\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[0;32m   2422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1170\u001B[0m, in \u001B[0;36mExecutionMagics.timeit\u001B[1;34m(self, line, cell, local_ns)\u001B[0m\n\u001B[0;32m   1168\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m   1169\u001B[0m     number \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m index\n\u001B[1;32m-> 1170\u001B[0m     time_number \u001B[38;5;241m=\u001B[39m \u001B[43mtimer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1171\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m time_number \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m:\n\u001B[0;32m   1172\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\magics\\execution.py:158\u001B[0m, in \u001B[0;36mTimer.timeit\u001B[1;34m(self, number)\u001B[0m\n\u001B[0;32m    156\u001B[0m gc\u001B[38;5;241m.\u001B[39mdisable()\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 158\u001B[0m     timing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "File \u001B[1;32m<magic-timeit>:1\u001B[0m, in \u001B[0;36minner\u001B[1;34m(_it, _timer)\u001B[0m\n",
      "Cell \u001B[1;32mIn[112], line 35\u001B[0m, in \u001B[0;36mtrain_test\u001B[1;34m(algo, pca_n_comp, knn_n_neighbors)\u001B[0m\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munknown algo\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# missing_labels = np.sort(np.array(list(set(range(100)).difference(set(np.unique(y_train))))))\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# if len(missing_labels) > 0:\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m#     missing_labels = missing_labels - np.arange(len(missing_labels))\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m#     print(y_proba.shape)\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m#     y_proba = np.insert(y_proba, missing_labels, 0, axis=1)\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m#     print(y_proba.shape)\u001B[39;00m\n\u001B[1;32m---> 35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43my_proba\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m)\n\u001B[0;32m     36\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(y_proba, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# print(y_hat.shape)\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# print(y_proba.shape)\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "%timeit train_test(algo=\"knn\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:38:32.094021500Z",
     "start_time": "2024-01-03T17:38:28.017232400Z"
    }
   },
   "id": "464056757809dac8"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:20:35.902801100Z",
     "start_time": "2024-01-03T17:20:35.456959400Z"
    }
   },
   "id": "33d47e6313a42e0f"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:20:05.948611700Z",
     "start_time": "2024-01-03T17:20:05.485614100Z"
    }
   },
   "id": "c76d7bf87d20cb65"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "array({1, 2, 3}, dtype=object)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array({1, 2, 3})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:17:43.978246200Z",
     "start_time": "2024-01-03T17:17:43.678948400Z"
    }
   },
   "id": "a7c1501efdea2fa2"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:05:55.247974200Z",
     "start_time": "2024-01-03T17:05:55.201971400Z"
    }
   },
   "id": "8fddaf4756a457e5"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "2048"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:05:56.339010600Z",
     "start_time": "2024-01-03T17:05:56.319010900Z"
    }
   },
   "id": "b38db0e9551ea060"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of given labels, 100, not equal to the number of columns in 'y_score', 101",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtimeit\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain_test(algo=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mknn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2417\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[1;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[0;32m   2415\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[0;32m   2416\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m-> 2417\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2419\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[0;32m   2420\u001B[0m \u001B[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001B[39;00m\n\u001B[0;32m   2421\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[0;32m   2422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1170\u001B[0m, in \u001B[0;36mExecutionMagics.timeit\u001B[1;34m(self, line, cell, local_ns)\u001B[0m\n\u001B[0;32m   1168\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m   1169\u001B[0m     number \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m index\n\u001B[1;32m-> 1170\u001B[0m     time_number \u001B[38;5;241m=\u001B[39m \u001B[43mtimer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1171\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m time_number \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m:\n\u001B[0;32m   1172\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\magics\\execution.py:158\u001B[0m, in \u001B[0;36mTimer.timeit\u001B[1;34m(self, number)\u001B[0m\n\u001B[0;32m    156\u001B[0m gc\u001B[38;5;241m.\u001B[39mdisable()\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 158\u001B[0m     timing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "File \u001B[1;32m<magic-timeit>:1\u001B[0m, in \u001B[0;36minner\u001B[1;34m(_it, _timer)\u001B[0m\n",
      "Cell \u001B[1;32mIn[65], line 38\u001B[0m, in \u001B[0;36mtrain_test\u001B[1;34m(algo, pca_n_comp, knn_n_neighbors)\u001B[0m\n\u001B[0;32m     32\u001B[0m     y_proba \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39minsert(y_proba, missing_labels, \u001B[38;5;241m0\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     33\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(y_proba, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124macc\u001B[39m\u001B[38;5;124m\"\u001B[39m: accuracy_score(y_test, y_hat),\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m\"\u001B[39m: f1_score(y_test, y_hat, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m\"\u001B[39m, labels\u001B[38;5;241m=\u001B[39mlabels),\n\u001B[1;32m---> 38\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauc\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mroc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_proba\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43movr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124map\u001B[39m\u001B[38;5;124m\"\u001B[39m: average_precision_score(y_test, y_proba, labels\u001B[38;5;241m=\u001B[39mlabels),\n\u001B[0;32m     40\u001B[0m }\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:620\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    618\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m multi_class \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    619\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti_class must be in (\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movo\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 620\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_multiclass_roc_auc_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    621\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    623\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    624\u001B[0m     labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y_true)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:728\u001B[0m, in \u001B[0;36m_multiclass_roc_auc_score\u001B[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001B[0m\n\u001B[0;32m    726\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParameter \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must be ordered\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    727\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(classes) \u001B[38;5;241m!=\u001B[39m y_score\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m--> 728\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    729\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of given labels, \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m, not equal to the number \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    730\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof columns in \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_score\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mlen\u001B[39m(classes), y_score\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    731\u001B[0m     )\n\u001B[0;32m    732\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39msetdiff1d(y_true, classes)):\n\u001B[0;32m    733\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m contains labels not in parameter \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Number of given labels, 100, not equal to the number of columns in 'y_score', 101"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:19:14.858474600Z",
     "start_time": "2024-01-03T17:19:11.282647800Z"
    }
   },
   "id": "7171d6adad6cbead"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "970091408e9e9275"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0,  0,  1,  2,  3,  0,  0,  4],\n       [ 5,  0,  6,  7,  8,  0,  0,  9],\n       [10,  0, 11, 12, 13,  0,  0, 14],\n       [15,  0, 16, 17, 18,  0,  0, 19],\n       [20,  0, 21, 22, 23,  0,  0, 24]])"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.insert(np.arange(25).reshape(5, 5), np.array([1, 4, 4]), 0, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:18:51.532769800Z",
     "start_time": "2024-01-03T17:18:51.057560600Z"
    }
   },
   "id": "2de84d93066ae42"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 2, 3])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:16:47.920496400Z",
     "start_time": "2024-01-03T17:16:47.460981600Z"
    }
   },
   "id": "cbe96b5df31c37e7"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.min()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:56:10.808615100Z",
     "start_time": "2024-01-03T16:56:10.183544700Z"
    }
   },
   "id": "15dcdf32fade08f4"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.min()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:56:16.323847500Z",
     "start_time": "2024-01-03T16:56:16.285668900Z"
    }
   },
   "id": "99d7e0effddd7ace"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(4711,)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:56:19.019295300Z",
     "start_time": "2024-01-03T16:56:18.978811600Z"
    }
   },
   "id": "e84cdbf534844736"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(4711,)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:56:27.082894900Z",
     "start_time": "2024-01-03T16:56:26.554536600Z"
    }
   },
   "id": "41f41e5ed46aae9e"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:/Data/AAIT/task1/train_data/annotations.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:49:37.339054300Z",
     "start_time": "2024-01-03T19:49:36.119313800Z"
    }
   },
   "id": "b28a790d830389a5"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           sample  label\n0          task1/train_data/images/labeled/0.jpeg      0\n1          task1/train_data/images/labeled/1.jpeg      1\n2          task1/train_data/images/labeled/2.jpeg      2\n3          task1/train_data/images/labeled/3.jpeg      3\n4          task1/train_data/images/labeled/4.jpeg      4\n...                                           ...    ...\n23550  task1/train_data/images/labeled/23550.jpeg     97\n23551  task1/train_data/images/labeled/23551.jpeg     28\n23552  task1/train_data/images/labeled/23552.jpeg     53\n23553  task1/train_data/images/labeled/23553.jpeg      9\n23554  task1/train_data/images/labeled/23554.jpeg     90\n\n[23555 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>task1/train_data/images/labeled/0.jpeg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>task1/train_data/images/labeled/1.jpeg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>task1/train_data/images/labeled/2.jpeg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>task1/train_data/images/labeled/3.jpeg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>task1/train_data/images/labeled/4.jpeg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23550</th>\n      <td>task1/train_data/images/labeled/23550.jpeg</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>23551</th>\n      <td>task1/train_data/images/labeled/23551.jpeg</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>23552</th>\n      <td>task1/train_data/images/labeled/23552.jpeg</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>23553</th>\n      <td>task1/train_data/images/labeled/23553.jpeg</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>23554</th>\n      <td>task1/train_data/images/labeled/23554.jpeg</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n<p>23555 rows  2 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:49:38.187524Z",
     "start_time": "2024-01-03T19:49:38.129490700Z"
    }
   },
   "id": "2b0f973c9c3b7402"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "       sample\nlabel        \n96         75\n89        149\n92        156\n75        167\n83        170\n...       ...\n82        280\n8         280\n3         286\n5         289\n52        289\n\n[100 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>96</th>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>156</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>286</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>289</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>289</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows  1 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count().sort_values(\"sample\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:50:27.351143500Z",
     "start_time": "2024-01-03T19:50:26.101787300Z"
    }
   },
   "id": "8159e098eec5476d"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "       sample\nlabel        \n52        289\n5         289\n3         286\n8         280\n82        280\n...       ...\n83        170\n75        167\n92        156\n89        149\n96         75\n\n[100 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>52</th>\n      <td>289</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>289</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>286</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>156</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>75</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows  1 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count().sort_values(\"sample\", ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:50:41.145325100Z",
     "start_time": "2024-01-03T19:50:41.067230Z"
    }
   },
   "id": "ad55987ec36a428a"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1\n",
      "1/1\n",
      "2/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[67], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m train_zeros \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(y[train_index] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_zeros\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_zeros\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m test_zeros \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m train_zeros \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "X = np.arange(400).reshape((80, 5))\n",
    "y = np.sqrt(np.random.randint(0, 16, size=(80,))).astype(int)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    test_zeros = np.sum(y[test_index] == 0)\n",
    "    train_zeros = np.sum(y[train_index] == 0)\n",
    "    print(f\"{train_zeros}/{test_zeros}\")\n",
    "    assert test_zeros > 0 and train_zeros > 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:58:59.294775Z",
     "start_time": "2024-01-03T19:58:58.787604300Z"
    }
   },
   "id": "a2288065cd958e89"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:58:17.085019600Z",
     "start_time": "2024-01-03T19:58:16.590833400Z"
    }
   },
   "id": "87c0738554e1a90e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "imagenet_classes = {\n",
    "0: \"tench, Tinca tinca\",\n",
    "1: \"goldfish, Carassius auratus\",\n",
    "2: \"great white shark, white shark, man-eater, man-eating shark, Carcharodon caharias',\",\n",
    "3: \"tiger shark, Galeocerdo cuvieri\",\n",
    "4: \"hammerhead, hammerhead shark\",\n",
    "5: \"electric ray, crampfish, numbfish, torpedo\",\n",
    "6: \"stingray\",\n",
    "7: \"cock\",\n",
    "8: \"hen\",\n",
    "9: \"ostrich, Struthio camelus\",\n",
    "10: \"brambling, Fringilla montifringilla\",\n",
    "11: \"goldfinch, Carduelis carduelis\",\n",
    "12: \"house finch, linnet, Carpodacus mexicanus\",\n",
    "13: \"junco, snowbird\",\n",
    "14: \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\",\n",
    "15: \"robin, American robin, Turdus migratorius\",\n",
    "16: \"bulbul\",\n",
    "17: \"jay\",\n",
    "18: \"magpie\",\n",
    "19: \"chickadee\",\n",
    "20: \"water ouzel, dipper\",\n",
    "21: \"kite\",\n",
    "22: \"bald eagle, American eagle, Haliaeetus leucocephalus\",\n",
    "23: \"vulture\",\n",
    "24: \"great grey owl, great gray owl, Strix nebulosa\",\n",
    "25: \"European fire salamander, Salamandra salamandra\",\n",
    "26: \"common newt, Triturus vulgaris\",\n",
    "27: \"eft\",\n",
    "28: \"spotted salamander, Ambystoma maculatum\",\n",
    "29: \"axolotl, mud puppy, Ambystoma mexicanum\",\n",
    "30: \"bullfrog, Rana catesbeiana\",\n",
    "31: \"tree frog, tree-frog\",\n",
    "32: \"tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\",\n",
    "33: \"loggerhead, loggerhead turtle, Caretta caretta\",\n",
    "34: \"leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea\",\n",
    "35: \"mud turtle\",\n",
    "36: \"terrapin\",\n",
    "37: \"box turtle, box tortoise\",\n",
    "38: \"banded gecko\",\n",
    "39: \"common iguana, iguana, Iguana iguana\",\n",
    "40: \"American chameleon, anole, Anolis carolinensis\",\n",
    "41: \"whiptail, whiptail lizard\",\n",
    "42: \"agama\",\n",
    "43: \"frilled lizard, Chlamydosaurus kingi\",\n",
    "44: \"alligator lizard\",\n",
    "45: \"Gila monster, Heloderma suspectum\",\n",
    "46: \"green lizard, Lacerta viridis\",\n",
    "47: \"African chameleon, Chamaeleo chamaeleon\",\n",
    "48: \"Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoeis',\",\n",
    "49: \"African crocodile, Nile crocodile, Crocodylus niloticus\",\n",
    "50: \"American alligator, Alligator mississipiensis\",\n",
    "51: \"triceratops\",\n",
    "52: \"thunder snake, worm snake, Carphophis amoenus\",\n",
    "53: \"ringneck snake, ring-necked snake, ring snake\",\n",
    "54: \"hognose snake, puff adder, sand viper\",\n",
    "55: \"green snake, grass snake\",\n",
    "56: \"king snake, kingsnake\",\n",
    "57: \"garter snake, grass snake\",\n",
    "58: \"water snake\",\n",
    "59: \"vine snake\",\n",
    "60: \"night snake, Hypsiglena torquata\",\n",
    "61: \"boa constrictor, Constrictor constrictor\",\n",
    "62: \"rock python, rock snake, Python sebae\",\n",
    "63: \"Indian cobra, Naja naja\",\n",
    "64: \"green mamba\",\n",
    "65: \"sea snake\",\n",
    "66: \"horned viper, cerastes, sand viper, horned asp, Cerastes cornutus\",\n",
    "67: \"diamondback, diamondback rattlesnake, Crotalus adamanteus\",\n",
    "68: \"sidewinder, horned rattlesnake, Crotalus cerastes\",\n",
    "69: \"trilobite\",\n",
    "70: \"harvestman, daddy longlegs, Phalangium opilio\",\n",
    "71: \"scorpion\",\n",
    "72: \"black and gold garden spider, Argiope aurantia\",\n",
    "73: \"barn spider, Araneus cavaticus\",\n",
    "74: \"garden spider, Aranea diademata\",\n",
    "75: \"black widow, Latrodectus mactans\",\n",
    "76: \"tarantula\",\n",
    "77: \"wolf spider, hunting spider\",\n",
    "78: \"tick\",\n",
    "79: \"centipede\",\n",
    "80: \"black grouse\",\n",
    "81: \"ptarmigan\",\n",
    "82: \"ruffed grouse, partridge, Bonasa umbellus\",\n",
    "83: \"prairie chicken, prairie grouse, prairie fowl\",\n",
    "84: \"peacock\",\n",
    "85: \"quail\",\n",
    "86: \"partridge\",\n",
    "87: \"African grey, African gray, Psittacus erithacus\",\n",
    "88: \"macaw\",\n",
    "89: \"sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita\",\n",
    "90: \"lorikeet\",\n",
    "91: \"coucal\",\n",
    "92: \"bee eater\",\n",
    "93: \"hornbill\",\n",
    "94: \"hummingbird\",\n",
    "95: \"jacamar\",\n",
    "96: \"toucan\",\n",
    "97: \"drake\",\n",
    "98: \"red-breasted merganser, Mergus serrator\",\n",
    "99: \"goose\",\n",
    "100: \"black swan, Cygnus atratus\",\n",
    "101: \"tusker\",\n",
    "102: \"echidna, spiny anteater, anteater\",\n",
    "103: \"platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhyhus anatinus',\",\n",
    "104: \"wallaby, brush kangaroo\",\n",
    "105: \"koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\",\n",
    "106: \"wombat\",\n",
    "107: \"jellyfish\",\n",
    "108: \"sea anemone, anemone\",\n",
    "109: \"brain coral\",\n",
    "110: \"flatworm, platyhelminth\",\n",
    "111: \"nematode, nematode worm, roundworm\",\n",
    "112: \"conch\",\n",
    "113: \"snail\",\n",
    "114: \"slug\",\n",
    "115: \"sea slug, nudibranch\",\n",
    "116: \"chiton, coat-of-mail shell, sea cradle, polyplacophore\",\n",
    "117: \"chambered nautilus, pearly nautilus, nautilus\",\n",
    "118: \"Dungeness crab, Cancer magister\",\n",
    "119: \"rock crab, Cancer irroratus\",\n",
    "120: \"fiddler crab\",\n",
    "121: \"king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodesamtschatica',\",\n",
    "122: \"American lobster, Northern lobster, Maine lobster, Homarus americanus\",\n",
    "123: \"spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\",\n",
    "124: \"crayfish, crawfish, crawdad, crawdaddy\",\n",
    "125: \"hermit crab\",\n",
    "126: \"isopod\",\n",
    "127: \"white stork, Ciconia ciconia\",\n",
    "128: \"black stork, Ciconia nigra\",\n",
    "129: \"spoonbill\",\n",
    "130: \"flamingo\",\n",
    "131: \"little blue heron, Egretta caerulea\",\n",
    "132: \"American egret, great white heron, Egretta albus\",\n",
    "133: \"bittern\",\n",
    "134: \"crane, bird\",\n",
    "135: \"limpkin, Aramus pictus\",\n",
    "136: \"European gallinule, Porphyrio porphyrio\",\n",
    "137: \"American coot, marsh hen, mud hen, water hen, Fulica americana\",\n",
    "138: \"bustard\",\n",
    "139: \"ruddy turnstone, Arenaria interpres\",\n",
    "140: \"red-backed sandpiper, dunlin, Erolia alpina\",\n",
    "141: \"redshank, Tringa totanus\",\n",
    "142: \"dowitcher\",\n",
    "143: \"oystercatcher, oyster catcher\",\n",
    "144: \"pelican\",\n",
    "145: \"king penguin, Aptenodytes patagonica\",\n",
    "146: \"albatross, mollymawk\",\n",
    "147: \"grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius rostus',\",\n",
    "148: \"killer whale, killer, orca, grampus, sea wolf, Orcinus orca\",\n",
    "149: \"dugong, Dugong dugon\",\n",
    "150: \"sea lion\",\n",
    "151: \"Chihuahua\",\n",
    "152: \"Japanese spaniel\",\n",
    "153: \"Maltese dog, Maltese terrier, Maltese\",\n",
    "154: \"Pekinese, Pekingese, Peke\",\n",
    "155: \"Shih-Tzu\",\n",
    "156: \"Blenheim spaniel\",\n",
    "157: \"papillon\",\n",
    "158: \"toy terrier\",\n",
    "159: \"Rhodesian ridgeback\",\n",
    "160: \"Afghan hound, Afghan\",\n",
    "161: \"basset, basset hound\",\n",
    "162: \"beagle\",\n",
    "163: \"bloodhound, sleuthhound\",\n",
    "164: \"bluetick\",\n",
    "165: \"black-and-tan coonhound\",\n",
    "166: \"Walker hound, Walker foxhound\",\n",
    "167: \"English foxhound\",\n",
    "168: \"redbone\",\n",
    "169: \"borzoi, Russian wolfhound\",\n",
    "170: \"Irish wolfhound\",\n",
    "171: \"Italian greyhound\",\n",
    "172: \"whippet\",\n",
    "173: \"Ibizan hound, Ibizan Podenco\",\n",
    "174: \"Norwegian elkhound, elkhound\",\n",
    "175: \"otterhound, otter hound\",\n",
    "176: \"Saluki, gazelle hound\",\n",
    "177: \"Scottish deerhound, deerhound\",\n",
    "178: \"Weimaraner\",\n",
    "179: \"Staffordshire bullterrier, Staffordshire bull terrier\",\n",
    "180: \"American Staffordshire terrier, Staffordshire terrier, American pit bull rrier, pit bull terrier',\",\n",
    "181: \"Bedlington terrier\",\n",
    "182: \"Border terrier\",\n",
    "183: \"Kerry blue terrier\",\n",
    "184: \"Irish terrier\",\n",
    "185: \"Norfolk terrier\",\n",
    "186: \"Norwich terrier\",\n",
    "187: \"Yorkshire terrier\",\n",
    "188: \"wire-haired fox terrier\",\n",
    "189: \"Lakeland terrier\",\n",
    "190: \"Sealyham terrier, Sealyham\",\n",
    "191: \"Airedale, Airedale terrier\",\n",
    "192: \"cairn, cairn terrier\",\n",
    "193: \"Australian terrier\",\n",
    "194: \"Dandie Dinmont, Dandie Dinmont terrier\",\n",
    "195: \"Boston bull, Boston terrier\",\n",
    "196: \"miniature schnauzer\",\n",
    "197: \"giant schnauzer\",\n",
    "198: \"standard schnauzer\",\n",
    "199: \"Scotch terrier, Scottish terrier, Scottie\",\n",
    "200: \"Tibetan terrier, chrysanthemum dog\",\n",
    "201: \"silky terrier, Sydney silky\",\n",
    "202: \"soft-coated wheaten terrier\",\n",
    "203: \"West Highland white terrier\",\n",
    "204: \"Lhasa, Lhasa apso\",\n",
    "205: \"flat-coated retriever\",\n",
    "206: \"curly-coated retriever\",\n",
    "207: \"golden retriever\",\n",
    "208: \"Labrador retriever\",\n",
    "209: \"Chesapeake Bay retriever\",\n",
    "210: \"German short-haired pointer\",\n",
    "211: \"vizsla, Hungarian pointer\",\n",
    "212: \"English setter\",\n",
    "213: \"Irish setter, red setter\",\n",
    "214: \"Gordon setter\",\n",
    "215: \"Brittany spaniel\",\n",
    "216: \"clumber, clumber spaniel\",\n",
    "217: \"English springer, English springer spaniel\",\n",
    "218: \"Welsh springer spaniel\",\n",
    "219: \"cocker spaniel, English cocker spaniel, cocker\",\n",
    "220: \"Sussex spaniel\",\n",
    "221: \"Irish water spaniel\",\n",
    "222: \"kuvasz\",\n",
    "223: \"schipperke\",\n",
    "224: \"groenendael\",\n",
    "225: \"malinois\",\n",
    "226: \"briard\",\n",
    "227: \"kelpie\",\n",
    "228: \"komondor\",\n",
    "229: \"Old English sheepdog, bobtail\",\n",
    "230: \"Shetland sheepdog, Shetland sheep dog, Shetland\",\n",
    "231: \"collie\",\n",
    "232: \"Border collie\",\n",
    "233: \"Bouvier des Flandres, Bouviers des Flandres\",\n",
    "234: \"Rottweiler\",\n",
    "235: \"German shepherd, German shepherd dog, German police dog, alsatian\",\n",
    "236: \"Doberman, Doberman pinscher\",\n",
    "237: \"miniature pinscher\",\n",
    "238: \"Greater Swiss Mountain dog\",\n",
    "239: \"Bernese mountain dog\",\n",
    "240: \"Appenzeller\",\n",
    "241: \"EntleBucher\",\n",
    "242: \"boxer\",\n",
    "243: \"bull mastiff\",\n",
    "244: \"Tibetan mastiff\",\n",
    "245: \"French bulldog\",\n",
    "246: \"Great Dane\",\n",
    "247: \"Saint Bernard, St Bernard\",\n",
    "248: \"Eskimo dog, husky\",\n",
    "249: \"malamute, malemute, Alaskan malamute\",\n",
    "250: \"Siberian husky\",\n",
    "251: \"dalmatian, coach dog, carriage dog\",\n",
    "252: \"affenpinscher, monkey pinscher, monkey dog\",\n",
    "253: \"basenji\",\n",
    "254: \"pug, pug-dog\",\n",
    "255: \"Leonberg\",\n",
    "256: \"Newfoundland, Newfoundland dog\",\n",
    "257: \"Great Pyrenees\",\n",
    "258: \"Samoyed, Samoyede\",\n",
    "259: \"Pomeranian\",\n",
    "260: \"chow, chow chow\",\n",
    "261: \"keeshond\",\n",
    "262: \"Brabancon griffon\",\n",
    "263: \"Pembroke, Pembroke Welsh corgi\",\n",
    "264: \"Cardigan, Cardigan Welsh corgi\",\n",
    "265: \"toy poodle\",\n",
    "266: \"miniature poodle\",\n",
    "267: \"standard poodle\",\n",
    "268: \"Mexican hairless\",\n",
    "269: \"timber wolf, grey wolf, gray wolf, Canis lupus\",\n",
    "270: \"white wolf, Arctic wolf, Canis lupus tundrarum\",\n",
    "271: \"red wolf, maned wolf, Canis rufus, Canis niger\",\n",
    "272: \"coyote, prairie wolf, brush wolf, Canis latrans\",\n",
    "273: \"dingo, warrigal, warragal, Canis dingo\",\n",
    "274: \"dhole, Cuon alpinus\",\n",
    "275: \"African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus\",\n",
    "276: \"hyena, hyaena\",\n",
    "277: \"red fox, Vulpes vulpes\",\n",
    "278: \"kit fox, Vulpes macrotis\",\n",
    "279: \"Arctic fox, white fox, Alopex lagopus\",\n",
    "280: \"grey fox, gray fox, Urocyon cinereoargenteus\",\n",
    "281: \"tabby, tabby cat\",\n",
    "282: \"tiger cat\",\n",
    "283: \"Persian cat\",\n",
    "284: \"Siamese cat, Siamese\",\n",
    "285: \"Egyptian cat\",\n",
    "286: \"cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\",\n",
    "287: \"lynx, catamount\",\n",
    "288: \"leopard, Panthera pardus\",\n",
    "289: \"snow leopard, ounce, Panthera uncia\",\n",
    "290: \"jaguar, panther, Panthera onca, Felis onca\",\n",
    "291: \"lion, king of beasts, Panthera leo\",\n",
    "292: \"tiger, Panthera tigris\",\n",
    "293: \"cheetah, chetah, Acinonyx jubatus\",\n",
    "294: \"brown bear, bruin, Ursus arctos\",\n",
    "295: \"American black bear, black bear, Ursus americanus, Euarctos americanus\",\n",
    "296: \"ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus\",\n",
    "297: \"sloth bear, Melursus ursinus, Ursus ursinus\",\n",
    "298: \"mongoose\",\n",
    "299: \"meerkat, mierkat\",\n",
    "300: \"tiger beetle\",\n",
    "301: \"ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\",\n",
    "302: \"ground beetle, carabid beetle\",\n",
    "303: \"long-horned beetle, longicorn, longicorn beetle\",\n",
    "304: \"leaf beetle, chrysomelid\",\n",
    "305: \"dung beetle\",\n",
    "306: \"rhinoceros beetle\",\n",
    "307: \"weevil\",\n",
    "308: \"fly\",\n",
    "309: \"bee\",\n",
    "310: \"ant, emmet, pismire\",\n",
    "311: \"grasshopper, hopper\",\n",
    "312: \"cricket\",\n",
    "313: \"walking stick, walkingstick, stick insect\",\n",
    "314: \"cockroach, roach\",\n",
    "315: \"mantis, mantid\",\n",
    "316: \"cicada, cicala\",\n",
    "317: \"leafhopper\",\n",
    "318: \"lacewing, lacewing fly\",\n",
    "319: \"dragonfly, darning needle, devil's darning needle, sewing needle, snake fder, snake doctor, mosquito hawk, skeeter hawk\",\n",
    "320: \"damselfly\",\n",
    "321: \"admiral\",\n",
    "322: \"ringlet, ringlet butterfly\",\n",
    "323: \"monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\",\n",
    "324: \"cabbage butterfly\",\n",
    "325: \"sulphur butterfly, sulfur butterfly\",\n",
    "326: \"lycaenid, lycaenid butterfly\",\n",
    "327: \"starfish, sea star\",\n",
    "328: \"sea urchin\",\n",
    "329: \"sea cucumber, holothurian\",\n",
    "330: \"wood rabbit, cottontail, cottontail rabbit\",\n",
    "331: \"hare\",\n",
    "332: \"Angora, Angora rabbit\",\n",
    "333: \"hamster\",\n",
    "334: \"porcupine, hedgehog\",\n",
    "335: \"fox squirrel, eastern fox squirrel, Sciurus niger\",\n",
    "336: \"marmot\",\n",
    "337: \"beaver\",\n",
    "338: \"guinea pig, Cavia cobaya\",\n",
    "339: \"sorrel\",\n",
    "340: \"zebra\",\n",
    "341: \"hog, pig, grunter, squealer, Sus scrofa\",\n",
    "342: \"wild boar, boar, Sus scrofa\",\n",
    "343: \"warthog\",\n",
    "344: \"hippopotamus, hippo, river horse, Hippopotamus amphibius\",\n",
    "345: \"ox\",\n",
    "346: \"water buffalo, water ox, Asiatic buffalo, Bubalus bubalis\",\n",
    "347: \"bison\",\n",
    "348: \"ram, tup\",\n",
    "349: \"bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain eep, Ovis canadensis',\",\n",
    "350: \"ibex, Capra ibex\",\n",
    "351: \"hartebeest\",\n",
    "352: \"impala, Aepyceros melampus\",\n",
    "353: \"gazelle\",\n",
    "354: \"Arabian camel, dromedary, Camelus dromedarius\",\n",
    "355: \"llama\",\n",
    "356: \"weasel\",\n",
    "357: \"mink\",\n",
    "358: \"polecat, fitch, foulmart, foumart, Mustela putorius\",\n",
    "359: \"black-footed ferret, ferret, Mustela nigripes\",\n",
    "360: \"otter\",\n",
    "361: \"skunk, polecat, wood pussy\",\n",
    "362: \"badger\",\n",
    "363: \"armadillo\",\n",
    "364: \"three-toed sloth, ai, Bradypus tridactylus\",\n",
    "365: \"orangutan, orang, orangutang, Pongo pygmaeus\",\n",
    "366: \"gorilla, Gorilla gorilla\",\n",
    "367: \"chimpanzee, chimp, Pan troglodytes\",\n",
    "368: \"gibbon, Hylobates lar\",\n",
    "369: \"siamang, Hylobates syndactylus, Symphalangus syndactylus\",\n",
    "370: \"guenon, guenon monkey\",\n",
    "371: \"patas, hussar monkey, Erythrocebus patas\",\n",
    "372: \"baboon\",\n",
    "373: \"macaque\",\n",
    "374: \"langur\",\n",
    "375: \"colobus, colobus monkey\",\n",
    "376: \"proboscis monkey, Nasalis larvatus\",\n",
    "377: \"marmoset\",\n",
    "378: \"capuchin, ringtail, Cebus capucinus\",\n",
    "379: \"howler monkey, howler\",\n",
    "380: \"titi, titi monkey\",\n",
    "381: \"spider monkey, Ateles geoffroyi\",\n",
    "382: \"squirrel monkey, Saimiri sciureus\",\n",
    "383: \"Madagascar cat, ring-tailed lemur, Lemur catta\",\n",
    "384: \"indri, indris, Indri indri, Indri brevicaudatus\",\n",
    "385: \"Indian elephant, Elephas maximus\",\n",
    "386: \"African elephant, Loxodonta africana\",\n",
    "387: \"lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\",\n",
    "388: \"giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\",\n",
    "389: \"barracouta, snoek\",\n",
    "390: \"eel\",\n",
    "391: \"coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch\",\n",
    "392: \"rock beauty, Holocanthus tricolor\",\n",
    "393: \"anemone fish\",\n",
    "394: \"sturgeon\",\n",
    "395: \"gar, garfish, garpike, billfish, Lepisosteus osseus\",\n",
    "396: \"lionfish\",\n",
    "397: \"puffer, pufferfish, blowfish, globefish\",\n",
    "398: \"abacus\",\n",
    "399: \"abaya\",\n",
    "400: \"academic gown, academic robe, judge's robe\",\n",
    "401: \"accordion, piano accordion, squeeze box\",\n",
    "402: \"acoustic guitar\",\n",
    "403: \"aircraft carrier, carrier, flattop, attack aircraft carrier\",\n",
    "404: \"airliner\",\n",
    "405: \"airship, dirigible\",\n",
    "406: \"altar\",\n",
    "407: \"ambulance\",\n",
    "408: \"amphibian, amphibious vehicle\",\n",
    "409: \"analog clock\",\n",
    "410: \"apiary, bee house\",\n",
    "411: \"apron\",\n",
    "412: \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustb, trash barrel, trash bin',\",\n",
    "413: \"assault rifle, assault gun\",\n",
    "414: \"backpack, back pack, knapsack, packsack, rucksack, haversack\",\n",
    "415: \"bakery, bakeshop, bakehouse\",\n",
    "416: \"balance beam, beam\",\n",
    "417: \"balloon\",\n",
    "418: \"ballpoint, ballpoint pen, ballpen, Biro\",\n",
    "419: \"Band Aid\",\n",
    "420: \"banjo\",\n",
    "421: \"bannister, banister, balustrade, balusters, handrail\",\n",
    "422: \"barbell\",\n",
    "423: \"barber chair\",\n",
    "424: \"barbershop\",\n",
    "425: \"barn\",\n",
    "426: \"barometer\",\n",
    "427: \"barrel, cask\",\n",
    "428: \"barrow, garden cart, lawn cart, wheelbarrow\",\n",
    "429: \"baseball\",\n",
    "430: \"basketball\",\n",
    "431: \"bassinet\",\n",
    "432: \"bassoon\",\n",
    "433: \"bathing cap, swimming cap\",\n",
    "434: \"bath towel\",\n",
    "435: \"bathtub, bathing tub, bath, tub\",\n",
    "436: \"beach wagon, station wagon, wagon, estate car, beach waggon, station wagg, waggon',\",\n",
    "437: \"beacon, lighthouse, beacon light, pharos\",\n",
    "438: \"beaker\",\n",
    "439: \"bearskin, busby, shako\",\n",
    "440: \"beer bottle\",\n",
    "441: \"beer glass\",\n",
    "442: \"bell cote, bell cot\",\n",
    "443: \"bib\",\n",
    "444: \"bicycle-built-for-two, tandem bicycle, tandem\",\n",
    "445: \"bikini, two-piece\",\n",
    "446: \"binder, ring-binder\",\n",
    "447: \"binoculars, field glasses, opera glasses\",\n",
    "448: \"birdhouse\",\n",
    "449: \"boathouse\",\n",
    "450: \"bobsled, bobsleigh, bob\",\n",
    "451: \"bolo tie, bolo, bola tie, bola\",\n",
    "452: \"bonnet, poke bonnet\",\n",
    "453: \"bookcase\",\n",
    "454: \"bookshop, bookstore, bookstall\",\n",
    "455: \"bottlecap\",\n",
    "456: \"bow\",\n",
    "457: \"bow tie, bow-tie, bowtie\",\n",
    "458: \"brass, memorial tablet, plaque\",\n",
    "459: \"brassiere, bra, bandeau\",\n",
    "460: \"breakwater, groin, groyne, mole, bulwark, seawall, jetty\",\n",
    "461: \"breastplate, aegis, egis\",\n",
    "462: \"broom\",\n",
    "463: \"bucket, pail\",\n",
    "464: \"buckle\",\n",
    "465: \"bulletproof vest\",\n",
    "466: \"bullet train, bullet\",\n",
    "467: \"butcher shop, meat market\",\n",
    "468: \"cab, hack, taxi, taxicab\",\n",
    "469: \"caldron, cauldron\",\n",
    "470: \"candle, taper, wax light\",\n",
    "471: \"cannon\",\n",
    "472: \"canoe\",\n",
    "473: \"can opener, tin opener\",\n",
    "474: \"cardigan\",\n",
    "475: \"car mirror\",\n",
    "476: \"carousel, carrousel, merry-go-round, roundabout, whirligig\",\n",
    "477: \"carpenter's kit, tool kit\",\n",
    "478: \"carton\",\n",
    "479: \"car wheel\",\n",
    "480: \"cash machine, cash dispenser, automated teller machine, automatic teller chine, automated teller, automatic teller, ATM',\",\n",
    "481: \"cassette\",\n",
    "482: \"cassette player\",\n",
    "483: \"castle\",\n",
    "484: \"catamaran\",\n",
    "485: \"CD player\",\n",
    "486: \"cello, violoncello\",\n",
    "487: \"cellular telephone, cellular phone, cellphone, cell, mobile phone\",\n",
    "488: \"chain\",\n",
    "489: \"chainlink fence\",\n",
    "490: \"chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring mour',\",\n",
    "491: \"chain saw, chainsaw\",\n",
    "492: \"chest\",\n",
    "493: \"chiffonier, commode\",\n",
    "494: \"chime, bell, gong\",\n",
    "495: \"china cabinet, china closet\",\n",
    "496: \"Christmas stocking\",\n",
    "497: \"church, church building\",\n",
    "498: \"cinema, movie theater, movie theatre, movie house, picture palace\",\n",
    "499: \"cleaver, meat cleaver, chopper\",\n",
    "500: \"cliff dwelling\",\n",
    "501: \"cloak\",\n",
    "502: \"clog, geta, patten, sabot\",\n",
    "503: \"cocktail shaker\",\n",
    "504: \"coffee mug\",\n",
    "505: \"coffeepot\",\n",
    "506: \"coil, spiral, volute, whorl, helix\",\n",
    "507: \"combination lock\",\n",
    "508: \"computer keyboard, keypad\",\n",
    "509: \"confectionery, confectionary, candy store\",\n",
    "510: \"container ship, containership, container vessel\",\n",
    "511: \"convertible\",\n",
    "512: \"corkscrew, bottle screw\",\n",
    "513: \"cornet, horn, trumpet, trump\",\n",
    "514: \"cowboy boot\",\n",
    "515: \"cowboy hat, ten-gallon hat\",\n",
    "516: \"cradle\",\n",
    "517: \"crane\",\n",
    "518: \"crash helmet\",\n",
    "519: \"crate\",\n",
    "520: \"crib, cot\",\n",
    "521: \"Crock Pot\",\n",
    "522: \"croquet ball\",\n",
    "523: \"crutch\",\n",
    "524: \"cuirass\",\n",
    "525: \"dam, dike, dyke\",\n",
    "526: \"desk\",\n",
    "527: \"desktop computer\",\n",
    "528: \"dial telephone, dial phone\",\n",
    "529: \"diaper, nappy, napkin\",\n",
    "530: \"digital clock\",\n",
    "531: \"digital watch\",\n",
    "532: \"dining table, board\",\n",
    "533: \"dishrag, dishcloth\",\n",
    "534: \"dishwasher, dish washer, dishwashing machine\",\n",
    "535: \"disk brake, disc brake\",\n",
    "536: \"dock, dockage, docking facility\",\n",
    "537: \"dogsled, dog sled, dog sleigh\",\n",
    "538: \"dome\",\n",
    "539: \"doormat, welcome mat\",\n",
    "540: \"drilling platform, offshore rig\",\n",
    "541: \"drum, membranophone, tympan\",\n",
    "542: \"drumstick\",\n",
    "543: \"dumbbell\",\n",
    "544: \"Dutch oven\",\n",
    "545: \"electric fan, blower\",\n",
    "546: \"electric guitar\",\n",
    "547: \"electric locomotive\",\n",
    "548: \"entertainment center\",\n",
    "549: \"envelope\",\n",
    "550: \"espresso maker\",\n",
    "551: \"face powder\",\n",
    "552: \"feather boa, boa\",\n",
    "553: \"file, file cabinet, filing cabinet\",\n",
    "554: \"fireboat\",\n",
    "555: \"fire engine, fire truck\",\n",
    "556: \"fire screen, fireguard\",\n",
    "557: \"flagpole, flagstaff\",\n",
    "558: \"flute, transverse flute\",\n",
    "559: \"folding chair\",\n",
    "560: \"football helmet\",\n",
    "561: \"forklift\",\n",
    "562: \"fountain\",\n",
    "563: \"fountain pen\",\n",
    "564: \"four-poster\",\n",
    "565: \"freight car\",\n",
    "566: \"French horn, horn\",\n",
    "567: \"frying pan, frypan, skillet\",\n",
    "568: \"fur coat\",\n",
    "569: \"garbage truck, dustcart\",\n",
    "570: \"gasmask, respirator, gas helmet\",\n",
    "571: \"gas pump, gasoline pump, petrol pump, island dispenser\",\n",
    "572: \"goblet\",\n",
    "573: \"go-kart\",\n",
    "574: \"golf ball\",\n",
    "575: \"golfcart, golf cart\",\n",
    "576: \"gondola\",\n",
    "577: \"gong, tam-tam\",\n",
    "578: \"gown\",\n",
    "579: \"grand piano, grand\",\n",
    "580: \"greenhouse, nursery, glasshouse\",\n",
    "581: \"grille, radiator grille\",\n",
    "582: \"grocery store, grocery, food market, market\",\n",
    "583: \"guillotine\",\n",
    "584: \"hair slide\",\n",
    "585: \"hair spray\",\n",
    "586: \"half track\",\n",
    "587: \"hammer\",\n",
    "588: \"hamper\",\n",
    "589: \"hand blower, blow dryer, blow drier, hair dryer, hair drier\",\n",
    "590: \"hand-held computer, hand-held microcomputer\",\n",
    "591: \"handkerchief, hankie, hanky, hankey\",\n",
    "592: \"hard disc, hard disk, fixed disk\",\n",
    "593: \"harmonica, mouth organ, harp, mouth harp\",\n",
    "594: \"harp\",\n",
    "595: \"harvester, reaper\",\n",
    "596: \"hatchet\",\n",
    "597: \"holster\",\n",
    "598: \"home theater, home theatre\",\n",
    "599: \"honeycomb\",\n",
    "600: \"hook, claw\",\n",
    "601: \"hoopskirt, crinoline\",\n",
    "602: \"horizontal bar, high bar\",\n",
    "603: \"horse cart, horse-cart\",\n",
    "604: \"hourglass\",\n",
    "605: \"iPod\",\n",
    "606: \"iron, smoothing iron\",\n",
    "607: \"jack-o'-lantern\",\n",
    "608: \"jean, blue jean, denim\",\n",
    "609: \"jeep, landrover\",\n",
    "610: \"jersey, T-shirt, tee shirt\",\n",
    "611: \"jigsaw puzzle\",\n",
    "612: \"jinrikisha, ricksha, rickshaw\",\n",
    "613: \"joystick\",\n",
    "614: \"kimono\",\n",
    "615: \"knee pad\",\n",
    "616: \"knot\",\n",
    "617: \"lab coat, laboratory coat\",\n",
    "618: \"ladle\",\n",
    "619: \"lampshade, lamp shade\",\n",
    "620: \"laptop, laptop computer\",\n",
    "621: \"lawn mower, mower\",\n",
    "622: \"lens cap, lens cover\",\n",
    "623: \"letter opener, paper knife, paperknife\",\n",
    "624: \"library\",\n",
    "625: \"lifeboat\",\n",
    "626: \"lighter, light, igniter, ignitor\",\n",
    "627: \"limousine, limo\",\n",
    "628: \"liner, ocean liner\",\n",
    "629: \"lipstick, lip rouge\",\n",
    "630: \"Loafer\",\n",
    "631: \"lotion\",\n",
    "632: \"loudspeaker, speaker, speaker unit, loudspeaker system, speaker system\",\n",
    "633: \"loupe, jeweler's loupe\",\n",
    "634: \"lumbermill, sawmill\",\n",
    "635: \"magnetic compass\",\n",
    "636: \"mailbag, postbag\",\n",
    "637: \"mailbox, letter box\",\n",
    "638: \"maillot\",\n",
    "639: \"maillot, tank suit\",\n",
    "640: \"manhole cover\",\n",
    "641: \"maraca\",\n",
    "642: \"marimba, xylophone\",\n",
    "643: \"mask\",\n",
    "644: \"matchstick\",\n",
    "645: \"maypole\",\n",
    "646: \"maze, labyrinth\",\n",
    "647: \"measuring cup\",\n",
    "648: \"medicine chest, medicine cabinet\",\n",
    "649: \"megalith, megalithic structure\",\n",
    "650: \"microphone, mike\",\n",
    "651: \"microwave, microwave oven\",\n",
    "652: \"military uniform\",\n",
    "653: \"milk can\",\n",
    "654: \"minibus\",\n",
    "655: \"miniskirt, mini\",\n",
    "656: \"minivan\",\n",
    "657: \"missile\",\n",
    "658: \"mitten\",\n",
    "659: \"mixing bowl\",\n",
    "660: \"mobile home, manufactured home\",\n",
    "661: \"Model T\",\n",
    "662: \"modem\",\n",
    "663: \"monastery\",\n",
    "664: \"monitor\",\n",
    "665: \"moped\",\n",
    "666: \"mortar\",\n",
    "667: \"mortarboard\",\n",
    "668: \"mosque\",\n",
    "669: \"mosquito net\",\n",
    "670: \"motor scooter, scooter\",\n",
    "671: \"mountain bike, all-terrain bike, off-roader\",\n",
    "672: \"mountain tent\",\n",
    "673: \"mouse, computer mouse\",\n",
    "674: \"mousetrap\",\n",
    "675: \"moving van\",\n",
    "676: \"muzzle\",\n",
    "677: \"nail\",\n",
    "678: \"neck brace\",\n",
    "679: \"necklace\",\n",
    "680: \"nipple\",\n",
    "681: \"notebook, notebook computer\",\n",
    "682: \"obelisk\",\n",
    "683: \"oboe, hautboy, hautbois\",\n",
    "684: \"ocarina, sweet potato\",\n",
    "685: \"odometer, hodometer, mileometer, milometer\",\n",
    "686: \"oil filter\",\n",
    "687: \"organ, pipe organ\",\n",
    "688: \"oscilloscope, scope, cathode-ray oscilloscope, CRO\",\n",
    "689: \"overskirt\",\n",
    "690: \"oxcart\",\n",
    "691: \"oxygen mask\",\n",
    "692: \"packet\",\n",
    "693: \"paddle, boat paddle\",\n",
    "694: \"paddlewheel, paddle wheel\",\n",
    "695: \"padlock\",\n",
    "696: \"paintbrush\",\n",
    "697: \"pajama, pyjama, pj's, jammies\",\n",
    "698: \"palace\",\n",
    "699: \"panpipe, pandean pipe, syrinx\",\n",
    "700: \"paper towel\",\n",
    "701: \"parachute, chute\",\n",
    "702: \"parallel bars, bars\",\n",
    "703: \"park bench\",\n",
    "704: \"parking meter\",\n",
    "705: \"passenger car, coach, carriage\",\n",
    "706: \"patio, terrace\",\n",
    "707: \"pay-phone, pay-station\",\n",
    "708: \"pedestal, plinth, footstall\",\n",
    "709: \"pencil box, pencil case\",\n",
    "710: \"pencil sharpener\",\n",
    "711: \"perfume, essence\",\n",
    "712: \"Petri dish\",\n",
    "713: \"photocopier\",\n",
    "714: \"pick, plectrum, plectron\",\n",
    "715: \"pickelhaube\",\n",
    "716: \"picket fence, paling\",\n",
    "717: \"pickup, pickup truck\",\n",
    "718: \"pier\",\n",
    "719: \"piggy bank, penny bank\",\n",
    "720: \"pill bottle\",\n",
    "721: \"pillow\",\n",
    "722: \"ping-pong ball\",\n",
    "723: \"pinwheel\",\n",
    "724: \"pirate, pirate ship\",\n",
    "725: \"pitcher, ewer\",\n",
    "726: \"plane, carpenter's plane, woodworking plane\",\n",
    "727: \"planetarium\",\n",
    "728: \"plastic bag\",\n",
    "729: \"plate rack\",\n",
    "730: \"plow, plough\",\n",
    "731: \"plunger, plumber's helper\",\n",
    "732: \"Polaroid camera, Polaroid Land camera\",\n",
    "733: \"pole\",\n",
    "734: \"police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\",\n",
    "735: \"poncho\",\n",
    "736: \"pool table, billiard table, snooker table\",\n",
    "737: \"pop bottle, soda bottle\",\n",
    "738: \"pot, flowerpot\",\n",
    "739: \"potter's wheel\",\n",
    "740: \"power drill\",\n",
    "741: \"prayer rug, prayer mat\",\n",
    "742: \"printer\",\n",
    "743: \"prison, prison house\",\n",
    "744: \"projectile, missile\",\n",
    "745: \"projector\",\n",
    "746: \"puck, hockey puck\",\n",
    "747: \"punching bag, punch bag, punching ball, punchball\",\n",
    "748: \"purse\",\n",
    "749: \"quill, quill pen\",\n",
    "750: \"quilt, comforter, comfort, puff\",\n",
    "751: \"racer, race car, racing car\",\n",
    "752: \"racket, racquet\",\n",
    "753: \"radiator\",\n",
    "754: \"radio, wireless\",\n",
    "755: \"radio telescope, radio reflector\",\n",
    "756: \"rain barrel\",\n",
    "757: \"recreational vehicle, RV, R.V.\",\n",
    "758: \"reel\",\n",
    "759: \"reflex camera\",\n",
    "760: \"refrigerator, icebox\",\n",
    "761: \"remote control, remote\",\n",
    "762: \"restaurant, eating house, eating place, eatery\",\n",
    "763: \"revolver, six-gun, six-shooter\",\n",
    "764: \"rifle\",\n",
    "765: \"rocking chair, rocker\",\n",
    "766: \"rotisserie\",\n",
    "767: \"rubber eraser, rubber, pencil eraser\",\n",
    "768: \"rugby ball\",\n",
    "769: \"rule, ruler\",\n",
    "770: \"running shoe\",\n",
    "771: \"safe\",\n",
    "772: \"safety pin\",\n",
    "773: \"saltshaker, salt shaker\",\n",
    "774: \"sandal\",\n",
    "775: \"sarong\",\n",
    "776: \"sax, saxophone\",\n",
    "777: \"scabbard\",\n",
    "778: \"scale, weighing machine\",\n",
    "779: \"school bus\",\n",
    "780: \"schooner\",\n",
    "781: \"scoreboard\",\n",
    "782: \"screen, CRT screen\",\n",
    "783: \"screw\",\n",
    "784: \"screwdriver\",\n",
    "785: \"seat belt, seatbelt\",\n",
    "786: \"sewing machine\",\n",
    "787: \"shield, buckler\",\n",
    "788: \"shoe shop, shoe-shop, shoe store\",\n",
    "789: \"shoji\",\n",
    "790: \"shopping basket\",\n",
    "791: \"shopping cart\",\n",
    "792: \"shovel\",\n",
    "793: \"shower cap\",\n",
    "794: \"shower curtain\",\n",
    "795: \"ski\",\n",
    "796: \"ski mask\",\n",
    "797: \"sleeping bag\",\n",
    "798: \"slide rule, slipstick\",\n",
    "799: \"sliding door\",\n",
    "800: \"slot, one-armed bandit\",\n",
    "801: \"snorkel\",\n",
    "802: \"snowmobile\",\n",
    "803: \"snowplow, snowplough\",\n",
    "804: \"soap dispenser\",\n",
    "805: \"soccer ball\",\n",
    "806: \"sock\",\n",
    "807: \"solar dish, solar collector, solar furnace\",\n",
    "808: \"sombrero\",\n",
    "809: \"soup bowl\",\n",
    "810: \"space bar\",\n",
    "811: \"space heater\",\n",
    "812: \"space shuttle\",\n",
    "813: \"spatula\",\n",
    "814: \"speedboat\",\n",
    "815: \"spider web, spider's web\",\n",
    "816: \"spindle\",\n",
    "817: \"sports car, sport car\",\n",
    "818: \"spotlight, spot\",\n",
    "819: \"stage\",\n",
    "820: \"steam locomotive\",\n",
    "821: \"steel arch bridge\",\n",
    "822: \"steel drum\",\n",
    "823: \"stethoscope\",\n",
    "824: \"stole\",\n",
    "825: \"stone wall\",\n",
    "826: \"stopwatch, stop watch\",\n",
    "827: \"stove\",\n",
    "828: \"strainer\",\n",
    "829: \"streetcar, tram, tramcar, trolley, trolley car\",\n",
    "830: \"stretcher\",\n",
    "831: \"studio couch, day bed\",\n",
    "832: \"stupa, tope\",\n",
    "833: \"submarine, pigboat, sub, U-boat\",\n",
    "834: \"suit, suit of clothes\",\n",
    "835: \"sundial\",\n",
    "836: \"sunglass\",\n",
    "837: \"sunglasses, dark glasses, shades\",\n",
    "838: \"sunscreen, sunblock, sun blocker\",\n",
    "839: \"suspension bridge\",\n",
    "840: \"swab, swob, mop\",\n",
    "841: \"sweatshirt\",\n",
    "842: \"swimming trunks, bathing trunks\",\n",
    "843: \"swing\",\n",
    "844: \"switch, electric switch, electrical switch\",\n",
    "845: \"syringe\",\n",
    "846: \"table lamp\",\n",
    "847: \"tank, army tank, armored combat vehicle, armoured combat vehicle\",\n",
    "848: \"tape player\",\n",
    "849: \"teapot\",\n",
    "850: \"teddy, teddy bear\",\n",
    "851: \"television, television system\",\n",
    "852: \"tennis ball\",\n",
    "853: \"thatch, thatched roof\",\n",
    "854: \"theater curtain, theatre curtain\",\n",
    "855: \"thimble\",\n",
    "856: \"thresher, thrasher, threshing machine\",\n",
    "857: \"throne\",\n",
    "858: \"tile roof\",\n",
    "859: \"toaster\",\n",
    "860: \"tobacco shop, tobacconist shop, tobacconist\",\n",
    "861: \"toilet seat\",\n",
    "862: \"torch\",\n",
    "863: \"totem pole\",\n",
    "864: \"tow truck, tow car, wrecker\",\n",
    "865: \"toyshop\",\n",
    "866: \"tractor\",\n",
    "867: \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, sem,\",\n",
    "868: \"tray\",\n",
    "869: \"trench coat\",\n",
    "870: \"tricycle, trike, velocipede\",\n",
    "871: \"trimaran\",\n",
    "872: \"tripod\",\n",
    "873: \"triumphal arch\",\n",
    "874: \"trolleybus, trolley coach, trackless trolley\",\n",
    "875: \"trombone\",\n",
    "876: \"tub, vat\",\n",
    "877: \"turnstile\",\n",
    "878: \"typewriter keyboard\",\n",
    "879: \"umbrella\",\n",
    "880: \"unicycle, monocycle\",\n",
    "881: \"upright, upright piano\",\n",
    "882: \"vacuum, vacuum cleaner\",\n",
    "883: \"vase\",\n",
    "884: \"vault\",\n",
    "885: \"velvet\",\n",
    "886: \"vending machine\",\n",
    "887: \"vestment\",\n",
    "888: \"viaduct\",\n",
    "889: \"violin, fiddle\",\n",
    "890: \"volleyball\",\n",
    "891: \"waffle iron\",\n",
    "892: \"wall clock\",\n",
    "893: \"wallet, billfold, notecase, pocketbook\",\n",
    "894: \"wardrobe, closet, press\",\n",
    "895: \"warplane, military plane\",\n",
    "896: \"washbasin, handbasin, washbowl, lavabo, wash-hand basin\",\n",
    "897: \"washer, automatic washer, washing machine\",\n",
    "898: \"water bottle\",\n",
    "899: \"water jug\",\n",
    "900: \"water tower\",\n",
    "901: \"whiskey jug\",\n",
    "902: \"whistle\",\n",
    "903: \"wig\",\n",
    "904: \"window screen\",\n",
    "905: \"window shade\",\n",
    "906: \"Windsor tie\",\n",
    "907: \"wine bottle\",\n",
    "908: \"wing\",\n",
    "909: \"wok\",\n",
    "910: \"wooden spoon\",\n",
    "911: \"wool, woolen, woollen\",\n",
    "912: \"worm fence, snake fence, snake-rail fence, Virginia fence\",\n",
    "913: \"wreck\",\n",
    "914: \"yawl\",\n",
    "915: \"yurt\",\n",
    "916: \"web site, website, internet site, site\",\n",
    "917: \"comic book\",\n",
    "918: \"crossword puzzle, crossword\",\n",
    "919: \"street sign\",\n",
    "920: \"traffic light, traffic signal, stoplight\",\n",
    "921: \"book jacket, dust cover, dust jacket, dust wrapper\",\n",
    "922: \"menu\",\n",
    "923: \"plate\",\n",
    "924: \"guacamole\",\n",
    "925: \"consomme\",\n",
    "926: \"hot pot, hotpot\",\n",
    "927: \"trifle\",\n",
    "928: \"ice cream, icecream\",\n",
    "929: \"ice lolly, lolly, lollipop, popsicle\",\n",
    "930: \"French loaf\",\n",
    "931: \"bagel, beigel\",\n",
    "932: \"pretzel\",\n",
    "933: \"cheeseburger\",\n",
    "934: \"hotdog, hot dog, red hot\",\n",
    "935: \"mashed potato\",\n",
    "936: \"head cabbage\",\n",
    "937: \"broccoli\",\n",
    "938: \"cauliflower\",\n",
    "939: \"zucchini, courgette\",\n",
    "940: \"spaghetti squash\",\n",
    "941: \"acorn squash\",\n",
    "942: \"butternut squash\",\n",
    "943: \"cucumber, cuke\",\n",
    "944: \"artichoke, globe artichoke\",\n",
    "945: \"bell pepper\",\n",
    "946: \"cardoon\",\n",
    "947: \"mushroom\",\n",
    "948: \"Granny Smith\",\n",
    "949: \"strawberry\",\n",
    "950: \"orange\",\n",
    "951: \"lemon\",\n",
    "952: \"fig\",\n",
    "953: \"pineapple, ananas\",\n",
    "954: \"banana\",\n",
    "955: \"jackfruit, jak, jack\",\n",
    "956: \"custard apple\",\n",
    "957: \"pomegranate\",\n",
    "958: \"hay\",\n",
    "959: \"carbonara\",\n",
    "960: \"chocolate sauce, chocolate syrup\",\n",
    "961: \"dough\",\n",
    "962: \"meat loaf, meatloaf\",\n",
    "963: \"pizza, pizza pie\",\n",
    "964: \"potpie\",\n",
    "965: \"burrito\",\n",
    "966: \"red wine\",\n",
    "967: \"espresso\",\n",
    "968: \"cup\",\n",
    "969: \"eggnog\",\n",
    "970: \"alp\",\n",
    "971: \"bubble\",\n",
    "972: \"cliff, drop, drop-off\",\n",
    "973: \"coral reef\",\n",
    "974: \"geyser\",\n",
    "975: \"lakeside, lakeshore\",\n",
    "976: \"promontory, headland, head, foreland\",\n",
    "977: \"sandbar, sand bar\",\n",
    "978: \"seashore, coast, seacoast, sea-coast\",\n",
    "979: \"valley, vale\",\n",
    "980: \"volcano\",\n",
    "981: \"ballplayer, baseball player\",\n",
    "982: \"groom, bridegroom\",\n",
    "983: \"scuba diver\",\n",
    "984: \"rapeseed\",\n",
    "985: \"daisy\",\n",
    "986: \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripium parviflorum\",\n",
    "987: \"corn\",\n",
    "988: \"acorn\",\n",
    "989: \"hip, rose hip, rosehip\",\n",
    "990: \"buckeye, horse chestnut, conker\",\n",
    "991: \"coral fungus\",\n",
    "992: \"agaric\",\n",
    "993: \"gyromitra\",\n",
    "994: \"stinkhorn, carrion fungus\",\n",
    "995: \"earthstar\",\n",
    "996: \"hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\",\n",
    "997: \"bolete\",\n",
    "998: \"ear, spike, capitulum\",\n",
    "999: \"toilet tissue, toilet paper, bathroom tissue\",\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:45:24.583907482Z",
     "start_time": "2024-01-06T16:45:24.451017700Z"
    }
   },
   "id": "2cfe9bebbd6e55bd",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "imagenet64_classes = {\n",
    "1: \"kit_fox\",\n",
    "2: \"English_setter\",\n",
    "3: \"Siberian_husky\",\n",
    "4: \"Australian_terrier\",\n",
    "5: \"English_springer\",\n",
    "6: \"grey_whale\",\n",
    "7: \"lesser_panda\",\n",
    "8: \"Egyptian_cat\",\n",
    "9: \"ibex\",\n",
    "10: \"Persian_cat\",\n",
    "11: \"cougar\",\n",
    "12: \"gazelle\",\n",
    "13: \"porcupine\",\n",
    "14: \"sea_lion\",\n",
    "15: \"malamute\",\n",
    "16: \"badger\",\n",
    "17: \"Great_Dane\",\n",
    "18: \"Walker_hound\",\n",
    "19: \"Welsh_springer_spaniel\",\n",
    "20: \"whippet\",\n",
    "21: \"Scottish_deerhound\",\n",
    "22: \"killer_whale\",\n",
    "23: \"mink\",\n",
    "24: \"African_elephant\",\n",
    "25: \"Weimaraner\",\n",
    "26: \"soft-coated_wheaten_terrier\",\n",
    "27: \"Dandie_Dinmont\",\n",
    "28: \"red_wolf\",\n",
    "29: \"Old_English_sheepdog\",\n",
    "30: \"jaguar\",\n",
    "31: \"otterhound\",\n",
    "32: \"bloodhound\",\n",
    "33: \"Airedale\",\n",
    "34: \"hyena\",\n",
    "35: \"meerkat\",\n",
    "36: \"giant_schnauzer\",\n",
    "37: \"titi\",\n",
    "38: \"three-toed_sloth\",\n",
    "39: \"sorrel\",\n",
    "40: \"black-footed_ferret\",\n",
    "41: \"dalmatian\",\n",
    "42: \"black-and-tan_coonhound\",\n",
    "43: \"papillon\",\n",
    "44: \"skunk\",\n",
    "45: \"Staffordshire_bullterrier\",\n",
    "46: \"Mexican_hairless\",\n",
    "47: \"Bouvier_des_Flandres\",\n",
    "48: \"weasel\",\n",
    "49: \"miniature_poodle\",\n",
    "50: \"Cardigan\",\n",
    "51: \"malinois\",\n",
    "52: \"bighorn\",\n",
    "53: \"fox_squirrel\",\n",
    "54: \"colobus\",\n",
    "55: \"tiger_cat\",\n",
    "56: \"Lhasa\",\n",
    "57: \"impala\",\n",
    "58: \"coyote\",\n",
    "59: \"Yorkshire_terrier\",\n",
    "60: \"Newfoundland\",\n",
    "61: \"brown_bear\",\n",
    "62: \"red_fox\",\n",
    "63: \"Norwegian_elkhound\",\n",
    "64: \"Rottweiler\",\n",
    "65: \"hartebeest\",\n",
    "66: \"Saluki\",\n",
    "67: \"grey_fox\",\n",
    "68: \"schipperke\",\n",
    "69: \"Pekinese\",\n",
    "70: \"Brabancon_griffon\",\n",
    "71: \"West_Highland_white_terrier\",\n",
    "72: \"Sealyham_terrier\",\n",
    "73: \"guenon\",\n",
    "74: \"mongoose\",\n",
    "75: \"indri\",\n",
    "76: \"tiger\",\n",
    "77: \"Irish_wolfhound\",\n",
    "78: \"wild_boar\",\n",
    "79: \"EntleBucher\",\n",
    "80: \"zebra\",\n",
    "81: \"ram\",\n",
    "82: \"French_bulldog\",\n",
    "83: \"orangutan\",\n",
    "84: \"basenji\",\n",
    "85: \"leopard\",\n",
    "86: \"Bernese_mountain_dog\",\n",
    "87: \"Maltese_dog\",\n",
    "88: \"Norfolk_terrier\",\n",
    "89: \"toy_terrier\",\n",
    "90: \"vizsla\",\n",
    "91: \"cairn\",\n",
    "92: \"squirrel_monkey\",\n",
    "93: \"groenendael\",\n",
    "94: \"clumber\",\n",
    "95: \"Siamese_cat\",\n",
    "96: \"chimpanzee\",\n",
    "97: \"komondor\",\n",
    "98: \"Afghan_hound\",\n",
    "99: \"Japanese_spaniel\",\n",
    "100: \"proboscis_monkey\",\n",
    "101: \"guinea_pig\",\n",
    "102: \"white_wolf\",\n",
    "103: \"ice_bear\",\n",
    "104: \"gorilla\",\n",
    "105: \"borzoi\",\n",
    "106: \"toy_poodle\",\n",
    "107: \"Kerry_blue_terrier\",\n",
    "108: \"ox\",\n",
    "109: \"Scotch_terrier\",\n",
    "110: \"Tibetan_mastiff\",\n",
    "111: \"spider_monkey\",\n",
    "112: \"Doberman\",\n",
    "113: \"Boston_bull\",\n",
    "114: \"Greater_Swiss_Mountain_dog\",\n",
    "115: \"Appenzeller\",\n",
    "116: \"Shih-Tzu\",\n",
    "117: \"Irish_water_spaniel\",\n",
    "118: \"Pomeranian\",\n",
    "119: \"Bedlington_terrier\",\n",
    "120: \"warthog\",\n",
    "121: \"Arabian_camel\",\n",
    "122: \"siamang\",\n",
    "123: \"miniature_schnauzer\",\n",
    "124: \"collie\",\n",
    "125: \"golden_retriever\",\n",
    "126: \"Irish_terrier\",\n",
    "127: \"affenpinscher\",\n",
    "128: \"Border_collie\",\n",
    "129: \"hare\",\n",
    "130: \"boxer\",\n",
    "131: \"silky_terrier\",\n",
    "132: \"beagle\",\n",
    "133: \"Leonberg\",\n",
    "134: \"German_short-haired_pointer\",\n",
    "135: \"patas\",\n",
    "136: \"dhole\",\n",
    "137: \"baboon\",\n",
    "138: \"macaque\",\n",
    "139: \"Chesapeake_Bay_retriever\",\n",
    "140: \"bull_mastiff\",\n",
    "141: \"kuvasz\",\n",
    "142: \"capuchin\",\n",
    "143: \"pug\",\n",
    "144: \"curly-coated_retriever\",\n",
    "145: \"Norwich_terrier\",\n",
    "146: \"flat-coated_retriever\",\n",
    "147: \"hog\",\n",
    "148: \"keeshond\",\n",
    "149: \"Eskimo_dog\",\n",
    "150: \"Brittany_spaniel\",\n",
    "151: \"standard_poodle\",\n",
    "152: \"Lakeland_terrier\",\n",
    "153: \"snow_leopard\",\n",
    "154: \"Gordon_setter\",\n",
    "155: \"dingo\",\n",
    "156: \"standard_schnauzer\",\n",
    "157: \"hamster\",\n",
    "158: \"Tibetan_terrier\",\n",
    "159: \"Arctic_fox\",\n",
    "160: \"wire-haired_fox_terrier\",\n",
    "161: \"basset\",\n",
    "162: \"water_buffalo\",\n",
    "163: \"American_black_bear\",\n",
    "164: \"Angora\",\n",
    "165: \"bison\",\n",
    "166: \"howler_monkey\",\n",
    "167: \"hippopotamus\",\n",
    "168: \"chow\",\n",
    "169: \"giant_panda\",\n",
    "170: \"American_Staffordshire_terrier\",\n",
    "171: \"Shetland_sheepdog\",\n",
    "172: \"Great_Pyrenees\",\n",
    "173: \"Chihuahua\",\n",
    "174: \"tabby\",\n",
    "175: \"marmoset\",\n",
    "176: \"Labrador_retriever\",\n",
    "177: \"Saint_Bernard\",\n",
    "178: \"armadillo\",\n",
    "179: \"Samoyed\",\n",
    "180: \"bluetick\",\n",
    "181: \"redbone\",\n",
    "182: \"polecat\",\n",
    "183: \"marmot\",\n",
    "184: \"kelpie\",\n",
    "185: \"gibbon\",\n",
    "186: \"llama\",\n",
    "187: \"miniature_pinscher\",\n",
    "188: \"wood_rabbit\",\n",
    "189: \"Italian_greyhound\",\n",
    "190: \"lion\",\n",
    "191: \"cocker_spaniel\",\n",
    "192: \"Irish_setter\",\n",
    "193: \"dugong\",\n",
    "194: \"Indian_elephant\",\n",
    "195: \"beaver\",\n",
    "196: \"Sussex_spaniel\",\n",
    "197: \"Pembroke\",\n",
    "198: \"Blenheim_spaniel\",\n",
    "199: \"Madagascar_cat\",\n",
    "200: \"Rhodesian_ridgeback\",\n",
    "201: \"lynx\",\n",
    "202: \"African_hunting_dog\",\n",
    "203: \"langur\",\n",
    "204: \"Ibizan_hound\",\n",
    "205: \"timber_wolf\",\n",
    "206: \"cheetah\",\n",
    "207: \"English_foxhound\",\n",
    "208: \"briard\",\n",
    "209: \"sloth_bear\",\n",
    "210: \"Border_terrier\",\n",
    "211: \"German_shepherd\",\n",
    "212: \"otter\",\n",
    "213: \"koala\",\n",
    "214: \"tusker\",\n",
    "215: \"echidna\",\n",
    "216: \"wallaby\",\n",
    "217: \"platypus\",\n",
    "218: \"wombat\",\n",
    "219: \"revolver\",\n",
    "220: \"umbrella\",\n",
    "221: \"schooner\",\n",
    "222: \"soccer_ball\",\n",
    "223: \"accordion\",\n",
    "224: \"ant\",\n",
    "225: \"starfish\",\n",
    "226: \"chambered_nautilus\",\n",
    "227: \"grand_piano\",\n",
    "228: \"laptop\",\n",
    "229: \"strawberry\",\n",
    "230: \"airliner\",\n",
    "231: \"warplane\",\n",
    "232: \"airship\",\n",
    "233: \"balloon\",\n",
    "234: \"space_shuttle\",\n",
    "235: \"fireboat\",\n",
    "236: \"gondola\",\n",
    "237: \"speedboat\",\n",
    "238: \"lifeboat\",\n",
    "239: \"canoe\",\n",
    "240: \"yawl\",\n",
    "241: \"catamaran\",\n",
    "242: \"trimaran\",\n",
    "243: \"container_ship\",\n",
    "244: \"liner\",\n",
    "245: \"pirate\",\n",
    "246: \"aircraft_carrier\",\n",
    "247: \"submarine\",\n",
    "248: \"wreck\",\n",
    "249: \"half_track\",\n",
    "250: \"tank\",\n",
    "251: \"missile\",\n",
    "252: \"bobsled\",\n",
    "253: \"dogsled\",\n",
    "254: \"bicycle-built-for-two\",\n",
    "255: \"mountain_bike\",\n",
    "256: \"freight_car\",\n",
    "257: \"passenger_car\",\n",
    "258: \"barrow\",\n",
    "259: \"shopping_cart\",\n",
    "260: \"motor_scooter\",\n",
    "261: \"forklift\",\n",
    "262: \"electric_locomotive\",\n",
    "263: \"steam_locomotive\",\n",
    "264: \"amphibian\",\n",
    "265: \"ambulance\",\n",
    "266: \"beach_wagon\",\n",
    "267: \"cab\",\n",
    "268: \"convertible\",\n",
    "269: \"jeep\",\n",
    "270: \"limousine\",\n",
    "271: \"minivan\",\n",
    "272: \"Model_T\",\n",
    "273: \"racer\",\n",
    "274: \"sports_car\",\n",
    "275: \"go-kart\",\n",
    "276: \"golfcart\",\n",
    "277: \"moped\",\n",
    "278: \"snowplow\",\n",
    "279: \"fire_engine\",\n",
    "280: \"garbage_truck\",\n",
    "281: \"pickup\",\n",
    "282: \"tow_truck\",\n",
    "283: \"trailer_truck\",\n",
    "284: \"moving_van\",\n",
    "285: \"police_van\",\n",
    "286: \"recreational_vehicle\",\n",
    "287: \"streetcar\",\n",
    "288: \"snowmobile\",\n",
    "289: \"tractor\",\n",
    "290: \"mobile_home\",\n",
    "291: \"tricycle\",\n",
    "292: \"unicycle\",\n",
    "293: \"horse_cart\",\n",
    "294: \"jinrikisha\",\n",
    "295: \"oxcart\",\n",
    "296: \"bassinet\",\n",
    "297: \"cradle\",\n",
    "298: \"crib\",\n",
    "299: \"four-poster\",\n",
    "300: \"bookcase\",\n",
    "301: \"china_cabinet\",\n",
    "302: \"medicine_chest\",\n",
    "303: \"chiffonier\",\n",
    "304: \"table_lamp\",\n",
    "305: \"file\",\n",
    "306: \"park_bench\",\n",
    "307: \"barber_chair\",\n",
    "308: \"throne\",\n",
    "309: \"folding_chair\",\n",
    "310: \"rocking_chair\",\n",
    "311: \"studio_couch\",\n",
    "312: \"toilet_seat\",\n",
    "313: \"desk\",\n",
    "314: \"pool_table\",\n",
    "315: \"dining_table\",\n",
    "316: \"entertainment_center\",\n",
    "317: \"wardrobe\",\n",
    "318: \"Granny_Smith\",\n",
    "319: \"orange\",\n",
    "320: \"lemon\",\n",
    "321: \"fig\",\n",
    "322: \"pineapple\",\n",
    "323: \"banana\",\n",
    "324: \"jackfruit\",\n",
    "325: \"custard_apple\",\n",
    "326: \"pomegranate\",\n",
    "327: \"acorn\",\n",
    "328: \"hip\",\n",
    "329: \"ear\",\n",
    "330: \"rapeseed\",\n",
    "331: \"corn\",\n",
    "332: \"buckeye\",\n",
    "333: \"organ\",\n",
    "334: \"upright\",\n",
    "335: \"chime\",\n",
    "336: \"drum\",\n",
    "337: \"gong\",\n",
    "338: \"maraca\",\n",
    "339: \"marimba\",\n",
    "340: \"steel_drum\",\n",
    "341: \"banjo\",\n",
    "342: \"cello\",\n",
    "343: \"violin\",\n",
    "344: \"harp\",\n",
    "345: \"acoustic_guitar\",\n",
    "346: \"electric_guitar\",\n",
    "347: \"cornet\",\n",
    "348: \"French_horn\",\n",
    "349: \"trombone\",\n",
    "350: \"harmonica\",\n",
    "351: \"ocarina\",\n",
    "352: \"panpipe\",\n",
    "353: \"bassoon\",\n",
    "354: \"oboe\",\n",
    "355: \"sax\",\n",
    "356: \"flute\",\n",
    "357: \"daisy\",\n",
    "358: \"yellow_lady's_slipper\",\n",
    "359: \"cliff\",\n",
    "360: \"valley\",\n",
    "361: \"alp\",\n",
    "362: \"volcano\",\n",
    "363: \"promontory\",\n",
    "364: \"sandbar\",\n",
    "365: \"coral_reef\",\n",
    "366: \"lakeside\",\n",
    "367: \"seashore\",\n",
    "368: \"geyser\",\n",
    "369: \"hatchet\",\n",
    "370: \"cleaver\",\n",
    "371: \"letter_opener\",\n",
    "372: \"plane\",\n",
    "373: \"power_drill\",\n",
    "374: \"lawn_mower\",\n",
    "375: \"hammer\",\n",
    "376: \"corkscrew\",\n",
    "377: \"can_opener\",\n",
    "378: \"plunger\",\n",
    "379: \"screwdriver\",\n",
    "380: \"shovel\",\n",
    "381: \"plow\",\n",
    "382: \"chain_saw\",\n",
    "383: \"cock\",\n",
    "384: \"hen\",\n",
    "385: \"ostrich\",\n",
    "386: \"brambling\",\n",
    "387: \"goldfinch\",\n",
    "388: \"house_finch\",\n",
    "389: \"junco\",\n",
    "390: \"indigo_bunting\",\n",
    "391: \"robin\",\n",
    "392: \"bulbul\",\n",
    "393: \"jay\",\n",
    "394: \"magpie\",\n",
    "395: \"chickadee\",\n",
    "396: \"water_ouzel\",\n",
    "397: \"kite\",\n",
    "398: \"bald_eagle\",\n",
    "399: \"vulture\",\n",
    "400: \"great_grey_owl\",\n",
    "401: \"black_grouse\",\n",
    "402: \"ptarmigan\",\n",
    "403: \"ruffed_grouse\",\n",
    "404: \"prairie_chicken\",\n",
    "405: \"peacock\",\n",
    "406: \"quail\",\n",
    "407: \"partridge\",\n",
    "408: \"African_grey\",\n",
    "409: \"macaw\",\n",
    "410: \"sulphur-crested_cockatoo\",\n",
    "411: \"lorikeet\",\n",
    "412: \"coucal\",\n",
    "413: \"bee_eater\",\n",
    "414: \"hornbill\",\n",
    "415: \"hummingbird\",\n",
    "416: \"jacamar\",\n",
    "417: \"toucan\",\n",
    "418: \"drake\",\n",
    "419: \"red-breasted_merganser\",\n",
    "420: \"goose\",\n",
    "421: \"black_swan\",\n",
    "422: \"white_stork\",\n",
    "423: \"black_stork\",\n",
    "424: \"spoonbill\",\n",
    "425: \"flamingo\",\n",
    "426: \"American_egret\",\n",
    "427: \"little_blue_heron\",\n",
    "428: \"bittern\",\n",
    "429: \"crane\",\n",
    "430: \"limpkin\",\n",
    "431: \"American_coot\",\n",
    "432: \"bustard\",\n",
    "433: \"ruddy_turnstone\",\n",
    "434: \"red-backed_sandpiper\",\n",
    "435: \"redshank\",\n",
    "436: \"dowitcher\",\n",
    "437: \"oystercatcher\",\n",
    "438: \"European_gallinule\",\n",
    "439: \"pelican\",\n",
    "440: \"king_penguin\",\n",
    "441: \"albatross\",\n",
    "442: \"great_white_shark\",\n",
    "443: \"tiger_shark\",\n",
    "444: \"hammerhead\",\n",
    "445: \"electric_ray\",\n",
    "446: \"stingray\",\n",
    "447: \"barracouta\",\n",
    "448: \"coho\",\n",
    "449: \"tench\",\n",
    "450: \"goldfish\",\n",
    "451: \"eel\",\n",
    "452: \"rock_beauty\",\n",
    "453: \"anemone_fish\",\n",
    "454: \"lionfish\",\n",
    "455: \"puffer\",\n",
    "456: \"sturgeon\",\n",
    "457: \"gar\",\n",
    "458: \"loggerhead\",\n",
    "459: \"leatherback_turtle\",\n",
    "460: \"mud_turtle\",\n",
    "461: \"terrapin\",\n",
    "462: \"box_turtle\",\n",
    "463: \"banded_gecko\",\n",
    "464: \"common_iguana\",\n",
    "465: \"American_chameleon\",\n",
    "466: \"whiptail\",\n",
    "467: \"agama\",\n",
    "468: \"frilled_lizard\",\n",
    "469: \"alligator_lizard\",\n",
    "470: \"Gila_monster\",\n",
    "471: \"green_lizard\",\n",
    "472: \"African_chameleon\",\n",
    "473: \"Komodo_dragon\",\n",
    "474: \"triceratops\",\n",
    "475: \"African_crocodile\",\n",
    "476: \"American_alligator\",\n",
    "477: \"thunder_snake\",\n",
    "478: \"ringneck_snake\",\n",
    "479: \"hognose_snake\",\n",
    "480: \"green_snake\",\n",
    "481: \"king_snake\",\n",
    "482: \"garter_snake\",\n",
    "483: \"water_snake\",\n",
    "484: \"vine_snake\",\n",
    "485: \"night_snake\",\n",
    "486: \"boa_constrictor\",\n",
    "487: \"rock_python\",\n",
    "488: \"Indian_cobra\",\n",
    "489: \"green_mamba\",\n",
    "490: \"sea_snake\",\n",
    "491: \"horned_viper\",\n",
    "492: \"diamondback\",\n",
    "493: \"sidewinder\",\n",
    "494: \"European_fire_salamander\",\n",
    "495: \"common_newt\",\n",
    "496: \"eft\",\n",
    "497: \"spotted_salamander\",\n",
    "498: \"axolotl\",\n",
    "499: \"bullfrog\",\n",
    "500: \"tree_frog\",\n",
    "501: \"tailed_frog\",\n",
    "502: \"whistle\",\n",
    "503: \"wing\",\n",
    "504: \"paintbrush\",\n",
    "505: \"hand_blower\",\n",
    "506: \"oxygen_mask\",\n",
    "507: \"snorkel\",\n",
    "508: \"loudspeaker\",\n",
    "509: \"microphone\",\n",
    "510: \"screen\",\n",
    "511: \"mouse\",\n",
    "512: \"electric_fan\",\n",
    "513: \"oil_filter\",\n",
    "514: \"strainer\",\n",
    "515: \"space_heater\",\n",
    "516: \"stove\",\n",
    "517: \"guillotine\",\n",
    "518: \"barometer\",\n",
    "519: \"rule\",\n",
    "520: \"odometer\",\n",
    "521: \"scale\",\n",
    "522: \"analog_clock\",\n",
    "523: \"digital_clock\",\n",
    "524: \"wall_clock\",\n",
    "525: \"hourglass\",\n",
    "526: \"sundial\",\n",
    "527: \"parking_meter\",\n",
    "528: \"stopwatch\",\n",
    "529: \"digital_watch\",\n",
    "530: \"stethoscope\",\n",
    "531: \"syringe\",\n",
    "532: \"magnetic_compass\",\n",
    "533: \"binoculars\",\n",
    "534: \"projector\",\n",
    "535: \"sunglasses\",\n",
    "536: \"loupe\",\n",
    "537: \"radio_telescope\",\n",
    "538: \"bow\",\n",
    "539: \"cannon\",\n",
    "540: \"assault_rifle\",\n",
    "541: \"rifle\",\n",
    "542: \"projectile\",\n",
    "543: \"computer_keyboard\",\n",
    "544: \"typewriter_keyboard\",\n",
    "545: \"crane\",\n",
    "546: \"lighter\",\n",
    "547: \"abacus\",\n",
    "548: \"cash_machine\",\n",
    "549: \"slide_rule\",\n",
    "550: \"desktop_computer\",\n",
    "551: \"hand-held_computer\",\n",
    "552: \"notebook\",\n",
    "553: \"web_site\",\n",
    "554: \"harvester\",\n",
    "555: \"thresher\",\n",
    "556: \"printer\",\n",
    "557: \"slot\",\n",
    "558: \"vending_machine\",\n",
    "559: \"sewing_machine\",\n",
    "560: \"joystick\",\n",
    "561: \"switch\",\n",
    "562: \"hook\",\n",
    "563: \"car_wheel\",\n",
    "564: \"paddlewheel\",\n",
    "565: \"pinwheel\",\n",
    "566: \"potter's_wheel\",\n",
    "567: \"gas_pump\",\n",
    "568: \"carousel\",\n",
    "569: \"swing\",\n",
    "570: \"reel\",\n",
    "571: \"radiator\",\n",
    "572: \"puck\",\n",
    "573: \"hard_disc\",\n",
    "574: \"sunglass\",\n",
    "575: \"pick\",\n",
    "576: \"car_mirror\",\n",
    "577: \"solar_dish\",\n",
    "578: \"remote_control\",\n",
    "579: \"disk_brake\",\n",
    "580: \"buckle\",\n",
    "581: \"hair_slide\",\n",
    "582: \"knot\",\n",
    "583: \"combination_lock\",\n",
    "584: \"padlock\",\n",
    "585: \"nail\",\n",
    "586: \"safety_pin\",\n",
    "587: \"screw\",\n",
    "588: \"muzzle\",\n",
    "589: \"seat_belt\",\n",
    "590: \"ski\",\n",
    "591: \"candle\",\n",
    "592: \"jack-o'-lantern\",\n",
    "593: \"spotlight\",\n",
    "594: \"torch\",\n",
    "595: \"neck_brace\",\n",
    "596: \"pier\",\n",
    "597: \"tripod\",\n",
    "598: \"maypole\",\n",
    "599: \"mousetrap\",\n",
    "600: \"spider_web\",\n",
    "601: \"trilobite\",\n",
    "602: \"harvestman\",\n",
    "603: \"scorpion\",\n",
    "604: \"black_and_gold_garden_spider\",\n",
    "605: \"barn_spider\",\n",
    "606: \"garden_spider\",\n",
    "607: \"black_widow\",\n",
    "608: \"tarantula\",\n",
    "609: \"wolf_spider\",\n",
    "610: \"tick\",\n",
    "611: \"centipede\",\n",
    "612: \"isopod\",\n",
    "613: \"Dungeness_crab\",\n",
    "614: \"rock_crab\",\n",
    "615: \"fiddler_crab\",\n",
    "616: \"king_crab\",\n",
    "617: \"American_lobster\",\n",
    "618: \"spiny_lobster\",\n",
    "619: \"crayfish\",\n",
    "620: \"hermit_crab\",\n",
    "621: \"tiger_beetle\",\n",
    "622: \"ladybug\",\n",
    "623: \"ground_beetle\",\n",
    "624: \"long-horned_beetle\",\n",
    "625: \"leaf_beetle\",\n",
    "626: \"dung_beetle\",\n",
    "627: \"rhinoceros_beetle\",\n",
    "628: \"weevil\",\n",
    "629: \"fly\",\n",
    "630: \"bee\",\n",
    "631: \"grasshopper\",\n",
    "632: \"cricket\",\n",
    "633: \"walking_stick\",\n",
    "634: \"cockroach\",\n",
    "635: \"mantis\",\n",
    "636: \"cicada\",\n",
    "637: \"leafhopper\",\n",
    "638: \"lacewing\",\n",
    "639: \"dragonfly\",\n",
    "640: \"damselfly\",\n",
    "641: \"admiral\",\n",
    "642: \"ringlet\",\n",
    "643: \"monarch\",\n",
    "644: \"cabbage_butterfly\",\n",
    "645: \"sulphur_butterfly\",\n",
    "646: \"lycaenid\",\n",
    "647: \"jellyfish\",\n",
    "648: \"sea_anemone\",\n",
    "649: \"brain_coral\",\n",
    "650: \"flatworm\",\n",
    "651: \"nematode\",\n",
    "652: \"conch\",\n",
    "653: \"snail\",\n",
    "654: \"slug\",\n",
    "655: \"sea_slug\",\n",
    "656: \"chiton\",\n",
    "657: \"sea_urchin\",\n",
    "658: \"sea_cucumber\",\n",
    "659: \"iron\",\n",
    "660: \"espresso_maker\",\n",
    "661: \"microwave\",\n",
    "662: \"Dutch_oven\",\n",
    "663: \"rotisserie\",\n",
    "664: \"toaster\",\n",
    "665: \"waffle_iron\",\n",
    "666: \"vacuum\",\n",
    "667: \"dishwasher\",\n",
    "668: \"refrigerator\",\n",
    "669: \"washer\",\n",
    "670: \"Crock_Pot\",\n",
    "671: \"frying_pan\",\n",
    "672: \"wok\",\n",
    "673: \"caldron\",\n",
    "674: \"coffeepot\",\n",
    "675: \"teapot\",\n",
    "676: \"spatula\",\n",
    "677: \"altar\",\n",
    "678: \"triumphal_arch\",\n",
    "679: \"patio\",\n",
    "680: \"steel_arch_bridge\",\n",
    "681: \"suspension_bridge\",\n",
    "682: \"viaduct\",\n",
    "683: \"barn\",\n",
    "684: \"greenhouse\",\n",
    "685: \"palace\",\n",
    "686: \"monastery\",\n",
    "687: \"library\",\n",
    "688: \"apiary\",\n",
    "689: \"boathouse\",\n",
    "690: \"church\",\n",
    "691: \"mosque\",\n",
    "692: \"stupa\",\n",
    "693: \"planetarium\",\n",
    "694: \"restaurant\",\n",
    "695: \"cinema\",\n",
    "696: \"home_theater\",\n",
    "697: \"lumbermill\",\n",
    "698: \"coil\",\n",
    "699: \"obelisk\",\n",
    "700: \"totem_pole\",\n",
    "701: \"castle\",\n",
    "702: \"prison\",\n",
    "703: \"grocery_store\",\n",
    "704: \"bakery\",\n",
    "705: \"barbershop\",\n",
    "706: \"bookshop\",\n",
    "707: \"butcher_shop\",\n",
    "708: \"confectionery\",\n",
    "709: \"shoe_shop\",\n",
    "710: \"tobacco_shop\",\n",
    "711: \"toyshop\",\n",
    "712: \"fountain\",\n",
    "713: \"cliff_dwelling\",\n",
    "714: \"yurt\",\n",
    "715: \"dock\",\n",
    "716: \"brass\",\n",
    "717: \"megalith\",\n",
    "718: \"bannister\",\n",
    "719: \"breakwater\",\n",
    "720: \"dam\",\n",
    "721: \"chainlink_fence\",\n",
    "722: \"picket_fence\",\n",
    "723: \"worm_fence\",\n",
    "724: \"stone_wall\",\n",
    "725: \"grille\",\n",
    "726: \"sliding_door\",\n",
    "727: \"turnstile\",\n",
    "728: \"mountain_tent\",\n",
    "729: \"scoreboard\",\n",
    "730: \"honeycomb\",\n",
    "731: \"plate_rack\",\n",
    "732: \"pedestal\",\n",
    "733: \"beacon\",\n",
    "734: \"mashed_potato\",\n",
    "735: \"bell_pepper\",\n",
    "736: \"head_cabbage\",\n",
    "737: \"broccoli\",\n",
    "738: \"cauliflower\",\n",
    "739: \"zucchini\",\n",
    "740: \"spaghetti_squash\",\n",
    "741: \"acorn_squash\",\n",
    "742: \"butternut_squash\",\n",
    "743: \"cucumber\",\n",
    "744: \"artichoke\",\n",
    "745: \"cardoon\",\n",
    "746: \"mushroom\",\n",
    "747: \"shower_curtain\",\n",
    "748: \"jean\",\n",
    "749: \"carton\",\n",
    "750: \"handkerchief\",\n",
    "751: \"sandal\",\n",
    "752: \"ashcan\",\n",
    "753: \"safe\",\n",
    "754: \"plate\",\n",
    "755: \"necklace\",\n",
    "756: \"croquet_ball\",\n",
    "757: \"fur_coat\",\n",
    "758: \"thimble\",\n",
    "759: \"pajama\",\n",
    "760: \"running_shoe\",\n",
    "761: \"cocktail_shaker\",\n",
    "762: \"chest\",\n",
    "763: \"manhole_cover\",\n",
    "764: \"modem\",\n",
    "765: \"tub\",\n",
    "766: \"tray\",\n",
    "767: \"balance_beam\",\n",
    "768: \"bagel\",\n",
    "769: \"prayer_rug\",\n",
    "770: \"kimono\",\n",
    "771: \"hot_pot\",\n",
    "772: \"whiskey_jug\",\n",
    "773: \"knee_pad\",\n",
    "774: \"book_jacket\",\n",
    "775: \"spindle\",\n",
    "776: \"ski_mask\",\n",
    "777: \"beer_bottle\",\n",
    "778: \"crash_helmet\",\n",
    "779: \"bottlecap\",\n",
    "780: \"tile_roof\",\n",
    "781: \"mask\",\n",
    "782: \"maillot\",\n",
    "783: \"Petri_dish\",\n",
    "784: \"football_helmet\",\n",
    "785: \"bathing_cap\",\n",
    "786: \"teddy\",\n",
    "787: \"holster\",\n",
    "788: \"pop_bottle\",\n",
    "789: \"photocopier\",\n",
    "790: \"vestment\",\n",
    "791: \"crossword_puzzle\",\n",
    "792: \"golf_ball\",\n",
    "793: \"trifle\",\n",
    "794: \"suit\",\n",
    "795: \"water_tower\",\n",
    "796: \"feather_boa\",\n",
    "797: \"cloak\",\n",
    "798: \"red_wine\",\n",
    "799: \"drumstick\",\n",
    "800: \"shield\",\n",
    "801: \"Christmas_stocking\",\n",
    "802: \"hoopskirt\",\n",
    "803: \"menu\",\n",
    "804: \"stage\",\n",
    "805: \"bonnet\",\n",
    "806: \"meat_loaf\",\n",
    "807: \"baseball\",\n",
    "808: \"face_powder\",\n",
    "809: \"scabbard\",\n",
    "810: \"sunscreen\",\n",
    "811: \"beer_glass\",\n",
    "812: \"hen-of-the-woods\",\n",
    "813: \"guacamole\",\n",
    "814: \"lampshade\",\n",
    "815: \"wool\",\n",
    "816: \"hay\",\n",
    "817: \"bow_tie\",\n",
    "818: \"mailbag\",\n",
    "819: \"water_jug\",\n",
    "820: \"bucket\",\n",
    "821: \"dishrag\",\n",
    "822: \"soup_bowl\",\n",
    "823: \"eggnog\",\n",
    "824: \"mortar\",\n",
    "825: \"trench_coat\",\n",
    "826: \"paddle\",\n",
    "827: \"chain\",\n",
    "828: \"swab\",\n",
    "829: \"mixing_bowl\",\n",
    "830: \"potpie\",\n",
    "831: \"wine_bottle\",\n",
    "832: \"shoji\",\n",
    "833: \"bulletproof_vest\",\n",
    "834: \"drilling_platform\",\n",
    "835: \"binder\",\n",
    "836: \"cardigan\",\n",
    "837: \"sweatshirt\",\n",
    "838: \"pot\",\n",
    "839: \"birdhouse\",\n",
    "840: \"hamper\",\n",
    "841: \"ping-pong_ball\",\n",
    "842: \"pencil_box\",\n",
    "843: \"pay-phone\",\n",
    "844: \"consomme\",\n",
    "845: \"apron\",\n",
    "846: \"punching_bag\",\n",
    "847: \"backpack\",\n",
    "848: \"groom\",\n",
    "849: \"bearskin\",\n",
    "850: \"pencil_sharpener\",\n",
    "851: \"broom\",\n",
    "852: \"mosquito_net\",\n",
    "853: \"abaya\",\n",
    "854: \"mortarboard\",\n",
    "855: \"poncho\",\n",
    "856: \"crutch\",\n",
    "857: \"Polaroid_camera\",\n",
    "858: \"space_bar\",\n",
    "859: \"cup\",\n",
    "860: \"racket\",\n",
    "861: \"traffic_light\",\n",
    "862: \"quill\",\n",
    "863: \"radio\",\n",
    "864: \"dough\",\n",
    "865: \"cuirass\",\n",
    "866: \"military_uniform\",\n",
    "867: \"lipstick\",\n",
    "868: \"shower_cap\",\n",
    "869: \"monitor\",\n",
    "870: \"oscilloscope\",\n",
    "871: \"mitten\",\n",
    "872: \"brassiere\",\n",
    "873: \"French_loaf\",\n",
    "874: \"vase\",\n",
    "875: \"milk_can\",\n",
    "876: \"rugby_ball\",\n",
    "877: \"paper_towel\",\n",
    "878: \"earthstar\",\n",
    "879: \"envelope\",\n",
    "880: \"miniskirt\",\n",
    "881: \"cowboy_hat\",\n",
    "882: \"trolleybus\",\n",
    "883: \"perfume\",\n",
    "884: \"bathtub\",\n",
    "885: \"hotdog\",\n",
    "886: \"coral_fungus\",\n",
    "887: \"bullet_train\",\n",
    "888: \"pillow\",\n",
    "889: \"toilet_tissue\",\n",
    "890: \"cassette\",\n",
    "891: \"carpenter's_kit\",\n",
    "892: \"ladle\",\n",
    "893: \"stinkhorn\",\n",
    "894: \"lotion\",\n",
    "895: \"hair_spray\",\n",
    "896: \"academic_gown\",\n",
    "897: \"dome\",\n",
    "898: \"crate\",\n",
    "899: \"wig\",\n",
    "900: \"burrito\",\n",
    "901: \"pill_bottle\",\n",
    "902: \"chain_mail\",\n",
    "903: \"theater_curtain\",\n",
    "904: \"window_shade\",\n",
    "905: \"barrel\",\n",
    "906: \"washbasin\",\n",
    "907: \"ballpoint\",\n",
    "908: \"basketball\",\n",
    "909: \"bath_towel\",\n",
    "910: \"cowboy_boot\",\n",
    "911: \"gown\",\n",
    "912: \"window_screen\",\n",
    "913: \"agaric\",\n",
    "914: \"cellular_telephone\",\n",
    "915: \"nipple\",\n",
    "916: \"barbell\",\n",
    "917: \"mailbox\",\n",
    "918: \"lab_coat\",\n",
    "919: \"fire_screen\",\n",
    "920: \"minibus\",\n",
    "921: \"packet\",\n",
    "922: \"maze\",\n",
    "923: \"pole\",\n",
    "924: \"horizontal_bar\",\n",
    "925: \"sombrero\",\n",
    "926: \"pickelhaube\",\n",
    "927: \"rain_barrel\",\n",
    "928: \"wallet\",\n",
    "929: \"cassette_player\",\n",
    "930: \"comic_book\",\n",
    "931: \"piggy_bank\",\n",
    "932: \"street_sign\",\n",
    "933: \"bell_cote\",\n",
    "934: \"fountain_pen\",\n",
    "935: \"Windsor_tie\",\n",
    "936: \"volleyball\",\n",
    "937: \"overskirt\",\n",
    "938: \"sarong\",\n",
    "939: \"purse\",\n",
    "940: \"bolo_tie\",\n",
    "941: \"bib\",\n",
    "942: \"parachute\",\n",
    "943: \"sleeping_bag\",\n",
    "944: \"television\",\n",
    "945: \"swimming_trunks\",\n",
    "946: \"measuring_cup\",\n",
    "947: \"espresso\",\n",
    "948: \"pizza\",\n",
    "949: \"breastplate\",\n",
    "950: \"shopping_basket\",\n",
    "951: \"wooden_spoon\",\n",
    "952: \"saltshaker\",\n",
    "953: \"chocolate_sauce\",\n",
    "954: \"ballplayer\",\n",
    "955: \"goblet\",\n",
    "956: \"gyromitra\",\n",
    "957: \"stretcher\",\n",
    "958: \"water_bottle\",\n",
    "959: \"dial_telephone\",\n",
    "960: \"soap_dispenser\",\n",
    "961: \"jersey\",\n",
    "962: \"school_bus\",\n",
    "963: \"jigsaw_puzzle\",\n",
    "964: \"plastic_bag\",\n",
    "965: \"reflex_camera\",\n",
    "966: \"diaper\",\n",
    "967: \"Band_Aid\",\n",
    "968: \"ice_lolly\",\n",
    "969: \"velvet\",\n",
    "970: \"tennis_ball\",\n",
    "971: \"gasmask\",\n",
    "972: \"doormat\",\n",
    "973: \"Loafer\",\n",
    "974: \"ice_cream\",\n",
    "975: \"pretzel\",\n",
    "976: \"quilt\",\n",
    "977: \"maillot\",\n",
    "978: \"tape_player\",\n",
    "979: \"clog\",\n",
    "980: \"iPod\",\n",
    "981: \"bolete\",\n",
    "982: \"scuba_diver\",\n",
    "983: \"pitcher\",\n",
    "984: \"matchstick\",\n",
    "985: \"bikini\",\n",
    "986: \"sock\",\n",
    "987: \"CD_player\",\n",
    "988: \"lens_cap\",\n",
    "989: \"thatch\",\n",
    "990: \"vault\",\n",
    "991: \"beaker\",\n",
    "992: \"bubble\",\n",
    "993: \"cheeseburger\",\n",
    "994: \"parallel_bars\",\n",
    "995: \"flagpole\",\n",
    "996: \"coffee_mug\",\n",
    "997: \"rubber_eraser\",\n",
    "998: \"stole\",\n",
    "999: \"carbonara\",\n",
    "1000: \"dumbbell\",\n",
    "}\n",
    "imagenet64_classes = {k-1:v for k, v in imagenet64_classes.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:38:46.595945585Z",
     "start_time": "2024-01-06T16:38:46.524315936Z"
    }
   },
   "id": "e219054dbdc021f6",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "imagenet_assoc = [314,\n",
    " 932,\n",
    " 810,\n",
    " 414,\n",
    " 341,\n",
    " 917,\n",
    " 627,\n",
    " 877,\n",
    " 705,\n",
    " 625,\n",
    " 683,\n",
    " 448,\n",
    " 781,\n",
    " 372,\n",
    " 704,\n",
    " 158,\n",
    " 105,\n",
    " 689,\n",
    " 354,\n",
    " 325,\n",
    " 400,\n",
    " 739,\n",
    " 308,\n",
    " 862,\n",
    " 207,\n",
    " 614,\n",
    " 114,\n",
    " 954,\n",
    " 187,\n",
    " 474,\n",
    " 457,\n",
    " 286,\n",
    " 69,\n",
    " 806,\n",
    " 912,\n",
    " 652,\n",
    " 733,\n",
    " 938,\n",
    " 570,\n",
    " 910,\n",
    " 496,\n",
    " 73,\n",
    " 839,\n",
    " 511,\n",
    " 747,\n",
    " 849,\n",
    " 970,\n",
    " 978,\n",
    " 540,\n",
    " 367,\n",
    " 480,\n",
    " 32,\n",
    " 25,\n",
    " 424,\n",
    " 842,\n",
    " 425,\n",
    " 525,\n",
    " 109,\n",
    " 50,\n",
    " 675,\n",
    " 283,\n",
    " 349,\n",
    " 1,\n",
    " 281,\n",
    " 526,\n",
    " 765,\n",
    " 440,\n",
    " 737,\n",
    " 438,\n",
    " 821,\n",
    " 612,\n",
    " 311,\n",
    " 964,\n",
    " 744,\n",
    " 500,\n",
    " 975,\n",
    " 430,\n",
    " 458,\n",
    " 761,\n",
    " 945,\n",
    " 678,\n",
    " 957,\n",
    " 79,\n",
    " 619,\n",
    " 734,\n",
    " 774,\n",
    " 470,\n",
    " 482,\n",
    " 447,\n",
    " 542,\n",
    " 532,\n",
    " 760,\n",
    " 75,\n",
    " 315,\n",
    " 887,\n",
    " 411,\n",
    " 71,\n",
    " 567,\n",
    " 123,\n",
    " 758]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:45:54.533739794Z",
     "start_time": "2024-01-06T16:45:54.271577516Z"
    }
   },
   "id": "e3d73e265eb06676",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "from datamodules import Task1Datamodule\n",
    "import torch\n",
    "\n",
    "dm = Task1Datamodule(\n",
    "    path=\"/home/doved/Data/AAIT/task1\",\n",
    "    batch_size=64,\n",
    "    num_train_workers=0,\n",
    "    num_val_workers=0,\n",
    "    labeled=True,\n",
    "    unlabeled=False,\n",
    "    no_train_augmentations=True,\n",
    "    val_size=0,\n",
    ")\n",
    "dm.setup(\"fit\")\n",
    "resnet50 = timm.create_model(\"resnet50\", pretrained=True)\n",
    "resnet50.eval()\n",
    "resnet50.load_state_dict(torch.load(\"/home/doved/Downloads/checkpoint-86.pth.tar\")[\"state_dict\"])\n",
    "resnet50.to(\"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:38:59.145282319Z",
     "start_time": "2024-01-06T16:38:46.576728829Z"
    }
   },
   "id": "a4b5ead502a524cb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 369/369 [03:00<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "outputs = []\n",
    "labels = []\n",
    "for batch, l in tqdm(dm.train_dataloader()):\n",
    "    with torch.no_grad():\n",
    "        out = resnet50(batch[\"image\"])\n",
    "    outputs.append(out)\n",
    "    labels.append(l)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:41:59.681857813Z",
     "start_time": "2024-01-06T16:38:59.138199037Z"
    }
   },
   "id": "c263eee837a6476a",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_pred = [torch.argmax(o, dim=1) for o in outputs]\n",
    "y_pred = torch.cat(y_pred)\n",
    "y_true = torch.cat(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:41:59.788387628Z",
     "start_time": "2024-01-06T16:41:59.635077977Z"
    }
   },
   "id": "aa13e52766a44f52",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.6084, 2.8699, 5.0382,  ..., 4.7266, 2.0641, 0.4604])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y_score = torch.cat(outputs, dim=0)\n",
    "y_score = F.softmax(y_score, dim=1)\n",
    "entropy = -torch.sum(y_score * torch.log(y_score), dim=1)\n",
    "entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:41:59.916119998Z",
     "start_time": "2024-01-06T16:41:59.674645375Z"
    }
   },
   "id": "c7b8e9fa4de69db",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "per_label = {}\n",
    "for i in range(len(y_true)):\n",
    "    true_label = y_true[i].item()\n",
    "    pred_label = y_pred[i].item()\n",
    "    if true_label not in per_label:\n",
    "        per_label[true_label] = []\n",
    "    per_label[true_label].append(pred_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:41:59.980788785Z",
     "start_time": "2024-01-06T16:41:59.816260200Z"
    }
   },
   "id": "4f1f2a12351c6eee",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "per_label_entropy = {}\n",
    "for i in range(len(y_true)):\n",
    "    true_label = y_true[i].item()\n",
    "    item_entropy = entropy[i]\n",
    "    if true_label not in per_label_entropy:\n",
    "        per_label_entropy[true_label] = []\n",
    "    per_label_entropy[true_label].append(item_entropy)\n",
    "per_label_entropy = {k:torch.mean(torch.tensor(v)).item() for k,v in per_label_entropy.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.068619653Z",
     "start_time": "2024-01-06T16:41:59.929000347Z"
    }
   },
   "id": "64f10e52384b9213",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "3.5596110820770264"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_label_entropy[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.095959605Z",
     "start_time": "2024-01-06T16:42:00.060091996Z"
    }
   },
   "id": "58328e155691d12",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{57: 2.4214372634887695,\n 19: 2.5537047386169434,\n 81: 2.664971113204956,\n 12: 2.786641836166382,\n 79: 2.8026998043060303,\n 5: 2.8530499935150146,\n 77: 2.8675642013549805,\n 62: 2.8692777156829834,\n 59: 2.894524335861206,\n 41: 2.905123233795166,\n 37: 2.9957711696624756,\n 32: 3.049877643585205,\n 29: 3.0604028701782227,\n 69: 3.0735137462615967,\n 92: 3.126189708709717,\n 9: 3.1849143505096436,\n 20: 3.210815906524658,\n 55: 3.2479021549224854,\n 33: 3.2527663707733154,\n 47: 3.2875518798828125,\n 34: 3.3119864463806152,\n 84: 3.3246548175811768,\n 83: 3.3819494247436523,\n 75: 3.3865177631378174,\n 68: 3.4168264865875244,\n 40: 3.4199252128601074,\n 56: 3.4300479888916016,\n 43: 3.434837818145752,\n 42: 3.4743216037750244,\n 82: 3.4743916988372803,\n 22: 3.481916904449463,\n 72: 3.4850668907165527,\n 46: 3.49448299407959,\n 27: 3.499361038208008,\n 73: 3.5091378688812256,\n 94: 3.5351462364196777,\n 1: 3.5596110820770264,\n 8: 3.5785515308380127,\n 48: 3.583818197250366,\n 58: 3.584379196166992,\n 6: 3.5846502780914307,\n 74: 3.6024951934814453,\n 97: 3.6062676906585693,\n 18: 3.6112565994262695,\n 98: 3.612828016281128,\n 63: 3.6216728687286377,\n 96: 3.625291347503662,\n 10: 3.6281626224517822,\n 45: 3.642641067504883,\n 16: 3.658484935760498,\n 4: 3.6676316261291504,\n 13: 3.6743228435516357,\n 86: 3.6769816875457764,\n 87: 3.68025803565979,\n 52: 3.6847620010375977,\n 49: 3.6884028911590576,\n 51: 3.7000954151153564,\n 7: 3.7051773071289062,\n 60: 3.7069783210754395,\n 78: 3.7128608226776123,\n 65: 3.7188594341278076,\n 31: 3.7204689979553223,\n 95: 3.724102020263672,\n 93: 3.7267098426818848,\n 71: 3.732797384262085,\n 90: 3.7431273460388184,\n 0: 3.7510504722595215,\n 28: 3.7551705837249756,\n 24: 3.766524076461792,\n 36: 3.795670509338379,\n 50: 3.8050601482391357,\n 2: 3.805953025817871,\n 26: 3.820253849029541,\n 30: 3.833059072494507,\n 61: 3.850048065185547,\n 66: 3.867354154586792,\n 85: 3.8784258365631104,\n 70: 3.8959126472473145,\n 54: 3.89794921875,\n 3: 3.9098634719848633,\n 39: 3.913902521133423,\n 21: 3.9219162464141846,\n 25: 3.922314405441284,\n 80: 3.9283359050750732,\n 14: 3.935610055923462,\n 91: 3.9481186866760254,\n 99: 3.9559268951416016,\n 38: 4.005514144897461,\n 76: 4.0251545906066895,\n 35: 4.031134128570557,\n 89: 4.045079231262207,\n 67: 4.064665794372559,\n 11: 4.084537029266357,\n 23: 4.094529628753662,\n 64: 4.119641304016113,\n 15: 4.174454212188721,\n 88: 4.2116193771362305,\n 17: 4.220486640930176,\n 53: 4.234028339385986,\n 44: 4.249999046325684}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(per_label_entropy.items(), key=lambda item: item[1])}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.234609270Z",
     "start_time": "2024-01-06T16:42:00.065564069Z"
    }
   },
   "id": "995b7502e3a3ae62",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "per_label = {k:Counter(v) for k, v in per_label.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.239847593Z",
     "start_time": "2024-01-06T16:42:00.107788822Z"
    }
   },
   "id": "91a2715619473e4",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(846, 35), (918, 27), (817, 10), (901, 9), (832, 8)]"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_label[3].most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.279039069Z",
     "start_time": "2024-01-06T16:42:00.108423874Z"
    }
   },
   "id": "c6d573148f375f55",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{53: 704,\n 18: 120,\n 1: 52,\n 82: 610,\n 54: 944,\n 71: 603,\n 60: 9,\n 33: 985,\n 51: 29,\n 16: 52,\n 48: 544,\n 99: 569,\n 38: 970,\n 26: 901,\n 20: 895,\n 50: 550,\n 23: 593,\n 22: 628,\n 12: 728,\n 90: 314,\n 56: 719,\n 9: 237,\n 6: 269,\n 41: 599,\n 45: 771,\n 49: 95,\n 98: 29,\n 36: 922,\n 8: 265,\n 0: 611,\n 21: 565,\n 24: 124,\n 37: 737,\n 79: 734,\n 62: 449,\n 94: 789,\n 81: 325,\n 29: 901,\n 76: 29,\n 52: 496,\n 3: 846,\n 32: 600,\n 69: 679,\n 43: 267,\n 93: 637,\n 10: 353,\n 14: 526,\n 19: 644,\n 78: 577,\n 28: 52,\n 73: 541,\n 87: 928,\n 42: 680,\n 35: 901,\n 65: 309,\n 58: 901,\n 39: 901,\n 13: 901,\n 68: 990,\n 70: 293,\n 17: 901,\n 47: 366,\n 77: 715,\n 30: 934,\n 5: 929,\n 57: 648,\n 74: 712,\n 40: 800,\n 55: 682,\n 91: 667,\n 11: 838,\n 15: 52,\n 89: 353,\n 2: 542,\n 7: 726,\n 44: 845,\n 61: 205,\n 95: 887,\n 31: 52,\n 85: 750,\n 25: 769,\n 4: 901,\n 67: 787,\n 66: 776,\n 80: 594,\n 59: 283,\n 97: 664,\n 64: 549,\n 84: 284,\n 46: 360,\n 34: 721,\n 88: 532,\n 63: 84,\n 27: 322,\n 86: 590,\n 83: 813,\n 72: 829,\n 92: 606,\n 96: 492,\n 75: 365}"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assoc = {k:pl.most_common(1)[0][0] for k, pl in per_label.items()}\n",
    "assoc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.299689259Z",
     "start_time": "2024-01-06T16:42:00.108952385Z"
    }
   },
   "id": "35d9fcf5d2e7e13a",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[9,\n 29,\n 29,\n 29,\n 52,\n 52,\n 52,\n 52,\n 52,\n 84,\n 95,\n 120,\n 124,\n 205,\n 237,\n 265,\n 267,\n 269,\n 283,\n 284,\n 293,\n 309,\n 314,\n 322,\n 325,\n 353,\n 353,\n 360,\n 365,\n 366,\n 449,\n 492,\n 496,\n 526,\n 532,\n 541,\n 542,\n 544,\n 549,\n 550,\n 565,\n 569,\n 577,\n 590,\n 593,\n 594,\n 599,\n 600,\n 603,\n 606,\n 610,\n 611,\n 628,\n 637,\n 644,\n 648,\n 664,\n 667,\n 679,\n 680,\n 682,\n 704,\n 712,\n 715,\n 719,\n 721,\n 726,\n 728,\n 734,\n 737,\n 750,\n 769,\n 771,\n 776,\n 787,\n 789,\n 800,\n 813,\n 829,\n 838,\n 845,\n 846,\n 887,\n 895,\n 901,\n 901,\n 901,\n 901,\n 901,\n 901,\n 901,\n 901,\n 922,\n 928,\n 929,\n 934,\n 944,\n 970,\n 985,\n 990]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(assoc.values())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.305522886Z",
     "start_time": "2024-01-06T16:42:00.109434537Z"
    }
   },
   "id": "5b8028342b8a05ba",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 29, 901, 353]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "print([item for item, count in collections.Counter(assoc.values()).items() if count > 1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.311034329Z",
     "start_time": "2024-01-06T16:42:00.110100934Z"
    }
   },
   "id": "f75d94c054b8db43",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[26, 29, 35, 58, 39, 13, 17, 4]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k, v in assoc.items() if v == 901]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.331008698Z",
     "start_time": "2024-01-06T16:42:00.110526563Z"
    }
   },
   "id": "b4d3656e9c5f0eb3",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 45 = kettle\n",
    "# 66 = beer bottle\n",
    "# 67 = also bottle?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.336639595Z",
     "start_time": "2024-01-06T16:42:00.110926778Z"
    }
   },
   "id": "2f392ec9bff11aa6",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(771, 31), (674, 17), (982, 11), (672, 11), (673, 6)]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_label[45].most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.356243989Z",
     "start_time": "2024-01-06T16:42:00.111297736Z"
    }
   },
   "id": "fc554cf31efd5fd7",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(776, 22), (771, 19), (757, 12), (830, 8), (787, 8)]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_label[66].most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.375482923Z",
     "start_time": "2024-01-06T16:42:00.111640297Z"
    }
   },
   "id": "438fefc50bb81e07",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(787, 21), (771, 10), (776, 9), (29, 7), (893, 5)]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_label[67].most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.381037409Z",
     "start_time": "2024-01-06T16:42:00.112036864Z"
    }
   },
   "id": "558c71169c752ff1",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assoc[45] = 849\n",
    "assoc[66] = 440\n",
    "assoc[67] = 737"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T09:36:18.195546638Z",
     "start_time": "2024-01-05T09:36:17.799364640Z"
    }
   },
   "id": "c110d997f42b96c8",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 82 = miriapod\n",
    "# 86 = scorpion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T09:36:18.420667038Z",
     "start_time": "2024-01-05T09:36:18.254596755Z"
    }
   },
   "id": "31d456fccb5fc81c",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:44:28.271832714Z",
     "start_time": "2024-01-06T16:44:27.974028640Z"
    }
   },
   "id": "b91b5c667a1a49bf",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDpfC+l31lqFzvSE6fLLIIQhcsAGOGYH5cEBcEckEde3S3dsGgKLHvDkLtBxjJxn+tZZ1uERaRrMjukFzEYpOpXcSuOPXqc+gNWNM1WW5WdLx7Z3R8KY12YIOACCTzke30FKUkkm+plFXfoePePfB50bV47wKRb3bkNhSNr9Tx6Ec/n6Vn+FPDUetatNFJKUhhXzHGeXXcBtB7Hnrg4xXsnxIvNJuvDiWN1dRJqEgWe2j2lm3A+33cjcOcA8+lcv4O8LyQX8GpNMBIvIjC/Lz6+tcVSD9rpsd0av7vfU5/X/CLeHNb+wiRZYXAliYcnYSQA3HUYP6H2p9pozybflPXknt3r0K88CT3l/PqMV0ZZJXMjRyfyB9B0A9qsxafa6TaSXeqpJBaw7A52ElnZgiquBzkkDPbI+omNB8+1kVKuuS9zzpdKnuNS+yWseXAO4jAwOOueg5HPuBgk109n4Lils1jMId3+9u+YMOmAM89jk5PXnHFdbpOn6GttLqEMc0Vu6iV4bgg/KwyDnJypyxySeSc+gh1SWOHbfzQvMkqkRBImL8AsMZxtIAz1HTrmt5RcdI6em5wtSqu8jI0e2XUPhtpwQO5heNm2AZCnAJ/DJP4VS1prTQmhle5SaZ2D7DEFmcAYBZxxgemMnHHSq/w48UR2kMmk3mI8sTEpPBXPT6jOMf0IrqdS0TS79ZWWGPzJBndgZyBgc/pWktY8vYqOjujhZpLvxHPbPcJtitxiLcMtj3NdfpUdzAihW4HTisbTLu0RvL4VlO0r6Gursp7cgcg1jFXd2yrmra3V4FA3D8qzfEui3fiG2s42uFiFtdLdAbMhyqOoU+gy+c8/dFbto8DYyQK0FMJ7iuhEtXVjMt7OGKxW2RV3JbhG29QoOE59sNiuXuv9L1dtOkcPA6ssqyAks2QQOOOCV+g9e3W6rctZ2MslqFeYY2rjOTkD+tcgwe7DahBIIb6J1HlsoIXJJByOxxjmrgkjKcre6jxxLaJ7iSMzQRMrbkDuQSRn+JRweCOoySO2a2RrWv6JAm+5WdAMr5jAEgAEkN0PUHnHB71gXepQxXQYzM9zE23zLMgAHb94MFwQGOOMH3FZ+pXsd/oq7IflQeW5VAhLZU5yBjdhW5/2z8vBNcbqSk02dapo1NS19o/EFwMCOQsDIisDtfHzDI461v6f4lmjUHcT+Nef6F4WvdZeNo7tYUOSWkRyVUck8Kc8Ed+dy+tdR4c0i4Yyf2jE8aRRecWIwGTuwzjNDlG+43Cx6Jp/ivdA7lhmMbmTndt4BI9QCR789K0n8YQwW6zSSqiN0ZmxxwDkdQQT0+nrXMa1pEmnWccenRb1niyJ0lUE/KSQOcE7cnnuK5yaJLjSHuFlZxzAsjtHk8tydqEkAtyVbkL37YyrNOyZUaSauzrfDvxI1C71+4+3ac0emjiN8Z+XIHzHs2eQOnUf7VeixS6XPdBbeSMtIgZkEZDMpzgHPOQQTjqMc4rxVo2sYfstjBKxuYyQVgzFD8w3BtwyQCOMnuoOCeZ9CfUdImghkv450lTAaUAqFVcsoG45XOcEHJ2np20WJ0vZafkZyoavU83i1mC5u5GaIWzSHaiAHaqgKqAsDk8bs8YyB2JxbuYWtdUhtncBy26TcC7Kc5O/IBzjOQR3OOtc2AcnaSOCOD69atz31zcXaXLyZnQLiRflb5RwcjqffrWkoLoWmeh6dIkFh9rtZUfyIg5W5gzHIvMZXOFAUtkbQCTyBkgbqeneIHmk8mzhnVUjSJsTB9pzjK7SOB1AU9u/OOMudWvJVKRN9likjVJorYsiS4/idc4JP5e1WtH1q90yIRQyfIJBIASwxwwI4IODuz9QCO+cfZWTLvc9Uhi0+1lluEtVjEYDEnP7liXO0BAflUbuQByOPbn9VsL/AEzULjUNNsIZLB40ka2ifa0ZCrw8YwQQzKzADHI5zzXOf27O1nHtl2ymVmkQxq0ZAC7XAI4fIbPbGPfObPqN9JPFILud5Y2DJI0hypHQg9Qfeso0n3LbOzs9RjsreHzLuCea6LvhmZAvLZ5PIVuQRgZ44qfVtQt7C/3YnWR49sM/miQAKuMccMd+ecggfgBw17qMt/EiXMULXCtk3AXbIw54bHDHJJLEFieppiXMgUIgITIyB3x/+uqVFXuw5j//2Q==",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDkWH7004daTOZD9KA3zCuI6R7DkdKQ5A4GT2FKxGat2+m3NyS0ERfHGSQP50mNGf5MhOTO49lVcfqDVe9v00+0aWcbnB2hVH3ien06H8j1qbX5bjQrfdNayCRjtQlfkz7kcfhXJRSvd6fqUs7Fn/dyZP8Ae3Y/kSKuML6kuXQZdapNqMmZDtUciMHgdvxNZu5tz/P0Y8HpT4Bhyfb/AAqNgdzcHhjXSklsYvU9F4DEelTWBiOpQidN8RbDKSRVcn525piMRMCDgiuRbG5tXuiyfbDBHIRGzAhwednfpyD0H510+n2rQIFVRjHeuUsdRJuS0jku3Jz29q6y1vUKjBqWmUrGZ4v0O41zTHjVgswIK7iSvHtzjr1HP4cV5NNa3Ol2F7HdW0kUkjJGA4IB5Ykj1Hy9RXvlxfpLCi+WilR1Hf615N8RNQEV4ttBtBnjBmPOSobKj0AyPTPArSm2/dM523OIjJD568etSNGrEnoT3BqKEKCSe/p2qYkY4rpZidp56h260xbgeb0NUvO5NMWb5+tYKJtcmn1Dyb3Chl6YyOp9v89a3LDV7vAAtpnHqqE1yt3++mXA5Xoat2sd2MbZnUfWm0rCudZe+IJrS1aae3mjRerOhArzPXNQk1TUWunYHI2qv90Dt/X8a6u6tLi6gMU08joezMcVxuo2z2l20T9ByD6irpJJkzbK6uRUyNnkngVXApwwO1atEHRebyeaaHLOAOpqsJKkt5EW4VnbCg5PvWVtC7l6CMibDjkVswKoA5rnX1BzKZNuSSMD0FaMN9kD5lHHQmpaY1Y3ZU8uNWLKdw6Z6VxfiRFe6EqFTsUBx3HPFX9V1Oa3tvkI3EgA9hXNPNJPE5kdnIIOWOfX/Gqpxe4pNbEIPrS5Apo60mea2Mz/2Q==",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDxx4mAHFVmQ9+9aMgKEqwKsuQQRgioCoJ571BRW2n0/StLQtHGsXjQvKY0UZOByatWmktccn5U9Mcmuh0rRltSfLkUMepyuT+tCEcprWhTaJqv2GSQSKYxIkgGN6nvjJxzkfhTGsGKDHevRLjw3b6gyPN5W5RhZN+GA/766fX3qpP4NmVCbKaOYj+EyLnPJ4GfbH9arlYJo4QWJC9uOtRva7evatmVdpIOfl4weOaoTkbentk0mVY6HxZpzSTC/hBYsMSgcnI6Gsiw04sQZEJY9M1015dlLdjuGT8oJPrVKwG8hvwHGKTEi/Z2WxFwiqP0/Wty0hCpGCO24E9SPeqtrED8zHH861oECxo2QSwyQP4fY1SEzQtYySNqA8f3QavC0yPmwSx6HnH4dAKg02B7q5SGPG5umc+ntWzHBsU5wWAyAO/FaxIZx2veErW4U3jwSqFBLGBSS+BkqBnBJyP0rhD4it7dykGk2i2zYDLIvmO31J4/SvcrixxaFpMK2FIXIOQfx4/z7Z+fPFlmNM8Q3tsgxGH3IMYADDIA+mcfhUzVtUUmT319HPbQsrYV2Bz7YNaGmPkDiuMivS0Rjbs+9QT+n610+lXG5V7/AI1kykdhakba1IQdidzj5h6Gsa0lyB61rQOdi8jcBznvTTBmvYqQ2dhOOhroLcYiwBx15rnbSeQcbF9fvVsx3DGPBYKcdu1aRZDNV0a3sFkYxnz4sEDJIIKk89unv39a8I+JcTzeKoo41LSPboAF/wB5q9pn1BltQolYAR7WGcg854z06D8q8X8QeMbU6hLNa2az3UZMS3Er5XaCegHUdT1705bAjzpjk8EfhWtpV+Y2CtJyPfqKyTHx0pyxMcY61kxo9HsNQRgD5gret7pWgDGT5VJHmZ/n2rzLT5pkI3pIQO6810lrelcERXZ+gXn8zUbF7neQXcaruMwA9cirTX64+8zEfNwcdPyFcdHqAxnyZ8+5Uf1qU6jK0ChbeOJyPm3SGTt24FNTXcXKxvizxgkNtLZWQb7VKPmYHAQHqeP4v/115o8bFOhNdNdaVumeQv8AeYk8ZqqbGNeCzfWk6qHyM//Z",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "\n",
    "df = pd.read_csv(\"/home/doved/Data/AAIT/task1/train_data/annotations.csv\")\n",
    "\n",
    "def show_images_with_label(label):\n",
    "    ldf = df[df[\"label\"] == label]\n",
    "    ldf = ldf.sample(12)\n",
    "    paths = ldf[\"sample\"].tolist()\n",
    "    for imageName in paths:\n",
    "        display(Image(filename=f\"/home/doved/Data/AAIT/{imageName}\"))\n",
    "\n",
    "show_images_with_label(45)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:18.716541628Z",
     "start_time": "2024-01-06T16:42:18.591544159Z"
    }
   },
   "id": "1c8b65901cfd9555",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "cassoc = deepcopy(assoc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:21.078711313Z",
     "start_time": "2024-01-06T16:42:20.965984759Z"
    }
   },
   "id": "a41521dd2ec286d1",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 99\n",
      "Guesses:\n",
      "    569: reel\n",
      "    5: grey_whale\n",
      "    901: chain_mail\n",
      "    29: jaguar\n",
      "    218: revolver\n",
      "    720: chainlink_fence\n",
      "    939: bolo_tie\n",
      "    247: wreck\n",
      "    353: oboe\n",
      "    586: screw\n",
      "Predicted: 569: reel\n",
      "Was: reel\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDXwRUig+lC4J7VKBXQeMxFBp+3PSjFOAOeKZIzFLtpwB9KjSZJohJE6yRt0ZGBB/EUi0nuIy1yvjuye40RJV6RE5/Ef/WrqmfFZPiOMXGg3C45XDD88H9CamWxrSdpo1I0xUuDUYcA8Uu9mPFVcwdiZI2chVBZiQAo6k+gqRRNCZTLauHiB/dPKsbbtu4Dvjt1AHPXpUKqx6mm3MDzWV1HGQSYHJXdt3KFJZc9sjI6jr1XqE3bV7Djq7JanCNrVwzyS3ctu0UFwTDJNulBcffZNp4UgrgHOM8HrVGDUJ7Qwrp87W1vn5IYgQhz3O7JJ9zmql/EJdQfT7WJo0jYxxwsQSnJYrkE5wSwzk/U1oWlkZNLubprKWeOxRhut0lKtt5Ys33RgehFKnUo003Vjzfj+bsd1SlVqWVKXL+H6HdWkyT6bbyhg5Ma7jnkNgZz71HcpFJazJNjyWjYSZOBtxzz24rnbfxFFp3hZ721sTPEsybl89T5aumQSVLdwBg4PNdYsYYq8bBkYAqynIIPcUlNSV0rHNOEqcrPUrosuOnFS4dRTBKw78U4Sev8qo52l3Jkc96i1BDcaVewrF5rSQSIqYBySpAxnjOe/anbl9akV145oe1hxdnc86v4rjT9Zubp7eWO5u5H+yxuo3ZYn5uCRx7GslPEUlvJDpun6NamRV8qN54i00hJ+8OhBOTxzjNa2u3N1e+IdQuTGF+ykW8ImyEAzjJPGAckg+4ql4isYrPTjDLLG073DS20a8ssJU5LHJIy2ep6k446efXcedQavc9zDp8jne1h1lqjajoh8PWdrdPe3OyOczsgjhKPuwoA3HPPDYx9BXUweFnFoINQ1e/mTAUwxzssYA7YOTj8qxvh1EIpp3KRktGx3bfmXG3HPvlvy967d39a6qcUlZHBXqNS0IAffipFIqvwo708OPStThsWSFx1pQoHTmq+7PelV/Q0xWKviK3mvPDl9bQLukZQwXGc7WDEAeuBx715vfRq9zDE24XILR3CGQyyGTJ3E8AZz0AJ4xyeTXqnmv1zWc2k2TamuohGhuF5Hkqqh2JOS3GTnJ79hWVRdUdWHqqPusy/C0mqtqFy1zZtbWnlHGYlQM2Rgj143ZI4PHoK6N5DjGKY8rHkk1H5vrVJWVjOdXnlc//Z",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "for i in range(100):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Index {i}\")\n",
    "    top_guesses = [p[0] for p in per_label[i].most_common(10)]\n",
    "    print(\"Guesses:\")\n",
    "    for j in top_guesses:\n",
    "        print(f\"    {j}: {imagenet64_classes[j]}\")\n",
    "    print(f\"Predicted: {assoc[i]}: {imagenet64_classes[assoc[i]]}\")\n",
    "    print(f\"Was: {imagenet_classes[imagenet_assoc[i]]}\", flush=True)\n",
    "    show_images_with_label(i)\n",
    "    time.sleep(0.5)\n",
    "    new_class = input(f\"{imagenet64_classes[assoc[i]]}\\nCorrect: {imagenet_classes[imagenet_assoc[i]]}\") \n",
    "    if len(new_class) > 0:\n",
    "        ok = True\n",
    "        try:\n",
    "            new_class = int(new_class)\n",
    "        except Exception:\n",
    "            ok = False\n",
    "        if not ok:\n",
    "            break\n",
    "        assoc[i] = new_class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6049562dd4d59314",
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[901, 585, 969, 440, 737]"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [p[0] for p in per_label[67].most_common(5)]\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T09:48:29.789196039Z",
     "start_time": "2024-01-05T09:48:29.531413491Z"
    }
   },
   "id": "696f096105d99de5",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 42\n",
      "Guesses:\n",
      "    821: steel arch bridge\n",
      "    912: worm fence, snake fence, snake-rail fence, Virginia fence\n",
      "    839: suspension bridge\n",
      "    724: pirate, pirate ship\n",
      "    975: lakeside, lakeshore\n",
      "Predicted: 821: steel arch bridge\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD2cW/HGM+4zUiwV5fdfEXVUuZYoLi3MYwVkWzfhSOvJ56jGBg98Ag02Xxj4jmvIVhvojbzEENGiKVx6Ag5Bz94tjnHuT2t+pSpnqywgdqkEQ9M15nc33ieQM0moTWcKnBLSR524OW4+7zjueB9a5KPXvIVrqPXUx9pdUto7+d2n28Zzt+bO046jH8QqFVT2ZXIke8kIg+ZgufU01J7ZywWeNipwQHBwf8AJFeCz+KZW1GVtPlnaxkhKoux0TzCzffVT0GQTnBODx1punSaRq6CK7tvsQhBJDahgOHOcEFWO7GTgcc5GKHNJXYWR7tcanYWiGSacBFUuWVSwwO+QD6VRh8YeGplUprVkSwyFMoDYwScqeRwD+VeG38FjJJcRPpM0oDvgwahAI2HUchC3Pp7dAKppb6NFbsZNOuoEwxO28SQJ8wGcsnGBk5HQD14qk4NXv8Al/mJ2vp/X4GFMdVs0hf+xtVE65GY7rzcj64bGcknjk+lRx6nLbxSy3NjqkGxxLFDKpfc2R919ilMAY78H2Feir7mrCIzLvCEgYBIHAz0puERbnBQePLZINl8048tFIQZDM3OcDHHOCQWAx3OcVV1Pxro15YxIulwSSIxYSlGjmwGGAWBOeMg9vQDivQrnT7W6Vobu2STI24deR/UVlp4N0BHDjTosjPDZYH881HsoLUr3trnntp4kMkqm5uCEaIrtIIRmAI+bjqeMnnqO1Ou9Xs763Bu2tPOWN9pCFjkAqBkZ67s9eNufTPSX3w40yYMYJZbdy2cr8ygemCc/rVE/CiUyBRqTBmPCtb9f/HuaG6dxezkU9O1PzIo0gms40l2xsSm91YKoPA6DBAySAcHnjIktry5mF88ckhwVDJ/rCUP8J64YDP3sY9uBTf+FbmC7VJtTSSIruCxqQ5GcHjnGM56H8M1HN4W1uMGG0s/LRU+WSSdR8wbh1VDgEqAPm3Hk89MFobi5H2PTCtvY3Ue2V7uIsFdlZcRSkM20lsfKAhPQcEdc8Sw2sdxd3kSsxNkdhzDliWBIOA2VB24B77hwc8M/wCEc8TyGB21HToEQALFb2JYLjIBwSBuwccYx2xk1HfWTaFEmo6mZL22ErTeZejcFGRjlAo67eACeBjAXFYKUtkzr9jbW1iXbIeDG3r04qVrx4ogXuyiY6b+gz0rMn8R2F9bQ2dtdpcLLOYhLJKY2j3qWDYKqQuMYCsCeFGA2BbS0gtNPtvIijjmliiSzdoWaNiW2hN7EooPXliSTnLqBnTnfUx5ewst20sn+rlmI3YaclQD29we/cf1bIsk67Zp2EeMbI/kGO3TnPXv3NDzJCI1ZoGWdSqSu5jXccGMqxJBDAHjk9ccDIhhu4PMkhu5BazpEJfKbLfLgnjHJ5HBAwRgjqBUufZD5e5ZjVU4RQo68d6fxnB7VFFJFM0Sx3ET+aCYzkgSAHB2kjnkgcdzQr7oUlBzG/3X7N9D3/8Ar0k0Gp12qbJ5uLi6SJE2IEO+ItngYBDF8gDuAD75qlJfPYJLHBcSkgKP3kZSAMTyFIQuzEBiR82CenXFVtZto4JdOuD5yBSs3n4Eb8YYNk5xzjDdSeprJktbWV47uQmZkRnZhD5UnJJ+Vgx2nkghfwwBWPPHqdV09EzbvJLnUdMWRb2y8sx7jHJEA27GVdGEmMdOcZ4JB6Y5600mwtx/ZyQXSNIpVXjuHKIcqx++xO3GTkjBKt16VcW9tLe43wrKhyWDqMbznBIBAPY4I+ueMm9DLJqlykNrDJdW2AZEMiqoDrsDLvyGXljxgjPRsU4zvsOSXU5OS3u7e6Us2oWcl3KRvvI1ljPycAbVzICBtOG3c85ywqe1SyEUCi4k3xTSCM2liiRSyAYAbLMCACQSCP4uc5J1YzPHew6ewvbe8u8vHA0jKdoO6MFgCwUbSMsSfvcAAUXcN/qQDyaTN5kBKwTW7lznHJLod2CFUgumTgfKTWl32MuVHLWul3IEr6XLBfqG3RxurMEHLDzPmUE4ZDn5mJNH9pTxXTi1k/fwkySWFuFDRRk7mALBenzDAG4ZQc4zWzo9rE9rdXVhDdRNbgxuTbLLJIy427GXYSgBzjGSo6ZxmlJ4mudE8OpfzXVnfooBgIdY3nG5RhkOSGGTkcn5T0xVWbfcnljbXQ//2Q==",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD0rxPMmn6A9xNGjzSukYWQeYXIIbDNwcfJnjHbivHn1qe6197Zwnl84KqFwwHXA47enpXqPxCvIjptnaKo3SStJ5g7bRjB+u/9K8is3sJNZJhui0vJZTERng5waVTR2M4rS52Xg65vE8WQRWtyI3YMFDsQj4Una3scYzzjOeor2TTtQXULYuYngmRvLmhk+9G46g44PUEEcEEEda8E0yJX8SWY88xAzRgOpwwBYZIPY8fpXtbyy2c0SzsPtMg2JLsIWUDsxAwrZPAzzyR3AIK6KbsblFZUGrpLHKeFMPEytwYjjPzenHPoRgjIINQXPiTT7d2Sa9tkdRkxmUbvX7vWr5WLnRthgehpkpIXiuOuPH+nwXMkUaSThDt8yMAxsdu7hhkHAIz7/hV658Z6RBCjtfwNuYKFjcMee5APAHU//qoS1E5XWp5D/ab6k7iZ48Rt8uM9D26e3WuW0tFGsBlXrnJHJPBNakE9mluWsJWBdVdS+Dycbhkdh27Y59RVCOGCyuUlinLuF+ZCByecj6YzWMpp6tlpJI0JJNt9GAeGOOf91j/StQw649pGqw3Qi8zIDblVAO+T05Nc/HqscskzCIqR0X2x7n3/APrVpw67eK2YZ7oALuO6dyv5Z7n9annUSnE21sdWuQu+yeRfkUyCQkleh3L7Bf8AZPJyTmoLrRrO3maR9TgVEIzDJMokI/oev8J7VzN/qV1dEtc3cs0eMRiR94Dc57/SsuRpZHG6QCPdglTj9fzp86Znex211e6Xb2Col4ssyNvULBISQeAASuBx2z171zVxdFZiqSPhSG5HJyOmPSonuI4UjweEQKT0yeMcfWq9xNJNMZlYBCBlfoAOfyp3Kkl0GXEMk2nxzKqBkn5fJ+Qe3vnHSp47mSRQDlz/AHFONv8AiOelJbXKy6dcxSsY/s+HA3devT3Occe3oRV601BWt/8AR4dhm5wRgBSSCuQfQ/0rlk1bUTS7lW1hiFzK+GGQFIcADoP/ANVPniSKQ7iDuHyj2/pU8kCxbxbzSSqj4wynOME59Dntkcfnmm8aoxSYzFsEfKVwCPbPuaG7otptWZPFNHKoREQKcblJOV981kvB5c7bX24zjPP15+tX5OPmJXCYI+clsd8cc0KUkmcSnbDEoIYrnqudueMfr+uKqLMvIbtVQrmTIYdfXHb6demKqGZEI2AM3UjHXjtUtxDN5wYjMRGEZztHT0/z096oSTGN93zDJwoPb3rRGg4JFKzlw6x/dY7c/Tv9Pz/GpoZIpA/kfIsY+QEZYn1J+hPb0qaWI2+mmNVXckgBcMQRkZ5XjHOOeQT096lmI5JQZXKg8BVwCVweefqP1rneq0Id9kXYZ2SIblJydquQdpPT09/Xocd6WGG8uYdyP+7VzuOcuxxnPAJ6Z57fnSG4kkRUCgQpyA6lccdD+IH4+mami1VotPMTl9gcnbnbjgnH1oBS1tckkhhYxKzHbKCYy+VVuo69ugPrg1n35SG+kIYFQcMFGNw9fzBpEngmeMuGBgmUgcfMO4PsQp6evvVS+nj4xGVOSwdfvAHPbp2HH1/BqIm01oaiQzXkJ8l23JgFAM4Hbv6DFVp9PukV38gn+Ig/p1q74VlK3EkbqsjsP9ZnkD0HTOT/AErqHUHtWi8zSMbxR//Z",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwBUgts/8e0P/fArWt7WzZRm2gPH/PMVgxy4A/LrWraT/uiSRgdea9VPucZppZ2ZHNpBn/rkKsR2llxm0t+f+mS/4VTgnDZ5FWlkyKehVy2lpY55s7f/AL9L/hU62Vj/AM+Vt/36X/CqSyY75qwk3rTsuwXLQsLA/wDLnbf9+Vpf7PsO9lbf9+l/wqNZh2PtT/M7Zo5V2C55fFMD3PvV1Jf3eB3/AErFR+c549KuQzAAnNYpiSN21nO7jvmtFJe1c/FNg5HHOetX4boZUHrVJgbIk7ZqVZOOKzEnXPX368VYSXjmqTGXlf8ACplm7VQEnHXpT1kB5qkB5lHKcZ/DirKv8vB7+lUUYMc4K9M8VMsoLDBAA71zajsaKT7Tg4x9ehq1FMc78g+9ZCscDj8qnSXjGSD/ADp3A2oroHcuRwBwWGec/n0/UetXoJ9xx9K5xZtjb2UcDG4DtVyG6AIII+btTTE0dAJfl6jPoKkEuPQ4rIW7XGegAyfag6pbx482QRHy/MIfggf484xWikiTltTihtWPl3ccskieYwjj2IvTIwTnpzgc5PQVkx6gN7eZtChsctj2/Kub+1STR+VEHwc7gP4j1OMd/wD6/pVdHLKC8gVWJDH145478+nH9OB1XfQ1UWdna6kkrRgkAMeGbgd8ck9f8DWtGr7PMLRrGW272kUKDnHXNcLbatsuPMLDGwKY1OFIznH+fU9zmtmz1R5X8sTJGpwo4OwYYYO3OOnPPf8AA1cancTR0xWaHDSwuq5wCVOKr+aDdbQAj5ZUZW68bjlenpz1z7GpJ9Tm/syZ44wzZHlcjkEZ34bOR1zjPTtnjDl1CE3omt5YWiuCfvRso3hVBxnJJ545HfnBrWUkhGrqV5LBYlC4G7OGJxjnuOpHt/jWLPqDu0ZCuQI1JyM4AGSOOx4PPoD9I9XvMW0NvjcfKbe74Y5JGQCfQj17Y7VgO8YlZd/yDgENjnGMn8qxnLWw1E//2Q==",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDPENOEVWVjxUvlZr27nllRY6lVKsCEkgBTkkDikurNLlH2SzQANtCxsM9euSM9v1PtWcppOxSjdXGqtGUBYbssq7mUckD6DntTorLa4EsrzAYIWQLgEdDwAc1P5HmMrMWG1iRhiOffHX6VVxEADE/Kh+7uDNwM+h7j8qYxLRyHzgFC7T5K72R+/rnqONtXRAhcS7FLj5Q2OcZ9fSpki5Cnk+tK4yr5WB0p6x+1aH2elEGO1LmFYobQsillIAIwexJOPr/+umouxggz8xc8nP8AGP8AGrVzAfJXAIbzI2I4yPnH+fwpRB/psS4yQsm4enzrjNYzkr/d+ZpFO33/AJDGjO7j2/nT/K6YHfmrscOV3Y/zipDBjAx1OK05kZ2M9Y8AeoFSKM/nVs25IYDr0FK1twCOo5FF0Gpd+zj0prQcDHHNXgvGcHHrVSa5gt3ElxOkKv8AdMjhQQD259/yrm5zblILq2xbOcc5B/UVDFYx2jRuhch5GRjJIzkknjkk+lQ6h4jsks0aKO5kikJHneQwQ4zwGIAJJBHGehqvNceJ5zHHHYWmnq0vytPJ5xZjkj7uMD86iT1uXFaWNyK1Jt8eo/pVe91HTdNLC/vra3I+YLJIAxGOw6n8KyL3wdruoLtufFlyilcGOKDy19/usMj61Np/w28OWUSCS2e6lU7vNmkOc/RcDH4VXOTyGVd/ETQ4c/ZEubxhkho49q59y2D+lZ7+JPGWrSKmlaD9mjlXdHLIhYYxnO84X8+tekWulWFkXazs7e3LY3GGNULemcDmrYQDHTn3pc4+XyPJH8WNdJLHdT3Ue7BQLhFQnIPK4JAzkA9cVeTX7fTQhsEtJshszM4Mhy5IBOc9NtcG8qbsHjnvjA+lVmJVsqhIxk+1N01e4KbaPSo9XfxLNHZ3AiijjPnEo33scY6/7ValvqOp3dzEt1bxQwIxbekgznBA7n1ryKK9ZZdySOg2lSVOcjg9Ovar9rrd1HIEFy+0dxx/nrWM07tJGkXonI7s+OL0g4jgB9QD/jUDeMtVznzgB/ur/hXHSXAbgPx/vcfj3pFulBKi4+ZR8ygcfnW6jHsYOcu52Y8aarjiQH3KCm/8Jpqx/wCW6gf7i1x6XDkhiXweQ2Bj8utOSVSfmfLAdF71XLHsLml3P//Z",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 42\n",
    "print(f\"Index {i}\")\n",
    "top_guesses = [p[0] for p in per_label[i].most_common(5)]\n",
    "print(\"Guesses:\")\n",
    "for j in top_guesses:\n",
    "    print(f\"    {j}: {imagenet_classes[j]}\")\n",
    "print(f\"Predicted: {assoc[i]}: {imagenet_classes[assoc[i]]}\", flush=True)\n",
    "show_images_with_label(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:13:33.439182697Z",
     "start_time": "2024-01-05T10:13:33.355661409Z"
    }
   },
   "id": "95269b3289d764f2",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assoc[42] = 839"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:13:45.954803043Z",
     "start_time": "2024-01-05T10:13:45.695567253Z"
    }
   },
   "id": "a1e911a85a9bf7a8",
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'steel arch bridge'"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet_classes[821]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:12:02.206001042Z",
     "start_time": "2024-01-05T10:12:01.909248723Z"
    }
   },
   "id": "7ccbcfef34b3245f",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{61: 349, 66: 440, 28: 187, 13: 372, 16: 105, 56: 525, 81: 957, 89: 542, 12: 781, 34: 912, 53: 424, 98: 123, 82: 79, 72: 964, 85: 774, 41: 73, 86: 470, 46: 970, 5: 917, 95: 411, 32: 69, 3: 414, 21: 739, 99: 758, 27: 954, 7: 877, 93: 315, 47: 978, 60: 283, 20: 400, 59: 675, 8: 705, 45: 849, 23: 862, 90: 532, 74: 500, 71: 311, 2: 810, 73: 744, 76: 430, 38: 570, 43: 511, 33: 806, 10: 683, 1: 932, 18: 354, 54: 842, 22: 308, 40: 496, 58: 50, 31: 286, 39: 910, 94: 887, 77: 458, 69: 821, 30: 457, 52: 25, 19: 325, 83: 619, 0: 314, 15: 158, 64: 526, 11: 448, 42: 839, 68: 438, 75: 975, 51: 32, 24: 207, 25: 614, 29: 474, 78: 761, 92: 75, 6: 627, 17: 689, 9: 625, 97: 567, 48: 540, 57: 109, 50: 480, 37: 938, 14: 704, 44: 747, 67: 737, 70: 612, 84: 734, 80: 678, 36: 733, 63: 281, 49: 367, 26: 114, 4: 341, 35: 652, 62: 1, 79: 945, 91: 760, 96: 71, 55: 425, 87: 482, 65: 765, 88: 447}\n"
     ]
    }
   ],
   "source": [
    "print(assoc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:14:13.386283588Z",
     "start_time": "2024-01-05T10:14:13.149189382Z"
    }
   },
   "id": "184a992f0703ef49",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[314,\n 932,\n 810,\n 414,\n 341,\n 917,\n 627,\n 877,\n 705,\n 625,\n 683,\n 448,\n 781,\n 372,\n 704,\n 158,\n 105,\n 689,\n 354,\n 325,\n 400,\n 739,\n 308,\n 862,\n 207,\n 614,\n 114,\n 954,\n 187,\n 474,\n 457,\n 286,\n 69,\n 806,\n 912,\n 652,\n 733,\n 938,\n 570,\n 910,\n 496,\n 73,\n 839,\n 511,\n 747,\n 849,\n 970,\n 978,\n 540,\n 367,\n 480,\n 32,\n 25,\n 424,\n 842,\n 425,\n 525,\n 109,\n 50,\n 675,\n 283,\n 349,\n 1,\n 281,\n 526,\n 765,\n 440,\n 737,\n 438,\n 821,\n 612,\n 311,\n 964,\n 744,\n 500,\n 975,\n 430,\n 458,\n 761,\n 945,\n 678,\n 957,\n 79,\n 619,\n 734,\n 774,\n 470,\n 482,\n 447,\n 542,\n 532,\n 760,\n 75,\n 315,\n 887,\n 411,\n 71,\n 567,\n 123,\n 758]"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assoc_vec = [assoc[i] for i in range(100)]\n",
    "assoc_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:29:36.160582857Z",
     "start_time": "2024-01-05T10:29:35.842457234Z"
    }
   },
   "id": "496b2ab9df5261fd",
   "execution_count": 97
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'goldfish, Carassius auratus'"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet_classes[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:29:46.887839133Z",
     "start_time": "2024-01-05T10:29:46.643668533Z"
    }
   },
   "id": "3d9be506027cd330",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[633,\n 974,\n 542,\n 846,\n 146,\n 929,\n 269,\n 726,\n 265,\n 237,\n 353,\n 838,\n 728,\n 136,\n 526,\n 88,\n 212,\n 879,\n 120,\n 644,\n 895,\n 565,\n 628,\n 593,\n 124,\n 769,\n 653,\n 322,\n 58,\n 835,\n 816,\n 10,\n 600,\n 985,\n 721,\n 865,\n 922,\n 737,\n 970,\n 950,\n 800,\n 599,\n 680,\n 267,\n 845,\n 674,\n 360,\n 366,\n 544,\n 95,\n 547,\n 498,\n 493,\n 704,\n 944,\n 682,\n 719,\n 648,\n 475,\n 283,\n 9,\n 51,\n 449,\n 173,\n 312,\n 309,\n 776,\n 787,\n 990,\n 679,\n 293,\n 631,\n 829,\n 541,\n 712,\n 365,\n 907,\n 715,\n 577,\n 734,\n 594,\n 325,\n 610,\n 813,\n 284,\n 750,\n 590,\n 928,\n 532,\n 798,\n 314,\n 667,\n 606,\n 634,\n 789,\n 844,\n 602,\n 670,\n 617,\n 569]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assoc_vec = [assoc[i] for i in range(100)]\n",
    "assoc_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:04:29.523438539Z",
     "start_time": "2024-01-06T17:04:29.180292934Z"
    }
   },
   "id": "22fed6d50dfc586b",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['H',\n 'T',\n '__abs__',\n '__add__',\n '__and__',\n '__array__',\n '__array_priority__',\n '__array_wrap__',\n '__bool__',\n '__class__',\n '__complex__',\n '__contains__',\n '__deepcopy__',\n '__delattr__',\n '__delitem__',\n '__dict__',\n '__dir__',\n '__div__',\n '__dlpack__',\n '__dlpack_device__',\n '__doc__',\n '__eq__',\n '__float__',\n '__floordiv__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__iand__',\n '__idiv__',\n '__ifloordiv__',\n '__ilshift__',\n '__imod__',\n '__imul__',\n '__index__',\n '__init__',\n '__init_subclass__',\n '__int__',\n '__invert__',\n '__ior__',\n '__ipow__',\n '__irshift__',\n '__isub__',\n '__iter__',\n '__itruediv__',\n '__ixor__',\n '__le__',\n '__len__',\n '__long__',\n '__lshift__',\n '__lt__',\n '__matmul__',\n '__mod__',\n '__module__',\n '__mul__',\n '__ne__',\n '__neg__',\n '__new__',\n '__nonzero__',\n '__or__',\n '__pos__',\n '__pow__',\n '__radd__',\n '__rand__',\n '__rdiv__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rfloordiv__',\n '__rlshift__',\n '__rmatmul__',\n '__rmod__',\n '__rmul__',\n '__ror__',\n '__rpow__',\n '__rrshift__',\n '__rshift__',\n '__rsub__',\n '__rtruediv__',\n '__rxor__',\n '__setattr__',\n '__setitem__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__sub__',\n '__subclasshook__',\n '__torch_dispatch__',\n '__torch_function__',\n '__truediv__',\n '__weakref__',\n '__xor__',\n '_addmm_activation',\n '_autocast_to_full_precision',\n '_autocast_to_reduced_precision',\n '_backward_hooks',\n '_base',\n '_cdata',\n '_coalesced_',\n '_conj',\n '_conj_physical',\n '_dimI',\n '_dimV',\n '_fix_weakref',\n '_grad',\n '_grad_fn',\n '_has_symbolic_sizes_strides',\n '_indices',\n '_is_all_true',\n '_is_any_true',\n '_is_view',\n '_is_zerotensor',\n '_make_subclass',\n '_make_wrapper_subclass',\n '_neg_view',\n '_nested_tensor_size',\n '_nested_tensor_storage_offsets',\n '_nested_tensor_strides',\n '_nnz',\n '_post_accumulate_grad_hooks',\n '_python_dispatch',\n '_reduce_ex_internal',\n '_sparse_mask_projection',\n '_to_dense',\n '_to_sparse',\n '_to_sparse_bsc',\n '_to_sparse_bsr',\n '_to_sparse_csc',\n '_to_sparse_csr',\n '_typed_storage',\n '_update_names',\n '_values',\n '_version',\n '_view_func',\n 'abs',\n 'abs_',\n 'absolute',\n 'absolute_',\n 'acos',\n 'acos_',\n 'acosh',\n 'acosh_',\n 'add',\n 'add_',\n 'addbmm',\n 'addbmm_',\n 'addcdiv',\n 'addcdiv_',\n 'addcmul',\n 'addcmul_',\n 'addmm',\n 'addmm_',\n 'addmv',\n 'addmv_',\n 'addr',\n 'addr_',\n 'adjoint',\n 'align_as',\n 'align_to',\n 'all',\n 'allclose',\n 'amax',\n 'amin',\n 'aminmax',\n 'angle',\n 'any',\n 'apply_',\n 'arccos',\n 'arccos_',\n 'arccosh',\n 'arccosh_',\n 'arcsin',\n 'arcsin_',\n 'arcsinh',\n 'arcsinh_',\n 'arctan',\n 'arctan2',\n 'arctan2_',\n 'arctan_',\n 'arctanh',\n 'arctanh_',\n 'argmax',\n 'argmin',\n 'argsort',\n 'argwhere',\n 'as_strided',\n 'as_strided_',\n 'as_strided_scatter',\n 'as_subclass',\n 'asin',\n 'asin_',\n 'asinh',\n 'asinh_',\n 'atan',\n 'atan2',\n 'atan2_',\n 'atan_',\n 'atanh',\n 'atanh_',\n 'backward',\n 'baddbmm',\n 'baddbmm_',\n 'bernoulli',\n 'bernoulli_',\n 'bfloat16',\n 'bincount',\n 'bitwise_and',\n 'bitwise_and_',\n 'bitwise_left_shift',\n 'bitwise_left_shift_',\n 'bitwise_not',\n 'bitwise_not_',\n 'bitwise_or',\n 'bitwise_or_',\n 'bitwise_right_shift',\n 'bitwise_right_shift_',\n 'bitwise_xor',\n 'bitwise_xor_',\n 'bmm',\n 'bool',\n 'broadcast_to',\n 'byte',\n 'cauchy_',\n 'ccol_indices',\n 'cdouble',\n 'ceil',\n 'ceil_',\n 'cfloat',\n 'chalf',\n 'char',\n 'cholesky',\n 'cholesky_inverse',\n 'cholesky_solve',\n 'chunk',\n 'clamp',\n 'clamp_',\n 'clamp_max',\n 'clamp_max_',\n 'clamp_min',\n 'clamp_min_',\n 'clip',\n 'clip_',\n 'clone',\n 'coalesce',\n 'col_indices',\n 'conj',\n 'conj_physical',\n 'conj_physical_',\n 'contiguous',\n 'copy_',\n 'copysign',\n 'copysign_',\n 'corrcoef',\n 'cos',\n 'cos_',\n 'cosh',\n 'cosh_',\n 'count_nonzero',\n 'cov',\n 'cpu',\n 'cross',\n 'crow_indices',\n 'cuda',\n 'cummax',\n 'cummin',\n 'cumprod',\n 'cumprod_',\n 'cumsum',\n 'cumsum_',\n 'data',\n 'data_ptr',\n 'deg2rad',\n 'deg2rad_',\n 'dense_dim',\n 'dequantize',\n 'det',\n 'detach',\n 'detach_',\n 'device',\n 'diag',\n 'diag_embed',\n 'diagflat',\n 'diagonal',\n 'diagonal_scatter',\n 'diff',\n 'digamma',\n 'digamma_',\n 'dim',\n 'dim_order',\n 'dist',\n 'div',\n 'div_',\n 'divide',\n 'divide_',\n 'dot',\n 'double',\n 'dsplit',\n 'dtype',\n 'eig',\n 'element_size',\n 'eq',\n 'eq_',\n 'equal',\n 'erf',\n 'erf_',\n 'erfc',\n 'erfc_',\n 'erfinv',\n 'erfinv_',\n 'exp',\n 'exp2',\n 'exp2_',\n 'exp_',\n 'expand',\n 'expand_as',\n 'expm1',\n 'expm1_',\n 'exponential_',\n 'fill_',\n 'fill_diagonal_',\n 'fix',\n 'fix_',\n 'flatten',\n 'flip',\n 'fliplr',\n 'flipud',\n 'float',\n 'float_power',\n 'float_power_',\n 'floor',\n 'floor_',\n 'floor_divide',\n 'floor_divide_',\n 'fmax',\n 'fmin',\n 'fmod',\n 'fmod_',\n 'frac',\n 'frac_',\n 'frexp',\n 'gather',\n 'gcd',\n 'gcd_',\n 'ge',\n 'ge_',\n 'geometric_',\n 'geqrf',\n 'ger',\n 'get_device',\n 'grad',\n 'grad_fn',\n 'greater',\n 'greater_',\n 'greater_equal',\n 'greater_equal_',\n 'gt',\n 'gt_',\n 'half',\n 'hardshrink',\n 'has_names',\n 'heaviside',\n 'heaviside_',\n 'histc',\n 'histogram',\n 'hsplit',\n 'hypot',\n 'hypot_',\n 'i0',\n 'i0_',\n 'igamma',\n 'igamma_',\n 'igammac',\n 'igammac_',\n 'imag',\n 'index_add',\n 'index_add_',\n 'index_copy',\n 'index_copy_',\n 'index_fill',\n 'index_fill_',\n 'index_put',\n 'index_put_',\n 'index_reduce',\n 'index_reduce_',\n 'index_select',\n 'indices',\n 'inner',\n 'int',\n 'int_repr',\n 'inverse',\n 'ipu',\n 'is_coalesced',\n 'is_complex',\n 'is_conj',\n 'is_contiguous',\n 'is_cpu',\n 'is_cuda',\n 'is_distributed',\n 'is_floating_point',\n 'is_inference',\n 'is_ipu',\n 'is_leaf',\n 'is_meta',\n 'is_mkldnn',\n 'is_mps',\n 'is_neg',\n 'is_nested',\n 'is_nonzero',\n 'is_ort',\n 'is_pinned',\n 'is_quantized',\n 'is_same_size',\n 'is_set_to',\n 'is_shared',\n 'is_signed',\n 'is_sparse',\n 'is_sparse_csr',\n 'is_vulkan',\n 'is_xla',\n 'is_xpu',\n 'isclose',\n 'isfinite',\n 'isinf',\n 'isnan',\n 'isneginf',\n 'isposinf',\n 'isreal',\n 'istft',\n 'item',\n 'itemsize',\n 'kron',\n 'kthvalue',\n 'layout',\n 'lcm',\n 'lcm_',\n 'ldexp',\n 'ldexp_',\n 'le',\n 'le_',\n 'lerp',\n 'lerp_',\n 'less',\n 'less_',\n 'less_equal',\n 'less_equal_',\n 'lgamma',\n 'lgamma_',\n 'log',\n 'log10',\n 'log10_',\n 'log1p',\n 'log1p_',\n 'log2',\n 'log2_',\n 'log_',\n 'log_normal_',\n 'log_softmax',\n 'logaddexp',\n 'logaddexp2',\n 'logcumsumexp',\n 'logdet',\n 'logical_and',\n 'logical_and_',\n 'logical_not',\n 'logical_not_',\n 'logical_or',\n 'logical_or_',\n 'logical_xor',\n 'logical_xor_',\n 'logit',\n 'logit_',\n 'logsumexp',\n 'long',\n 'lstsq',\n 'lt',\n 'lt_',\n 'lu',\n 'lu_solve',\n 'mH',\n 'mT',\n 'map2_',\n 'map_',\n 'masked_fill',\n 'masked_fill_',\n 'masked_scatter',\n 'masked_scatter_',\n 'masked_select',\n 'matmul',\n 'matrix_exp',\n 'matrix_power',\n 'max',\n 'maximum',\n 'mean',\n 'median',\n 'min',\n 'minimum',\n 'mm',\n 'mode',\n 'moveaxis',\n 'movedim',\n 'msort',\n 'mul',\n 'mul_',\n 'multinomial',\n 'multiply',\n 'multiply_',\n 'mv',\n 'mvlgamma',\n 'mvlgamma_',\n 'name',\n 'names',\n 'nan_to_num',\n 'nan_to_num_',\n 'nanmean',\n 'nanmedian',\n 'nanquantile',\n 'nansum',\n 'narrow',\n 'narrow_copy',\n 'nbytes',\n 'ndim',\n 'ndimension',\n 'ne',\n 'ne_',\n 'neg',\n 'neg_',\n 'negative',\n 'negative_',\n 'nelement',\n 'new',\n 'new_empty',\n 'new_empty_strided',\n 'new_full',\n 'new_ones',\n 'new_tensor',\n 'new_zeros',\n 'nextafter',\n 'nextafter_',\n 'nonzero',\n 'nonzero_static',\n 'norm',\n 'normal_',\n 'not_equal',\n 'not_equal_',\n 'numel',\n 'numpy',\n 'orgqr',\n 'ormqr',\n 'outer',\n 'output_nr',\n 'permute',\n 'pin_memory',\n 'pinverse',\n 'polygamma',\n 'polygamma_',\n 'positive',\n 'pow',\n 'pow_',\n 'prelu',\n 'prod',\n 'put',\n 'put_',\n 'q_per_channel_axis',\n 'q_per_channel_scales',\n 'q_per_channel_zero_points',\n 'q_scale',\n 'q_zero_point',\n 'qr',\n 'qscheme',\n 'quantile',\n 'rad2deg',\n 'rad2deg_',\n 'random_',\n 'ravel',\n 'real',\n 'reciprocal',\n 'reciprocal_',\n 'record_stream',\n 'refine_names',\n 'register_hook',\n 'register_post_accumulate_grad_hook',\n 'reinforce',\n 'relu',\n 'relu_',\n 'remainder',\n 'remainder_',\n 'rename',\n 'rename_',\n 'renorm',\n 'renorm_',\n 'repeat',\n 'repeat_interleave',\n 'requires_grad',\n 'requires_grad_',\n 'reshape',\n 'reshape_as',\n 'resize',\n 'resize_',\n 'resize_as',\n 'resize_as_',\n 'resize_as_sparse_',\n 'resolve_conj',\n 'resolve_neg',\n 'retain_grad',\n 'retains_grad',\n 'roll',\n 'rot90',\n 'round',\n 'round_',\n 'row_indices',\n 'rsqrt',\n 'rsqrt_',\n 'scatter',\n 'scatter_',\n 'scatter_add',\n 'scatter_add_',\n 'scatter_reduce',\n 'scatter_reduce_',\n 'select',\n 'select_scatter',\n 'set_',\n 'sgn',\n 'sgn_',\n 'shape',\n 'share_memory_',\n 'short',\n 'sigmoid',\n 'sigmoid_',\n 'sign',\n 'sign_',\n 'signbit',\n 'sin',\n 'sin_',\n 'sinc',\n 'sinc_',\n 'sinh',\n 'sinh_',\n 'size',\n 'slice_scatter',\n 'slogdet',\n 'smm',\n 'softmax',\n 'solve',\n 'sort',\n 'sparse_dim',\n 'sparse_mask',\n 'sparse_resize_',\n 'sparse_resize_and_clear_',\n 'split',\n 'split_with_sizes',\n 'sqrt',\n 'sqrt_',\n 'square',\n 'square_',\n 'squeeze',\n 'squeeze_',\n 'sspaddmm',\n 'std',\n 'stft',\n 'storage',\n 'storage_offset',\n 'storage_type',\n 'stride',\n 'sub',\n 'sub_',\n 'subtract',\n 'subtract_',\n 'sum',\n 'sum_to_size',\n 'svd',\n 'swapaxes',\n 'swapaxes_',\n 'swapdims',\n 'swapdims_',\n 'symeig',\n 't',\n 't_',\n 'take',\n 'take_along_dim',\n 'tan',\n 'tan_',\n 'tanh',\n 'tanh_',\n 'tensor_split',\n 'tile',\n 'to',\n 'to_dense',\n 'to_mkldnn',\n 'to_padded_tensor',\n 'to_sparse',\n 'to_sparse_bsc',\n 'to_sparse_bsr',\n 'to_sparse_coo',\n 'to_sparse_csc',\n 'to_sparse_csr',\n 'tolist',\n 'topk',\n 'trace',\n 'transpose',\n 'transpose_',\n 'triangular_solve',\n 'tril',\n 'tril_',\n 'triu',\n 'triu_',\n 'true_divide',\n 'true_divide_',\n 'trunc',\n 'trunc_',\n 'type',\n 'type_as',\n 'unbind',\n 'unflatten',\n 'unfold',\n 'uniform_',\n 'unique',\n 'unique_consecutive',\n 'unsafe_chunk',\n 'unsafe_split',\n 'unsafe_split_with_sizes',\n 'unsqueeze',\n 'unsqueeze_',\n 'untyped_storage',\n 'values',\n 'var',\n 'vdot',\n 'view',\n 'view_as',\n 'vsplit',\n 'where',\n 'xlogy',\n 'xlogy_',\n 'xpu',\n 'zero_']"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(resnet50.fc.weight)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:11:05.882316321Z",
     "start_time": "2024-01-06T17:11:05.647452147Z"
    }
   },
   "id": "81056bd713d345b1",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "resnet50.fc.weight.set_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40539e7e6912c1c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"/home/doved/Downloads/checkpoint-86.pth.tar\")[\"state_dict\"]\n",
    "ckpt.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:12:05.045145922Z",
     "start_time": "2024-01-06T17:12:03.273744218Z"
    }
   },
   "id": "4e4e2bc6b00643a3",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 2048])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"fc.weight\"].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:12:29.764133031Z",
     "start_time": "2024-01-06T17:12:29.389839445Z"
    }
   },
   "id": "1302af4ecbd2ec7",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 2048])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"fc.weight\"][assoc_vec, :].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:13:11.454019355Z",
     "start_time": "2024-01-06T17:13:11.078309061Z"
    }
   },
   "id": "5168dbf810649ccb",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"fc.bias\"][assoc_vec].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:13:28.773431200Z",
     "start_time": "2024-01-06T17:13:28.024116659Z"
    }
   },
   "id": "877c926ec6e8c4fd",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.0081, -0.0097,  0.0011,  ..., -0.0133, -0.0127,  0.0085],\n        [-0.0019,  0.0140, -0.0250,  ..., -0.0080, -0.0202, -0.0104],\n        [ 0.0090, -0.0086, -0.0173,  ...,  0.0043, -0.0041,  0.0032],\n        ...,\n        [-0.0156,  0.0012,  0.0091,  ..., -0.0050, -0.0256, -0.0050],\n        [-0.0131,  0.0065, -0.0048,  ..., -0.0041,  0.0036,  0.0081],\n        [ 0.0165,  0.0112, -0.0049,  ...,  0.0074,  0.0196, -0.0051]],\n       requires_grad=True)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T19:00:50.533719347Z",
     "start_time": "2024-01-06T19:00:50.207178604Z"
    }
   },
   "id": "7d41f2ff0109e259",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0067, -0.0298, -0.0128,  ..., -0.0086, -0.0073, -0.0129],\n        [-0.0191, -0.0153, -0.0138,  ...,  0.0082, -0.0227,  0.0018],\n        [ 0.0037,  0.0036, -0.0062,  ..., -0.0047,  0.0087,  0.0090],\n        ...,\n        [-0.0155, -0.0111, -0.0111,  ...,  0.0053, -0.0109,  0.0098],\n        [-0.0113, -0.0032, -0.0249,  ..., -0.0084, -0.0237, -0.0171],\n        [-0.0189,  0.0148, -0.0050,  ..., -0.0014, -0.0113, -0.0154]])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc.weight.data.set_(resnet50.fc.weight.data[assoc_vec, :])\n",
    "# resnet50.fc.bias.data.set_(resnet50.fc.bias.data[assoc_vec])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T19:01:32.984376509Z",
     "start_time": "2024-01-06T19:01:32.551020071Z"
    }
   },
   "id": "6796eba359a254ec",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.0081, -0.0097,  0.0011,  ..., -0.0133, -0.0127,  0.0085],\n        [-0.0019,  0.0140, -0.0250,  ..., -0.0080, -0.0202, -0.0104],\n        [ 0.0090, -0.0086, -0.0173,  ...,  0.0043, -0.0041,  0.0032],\n        ...,\n        [-0.0156,  0.0012,  0.0091,  ..., -0.0050, -0.0256, -0.0050],\n        [-0.0131,  0.0065, -0.0048,  ..., -0.0041,  0.0036,  0.0081],\n        [ 0.0165,  0.0112, -0.0049,  ...,  0.0074,  0.0196, -0.0051]],\n       requires_grad=True)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T19:01:36.383121767Z",
     "start_time": "2024-01-06T19:01:36.204558169Z"
    }
   },
   "id": "799f69b75dcda320",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 2048])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc.weight.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T19:01:37.821604996Z",
     "start_time": "2024-01-06T19:01:37.808060495Z"
    }
   },
   "id": "839bcd8931c40211",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(assoc_vec)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T19:01:22.806854157Z",
     "start_time": "2024-01-06T19:01:22.604069368Z"
    }
   },
   "id": "d1ac60109ad2f880",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn.init\n",
    "\n",
    "torch.nn.init.uniform_()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9905fe74ca325290"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
