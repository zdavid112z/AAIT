{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "{'epoch': 21,\n 'global_step': 2046,\n 'pytorch-lightning_version': '2.1.2',\n 'state_dict': OrderedDict([('backbone.ensemble_weights', tensor([0.])),\n              ('backbone.models.0.model.conv1.weight',\n               tensor([[[[-1.6376e-04, -1.8623e-03,  7.1562e-03,  ..., -2.7018e-02,\n                           3.3938e-02, -8.0275e-03],\n                         [ 8.9681e-04, -3.8325e-03,  2.7680e-02,  ...,  9.7621e-02,\n                          -9.0392e-02,  2.5763e-03],\n                         [-3.7794e-03, -7.5868e-03, -1.3436e-03,  ...,  6.8120e-01,\n                          -6.8738e-01, -1.2337e-03],\n                         ...,\n                         [-3.2197e-03,  5.7158e-03,  1.6118e-03,  ...,  4.2116e-01,\n                          -4.7007e-01,  3.1200e-02],\n                         [-8.4122e-03,  7.4070e-05,  3.5489e-03,  ..., -6.4474e-03,\n                           2.6696e-02, -1.2521e-03],\n                         [ 7.8091e-03,  4.7772e-03,  1.2385e-02,  ...,  1.3241e-02,\n                           7.0468e-03, -2.0371e-02]],\n               \n                        [[ 9.3451e-03,  5.4781e-03,  2.8808e-03,  ..., -3.1501e-02,\n                           5.0757e-02,  4.1006e-03],\n                         [ 1.0620e-03,  1.2659e-02,  1.1428e-03,  ...,  1.7311e-01,\n                          -1.6216e-01, -1.6995e-02],\n                         [-7.0421e-03, -2.1304e-03, -3.0845e-02,  ...,  9.9819e-01,\n                          -9.6910e-01, -6.6042e-02],\n                         ...,\n                         [-1.7777e-02,  1.4217e-02, -9.7325e-03,  ...,  5.7668e-01,\n                          -5.9144e-01, -2.4378e-02],\n                         [ 4.1279e-03,  3.6059e-03,  1.8031e-03,  ...,  2.3965e-02,\n                          -2.3155e-02,  3.1190e-02],\n                         [-2.1811e-03,  1.3048e-02,  1.9922e-02,  ..., -1.8841e-02,\n                           1.0658e-02,  3.1295e-02]],\n               \n                        [[-9.5390e-03,  1.0844e-02, -1.0830e-02,  ...,  1.9806e-02,\n                           1.9233e-02, -2.1690e-02],\n                         [-4.0475e-03,  1.7358e-02,  1.4525e-03,  ...,  5.2333e-03,\n                           5.9786e-02, -8.8210e-03],\n                         [ 2.5184e-03,  3.7490e-03, -1.0697e-02,  ...,  1.4902e-01,\n                          -1.3224e-01,  4.8978e-02],\n                         ...,\n                         [ 3.9886e-03, -8.6837e-04, -9.4336e-03,  ...,  9.5077e-02,\n                          -7.8055e-02,  3.3841e-02],\n                         [ 6.6265e-03, -2.6358e-03,  6.2604e-03,  ...,  7.0954e-04,\n                           1.2405e-02, -1.7160e-03],\n                         [ 8.4979e-04, -1.1162e-02,  2.5281e-02,  ...,  6.2359e-03,\n                          -1.3319e-02, -1.5899e-02]]],\n               \n               \n                       [[[-2.6315e-03, -1.6801e-02,  1.9117e-01,  ..., -9.8463e-02,\n                           1.2924e-01, -4.8961e-02],\n                         [-7.3179e-02, -2.2558e-01,  1.3384e-01,  ..., -3.5997e-01,\n                           9.7212e-02, -1.9278e-01],\n                         [ 1.6561e-01,  3.8708e-02,  8.0405e-01,  ...,  5.5766e-02,\n                           7.3692e-01,  1.1547e-01],\n                         ...,\n                         [-2.1541e-02, -4.7143e-01,  3.4198e-01,  ..., -7.9442e-01,\n                           4.1759e-01, -1.8444e-01],\n                         [ 2.7118e-01, -7.2276e-02,  7.1888e-01,  ..., -1.1141e-01,\n                           6.8500e-01,  2.0914e-01],\n                         [-6.2434e-02, -3.1468e-01,  1.0358e-01,  ..., -6.3581e-01,\n                          -7.7553e-02, -1.4137e-01]],\n               \n                        [[-1.5638e-02, -1.6767e-02, -1.2180e-02,  ..., -3.5226e-02,\n                          -8.6545e-02,  2.1798e-02],\n                         [ 3.6655e-02, -4.0150e-02,  3.9027e-02,  ..., -2.7911e-02,\n                          -1.0162e-02,  6.4416e-02],\n                         [-1.7451e-02, -1.5295e-02,  1.0405e-02,  ..., -1.4205e-02,\n                          -2.0208e-02,  1.4872e-02],\n                         ...,\n                         [ 3.9155e-02, -6.6113e-02,  7.4964e-02,  ..., -3.5668e-02,\n                          -5.0753e-02,  1.0611e-01],\n                         [ 1.6081e-03,  1.6738e-02,  5.9064e-03,  ..., -1.9073e-02,\n                           3.9803e-02,  5.7382e-02],\n                         [-1.5692e-03, -2.8024e-02, -2.9106e-02,  ..., -7.2271e-02,\n                          -7.2621e-02,  4.1023e-04]],\n               \n                        [[ 1.0302e-02,  5.0874e-02, -1.8556e-01,  ...,  9.8409e-02,\n                          -3.0296e-02,  3.1480e-02],\n                         [ 6.9135e-02,  2.1107e-01, -1.2303e-01,  ...,  3.7013e-01,\n                          -7.9327e-02,  1.1486e-01],\n                         [-1.8992e-01, -1.0091e-02, -8.1873e-01,  ..., -1.0924e-01,\n                          -6.4503e-01, -1.4816e-01],\n                         ...,\n                         [-3.4080e-02,  4.6295e-01, -4.3971e-01,  ...,  6.9620e-01,\n                          -3.2638e-01,  5.5811e-02],\n                         [-2.4386e-01,  7.1167e-02, -6.7135e-01,  ...,  7.7208e-02,\n                          -6.2066e-01, -2.6901e-01],\n                         [ 4.3942e-02,  3.2373e-01, -1.1570e-01,  ...,  6.3025e-01,\n                           1.3371e-01,  1.2882e-01]]],\n               \n               \n                       [[[ 1.1432e-02, -1.9481e-02,  2.2709e-02,  ...,  4.3141e-03,\n                          -2.7294e-02,  2.0937e-02],\n                         [-9.0417e-03, -5.0404e-02,  4.2218e-02,  ..., -7.0066e-02,\n                          -2.4375e-02,  2.6073e-02],\n                         [-3.6233e-02,  2.4289e-02,  7.6348e-02,  ..., -1.2843e-02,\n                           4.2986e-02,  3.0368e-02],\n                         ...,\n                         [ 4.0508e-02, -3.5121e-02,  8.5845e-03,  ..., -8.0336e-02,\n                           1.0519e-01, -3.1368e-02],\n                         [ 2.2425e-02, -3.7577e-02,  3.7621e-02,  ...,  7.2265e-02,\n                           4.6264e-02, -2.6009e-02],\n                         [-7.4946e-03, -3.5865e-02, -2.5957e-02,  ...,  1.0043e-01,\n                          -5.1559e-02,  9.8508e-03]],\n               \n                        [[-4.3382e-03,  2.6330e-03,  1.2297e-02,  ...,  5.3991e-02,\n                          -1.5555e-02, -9.2307e-03],\n                         [-2.9231e-02,  1.0987e-03,  5.1195e-02,  ..., -5.0974e-02,\n                           8.3259e-03,  9.2403e-03],\n                         [-3.5705e-02,  1.3377e-01, -4.3367e-02,  ...,  8.2877e-02,\n                          -4.0846e-02,  7.1589e-03],\n                         ...,\n                         [ 6.9316e-02, -1.0622e-01, -5.4860e-02,  ..., -3.3133e-01,\n                           1.7437e-01,  7.3566e-03],\n                         [ 1.1674e-02, -1.1342e-01,  1.2858e-01,  ..., -1.1170e-01,\n                           1.8420e-01, -8.1315e-02],\n                         [-5.9987e-03, -3.3749e-02,  4.4477e-02,  ...,  1.0151e-01,\n                           2.0728e-02, -5.1241e-02]],\n               \n                        [[-1.1731e-02,  4.8514e-02, -1.9768e-02,  ...,  1.6896e-01,\n                           9.8939e-02, -6.3661e-02],\n                         [-1.8163e-02,  1.3647e-01, -1.0421e-01,  ...,  2.8137e-01,\n                           1.5811e-01, -9.7507e-02],\n                         [ 2.2971e-02,  1.8742e-01, -5.2640e-01,  ...,  8.0392e-01,\n                          -3.1212e-01, -1.7428e-01],\n                         ...,\n                         [-4.1354e-02, -4.3703e-01,  1.4202e-01,  ..., -1.1593e+00,\n                          -3.4697e-01,  2.7957e-01],\n                         [-8.3380e-02, -1.4990e-01,  8.3651e-01,  ..., -9.8742e-01,\n                           3.3407e-01,  8.6240e-02],\n                         [-6.3870e-03,  1.4795e-01,  3.5545e-01,  ..., -9.1997e-02,\n                           2.7802e-01, -1.8861e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-2.1559e-02, -2.1536e-02,  1.4240e-02,  ...,  6.5747e-02,\n                          -6.1537e-03, -3.7295e-02],\n                         [ 4.0940e-02,  2.6271e-02, -1.4604e-01,  ...,  3.1056e-02,\n                           1.7467e-02,  2.5050e-03],\n                         [-6.9702e-02, -1.3979e-01, -5.4597e-01,  ..., -9.4110e-01,\n                          -2.4263e-01, -3.1445e-02],\n                         ...,\n                         [ 3.3142e-02,  4.6692e-03, -1.5889e-02,  ...,  1.5493e-01,\n                           1.2204e-02,  2.2430e-02],\n                         [-1.6820e-02, -1.4333e-03, -6.7928e-02,  ..., -6.3776e-02,\n                          -3.7783e-02, -3.0395e-02],\n                         [ 1.5574e-02, -7.4459e-03, -3.7540e-02,  ...,  7.8265e-03,\n                          -1.2493e-02,  1.9394e-02]],\n               \n                        [[-1.0504e-02,  6.1390e-03, -2.9115e-04,  ...,  5.2443e-02,\n                           2.5422e-02, -2.9605e-02],\n                         [ 2.3704e-02, -4.6546e-02, -1.4278e-01,  ...,  5.0617e-02,\n                           3.5710e-02,  3.7785e-02],\n                         [-1.1744e-02, -3.8594e-02, -4.3042e-01,  ..., -8.3108e-01,\n                          -1.3122e-01, -9.8274e-03],\n                         ...,\n                         [-3.5383e-02, -3.4375e-02, -6.9060e-02,  ...,  1.4892e-02,\n                           2.3236e-02, -2.3629e-02],\n                         [ 1.3251e-03, -3.0696e-02, -5.3918e-02,  ..., -5.1744e-02,\n                           8.3262e-03,  2.6040e-02],\n                         [-9.2926e-03, -5.2613e-03, -1.4360e-02,  ..., -3.0879e-02,\n                          -1.5832e-02,  4.1736e-03]],\n               \n                        [[-6.0018e-03, -1.1008e-02,  5.9996e-03,  ..., -1.5655e-02,\n                          -3.0870e-02, -1.8405e-02],\n                         [-1.0347e-02, -2.1183e-02, -2.2098e-02,  ...,  7.8980e-02,\n                           5.5060e-02,  5.0023e-03],\n                         [ 2.2788e-02,  2.8678e-02, -1.0828e-01,  ..., -2.1594e-01,\n                           3.9227e-02,  6.1836e-05],\n                         ...,\n                         [-2.9468e-02, -7.3981e-02, -1.2707e-01,  ..., -7.4615e-02,\n                           4.7474e-03, -1.2613e-02],\n                         [-2.7751e-03,  1.8215e-02,  9.7580e-03,  ..., -5.1682e-02,\n                           3.3247e-02,  3.5549e-02],\n                         [ 6.9370e-03,  1.0314e-02,  4.9874e-03,  ...,  1.3288e-02,\n                           1.1762e-03, -2.0823e-02]]],\n               \n               \n                       [[[ 1.2787e-03, -4.0554e-02,  1.5307e-02,  ...,  4.8506e-02,\n                          -3.2362e-02,  2.1859e-02],\n                         [ 4.5470e-04, -1.6596e-02,  9.3957e-03,  ...,  4.2667e-02,\n                          -1.8653e-02,  1.3083e-02],\n                         [ 1.4582e-02, -1.0989e-01, -3.7453e-02,  ...,  7.5297e-02,\n                          -6.4321e-02, -3.7511e-02],\n                         ...,\n                         [-1.8780e-02, -2.1031e-01, -1.7234e-01,  ...,  2.9982e-01,\n                           2.0505e-02, -2.2981e-02],\n                         [-1.3939e-03, -2.8676e-01, -2.4719e-01,  ...,  3.2807e-01,\n                           8.4253e-02, -2.1909e-02],\n                         [-3.7981e-02, -2.2097e-01, -1.6051e-01,  ...,  2.5732e-01,\n                           8.9503e-02, -3.2050e-03]],\n               \n                        [[ 7.6881e-03,  1.9772e-02,  1.5429e-02,  ...,  1.3545e-02,\n                          -1.9886e-02, -5.9824e-03],\n                         [-1.9270e-03, -3.2746e-03,  2.5730e-02,  ..., -2.1208e-02,\n                           8.6760e-03,  2.0029e-03],\n                         [-6.7307e-03,  1.8135e-02,  2.4499e-02,  ...,  2.8666e-02,\n                           4.1783e-02, -1.8613e-03],\n                         ...,\n                         [-1.2733e-02,  1.4456e-01,  2.0509e-01,  ..., -1.0807e-01,\n                           5.5768e-02, -6.7771e-03],\n                         [ 2.9313e-03,  1.6698e-01,  1.9806e-01,  ..., -1.6177e-01,\n                           9.6759e-03, -3.7802e-02],\n                         [-2.0599e-02,  9.5314e-02,  1.9838e-01,  ..., -1.4510e-01,\n                           4.2967e-02, -3.0642e-02]],\n               \n                        [[ 2.0618e-02,  1.2752e-03, -1.8213e-02,  ..., -5.8605e-03,\n                           1.8649e-02, -2.3928e-02],\n                         [ 3.4474e-02, -2.2925e-02, -3.0582e-02,  ...,  5.1964e-03,\n                           1.7348e-03, -3.6005e-02],\n                         [ 2.1688e-02,  3.4021e-02,  8.3044e-02,  ..., -3.3401e-02,\n                           4.8975e-02,  4.8788e-03],\n                         ...,\n                         [-1.1479e-01,  8.4571e-01,  7.1931e-01,  ..., -8.7855e-01,\n                          -9.7554e-02,  1.2845e-01],\n                         [ 6.7402e-02,  9.0611e-01,  7.8816e-01,  ..., -1.0502e+00,\n                          -1.9090e-01,  1.4442e-01],\n                         [ 6.5247e-02,  5.4210e-01,  6.6150e-01,  ..., -7.9120e-01,\n                          -1.3924e-01,  6.4917e-02]]],\n               \n               \n                       [[[-4.8277e-04, -7.2104e-03,  1.3232e-02,  ..., -1.1959e-02,\n                           3.8941e-03, -1.2278e-03],\n                         [-1.2053e-02, -1.0203e-02, -2.0181e-02,  ...,  7.5179e-03,\n                           3.3369e-02, -3.1610e-02],\n                         [ 2.8372e-02,  2.4637e-02, -6.4287e-04,  ...,  4.9105e-01,\n                           6.3267e-01,  1.7061e-01],\n                         ...,\n                         [ 1.4310e-02,  2.7793e-03,  1.5764e-02,  ...,  3.3596e-02,\n                           1.2221e-02,  2.1215e-02],\n                         [-2.2242e-02,  1.8349e-03, -1.1377e-02,  ...,  1.9738e-03,\n                           2.8709e-02, -1.5265e-02],\n                         [-2.6331e-03, -5.6906e-03,  1.1781e-02,  ...,  1.0987e-02,\n                           8.9726e-03, -1.3359e-02]],\n               \n                        [[ 2.3690e-02,  1.4813e-02,  5.0973e-03,  ..., -6.6780e-02,\n                          -3.0339e-02,  7.2553e-03],\n                         [-8.4789e-03, -6.3468e-03, -1.2256e-02,  ...,  9.3074e-02,\n                           7.7314e-02,  2.0474e-02],\n                         [-1.9717e-03, -1.3631e-02, -7.0381e-02,  ...,  1.3826e+00,\n                           1.5557e+00,  4.5373e-01],\n                         ...,\n                         [ 3.0534e-02,  1.5357e-02,  1.4703e-02,  ..., -8.8083e-02,\n                          -8.8893e-02, -1.3938e-02],\n                         [-2.0674e-02, -2.9348e-03,  5.1977e-03,  ...,  3.3041e-02,\n                           8.0221e-03,  2.0935e-02],\n                         [-5.2290e-03,  1.5459e-02, -4.3142e-03,  ...,  4.6626e-03,\n                           1.6312e-02,  9.9830e-03]],\n               \n                        [[ 4.7784e-03,  4.8235e-03,  9.8835e-04,  ..., -1.5608e-02,\n                          -1.8413e-02,  1.3889e-02],\n                         [-4.7439e-03,  7.7348e-03, -3.5677e-03,  ..., -2.1269e-03,\n                          -1.1912e-02, -1.4953e-02],\n                         [ 2.7751e-02,  1.9512e-02,  2.4729e-03,  ...,  6.2599e-01,\n                           8.3081e-01,  2.9583e-01],\n                         ...,\n                         [ 1.2290e-02,  1.7363e-02,  1.1903e-03,  ...,  2.0253e-02,\n                          -2.2035e-02,  1.1522e-03],\n                         [-8.9418e-03, -6.0125e-03, -2.7675e-03,  ...,  5.4208e-03,\n                          -2.1569e-02, -2.7943e-02],\n                         [ 9.0843e-03, -3.6432e-04,  2.2002e-02,  ...,  5.9915e-03,\n                           1.0791e-02, -5.6581e-03]]]])),\n              ('backbone.models.0.model.bn1.weight',\n               tensor([0.7074, 0.4463, 0.4471, 0.8742, 0.6727, 0.9520, 0.4764, 0.4371, 0.5962,\n                       0.6327, 0.9743, 0.5047, 0.4490, 0.6642, 0.4689, 0.4933, 0.4201, 0.5223,\n                       0.4925, 0.4682, 0.5463, 0.6056, 1.0126, 0.5790, 1.6378, 0.4777, 0.4377,\n                       1.2377, 0.4293, 0.4433, 0.4799, 0.7461, 0.4769, 0.6524, 0.6479, 0.9938,\n                       0.6849, 0.6120, 0.6671, 0.4432, 0.6997, 0.6403, 0.7546, 1.9113, 0.5025,\n                       0.4876, 2.5323, 0.5205, 0.6664, 1.2963, 0.9907, 0.7349, 0.5309, 0.5850,\n                       0.6018, 0.7061, 0.9654, 0.5425, 2.8937, 0.4455, 0.6105, 0.7104, 0.7010,\n                       0.8146])),\n              ('backbone.models.0.model.bn1.bias',\n               tensor([ 0.0420,  0.6573,  0.9644,  0.4175,  1.0208,  4.2969,  0.9593,  1.0333,\n                       -0.0077,  0.3171,  4.0162,  1.0205,  0.9540,  0.1749,  0.5766,  0.8934,\n                        0.9848,  0.4998,  1.7843,  0.8755,  0.5629, -0.0089,  4.3795,  0.3657,\n                        2.7031,  0.7181,  0.8810,  2.3149,  1.0505,  0.8149,  0.9945,  0.2019,\n                        0.8905,  0.2055,  0.0928,  3.6111,  0.2958,  0.4251,  0.1112,  1.1033,\n                        0.2782,  0.0808,  0.1489,  4.1931,  0.9396,  0.9535,  5.2943,  0.8355,\n                        0.9526,  2.6713,  3.1706,  0.1579,  0.4930,  0.4835,  0.3172,  0.1232,\n                        2.4044,  0.9071,  7.0975,  1.0182,  0.8043,  0.0509,  0.1474,  0.0399])),\n              ('backbone.models.0.model.bn1.running_mean',\n               tensor([-1.6567e-02,  1.6244e-03,  2.2600e-03, -4.4520e-01,  8.4950e-02,\n                       -1.1371e-01, -5.6879e-03, -2.4969e-04,  3.1149e-03, -7.3315e-03,\n                       -1.7742e-01,  1.5040e-02,  1.0405e-02, -2.4475e-02, -1.2237e-02,\n                       -7.4392e-03,  6.2130e-03,  9.7974e-03,  2.1615e-03,  3.4713e-03,\n                       -2.0200e-02, -3.1966e-03,  8.8944e-02, -2.7532e-02, -3.8798e-01,\n                        4.6149e-03,  1.3992e-02, -2.9662e-02,  3.6416e-03,  6.8166e-03,\n                       -9.7705e-03,  3.1004e-02, -9.2301e-03,  1.7724e-02,  9.7891e-04,\n                        1.0837e-01, -3.2747e-02, -3.4999e-02,  4.1541e-02,  6.8314e-03,\n                        8.6866e-02, -5.2192e-03, -2.5269e-02,  3.9886e-01,  9.0313e-03,\n                       -2.3197e-04, -5.8874e-01,  3.9115e-03,  1.3270e-01, -2.9335e-01,\n                        2.7311e-01, -2.9426e-02,  1.4246e-02, -1.7510e-02, -3.2232e-02,\n                        2.7131e-02,  1.2798e-02, -2.7795e-06,  7.2629e-01,  2.4115e-02,\n                        6.7929e-03,  8.3500e-03,  3.0907e-02, -6.9532e-03])),\n              ('backbone.models.0.model.bn1.running_var',\n               tensor([9.5056e+00, 2.9460e-01, 2.9481e+00, 3.1941e+01, 1.1507e+01, 1.3691e+01,\n                       1.4281e+00, 3.9162e-02, 8.3963e+00, 1.2665e+01, 8.8712e+00, 1.9934e+00,\n                       5.0945e+00, 4.3438e+00, 2.0571e-01, 6.0357e+00, 5.4642e+00, 2.2366e+00,\n                       5.0385e-01, 1.2956e-01, 6.8601e-01, 8.7263e+00, 5.7798e+00, 1.5104e+00,\n                       4.0733e+01, 6.4059e+00, 3.1486e-01, 3.1335e+01, 5.4693e+00, 1.3319e-01,\n                       4.4187e+00, 1.1336e+01, 1.3230e+00, 2.0869e+00, 2.6993e+00, 1.0732e+01,\n                       2.4499e+01, 9.6632e+00, 9.7201e+00, 5.4637e+00, 2.1985e+01, 1.9474e+00,\n                       1.6734e+01, 4.4842e+01, 4.1156e+00, 7.2454e-02, 1.7613e+02, 7.0846e+00,\n                       1.5068e+01, 6.0165e+01, 1.2537e+01, 1.1153e+01, 6.5767e+00, 8.4093e+00,\n                       1.1384e+01, 1.2223e+01, 1.3084e+01, 8.0647e+00, 2.3955e+02, 1.3219e+00,\n                       1.1004e+01, 1.0716e+01, 7.3014e+00, 1.2803e+01])),\n              ('backbone.models.0.model.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer1.0.conv1.weight',\n               tensor([[[[ 0.0569]],\n               \n                        [[ 0.1948]],\n               \n                        [[ 0.0514]],\n               \n                        ...,\n               \n                        [[ 0.0189]],\n               \n                        [[ 0.0850]],\n               \n                        [[ 0.0188]]],\n               \n               \n                       [[[-0.0480]],\n               \n                        [[ 0.1260]],\n               \n                        [[-0.0223]],\n               \n                        ...,\n               \n                        [[-0.0620]],\n               \n                        [[ 0.0428]],\n               \n                        [[ 0.0114]]],\n               \n               \n                       [[[-0.0241]],\n               \n                        [[ 0.1177]],\n               \n                        [[ 0.4235]],\n               \n                        ...,\n               \n                        [[ 0.0753]],\n               \n                        [[-0.0048]],\n               \n                        [[ 0.0415]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.1215]],\n               \n                        [[ 0.0531]],\n               \n                        [[-0.1862]],\n               \n                        ...,\n               \n                        [[-0.0491]],\n               \n                        [[ 0.0102]],\n               \n                        [[-0.3008]]],\n               \n               \n                       [[[ 0.1654]],\n               \n                        [[-0.0522]],\n               \n                        [[ 0.0015]],\n               \n                        ...,\n               \n                        [[ 0.1039]],\n               \n                        [[-0.2222]],\n               \n                        [[-0.4162]]],\n               \n               \n                       [[[-0.0853]],\n               \n                        [[-0.1456]],\n               \n                        [[-0.0786]],\n               \n                        ...,\n               \n                        [[-0.1842]],\n               \n                        [[-0.1600]],\n               \n                        [[-0.2255]]]])),\n              ('backbone.models.0.model.layer1.0.bn1.weight',\n               tensor([0.8885, 0.7514, 0.4694, 0.4551, 1.1946, 1.7072, 0.7621, 0.3734, 1.6303,\n                       0.9977, 1.0930, 0.5050, 1.4941, 0.9587, 1.1218, 1.2596, 0.5061, 0.4615,\n                       1.9150, 0.4512, 1.3256, 0.8449, 0.4398, 1.0013, 1.4928, 1.1326, 0.5439,\n                       0.3705, 0.8324, 0.5480, 1.4318, 0.4632, 0.9379, 0.4603, 0.7897, 0.3886,\n                       1.1462, 0.9739, 1.3552, 0.3067, 0.6446, 0.5051, 0.6948, 0.8372, 0.5678,\n                       1.0145, 0.9268, 0.4878, 0.6804, 0.3812, 0.9944, 0.9552, 0.4567, 1.0325,\n                       0.4501, 0.6555, 1.0115, 0.6047, 0.8755, 0.3394, 0.3803, 1.4998, 1.2057,\n                       1.0776])),\n              ('backbone.models.0.model.layer1.0.bn1.bias',\n               tensor([-0.1574,  0.4303,  0.2361,  0.4943, -0.8528, -2.6573, -0.1544,  0.5962,\n                       -1.6105, -0.4142,  2.2320,  0.4227, -2.1374,  0.0967, -0.9125, -0.5859,\n                        0.2147,  0.8167, -1.3873,  0.7450, -0.6693,  0.6193,  0.5261, -0.3399,\n                       -0.9694, -0.3999,  0.1194,  0.4237,  0.1262,  0.3992, -1.6613,  0.6536,\n                       -0.3992,  0.3595, -0.2171,  0.5109, -0.3187, -0.1390, -0.8218,  0.3607,\n                       -0.1377,  0.7289, -0.1166, -0.2399,  0.6882,  0.1698,  0.1426,  0.0231,\n                       -0.1808,  0.3783, -0.0614, -0.1086,  0.1597,  2.3088,  0.0370, -0.0313,\n                       -0.2166,  0.0333, -0.0319,  0.2112,  0.1582, -0.9496, -1.0439, -0.8848])),\n              ('backbone.models.0.model.layer1.0.bn1.running_mean',\n               tensor([ -3.1771,  -5.4296,  -2.4553,  -7.4902,   7.9023, -17.3289,   0.2677,\n                         6.0727,   1.1467,  -4.8278, -13.8301,  -0.3410,  -0.6742, -12.2657,\n                         3.2644,  -0.4673,  -2.7777,   8.1112,  -1.5045,   7.5566,  -0.2033,\n                        10.7955,  -4.2650,  -2.2162,  -0.6400, -15.4413,   0.3189,   1.1176,\n                        -5.0336,  -5.2873,   5.4973,   1.3054,  -7.3905,   0.6191,  -2.8979,\n                         2.0994,  -1.9120,  -0.5216,  -5.1000,   1.2380,   1.1290,  12.2862,\n                         0.4798,  -1.9085,   7.5241, -10.0417,  -2.9425,  -9.0092,  -1.1108,\n                         3.2959,  -8.2722,  -1.3778,   0.7839, -13.9926,   0.9840,  -0.9412,\n                        -0.7926,  -2.8307,   0.2905,   4.1465,   2.3533,  -2.8696,  -4.9518,\n                       -12.2679])),\n              ('backbone.models.0.model.layer1.0.bn1.running_var',\n               tensor([ 1.0541,  7.9477,  0.5308,  3.9563,  8.0220, 10.9965,  1.3043,  0.4674,\n                        5.0499,  1.4397, 62.6463,  1.9277,  2.5951,  1.4601,  6.6864,  2.8574,\n                        0.9365,  5.7678,  3.5093,  2.4264,  3.7738,  8.2112,  0.3330,  2.3295,\n                        3.4959,  1.3499,  0.6098,  1.4947,  6.3044,  1.7502,  7.2542,  0.6411,\n                        3.3504,  1.2846,  1.1599,  1.6618,  2.2573,  1.6540,  3.1601,  0.6334,\n                        2.6022,  5.5682,  3.9216,  1.0049,  2.2326,  7.6148,  9.4577,  2.9583,\n                        1.0512,  1.3811,  6.6907,  2.7381,  0.9943, 51.6155,  0.9213,  1.3202,\n                        2.6715,  0.6813,  2.1987,  0.4330,  0.3638,  2.9082,  1.2996,  6.1125])),\n              ('backbone.models.0.model.layer1.0.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer1.0.conv2.weight',\n               tensor([[[[-2.0373e-02,  7.4928e-02,  4.4418e-02],\n                         [ 7.5320e-02,  1.0057e-02, -1.0660e-01],\n                         [-3.8299e-02, -9.4022e-02, -7.3655e-02]],\n               \n                        [[-3.2072e-02,  1.1060e-02, -4.5017e-02],\n                         [ 8.7903e-02,  1.0985e-01,  1.2449e-01],\n                         [ 1.4675e-02, -1.5141e-01, -4.4216e-02]],\n               \n                        [[-9.5296e-03,  4.8101e-02,  1.0651e-02],\n                         [-6.8134e-02,  9.9649e-02, -6.8060e-03],\n                         [-6.7908e-02, -3.3115e-03, -7.7496e-02]],\n               \n                        ...,\n               \n                        [[ 8.2827e-02,  7.6774e-02,  1.1286e-01],\n                         [-5.2245e-02, -1.4110e-02,  4.7032e-02],\n                         [-3.4226e-02, -2.7428e-02, -6.0319e-02]],\n               \n                        [[ 6.8131e-02,  5.2236e-02,  2.9728e-03],\n                         [-3.1662e-02,  2.0998e-02, -4.9530e-02],\n                         [-3.0448e-02, -1.2522e-01, -8.1875e-02]],\n               \n                        [[ 5.7448e-02,  2.3060e-01,  1.0295e-01],\n                         [ 4.7879e-02,  2.4030e-01,  6.7497e-02],\n                         [-1.3145e-01, -2.5423e-01, -1.2891e-01]]],\n               \n               \n                       [[[ 1.0820e-02,  2.9475e-02,  4.1386e-02],\n                         [-3.6758e-02, -7.0819e-02,  9.0606e-02],\n                         [-2.6392e-02, -1.0368e-02, -5.2419e-02]],\n               \n                        [[-9.3451e-02,  5.4940e-02,  5.4773e-02],\n                         [-1.8095e-01,  6.9254e-02,  1.0042e-01],\n                         [-7.3319e-02,  1.6647e-04,  7.5318e-02]],\n               \n                        [[-2.3401e-02,  4.5843e-02, -2.8233e-02],\n                         [ 6.1255e-02,  3.9821e-02, -7.1281e-02],\n                         [ 4.1823e-04,  3.9272e-02,  1.9052e-02]],\n               \n                        ...,\n               \n                        [[ 1.6526e-02,  3.9149e-04, -2.3960e-02],\n                         [ 3.6356e-02,  7.9006e-02, -9.0337e-02],\n                         [-2.5185e-02,  2.4094e-02,  1.0238e-02]],\n               \n                        [[-4.2153e-02,  3.9251e-03,  3.7581e-02],\n                         [ 5.6275e-02, -4.3146e-02, -5.1834e-02],\n                         [ 9.2709e-03, -1.1262e-02, -2.5463e-02]],\n               \n                        [[ 1.3113e-02, -7.4767e-02, -7.1171e-02],\n                         [ 1.8733e-01,  3.2735e-02, -1.6564e-01],\n                         [ 6.7468e-02, -2.0685e-02, -6.9633e-02]]],\n               \n               \n                       [[[-3.5461e-02,  1.7058e-03, -1.9230e-02],\n                         [ 3.7856e-04,  1.2789e-01, -3.3214e-02],\n                         [-5.5694e-03,  1.4146e-02, -4.7213e-02]],\n               \n                        [[-6.4386e-02,  3.0812e-02, -1.8057e-02],\n                         [-5.7474e-02,  3.4743e-02, -2.5004e-05],\n                         [-8.1822e-02,  7.4736e-03, -1.0946e-02]],\n               \n                        [[-4.2258e-02, -2.7234e-02, -7.0568e-03],\n                         [-5.8740e-02,  1.0302e-02, -3.4507e-03],\n                         [-1.0291e-02,  2.6310e-02,  2.5421e-02]],\n               \n                        ...,\n               \n                        [[-4.5168e-02,  1.7658e-02, -9.4619e-04],\n                         [ 3.5653e-02,  2.1936e-01,  3.0168e-02],\n                         [-1.8155e-02,  6.4995e-02, -1.2111e-03]],\n               \n                        [[ 2.7112e-03,  3.0596e-02,  5.3669e-02],\n                         [-1.4800e-02,  9.3021e-02,  8.5890e-03],\n                         [-2.7303e-02,  1.5330e-02, -8.6886e-03]],\n               \n                        [[-2.3321e-02,  6.9650e-02,  7.1214e-02],\n                         [ 3.4974e-02,  2.0575e-01,  1.3275e-01],\n                         [ 3.6108e-02,  1.1153e-01,  9.9375e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-5.3193e-02, -3.9053e-02,  1.0119e-01],\n                         [-4.9712e-02, -1.7598e-01, -1.4826e-02],\n                         [ 1.3962e-01,  2.6157e-01, -1.9903e-02]],\n               \n                        [[-6.5294e-02, -9.9856e-02, -8.0766e-02],\n                         [ 1.2241e-01,  1.0207e-01,  7.0605e-02],\n                         [ 3.9537e-02, -6.4206e-02,  1.0436e-01]],\n               \n                        [[ 5.2533e-02,  2.2059e-02, -3.6942e-03],\n                         [ 2.3128e-02,  4.3041e-03, -6.8737e-02],\n                         [ 4.0806e-02, -4.1179e-02, -4.6739e-02]],\n               \n                        ...,\n               \n                        [[-1.3600e-02, -4.5167e-02,  3.2092e-02],\n                         [-9.6947e-02,  2.0563e-01, -8.3113e-02],\n                         [-4.8082e-02,  6.0221e-02, -4.4778e-02]],\n               \n                        [[ 1.0871e-01, -1.1965e-02,  5.5300e-02],\n                         [-1.1483e-01, -1.0447e-01, -2.5460e-02],\n                         [-4.4244e-02,  9.1969e-02, -2.2719e-02]],\n               \n                        [[ 7.2056e-02, -5.7013e-02,  3.7924e-02],\n                         [ 3.1557e-02, -2.2732e-01, -5.0739e-02],\n                         [ 8.9445e-02,  2.2137e-01,  6.4813e-02]]],\n               \n               \n                       [[[ 1.7086e-02,  6.7037e-02,  1.5403e-03],\n                         [-9.2611e-03, -5.2089e-02,  8.1578e-02],\n                         [ 2.4622e-04,  6.9476e-02,  5.1256e-02]],\n               \n                        [[-6.9193e-02, -1.8782e-01,  3.1556e-01],\n                         [-1.0320e-01, -6.3511e-01,  8.2320e-01],\n                         [ 4.0153e-03, -2.4353e-01,  3.8054e-01]],\n               \n                        [[ 3.3895e-02, -6.8912e-02, -3.2101e-03],\n                         [ 1.2807e-02, -4.1823e-02, -1.4174e-01],\n                         [-2.4007e-02,  9.3753e-02, -3.2813e-02]],\n               \n                        ...,\n               \n                        [[ 4.3104e-02,  6.4835e-02,  5.6216e-02],\n                         [ 1.4539e-02,  2.3818e-02,  9.7121e-02],\n                         [ 7.6300e-03,  2.0184e-02,  6.9792e-02]],\n               \n                        [[-7.2993e-02, -5.6372e-03,  8.9066e-02],\n                         [ 4.9834e-03, -3.7068e-02, -4.1151e-02],\n                         [-4.7870e-03, -3.4633e-02,  6.3593e-03]],\n               \n                        [[ 7.3515e-02,  7.3245e-02, -9.9439e-03],\n                         [ 4.3003e-02,  9.5943e-02, -1.1510e-02],\n                         [ 1.0106e-01,  2.3625e-02, -2.5520e-02]]],\n               \n               \n                       [[[-1.0941e-02, -1.9435e-02,  7.6637e-02],\n                         [-2.0317e-02,  2.9331e-01,  3.4858e-02],\n                         [ 3.2828e-02,  8.8318e-02, -3.2483e-03]],\n               \n                        [[ 3.7666e-02,  5.5635e-02,  1.7909e-02],\n                         [-7.2171e-02, -4.8260e-02, -8.4161e-02],\n                         [ 8.9526e-03, -2.1431e-02, -2.4974e-02]],\n               \n                        [[ 4.5233e-02,  3.0263e-02,  8.1548e-02],\n                         [-2.1307e-02, -2.6961e-02, -2.4806e-01],\n                         [-2.1353e-02, -7.8178e-02, -6.4845e-02]],\n               \n                        ...,\n               \n                        [[-4.0208e-02, -1.1051e-01, -5.7255e-02],\n                         [ 6.6015e-03, -4.1572e-02, -5.4165e-02],\n                         [ 1.7063e-01,  8.7858e-02, -9.9134e-03]],\n               \n                        [[-6.6807e-02,  1.2867e-01, -1.2312e-01],\n                         [ 3.2801e-02,  2.8287e-02,  1.2240e-02],\n                         [ 1.1061e-01, -5.4927e-02, -8.4100e-03]],\n               \n                        [[-3.0698e-02, -8.2950e-02,  2.3295e-02],\n                         [-1.9651e-02,  9.6666e-03,  9.9292e-02],\n                         [-6.5507e-02, -3.6672e-02,  7.0393e-02]]]])),\n              ('backbone.models.0.model.layer1.0.bn2.weight',\n               tensor([0.5345, 0.4969, 0.5886, 0.7713, 0.3397, 0.3407, 0.6342, 0.8602, 0.5169,\n                       0.4372, 0.9552, 0.4947, 0.3253, 0.3489, 0.6682, 0.8435, 0.3987, 0.4936,\n                       0.8584, 0.2884, 0.4857, 0.6695, 0.6467, 2.3470, 0.5019, 0.3693, 0.6991,\n                       0.4545, 0.4812, 0.7428, 0.5470, 0.5712, 0.7205, 0.9584, 0.5413, 0.7279,\n                       0.9599, 0.6460, 0.6634, 0.3703, 0.7499, 0.5426, 0.9457, 0.7103, 0.8546,\n                       2.0849, 0.4741, 0.4736, 0.6825, 0.4617, 0.6611, 0.4533, 0.4912, 0.5474,\n                       0.5150, 0.6968, 0.3216, 0.7275, 0.3150, 0.6055, 0.8303, 0.5680, 0.8547,\n                       2.4759])),\n              ('backbone.models.0.model.layer1.0.bn2.bias',\n               tensor([ 3.8263e-01,  5.1792e-02, -5.9537e-01,  2.4937e-02,  1.2696e+00,\n                        1.1948e+00,  5.1170e-01,  6.3663e-03, -1.1654e-01,  1.4810e+00,\n                        1.8495e+00,  1.0413e+00,  1.1302e+00,  1.1922e+00,  2.1807e-01,\n                        5.0111e-02,  1.4816e+00,  1.4657e-01,  7.6865e-02,  1.2437e+00,\n                       -9.6714e-03, -9.1254e-02,  3.2756e-01,  4.9507e+00, -5.1284e-02,\n                        1.2697e+00, -3.4996e-03,  3.0949e-01,  6.5118e-01,  1.4963e-01,\n                       -1.1044e-01, -8.9320e-02,  1.3204e-01, -1.0275e+00, -2.4327e-03,\n                        9.6528e-02, -7.0302e-01, -6.6748e-02, -4.2984e-01,  1.2476e+00,\n                        1.6817e+00,  2.5893e-01,  2.3643e+00,  2.0298e-02, -9.7594e-01,\n                        4.7010e+00,  5.1963e-01, -1.7293e+00, -1.0009e-01, -1.3032e-01,\n                       -9.7084e-02,  1.4493e-02,  2.1377e-01, -4.0904e-02,  3.8319e-01,\n                        1.9475e+00,  1.2101e+00,  1.5641e-01,  1.0670e+00,  4.0417e-02,\n                       -1.9352e+00,  3.6821e-01,  2.4801e-01,  5.4590e+00])),\n              ('backbone.models.0.model.layer1.0.bn2.running_mean',\n               tensor([ 2.6895, -1.0488,  1.0473,  1.7321,  0.9085,  0.0401, -0.4314,  2.5653,\n                        0.8038, -1.4937,  0.9771,  3.2459,  0.1424, -2.3407,  1.3545,  2.2077,\n                        0.6534,  1.5099,  1.5851,  0.4411,  1.4246,  1.0263,  2.1393,  1.4554,\n                       -0.2511,  1.1033,  2.6635,  4.4812, -1.1162,  2.7030, -0.1007,  0.7040,\n                        2.0371, -4.4043, -3.1202,  2.5061, -7.7225,  0.4451, -1.2772, -0.4350,\n                       -0.7421,  1.1215, -1.0395,  1.3392, -4.3810,  1.0988, -1.0819, -0.5876,\n                        1.3817, -1.8456,  0.8138,  2.4031,  1.9370, -5.1537,  3.8542, -1.4150,\n                       -0.2063,  1.8254, -1.3348, -4.8236, -2.5772,  0.7061,  2.2053,  1.4747])),\n              ('backbone.models.0.model.layer1.0.bn2.running_var',\n               tensor([ 4.6226,  3.4270,  2.3488,  3.5956,  2.4868,  1.2700,  3.6068,  4.5219,\n                        1.0785,  2.9166,  8.3687,  7.6783,  1.1246,  3.0466,  8.1712,  4.3833,\n                        3.8818,  1.9476,  5.8611,  2.5560,  1.6194,  3.5531,  6.3769, 28.6610,\n                        1.2236,  2.0626,  2.7385,  1.7960,  2.6061, 10.2709,  1.3479,  1.4825,\n                        7.8237,  3.0816,  1.7540,  3.6817,  6.0123,  3.0482,  2.9879,  1.3285,\n                        3.6267,  3.1519,  6.0840,  2.7511,  1.7641, 29.9410,  5.5685,  0.0682,\n                        3.1188,  1.1123,  2.6899,  4.1226,  2.4160,  2.1985,  4.6132,  4.1350,\n                        1.8003, 10.4529,  1.0254,  4.5719,  0.4711,  4.3529,  5.4256, 38.4701])),\n              ('backbone.models.0.model.layer1.0.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer1.0.conv3.weight',\n               tensor([[[[-0.0756]],\n               \n                        [[-0.0742]],\n               \n                        [[-0.1921]],\n               \n                        ...,\n               \n                        [[ 0.0344]],\n               \n                        [[-0.0447]],\n               \n                        [[ 0.1679]]],\n               \n               \n                       [[[ 0.0231]],\n               \n                        [[ 0.1673]],\n               \n                        [[-0.0375]],\n               \n                        ...,\n               \n                        [[-0.0484]],\n               \n                        [[ 0.0280]],\n               \n                        [[-0.3814]]],\n               \n               \n                       [[[-0.0600]],\n               \n                        [[-0.0860]],\n               \n                        [[-0.2505]],\n               \n                        ...,\n               \n                        [[-0.1067]],\n               \n                        [[-0.0993]],\n               \n                        [[-0.1914]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0409]],\n               \n                        [[ 0.0243]],\n               \n                        [[-0.0779]],\n               \n                        ...,\n               \n                        [[-0.0554]],\n               \n                        [[-0.1117]],\n               \n                        [[ 0.1479]]],\n               \n               \n                       [[[ 0.1463]],\n               \n                        [[-0.1563]],\n               \n                        [[-0.0063]],\n               \n                        ...,\n               \n                        [[ 0.1466]],\n               \n                        [[-0.0833]],\n               \n                        [[ 0.4541]]],\n               \n               \n                       [[[ 0.0095]],\n               \n                        [[-0.0470]],\n               \n                        [[-0.0121]],\n               \n                        ...,\n               \n                        [[-0.0096]],\n               \n                        [[ 0.0029]],\n               \n                        [[ 0.0989]]]])),\n              ('backbone.models.0.model.layer1.0.bn3.weight',\n               tensor([-1.0473,  1.2022,  0.5879,  0.9840,  1.1350, -1.5051,  0.9814,  1.0513,\n                       -1.2510, -1.3611,  0.5808,  0.8527,  0.9991,  1.4972,  1.3195,  1.1104,\n                       -1.2931,  1.3616, -0.2268,  0.8450,  0.6177, -1.3174, -0.8382,  0.6960,\n                       -1.2521, -1.1875, -0.9911, -0.9698,  1.7810, -1.0389, -0.7328,  1.4917,\n                        1.3150,  1.4452,  1.0240, -1.1163,  0.3674, -1.3004,  1.3256, -0.9409,\n                       -0.5999, -1.0750,  0.9629,  0.9315,  1.1442,  0.7836, -1.5137,  0.6216,\n                       -1.3156, -1.6052, -0.9283, -0.5702,  1.3669,  1.2796, -0.3867,  1.2176,\n                       -0.8573,  1.3484, -1.3939,  0.6693, -0.6862,  0.9673, -0.9742,  0.7584,\n                        1.7479,  1.1551, -0.5531, -1.3111, -1.5500,  1.4628, -1.2451, -1.3360,\n                        0.8597, -0.7763, -0.9283, -1.4403,  1.3698, -1.1787, -0.8949,  1.0943,\n                       -0.8299, -0.3634,  1.2915, -1.1277,  1.3685,  1.4058, -1.1533, -1.3362,\n                       -0.9753, -1.3563,  1.0752,  0.8588, -1.3411, -1.3016, -0.3534, -0.7689,\n                       -1.5005, -1.3415, -1.3373,  0.9600,  1.1435,  1.5146,  1.0934, -1.2726,\n                       -0.5153,  1.1158,  1.2286,  0.8180, -1.2040,  1.4338,  1.8064, -0.8962,\n                        1.2672,  1.6666, -1.5030,  0.3593, -0.9672,  1.1714,  1.0160,  1.5153,\n                        1.5797,  0.7845, -0.7631, -0.6727,  1.9195, -1.3557, -1.5638, -1.4884,\n                        1.0388,  1.3930, -1.2710,  0.8192, -1.4886,  1.1041,  0.6202, -0.9542,\n                       -1.0545, -1.1350,  0.9761, -0.2086,  1.0430, -0.7898,  0.5827,  1.4019,\n                       -1.3520, -1.2341,  1.0538, -1.0635, -1.3315,  1.1251, -1.0494, -0.6742,\n                       -0.5921,  1.5213, -0.8176, -1.6819,  0.4966, -1.2958, -1.7050, -1.1240,\n                       -1.3926,  0.6690, -0.5386,  1.4417,  1.3200,  1.6726,  1.4899,  1.0756,\n                        0.8934, -1.0501, -0.0121,  1.3099, -0.9768, -0.8933,  1.5917, -0.9664,\n                        0.2628, -1.2190, -0.9880, -1.1601, -1.2786, -1.4575,  1.1501, -1.2768,\n                       -1.2785,  0.4855,  1.1018,  1.2047,  0.9857, -1.3051,  1.9454, -1.3595,\n                        0.9571,  1.1216,  1.0392, -1.5008, -0.6260,  1.3388, -1.4612, -0.7670,\n                        0.9826, -1.3156,  1.0639, -1.1998,  0.9378,  1.1713, -0.8874, -1.7168,\n                       -1.4608, -0.7341,  0.9376,  1.7721,  1.1485,  1.0322,  1.8546,  1.5017,\n                        0.9077,  1.4474,  0.8993, -1.1646, -0.9756,  0.9142,  0.8668, -1.1621,\n                       -0.5648,  0.8452, -1.2194,  1.1932,  1.3546, -1.5810, -1.1931, -0.7546,\n                        1.2004,  0.7563, -1.7389,  0.8514,  1.3041, -1.3568,  1.0008, -0.5728,\n                       -1.0886, -0.9310,  0.7349,  1.5612,  0.1154, -1.2270,  0.8755, -1.4478,\n                        0.7780,  1.6855, -1.1450,  0.8660, -0.9546,  1.1167, -0.8250, -1.1234])),\n              ('backbone.models.0.model.layer1.0.bn3.bias',\n               tensor([-5.9330e-01, -2.4666e-01, -1.2683e-01,  7.3432e-03,  6.7339e-02,\n                       -5.4014e-01,  4.3823e-03, -5.4316e-01, -1.3316e-01, -2.5799e-01,\n                        4.6345e-01,  7.9039e-01,  3.4046e-01, -2.3860e-01, -1.4286e-01,\n                        2.9011e-01, -4.3051e-02, -2.0485e-01,  8.8038e-01,  8.8502e-02,\n                        1.2924e+00, -5.9322e-02,  1.2274e-01,  1.8548e+00, -6.9475e-02,\n                       -3.0399e-02,  2.7230e-02,  6.6122e-03, -1.3116e-01,  1.5228e-01,\n                        2.2822e-01, -2.9434e-01, -1.6221e-01, -3.2642e-01, -3.5555e-01,\n                        5.3241e-01, -1.6526e-01, -2.1040e-01, -1.0691e-01,  5.2117e-01,\n                       -1.1126e-02, -2.2096e-01, -5.1554e-02, -4.5848e-02, -1.8178e-01,\n                        2.5309e+00,  2.1170e-02, -1.8418e-01,  1.5116e-02,  9.5966e-02,\n                       -1.0737e-01,  1.1957e+00, -3.8569e-01, -1.3821e-01, -1.7724e-01,\n                       -4.6116e-02,  2.5620e-01,  3.8446e-02, -3.7275e-02, -2.1487e-01,\n                       -2.2741e-01,  3.4566e-01,  1.0509e-01, -1.8460e-02, -2.7903e-02,\n                        6.2835e-02,  4.2656e+00, -1.7146e-02, -3.3407e-01, -1.3860e-02,\n                       -3.4994e-02,  9.6767e-02, -1.5996e-01,  1.2607e-01,  7.6547e-02,\n                       -7.2897e-02, -2.5164e-01, -5.3177e-02, -1.8252e-01, -2.3592e-01,\n                        1.5446e+00, -5.2136e-02, -5.5049e-02, -1.7880e-01, -1.5607e-01,\n                        5.7573e-04, -3.8652e-01,  9.3147e-02, -2.6820e-01, -8.5172e-02,\n                       -4.2302e-01, -5.6345e-02, -4.0570e-01,  2.5556e-02, -1.1378e+00,\n                       -4.7810e-01,  1.1070e-01,  7.4400e-03, -1.2271e-01,  1.5415e-01,\n                        2.9822e-02, -2.2744e-01, -3.8713e-01, -9.2724e-02, -7.6982e-01,\n                       -5.0736e-01, -2.6654e-02,  2.1700e+00, -7.2205e-02, -6.1080e-02,\n                       -1.2271e-01,  1.6823e+00,  1.9831e-01, -1.7940e-01, -4.3980e-02,\n                       -1.1481e-02,  3.3538e-02, -1.1544e-01, -1.1344e-01, -1.5806e-01,\n                       -2.6484e-01, -4.0674e-01, -5.3927e-01,  6.0994e-02, -2.1262e-01,\n                       -2.3668e-01, -1.4475e-01,  4.3863e-02, -1.2600e-01, -9.5348e-02,\n                       -2.3840e-01,  1.3397e-01, -2.6601e-01,  5.8530e-02,  3.9364e-01,\n                       -8.0505e-02, -2.0460e-01,  4.9201e-02,  8.5793e-02,  9.1211e-02,\n                        1.0957e-02,  1.5759e-01,  2.1733e-01,  6.5272e-02, -4.5693e-01,\n                        2.3305e-02, -2.3965e-02,  2.9013e-01,  1.2299e-02,  1.2070e-01,\n                       -3.5428e-01, -1.5504e-01, -1.2707e-03, -2.8279e-02,  1.3722e+00,\n                       -3.0189e-01,  1.0946e-01, -3.9771e-01, -7.9110e-02,  6.1996e-02,\n                       -4.1570e-02,  2.0230e-01, -2.8624e-01,  1.6934e-01, -6.8920e-02,\n                       -3.1594e-01, -2.9433e-01, -2.1995e-01,  1.0598e+00,  1.9294e-01,\n                        8.0508e-01, -2.8653e-01,  2.3372e-01, -1.1862e-01, -2.2201e-01,\n                       -4.7528e-02,  2.5048e+00, -5.2950e-02, -3.7244e-02, -3.0398e-01,\n                       -1.4316e-01, -1.9513e-01,  2.6655e-01, -1.0233e-02, -7.5927e-02,\n                        1.3461e-01,  1.7779e-01, -1.1708e-01,  8.5408e-02, -1.0161e-02,\n                       -2.3263e-01, -1.4949e-02, -3.4143e-02,  1.2063e-02, -5.7431e-02,\n                       -5.6329e-01, -1.4246e+00, -3.4781e-01,  7.9798e-02, -1.8885e-01,\n                        8.8207e-02, -1.6091e-01,  3.0378e-01, -4.1705e-02, -1.1305e-02,\n                        3.8056e-03,  9.1564e-02, -1.8738e-01,  9.6185e-02,  1.1109e+00,\n                        8.2883e-02, -2.7754e-02,  3.1298e-01, -7.4722e-03, -2.1503e-01,\n                       -1.6287e-01,  5.1425e-02, -8.2840e-02, -1.0252e-01, -2.3996e-01,\n                        4.1517e-01, -1.7047e-01,  1.0093e-01,  1.2289e-01,  3.2111e+00,\n                        3.1848e-01,  1.5794e-01, -4.3849e-02, -2.0453e-01, -1.4998e-01,\n                        1.7723e-01, -1.6563e-01,  1.4095e-01,  1.5277e+00, -1.3972e+00,\n                        4.1029e-01,  2.9298e-01, -3.0134e-01, -1.5563e-01, -9.1545e-01,\n                        6.3336e-02,  2.6617e-01,  3.5224e-02, -3.1476e-01,  2.3249e-01,\n                       -1.2709e-01,  1.4473e+00, -1.0611e-01, -7.8776e-04, -4.8848e-01,\n                       -1.5745e-02, -1.2088e-02,  1.2991e+00,  1.4073e-01, -1.0376e-02,\n                        1.7829e-01])),\n              ('backbone.models.0.model.layer1.0.bn3.running_mean',\n               tensor([ 2.2766, -1.9684, -0.9514,  2.6836,  0.3729,  3.2086,  2.0871,  1.2448,\n                       -2.9497,  0.1538,  0.6477,  4.6404, -4.3994,  1.8930, -0.8807,  2.0270,\n                        2.5293,  3.7728,  0.6657,  1.3772, -0.5952,  2.2159, -0.8390,  0.5984,\n                       -2.5047,  1.4483,  1.5595,  0.3626,  1.3942,  2.2919, -0.7309, -2.8327,\n                        0.1305, -4.1935,  0.1584,  4.1565,  1.7003, -2.7153,  3.0060,  0.7806,\n                       -0.9693, -1.6857, -3.1550, -0.8159, -1.7757, -1.6655, -2.2329, -1.6594,\n                        3.0085, -3.5193, -1.7419, -1.3448, -1.1102,  4.4121,  1.9643,  1.8720,\n                       -1.4821, -1.7672,  0.3474, -3.8875,  1.3641,  0.5754,  0.3266,  1.3243,\n                        2.0930,  1.5251,  4.2496,  1.2656, -0.9155, -1.4950,  1.9869,  2.5820,\n                        0.0084, -1.9565, -1.3295,  1.9238,  2.7210, -1.8959,  1.1736,  0.8625,\n                        5.0465,  0.1576,  2.1974,  3.4087, -2.0051,  1.6737,  2.3920, -1.8971,\n                       -1.4717,  0.1218,  0.7061, -1.2061,  0.2146, -2.4214, -1.1620,  0.4901,\n                       -1.8847,  4.7320,  4.2506, -0.4083,  2.5958,  1.5367, -1.3172,  2.2713,\n                        1.9527,  1.1203,  0.8750,  2.1109,  2.5733,  4.7340, -4.8307, -0.0189,\n                       -3.5554,  2.7011, -0.9664, -1.3979, -0.0120, -1.2096,  1.9925, -0.0540,\n                        2.9731,  1.1022,  1.4752, -1.1440, -0.3208,  1.6046, -4.6204, -4.9645,\n                        2.8952, -1.3376,  1.6094, -2.8498, -0.6729, -0.7385,  2.9711,  2.0492,\n                       -0.7064,  1.7199,  3.0695,  0.1558,  0.4622, -0.6109,  1.6079, -2.6338,\n                       -2.4433,  1.8733, -1.2300, -2.8428, -3.5605, -1.8868,  0.6476,  0.8043,\n                        1.6246, -0.4900, -4.0831, -2.6553,  1.8279,  0.3343,  3.8759, -2.2973,\n                        2.6522, -1.2956,  0.0539, -4.1002, -2.5067, -2.8394, -2.1413, -2.2562,\n                        5.4943, -2.3993,  0.3792,  3.1717, -2.9469,  2.0059,  4.4396, -3.2938,\n                       -0.6453, -1.9683,  1.5545, -1.5398,  0.4816, -2.2771, -3.8977,  0.5906,\n                        2.7281,  3.3611, -1.5589,  1.8286,  0.7524, -1.9181,  4.1850,  2.4123,\n                       -4.1003,  2.7222,  0.2971,  3.1056,  0.0354,  2.3125,  2.1931,  1.2373,\n                       -2.6998,  2.4073, -3.4124,  0.7046, -3.3497, -2.6449, -0.2445,  3.2894,\n                        4.0268,  2.1568,  3.5176,  2.0132, -2.7991, -1.0821, -2.2817,  0.3662,\n                        2.8211,  1.4216, -1.5626, -0.2927,  1.9831, -1.3783,  1.3110, -4.3800,\n                       -1.2357, -2.5057,  1.0693,  1.9537,  0.8508, -3.0393, -2.5209, -2.1965,\n                       -0.3976,  0.3320, -4.2058, -2.0211,  3.3746, -1.0544,  1.6299, -3.1835,\n                       -1.0917,  1.1173, -0.5429, -2.7399,  1.6973,  1.5808, -0.4982,  3.3527,\n                       -1.0402, -2.2010, -1.9448,  1.0413,  0.5077,  1.5515,  3.2394,  0.7918])),\n              ('backbone.models.0.model.layer1.0.bn3.running_var',\n               tensor([1.0278e+00, 7.9736e+00, 1.4304e+00, 4.2771e+00, 4.1294e+00, 3.7307e+00,\n                       5.2747e+00, 2.7117e+00, 5.5907e+00, 3.6851e+00, 4.1128e+00, 2.0853e+00,\n                       1.6810e+01, 7.2247e+00, 6.1024e+00, 8.7604e+00, 9.3430e+00, 7.7565e+00,\n                       7.0691e-01, 3.4598e+00, 2.5330e+00, 2.0618e+00, 4.1065e+00, 3.8364e+00,\n                       1.1434e+01, 3.7162e+00, 8.3398e+00, 2.4955e+00, 1.3673e+01, 5.6638e+00,\n                       6.8181e+00, 9.1215e+00, 2.7801e+00, 2.0064e+00, 1.4619e+00, 1.2359e+01,\n                       7.0864e-01, 3.8759e+00, 8.1015e+00, 1.7353e+00, 5.4926e-01, 1.1655e+00,\n                       1.7477e+00, 2.0683e+00, 1.4051e+00, 2.0664e+00, 8.6785e+00, 1.1577e+00,\n                       7.0229e+00, 1.0966e+01, 1.1025e+00, 1.3171e+00, 5.4357e+00, 9.3604e+00,\n                       1.3201e+00, 1.0083e+01, 3.2531e+00, 8.5464e+00, 2.1275e+00, 1.1820e+00,\n                       8.6332e-01, 5.9129e+00, 2.4423e+00, 3.0495e+00, 5.1120e+00, 2.9722e+00,\n                       3.5653e+00, 3.8743e+00, 3.9341e+00, 6.9658e+00, 6.6202e+00, 1.4750e+01,\n                       3.2985e+00, 2.0063e+00, 3.0316e+00, 1.0816e+01, 4.7071e+00, 8.5128e+00,\n                       4.7865e+00, 3.0070e+00, 2.1976e+00, 5.7563e-01, 1.2037e+01, 5.8212e+00,\n                       1.1035e+01, 4.6006e+00, 5.0639e+00, 1.0074e+01, 1.8147e+00, 1.7521e+00,\n                       2.8037e+00, 2.9801e+00, 1.9209e+00, 7.2412e+00, 4.8994e-01, 6.4533e-01,\n                       1.1476e+01, 7.1014e+00, 3.3227e+00, 3.0503e+00, 3.3392e+00, 2.9544e+00,\n                       1.1626e+00, 1.6213e+00, 4.6474e-01, 2.6874e+00, 1.3486e+01, 4.8473e+00,\n                       2.1693e+00, 9.8322e+00, 1.7031e+01, 4.5784e+00, 1.0013e+01, 1.1454e+01,\n                       2.8007e+00, 4.9501e-01, 1.7958e+00, 1.2518e+00, 2.3987e+00, 1.8076e+00,\n                       9.7717e+00, 1.6060e+00, 8.7686e-01, 1.7331e+00, 7.1796e+00, 1.4153e+00,\n                       1.7521e+01, 1.8327e+01, 8.0768e+00, 8.7340e+00, 7.0615e+00, 4.3009e+00,\n                       4.1037e+00, 3.9393e+00, 5.1818e+00, 3.3797e+00, 1.9937e+00, 4.6909e+00,\n                       5.8381e+00, 6.4720e-01, 1.2368e+00, 3.4339e+00, 2.5511e+00, 9.2993e+00,\n                       5.7884e+00, 9.8259e+00, 2.7418e+00, 1.3393e+01, 1.3408e+01, 6.7898e+00,\n                       2.3525e+00, 6.5086e-01, 4.6689e+00, 2.9947e+00, 1.3551e+01, 1.2404e+01,\n                       9.0127e-01, 1.8059e+00, 1.1836e+01, 3.9424e+00, 2.7675e+00, 1.6422e+00,\n                       1.6946e-01, 1.5497e+01, 1.9196e+00, 3.7855e+00, 1.1227e+01, 2.6560e+00,\n                       2.4696e+00, 1.1178e+01, 1.8477e-02, 1.0302e+01, 4.8428e+00, 4.0714e+00,\n                       1.3391e+01, 1.4224e+00, 5.6648e-01, 1.0471e+01, 3.4764e+00, 4.5333e+00,\n                       1.3057e+00, 9.3619e+00, 1.5985e+01, 2.2431e+00, 3.8141e+00, 2.0237e+00,\n                       4.8000e+00, 3.6043e+00, 2.3343e+00, 2.7210e+00, 9.7330e+00, 2.7765e+00,\n                       2.1736e+00, 4.4551e+00, 2.2786e+00, 4.3646e+00, 6.1559e-04, 4.1335e+00,\n                       8.9974e+00, 1.7672e+00, 2.5049e+00, 6.4568e+00, 1.2490e+01, 2.2594e+00,\n                       1.2650e+00, 8.2278e+00, 4.1224e+00, 6.9443e+00, 1.0181e+01, 1.7303e+00,\n                       5.4401e+00, 4.7574e+00, 4.5381e+00, 1.6262e+00, 9.2587e+00, 4.4168e+00,\n                       4.1167e+00, 2.2360e+00, 2.7170e+00, 2.0641e+00, 6.9887e+00, 3.7245e+00,\n                       2.7112e+00, 1.7082e+00, 1.5748e+00, 3.0742e+00, 1.8590e+00, 4.9884e+00,\n                       3.5142e+00, 4.9242e+00, 1.0173e+01, 3.3559e+00, 1.7159e+00, 1.9554e+00,\n                       2.2035e+00, 1.6320e+00, 1.2941e+01, 4.5973e+00, 6.1291e+00, 3.9028e-01,\n                       1.5331e+00, 2.2099e+00, 1.1742e+00, 1.0772e+01, 6.0586e-01, 5.9065e+00,\n                       6.3094e+00, 1.0449e+01, 1.4827e+00, 4.2794e+00, 5.0079e+00, 2.0378e+00,\n                       4.7294e+00, 6.2125e+00, 3.3088e+00, 2.9149e+00])),\n              ('backbone.models.0.model.layer1.0.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer1.0.downsample.0.weight',\n               tensor([[[[ 0.0404]],\n               \n                        [[-0.0206]],\n               \n                        [[-0.6815]],\n               \n                        ...,\n               \n                        [[ 0.0216]],\n               \n                        [[-0.0773]],\n               \n                        [[ 0.0968]]],\n               \n               \n                       [[[ 0.1788]],\n               \n                        [[-0.0272]],\n               \n                        [[ 0.1397]],\n               \n                        ...,\n               \n                        [[ 0.0611]],\n               \n                        [[ 0.0675]],\n               \n                        [[ 0.0345]]],\n               \n               \n                       [[[-0.0296]],\n               \n                        [[ 0.0320]],\n               \n                        [[ 0.0789]],\n               \n                        ...,\n               \n                        [[-0.0394]],\n               \n                        [[ 0.0622]],\n               \n                        [[-0.0150]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0123]],\n               \n                        [[ 0.0348]],\n               \n                        [[-0.0163]],\n               \n                        ...,\n               \n                        [[-0.0076]],\n               \n                        [[ 0.1015]],\n               \n                        [[-0.0606]]],\n               \n               \n                       [[[ 0.0858]],\n               \n                        [[ 0.0743]],\n               \n                        [[-0.1601]],\n               \n                        ...,\n               \n                        [[-0.2501]],\n               \n                        [[ 0.1513]],\n               \n                        [[ 0.1004]]],\n               \n               \n                       [[[-0.0582]],\n               \n                        [[-0.0904]],\n               \n                        [[ 0.1154]],\n               \n                        ...,\n               \n                        [[-0.0602]],\n               \n                        [[ 0.0982]],\n               \n                        [[ 0.1056]]]])),\n              ('backbone.models.0.model.layer1.0.downsample.1.weight',\n               tensor([1.5835, 1.6000, 1.1890, 1.1117, 1.3187, 2.1245, 1.1011, 1.8936, 1.6292,\n                       1.4879, 0.6726, 0.7636, 1.1046, 1.8358, 1.3503, 1.1408, 1.4182, 1.8517,\n                       0.2248, 0.9485, 0.6455, 1.5235, 0.9363, 0.6994, 1.5267, 1.2278, 1.2441,\n                       0.9875, 2.0495, 1.2542, 0.8251, 1.7912, 1.5211, 1.5837, 1.7283, 1.2293,\n                       1.2079, 1.6594, 1.5108, 0.8565, 0.5216, 1.1875, 1.1594, 0.9557, 1.2184,\n                       0.7376, 1.6011, 0.9994, 1.3660, 1.6737, 0.8887, 0.5700, 1.7022, 1.7285,\n                       0.4752, 1.3095, 0.9628, 1.4291, 1.3212, 1.4409, 0.8826, 1.0198, 1.0349,\n                       0.9060, 1.9208, 1.1949, 0.6812, 1.3130, 1.9339, 1.5358, 1.3417, 1.4642,\n                       1.1658, 0.9768, 1.0561, 1.5943, 1.8019, 1.3182, 1.1228, 1.4974, 0.7548,\n                       0.9149, 1.4642, 1.2817, 1.6168, 1.5223, 1.4770, 1.4226, 1.4543, 1.2794,\n                       1.4707, 1.0289, 1.8164, 1.3526, 2.4288, 1.3422, 1.6068, 1.4610, 1.5689,\n                       1.0270, 1.2294, 1.7027, 1.3594, 1.1440, 1.0718, 1.5679, 1.3939, 0.9291,\n                       1.2231, 1.5768, 2.1746, 0.9376, 1.3846, 1.9030, 1.5047, 0.4191, 1.1684,\n                       0.9547, 1.2571, 1.1623, 2.2037, 1.0551, 1.3178, 0.6522, 2.0988, 1.5139,\n                       1.8898, 1.6721, 1.1790, 1.7484, 1.4569, 0.8496, 2.0146, 1.1793, 0.7294,\n                       1.3426, 1.1724, 1.1878, 1.0824, 0.5091, 0.9680, 0.8228, 0.7829, 1.4888,\n                       1.7030, 1.3923, 1.1680, 1.1270, 1.4419, 1.2031, 1.4036, 0.8896, 0.8336,\n                       1.4274, 0.8557, 2.0224, 0.6018, 1.5224, 1.9285, 1.1239, 1.3031, 0.8222,\n                       0.3308, 1.5793, 1.2212, 1.8849, 2.0867, 1.3215, 0.8544, 1.1251, 0.0232,\n                       1.5604, 1.0590, 1.1263, 1.7864, 0.9550, 0.2991, 1.3535, 1.1157, 1.4727,\n                       1.2563, 1.6861, 1.2310, 1.2826, 1.4801, 0.5050, 1.1843, 1.3064, 0.9013,\n                       1.2732, 2.3037, 1.2977, 0.8857, 1.1697, 0.9263, 1.7876, 1.1173, 1.6530,\n                       1.7054, 1.3535, 0.9757, 1.4352, 1.1142, 1.2777, 0.8672, 1.2157, 1.1278,\n                       1.8814, 1.5571, 0.6831, 1.0420, 1.9338, 1.1925, 0.9947, 2.0016, 1.7097,\n                       1.0150, 1.3910, 1.0243, 1.5836, 1.0145, 1.0969, 0.9322, 1.0418, 0.5628,\n                       0.7521, 1.0065, 1.4333, 1.4507, 1.8339, 1.2994, 1.0737, 1.1156, 0.6739,\n                       0.5887, 0.7389, 1.3796, 1.6303, 1.2539, 0.9734, 0.9703, 0.8525, 0.9274,\n                       2.0070, 0.7121, 1.4391, 0.9395, 1.6384, 0.8773, 2.2398, 1.2855, 0.9644,\n                       1.0117, 1.1702, 0.8881, 1.1413])),\n              ('backbone.models.0.model.layer1.0.downsample.1.bias',\n               tensor([-5.9330e-01, -2.4666e-01, -1.2683e-01,  7.3432e-03,  6.7339e-02,\n                       -5.4014e-01,  4.3823e-03, -5.4316e-01, -1.3316e-01, -2.5799e-01,\n                        4.6345e-01,  7.9039e-01,  3.4046e-01, -2.3860e-01, -1.4286e-01,\n                        2.9011e-01, -4.3051e-02, -2.0485e-01,  8.8038e-01,  8.8502e-02,\n                        1.2924e+00, -5.9322e-02,  1.2274e-01,  1.8548e+00, -6.9475e-02,\n                       -3.0399e-02,  2.7230e-02,  6.6122e-03, -1.3116e-01,  1.5228e-01,\n                        2.2822e-01, -2.9434e-01, -1.6221e-01, -3.2642e-01, -3.5555e-01,\n                        5.3241e-01, -1.6526e-01, -2.1040e-01, -1.0691e-01,  5.2117e-01,\n                       -1.1126e-02, -2.2096e-01, -5.1554e-02, -4.5848e-02, -1.8178e-01,\n                        2.5309e+00,  2.1170e-02, -1.8418e-01,  1.5116e-02,  9.5966e-02,\n                       -1.0737e-01,  1.1957e+00, -3.8569e-01, -1.3821e-01, -1.7724e-01,\n                       -4.6116e-02,  2.5620e-01,  3.8446e-02, -3.7275e-02, -2.1487e-01,\n                       -2.2741e-01,  3.4566e-01,  1.0509e-01, -1.8460e-02, -2.7903e-02,\n                        6.2835e-02,  4.2656e+00, -1.7146e-02, -3.3407e-01, -1.3860e-02,\n                       -3.4994e-02,  9.6767e-02, -1.5996e-01,  1.2607e-01,  7.6547e-02,\n                       -7.2897e-02, -2.5164e-01, -5.3177e-02, -1.8252e-01, -2.3592e-01,\n                        1.5446e+00, -5.2136e-02, -5.5049e-02, -1.7880e-01, -1.5607e-01,\n                        5.7573e-04, -3.8652e-01,  9.3147e-02, -2.6820e-01, -8.5172e-02,\n                       -4.2302e-01, -5.6345e-02, -4.0570e-01,  2.5556e-02, -1.1378e+00,\n                       -4.7810e-01,  1.1070e-01,  7.4400e-03, -1.2271e-01,  1.5415e-01,\n                        2.9822e-02, -2.2744e-01, -3.8713e-01, -9.2724e-02, -7.6982e-01,\n                       -5.0736e-01, -2.6654e-02,  2.1700e+00, -7.2205e-02, -6.1080e-02,\n                       -1.2271e-01,  1.6823e+00,  1.9831e-01, -1.7940e-01, -4.3980e-02,\n                       -1.1481e-02,  3.3538e-02, -1.1544e-01, -1.1344e-01, -1.5806e-01,\n                       -2.6484e-01, -4.0674e-01, -5.3927e-01,  6.0994e-02, -2.1262e-01,\n                       -2.3668e-01, -1.4475e-01,  4.3863e-02, -1.2600e-01, -9.5348e-02,\n                       -2.3840e-01,  1.3397e-01, -2.6601e-01,  5.8530e-02,  3.9364e-01,\n                       -8.0505e-02, -2.0460e-01,  4.9201e-02,  8.5793e-02,  9.1211e-02,\n                        1.0957e-02,  1.5759e-01,  2.1733e-01,  6.5272e-02, -4.5693e-01,\n                        2.3305e-02, -2.3965e-02,  2.9013e-01,  1.2299e-02,  1.2070e-01,\n                       -3.5428e-01, -1.5504e-01, -1.2707e-03, -2.8279e-02,  1.3722e+00,\n                       -3.0189e-01,  1.0946e-01, -3.9771e-01, -7.9110e-02,  6.1996e-02,\n                       -4.1570e-02,  2.0230e-01, -2.8624e-01,  1.6934e-01, -6.8920e-02,\n                       -3.1594e-01, -2.9433e-01, -2.1995e-01,  1.0598e+00,  1.9294e-01,\n                        8.0508e-01, -2.8653e-01,  2.3372e-01, -1.1862e-01, -2.2201e-01,\n                       -4.7528e-02,  2.5048e+00, -5.2950e-02, -3.7244e-02, -3.0398e-01,\n                       -1.4316e-01, -1.9513e-01,  2.6655e-01, -1.0233e-02, -7.5927e-02,\n                        1.3461e-01,  1.7779e-01, -1.1708e-01,  8.5408e-02, -1.0161e-02,\n                       -2.3263e-01, -1.4949e-02, -3.4143e-02,  1.2063e-02, -5.7431e-02,\n                       -5.6329e-01, -1.4246e+00, -3.4781e-01,  7.9798e-02, -1.8885e-01,\n                        8.8207e-02, -1.6091e-01,  3.0378e-01, -4.1705e-02, -1.1305e-02,\n                        3.8056e-03,  9.1564e-02, -1.8738e-01,  9.6185e-02,  1.1109e+00,\n                        8.2883e-02, -2.7754e-02,  3.1298e-01, -7.4722e-03, -2.1503e-01,\n                       -1.6287e-01,  5.1425e-02, -8.2840e-02, -1.0252e-01, -2.3996e-01,\n                        4.1517e-01, -1.7047e-01,  1.0093e-01,  1.2289e-01,  3.2111e+00,\n                        3.1848e-01,  1.5794e-01, -4.3849e-02, -2.0453e-01, -1.4998e-01,\n                        1.7723e-01, -1.6563e-01,  1.4095e-01,  1.5277e+00, -1.3972e+00,\n                        4.1029e-01,  2.9298e-01, -3.0134e-01, -1.5563e-01, -9.1545e-01,\n                        6.3336e-02,  2.6617e-01,  3.5224e-02, -3.1476e-01,  2.3249e-01,\n                       -1.2709e-01,  1.4473e+00, -1.0611e-01, -7.8776e-04, -4.8848e-01,\n                       -1.5745e-02, -1.2088e-02,  1.2991e+00,  1.4073e-01, -1.0376e-02,\n                        1.7829e-01])),\n              ('backbone.models.0.model.layer1.0.downsample.1.running_mean',\n               tensor([-6.7962e+00, -2.9738e+00,  3.8270e+00, -7.9216e+00, -3.7241e+00,\n                       -1.5965e+00, -1.7005e+00, -7.9815e+00, -8.8703e-01, -1.0718e+00,\n                        7.1914e-01, -6.0317e-01, -1.9930e+00,  9.8314e-01, -1.9108e+00,\n                       -1.6768e+00, -1.5368e+00, -2.1706e+00,  1.6399e-01,  2.9057e+00,\n                        4.7229e+00,  1.8026e+00, -6.9579e-02, -9.0610e-01, -1.2522e+00,\n                        6.5011e-01, -5.6480e+00,  2.4655e-01, -1.1061e+01,  1.0821e+00,\n                       -4.0746e+00, -3.9116e-01, -1.0777e+00, -5.9157e-01,  3.8166e+00,\n                       -8.9340e-02,  8.2137e+00, -1.3397e+00, -1.3050e+00, -1.6614e+00,\n                       -1.1419e+00,  1.0546e+00, -4.5518e+00,  1.6119e+00, -1.5402e+00,\n                        8.4245e+00,  2.9576e-01, -1.4135e+00, -1.6189e+00, -4.1619e-01,\n                       -4.7164e-01,  7.7702e+00, -3.0833e+00, -2.3477e+00, -9.7955e+00,\n                       -1.8044e+00,  3.1385e+00,  5.9331e-01,  7.0652e-01,  3.5162e+00,\n                       -5.2133e+00, -4.6577e-01,  1.8051e+00, -4.6402e-01,  3.3353e-01,\n                       -2.5722e+00,  7.0862e+00, -1.3771e+00, -5.4133e+00,  2.3146e+00,\n                        2.9005e+00, -1.7627e+00, -1.9374e+00,  2.7311e+00,  2.4843e+00,\n                       -1.7017e+00, -1.8722e-01, -1.2363e-01, -1.2622e+00, -2.1434e+00,\n                        7.1103e-02,  9.1789e+00, -2.4309e+00, -1.9717e+00, -2.4990e+00,\n                        1.7164e+00, -4.6474e+00, -1.6839e+00, -9.5230e+00, -1.1131e+00,\n                       -1.5805e+00, -3.1736e+00, -7.9592e+00,  2.7537e-01,  6.4808e+00,\n                       -6.4999e+00,  7.9062e-01, -3.8331e+00, -5.1776e+00,  3.4666e+00,\n                       -4.8536e+00,  2.2845e-01, -4.4621e-01, -1.6218e+00,  2.3958e+00,\n                       -2.4646e+00, -2.1727e+00, -1.5657e+00, -5.2467e-01, -6.0134e-01,\n                       -8.6543e+00, -1.3903e-01,  1.5093e-01, -1.0849e+01, -1.4132e+00,\n                        4.6355e-01,  1.1179e-01,  3.2617e-01, -1.4905e+00, -6.5233e-01,\n                        1.8864e-01, -3.5959e+00, -6.3307e+00, -1.9668e+00, -1.5336e+00,\n                        2.0252e-01, -2.3833e+00,  6.1863e-01, -1.1328e+00, -2.8449e+00,\n                       -1.7066e+00, -2.2731e+00,  2.9338e-02, -2.6921e-01, -3.9269e-01,\n                       -1.2807e+01,  2.8215e+00, -4.0397e+00, -1.6855e+00, -9.2623e+00,\n                        1.7737e+00,  5.0833e-01, -9.7003e+00, -8.3326e-01, -3.9154e+00,\n                       -2.4337e+00, -1.3417e+00, -1.7990e-01, -1.0016e+00,  3.2653e+00,\n                       -1.3211e+01,  1.2105e+01, -8.3374e+00,  1.2918e+00,  1.7513e+01,\n                       -2.6534e-01, -6.8624e-01, -1.0431e+00, -8.4866e+00,  3.7530e+00,\n                       -1.3134e+00,  9.3671e+00, -2.9895e+00, -6.3676e-01, -2.7334e+00,\n                       -5.0437e-01, -3.0398e+00, -1.9865e+00,  2.6562e+00,  3.5376e+00,\n                        1.5186e-01, -2.0984e+00, -2.7104e+00, -4.3073e+00, -3.4012e+00,\n                       -3.6274e+00,  2.1254e+00,  8.7332e-01, -1.7065e-01, -3.8410e-01,\n                        1.0291e+00,  3.5626e-01, -1.2741e+00, -4.0966e-01, -4.0937e+00,\n                       -4.2745e+00,  1.8670e+00,  6.9374e-02,  2.4562e+00,  9.7222e-01,\n                        4.5815e-01, -3.1564e-01, -2.5820e+00,  1.2558e-01,  1.5822e-01,\n                       -3.3958e+00, -4.0179e-02, -7.6509e-01, -1.4946e+00, -2.7094e+00,\n                       -5.9873e+00, -3.8251e+00, -2.9486e+00, -3.8794e+00, -1.4223e+00,\n                       -1.9689e+00, -1.1136e+01, -7.9342e+00,  1.0882e+00,  5.8818e-02,\n                       -4.3571e+00, -1.2755e-01,  1.8726e+00,  1.3572e+00, -1.6802e+00,\n                       -1.8009e+00, -6.1005e+00,  2.4030e+00, -4.5700e+00, -2.5911e+00,\n                       -4.1350e+00, -1.0955e+00,  1.7220e+00,  1.7968e+00, -1.7719e+00,\n                       -6.6767e-01,  7.8099e+00, -2.9712e-01, -9.0852e-01,  7.8640e-03,\n                        1.9537e+00, -6.8206e-01,  3.7456e+00, -1.9118e+00,  6.8460e+00,\n                        1.3376e+00, -6.2349e-01, -1.1204e+00, -4.5782e-01,  1.0337e+01,\n                        5.7571e+00, -1.1288e-02, -3.0816e-01, -2.0735e+00,  1.4380e+01,\n                       -1.6344e+00,  1.0796e+00,  3.5292e-01,  4.0833e+00, -7.3197e+00,\n                       -2.4089e+00,  9.7567e-01, -5.6487e+00, -5.6957e+00, -3.9633e+00,\n                        5.8764e-01])),\n              ('backbone.models.0.model.layer1.0.downsample.1.running_var',\n               tensor([3.4144e+00, 5.7911e+00, 8.4188e+00, 8.0040e+00, 5.5898e+00, 4.2562e+00,\n                       6.2862e+00, 2.9285e+00, 5.0032e+00, 4.6777e+00, 8.7494e+00, 1.3683e+01,\n                       2.0289e+01, 5.2435e+00, 3.5333e+00, 6.5936e+00, 5.0741e+00, 9.2223e+00,\n                       2.4884e+00, 1.2802e+01, 4.0031e+00, 4.5856e+00, 1.2389e+01, 1.1606e+01,\n                       8.0947e+00, 4.7385e+00, 1.4121e+01, 4.3364e+00, 3.7054e+00, 6.4996e+00,\n                       1.0341e+01, 5.7863e+00, 2.7498e+00, 3.9284e+00, 1.0816e+01, 1.0802e+01,\n                       1.7182e+01, 6.4364e+00, 6.3296e+00, 1.3771e+01, 2.1613e+00, 3.2374e+00,\n                       2.1240e+00, 2.7343e+00, 6.7160e+00, 7.9331e+00, 7.1639e+00, 6.3691e+00,\n                       6.8709e+00, 7.6738e+00, 5.0393e+00, 9.0163e+00, 8.5589e+00, 1.3828e+01,\n                       5.3730e+00, 8.9650e+00, 1.0446e+01, 5.4424e+00, 9.9609e+00, 5.8517e+00,\n                       4.5736e+00, 3.9407e+00, 1.2453e+01, 7.1274e+00, 4.3296e+00, 1.6805e+01,\n                       1.2493e+01, 4.0853e+00, 8.6637e+00, 8.5450e+00, 5.1464e+00, 1.0001e+01,\n                       5.1792e+00, 5.4902e+00, 8.5949e+00, 1.0319e+01, 5.4109e+00, 7.5759e+00,\n                       3.1831e+00, 4.5989e+00, 1.1010e+01, 1.1728e+01, 5.2115e+00, 4.9739e+00,\n                       8.1683e+00, 6.9839e+00, 5.5515e+00, 5.2209e+00, 6.2569e+00, 8.6667e+00,\n                       5.5191e+00, 1.4329e+01, 7.0021e+00, 5.8082e+00, 1.3187e+01, 1.8621e+00,\n                       6.8509e+00, 2.9744e+00, 7.8655e+00, 1.1355e+01, 5.0367e+00, 4.9166e+00,\n                       2.3688e+00, 9.1386e+00, 5.3813e+00, 5.9781e+00, 6.2905e+00, 7.1562e+00,\n                       1.0842e+01, 1.2428e+01, 4.7507e+00, 5.6691e+00, 8.9783e+00, 4.3615e+00,\n                       1.2121e+01, 1.0390e+00, 5.5428e+00, 8.2215e+00, 3.6034e+00, 1.1169e+01,\n                       6.5314e+00, 4.4943e+00, 3.3065e+00, 4.3615e+00, 9.9516e+00, 2.0119e+00,\n                       7.9217e+00, 1.3626e+01, 4.3567e+00, 1.2214e+01, 5.3968e+00, 1.3762e+01,\n                       5.3563e+00, 4.0192e+00, 6.7758e+00, 4.9133e+00, 7.3035e+00, 9.3993e+00,\n                       3.5956e+00, 7.0095e+00, 6.5781e+00, 7.7643e+00, 8.3536e+00, 5.4085e+00,\n                       9.2068e+00, 6.6007e+00, 2.4504e+00, 1.2456e+01, 9.0371e+00, 5.2840e+00,\n                       5.3169e+00, 7.3912e+00, 1.1243e+01, 1.7474e+01, 3.3560e+01, 6.4362e+00,\n                       7.1115e+00, 3.6835e+00, 5.2651e+00, 1.8490e+01, 1.4904e+01, 1.1446e+01,\n                       7.3064e-01, 8.8027e+00, 1.4084e+01, 7.4963e+00, 7.1744e+00, 6.4622e+00,\n                       1.2238e+01, 9.6327e+00, 3.6881e-02, 7.3804e+00, 5.1921e+00, 1.0716e+01,\n                       8.1828e+00, 4.6317e+00, 3.2786e+00, 8.1858e+00, 3.8943e+00, 3.5474e+00,\n                       5.5158e+00, 7.5551e+00, 1.4079e+01, 9.6154e+00, 3.6719e+00, 4.1690e+00,\n                       6.1403e+00, 3.9279e+00, 1.4061e+01, 1.2340e+01, 1.0018e+01, 1.3810e+01,\n                       9.7508e+00, 1.1528e+01, 1.5614e+01, 7.5928e+00, 1.2709e-04, 7.2253e+00,\n                       6.1092e+00, 8.2597e+00, 1.2413e+01, 6.4887e+00, 1.1646e+01, 6.3515e+00,\n                       5.4857e+00, 6.0772e+00, 9.2761e+00, 7.1918e+00, 4.1316e+00, 1.1254e+01,\n                       6.0115e+00, 4.9449e+00, 1.7082e+01, 8.5344e+00, 8.4145e+00, 5.3833e+00,\n                       1.3068e+01, 1.3135e+01, 3.1077e+00, 7.3715e+00, 6.7782e+00, 4.1543e+00,\n                       5.1941e+00, 1.4213e+01, 5.3058e+00, 1.7607e+01, 2.4587e+01, 1.1027e+01,\n                       3.7275e+00, 5.8459e+00, 1.2119e+01, 3.0503e+00, 1.4769e+01, 1.0704e+01,\n                       1.7184e+00, 1.1974e+01, 9.9044e+00, 4.0760e+00, 4.5306e+00, 5.8689e+00,\n                       1.9739e+01, 1.0631e+01, 1.0599e+01, 6.7928e+00, 2.6643e+01, 5.9989e+00,\n                       7.9064e+00, 5.9030e+00, 7.4098e+00, 4.8987e+00, 3.7486e+00, 4.5527e+00,\n                       6.2055e+00, 5.8457e+00, 5.5596e+00, 8.3844e+00])),\n              ('backbone.models.0.model.layer1.0.downsample.1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer1.1.conv1.weight',\n               tensor([[[[ 0.1050]],\n               \n                        [[ 0.2403]],\n               \n                        [[-0.0407]],\n               \n                        ...,\n               \n                        [[-0.0371]],\n               \n                        [[-0.1267]],\n               \n                        [[-0.0930]]],\n               \n               \n                       [[[-0.0051]],\n               \n                        [[ 0.0827]],\n               \n                        [[-0.0726]],\n               \n                        ...,\n               \n                        [[ 0.0119]],\n               \n                        [[ 0.1671]],\n               \n                        [[-0.1096]]],\n               \n               \n                       [[[-0.1611]],\n               \n                        [[-0.3197]],\n               \n                        [[ 0.0849]],\n               \n                        ...,\n               \n                        [[ 0.0863]],\n               \n                        [[-0.0682]],\n               \n                        [[-0.0010]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.2189]],\n               \n                        [[ 0.2432]],\n               \n                        [[-0.0366]],\n               \n                        ...,\n               \n                        [[-0.1148]],\n               \n                        [[ 0.1233]],\n               \n                        [[-0.0532]]],\n               \n               \n                       [[[-0.1207]],\n               \n                        [[ 0.1677]],\n               \n                        [[ 0.0888]],\n               \n                        ...,\n               \n                        [[ 0.0098]],\n               \n                        [[-0.0799]],\n               \n                        [[ 0.1077]]],\n               \n               \n                       [[[-0.1734]],\n               \n                        [[-0.0480]],\n               \n                        [[-0.0089]],\n               \n                        ...,\n               \n                        [[-0.0693]],\n               \n                        [[-0.0285]],\n               \n                        [[-0.0852]]]])),\n              ('backbone.models.0.model.layer1.1.bn1.weight',\n               tensor([1.3231, 0.4967, 0.5327, 1.0511, 1.3211, 0.4994, 0.5862, 1.0438, 0.6080,\n                       1.1685, 1.1540, 0.5967, 0.3280, 0.5168, 0.9276, 0.7118, 0.5347, 0.5232,\n                       0.4552, 0.8741, 0.4083, 1.1959, 0.7236, 1.6354, 1.6188, 0.5222, 0.4225,\n                       1.3916, 1.3593, 1.3539, 0.6711, 0.4495, 0.4420, 0.4802, 0.7236, 0.5234,\n                       0.4582, 0.6617, 1.0515, 0.6277, 0.4513, 0.8863, 0.5436, 0.6749, 0.4998,\n                       0.5885, 0.6332, 0.5422, 0.8247, 1.1939, 1.0361, 0.5369, 0.6185, 0.4215,\n                       0.4482, 0.4977, 0.6566, 0.7084, 1.0941, 0.4659, 0.4813, 1.3887, 0.4942,\n                       0.5909])),\n              ('backbone.models.0.model.layer1.1.bn1.bias',\n               tensor([-1.1673,  0.3807,  0.1777, -1.7127, -1.7587, -0.0242,  0.1785, -1.6596,\n                        0.1047, -0.7668, -1.5798,  0.0446,  0.6234,  0.0961, -1.2753, -0.1048,\n                        0.2988,  0.4714,  0.2214, -0.5383,  0.4823, -0.8243, -0.0600, -4.1242,\n                       -2.9897,  0.4184,  0.6795, -1.7973, -0.9804, -0.9754,  0.2524,  0.3558,\n                        0.6979,  0.4882, -0.1469,  0.1909,  0.3546,  0.1945, -1.0570,  0.2223,\n                        0.4395, -0.4785,  0.1490, -0.0345,  0.4245, -0.0557, -0.1027,  0.3926,\n                       -0.4617, -1.2428, -1.1778,  0.2729, -0.0401,  0.2656,  0.1497,  0.3736,\n                       -0.4037, -0.2631, -1.0177,  0.2686,  0.0042, -1.9071,  0.6279,  0.0716])),\n              ('backbone.models.0.model.layer1.1.bn1.running_mean',\n               tensor([-1.6421, -0.3202, -0.7421, -2.7053,  3.1100,  3.3811, -1.1554, -1.1913,\n                       -1.2286, -2.4594, -3.7810,  3.3485,  2.3813, -0.3700, -4.3952, -1.5597,\n                        2.4812, -1.5513,  0.5452, -2.0855,  0.3141, -4.0869,  1.8987, -1.2461,\n                       -0.2616, -0.9701,  0.4673, -1.1750, -2.7472, -3.5144, -2.0442, -0.7206,\n                        0.5041, -2.5738, -2.8037,  2.2289,  1.7476, -0.3529, -2.0409, -5.0741,\n                       -0.6211,  0.3118,  1.6197,  1.0069, -3.2532,  1.2798,  3.7414, -0.3837,\n                        0.2772, -1.4085, -2.2380, -1.8780, -1.3863, -3.3076,  3.9034,  0.5705,\n                        4.5565,  1.8526,  1.0643,  1.1172,  2.6613, -1.9305,  1.3164,  2.7099])),\n              ('backbone.models.0.model.layer1.1.bn1.running_var',\n               tensor([1.0625, 0.4622, 0.7966, 0.5042, 0.6654, 0.3196, 0.7022, 0.2569, 0.6599,\n                       0.8462, 0.3262, 0.7802, 0.3376, 0.5408, 0.5105, 0.9958, 0.9170, 0.7659,\n                       0.4443, 0.5524, 0.6480, 0.9793, 0.5728, 1.5764, 0.5695, 0.8294, 1.0084,\n                       0.7514, 2.0040, 1.8557, 0.4735, 0.4201, 0.8270, 0.8493, 0.4556, 0.8609,\n                       0.5855, 0.9929, 1.0206, 0.9278, 0.6098, 0.7409, 0.8649, 0.4728, 0.9847,\n                       0.5356, 0.4253, 0.9736, 0.4704, 1.2858, 0.3648, 0.3442, 0.8728, 0.2800,\n                       0.4045, 0.7446, 0.6805, 0.3872, 1.0096, 0.5988, 0.3845, 0.5914, 0.9113,\n                       0.9976])),\n              ('backbone.models.0.model.layer1.1.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer1.1.conv2.weight',\n               tensor([[[[ 5.9539e-02, -1.1651e-02,  5.4444e-04],\n                         [-8.9748e-02,  2.6537e-01, -2.1576e-01],\n                         [-7.4544e-02,  3.5986e-02, -6.8156e-02]],\n               \n                        [[-4.1501e-02,  1.7371e-01, -6.2663e-02],\n                         [-3.0471e-01,  2.9283e-01, -2.6433e-01],\n                         [ 2.9513e-02, -7.8101e-02, -3.9174e-03]],\n               \n                        [[ 4.4344e-02, -7.7708e-02, -1.3062e-02],\n                         [ 4.3529e-02, -2.7733e-01,  6.2081e-02],\n                         [ 2.9024e-02,  1.4020e-02,  3.7383e-02]],\n               \n                        ...,\n               \n                        [[ 1.5562e-02, -8.5381e-02,  7.2088e-02],\n                         [-4.5660e-02,  4.8794e-02,  1.0285e-02],\n                         [ 3.8764e-02, -7.1761e-02,  4.1184e-03]],\n               \n                        [[ 6.4626e-02,  4.3703e-01,  4.0214e-02],\n                         [ 2.2741e-01, -4.6541e-01,  3.3616e-01],\n                         [ 9.9838e-02,  4.6725e-01,  1.2522e-01]],\n               \n                        [[-1.1609e-02, -2.8255e-01,  6.2123e-02],\n                         [-2.4202e-01,  3.0021e-01, -1.3650e-01],\n                         [-1.4379e-01, -2.7077e-01, -2.6009e-01]]],\n               \n               \n                       [[[ 4.1394e-02, -2.4541e-02,  1.0995e-01],\n                         [-8.1101e-02,  4.4100e-02,  1.1339e-01],\n                         [-1.2035e-01, -2.9121e-02, -5.8069e-02]],\n               \n                        [[-7.6558e-02, -2.5110e-01,  2.1119e-02],\n                         [ 1.1375e-01,  1.5522e-01,  2.9947e-01],\n                         [ 2.5377e-02, -2.6739e-01, -1.5745e-02]],\n               \n                        [[-3.1081e-02, -1.8800e-02, -8.6165e-02],\n                         [ 2.7416e-02, -2.7810e-02, -4.7901e-02],\n                         [-3.0559e-02, -7.1535e-02, -5.6520e-02]],\n               \n                        ...,\n               \n                        [[ 1.2476e-01, -5.4427e-03,  2.7587e-02],\n                         [ 6.6201e-03, -1.7063e-02, -9.9805e-02],\n                         [-3.9276e-03, -1.0326e-01, -2.9097e-02]],\n               \n                        [[ 6.3948e-03,  1.6461e-01, -6.1397e-04],\n                         [ 2.7886e-01, -3.4991e-01, -1.5529e-01],\n                         [ 7.3895e-02, -2.3404e-01,  2.7134e-02]],\n               \n                        [[-6.5070e-02, -2.7190e-01, -1.0421e-01],\n                         [-2.3931e-01,  2.8603e-01,  2.5295e-01],\n                         [ 1.6213e-02, -1.4449e-01, -9.1793e-03]]],\n               \n               \n                       [[[-7.3879e-03,  1.0011e-01,  3.1894e-02],\n                         [ 1.1613e-02, -6.0326e-03,  1.0626e-01],\n                         [-2.4478e-02,  3.6268e-02, -6.8946e-02]],\n               \n                        [[ 2.4979e-02,  1.0714e-01,  1.2465e-01],\n                         [-5.2493e-02, -4.5089e-01, -5.2801e-02],\n                         [ 1.3006e-01,  1.2503e-01,  3.1183e-02]],\n               \n                        [[ 6.6709e-02,  9.5229e-02, -6.5392e-02],\n                         [ 1.9929e-02, -1.5095e-02,  3.9900e-02],\n                         [ 5.0813e-02, -2.1581e-02,  3.7011e-02]],\n               \n                        ...,\n               \n                        [[-8.5296e-03, -3.6443e-02,  2.0892e-02],\n                         [-3.3726e-02, -1.0893e-01, -7.9675e-02],\n                         [-9.9841e-03,  6.9348e-03, -6.5439e-02]],\n               \n                        [[ 3.8248e-02, -6.6427e-02, -1.2989e-01],\n                         [ 1.1908e-01,  3.2935e-02,  4.6959e-02],\n                         [ 1.0636e-02,  7.5640e-02,  1.0851e-01]],\n               \n                        [[ 1.7650e-01,  1.9530e-01,  1.2187e-01],\n                         [-2.5639e-02, -4.2160e-01,  7.0614e-01],\n                         [-1.5342e-01,  2.3707e-01,  7.5902e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-4.7600e-02, -5.8355e-02, -3.6324e-02],\n                         [ 1.0685e-01,  2.6821e-01,  1.0019e-01],\n                         [-2.6066e-02,  2.3282e-02, -2.8086e-02]],\n               \n                        [[-2.6333e-02,  1.4576e-02,  5.2200e-02],\n                         [ 1.3881e-01,  3.7847e-02, -7.8128e-02],\n                         [ 1.4058e-02,  5.3610e-02, -4.1276e-02]],\n               \n                        [[-1.2921e-01, -4.7273e-01, -1.3067e-01],\n                         [ 4.2420e-04,  3.4007e-01,  2.9426e-01],\n                         [ 1.3389e-01,  6.5116e-02,  1.8321e-02]],\n               \n                        ...,\n               \n                        [[ 4.7922e-03,  2.9095e-02, -8.8400e-02],\n                         [ 2.0492e-02, -2.3222e-01,  2.3388e-02],\n                         [ 2.8211e-02,  1.1317e-01,  7.2041e-02]],\n               \n                        [[ 5.9148e-02,  8.4532e-03,  5.0084e-02],\n                         [ 1.2806e-01,  2.0782e-01,  1.2613e-01],\n                         [ 7.7487e-02, -1.6413e-01,  9.2959e-03]],\n               \n                        [[ 3.7680e-04, -5.1291e-02,  5.0205e-04],\n                         [ 1.2998e-01,  2.5808e-02,  1.1508e-01],\n                         [-1.3570e-02,  6.2463e-02,  2.6976e-02]]],\n               \n               \n                       [[[-8.0711e-03,  2.8463e-02,  8.5461e-03],\n                         [-5.1880e-02,  1.1078e-01, -7.1794e-02],\n                         [ 4.5251e-02,  6.8634e-02,  1.6396e-02]],\n               \n                        [[ 9.6004e-02,  6.7566e-02,  1.2168e-01],\n                         [ 6.2582e-02,  9.2154e-02,  4.7001e-02],\n                         [ 1.2828e-02,  4.5365e-03, -2.3835e-02]],\n               \n                        [[-2.0967e-02, -8.5956e-03, -5.8911e-02],\n                         [ 3.6142e-02, -7.1623e-02, -8.1521e-02],\n                         [-4.6617e-03,  4.7546e-03, -9.2290e-02]],\n               \n                        ...,\n               \n                        [[-5.4580e-02, -8.5699e-02, -4.7989e-02],\n                         [-3.7072e-02, -1.9901e-01, -1.9967e-02],\n                         [-4.4184e-02, -5.0763e-02, -6.5353e-02]],\n               \n                        [[ 7.8703e-03, -4.2752e-02, -2.3938e-02],\n                         [ 2.2876e-03, -5.8769e-02, -1.6453e-02],\n                         [ 1.2657e-02, -5.2288e-02,  1.3345e-02]],\n               \n                        [[-3.4244e-02, -9.2953e-02, -6.5682e-03],\n                         [ 3.1674e-02,  1.1243e-01,  1.4030e-02],\n                         [-3.0586e-02, -9.4698e-03, -1.5093e-02]]],\n               \n               \n                       [[[ 2.7408e-02,  4.9791e-02, -3.2788e-02],\n                         [-1.9812e-02,  1.2403e-01,  1.1161e-01],\n                         [-1.3335e-01, -2.8879e-02,  1.1565e-01]],\n               \n                        [[ 3.0794e-02, -2.4324e-02, -6.7816e-02],\n                         [ 3.4669e-02, -1.5640e-01,  1.3864e-01],\n                         [ 1.0559e-01,  4.3585e-03, -7.9069e-02]],\n               \n                        [[ 1.1727e-01,  5.6245e-02,  4.5118e-02],\n                         [ 2.2512e-01,  4.2388e-02,  1.9830e-01],\n                         [ 1.4348e-01,  1.0837e-01,  9.0341e-02]],\n               \n                        ...,\n               \n                        [[-5.1684e-02, -1.2261e-01, -8.8361e-02],\n                         [-1.1698e-01,  6.6999e-02,  7.9863e-02],\n                         [-4.2926e-02, -7.2620e-02, -6.1104e-02]],\n               \n                        [[ 1.7689e-02, -1.1955e-01,  5.8348e-02],\n                         [ 1.3885e-01, -1.0407e-01, -3.7125e-01],\n                         [ 8.0026e-02,  1.9062e-01, -2.6696e-02]],\n               \n                        [[-1.0472e-02,  2.1909e-02, -1.0838e-01],\n                         [ 5.5663e-03, -9.3455e-02,  1.2221e-01],\n                         [ 3.8973e-02, -3.7458e-03, -3.0844e-02]]]])),\n              ('backbone.models.0.model.layer1.1.bn2.weight',\n               tensor([0.4973, 0.6109, 0.4846, 0.8697, 0.9432, 0.5942, 0.4018, 0.5469, 0.6336,\n                       0.7162, 0.6203, 0.5723, 0.6605, 0.4948, 0.8523, 1.1853, 1.2206, 0.6289,\n                       0.8608, 0.7414, 0.6792, 0.6448, 0.4469, 1.6545, 0.8335, 0.6139, 0.3999,\n                       0.6988, 1.1708, 1.4534, 0.5759, 0.4477, 0.7287, 0.8727, 0.6587, 0.8253,\n                       0.7764, 0.4853, 0.4430, 0.3704, 0.4975, 0.5078, 0.4650, 1.2359, 0.4876,\n                       0.8109, 0.6831, 0.7920, 0.4691, 0.7091, 0.8664, 0.4764, 1.2548, 0.9232,\n                       0.4806, 0.8945, 0.4845, 1.3823, 1.7924, 0.4563, 0.5601, 0.6866, 1.3028,\n                       0.8403])),\n              ('backbone.models.0.model.layer1.1.bn2.bias',\n               tensor([ 1.9740,  0.5160,  1.6760, -0.3775, -0.3462,  0.1244,  1.1257,  0.7261,\n                        0.1230, -0.1442,  0.1338,  0.3473,  0.3798,  0.5005, -0.1512, -1.0947,\n                       -1.3551, -0.0487, -0.2558, -0.4936, -0.0094,  0.2478,  1.4368, -3.4314,\n                       -0.2942,  0.8089,  1.5261, -0.0181, -1.1536, -1.8062,  0.4513,  2.0499,\n                        0.0041, -0.2110,  0.0213, -0.0132,  0.0037,  1.3437,  1.6741,  0.5693,\n                        0.1336,  0.2628,  0.9754, -1.2557,  0.6408,  0.0149,  0.0074, -0.2382,\n                        1.3472,  0.0751, -0.3109,  1.3371, -0.9225, -0.2262,  1.4727, -0.7272,\n                        0.6487, -1.7377, -2.3944,  1.4699,  1.2314,  0.4782, -1.4515, -0.1937])),\n              ('backbone.models.0.model.layer1.1.bn2.running_mean',\n               tensor([ 0.5236,  1.0097,  0.0567, -2.4874,  0.0123, -0.4755,  0.9090, -0.0960,\n                       -0.2111, -0.3785, -0.0410,  0.1284,  0.6783,  0.0138, -0.6488, -1.4975,\n                       -1.9152, -0.5479,  0.2033, -1.4544,  0.2888, -0.0380,  0.0712, -0.1593,\n                        0.2606,  0.2166, -1.6432, -2.1904, -1.9156, -1.4712,  0.4780, -0.5066,\n                        0.4220,  0.6438,  0.0669,  0.4314, -0.5110,  3.3541,  1.4480,  0.3635,\n                       -0.8409,  0.6574, -0.0051, -1.6361,  1.4784,  0.6616, -0.0339,  0.0198,\n                        1.7626, -0.1228,  0.3731,  1.0955, -1.6240, -0.2803, -0.3407, -0.7926,\n                       -0.5342, -0.1502, -2.6306,  1.2705, -0.1810,  0.5321, -0.9676, -0.9274])),\n              ('backbone.models.0.model.layer1.1.bn2.running_var',\n               tensor([1.6571, 1.9353, 2.1114, 1.1628, 1.1411, 1.6860, 1.4729, 1.9780, 1.8537,\n                       1.3285, 1.6431, 0.8740, 2.0235, 1.4809, 1.9546, 0.8655, 2.2710, 0.7621,\n                       1.3993, 0.8875, 1.3873, 1.7151, 2.2222, 0.9529, 1.0223, 1.9525, 1.3884,\n                       1.1397, 1.0161, 0.9733, 2.5916, 1.3816, 1.1112, 1.9258, 1.8407, 2.0151,\n                       1.1814, 1.7106, 0.9131, 1.7078, 0.6000, 1.7951, 3.0020, 2.7754, 0.9614,\n                       2.4136, 1.6179, 0.9732, 1.7163, 1.2845, 0.9525, 2.0797, 1.2445, 2.3097,\n                       1.6134, 0.9971, 0.9507, 2.0252, 0.8966, 2.3052, 2.0641, 2.0728, 0.9657,\n                       1.7465])),\n              ('backbone.models.0.model.layer1.1.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer1.1.conv3.weight',\n               tensor([[[[ 0.0212]],\n               \n                        [[-0.0294]],\n               \n                        [[-0.0576]],\n               \n                        ...,\n               \n                        [[ 0.0165]],\n               \n                        [[ 0.0954]],\n               \n                        [[-0.0111]]],\n               \n               \n                       [[[ 0.0234]],\n               \n                        [[ 0.1819]],\n               \n                        [[ 0.0614]],\n               \n                        ...,\n               \n                        [[-0.0061]],\n               \n                        [[ 0.0749]],\n               \n                        [[-0.0059]]],\n               \n               \n                       [[[-0.0642]],\n               \n                        [[ 0.0816]],\n               \n                        [[-0.0249]],\n               \n                        ...,\n               \n                        [[-0.0325]],\n               \n                        [[ 0.0306]],\n               \n                        [[ 0.0013]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0170]],\n               \n                        [[ 0.0093]],\n               \n                        [[-0.0249]],\n               \n                        ...,\n               \n                        [[-0.0063]],\n               \n                        [[-0.0186]],\n               \n                        [[ 0.0252]]],\n               \n               \n                       [[[-0.0762]],\n               \n                        [[-0.0132]],\n               \n                        [[ 0.0788]],\n               \n                        ...,\n               \n                        [[-0.1415]],\n               \n                        [[-0.1819]],\n               \n                        [[-0.1065]]],\n               \n               \n                       [[[-0.1760]],\n               \n                        [[-0.0345]],\n               \n                        [[-0.0058]],\n               \n                        ...,\n               \n                        [[ 0.0341]],\n               \n                        [[ 0.0087]],\n               \n                        [[-0.0799]]]])),\n              ('backbone.models.0.model.layer1.1.bn3.weight',\n               tensor([ 1.0486e+00,  4.6148e-01, -1.6936e-01, -9.3935e-02,  7.1038e-02,\n                       -1.3069e+00,  4.4944e-01,  5.7037e-01, -2.6179e-01, -2.4924e-01,\n                       -4.0514e-01,  1.0382e-01, -1.5372e-01, -2.1156e-01,  2.8301e-01,\n                        8.5132e-02, -1.6527e-01, -3.7963e-01,  4.4290e-01, -1.4494e-03,\n                        1.5841e-01,  1.7807e-01,  2.1566e-02, -2.4013e-01, -2.2575e-01,\n                       -3.3496e-01,  4.0919e-01,  3.6553e-01,  1.0801e-01,  1.9246e-01,\n                        3.9128e-01,  8.5245e-01, -1.8801e-01, -9.3533e-01,  1.7896e-01,\n                        1.4911e-01,  2.1330e-01,  1.2042e-01,  1.4755e-01,  1.2157e-01,\n                        5.8761e-01,  1.5768e+00, -2.5902e-01,  4.2406e-01, -1.6528e-01,\n                        2.8202e-01, -1.4767e-01,  1.4235e-01, -2.4805e-01,  1.4337e-01,\n                        5.0010e-01, -2.7431e-01, -5.5197e-01, -3.2311e-01,  1.1529e-01,\n                        4.3299e-01,  4.9111e-03, -1.4883e-01, -2.5995e-01,  2.7294e-01,\n                       -4.6442e-01, -9.3054e-02,  3.8080e-02, -2.8256e-01,  3.1066e-01,\n                        2.5877e-02,  7.1951e-03,  3.5860e-01, -1.2698e-01,  1.8589e-01,\n                        1.4949e-01,  3.5769e-01, -3.8949e-01, -2.9266e-01, -4.5538e-01,\n                       -2.0831e-01, -8.3557e-02, -3.4967e-01, -2.4975e-01, -4.8746e-01,\n                        1.9132e-01, -2.4808e-01,  8.8857e-02,  5.3901e-01,  3.5446e-01,\n                        1.0662e-01,  3.1228e-01, -5.5710e-02, -6.2177e-01, -9.5029e-02,\n                        3.1273e-01, -1.5199e-02,  2.6558e-01,  2.4632e-01, -1.4561e-01,\n                        5.5683e-01,  1.5455e-01,  4.8331e-02,  9.8485e-02,  2.9855e-01,\n                        4.3389e-01,  1.3501e-01,  4.6247e-01,  1.3749e-01,  4.8940e-01,\n                       -6.1872e-01,  1.7002e-01, -2.6867e-01, -4.2117e-02,  1.7863e-01,\n                        9.0842e-02,  4.6402e-02, -2.3514e-01,  1.1836e-01,  2.0332e-01,\n                       -5.3542e-01, -2.6928e-01,  1.1394e-01,  4.3079e-01, -7.6916e-02,\n                       -2.5057e-01, -5.8846e-01, -2.8477e-01,  6.0674e-01, -8.6080e-01,\n                       -1.4804e-01, -2.0035e-01,  1.8344e-01, -2.9765e-01, -2.7337e-01,\n                       -4.6444e-01,  1.7470e-03, -5.6362e-01,  3.0974e-01,  4.5385e-01,\n                        2.1623e-01, -8.4381e-02, -2.4857e-01,  2.9246e-01,  2.2597e-01,\n                        8.6454e-02,  2.7932e-02,  5.8798e-01, -1.5219e-01,  5.1481e-01,\n                       -2.1810e-01, -3.1258e-01,  1.4282e-01,  8.0402e-02,  1.0438e-02,\n                        2.1933e-01, -5.3217e-01,  2.1459e-01,  2.9798e-02, -1.0071e-01,\n                       -1.3640e-01, -2.7310e-01,  6.1591e-01, -7.0506e-02, -2.1152e-01,\n                       -9.6377e-02,  3.3247e-01, -3.5549e-01,  3.9925e-01,  1.0260e-01,\n                       -2.1835e-01, -1.6448e-01,  7.0015e-01, -1.3600e-01,  3.1619e-01,\n                       -1.2011e-01,  1.7688e-01,  2.8959e-02,  1.2370e-03,  2.1083e-01,\n                       -4.9707e-01, -3.2388e-01,  6.8891e-02,  4.0254e-01, -5.2660e-01,\n                       -1.2956e-01, -2.7263e-01, -2.1510e-01,  3.5882e-02, -1.2890e-01,\n                        1.3626e-01, -5.6299e-01, -4.2638e-01,  1.0088e-01, -2.3555e-01,\n                       -3.5063e-01,  1.6701e-01, -5.3266e-01, -3.9515e-01, -3.7066e-01,\n                       -6.3176e-01,  4.1120e-01,  5.2361e-01,  2.4580e-01,  6.8163e-02,\n                        4.6372e-01, -5.7322e-01,  2.2959e-01,  4.1491e-02, -8.5191e-01,\n                        1.9724e-01, -1.5064e-01,  8.0048e-02, -1.8293e-01,  1.6475e-01,\n                        1.3742e-02,  3.2038e-01,  4.0235e-01,  3.0751e-01,  1.7800e+00,\n                        1.5606e-01, -2.2964e-02, -7.5421e-02,  4.0945e-01,  1.0823e-01,\n                        3.6706e-02, -3.8021e-01,  4.8919e-01, -4.8165e-02,  2.9871e-01,\n                       -1.6572e-01, -3.1178e-01, -4.3898e-01, -5.7496e-01,  1.3641e-01,\n                       -1.1494e-01, -1.8166e-01,  7.0772e-02, -1.5147e-01,  8.8152e-01,\n                        1.2434e-01, -1.1964e-01,  4.5987e-01,  2.3608e-01, -2.3769e-01,\n                       -2.2302e-01,  8.4766e-02,  2.4626e-01,  1.6288e-01, -5.5081e-02,\n                        6.8808e-01, -1.3464e-01,  3.4558e-01,  5.4038e-01, -1.2298e-01,\n                       -9.9231e-02,  1.1465e-01,  1.3198e-01, -3.3676e-02,  3.0187e-01,\n                       -1.7125e-01])),\n              ('backbone.models.0.model.layer1.1.bn3.bias',\n               tensor([-1.6358e+00, -2.6393e-01, -2.5642e-01,  1.1350e-02, -5.1417e-02,\n                       -1.0017e+00, -4.7690e-01, -3.4601e-01,  1.1910e-02,  3.9226e-01,\n                        5.6343e-01,  1.6638e-03,  1.3050e-01,  4.0695e-02, -3.8734e-02,\n                        2.1694e-01,  1.5019e-02, -1.9210e-01,  1.2373e-01,  2.9884e-02,\n                        3.5530e-01, -1.6879e-01,  1.4448e-02,  2.4656e-01, -1.3974e-01,\n                       -1.8128e-02, -3.9841e-02, -6.0889e-02, -8.6704e-02, -3.3819e-01,\n                        6.5530e-01, -4.0875e-01,  1.2440e-01, -9.9826e-01,  6.9896e-02,\n                        2.7998e-01,  3.9882e-01,  6.5174e-02,  2.3453e-01,  1.1214e-01,\n                       -4.4496e-01, -1.9058e+00,  9.3548e-03, -1.3505e-01, -1.1400e-01,\n                        6.6467e-01, -2.0543e-01,  4.3109e-02, -1.1679e-01, -9.9373e-02,\n                        4.7754e-04,  1.1070e-01, -4.1811e-01, -8.0051e-02, -1.9176e-01,\n                        1.7336e-01,  2.5908e-01, -1.1041e-01, -1.7452e-01, -1.9511e-01,\n                       -1.5946e-01, -1.4651e-01, -3.3239e-02,  6.3407e-01, -4.8501e-01,\n                        7.5786e-02,  2.0852e-01, -1.0368e-01, -1.3850e-01,  3.7334e-01,\n                       -1.2805e-01, -1.4262e-02,  2.0768e-01, -1.8744e-01, -7.3428e-02,\n                       -9.0813e-02,  2.9375e-01, -1.3012e-01,  6.3686e-01, -1.4246e-01,\n                        5.4792e-01,  4.9119e-01,  3.8771e-01, -3.2657e-01, -1.0100e-01,\n                       -1.7216e-01, -2.5782e-02,  3.1158e-02, -8.1337e-01,  1.8048e-01,\n                        1.3873e-02,  6.0666e-02,  4.1588e-01,  6.6164e-01, -1.0519e-02,\n                       -3.5555e-01, -1.4441e-01,  4.9618e-01,  1.5289e-01, -2.8380e-01,\n                       -1.7300e-01,  2.6082e-01, -1.5194e-01,  1.9226e-01, -4.0074e-01,\n                       -4.6417e-01,  3.7351e-01,  4.3263e-01,  8.0773e-02,  8.5901e-02,\n                       -6.1115e-02,  5.3854e-01, -2.7107e-01,  5.2802e-03, -1.1555e-01,\n                        4.2906e-01, -8.1008e-02,  4.3001e-02, -1.2601e-01,  2.4347e-01,\n                       -2.2979e-01,  2.3893e-02,  4.8743e-01,  3.2039e-01, -4.1844e-01,\n                       -2.5435e-01, -1.9648e-01,  1.6972e-01,  5.4470e-01, -3.4714e-02,\n                       -1.5958e-01,  1.1386e-02, -7.1270e-01, -2.6744e-01,  7.1492e-01,\n                        7.0524e-02,  2.9440e-01,  2.4613e-01, -1.7482e-01,  3.5510e-02,\n                        2.1221e-01,  7.9673e-01, -5.8995e-02, -1.1694e-01, -1.2993e-01,\n                       -1.5422e-01, -2.2096e-01,  2.9381e-01,  5.8606e-01,  4.1519e-01,\n                        5.5007e-01, -8.6029e-03,  6.0438e-01,  1.2584e-01,  5.5740e-02,\n                        1.0843e-01,  5.2668e-01, -1.1738e-01, -9.7355e-02, -2.4633e-03,\n                        3.8459e-01,  6.4073e-01,  2.3868e-01, -2.6744e-01,  2.2226e-01,\n                       -1.2028e-01, -3.7720e-01, -7.3009e-01,  6.1870e-01, -1.6084e-01,\n                        2.9383e-01,  4.8436e-01, -5.5293e-03,  3.1992e-02,  2.3541e-01,\n                       -2.9314e-01,  4.6042e-01,  5.2709e-01, -6.0683e-02, -4.2781e-01,\n                       -1.3356e-01,  2.4810e-02, -2.1448e-02,  1.8500e-01,  2.2919e-01,\n                        6.5543e-01, -5.1948e-01,  5.0812e-01,  2.6319e-01, -4.1081e-02,\n                       -2.9463e-01, -1.2946e-01,  2.9457e-02, -1.4976e-01,  3.8640e-02,\n                       -8.1847e-01,  2.1231e-02, -4.4812e-01,  2.3173e-01,  2.5452e-01,\n                       -2.6107e-01, -3.8761e-01,  4.1844e-01,  1.6073e-01, -7.9494e-01,\n                       -2.2180e-01, -1.7823e-01,  5.0698e-01, -1.1915e-01,  4.2441e-01,\n                        1.8170e-01, -4.5412e-01, -3.7188e-01,  9.8645e-03, -1.2086e+00,\n                       -1.3078e-01,  2.5571e-02,  5.9663e-02, -5.9839e-03,  1.0287e-01,\n                        1.0525e-01, -3.5036e-01, -4.0318e-01,  3.9260e-02,  1.8407e-01,\n                        3.0757e-01, -1.9203e-01, -6.3455e-02, -6.3455e-01, -9.3736e-02,\n                        2.9429e-01,  5.7048e-01,  9.6177e-02,  4.6163e-01, -9.1876e-01,\n                        3.1329e-01, -6.4906e-02, -1.5642e-01,  6.3271e-01,  5.5913e-01,\n                       -6.7903e-03,  1.9054e-01,  6.4613e-01,  8.1673e-02,  1.5378e-01,\n                       -2.0813e-01,  5.4482e-01, -1.4795e-01, -2.2706e-01, -1.5107e-01,\n                        7.0031e-02,  4.7474e-01,  3.0160e-01,  3.7879e-01,  6.3667e-01,\n                        2.0642e-01])),\n              ('backbone.models.0.model.layer1.1.bn3.running_mean',\n               tensor([-1.2302e+00, -5.0239e-01,  5.1567e-02,  1.1830e+00,  1.4249e-01,\n                        1.1153e+00, -7.7720e-01, -1.0203e-01,  6.4597e-01,  1.0423e+00,\n                       -6.2324e-01,  4.8935e-01,  4.6089e-01,  1.4519e-01,  2.4513e+00,\n                       -7.6371e-01,  1.2374e+00, -7.8428e-01,  2.3140e+00, -1.6191e-01,\n                       -6.1848e-01, -1.1852e+00, -2.7747e-02,  3.2140e-01, -2.0557e-01,\n                        1.0453e+00,  2.0938e-01, -1.2598e+00,  4.3243e-01, -3.9453e-04,\n                        2.3202e+00, -9.1298e-01, -6.2374e-01, -5.2049e-01, -3.2955e-01,\n                        6.2982e-01, -2.0053e+00,  8.1442e-01, -4.3213e-02, -7.0052e-01,\n                        2.3034e-01, -1.9155e+00, -5.4214e-01, -1.9107e+00,  2.0497e-01,\n                       -1.7472e+00,  1.2883e+00,  1.7910e-01, -9.5228e-01, -5.3125e-01,\n                       -1.5310e+00,  1.9209e+00,  5.1219e-01,  4.7960e-02, -7.4341e-01,\n                        2.3481e-03,  1.2520e-02,  8.5346e-01,  1.5812e-01, -6.3149e-01,\n                       -1.4797e+00, -6.9565e-03, -1.5423e-03,  1.1389e+00, -1.2803e+00,\n                       -1.6601e-02,  1.4560e-01, -7.3555e-01,  2.4804e-01,  6.1193e-01,\n                       -2.0057e-01, -1.1368e+00, -1.3519e+00, -1.1003e-01,  9.6898e-02,\n                       -1.2461e-01,  2.7875e-01, -1.6774e-01, -1.3000e+00, -7.4613e-01,\n                        2.0606e-01,  1.5064e+00,  1.7715e-01, -2.2589e-01,  4.0509e-01,\n                       -4.2061e-01, -7.6076e-02,  5.1010e-01,  2.1220e+00,  5.2087e-03,\n                       -4.6944e-01,  4.9905e-02,  1.1768e+00, -1.4112e-01, -8.1316e-01,\n                        2.8094e-01, -9.1612e-01, -1.8367e-02,  7.4282e-01, -2.6480e-01,\n                       -2.4406e+00,  5.1100e-01, -1.3066e+00, -5.0357e-01, -7.8216e-01,\n                        1.3935e+00,  1.6296e+00,  2.4162e-01,  7.3075e-01, -8.4000e-01,\n                        2.8386e-01,  5.4424e-01, -4.0186e-02,  9.2144e-01,  5.1632e-01,\n                        4.4479e-01,  8.4827e-02, -8.5562e-01,  8.1523e-01,  1.9248e-01,\n                        1.0185e+00,  2.3243e+00,  2.3920e+00,  3.1963e-01,  1.1938e+00,\n                        1.2479e+00, -2.7461e-01,  1.1475e+00, -1.9926e+00,  4.5072e-01,\n                        1.7580e-01, -4.5931e-03, -3.6201e-01, -1.1226e+00,  1.0691e+00,\n                        6.3407e-01,  7.7815e-02,  4.9971e-01, -1.1840e+00, -4.9298e-02,\n                       -1.2928e-02, -1.0308e-01,  1.2827e+00, -6.1226e-02, -1.9753e+00,\n                        1.4352e+00,  1.1778e+00,  6.6132e-01, -8.5027e-01, -1.4991e-01,\n                       -5.9502e-01, -1.5101e-01, -2.2288e+00, -3.2969e-01, -5.5497e-02,\n                       -2.8362e-01,  9.1262e-01, -9.7161e-01,  4.9958e-01, -4.8537e-01,\n                       -2.2657e-01,  1.3372e-01,  1.4751e+00, -2.0834e+00,  3.5361e-01,\n                        4.6208e-03,  4.4349e-01, -8.6526e-01,  2.5552e-01, -9.7645e-01,\n                       -1.9616e-01,  7.7917e-02,  3.2772e-02,  8.5744e-02, -7.5452e-01,\n                        1.8608e+00,  1.5974e+00, -9.2342e-01, -1.0168e+00, -9.8374e-01,\n                        7.2564e-01,  6.0317e-01,  1.4654e+00, -1.9127e-01,  3.9105e-01,\n                       -2.9019e-01,  2.3131e+00, -1.2274e+00, -5.8899e-01,  4.0223e-01,\n                        5.5443e-01, -3.3922e-01, -1.8928e+00, -6.1462e-01, -7.2094e-03,\n                       -7.4634e-02, -6.7263e-01,  1.0685e-01, -1.0841e+00,  1.1646e+00,\n                        8.1783e-01,  6.2793e-01, -5.9204e-01, -2.3132e-01, -1.5345e+00,\n                        3.0944e-01, -5.1568e-01, -4.5548e-01,  1.3845e+00, -5.3445e-02,\n                       -1.9824e-02, -7.4617e-01, -1.1686e+00, -6.8803e-01, -3.6346e+00,\n                       -2.8841e-01, -2.6080e-01,  2.7508e-01, -7.6196e-01,  6.7881e-01,\n                        2.7084e-01,  1.8909e+00, -1.0276e+00, -6.5290e-03,  3.3464e-01,\n                       -1.0170e-01,  1.5374e+00, -3.4354e-01,  1.0701e+00, -6.9089e-01,\n                       -6.9950e-03,  1.0169e+00, -1.0114e-01,  1.4646e+00,  5.3976e-01,\n                       -8.1713e-01,  7.8635e-01, -1.0331e+00,  2.1401e+00,  1.0887e+00,\n                       -1.0367e+00, -3.6730e-01,  3.1872e-02, -2.5146e-01,  4.6761e-01,\n                        1.4754e+00, -8.1449e-01,  3.0572e-01, -3.2797e-01,  8.6722e-01,\n                       -8.2816e-01,  6.2418e-02,  2.0858e-01, -3.9314e-02, -4.7484e-01,\n                       -3.2025e-01])),\n              ('backbone.models.0.model.layer1.1.bn3.running_var',\n               tensor([0.1819, 0.3210, 0.2202, 0.1500, 0.1061, 0.3470, 0.3057, 0.2606, 0.2895,\n                       0.3214, 0.5386, 0.1335, 0.4946, 0.2491, 0.1576, 0.0825, 0.1825, 0.4537,\n                       0.6824, 0.0310, 0.1959, 0.1354, 0.0279, 0.5327, 0.2829, 0.2482, 0.9338,\n                       0.3295, 0.0805, 0.1575, 0.5919, 0.2845, 0.1530, 0.2325, 0.0517, 0.2164,\n                       0.1995, 0.1027, 0.1520, 0.1563, 0.2994, 0.4099, 0.1728, 0.3364, 0.1406,\n                       0.3604, 0.1579, 0.3479, 0.2281, 0.1840, 0.2631, 0.3926, 0.4840, 0.5816,\n                       0.1092, 0.4634, 0.0191, 0.1799, 0.2760, 0.1307, 0.4036, 0.1159, 0.0602,\n                       0.3017, 0.2390, 0.0144, 0.0581, 0.3550, 0.1147, 0.2336, 0.1508, 0.5093,\n                       0.4433, 0.2639, 0.3944, 0.2436, 0.1180, 0.2691, 0.2456, 0.2637, 0.2385,\n                       0.2652, 0.1293, 0.3212, 0.3107, 0.1168, 0.1968, 0.0788, 0.2210, 0.0860,\n                       0.2278, 0.0211, 0.2149, 0.2235, 0.1292, 0.3185, 0.1551, 0.0541, 0.0846,\n                       0.4658, 0.2271, 0.3744, 0.2135, 0.1589, 0.1665, 0.4042, 0.3224, 0.2946,\n                       0.0553, 0.2703, 0.0463, 0.0627, 0.2042, 0.1639, 0.2494, 0.6043, 0.2367,\n                       0.1157, 0.2491, 0.1169, 0.1877, 0.6684, 1.1002, 0.4250, 0.2453, 0.0516,\n                       0.2591, 0.3285, 0.3852, 0.4236, 0.3368, 0.0296, 0.1411, 0.1914, 0.5852,\n                       0.2054, 0.1216, 0.2755, 0.1879, 0.5697, 0.1055, 0.0563, 1.3110, 0.1104,\n                       0.2801, 0.2268, 0.2088, 0.2597, 0.1320, 0.0715, 0.2043, 0.3902, 0.3568,\n                       0.0465, 0.6719, 0.1518, 0.2647, 0.3826, 0.1162, 0.3684, 0.2219, 0.3374,\n                       0.2466, 0.4252, 0.1991, 0.1457, 0.1337, 0.3009, 0.1514, 0.5451, 0.1427,\n                       0.2030, 0.0215, 0.0185, 0.2060, 0.2264, 0.2752, 0.1249, 0.3881, 0.2558,\n                       0.1183, 0.2461, 0.4221, 0.0338, 0.2002, 0.1978, 0.2833, 0.3202, 0.1423,\n                       0.2956, 0.1281, 0.2544, 0.5437, 0.5051, 0.4345, 0.2979, 0.2776, 0.3198,\n                       0.2183, 0.1202, 0.6011, 0.3436, 0.4069, 0.0457, 0.3252, 0.1623, 0.1223,\n                       0.1643, 0.1030, 0.2261, 0.0528, 0.2125, 0.4451, 0.4866, 0.4853, 0.1321,\n                       0.0740, 0.1557, 0.3747, 0.0663, 0.0451, 0.2160, 0.3992, 0.0453, 0.3051,\n                       0.1827, 0.5368, 0.5269, 0.1611, 0.0986, 0.1555, 0.2233, 0.0794, 0.2633,\n                       0.5513, 0.2120, 0.1234, 0.2431, 0.3172, 0.3516, 0.3719, 0.1560, 0.2431,\n                       0.1837, 0.2667, 0.2958, 0.2272, 0.3410, 0.4146, 0.0655, 0.1688, 0.0904,\n                       0.1511, 0.0284, 0.3110, 0.1625])),\n              ('backbone.models.0.model.layer1.1.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer1.2.conv1.weight',\n               tensor([[[[-0.1669]],\n               \n                        [[-0.0363]],\n               \n                        [[-0.0429]],\n               \n                        ...,\n               \n                        [[ 0.1081]],\n               \n                        [[-0.1229]],\n               \n                        [[-0.0610]]],\n               \n               \n                       [[[ 0.4611]],\n               \n                        [[-0.0247]],\n               \n                        [[-0.1362]],\n               \n                        ...,\n               \n                        [[ 0.0108]],\n               \n                        [[ 0.1918]],\n               \n                        [[ 0.2227]]],\n               \n               \n                       [[[ 0.1772]],\n               \n                        [[ 0.1586]],\n               \n                        [[-0.0492]],\n               \n                        ...,\n               \n                        [[ 0.1116]],\n               \n                        [[ 0.1009]],\n               \n                        [[-0.0094]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0447]],\n               \n                        [[-0.1094]],\n               \n                        [[-0.0628]],\n               \n                        ...,\n               \n                        [[-0.0389]],\n               \n                        [[-0.2263]],\n               \n                        [[ 0.0138]]],\n               \n               \n                       [[[ 0.1384]],\n               \n                        [[-0.0436]],\n               \n                        [[ 0.0314]],\n               \n                        ...,\n               \n                        [[ 0.0868]],\n               \n                        [[-0.1391]],\n               \n                        [[-0.0615]]],\n               \n               \n                       [[[-0.1135]],\n               \n                        [[-0.0229]],\n               \n                        [[ 0.0018]],\n               \n                        ...,\n               \n                        [[-0.0173]],\n               \n                        [[ 0.0734]],\n               \n                        [[ 0.0082]]]])),\n              ('backbone.models.0.model.layer1.2.bn1.weight',\n               tensor([1.1851, 1.0369, 1.5534, 1.1288, 1.1288, 1.0366, 1.6653, 1.1697, 1.2713,\n                       1.0387, 1.2930, 1.4856, 1.0585, 1.0184, 1.1585, 1.8358, 1.5116, 1.1336,\n                       1.0170, 1.1272, 1.1968, 1.1906, 1.2419, 1.2683, 1.2508, 1.0499, 1.0226,\n                       1.1509, 1.1662, 1.2801, 2.1003, 1.3444, 1.2944, 1.4592, 0.9107, 1.0696,\n                       1.2817, 0.9974, 0.9711, 1.3258, 0.9728, 1.0985, 1.1863, 1.5825, 1.1224,\n                       1.2535, 1.4896, 1.1741, 1.8295, 1.0957, 1.1277, 1.1367, 1.2600, 1.4011,\n                       0.8498, 1.1574, 1.4411, 1.0668, 1.1169, 1.3687, 1.1348, 0.9861, 0.9313,\n                       2.1136])),\n              ('backbone.models.0.model.layer1.2.bn1.bias',\n               tensor([-0.1321,  0.2032,  0.8111, -0.3142,  0.2018,  0.3631, -0.7645,  0.2523,\n                       -0.5103,  0.1815, -0.3757, -0.5591,  0.0253,  0.3871,  0.1683, -1.2147,\n                       -0.2768,  0.2141,  0.0375,  0.1213, -0.1721, -0.3140, -0.3545,  0.0725,\n                       -0.3878,  0.1423,  0.1102, -0.5490,  0.1372, -0.2521, -1.8051, -0.4839,\n                       -0.3552, -0.0990, -0.1230,  0.2506, -0.2838,  0.3556,  0.0411, -0.0138,\n                        0.6891,  0.1249, -0.0602, -0.9069, -0.0457, -0.1033, -0.2414,  0.0548,\n                       -1.2862,  0.2594, -0.3962,  0.0223, -0.1619, -0.5841,  0.3221,  0.2119,\n                       -0.5116,  0.3311, -0.0389, -0.3860, -0.4290,  0.4383,  0.3974, -1.9413])),\n              ('backbone.models.0.model.layer1.2.bn1.running_mean',\n               tensor([ 2.4577, -1.0168, -0.6816,  0.1007, -2.8522, -3.1980, -2.2133, -0.2360,\n                       -3.9491, -0.0823,  0.2109, -0.9601,  4.1903, -3.3437, -1.5053, -1.5301,\n                       -0.2840, -1.5846,  1.2659, -0.4709, -0.2175, -0.6585,  0.8362, -2.2806,\n                       -1.1413,  2.7582, -0.9747,  1.0053, -1.3344,  2.8933, -0.8782, -1.8170,\n                       -0.3584, -0.1897, -1.7315, -2.0829, -1.5488, -0.2572,  1.5028, -2.5484,\n                        2.8820,  0.9320, -0.1793, -0.5566, -5.9755,  1.8315, -0.6040, -1.6813,\n                        0.4297,  2.0319, -3.6995, -2.3051, -1.0156,  1.0777, -1.1469, -0.9178,\n                       -0.1238, -1.0170,  0.5841,  0.3681,  3.0253, -1.2810, -2.1027, -0.0744])),\n              ('backbone.models.0.model.layer1.2.bn1.running_var',\n               tensor([0.8270, 0.6457, 2.4646, 0.4890, 1.1777, 0.9816, 0.8861, 1.2591, 0.7790,\n                       0.7784, 0.6513, 0.6792, 0.7638, 1.3634, 1.1568, 1.1174, 1.4705, 1.1191,\n                       0.7449, 0.7488, 0.6124, 0.7106, 0.6765, 1.2743, 0.8234, 1.0044, 0.9413,\n                       0.6066, 1.1697, 0.7972, 0.9583, 0.6272, 0.7189, 1.4827, 0.7624, 1.1595,\n                       0.8030, 0.9521, 0.5111, 1.4752, 1.0019, 0.8724, 0.7696, 1.3234, 0.8306,\n                       1.1879, 1.6326, 1.1631, 0.9897, 0.9100, 0.5683, 0.9495, 1.3307, 0.7752,\n                       0.5965, 1.0612, 1.0466, 1.2203, 0.6072, 0.9761, 0.6066, 0.6260, 0.7536,\n                       0.9486])),\n              ('backbone.models.0.model.layer1.2.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer1.2.conv2.weight',\n               tensor([[[[ 8.0967e-02,  3.1165e-02, -6.0190e-02],\n                         [-1.1700e-01,  2.5745e-02, -2.6166e-01],\n                         [-9.0726e-02, -1.0655e-01,  7.0206e-03]],\n               \n                        [[ 7.5673e-02,  1.1481e-01, -3.8088e-02],\n                         [-3.7364e-02, -2.4474e-01, -9.9103e-02],\n                         [ 2.3685e-02,  2.8926e-02,  9.6780e-02]],\n               \n                        [[-1.0955e-01, -1.3143e-01, -6.3039e-02],\n                         [-8.9488e-02, -7.7019e-02, -1.1631e-01],\n                         [-7.1711e-02, -1.9491e-01, -1.2219e-01]],\n               \n                        ...,\n               \n                        [[ 5.9274e-02,  8.3890e-02,  1.9932e-02],\n                         [ 1.9768e-02, -5.9525e-02, -9.5305e-02],\n                         [-8.6547e-02, -2.1026e-02, -1.0838e-01]],\n               \n                        [[ 7.8925e-02,  3.6168e-01, -8.3610e-03],\n                         [ 2.6003e-01, -2.8533e-01,  1.4186e-01],\n                         [ 1.8223e-01,  2.3333e-01,  1.8196e-01]],\n               \n                        [[ 5.0095e-02, -7.6172e-02,  1.8853e-02],\n                         [-2.8575e-01, -1.6536e-01, -2.2318e-01],\n                         [ 1.4315e-01,  4.5917e-02,  1.7127e-01]]],\n               \n               \n                       [[[ 1.2011e-02, -4.7788e-02,  1.1619e-01],\n                         [-3.2768e-02,  3.0083e-02, -5.4287e-02],\n                         [ 1.0967e-01,  3.2832e-03, -5.5981e-02]],\n               \n                        [[-7.8157e-02,  4.3134e-02,  2.8881e-02],\n                         [-1.1099e-01, -1.1543e-01,  4.2191e-03],\n                         [-8.6879e-02,  1.1009e-02,  4.7960e-02]],\n               \n                        [[ 3.0168e-01, -8.0616e-01, -3.5927e-01],\n                         [-9.9018e-02, -2.5337e-01, -4.1874e-01],\n                         [ 3.1660e-01, -8.9774e-01, -3.6553e-01]],\n               \n                        ...,\n               \n                        [[-2.6003e-02, -1.3987e-02,  7.9131e-02],\n                         [ 1.0090e-01, -6.0659e-02,  1.8392e-01],\n                         [ 3.9330e-02, -1.5120e-01,  1.8923e-01]],\n               \n                        [[-7.7185e-02, -6.0287e-03, -6.4694e-03],\n                         [-3.0125e-02, -4.2735e-02, -8.6901e-02],\n                         [ 2.9698e-02, -9.1573e-03,  9.4043e-02]],\n               \n                        [[ 1.6040e-01, -2.3824e-01, -8.2755e-02],\n                         [ 3.0289e-01,  6.0051e-02,  4.4577e-02],\n                         [ 8.6182e-02, -3.1083e-01, -1.1910e-01]]],\n               \n               \n                       [[[ 6.5360e-02,  1.7359e-02, -1.5516e-01],\n                         [-7.0199e-02, -2.6228e-01, -3.6388e-02],\n                         [-1.3580e-01,  1.9666e-01,  2.3839e-02]],\n               \n                        [[-5.4756e-02,  1.2964e-01, -1.5954e-01],\n                         [ 9.1263e-02, -3.6034e-01, -1.2603e-02],\n                         [-1.4444e-01,  1.1552e-01,  2.6259e-02]],\n               \n                        [[ 4.9336e-02, -9.7923e-02, -6.4447e-04],\n                         [ 4.1746e-02,  4.5699e-02,  1.0299e-01],\n                         [ 3.3687e-02,  7.1890e-02,  5.0723e-02]],\n               \n                        ...,\n               \n                        [[-1.0005e-01,  1.1651e-01, -1.3922e-01],\n                         [-7.5784e-02,  5.6203e-02, -8.3594e-02],\n                         [ 3.8643e-02, -7.4900e-03, -5.4978e-02]],\n               \n                        [[-7.8650e-02, -2.8879e-04, -1.3137e-02],\n                         [-1.5921e-02, -3.0067e-02,  4.9492e-02],\n                         [-7.1191e-02, -3.9603e-02, -3.5388e-02]],\n               \n                        [[ 6.1321e-02,  8.2257e-02, -5.3804e-02],\n                         [ 1.3100e-01,  1.3694e-01,  4.1299e-02],\n                         [ 7.0196e-02,  1.6224e-01,  6.0839e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-4.7773e-02, -9.0082e-02,  1.7395e-01],\n                         [-6.7157e-02,  1.4393e-01, -3.7627e-02],\n                         [ 9.9538e-02, -1.2496e-01, -8.4471e-02]],\n               \n                        [[ 7.2972e-02, -6.1210e-02,  4.1878e-03],\n                         [ 1.3532e-02, -1.4731e-01, -8.6190e-03],\n                         [-2.3496e-02, -1.3578e-01,  1.2975e-01]],\n               \n                        [[-1.0669e-01,  2.1743e-02, -1.1069e-01],\n                         [ 3.1226e-02,  2.4696e-02,  1.3151e-01],\n                         [-5.3454e-02, -7.4137e-02, -5.6059e-02]],\n               \n                        ...,\n               \n                        [[ 4.2982e-02,  3.6879e-02,  1.0399e-02],\n                         [-1.1045e-01, -1.1285e-01,  8.1352e-02],\n                         [ 1.3903e-01,  3.4936e-02, -8.0315e-02]],\n               \n                        [[-4.4360e-03,  1.6354e-01,  6.7061e-02],\n                         [ 4.4813e-01, -3.8474e-01, -2.7362e-02],\n                         [ 6.6327e-02, -1.4107e-01,  7.3793e-02]],\n               \n                        [[-7.1234e-02,  3.5042e-02,  5.6663e-02],\n                         [-7.0187e-02,  7.2678e-02,  1.1028e-02],\n                         [-2.9001e-02,  7.9169e-02,  6.1683e-03]]],\n               \n               \n                       [[[-1.1720e-01, -1.8118e-01,  4.0996e-02],\n                         [-1.3368e-01,  3.6396e-01, -1.2599e-01],\n                         [ 3.0136e-02, -1.1566e-01, -1.1682e-01]],\n               \n                        [[ 1.6669e-02, -1.3124e-01,  1.2207e-01],\n                         [ 1.2683e-02, -2.2742e-01,  1.0169e-02],\n                         [ 9.9444e-02, -6.0992e-02, -3.4470e-02]],\n               \n                        [[-1.8972e-01,  2.5069e-01, -1.3005e-01],\n                         [ 2.2086e-01, -1.9755e-01,  2.0031e-01],\n                         [-1.5071e-01,  2.7239e-01, -2.2554e-01]],\n               \n                        ...,\n               \n                        [[-1.2090e-02, -2.4703e-02,  3.3789e-02],\n                         [ 6.0388e-03,  3.3227e-04,  3.7475e-02],\n                         [-3.1199e-02,  1.3531e-01, -9.2383e-02]],\n               \n                        [[ 6.6591e-05, -5.7510e-02,  6.8239e-02],\n                         [-1.1176e-01,  1.5241e-02, -5.7467e-02],\n                         [-8.3598e-02, -8.4460e-03, -7.0906e-02]],\n               \n                        [[ 3.0326e-01,  1.6583e-01,  2.4886e-01],\n                         [-1.2666e-01, -2.2491e-02, -9.5190e-02],\n                         [ 2.1930e-01,  8.4749e-02,  1.6308e-01]]],\n               \n               \n                       [[[-5.7084e-02,  3.0454e-02,  1.4534e-02],\n                         [-2.6096e-02,  8.5955e-02, -1.0251e-01],\n                         [ 3.5992e-02, -5.6200e-02, -9.6928e-02]],\n               \n                        [[-2.9459e-02,  7.6761e-03, -8.7193e-03],\n                         [-1.1683e-02,  6.3584e-03, -7.6606e-02],\n                         [-5.7867e-02, -1.2527e-02,  5.0091e-02]],\n               \n                        [[ 3.9210e-02, -5.7164e-02, -7.1204e-02],\n                         [ 2.0289e-02, -2.3000e-03, -3.0043e-02],\n                         [-8.2748e-02, -1.1849e-03, -6.2787e-02]],\n               \n                        ...,\n               \n                        [[-5.4654e-04,  6.3958e-02,  6.6626e-02],\n                         [-3.5641e-02,  1.9694e-03, -1.0189e-02],\n                         [-5.8551e-02, -6.6320e-02, -9.3136e-02]],\n               \n                        [[ 1.3807e-01,  2.8843e-01,  1.0484e-01],\n                         [-2.2480e-02, -4.1168e-01, -4.6076e-01],\n                         [-1.2655e-02,  3.2067e-01,  2.2326e-01]],\n               \n                        [[ 7.7805e-02,  1.5990e-01,  1.0789e-01],\n                         [ 1.5176e-01,  1.0782e-01,  1.0146e-01],\n                         [ 1.8726e-01,  1.7092e-01,  1.4508e-01]]]])),\n              ('backbone.models.0.model.layer1.2.bn2.weight',\n               tensor([0.7244, 2.1702, 0.8870, 1.0108, 0.6867, 1.0309, 1.0505, 1.1313, 0.7909,\n                       0.6149, 1.0315, 0.7472, 1.1139, 0.9806, 0.9554, 1.0535, 1.0662, 1.0882,\n                       1.1244, 0.7898, 1.1037, 1.0208, 1.0143, 1.0188, 0.9690, 2.0582, 1.0434,\n                       1.0193, 1.0363, 0.9231, 1.1865, 1.0952, 1.1293, 1.0297, 1.0209, 1.0618,\n                       1.0526, 1.5391, 1.0596, 0.9872, 1.0298, 0.8182, 1.0591, 0.8081, 1.0428,\n                       1.0610, 0.6978, 0.6762, 1.0132, 1.1437, 1.1887, 1.2422, 0.9244, 1.0689,\n                       0.4447, 0.9825, 1.0552, 0.8732, 1.1019, 0.9510, 0.9659, 1.1188, 0.7650,\n                       0.8507])),\n              ('backbone.models.0.model.layer1.2.bn2.bias',\n               tensor([ 1.8430, -0.7484,  0.0512, -0.1881,  1.7641, -0.0972, -0.2221, -0.4417,\n                        0.1314,  1.9613, -0.0956,  0.5992, -0.5901,  0.1066, -0.4400, -0.1935,\n                       -0.3370, -0.2770, -0.3163,  0.7048, -0.6560, -0.2215, -0.2281, -0.3387,\n                       -0.1583, -1.6544, -0.1603, -0.2701, -0.0881, -0.1055, -0.6591, -0.2200,\n                       -0.2859, -0.0896, -0.2743, -0.3054, -0.2409, -0.7262, -0.2628,  0.0812,\n                       -0.3554,  0.1836, -0.2249,  0.1894, -0.1569, -0.0376,  2.4377,  2.1966,\n                       -0.2565, -0.3231, -0.4730, -0.7255, -0.0730, -0.2403,  1.4426, -0.3807,\n                       -0.2566,  0.0935, -0.6371, -0.1326,  0.0755, -0.3212,  0.8279,  0.1336])),\n              ('backbone.models.0.model.layer1.2.bn2.running_mean',\n               tensor([-1.9087, -3.6585, -1.2825, -0.0104,  2.6361, -0.1625, -0.9788, -0.3000,\n                       -2.1452,  0.4012, -0.6069, -0.0555, -1.6374, -1.3166, -1.2017, -0.3990,\n                       -0.8066,  0.2543, -0.7991,  0.1395, -1.2597, -0.1634, -0.5835, -1.0221,\n                       -0.6036, -3.5035, -0.3266, -0.4308, -0.5583,  0.3687, -0.7404, -0.2124,\n                        1.2097, -0.2444, -0.0203, -0.6126, -0.4754, -1.0413, -1.0595, -0.3775,\n                       -1.6231, -1.1651, -0.7058, -0.8148, -0.5554,  0.3768, -1.8784,  6.3228,\n                       -1.3222, -0.3900, -0.8871, -1.6890,  0.5889, -1.0381, -0.3067, -0.7752,\n                       -1.0525, -1.0419, -0.9248, -0.4744, -1.2439, -1.2443, -1.1478, -0.7946])),\n              ('backbone.models.0.model.layer1.2.bn2.running_var',\n               tensor([ 6.1094, 13.9451,  5.5882,  5.2795,  6.4398,  6.6716,  4.5785,  3.9981,\n                        4.7359,  4.2992,  6.2875,  6.0544,  4.8171,  5.7842,  4.8935,  6.8426,\n                        4.4725,  6.7269,  6.0798,  7.8258,  6.5990,  4.8959,  4.7540,  3.2323,\n                        4.8016, 19.8916,  6.0551,  6.2593,  7.2316,  5.0159,  3.6811,  4.8232,\n                        7.2890,  5.1866,  6.3340,  6.8577,  4.6523,  7.9705,  7.5275,  6.1779,\n                        4.2654,  4.2437,  4.5198,  4.8060,  5.4374,  6.8592,  4.7604,  6.9145,\n                        4.8575,  5.0504,  5.0773,  4.4886,  5.8675,  7.2865,  3.9721,  6.3475,\n                        6.9352,  5.0521,  6.7708,  5.8321,  5.5160,  5.9652,  5.0606,  4.8465])),\n              ('backbone.models.0.model.layer1.2.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer1.2.conv3.weight',\n               tensor([[[[ 7.5431e-02]],\n               \n                        [[ 1.9592e-01]],\n               \n                        [[ 4.2476e-05]],\n               \n                        ...,\n               \n                        [[-8.3501e-02]],\n               \n                        [[ 1.1275e-01]],\n               \n                        [[-1.7957e-01]]],\n               \n               \n                       [[[-1.7112e-01]],\n               \n                        [[-1.7181e-01]],\n               \n                        [[ 3.1324e-02]],\n               \n                        ...,\n               \n                        [[ 2.0772e-01]],\n               \n                        [[ 2.2725e-01]],\n               \n                        [[ 9.7331e-02]]],\n               \n               \n                       [[[-6.2918e-02]],\n               \n                        [[ 9.9921e-02]],\n               \n                        [[ 8.1362e-03]],\n               \n                        ...,\n               \n                        [[ 1.7329e-02]],\n               \n                        [[-1.0533e-01]],\n               \n                        [[ 3.6993e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-1.2731e-02]],\n               \n                        [[ 1.2170e-01]],\n               \n                        [[-7.8827e-03]],\n               \n                        ...,\n               \n                        [[-1.4254e-02]],\n               \n                        [[ 2.8074e-03]],\n               \n                        [[-1.1674e-02]]],\n               \n               \n                       [[[-6.0354e-02]],\n               \n                        [[ 3.0544e-02]],\n               \n                        [[-1.4379e-01]],\n               \n                        ...,\n               \n                        [[ 1.5999e-02]],\n               \n                        [[ 2.8013e-01]],\n               \n                        [[-2.6832e-02]]],\n               \n               \n                       [[[ 1.4166e-02]],\n               \n                        [[-1.1667e-01]],\n               \n                        [[-7.2309e-03]],\n               \n                        ...,\n               \n                        [[-2.6724e-03]],\n               \n                        [[ 1.3451e-02]],\n               \n                        [[-6.7583e-04]]]])),\n              ('backbone.models.0.model.layer1.2.bn3.weight',\n               tensor([ 3.9266e-01,  6.1348e-01, -5.6073e-02, -1.5774e-01,  4.8575e-02,\n                        7.4929e-01, -4.2242e-01, -2.6276e-01,  2.5007e-01, -4.8416e-01,\n                        3.0696e-01,  5.4822e-02, -1.5242e-01,  2.8192e-01, -7.1875e-01,\n                        1.7752e-01,  8.1594e-01, -2.2654e-01, -1.8399e-01,  2.2722e-02,\n                        3.1909e-01,  2.1395e-01, -1.0650e-02,  1.1335e-02,  1.0953e-01,\n                        6.8757e-01,  1.3713e-01, -3.3941e-01,  7.7540e-02, -7.0308e-01,\n                        3.4981e-01, -9.0217e-01,  3.8846e-02, -3.2323e-01, -6.2186e-02,\n                        1.2774e-01,  5.8600e-02, -6.0107e-02,  1.5014e-01, -8.6253e-03,\n                        8.7921e-01,  1.2864e+00, -5.7193e-01, -6.0146e-01, -6.9680e-02,\n                       -1.0556e-01,  2.3089e-02,  8.8987e-02,  3.6695e-01, -8.5422e-02,\n                        8.2749e-01, -2.1276e-01,  7.5881e-01,  1.5850e-01,  6.3537e-02,\n                       -5.7247e-01, -2.8250e-02,  4.2309e-01, -1.0892e-01, -1.5971e-01,\n                       -4.6294e-01,  7.9445e-02,  1.8802e-02,  5.3181e-02,  3.7477e-01,\n                        9.2312e-02,  2.2997e-02,  2.9030e-01,  1.4345e-01, -2.4324e-01,\n                       -3.2955e-01,  3.8716e-01,  4.2299e-01, -4.3640e-01, -4.1142e-01,\n                        4.2710e-01, -1.6597e-01,  5.5081e-01, -2.6198e-01, -5.1833e-01,\n                       -1.3855e-01, -1.5236e-01,  4.2795e-01,  6.1830e-01, -2.8147e-01,\n                        6.6472e-03, -8.4879e-01, -3.9164e-02, -2.3651e-01,  1.2131e-01,\n                        6.3200e-01,  2.2875e-02,  1.5458e-01, -3.7888e-02,  5.1333e-02,\n                        6.1411e-01, -5.9975e-01,  8.7340e-03,  2.2667e-02,  2.6660e-01,\n                       -7.9067e-02,  1.2252e-01, -7.7860e-01, -1.2249e-01,  1.0130e-01,\n                       -6.2529e-01,  4.4847e-02, -1.7684e-01, -1.1765e-01,  1.5954e-01,\n                       -1.1128e-01,  1.3705e-01, -3.6674e-01, -6.8256e-02, -9.9788e-02,\n                       -3.4495e-01,  2.6155e-01, -1.3149e-01,  6.3725e-01,  8.4649e-02,\n                       -3.5185e-01,  4.2695e-01,  1.9826e+00, -2.3202e-01,  1.1675e+00,\n                       -7.7832e-02, -1.0745e-01, -1.7923e-01,  1.1766e-01,  4.0353e-01,\n                       -6.6588e-01, -1.7227e-03, -4.0730e-01, -6.0161e-01, -2.0009e-01,\n                       -2.1127e-01, -5.5209e-02,  1.3949e-01, -6.8378e-01, -9.7618e-02,\n                       -1.1930e-02,  1.5132e-02, -8.2627e-02, -5.4768e-01, -5.4405e-01,\n                        2.1238e-01,  5.2262e-01, -1.7785e-01,  2.9114e-01, -5.1035e-05,\n                        3.0973e-01,  3.0025e-01,  1.1355e-01, -8.8209e-02, -2.9471e-02,\n                        2.5221e-01, -1.5560e-01, -8.8824e-01,  8.0905e-02, -1.0526e-01,\n                       -1.2212e-01, -1.7749e-01, -6.4498e-01,  4.3303e-01,  8.0688e-02,\n                        2.4912e-03,  2.0845e-01, -1.8076e-01,  8.2397e-02,  3.9819e-01,\n                        4.1922e-01,  3.1906e-01,  1.0327e-01, -1.6094e-02, -1.9042e-01,\n                        7.8875e-01, -3.4267e-01, -3.5092e-01,  5.3107e-01,  5.9051e-01,\n                       -5.9463e-02, -4.2662e-01, -7.8763e-02, -7.3658e-02,  3.5573e-02,\n                       -4.4979e-01, -4.3687e-01,  9.6240e-02, -9.6783e-02,  3.6117e-01,\n                       -3.1701e-01, -1.2439e-01, -2.2388e-01,  2.7664e-01, -1.7163e-01,\n                        3.4317e-01,  6.0071e-01, -6.4539e-01, -6.1959e-02, -8.7014e-03,\n                        3.5241e-01,  8.1051e-01, -3.1662e-01, -7.1035e-02, -6.7777e-01,\n                       -3.2175e-01, -6.8302e-02, -2.7640e-03,  5.4815e-01,  9.1586e-02,\n                        1.4730e-02, -3.7398e-01, -3.0273e-01,  2.1253e-01,  1.0860e+00,\n                       -1.0748e-01,  6.7701e-03,  1.1880e-01, -4.8341e-01,  3.8384e-02,\n                       -1.1042e-01,  7.8241e-01,  8.1312e-01,  2.2448e-02, -4.4155e-01,\n                        1.4100e-01, -1.7012e-01,  3.2131e-01, -1.0281e+00,  9.8643e-02,\n                        1.4904e-01, -4.9204e-01,  4.6989e-03, -7.3113e-02, -2.0007e-01,\n                       -5.9941e-02, -2.5144e-01,  6.5253e-01, -2.2131e-01,  7.9677e-02,\n                       -2.0799e-01, -5.3789e-02, -9.6623e-02, -8.1682e-02,  1.3019e-02,\n                        9.2981e-01, -7.7276e-03,  5.3478e-01,  6.2709e-01, -1.3022e-01,\n                       -8.3509e-02, -3.3862e-01, -1.0493e-01,  3.9344e-03,  2.8442e-01,\n                       -2.4424e-03])),\n              ('backbone.models.0.model.layer1.2.bn3.bias',\n               tensor([-2.9611e-01, -2.7953e-01, -7.7141e-02,  1.4393e-03,  2.1567e-03,\n                       -6.3911e-01,  2.0040e-01, -1.8406e-01, -3.0477e-01,  8.1107e-02,\n                        3.5001e-01, -6.1821e-02,  9.8600e-02, -2.4321e-01, -4.5395e-01,\n                        3.9983e-02, -6.2932e-01, -1.7346e-01, -4.7232e-03,  5.6330e-03,\n                        1.7356e-01,  5.1178e-03,  3.9066e-02, -1.5131e-01, -1.4921e-02,\n                       -6.2651e-01,  2.8003e-02, -1.7636e-01, -9.0558e-02, -4.2522e-01,\n                        4.0267e-01, -9.8203e-01, -6.8768e-02,  7.7364e-02, -3.3373e-01,\n                        1.5718e-01,  7.5739e-03, -5.3480e-02,  1.0419e-01,  1.0521e-01,\n                       -6.9376e-01, -1.8352e+00, -4.2188e-01, -5.0951e-01,  6.7051e-02,\n                        3.7247e-01,  1.1529e-01,  9.9803e-02,  2.3217e-01, -1.1002e-02,\n                       -9.9775e-01, -1.9547e-01, -3.6278e-01,  1.4722e-02, -2.1269e-02,\n                       -5.8067e-01, -1.3341e-01,  1.0455e-01,  5.3887e-02, -1.7555e-01,\n                        6.0050e-03, -2.5662e-01,  1.0114e-01,  2.0060e-02, -2.7712e-01,\n                        1.4272e-01, -2.1947e-01, -1.7271e-01, -5.9603e-02,  1.2767e-01,\n                        1.1618e-02, -2.4038e-01, -8.3038e-02, -4.9459e-01, -5.3404e-01,\n                       -9.5085e-02,  3.1640e-01, -1.2673e-01,  4.3194e-01, -2.5041e-01,\n                        1.3468e-01,  2.0531e-01, -5.2551e-02, -4.6634e-01,  3.6971e-01,\n                        1.7726e-01, -8.4581e-01,  1.5969e-02, -1.6458e-01, -1.1499e-01,\n                       -4.4966e-01, -4.7699e-02,  1.0763e-01, -3.2294e-01,  9.7992e-02,\n                       -1.3796e-01, -5.3062e-01,  4.8190e-02, -1.2604e-02,  9.5787e-02,\n                       -1.7148e-02,  1.5912e-01, -4.5669e-01,  1.1675e-01, -7.3584e-02,\n                       -1.4264e-01,  1.3340e-02,  1.6244e-01,  3.2137e-01,  4.0689e-01,\n                       -8.3632e-02,  2.0786e-01, -2.9664e-01,  5.1936e-01,  2.7784e-01,\n                       -4.3077e-01, -6.3361e-02,  3.0966e-02, -5.0702e-01,  2.1802e-02,\n                        4.4171e-01, -5.9158e-02,  2.7628e-01, -1.9568e-01, -7.2744e-01,\n                       -4.1641e-03,  1.1695e-01, -1.0213e-01,  1.5874e-01, -2.8663e-01,\n                       -4.4307e-01,  5.0374e-03, -3.9184e-02, -2.5252e-01, -1.6595e-02,\n                       -1.9497e-02,  1.3813e-01,  2.4370e-01, -6.4563e-01,  4.1833e-02,\n                       -1.9211e-02, -1.6485e-01,  6.3340e-02, -3.4817e-01, -4.3916e-01,\n                        1.6869e-01, -2.1339e-01,  3.1245e-01,  9.3373e-02, -1.9203e-01,\n                        5.4708e-01, -2.9499e-01,  6.2221e-01,  6.9728e-02,  2.7296e-01,\n                       -1.4727e-01,  3.2589e-01, -5.8720e-01, -5.4404e-02,  1.5159e-01,\n                       -7.6593e-04,  2.6176e-01, -6.3307e-01, -3.5372e-01,  1.5379e-01,\n                        6.3280e-02, -2.5190e-02,  4.1833e-03,  3.1239e-02, -1.5026e-01,\n                        1.3353e-01,  4.6577e-01, -5.7861e-02,  1.3243e-02,  9.9025e-02,\n                       -8.4992e-01, -9.9330e-02,  1.3080e-01, -2.1104e-01, -1.6114e-01,\n                       -9.0898e-02, -1.7786e-01,  1.8163e-01, -1.5423e-01,  7.5752e-02,\n                        2.5027e-01, -3.2513e-01,  5.0775e-02,  7.0981e-02, -2.1254e-01,\n                        3.8272e-01,  2.8729e-01,  4.1709e-02,  1.0623e-02, -6.5631e-02,\n                        1.7694e-01, -2.7056e-01, -5.5383e-01,  8.1280e-02, -1.2128e-01,\n                       -3.6783e-01, -8.4664e-01,  1.3458e-01, -6.5071e-02, -5.0583e-01,\n                        5.5514e-02,  2.8546e-01, -2.1294e-01, -6.2600e-01,  2.2684e-01,\n                        1.3530e-02, -2.0364e-01, -3.4774e-01, -7.2943e-02, -9.4926e-01,\n                       -1.2290e-01, -7.7298e-04,  2.5543e-01, -2.5707e-01, -1.5419e-01,\n                       -1.7272e-01, -2.6799e-01, -4.1394e-01,  2.1507e-02, -2.1248e-01,\n                        3.0385e-01, -8.5680e-02, -2.5219e-01, -7.3447e-01, -5.8453e-02,\n                        5.6879e-02, -1.0987e-01,  8.9899e-02, -1.1497e-01,  1.4659e-01,\n                        1.9276e-01, -2.5680e-01, -3.4589e-01,  8.2379e-02,  1.9578e-01,\n                        3.2625e-02,  3.1045e-02, -1.3287e-02,  9.3503e-02,  2.3837e-01,\n                       -9.9274e-01,  3.6237e-01, -3.2693e-01, -5.9526e-01, -3.3270e-02,\n                        2.9389e-01,  4.6644e-01,  1.3235e-02, -8.8016e-02,  7.9677e-02,\n                        9.9417e-02])),\n              ('backbone.models.0.model.layer1.2.bn3.running_mean',\n               tensor([-2.5380e-01, -8.6105e-01, -2.1028e-01,  1.0450e+00, -4.9736e-02,\n                       -1.5805e+00, -8.4101e-01, -1.3105e+00, -2.1382e-01,  9.1040e-01,\n                        8.5360e-01,  2.1086e-01, -1.6833e-01, -2.0969e-01, -2.2282e+00,\n                        1.8777e-01,  4.1054e-01, -1.5045e-03,  1.7014e+00,  8.8830e-02,\n                        5.9852e-01, -7.8847e-01, -7.7514e-02, -2.5183e-02,  5.0046e-01,\n                       -1.3876e+00,  1.9788e+00,  3.7248e-01, -1.0061e+00,  7.2689e-01,\n                        4.4924e+00,  9.3996e-01, -6.3780e-01, -1.2895e+00, -3.3833e-01,\n                       -3.2970e-01, -7.4303e-01,  1.3198e-01, -9.1938e-01,  1.0150e-01,\n                       -9.8787e-01, -8.9134e-02,  2.3724e+00,  6.1808e-02,  3.4777e-01,\n                       -3.7927e-01,  5.8900e-02,  5.4306e-01, -1.5970e-01,  3.1420e-01,\n                        7.7580e-03,  5.2248e-01, -6.7986e-01,  3.6375e-01, -2.3757e-02,\n                        5.7560e-01,  4.6789e-03, -2.0336e-01, -1.0309e-01, -3.2262e-01,\n                        1.3509e+00, -6.1006e-01, -1.0445e-01,  2.1020e-01, -5.3573e-01,\n                       -4.8912e-01, -9.3207e-02,  6.9846e-01, -3.3551e-01, -1.6837e+00,\n                        2.6179e-01, -2.2351e-02,  1.7917e+00,  1.3279e+00,  5.7447e-01,\n                       -2.9609e-01,  6.8001e-01, -1.9898e-01,  6.6340e-01, -1.1069e+00,\n                       -5.7143e-02,  1.7974e+00, -1.1843e+00,  2.6293e-01,  5.1579e-01,\n                       -2.5875e-03,  8.5676e-01,  2.7810e-01,  3.2898e-01, -5.9764e-01,\n                       -4.8569e-01,  3.4138e-02, -8.9308e-01,  1.8587e-01, -3.9376e-01,\n                        7.4072e-01,  6.2470e-01,  9.5030e-02, -1.1050e-02,  7.1606e-01,\n                        2.2582e-01,  1.3298e-01, -7.5293e-01, -3.6664e-01,  1.1188e-01,\n                       -4.8054e-01,  2.3949e-01,  9.2866e-01,  3.7588e-01, -8.3117e-01,\n                        6.6206e-01,  1.0085e+00,  4.5201e-01,  6.0863e-02, -3.0598e-01,\n                        2.9418e-01, -7.1723e-02, -1.3666e-01, -8.0016e-01, -9.1492e-02,\n                        1.4501e+00,  4.5250e-01, -1.6013e+00,  8.2562e-01,  5.2369e-01,\n                        3.8110e-01, -1.6785e-01, -8.4240e-01,  5.4571e-01, -5.9621e-01,\n                        2.8415e-01,  4.2923e-02, -4.8268e-01,  1.1247e+00, -4.1770e-02,\n                       -1.0592e+00,  2.5558e-01,  1.4721e+00, -2.3888e-03, -9.0214e-02,\n                        3.1507e-02,  5.2837e-02,  1.2099e+00,  4.6507e-01,  7.8387e-01,\n                        4.8157e-01,  6.7744e-01,  1.3546e+00, -4.0072e-01, -5.0741e-02,\n                       -1.5472e+00,  9.3949e-01,  4.2554e-02,  3.2550e-01, -1.1953e+00,\n                        4.5381e-01,  2.4007e-01,  7.0730e-01, -6.3551e-01,  4.9963e-01,\n                       -1.1133e-01, -2.4754e-01,  1.0205e+00,  8.5422e-01,  4.0282e-01,\n                       -1.5297e-02,  8.7446e-01,  2.1472e-01, -2.1541e-01, -8.3722e-01,\n                       -6.6258e-01,  1.1540e-01, -1.9732e-01,  4.7869e-02,  6.0005e-01,\n                       -2.6757e+00,  1.3574e+00, -7.6317e-02, -6.8887e-01,  7.4967e-01,\n                        8.0448e-01, -2.6113e-01,  3.9127e-01,  1.1551e-01,  2.7838e-02,\n                        6.8713e-01, -9.3056e-03,  8.1249e-01, -9.8941e-01, -3.3643e-01,\n                       -5.6918e-01,  9.4818e-01,  4.0052e-01,  6.4233e-01,  1.0229e+00,\n                        9.5062e-01, -3.3359e-01, -6.2840e-01, -4.4664e-01, -6.7108e-03,\n                       -2.5098e-03, -1.1496e+00,  5.1392e-01,  2.1056e-01, -2.3950e+00,\n                       -1.0377e+00,  3.7527e-01,  8.7864e-02, -5.4298e-01, -3.1368e-01,\n                       -2.5593e-02,  6.4579e-01,  1.0380e+00,  3.4331e-01, -8.8076e-01,\n                        8.4749e-01, -1.1509e-02,  1.8362e-01,  5.6516e-01, -4.1302e-02,\n                        5.0668e-01, -4.9502e-01,  3.4580e-01, -1.9218e-01,  4.0390e-01,\n                       -8.8166e-01, -7.0526e-02, -4.8985e-01,  7.8984e-01, -7.8973e-01,\n                       -1.0579e+00,  9.6384e-02,  3.9369e-02, -2.0669e-02, -3.4781e-01,\n                        5.8260e-01,  1.0834e+00, -3.6370e-01,  9.6184e-01, -7.3021e-01,\n                        3.6058e-01,  5.9500e-02, -9.2347e-01,  5.3933e-01, -3.2109e-02,\n                       -1.0407e+00, -4.6132e-02, -1.5081e+00, -4.9838e-03,  4.5383e-01,\n                        6.9023e-01, -1.6616e+00,  7.6779e-01, -4.3236e-02,  1.1323e+00,\n                       -2.0517e-02])),\n              ('backbone.models.0.model.layer1.2.bn3.running_var',\n               tensor([ 0.3511,  0.5995,  0.0645,  0.3189,  0.1607,  0.3319,  0.4404,  0.2609,\n                        0.3109,  0.5283,  0.5916,  0.1430,  0.9653,  0.3570,  0.5968,  0.2093,\n                        0.6487,  0.2544,  0.2814,  0.0954,  0.3675,  0.4487,  0.0798,  0.0726,\n                        0.1714,  0.4764,  0.4618,  0.5068,  0.2497,  0.7410,  0.8401,  0.2685,\n                        0.1031,  0.3511,  0.0678,  0.4109,  0.1640,  0.0862,  0.1270,  0.0487,\n                        0.4899,  0.6010,  0.6472,  0.3882,  0.0934,  0.1988,  0.0822,  0.2337,\n                        0.4511,  0.6050,  0.4401,  0.7987,  0.8547,  0.2375,  0.0943,  0.5630,\n                        0.1204,  0.4284,  0.1393,  0.1626,  0.5958,  0.1423,  0.1066,  0.0894,\n                        0.3071,  0.2230,  0.1142,  0.3572,  0.3385,  0.3514,  0.3197,  0.5466,\n                        0.4744,  0.5257,  0.3494,  0.7690,  0.2057,  0.4478,  0.3479,  0.3507,\n                        0.3914,  0.2371,  0.3726,  0.4146,  0.3967,  0.0519,  0.3151,  0.1093,\n                        0.1988,  0.1638,  0.4241,  0.0824,  0.1492,  0.0573,  0.1008,  0.3941,\n                        0.4338,  0.0477,  0.0370,  0.4897,  0.0925,  0.3219,  0.7142,  0.1633,\n                        0.1178,  0.7016,  0.0918,  0.2897,  0.1711,  0.2938,  0.4732,  0.1851,\n                        0.6058,  0.2857,  0.1512,  0.4945,  0.3887,  0.1842,  0.4777,  0.0902,\n                        0.2644,  0.5894, 13.6185,  1.2859,  0.9978,  0.1541,  0.2087,  0.6547,\n                        0.6625,  0.4413,  0.5527,  0.0966,  0.3817,  0.3985,  0.2564,  0.5712,\n                        0.1691,  0.2426,  0.4737,  0.3493,  0.0416,  0.0782,  0.2640,  0.4197,\n                        0.3646,  0.2087,  0.6124,  0.2491,  0.3361,  0.0738,  0.3690,  0.2783,\n                        0.7795,  0.1382,  0.1496,  0.2790,  0.2912,  0.6573,  0.5965,  0.2260,\n                        0.1879,  0.2933,  0.4896,  0.4048,  0.1798,  0.0526,  0.3513,  0.2097,\n                        0.1391,  0.4542,  0.4926,  0.2945,  0.2416,  0.1020,  0.2347,  0.5608,\n                        0.4471,  0.3872,  0.8675,  0.7127,  0.1017,  0.3370,  0.1755,  0.1165,\n                        0.1132,  0.6073,  0.3112,  0.1672,  0.1093,  0.8101,  0.2875,  0.1856,\n                        0.3518,  0.4257,  0.2904,  0.4157,  0.5849,  0.4954,  0.1421,  0.0446,\n                        0.3586,  0.4898,  0.4280,  0.1455,  0.4401,  0.5296,  0.1281,  0.0755,\n                        0.4246,  0.2083,  0.0626,  0.3435,  0.3234,  0.3114,  1.3809,  0.2267,\n                        0.0947,  0.1475,  0.6667,  0.0207,  0.1571,  0.9165,  1.0157,  0.1034,\n                        0.6329,  0.2137,  0.3803,  0.3240,  0.6106,  0.2385,  0.2334,  0.9564,\n                        0.0749,  0.3749,  0.4393,  0.1436,  0.4494,  0.4501,  0.2414,  0.2114,\n                        0.3310,  0.1836,  0.1121,  0.1502,  0.1900,  0.3922,  0.0647,  0.6405,\n                        0.4660,  0.1735,  0.1569,  0.3853,  0.1930,  0.0600,  0.3489,  0.0419])),\n              ('backbone.models.0.model.layer1.2.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.0.conv1.weight',\n               tensor([[[[-4.1330e-02]],\n               \n                        [[ 1.6953e-01]],\n               \n                        [[ 7.1092e-03]],\n               \n                        ...,\n               \n                        [[ 4.6136e-02]],\n               \n                        [[ 2.6106e-02]],\n               \n                        [[ 9.5705e-02]]],\n               \n               \n                       [[[-8.1868e-02]],\n               \n                        [[-2.0993e-04]],\n               \n                        [[-1.4997e-04]],\n               \n                        ...,\n               \n                        [[-4.1344e-02]],\n               \n                        [[-4.0936e-02]],\n               \n                        [[ 3.2273e-02]]],\n               \n               \n                       [[[-7.8845e-02]],\n               \n                        [[-6.9849e-02]],\n               \n                        [[-7.6958e-02]],\n               \n                        ...,\n               \n                        [[-2.2674e-02]],\n               \n                        [[ 1.1436e-01]],\n               \n                        [[ 1.5306e-01]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 3.2539e-02]],\n               \n                        [[-1.2928e-01]],\n               \n                        [[-1.4296e-02]],\n               \n                        ...,\n               \n                        [[ 7.6514e-03]],\n               \n                        [[ 1.1155e-01]],\n               \n                        [[-9.0902e-02]]],\n               \n               \n                       [[[-5.9431e-02]],\n               \n                        [[-1.0699e-02]],\n               \n                        [[-2.0690e-02]],\n               \n                        ...,\n               \n                        [[ 1.9168e-02]],\n               \n                        [[ 2.3308e-03]],\n               \n                        [[-3.6185e-02]]],\n               \n               \n                       [[[-1.3679e-01]],\n               \n                        [[ 1.5494e-03]],\n               \n                        [[-1.8439e-02]],\n               \n                        ...,\n               \n                        [[ 4.5281e-01]],\n               \n                        [[ 2.5946e-02]],\n               \n                        [[ 4.9053e-02]]]])),\n              ('backbone.models.0.model.layer2.0.bn1.weight',\n               tensor([1.1945, 1.9419, 0.7271, 0.9738, 1.5554, 1.3561, 0.8041, 1.1194, 1.9046,\n                       0.7526, 1.3020, 0.9124, 1.0625, 0.8606, 1.1168, 1.2067, 1.1171, 1.2192,\n                       1.1233, 1.1386, 0.7820, 1.3253, 1.5261, 1.2368, 1.0697, 0.7456, 1.1083,\n                       1.0244, 1.3796, 1.1931, 1.3197, 1.1029, 1.0155, 1.1463, 1.3570, 1.1364,\n                       1.1699, 1.3968, 1.2409, 0.5553, 1.3133, 0.9787, 1.4456, 1.0364, 1.5388,\n                       1.0209, 1.0700, 0.8302, 1.3704, 1.0742, 1.0770, 1.1631, 1.0618, 0.8490,\n                       1.0518, 1.3521, 0.7262, 0.8429, 1.0446, 1.0252, 0.8904, 1.2605, 0.9988,\n                       1.3081, 1.2874, 1.0265, 1.1981, 0.8836, 1.0844, 0.8050, 1.0666, 0.7789,\n                       0.9517, 1.4314, 1.3349, 0.9713, 0.9381, 0.8078, 1.0874, 1.0792, 1.1675,\n                       0.9912, 1.2293, 1.5853, 1.1888, 0.9170, 1.2230, 0.7904, 1.0557, 1.0950,\n                       1.0565, 1.3577, 0.9441, 1.0064, 1.3689, 1.2117, 1.2211, 1.3450, 1.1525,\n                       1.1785, 0.8903, 1.0946, 0.9947, 1.1048, 1.0630, 1.0384, 1.2159, 1.2398,\n                       1.1363, 1.0003, 0.9113, 1.1877, 1.0873, 0.9872, 1.4131, 1.3791, 0.7360,\n                       1.1183, 0.8051, 1.2306, 0.8615, 0.7411, 1.1848, 1.0929, 1.0700, 1.1440,\n                       0.9057, 1.0240])),\n              ('backbone.models.0.model.layer2.0.bn1.bias',\n               tensor([-0.7705, -1.2381,  0.1976, -0.1052, -1.3599, -0.9675,  0.0924, -0.7965,\n                       -1.1107,  0.2091, -0.7642,  0.0189, -0.1979,  0.0241, -1.3678, -1.0592,\n                       -0.6935, -0.5570, -0.5286, -0.9347,  0.5816, -0.8731, -1.1150, -0.3073,\n                       -0.4701,  0.1857, -0.6638, -0.1131, -0.8780, -0.4987, -0.9748, -0.4337,\n                       -0.3796, -0.5234, -0.7739, -0.6013, -0.8047, -0.9479, -0.8647,  1.0308,\n                       -0.9014, -0.2455, -0.8902, -0.5849, -1.9063, -0.2452, -0.5199,  0.0352,\n                       -0.9496, -0.3816, -0.7392, -0.3275, -0.2911, -0.3172, -0.4100, -0.8219,\n                        0.2754, -0.1311, -0.4174, -0.4523, -0.3157, -0.8630, -0.3049, -0.6064,\n                       -0.9073, -0.2749, -0.6197, -0.2743, -0.7154,  0.3803, -0.2594, -0.0423,\n                       -0.3519, -1.2606, -1.0100, -0.3011, -0.4663, -0.0261, -0.5876, -0.4449,\n                       -0.7114, -0.3065, -0.7081, -1.4787, -0.8268,  0.0140, -0.6817,  0.2799,\n                       -0.5793, -0.2789, -0.7373, -0.8405, -0.6052, -0.5860, -0.7880, -0.5951,\n                       -0.8800, -0.9668, -0.9205, -0.7766, -0.2818, -0.3545, -0.2557, -0.4223,\n                       -0.4181, -0.7749, -1.6606, -0.8294, -0.7450, -0.2674, -0.1291, -0.6146,\n                       -0.4183, -0.2613, -1.0228, -1.0049,  0.4429, -0.6164,  0.0822, -0.9709,\n                       -0.3160,  0.2339, -0.2677, -0.6437, -0.3683, -0.8141, -0.0765, -0.2386])),\n              ('backbone.models.0.model.layer2.0.bn1.running_mean',\n               tensor([-2.3264,  2.6612,  1.3971,  2.3131,  2.2969,  1.1565,  0.4728, -1.7328,\n                       -0.2419,  1.4182, -4.6507, -0.0297, -0.8641,  1.6410, -1.5974,  2.5389,\n                       -0.0840,  1.2938, -0.1521,  0.1231,  2.3243,  1.5194, -3.0496, -0.9171,\n                       -0.1465, -1.2364, -1.6216, -1.6847, -6.0191,  1.0397, -0.0120,  1.5743,\n                        0.3165, -1.4052, -0.9633,  2.0652, -2.3934,  0.5728, -5.3964,  4.4257,\n                        0.0547, -0.6552,  0.3348,  2.1946, -1.7303, -1.7159, -0.5676, -0.0128,\n                       -0.0905,  1.3331,  1.5680, -2.8396,  1.2810,  0.7116,  1.1137, -1.4549,\n                       -1.0697, -2.8896,  0.2946,  1.1485, -0.7357, -2.7245,  4.1112,  3.3043,\n                       -0.8273, -1.2867,  1.2481,  1.3902, -1.9557, -2.5192,  0.9856,  1.5444,\n                        1.5873,  0.0544, -3.3492, -2.5335, -0.1110, -2.2427, -1.5126, -2.6128,\n                       -4.5129, -4.8056,  4.0743,  2.6211, -2.7737, -0.1097, -1.7612, -0.6105,\n                       -2.3790,  0.1068, -5.5737, -0.1868,  2.3916,  0.0733, -2.2239, -1.0523,\n                        1.7977, -2.3481,  3.3875, -1.1437, -2.8751, -0.1198,  1.5031, -4.6116,\n                        1.3227, -2.7676,  2.2177, -1.5230, -4.2366,  0.9430, -0.4117,  0.2170,\n                       -2.1161, -3.2567,  1.1678, -3.4437, -0.4874, -2.8611,  1.8422,  1.1526,\n                        2.7898,  2.4648,  2.3103, -2.7728,  1.0084, -1.4046, -1.7335,  0.2225])),\n              ('backbone.models.0.model.layer2.0.bn1.running_var',\n               tensor([1.3807, 2.5865, 1.3610, 1.8771, 0.9208, 1.7011, 1.3434, 0.8395, 3.7641,\n                       1.8073, 0.8954, 2.2280, 1.7168, 1.5533, 0.4307, 0.9328, 1.4441, 1.0056,\n                       1.4967, 0.5824, 2.9687, 0.9115, 0.7088, 2.1287, 1.4109, 1.6944, 1.0282,\n                       1.5169, 0.7165, 1.8105, 0.9255, 1.7223, 1.1977, 1.2224, 1.4299, 0.8626,\n                       1.2984, 0.8058, 1.2563, 1.3696, 1.3791, 1.5972, 1.2496, 1.5087, 0.6264,\n                       1.5494, 1.1001, 2.0207, 0.7308, 0.9815, 1.2020, 1.2286, 1.1257, 0.9726,\n                       1.6460, 1.1600, 1.9464, 1.4929, 1.5513, 1.7176, 0.8158, 1.5325, 1.6376,\n                       1.2134, 1.3631, 1.9024, 1.3165, 1.0602, 0.9014, 1.9494, 1.6456, 0.6508,\n                       1.0825, 1.2034, 1.4434, 1.4470, 1.1106, 1.2932, 1.4630, 1.2633, 1.0907,\n                       1.3723, 0.7318, 0.8248, 1.4786, 2.0776, 1.7868, 2.5983, 1.0326, 2.2104,\n                       0.7441, 1.1454, 1.0508, 1.2685, 0.6694, 1.1228, 1.1687, 1.3459, 0.8169,\n                       1.1872, 1.1648, 0.9876, 1.8438, 1.7407, 1.6638, 1.2148, 0.7582, 0.7155,\n                       0.9923, 1.2723, 1.7838, 0.9973, 1.2610, 1.5894, 0.6840, 1.2373, 1.9210,\n                       1.1110, 1.6897, 0.7218, 1.2730, 1.3643, 1.5068, 1.3595, 1.4879, 1.0275,\n                       2.0028, 1.2467])),\n              ('backbone.models.0.model.layer2.0.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.0.conv2.weight',\n               tensor([[[[-1.6466e-02,  1.4923e-02,  2.7611e-02],\n                         [-2.7910e-02, -5.3267e-02, -2.6102e-02],\n                         [ 1.8458e-02,  7.7943e-03,  3.2768e-02]],\n               \n                        [[-1.0870e-02, -2.2039e-02,  3.7536e-03],\n                         [-1.1316e-03, -3.3010e-02, -2.2075e-02],\n                         [-1.3059e-02,  5.1394e-03, -1.4547e-02]],\n               \n                        [[-1.5657e-02, -1.1510e-03, -1.1683e-02],\n                         [-1.2713e-02, -4.3754e-02,  7.7824e-03],\n                         [-6.7680e-03, -1.0707e-02,  7.7736e-02]],\n               \n                        ...,\n               \n                        [[ 1.7391e-02, -1.0232e-02, -6.1846e-03],\n                         [-1.3366e-02, -8.4514e-03,  2.8122e-02],\n                         [-2.3102e-02,  3.9554e-02,  3.7099e-02]],\n               \n                        [[ 1.7731e-02,  1.8982e-02,  2.2779e-02],\n                         [-1.6391e-02, -5.4384e-02, -4.2135e-03],\n                         [ 3.0138e-02,  2.9129e-02,  2.6545e-02]],\n               \n                        [[-9.4689e-02, -2.5274e-01, -3.7804e-01],\n                         [-1.7715e-01, -4.7743e-01, -4.3726e-01],\n                         [ 1.4100e-01,  8.1798e-01,  9.4625e-01]]],\n               \n               \n                       [[[-3.9780e-03,  3.5384e-02,  2.5759e-02],\n                         [-7.4051e-03,  3.8721e-02,  7.1140e-02],\n                         [ 3.4843e-03,  6.0061e-02,  3.7531e-02]],\n               \n                        [[-2.3835e-03, -8.8134e-04, -1.1980e-02],\n                         [-7.9692e-02, -7.5714e-02, -1.2445e-01],\n                         [-6.8318e-02, -1.2307e-01, -1.2106e-01]],\n               \n                        [[ 4.9241e-02,  1.0665e-01,  6.5841e-02],\n                         [ 7.2686e-02, -1.4207e-01,  3.6021e-02],\n                         [ 6.3926e-02,  3.1080e-02, -1.4686e-02]],\n               \n                        ...,\n               \n                        [[ 3.7997e-02,  1.0833e-02, -2.2249e-02],\n                         [ 2.5217e-02,  2.0495e-02,  5.0458e-03],\n                         [-1.9548e-02,  3.9624e-02, -1.8327e-02]],\n               \n                        [[ 6.3269e-02,  6.6964e-02,  3.7736e-02],\n                         [ 4.4117e-02,  5.4946e-02,  7.4803e-02],\n                         [ 1.6231e-02,  5.3472e-02,  9.6303e-02]],\n               \n                        [[ 1.3483e-02,  8.0651e-02,  4.9693e-02],\n                         [ 4.0073e-02,  7.9386e-02,  7.3485e-02],\n                         [-2.4574e-02, -2.3082e-02, -3.1930e-02]]],\n               \n               \n                       [[[ 3.8737e-02, -2.9089e-04,  1.4236e-02],\n                         [-1.2845e-02, -8.1335e-03, -5.4462e-02],\n                         [-5.4403e-02, -5.4892e-02, -9.1068e-02]],\n               \n                        [[-3.5771e-02, -3.5855e-02, -4.7485e-02],\n                         [-1.0460e-01, -6.5688e-02, -1.4545e-01],\n                         [-8.3971e-02, -1.1583e-01, -1.1329e-01]],\n               \n                        [[-7.1010e-02, -5.4091e-02,  4.9459e-04],\n                         [-4.7794e-02,  3.5845e-02, -2.8999e-02],\n                         [-3.9081e-03, -7.7426e-02, -3.4655e-02]],\n               \n                        ...,\n               \n                        [[-6.0876e-02, -5.6762e-02, -1.1232e-02],\n                         [-7.0644e-02, -3.0071e-02, -4.2786e-02],\n                         [ 9.3146e-03, -3.8667e-02, -6.7135e-02]],\n               \n                        [[-4.3243e-03, -1.4888e-02, -5.6518e-02],\n                         [-4.1263e-02, -4.2375e-02, -2.9257e-02],\n                         [-2.7565e-02,  3.4544e-02,  1.8247e-02]],\n               \n                        [[ 3.9821e-02,  5.9312e-02,  1.6302e-03],\n                         [ 5.9012e-02,  6.9373e-02, -1.7375e-02],\n                         [-4.3077e-02, -6.0653e-02, -7.7677e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 8.7742e-03, -6.4250e-03, -2.9589e-02],\n                         [ 8.9867e-02, -1.6328e-01,  3.9682e-02],\n                         [ 8.2724e-02, -1.9323e-01,  6.1708e-02]],\n               \n                        [[-2.4847e-02,  1.5676e-02,  1.7323e-02],\n                         [ 3.5081e-02,  4.1071e-02,  3.4965e-02],\n                         [ 1.8285e-03, -5.8109e-03, -4.8974e-03]],\n               \n                        [[-2.6028e-02,  1.2496e-02, -5.2115e-02],\n                         [-9.0808e-02,  8.7137e-02, -1.2960e-01],\n                         [-1.2507e-01,  4.6094e-02, -7.1316e-02]],\n               \n                        ...,\n               \n                        [[ 1.2184e-02, -5.6660e-02, -2.1552e-02],\n                         [-3.0425e-02, -1.1470e-02, -4.4724e-03],\n                         [-2.4251e-02,  2.5682e-02, -2.5103e-02]],\n               \n                        [[-1.0592e-01,  4.9261e-02, -6.8986e-03],\n                         [-4.3924e-02,  1.9694e-01, -2.8639e-02],\n                         [ 6.5559e-02,  1.1784e-02, -1.3601e-01]],\n               \n                        [[ 1.9649e-02, -1.7781e-02,  8.6376e-03],\n                         [ 1.1799e-02, -2.2434e-02,  2.6086e-02],\n                         [-6.9693e-03, -5.8942e-02,  4.0303e-02]]],\n               \n               \n                       [[[-3.1395e-02, -9.0320e-03,  3.3287e-02],\n                         [-5.0143e-02, -8.9736e-02, -3.3532e-02],\n                         [-1.0830e-02, -1.9034e-02, -1.6039e-02]],\n               \n                        [[-4.3695e-02, -6.9177e-02, -3.5061e-02],\n                         [-1.2458e-01, -1.1416e-01, -1.7696e-01],\n                         [-7.1238e-02, -1.1739e-01, -1.2386e-01]],\n               \n                        [[ 4.8758e-02,  5.8921e-02,  7.2641e-02],\n                         [ 3.8029e-02, -7.9380e-02,  3.0223e-03],\n                         [-2.2159e-02, -5.1318e-02, -4.9940e-02]],\n               \n                        ...,\n               \n                        [[-1.1087e-01, -1.4469e-01, -1.0768e-01],\n                         [-1.4536e-01, -1.2737e-01, -1.9958e-01],\n                         [-1.4956e-01, -2.5438e-01, -1.8868e-01]],\n               \n                        [[-4.0117e-02,  1.0514e-02, -1.7942e-02],\n                         [-5.0934e-02, -4.5377e-02, -1.4332e-01],\n                         [-5.1968e-02, -1.1104e-01, -1.9282e-01]],\n               \n                        [[-2.5305e-02, -4.6148e-02, -1.5269e-02],\n                         [-7.0324e-02,  1.3073e-02, -2.9772e-02],\n                         [-1.0792e-01, -1.9077e-02, -3.4616e-02]]],\n               \n               \n                       [[[ 1.3088e-02,  1.2584e-03,  4.7675e-02],\n                         [ 8.9695e-02,  4.3698e-02,  1.5042e-01],\n                         [ 1.6532e-01,  2.6712e-01,  2.1718e-01]],\n               \n                        [[-5.4592e-03,  3.4020e-02,  2.0881e-02],\n                         [-4.4015e-02, -3.0754e-02, -5.6092e-02],\n                         [-8.2682e-02, -1.0466e-01, -9.1124e-02]],\n               \n                        [[-3.9718e-02, -2.7983e-02, -2.6976e-02],\n                         [ 6.8062e-02,  9.1052e-02,  1.9635e-02],\n                         [ 6.9105e-02, -7.1757e-03,  2.0081e-02]],\n               \n                        ...,\n               \n                        [[-3.1153e-02,  3.3052e-02,  8.8351e-02],\n                         [-4.3353e-02,  4.7082e-02,  1.3796e-01],\n                         [-5.5992e-03, -5.7891e-03,  4.8748e-02]],\n               \n                        [[-1.0018e-01, -2.0815e-01, -1.0541e-01],\n                         [-9.8881e-02, -1.8451e-01, -1.4410e-01],\n                         [-5.4538e-02, -1.6624e-01, -1.0438e-01]],\n               \n                        [[ 4.4332e-03,  2.3583e-02, -1.8950e-02],\n                         [ 3.6859e-02,  6.8280e-03,  8.4336e-03],\n                         [ 3.7402e-02,  4.3681e-02, -4.7769e-03]]]])),\n              ('backbone.models.0.model.layer2.0.bn2.weight',\n               tensor([0.8829, 0.6418, 0.5417, 1.0093, 0.8655, 0.6134, 0.9943, 0.5663, 0.9530,\n                       0.6224, 0.5820, 0.7503, 0.8492, 0.9992, 0.9743, 0.5844, 0.9784, 0.6007,\n                       0.5882, 0.7216, 0.7647, 1.1756, 1.5807, 0.7448, 1.0178, 0.8011, 0.7524,\n                       0.7157, 0.6920, 0.7381, 0.9172, 0.6451, 0.6147, 0.6098, 0.7523, 0.8241,\n                       0.9120, 1.0840, 0.6656, 0.5727, 0.5981, 0.7184, 0.6245, 0.5888, 0.5762,\n                       0.5984, 0.9065, 0.6291, 0.5449, 0.8895, 0.8735, 0.8495, 0.6086, 0.6289,\n                       1.1914, 1.0497, 1.0528, 0.6132, 0.8193, 0.5512, 0.6006, 0.5865, 0.8490,\n                       0.8814, 0.9142, 0.8898, 0.7581, 0.6381, 1.1703, 0.9463, 0.6326, 0.6819,\n                       0.6527, 0.6980, 0.5688, 0.5921, 0.6145, 0.5638, 0.9470, 0.6562, 0.7752,\n                       0.6392, 0.6394, 0.7441, 0.7177, 0.7013, 0.8151, 0.7827, 0.7748, 0.6267,\n                       0.7600, 0.7534, 0.9513, 1.3287, 0.7564, 0.7832, 0.7224, 0.9548, 0.8663,\n                       0.8131, 0.8140, 0.8298, 1.0286, 0.5911, 0.6400, 0.6081, 0.7165, 0.5689,\n                       0.5750, 1.0116, 0.5746, 0.9028, 0.8024, 0.6914, 0.9047, 0.7191, 0.6533,\n                       0.5644, 1.0949, 0.6629, 1.5639, 0.8729, 0.6371, 0.5832, 0.6695, 0.8524,\n                       0.6040, 0.5897])),\n              ('backbone.models.0.model.layer2.0.bn2.bias',\n               tensor([-0.2570,  1.7157,  1.7202, -0.4565, -0.0221,  1.5825, -0.3808,  1.6666,\n                       -0.1155,  1.8343,  1.4859, -0.0514,  1.8589,  0.3153, -0.1937,  1.2248,\n                       -0.3009,  1.8696,  1.5934,  0.8074,  0.7402, -0.5599, -1.5868,  0.1181,\n                       -0.9212,  0.1796,  0.2847,  0.1305,  0.2136,  0.3877, -0.0217,  1.0769,\n                        0.9466,  1.8293, -0.0928,  0.0375, -0.2610, -0.4372,  0.6319,  1.1099,\n                        1.6919,  2.0226,  2.1007,  1.6060,  1.8994,  1.2375,  0.0152,  1.6077,\n                        0.6869,  0.1416, -0.2290, -0.0357,  1.0996,  1.6086, -0.5869, -0.5010,\n                       -0.5771,  1.7433, -0.0353,  1.5681,  1.9515,  0.8257, -0.1350, -0.0048,\n                        0.2479, -0.2527, -0.0483,  1.4079, -0.0281, -0.1873,  2.0514,  1.1071,\n                        0.3454,  2.0569,  1.4263,  1.1838,  1.1208,  1.5409, -0.1665,  1.2984,\n                       -0.0531,  1.8990,  0.3887,  2.4508,  0.7661,  0.7190,  0.0048,  0.1095,\n                        0.2862,  1.7599, -0.0237,  0.2581, -0.2767, -0.1538,  0.0741,  0.2628,\n                        0.4943, -0.1306, -0.1550, -0.1885,  0.4408,  0.0630, -0.4931,  1.5771,\n                        1.1516,  1.7837,  0.0902,  1.2436,  1.2144, -0.4224,  0.9856, -0.3747,\n                        0.1785,  1.1551,  0.1978,  1.1616,  1.5380,  0.9524, -0.2402,  0.3141,\n                       -0.7665, -0.2888,  1.7921,  1.7513,  0.6024, -0.1367,  1.9555,  1.3979])),\n              ('backbone.models.0.model.layer2.0.bn2.running_mean',\n               tensor([ 0.1997,  0.1730,  0.6492, -0.8685, -0.1584,  1.7458,  0.8142,  1.0325,\n                        0.6186,  0.5862, -0.1671, -0.3971,  3.1380, -0.9536, -0.1258,  0.9886,\n                       -0.6182, -0.0097,  0.5333, -0.3030,  0.9169, -2.1936, -2.0430, -0.3781,\n                       -1.2640, -0.1883,  1.1956, -0.3084,  0.1456,  1.2685, -0.3915,  0.2361,\n                       -0.2700, -0.2742, -0.2322, -0.5989, -0.4257, -0.6227,  0.8586,  0.3926,\n                        1.0636,  1.8121, -0.4453,  1.1941, -0.9189,  1.3707,  0.1924,  1.2841,\n                        1.2411, -0.3949, -0.6265, -0.1020,  0.7687,  0.5803, -2.1597, -0.0524,\n                       -0.5424,  0.3540, -0.6801,  0.2870,  0.5950,  1.0602, -0.1529, -0.2508,\n                       -0.4198,  0.1233,  0.1408,  0.5682,  0.5833, -0.0223,  0.7500,  1.4206,\n                        0.6324,  1.3657,  0.3520, -0.4679,  0.1038,  0.3529, -0.1856,  0.4213,\n                       -0.6968, -0.1187,  0.6922,  0.0213,  0.6445,  1.0005, -0.4663,  0.2563,\n                        0.4250,  1.3898,  0.0806,  0.4156, -0.3814, -0.8626,  0.1991, -2.0366,\n                        0.4792, -0.4492, -0.4514,  0.4670, -0.5838, -0.2228, -0.9702,  1.1970,\n                       -0.5393,  0.6248,  0.7374,  0.7924,  0.2136, -0.6641,  0.9699, -0.7822,\n                       -0.1498,  1.8282, -0.3239,  1.8012,  1.0741,  0.5287, -1.1670,  0.9571,\n                       -0.9551, -0.2397,  1.0348,  1.8543,  0.4721, -0.6356,  0.9028, -0.0125])),\n              ('backbone.models.0.model.layer2.0.bn2.running_var',\n               tensor([ 2.2253,  3.7111,  2.8073,  2.0564,  3.7899,  3.3288,  2.9118,  3.0682,\n                        3.3800,  2.6792,  3.2713,  1.8788, 15.9475,  8.8118,  2.8570,  2.3488,\n                        2.3791,  3.0378,  2.5501,  4.5645,  7.7368,  4.6126,  1.8468,  2.4323,\n                        0.9513,  2.9716,  3.4270,  1.7537,  2.1886,  3.5934,  2.8155,  3.2826,\n                        3.3666,  3.2172,  1.8285,  2.1192,  1.7965,  2.6975,  3.1768,  3.8940,\n                        3.4353, 12.0479,  5.2604,  3.2837,  2.7734,  2.5933,  3.6854,  2.5893,\n                        2.6857,  4.8901,  2.2836,  2.3476,  3.6235,  3.1842,  4.2059,  1.8575,\n                        2.1975,  3.3200,  1.7996,  1.8571,  3.3908,  2.4695,  2.5056,  2.7170,\n                        3.1612,  1.9118,  1.6734,  6.2327,  4.5439,  3.2414,  3.3388,  5.3261,\n                        2.0231,  5.3993,  2.7770,  3.2872,  3.9337,  2.8478,  3.2332,  5.3592,\n                        2.4864,  3.2419,  1.8200, 13.4977,  5.6903,  4.5063,  2.3726,  3.5224,\n                        3.4083,  3.0507,  2.2089,  3.4721,  2.4287,  4.7157,  1.9809,  2.8278,\n                        4.4893,  2.8294,  2.8795,  2.0795,  3.2523,  3.8319,  2.1887,  3.7803,\n                        5.7825,  2.5128,  2.1989,  2.0838,  2.8561,  1.8121,  3.5300,  1.7429,\n                        3.6250,  7.1237,  5.2196,  6.9188,  3.8747,  2.2897,  4.1864,  1.9948,\n                        1.3247,  1.8768,  6.1901,  2.4215,  2.7536,  2.3764,  4.0572,  2.8204])),\n              ('backbone.models.0.model.layer2.0.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.0.conv3.weight',\n               tensor([[[[-0.0757]],\n               \n                        [[-0.0178]],\n               \n                        [[ 0.0870]],\n               \n                        ...,\n               \n                        [[ 0.0606]],\n               \n                        [[ 0.0399]],\n               \n                        [[ 0.0386]]],\n               \n               \n                       [[[ 0.0337]],\n               \n                        [[-0.0384]],\n               \n                        [[-0.0978]],\n               \n                        ...,\n               \n                        [[-0.0155]],\n               \n                        [[-0.0308]],\n               \n                        [[-0.0431]]],\n               \n               \n                       [[[ 0.0310]],\n               \n                        [[-0.1585]],\n               \n                        [[ 0.0716]],\n               \n                        ...,\n               \n                        [[-0.2061]],\n               \n                        [[-0.1496]],\n               \n                        [[ 0.0281]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0689]],\n               \n                        [[ 0.0221]],\n               \n                        [[-0.0027]],\n               \n                        ...,\n               \n                        [[-0.0458]],\n               \n                        [[ 0.1364]],\n               \n                        [[ 0.0285]]],\n               \n               \n                       [[[ 0.0055]],\n               \n                        [[ 0.4056]],\n               \n                        [[ 0.0425]],\n               \n                        ...,\n               \n                        [[-0.0411]],\n               \n                        [[ 0.0237]],\n               \n                        [[-0.0166]]],\n               \n               \n                       [[[ 0.0239]],\n               \n                        [[ 0.0351]],\n               \n                        [[-0.0521]],\n               \n                        ...,\n               \n                        [[-0.1108]],\n               \n                        [[-0.0037]],\n               \n                        [[ 0.2385]]]])),\n              ('backbone.models.0.model.layer2.0.bn3.weight',\n               tensor([ 0.3979,  1.7630,  0.8813,  0.9311,  0.7723,  1.1224, -0.5027, -0.5691,\n                       -1.1111,  0.7532,  0.7991,  1.4191,  0.4022,  1.4539,  1.0937,  0.5623,\n                       -1.2057,  1.0651,  0.9129,  0.3972, -1.1356,  0.6318,  0.8233,  0.9172,\n                       -1.0320, -0.2916, -1.2340,  0.3069, -0.8655, -0.9879,  1.3207, -1.0571,\n                       -2.6277, -0.2671,  0.5284,  0.8258,  0.9775,  0.7402,  0.9909, -0.4819,\n                       -0.6779,  1.4427, -0.8190, -0.8705, -0.7581, -1.0275,  0.9258, -0.9054,\n                       -0.4642,  1.1591,  1.1446, -0.9405, -0.6712, -0.7981,  1.3450,  0.8064,\n                       -0.6859,  0.8054, -1.0621, -0.9308, -1.0311,  1.0780,  0.4150, -1.2716,\n                       -0.6692, -0.6496,  0.4075,  0.4622,  1.3926, -1.1604, -1.1358,  0.8289,\n                       -1.0626, -1.2232, -0.9553, -0.8762,  1.3080,  0.7894,  0.7099, -0.8067,\n                        1.0634, -1.0019,  0.5870,  0.8887,  1.0860, -1.4048, -0.9722,  0.7841,\n                       -0.6152, -0.7219,  0.9626,  0.5535,  0.5150, -1.0327, -0.5761,  0.3431,\n                       -0.9613,  1.1116, -0.5113,  0.6155,  0.6544,  0.5160,  1.0881,  0.7890,\n                        0.5819,  1.0406, -1.0679, -0.6638, -0.9437, -0.6786, -0.6235, -0.8119,\n                       -0.6457,  0.1326, -0.4873, -0.3857,  0.2847, -0.9578,  0.7048, -1.1103,\n                       -1.2631, -0.6412, -1.2983,  1.2635, -0.7940,  0.9353, -0.8173,  0.5534,\n                       -0.8743, -0.6695, -1.5434,  0.2266, -0.6713, -0.7331,  0.4687,  0.6020,\n                        1.3125,  0.3685, -0.5314,  0.7267,  1.0281, -0.3487, -1.1129,  1.2503,\n                        0.9201, -1.1027,  0.5703, -0.9766, -0.2608,  0.8307, -0.3717,  0.8011,\n                       -0.8162, -1.0072, -0.8027,  0.1926, -0.4751, -0.1849,  0.8564, -0.8985,\n                       -0.5716,  1.0347, -0.6783,  0.8689, -0.7064, -0.8635,  0.4557,  1.2388,\n                       -1.0229,  0.8997, -1.1603, -0.6478, -0.6938, -0.5684, -1.0753,  0.7505,\n                        0.4135, -1.0410,  0.8829, -0.9027, -1.2535,  1.2505,  1.1072, -0.7519,\n                       -0.9845, -0.4836, -1.0876, -1.2223,  0.1489, -0.4833, -0.9718, -0.8733,\n                       -0.4997, -0.6854, -1.1710, -1.5037,  1.2051,  0.4459,  0.6140,  1.4322,\n                        0.6906,  0.8432, -1.2614,  0.2999, -0.9273, -0.8294,  1.2778,  0.4825,\n                       -0.9913, -1.4319,  0.9276,  1.1811, -0.6452,  0.8139, -0.9206,  0.6745,\n                       -0.6241,  0.8385, -0.8980,  1.4539, -1.0649, -0.6476,  0.2771, -1.5811,\n                       -0.7158,  1.2100,  0.9388, -1.2457,  0.5661, -0.2563,  0.7475, -0.7409,\n                        0.9552, -0.4157, -0.9947, -1.0221, -0.6214, -0.7408,  0.5674, -0.5502,\n                        0.5988, -0.3116,  1.0766,  0.7185,  0.5124, -0.4354,  1.1356, -1.1798,\n                       -0.9185,  0.2443,  1.1392,  0.8608, -0.1879,  0.9548, -0.8957, -0.9533,\n                        0.3819,  0.8335, -1.3216,  0.4270,  0.5528,  0.9119,  1.2348,  0.6012,\n                       -0.9710,  1.3210, -0.8221, -0.7076, -0.9062,  0.7625, -0.6176, -1.2636,\n                       -0.9492, -1.0860, -0.4910,  0.3892,  1.2323, -0.9929, -0.5969,  0.7868,\n                        0.9492,  0.7353,  1.0390,  0.8829, -0.7241, -0.9657, -0.9677,  0.6979,\n                        0.8331, -0.4055,  0.7097,  0.8838, -0.2270,  1.2452, -1.5693,  1.0864,\n                       -0.9699,  0.6483,  0.4345,  0.8618,  1.7924, -0.3365, -1.0297, -1.0530,\n                       -0.6941, -0.9174, -0.9221, -0.6473,  0.7797,  0.8176, -0.7824, -1.1391,\n                        0.6170,  0.9837,  0.9996, -1.1641, -1.5045,  1.1597, -1.1286, -1.1028,\n                       -1.1017,  0.7145, -0.7062, -0.8010, -0.7822,  1.2126, -0.9652, -2.1609,\n                        0.2801,  0.9101, -0.9219,  1.0078, -0.9914, -1.1393,  0.9414,  1.6872,\n                       -1.5025,  1.1393, -0.9323, -0.4578,  1.3418,  0.5606, -0.8695,  0.9651,\n                        0.6009,  0.4746, -0.9613, -1.1082, -0.9713,  1.0358, -0.5429,  0.8292,\n                        1.0974,  0.6210, -0.9264,  1.2754, -0.8717,  1.3653,  0.3679, -1.0008,\n                        0.6095, -0.7057, -0.5410,  0.8162, -0.5610,  1.4763,  0.9314,  1.0817,\n                        0.6231, -1.2190,  0.4139, -0.6421, -1.2590,  0.7562,  0.7166,  0.6635,\n                       -0.8753,  0.9259,  1.2912, -0.8412,  0.8505,  0.7685, -1.0765, -0.4907,\n                        1.5519, -0.4771, -0.5086, -1.0684, -0.4846,  1.2691,  0.6537,  0.7134,\n                       -0.5974,  0.7229,  0.6532, -0.4096,  1.0088,  0.6676,  0.7208,  0.9969,\n                        1.3343,  0.5856, -1.0177, -1.0750,  1.1482, -1.2764,  0.5203,  1.1556,\n                       -0.8412,  0.8288,  0.7780, -0.9631,  0.9791,  0.8282,  1.0828,  0.6052,\n                        1.0380,  1.1390,  1.4122,  0.6036, -1.5232, -1.2407, -1.1574,  0.7574,\n                       -0.9328, -0.5110,  0.7558,  1.0387, -0.8667,  0.9152, -1.0343, -0.6516,\n                        1.1036, -1.0049, -1.0987, -0.6620,  0.1749, -1.1007,  0.8169, -1.0827,\n                        1.1834, -1.2317, -0.6551,  1.1291,  0.7867,  0.5811, -1.3626,  0.7775,\n                       -0.6814,  0.3790, -0.8168,  0.8451, -0.3599,  0.5758, -0.9317, -1.1662,\n                       -1.0246,  0.8731, -1.1142, -0.5363,  1.1091, -0.8088, -0.6011,  0.7410,\n                       -1.6008, -1.2358, -1.2683,  0.6977, -1.3430,  1.2772,  0.9096,  0.8951,\n                       -0.7410,  0.2683, -0.8826, -1.1537,  1.2109, -1.3786,  1.0186,  0.1446,\n                       -0.8982,  1.1488, -0.3888, -0.4928,  1.2745, -1.0075,  1.1211, -1.1224,\n                        0.8152,  0.9831, -1.0119, -1.0518, -1.0144,  0.9442,  0.5191, -1.0434,\n                        0.5259, -0.8165, -0.6889,  1.0360,  0.8240, -0.9289,  0.6876, -0.7818,\n                       -0.9737,  1.0199, -0.9762,  1.1429, -0.6321,  1.0699, -1.4763,  0.8180])),\n              ('backbone.models.0.model.layer2.0.bn3.bias',\n               tensor([-0.2332, -1.8555,  0.6421,  0.0636, -0.2526, -0.5199, -0.3180, -0.3361,\n                       -0.1529, -0.5736, -0.1299, -1.1888, -0.0403, -0.7459, -0.7032, -0.2399,\n                       -0.2900, -0.0912, -0.2809, -0.2536, -0.3266, -0.4661, -0.3613, -0.3389,\n                       -0.0526, -0.0579, -0.9426,  0.5489, -0.4130,  0.0352, -0.2668, -0.7978,\n                       -0.0912,  0.2982,  0.3788, -0.3080, -0.4840, -0.2598, -0.2852, -0.2506,\n                        0.7481, -0.3985, -0.4594, -0.3218,  0.3133, -0.1543, -0.4011, -0.4782,\n                        0.1384, -0.8663, -0.9126, -0.6390,  0.0885, -0.8229, -0.3846,  0.3321,\n                       -0.0990,  0.0597, -0.5443, -0.8405, -0.1667, -0.5276,  0.2579, -0.4756,\n                       -0.3650, -0.0283, -0.6783, -0.0710, -0.7887, -0.4174,  0.0345, -0.2163,\n                       -0.3376, -0.5129, -0.0096, -0.6962, -0.3211, -0.3779, -0.4257, -0.3526,\n                       -0.2258, -0.5157,  0.1562, -0.1833,  0.0367, -0.7453, -0.8583, -0.2004,\n                        0.1803,  0.1006, -0.2667, -0.0604,  0.0704, -0.0622,  0.1199, -0.1330,\n                        0.1645, -0.6200, -0.3680,  0.2222, -0.4894, -0.3606, -0.5981, -0.2219,\n                       -0.2547, -0.6111, -0.4444, -0.2434, -0.1279,  0.2189, -0.2280, -0.2735,\n                       -0.2155,  0.0052,  0.0487,  0.6049,  0.0714,  0.0543, -0.7445, -0.2430,\n                       -0.7850, -0.3402, -0.1186, -0.4586, -0.0905, -0.1437, -0.3718,  0.1175,\n                       -0.7035, -0.1807, -0.7812, -0.0521, -0.4739,  0.5038, -0.0103, -0.2604,\n                       -0.3987,  0.9278, -0.1879, -0.3514, -0.3901, -0.4685,  0.0358, -0.5530,\n                       -0.4315, -0.2103,  0.4020,  0.7516,  0.2913, -0.2496,  0.6251,  0.0903,\n                       -0.4301, -0.2242,  0.1166,  0.5575,  0.7107,  0.6183, -0.4321, -0.4315,\n                       -0.2229, -0.6574, -0.2208,  0.4274,  0.3601, -0.0621,  0.2425, -0.6865,\n                        0.1357, -0.0727, -0.5358, -0.1282, -0.4182,  0.1490, -0.4534, -0.1205,\n                        0.1294, -0.4906, -0.3130, -0.2794, -0.2857, -0.3614, -0.2760, -0.3617,\n                        0.6054,  0.1744, -0.8098, -0.2538,  0.6282, -0.5937, -0.3408,  0.6513,\n                       -0.1911, -0.4878, -0.4132, -1.2689, -0.4208, -0.6251, -0.5913, -1.1431,\n                        0.5994, -0.2442, -0.1628,  0.1870,  0.0452,  0.5122, -0.4680,  0.6082,\n                       -0.2995, -0.6887, -0.5587, -0.4481,  0.3254,  0.0179, -0.2776, -0.0195,\n                       -0.5088, -0.4201, -0.2060, -0.8414, -0.2263, -0.4136, -0.1075, -0.0503,\n                        0.3029, -0.5893, -0.5676, -0.3072, -0.2232, -0.1288, -0.1062, -0.4228,\n                       -0.4168, -0.0821, -0.5923, -0.3835, -0.1709, -0.3735,  0.2577, -0.4897,\n                       -0.4271, -0.2884, -0.0591, -0.0627, -0.1682,  0.0456, -1.2687, -0.7045,\n                        0.3180,  0.2316, -0.2772, -0.7007,  0.0827,  0.0179, -0.4832, -0.0705,\n                       -0.4697, -0.3948, -0.2423,  0.2987, -0.0728,  0.7641, -0.5669,  0.0648,\n                       -0.5738, -0.4644,  0.2066, -0.6730, -0.0168, -0.1403,  0.0469, -0.2008,\n                       -0.6049, -0.5680,  1.6782,  0.5342, -0.7622, -0.7657,  0.1540, -0.2784,\n                       -0.4723, -0.4516, -0.3748,  0.9012, -0.0610, -0.3664, -0.4154,  0.9098,\n                       -0.0422, -0.3595,  0.2160,  1.8375,  0.2116, -0.5138, -0.9438, -0.2017,\n                        0.4680, -0.4897, -0.3294, -0.0615, -1.4831,  0.3042, -0.1266, -0.5070,\n                       -0.9031, -0.4126, -0.7210, -0.4871, -0.5760,  0.0934,  0.2171, -1.1076,\n                       -0.4864, -0.9076, -0.2933, -0.1075, -0.7352, -0.7535, -0.2320, -0.3257,\n                       -0.7519,  0.1258, -0.1957, -0.2635, -0.5700, -0.7723, -0.2665, -0.8147,\n                       -0.0552, -0.1743,  0.3233, -0.5158, -0.4925, -0.5601, -0.5105, -0.8889,\n                       -0.6445, -0.5167, -0.5802,  0.0554, -0.3485,  0.8043, -0.4157, -0.4003,\n                       -0.1006, -0.3448, -0.1312, -0.4335, -0.7161,  0.0459, -0.5307, -0.8645,\n                       -0.2349,  1.5943,  0.0875, -0.3338, -0.6697, -0.2130, -0.0436, -0.7416,\n                       -0.1825, -0.1296,  0.3581,  1.6894,  0.1494, -0.7247,  0.9541, -0.1774,\n                       -0.4530, -0.2228,  0.4788,  0.0899, -0.1083, -0.1602, -0.2276, -0.5715,\n                       -0.4386, -0.6953, -0.9161, -0.5439, -0.4179, -0.3224, -0.0507,  0.0439,\n                       -0.6503, -0.2076, -0.4797, -0.0346, -0.5006, -0.7133,  0.9757, -0.3769,\n                       -0.2019, -0.4050,  0.0051, -0.2091,  0.2135, -0.2830, -0.3354,  0.2381,\n                       -0.5839, -0.2658, -0.3049, -0.6490, -0.1462, -0.4104,  0.1190, -0.1421,\n                       -0.3396,  0.4129, -0.0303,  0.5478, -0.1435, -0.8662, -0.4009, -0.1229,\n                       -0.2211, -0.6302, -1.1802, -0.2170, -1.0423, -0.4031, -0.8794, -0.2407,\n                       -0.3687,  0.5576, -0.2549,  0.3000, -0.0905,  0.2791, -0.1234, -0.7652,\n                       -0.2650, -0.2182, -0.2208, -0.3983,  0.0602, -0.7207, -0.2246, -0.3719,\n                       -0.1699, -0.3653,  0.2934, -0.0576, -0.7471, -0.2889, -0.9002, -0.5251,\n                       -0.0966, -0.0166, -0.4336, -0.0362,  0.4016,  0.1026, -0.0865, -1.0205,\n                       -0.3873, -0.4139, -0.6116,  0.1328, -0.2915, -0.0971, -0.5789,  0.8088,\n                       -1.0663, -0.6186, -0.8977, -0.3601, -0.8007, -1.0122, -0.5472,  0.9156,\n                       -0.0614,  0.9722, -0.2183, -0.3709, -0.3771, -0.9485, -0.4259,  1.3901,\n                        0.9767, -0.1901,  0.0783, -0.2898, -0.7237, -0.7078, -0.2988, -0.5301,\n                       -0.5155,  0.9821, -1.0384,  0.3867, -0.3411, -0.5970,  0.2761,  0.2506,\n                       -0.2629,  0.9568, -0.4504, -0.2966, -0.2957, -0.0804,  0.0544, -0.2816,\n                        0.3362, -0.7741,  0.2836, -0.9198,  0.1062, -0.5742, -0.6026, -0.2741])),\n              ('backbone.models.0.model.layer2.0.bn3.running_mean',\n               tensor([-4.3005e-01, -7.2423e-01, -8.4154e-01, -8.9444e-01, -4.9080e-01,\n                        1.5115e-01, -1.8237e+00,  8.2030e-01,  8.0487e-01, -1.0634e+00,\n                        5.8860e-01, -1.6508e+00,  1.1802e+00, -4.5828e-01, -3.9839e-01,\n                        2.8260e+00,  1.0045e+00,  2.5335e+00, -3.9641e-01, -5.6755e-03,\n                       -1.5518e-01, -1.6980e+00,  5.9103e-01, -1.1086e-03, -1.8163e+00,\n                        1.4325e+00, -1.5746e+00,  1.0992e+00,  1.6213e+00, -1.7371e+00,\n                        2.3230e-01, -2.0404e-01,  3.1104e+00, -6.2005e-01, -4.3274e-01,\n                        1.3005e+00,  1.2055e+00,  7.4617e-01, -8.4130e-01, -1.8749e-01,\n                        2.1616e+00, -1.9692e+00,  1.2144e+00,  2.0960e+00, -1.7969e+00,\n                       -1.1643e-01, -1.8457e+00, -1.6976e+00, -2.1731e-01, -6.6177e-01,\n                       -5.1375e-01, -4.1443e-02, -2.2770e+00,  2.5682e-01, -3.4341e-01,\n                        1.5324e+00, -1.4932e+00,  2.3428e-01, -7.6531e-01, -3.3509e-02,\n                        6.0353e-01, -1.8089e+00,  2.0439e+00,  1.1744e-01, -2.6010e+00,\n                       -2.8710e-01, -1.2274e+00, -4.8595e-01,  2.7203e+00, -1.2434e+00,\n                       -2.9215e-02, -1.0722e+00, -9.1697e-01, -1.5044e+00, -2.8687e+00,\n                       -1.6724e-01,  2.4202e+00, -4.5720e-01, -1.0560e+00,  3.4640e-01,\n                       -2.2385e+00, -5.5452e-01, -1.8784e+00,  1.2093e+00, -1.2718e-01,\n                        8.3736e-01,  1.8347e+00,  3.3779e-01, -6.5369e-02, -1.2579e+00,\n                       -1.3903e+00,  6.2399e-01, -3.9218e-02,  7.6821e-01, -1.3121e+00,\n                       -1.4222e+00, -5.1101e-01, -1.2892e+00,  5.7755e-01, -3.2784e-02,\n                        1.4330e+00, -2.7074e-01,  5.5487e-01, -2.2834e+00,  2.1743e+00,\n                        6.4799e-01, -1.6167e+00, -1.0917e+00, -9.9533e-01, -8.1877e-01,\n                        1.0477e-01, -6.3782e-01,  1.5146e+00, -2.2702e-01, -1.6918e+00,\n                       -6.8829e-01,  4.7732e-01,  1.2119e+00, -1.3129e+00,  7.5595e-01,\n                        1.3797e+00, -1.9573e+00, -1.8043e+00,  3.9760e-01, -2.3904e+00,\n                       -1.4600e+00, -1.1304e+00,  4.5389e-01,  2.0926e+00, -1.2875e+00,\n                        8.2223e-01, -3.3847e-01, -7.5859e-01,  3.1304e-01, -1.4888e+00,\n                        4.5587e-01,  1.9020e-01,  2.3322e+00,  1.0624e+00,  1.1601e+00,\n                       -2.2553e-01,  3.6008e-01, -2.6837e+00, -2.0006e-01, -1.0506e+00,\n                       -1.6365e-01,  2.6506e-01, -2.9122e-01,  3.6754e-01,  1.4667e+00,\n                        2.5405e-01, -9.3114e-01, -8.9876e-01,  3.2810e-01, -2.3755e+00,\n                       -1.6520e+00, -3.8925e+00, -9.3843e-02, -1.8532e+00, -1.8933e+00,\n                        5.1758e-01,  2.9439e-01, -5.5098e-02,  2.0464e+00, -1.3341e+00,\n                        4.3556e-01,  9.9293e-01, -9.1346e-01, -1.0067e-02, -1.7123e-01,\n                       -4.9108e-01,  1.4644e+00, -6.5857e-01, -1.8122e+00, -2.2129e+00,\n                        1.8540e+00, -1.4998e+00, -6.5539e-02, -2.4287e+00, -6.9587e-01,\n                        5.8173e-01, -7.1866e-01, -8.1818e-01,  1.6244e-01,  1.2723e+00,\n                       -9.2118e-01, -2.3487e-01,  6.6489e-01,  8.3888e-01, -8.2008e-01,\n                        2.4181e+00, -2.9054e+00,  7.4981e-01, -1.8771e-01, -6.6273e-01,\n                        6.8194e-01, -2.2327e-01, -1.6806e+00,  1.6833e+00, -9.5949e-01,\n                        8.7599e-01,  4.0902e-01,  7.4769e-01,  1.6681e+00,  1.1429e+00,\n                       -3.1285e-01, -2.1027e-01,  2.5473e+00, -3.3652e-01, -2.9526e-01,\n                        5.7430e-01,  2.0283e-01, -1.4123e+00,  1.0697e+00, -9.7981e-02,\n                        1.4155e+00, -7.0233e-01,  8.4309e-01,  1.5636e+00,  4.8721e-01,\n                        8.0219e-01,  1.4120e-01,  3.9161e-01,  3.4131e+00, -9.7365e-01,\n                       -6.2139e-02,  3.7206e-01, -1.0038e+00, -4.9423e-03,  2.1601e+00,\n                        3.9193e+00, -2.0968e+00, -2.1742e+00, -1.2123e+00,  4.7123e-01,\n                       -7.1474e-01,  4.5552e-01,  1.7667e+00,  1.4300e+00,  8.8958e-01,\n                       -7.7365e-01,  1.5217e+00,  1.4093e+00,  2.4685e+00, -9.0943e-01,\n                       -1.5254e+00, -1.6013e+00,  3.6069e-02, -1.8970e+00,  7.4914e-01,\n                        1.6736e+00,  9.9244e-02,  4.8878e-01, -9.3824e-01, -1.7660e+00,\n                        1.5959e+00,  4.2342e-01,  5.9441e-01,  9.0592e-01, -1.2155e-01,\n                        4.8351e-01,  1.5366e+00, -1.7715e-01, -8.1017e-01, -4.1953e-01,\n                       -9.2816e-01, -2.4764e+00,  7.0440e-01, -4.6475e-01,  6.9864e-01,\n                       -8.4966e-01, -8.2839e-01,  4.8006e-01,  1.9114e-01, -2.2179e+00,\n                       -1.8505e-01, -1.6066e+00, -9.7977e-01, -7.6205e-01, -1.0762e-01,\n                       -7.0878e-01, -1.6118e+00,  1.3701e+00, -1.3969e+00,  1.3385e+00,\n                        1.0803e+00, -3.2607e-02,  7.5067e-01,  3.2446e+00,  8.1443e-01,\n                        1.4763e+00,  1.7420e+00, -5.4873e-01, -3.6914e-02, -1.7854e+00,\n                       -6.4750e-01, -1.3012e+00, -3.3384e-01, -2.8024e+00, -5.5920e-01,\n                        1.7416e+00,  4.9179e-01,  1.4340e+00, -6.5586e-01,  1.7206e+00,\n                        5.1442e-01,  2.8848e-01, -5.4355e-01, -2.9394e+00, -4.7660e-01,\n                       -2.3192e+00,  1.3745e+00, -8.5258e-01, -1.0712e+00,  2.8227e-01,\n                        5.6248e-01, -1.5641e+00, -1.4409e+00,  8.4278e-01, -1.7610e+00,\n                       -5.8556e-01,  7.9777e-01, -2.5512e+00, -8.7761e-01, -1.0115e+00,\n                       -1.1319e+00,  1.3502e+00,  5.1416e+00, -8.9785e-01, -1.2413e+00,\n                        3.3305e-01, -6.3292e-01,  1.3880e+00, -7.1135e-02, -2.2750e+00,\n                       -8.7354e-02, -3.8416e+00, -1.3281e-02,  4.2889e-01, -2.7906e+00,\n                       -4.5448e-01,  2.5083e+00,  2.3190e+00, -7.9971e-01,  9.1245e-01,\n                       -1.9008e+00,  1.6090e+00,  6.4266e-01, -2.2606e-01,  1.6090e+00,\n                        2.9493e-01, -6.9481e-01,  4.9706e-02, -3.9489e-01,  4.0831e-01,\n                        1.8245e-01,  1.4682e+00, -1.1887e+00,  3.7170e-02,  1.9549e+00,\n                        3.1148e+00, -1.0628e+00, -3.7325e-01, -5.0583e+00, -3.0118e+00,\n                       -2.6297e+00, -1.2001e+00, -8.1904e-01, -2.1523e+00, -6.9821e-01,\n                        1.1408e+00, -1.9435e+00, -1.1002e+00, -9.5438e-01,  6.1061e-01,\n                        8.7580e-01,  2.2676e-01,  1.2026e+00, -1.3026e+00, -7.7439e-01,\n                       -9.7920e-01,  1.1237e+00,  1.4800e+00, -8.5793e-01,  2.3912e-01,\n                       -4.6518e-01,  8.8107e-01,  1.6969e-01,  3.8010e-01, -1.2376e+00,\n                        4.6450e+00, -1.5353e+00, -3.2271e-01, -1.1020e+00,  3.1803e+00,\n                        1.4845e+00,  2.6651e+00, -2.0773e+00, -2.6027e-01, -7.1666e-01,\n                        2.2190e-01,  3.5095e-01,  7.1050e-01, -6.3747e-01,  1.5631e+00,\n                        1.8782e+00,  2.6592e-01, -8.2563e-01, -6.1769e-01, -5.2496e-01,\n                        9.5999e-01, -2.9712e+00, -1.3194e+00, -3.4289e-01,  2.8021e+00,\n                       -1.9384e+00, -1.0398e+00,  5.0549e-01, -8.1719e-01,  3.3473e-01,\n                        4.9051e-01,  2.0083e+00, -1.5080e+00, -1.8788e+00, -1.2135e+00,\n                        2.1489e-01,  1.4680e+00,  1.6120e-01, -2.1338e-01, -1.4056e+00,\n                       -3.6399e-01,  1.2928e+00,  2.8966e+00, -5.3054e-01, -4.3648e-01,\n                        1.7880e+00, -8.8153e-01,  1.0214e+00, -1.0573e-01, -2.5779e-01,\n                        1.3294e+00,  2.0667e+00, -3.9413e+00, -4.0280e-01,  5.8852e-01,\n                        7.7837e-01,  6.9652e-01,  1.2779e-01, -3.4022e+00, -1.3390e+00,\n                        5.3634e-01,  1.2457e+00, -1.3507e+00,  1.3473e+00, -2.4890e-01,\n                       -6.4587e-01, -5.4473e-02, -9.4669e-01,  1.0143e-01, -1.7260e+00,\n                       -4.0130e-01, -3.4138e-01,  9.7186e-01,  4.7401e-01, -1.0764e+00,\n                       -5.0942e-01, -3.6136e-01,  1.7848e+00,  2.6322e+00,  1.6199e-01,\n                       -3.8226e-01, -7.5400e-01,  3.0508e+00, -1.7798e-01, -1.1542e+00,\n                       -1.5997e+00,  7.0664e-01, -1.2507e-01, -8.5427e-01,  2.2774e-01,\n                       -1.1063e+00, -7.7982e-01,  2.2034e-01, -1.1907e-01, -1.1132e+00,\n                        1.0225e+00,  1.0358e+00, -3.8320e-02, -5.9621e-01,  1.8777e+00,\n                       -1.2375e-01, -2.5749e+00,  8.9973e-01, -4.5196e-01,  2.6767e+00,\n                       -1.4307e+00, -1.5475e+00, -2.0665e+00,  5.0049e-01,  2.5152e-01,\n                        1.7108e+00,  6.2030e-02,  1.9196e+00, -8.5195e-01,  1.1460e+00,\n                        1.5390e+00, -5.3275e+00, -5.8231e-01,  1.7565e+00, -4.1537e-01,\n                       -1.1190e+00, -9.2834e-01])),\n              ('backbone.models.0.model.layer2.0.bn3.running_var',\n               tensor([0.3731, 0.7860, 0.6831, 1.5013, 0.5322, 0.3471, 0.2079, 0.3942, 0.3091,\n                       0.2607, 0.5908, 0.4591, 0.2270, 0.5582, 0.4821, 0.3726, 0.5282, 0.8223,\n                       0.3066, 0.2984, 0.6090, 0.2122, 0.6692, 0.4164, 0.5180, 0.1886, 0.5437,\n                       0.2474, 0.4908, 0.8646, 0.5930, 0.7065, 1.6816, 0.2419, 0.4446, 0.5399,\n                       0.5269, 0.4425, 0.6019, 0.2157, 0.4905, 0.5813, 0.5640, 0.3796, 0.7401,\n                       0.7044, 0.3352, 0.2893, 0.3013, 0.3455, 0.4381, 0.6184, 0.4026, 0.2409,\n                       1.0994, 0.4547, 0.4360, 0.5906, 0.3853, 0.5252, 0.5195, 0.6360, 0.6923,\n                       0.7500, 0.4281, 0.3564, 0.1237, 0.4395, 0.6673, 0.7040, 0.6224, 0.4770,\n                       1.0366, 0.4423, 0.7681, 0.2621, 1.1920, 0.7889, 0.5364, 0.6152, 0.5730,\n                       0.3900, 0.6584, 0.4594, 0.5826, 0.5527, 0.4755, 0.2525, 0.3145, 0.4133,\n                       0.5931, 0.4692, 0.2986, 1.2632, 0.3255, 0.2408, 0.7567, 0.7782, 0.2419,\n                       0.4977, 0.2799, 0.2704, 0.2960, 0.3116, 0.3983, 0.4308, 0.7087, 0.4271,\n                       0.4830, 0.7220, 0.2292, 0.2799, 0.3073, 0.0984, 0.1556, 0.3601, 0.2318,\n                       0.6373, 0.2935, 0.6366, 0.6247, 0.2152, 1.3208, 0.7514, 0.8919, 0.4114,\n                       0.3913, 0.4797, 0.5117, 0.2520, 0.6516, 0.1768, 0.2771, 1.3718, 0.5702,\n                       0.4655, 0.6661, 0.4692, 0.3149, 0.3654, 0.5799, 0.1847, 0.5485, 0.3958,\n                       0.4962, 0.5530, 0.4595, 0.8378, 0.2081, 0.2929, 0.3795, 0.4407, 0.4029,\n                       0.5150, 0.6920, 0.5234, 1.6634, 0.1509, 0.2962, 0.4298, 0.2021, 0.5626,\n                       0.3042, 1.0482, 0.4172, 0.3846, 0.2872, 0.4071, 1.5964, 0.6824, 0.7063,\n                       0.3005, 0.2870, 0.4239, 0.5096, 0.4505, 0.2965, 0.6460, 0.4743, 0.4211,\n                       0.6469, 0.6834, 0.9205, 0.4340, 0.9598, 0.3903, 0.4301, 0.7936, 0.2006,\n                       1.3389, 0.6809, 0.7571, 0.2743, 0.3710, 0.8139, 0.3297, 0.7181, 0.5233,\n                       0.3791, 0.6746, 0.7932, 0.6243, 0.5294, 0.6279, 0.6380, 0.9096, 0.6174,\n                       0.4119, 0.5594, 0.7171, 0.7670, 0.6790, 0.5337, 0.3783, 0.2935, 0.4103,\n                       0.2136, 0.3253, 0.4181, 0.8063, 0.5335, 0.2166, 0.1295, 0.8352, 0.5180,\n                       0.5413, 0.4023, 0.8512, 0.2638, 0.1731, 0.9066, 0.2891, 0.4777, 0.4875,\n                       0.9960, 0.3439, 0.2385, 0.2956, 0.4667, 0.1917, 0.1905, 0.4915, 0.6824,\n                       0.6256, 0.3814, 0.2463, 0.4437, 0.3975, 0.8649, 0.2762, 0.5028, 0.5437,\n                       0.1629, 0.3575, 0.5335, 0.7322, 0.1549, 0.3877, 1.1931, 0.2634, 0.3418,\n                       0.8574, 0.8511, 0.4284, 0.6206, 0.8032, 0.6353, 0.2558, 0.4740, 0.3649,\n                       0.5324, 0.8479, 0.4798, 0.4536, 0.4234, 0.5148, 0.3593, 0.5093, 0.4136,\n                       0.3373, 0.5453, 0.4214, 0.2462, 0.7861, 0.8395, 0.3596, 0.6269, 0.7480,\n                       0.6383, 0.2374, 0.8986, 0.9881, 0.1789, 0.6088, 0.4931, 1.1590, 1.7102,\n                       0.1646, 0.1479, 0.5046, 0.4278, 0.3160, 0.9407, 0.4763, 0.2381, 0.3879,\n                       0.2344, 0.6645, 0.3227, 0.6128, 0.4417, 0.1325, 0.6176, 0.2504, 0.5950,\n                       0.8706, 0.4178, 0.3711, 1.1083, 0.5230, 0.3843, 0.4095, 0.5276, 0.3958,\n                       0.2735, 0.4509, 0.4502, 1.3012, 0.1885, 0.5781, 1.3102, 0.4373, 0.4389,\n                       0.8978, 0.5038, 0.8856, 0.6793, 0.4985, 0.2344, 0.3797, 1.2400, 0.9718,\n                       0.5059, 0.4834, 0.1955, 0.2768, 0.5751, 0.3950, 0.5206, 0.8293, 0.1264,\n                       0.2578, 0.6835, 0.5093, 0.5524, 0.4367, 0.2448, 0.7145, 0.5620, 0.3939,\n                       0.5782, 0.6262, 0.2127, 0.6598, 0.3570, 0.9750, 0.6721, 0.5482, 0.2648,\n                       1.7780, 0.6121, 0.5780, 1.3513, 0.7573, 0.5063, 0.2762, 0.3337, 0.5165,\n                       0.7693, 0.5944, 0.3380, 0.8340, 0.4509, 0.2069, 0.5977, 0.4239, 0.1200,\n                       0.9948, 0.3031, 0.3610, 1.6286, 0.5142, 0.3450, 0.2963, 0.6301, 0.1265,\n                       1.6123, 0.3710, 0.1851, 1.1205, 0.6244, 0.2860, 1.0149, 0.6921, 0.3430,\n                       0.7661, 0.8193, 0.6272, 0.3906, 0.6131, 0.5943, 1.5277, 0.6054, 0.2801,\n                       0.6072, 0.5056, 0.4946, 0.4354, 0.5723, 0.3872, 0.7147, 0.4604, 0.8167,\n                       0.3517, 0.4608, 0.9733, 0.2478, 1.7706, 0.7270, 0.7376, 0.3232, 0.2252,\n                       0.4746, 0.8636, 0.4863, 0.2436, 0.1570, 0.6694, 0.6152, 0.4156, 0.7470,\n                       0.5469, 0.4577, 0.8544, 0.2610, 0.4251, 0.7062, 0.3528, 0.5617, 0.3125,\n                       0.2924, 0.5401, 0.5126, 0.4318, 0.5502, 0.3696, 0.4372, 0.4381, 0.3421,\n                       0.2648, 0.5063, 0.6036, 0.1758, 0.8170, 0.9956, 0.6751, 0.2031, 0.3132,\n                       0.5312, 0.5627, 0.5647, 0.6637, 0.4516, 0.5753, 0.5923, 1.0113, 1.3672,\n                       0.6119, 0.4388, 0.1275, 0.6932, 1.3784, 0.2602, 0.5457, 0.4859, 0.4166,\n                       0.6019, 0.8049, 0.2788, 0.9029, 0.4595, 1.6356, 0.4719, 0.5083, 0.5316,\n                       0.9928, 0.2315, 0.6325, 0.5165, 0.5088, 0.2969, 0.5732, 0.3256, 0.2529,\n                       1.0823, 0.3563, 0.6335, 0.4460, 0.4778, 0.4371, 1.3447, 0.6444])),\n              ('backbone.models.0.model.layer2.0.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.0.downsample.0.weight',\n               tensor([[[[-0.0047]],\n               \n                        [[ 0.0132]],\n               \n                        [[-0.0725]],\n               \n                        ...,\n               \n                        [[ 0.1589]],\n               \n                        [[ 0.0940]],\n               \n                        [[-0.0184]]],\n               \n               \n                       [[[ 0.0737]],\n               \n                        [[ 0.0779]],\n               \n                        [[-0.3220]],\n               \n                        ...,\n               \n                        [[ 0.0415]],\n               \n                        [[ 0.0948]],\n               \n                        [[-0.0076]]],\n               \n               \n                       [[[ 0.0373]],\n               \n                        [[-0.0061]],\n               \n                        [[ 0.0181]],\n               \n                        ...,\n               \n                        [[-0.0057]],\n               \n                        [[ 0.0661]],\n               \n                        [[-0.0575]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0220]],\n               \n                        [[ 0.0587]],\n               \n                        [[-0.0047]],\n               \n                        ...,\n               \n                        [[ 0.0249]],\n               \n                        [[-0.0321]],\n               \n                        [[ 0.0309]]],\n               \n               \n                       [[[-0.0318]],\n               \n                        [[-0.1130]],\n               \n                        [[-0.0131]],\n               \n                        ...,\n               \n                        [[-0.0316]],\n               \n                        [[ 0.0422]],\n               \n                        [[ 0.0580]]],\n               \n               \n                       [[[-0.0133]],\n               \n                        [[-0.0015]],\n               \n                        [[-0.0056]],\n               \n                        ...,\n               \n                        [[ 0.0273]],\n               \n                        [[ 0.0553]],\n               \n                        [[-0.0195]]]])),\n              ('backbone.models.0.model.layer2.0.downsample.1.weight',\n               tensor([0.3182, 2.3177, 0.2264, 0.3638, 0.9836, 0.6961, 0.8540, 0.5479, 0.9555,\n                       1.4594, 1.0907, 1.2102, 1.3565, 0.8614, 1.2150, 1.4234, 1.2305, 0.4744,\n                       0.5812, 0.7770, 0.7727, 0.9878, 0.5669, 1.1221, 0.6685, 0.3037, 0.7405,\n                       0.2931, 0.7612, 0.4888, 0.5743, 0.7803, 2.1823, 1.8631, 0.2708, 0.9255,\n                       1.0014, 0.9757, 0.8119, 0.8046, 0.3323, 0.6505, 0.4439, 0.6970, 0.7078,\n                       0.8448, 0.8941, 1.1360, 1.7324, 1.3524, 1.5836, 0.6046, 1.0479, 1.3721,\n                       0.5625, 0.3130, 1.2455, 0.6472, 0.5747, 1.0394, 0.9832, 0.8966, 1.4967,\n                       0.8376, 1.0142, 1.5100, 2.3173, 0.3469, 0.5642, 0.7278, 0.4185, 0.8735,\n                       0.3914, 0.8149, 0.6896, 0.8861, 0.9679, 1.2324, 0.4364, 0.3947, 0.4807,\n                       0.7784, 0.9647, 0.8035, 0.6937, 0.8541, 1.5092, 1.2665, 1.3028, 0.9564,\n                       0.8270, 1.9035, 0.7598, 0.7999, 0.6456, 0.6933, 0.9063, 0.5198, 0.8594,\n                       1.4068, 1.3389, 1.5667, 1.2383, 1.1391, 0.3939, 1.2215, 1.1653, 0.6909,\n                       1.1939, 0.2819, 1.3237, 1.6115, 0.5363, 0.2580, 2.0012, 1.3820, 0.3076,\n                       1.4901, 1.1456, 1.2500, 1.0486, 0.4517, 0.4219, 0.6851, 0.3406, 0.3457,\n                       0.6194, 0.3541, 0.8487, 1.1321, 1.6728, 0.5445, 1.0974, 0.9075, 0.3812,\n                       1.3121, 1.3904, 1.1910, 0.5182, 0.7558, 0.8357, 1.1781, 1.4872, 1.0439,\n                       0.6312, 1.3700, 0.8843, 0.1834, 0.5997, 1.0033, 0.5993, 1.2715, 1.0777,\n                       0.6854, 1.1134, 1.1199, 1.0564, 0.2529, 1.1229, 1.1584, 1.2541, 0.6137,\n                       0.5625, 0.8610, 0.3912, 1.0261, 0.3316, 1.2906, 0.6539, 0.7251, 1.0119,\n                       0.8045, 1.2107, 1.4232, 1.0491, 0.9212, 0.7732, 0.6557, 0.9885, 1.5604,\n                       0.6437, 0.9090, 0.3859, 1.0939, 0.3119, 0.2905, 0.9669, 0.9867, 0.3435,\n                       0.9389, 0.7217, 0.2407, 0.9165, 0.7141, 0.6697, 1.3011, 0.8021, 2.1484,\n                       2.0693, 0.8157, 0.5623, 0.9679, 0.9155, 1.4929, 1.2501, 0.2630, 0.6501,\n                       1.1486, 0.7386, 0.7846, 1.0366, 0.6021, 1.0075, 1.4944, 1.4957, 1.7116,\n                       1.6962, 1.3320, 0.5703, 0.6046, 0.7729, 1.2201, 0.9012, 1.0338, 1.2745,\n                       1.0090, 1.5794, 0.7780, 0.8112, 0.3815, 0.6103, 1.4834, 1.0656, 0.4174,\n                       0.7606, 1.2916, 0.9185, 1.2118, 0.5042, 0.6458, 1.6183, 1.7470, 0.3237,\n                       0.9726, 0.6129, 1.1442, 1.5107, 1.6265, 0.4695, 0.2697, 0.9813, 1.2133,\n                       0.5290, 0.8959, 0.7716, 0.7218, 0.6657, 1.2536, 1.0046, 1.3179, 1.0445,\n                       0.2790, 0.6452, 0.9214, 1.2830, 0.7618, 0.8444, 1.7611, 0.9449, 1.3433,\n                       1.4945, 0.4088, 0.8949, 1.5730, 0.4916, 0.3303, 0.7336, 1.0415, 1.6901,\n                       0.5681, 0.6446, 0.9132, 1.5068, 0.2505, 0.7911, 0.7042, 0.8406, 0.2421,\n                       1.0077, 0.6360, 0.8044, 0.3025, 0.8489, 0.5553, 1.0761, 1.2929, 0.6759,\n                       1.6055, 1.0361, 0.4673, 1.4468, 0.4766, 0.6704, 1.1238, 1.0932, 1.4311,\n                       1.6671, 2.2262, 0.7551, 1.0900, 0.5216, 1.5798, 1.2339, 0.9444, 1.0400,\n                       0.3369, 1.1044, 1.4985, 0.8898, 0.6907, 1.3376, 0.4675, 0.2597, 0.9611,\n                       1.1924, 1.1205, 1.0710, 0.8556, 0.4534, 0.6704, 0.6927, 1.0812, 0.7079,\n                       0.9365, 0.7758, 0.7931, 1.4371, 1.1482, 0.8040, 1.6551, 0.4786, 1.1437,\n                       1.3046, 0.6710, 1.5194, 0.3298, 0.6688, 0.7003, 0.6877, 0.7329, 0.6022,\n                       1.4083, 1.2203, 0.2630, 1.5398, 0.6044, 2.0068, 0.7520, 1.1412, 1.3236,\n                       0.5601, 0.9981, 1.6515, 0.2695, 1.5409, 0.8094, 0.3043, 0.7307, 0.8254,\n                       0.5753, 1.5649, 0.3031, 0.3686, 1.5183, 0.3260, 1.8889, 0.5284, 0.8954,\n                       1.0610, 0.8299, 1.1868, 1.2034, 0.4343, 1.8009, 0.8008, 0.2892, 1.2421,\n                       0.6295, 1.8310, 1.2953, 1.0190, 0.5669, 1.5692, 0.5412, 0.9628, 1.5538,\n                       0.5288, 0.6469, 0.8014, 0.6659, 0.8182, 1.1089, 0.6051, 1.0301, 0.7506,\n                       0.4239, 1.0596, 0.8079, 1.4044, 0.4730, 0.7520, 0.4903, 1.1996, 0.8112,\n                       0.6050, 0.9520, 0.8252, 1.7175, 1.3188, 0.3926, 1.0311, 0.8373, 0.8449,\n                       1.0917, 0.5391, 1.2732, 1.6647, 0.4876, 0.5080, 0.9955, 1.1210, 2.0085,\n                       0.7561, 0.4846, 0.4175, 0.8178, 0.2440, 0.5798, 0.7664, 0.5964, 0.4698,\n                       1.0087, 0.6128, 0.5747, 0.8697, 1.1436, 0.5982, 1.6856, 1.1469, 0.4465,\n                       1.2559, 0.7771, 1.1747, 1.1171, 0.8045, 1.8311, 0.6325, 0.6734, 1.5318,\n                       1.2089, 0.4197, 1.3678, 0.8784, 0.2401, 0.8413, 0.8452, 1.1450, 1.0214,\n                       0.8687, 1.1872, 0.7813, 0.2382, 0.7651, 1.1619, 0.7030, 1.0564, 0.9170,\n                       1.1754, 0.6569, 0.1313, 0.2395, 0.7298, 1.6238, 1.0593, 1.4968, 0.9078,\n                       1.1761, 0.9956, 1.2191, 0.2234, 0.6942, 0.3314, 1.1367, 0.9410, 1.1451,\n                       0.3416, 0.7393, 0.2812, 1.4932, 0.9064, 0.8568, 0.9977, 1.2559, 1.7186,\n                       0.4116, 0.5862, 1.3222, 1.0623, 1.5364, 0.7024, 0.4551, 0.5519])),\n              ('backbone.models.0.model.layer2.0.downsample.1.bias',\n               tensor([ 3.5651e-01, -1.6623e+00,  1.2751e+00,  1.2394e+00,  2.0999e-01,\n                        1.3307e-01,  1.1048e-01,  1.4264e-01,  6.0992e-02, -1.6061e-01,\n                        6.6277e-02, -4.5032e-01, -3.8359e-01, -2.2929e-01, -2.3045e-01,\n                       -7.1095e-02,  1.0429e-01,  5.2355e-01, -1.5290e-01, -7.7601e-02,\n                        2.9122e-01,  3.5979e-02,  2.3773e-01, -8.9720e-03,  4.5127e-02,\n                        3.2520e-01,  1.8502e-01,  8.0071e-01,  6.1905e-01,  8.5754e-01,\n                        1.8137e-01,  1.7175e-01, -2.3576e-01,  4.9119e-01,  7.6517e-01,\n                        3.1425e-01, -2.7383e-01,  2.6373e-01,  1.5022e-01,  3.0119e-01,\n                        6.9702e-01,  3.5037e-01,  5.9476e-01, -1.7028e-01,  7.9271e-01,\n                        2.8349e-01, -2.1864e-01, -2.3697e-01, -2.6109e-01, -4.7404e-01,\n                        6.2259e-02,  5.8524e-01,  4.3643e-01, -1.0490e-01,  3.8255e-01,\n                        8.8045e-01,  1.8314e-01,  4.5977e-01,  1.5174e-01,  7.3126e-02,\n                        3.1088e-01,  1.2295e-01, -2.4198e-01,  5.4443e-01,  1.7411e-01,\n                       -1.4246e-01, -2.0415e-01,  6.4027e-01,  2.0788e-01,  4.8911e-01,\n                        4.5196e-01,  4.9544e-01,  1.8757e-01,  5.2992e-02,  7.2500e-01,\n                       -5.9459e-01,  3.7273e-01,  6.2982e-01,  4.5407e-01,  3.1203e-01,\n                        1.3970e-01,  2.3474e-01,  3.4073e-01,  1.1769e-01,  1.5005e-01,\n                       -4.8375e-01, -1.9723e-01, -3.4610e-01, -3.9880e-01,  8.1334e-02,\n                        2.4585e-01, -4.7543e-01,  1.9408e-01,  8.6204e-01,  2.9813e-02,\n                        3.8105e-01,  5.0126e-01,  3.7575e-01, -2.1994e-01,  6.5919e-01,\n                       -9.2962e-01, -2.1918e-01, -8.9882e-01, -1.3710e-01,  3.1282e-01,\n                       -6.0270e-01,  5.0931e-02,  3.3737e-01,  2.6711e-01,  1.0869e+00,\n                       -3.5564e-02, -3.8935e-01, -1.0446e-01,  4.1237e-01,  4.9969e-02,\n                        3.2592e-01,  8.1039e-01,  1.2076e-01, -3.4570e-04,  2.8485e-01,\n                        3.3339e-01,  3.6440e-02,  6.0440e-01,  3.0208e-01,  4.5104e-01,\n                        6.7778e-02,  1.5177e-01,  5.3902e-01,  5.6366e-01,  1.4321e-01,\n                       -4.6781e-01,  4.8386e-01, -4.7860e-01,  1.7558e+00,  4.4900e-01,\n                       -8.1252e-02, -4.2998e-01,  1.7076e-01,  4.9612e-01, -3.8035e-02,\n                        3.2705e-01, -5.4356e-01,  3.0948e-01, -4.8915e-01, -3.1441e-01,\n                        3.0001e-01,  3.4961e-01,  1.4465e+00, -9.0773e-02, -7.4880e-02,\n                        7.5713e-01,  6.6526e-02, -1.4566e-01,  2.1014e-01,  1.9573e-01,\n                        4.5947e-01,  6.3246e-01,  1.2574e+00, -1.6765e-01,  1.6018e-01,\n                       -4.6226e-02,  3.7624e-01, -1.9050e-01,  9.3080e-01,  4.1685e-01,\n                        2.3271e-01,  5.0770e-01,  3.5913e-02,  6.6285e-01,  4.5996e-01,\n                       -1.3843e-01,  6.1907e-02, -5.7106e-02, -1.0554e-01,  4.6164e-01,\n                        1.3681e-01,  5.8617e-01,  3.7039e-01, -2.2825e-02, -1.9112e-01,\n                        2.3485e-01,  2.6112e-01,  9.7520e-01,  2.9660e-01,  1.0209e+00,\n                        5.6572e-01,  7.1749e-02,  2.8750e-01,  8.9161e-01,  3.3759e-01,\n                        9.6330e-01,  8.0267e-01,  1.7971e-01, -3.6666e-02,  4.0761e-01,\n                       -1.1117e+00,  2.7196e-01, -1.1674e+00, -1.2507e+00,  4.6486e-01,\n                        9.5416e-01,  1.7683e-01,  1.6473e-01,  5.9658e-01,  3.8226e-01,\n                        7.3814e-01,  4.0750e-01,  1.9978e-01,  4.4325e-01, -1.6753e-01,\n                        4.1256e-01,  3.3406e-01,  4.2925e-01,  1.1784e-01, -1.6316e-01,\n                       -3.8363e-01, -4.2348e-01,  1.8619e-02,  3.2718e-01,  4.0350e-01,\n                        2.2441e-01, -9.6359e-02,  1.1753e-01, -2.6409e-02, -1.4080e-01,\n                        1.1091e-01, -3.0121e-01,  3.3393e-01, -6.5421e-02,  3.4413e-01,\n                        6.1286e-01, -2.2371e-01,  3.6290e-02,  9.2109e-01,  4.0992e-01,\n                       -1.4776e-01, -5.2009e-01, -8.9543e-02,  6.7874e-01,  5.3989e-02,\n                        5.3224e-01, -5.4507e-02,  3.1862e-01,  2.9535e-01,  3.8825e-01,\n                        2.5557e-01, -3.8298e-01, -7.0060e-01,  7.5124e-01,  8.1616e-01,\n                       -1.1564e-01, -3.7600e-01,  6.3539e-01,  2.7129e-02,  4.0156e-01,\n                        5.7215e-01,  1.2307e-01,  3.1135e-02,  5.1885e-01,  2.6916e-01,\n                        9.9779e-02,  1.0209e+00,  3.2948e-01,  2.1610e-01, -4.4047e-01,\n                       -4.7497e-02,  5.0141e-01, -9.9481e-01,  5.0369e-01,  3.2883e-01,\n                        1.2232e-01,  4.9481e-01,  2.5950e-01, -3.6110e-01,  1.0844e+00,\n                        9.6383e-01, -1.3735e-01,  7.8480e-02, -6.7382e-01,  1.1253e-01,\n                        1.8583e-01,  3.6527e-01, -4.7574e-01,  1.1918e+00,  5.2118e-01,\n                        1.5122e-01,  5.1610e-01,  1.0326e+00, -5.3891e-03,  6.4004e-01,\n                        4.1654e-01,  1.0291e+00,  6.9555e-01,  1.6515e-01, -2.3987e-01,\n                        1.4113e+00,  1.5100e+00, -7.7172e-01, -3.2742e-01,  4.7160e-01,\n                       -6.5036e-01,  1.0190e+00,  8.8625e-01, -3.2218e-01, -4.7146e-01,\n                       -4.2139e-01, -8.6676e-01, -4.5762e-01, -6.2434e-02,  3.6464e-01,\n                        5.2411e-01, -1.1775e+00,  3.1295e-02, -4.5211e-01, -1.2425e-01,\n                        4.8984e-01, -2.0832e-01, -1.6416e-01,  2.7002e-01,  9.1775e-03,\n                       -1.6683e-01,  1.0756e-01,  4.5800e-01,  1.3340e-01,  5.7648e-02,\n                       -2.7770e-02, -5.0925e-02, -5.8732e-01,  6.2528e-01,  1.5789e-01,\n                        1.0457e+00,  9.6276e-02,  3.8699e-01,  4.9309e-01,  4.6833e-01,\n                        1.2464e-01, -1.4046e-01, -1.3035e-01, -1.8602e-01, -1.5945e-01,\n                        6.8589e-01,  4.0256e-01,  2.9044e-01, -1.7252e-02, -3.5691e-01,\n                        2.0971e-01,  4.4961e-01,  2.3180e-02,  8.5352e-02,  7.2840e-01,\n                       -2.3120e-01, -8.6376e-02,  1.3392e-01,  1.4468e+00,  3.3934e-01,\n                       -8.5326e-02, -8.7307e-01,  2.6366e-01,  8.5156e-01, -1.2358e-01,\n                        8.8061e-01,  5.5493e-01,  3.9075e-01,  1.7373e+00, -7.2125e-02,\n                        7.2076e-02,  1.1462e+00,  1.3604e-01,  2.7284e-01,  1.1297e+00,\n                        2.2250e-01,  6.2906e-01,  6.7210e-01, -1.0704e-01,  6.0064e-01,\n                       -6.1599e-01, -4.6471e-03,  3.7042e-02,  3.3122e-01,  2.8785e-01,\n                       -6.2199e-02,  3.5645e-02,  2.0818e-01,  9.6299e-02,  7.8620e-02,\n                        4.6350e-01, -6.5548e-01,  5.7487e-01, -2.6743e-01, -7.3379e-01,\n                        1.2483e+00,  4.5615e-01, -3.3834e-01,  3.3857e-02,  3.6043e-01,\n                       -3.9831e-01,  1.0552e+00, -1.9855e-01, -1.3287e-02,  1.6626e+00,\n                       -4.6601e-01, -2.6223e-02,  7.4058e-01,  3.1021e-01,  7.7697e-02,\n                        4.0337e-01,  6.3655e-01,  5.5318e-01, -5.4213e-02,  7.0368e-01,\n                        3.9406e-01,  9.8261e-01,  4.7825e-01, -1.7852e-01,  2.0417e-01,\n                        3.1047e-01, -1.8474e-01, -1.1815e+00, -3.1912e-01,  3.3934e-01,\n                       -2.4303e-01, -2.2713e-01,  3.2075e-01,  4.9165e-01,  2.2145e-01,\n                        4.8491e-02, -5.1668e-01,  8.2872e-01,  7.0564e-01,  4.0660e-01,\n                        1.0347e-01, -1.0001e+00,  1.2816e-01,  5.6861e-01,  2.9648e-01,\n                        4.7431e-02,  8.0925e-01,  5.4114e-01,  4.6671e-01, -1.4459e-01,\n                        4.3887e-01, -1.9464e-01, -1.5677e-01,  4.1889e-01, -7.8827e-02,\n                        1.2220e-02,  4.4113e-01, -8.3979e-01,  2.6731e-01,  5.2317e-01,\n                       -3.7999e-01, -6.0059e-02,  2.4936e-01,  3.3436e-01,  5.4958e-01,\n                        1.1705e-02, -2.3513e-01,  1.8865e-01, -1.2484e+00,  2.0379e-01,\n                        1.9782e-01, -5.5272e-02,  8.8379e-03,  6.1653e-01,  4.1239e-01,\n                        1.0287e-01, -5.2663e-01, -1.5895e-01, -4.9471e-03, -1.9774e-01,\n                        2.2594e-01,  1.7327e+00,  4.3803e-01, -2.0892e-01,  2.6504e-01,\n                        4.0591e-01,  4.9209e-01,  1.5656e-01,  3.3612e-01,  1.3266e+00,\n                        9.8321e-01,  3.7035e-01,  3.2834e-01,  5.0778e-01, -7.0229e-01,\n                       -3.3192e-02,  2.3223e-01,  7.1250e-01, -3.0103e-01,  7.9118e-01,\n                        1.9283e-01,  1.1027e+00,  1.1068e-02, -3.4447e-01,  4.2996e-01,\n                        5.2829e-01, -2.2691e-01,  1.1156e+00,  5.2921e-01,  2.2154e-01,\n                       -1.2124e-01,  2.2781e-01,  2.3249e-01, -4.5857e-01,  1.0025e+00,\n                        2.7917e-01,  1.3719e-01, -3.6667e-01, -1.5891e-01,  2.8091e-01,\n                        7.1996e-01,  4.1871e-01])),\n              ('backbone.models.0.model.layer2.0.downsample.1.running_mean',\n               tensor([-6.8960e-01, -2.0830e+00,  2.4939e+00,  1.5772e-01, -4.0869e-01,\n                       -2.6443e+00,  2.1568e+00,  1.6261e+00,  4.4655e-01, -1.0687e+00,\n                       -4.8799e+00,  1.8489e+00,  1.2848e+00, -4.2922e-01, -1.7276e+00,\n                       -2.9676e+00,  6.0991e-01,  8.9394e-01,  1.4865e+00,  5.1208e+00,\n                       -1.1152e+00,  1.6427e-01, -1.4534e+00, -7.0349e-01, -5.2788e-01,\n                       -4.1922e-01, -9.0879e-01, -4.2563e-01,  4.9955e-01, -3.6328e-01,\n                       -2.6819e+00,  8.6387e-01, -1.4245e+00,  6.1288e-01,  7.7779e-01,\n                        3.2178e-01, -3.7065e+00,  1.2709e+00,  1.3518e+00,  7.1726e-01,\n                        2.3265e-01, -6.1747e-01,  5.3398e-01, -1.7308e+00, -7.5111e+00,\n                       -1.2977e+00, -1.8470e+00, -2.0628e+00, -1.3094e+00, -3.4087e+00,\n                        1.3075e+00, -5.6318e-01,  1.3019e+00, -1.7795e+00, -7.1401e-01,\n                       -2.0872e+00, -1.5179e+00, -1.7637e+00, -8.1922e-01,  1.1665e+00,\n                       -1.5642e+00, -5.4718e+00, -2.6373e+00, -2.3562e+00, -1.2879e-01,\n                        1.2566e+00, -5.5120e-01, -4.2205e-01, -2.0267e-01,  2.1780e-01,\n                       -1.3873e+00, -1.3436e-01, -1.6536e+00, -3.4120e-01, -2.1722e+00,\n                        2.0673e-02, -5.2974e-01, -3.4223e+00, -4.5868e-01,  1.4536e-02,\n                        6.6059e-01,  8.0205e-01,  1.0453e+00, -1.1155e+00, -2.3420e+00,\n                       -8.1621e-01,  2.0799e+00, -8.2191e-01, -4.3065e+00, -2.3920e+00,\n                        8.1903e-01, -1.9685e+00, -8.1313e-01,  2.5659e+00,  9.0548e-01,\n                       -2.2889e+00, -4.8083e-01, -6.7736e-01,  3.0471e-01,  3.2775e+00,\n                       -1.4456e+00, -7.2398e-01,  1.3334e+00, -1.5838e+00, -3.3800e+00,\n                        5.6265e-01, -3.7022e+00, -1.8612e-01, -4.6100e-01, -4.3209e-02,\n                        7.2815e-01,  1.7947e+00,  1.4280e-02,  9.8034e-01,  1.0458e+00,\n                       -1.2705e+01, -5.5486e-01, -7.0705e-01,  9.5122e-01, -9.7500e-01,\n                        1.8364e+00,  1.4602e+00, -2.4348e-01, -2.3765e+00, -6.5779e-02,\n                       -1.4998e+00, -2.0062e-01,  4.1066e-02, -5.6690e-01,  1.1350e-01,\n                       -1.9295e+00,  2.2561e+00,  1.6459e+00,  3.4924e+00, -2.0632e+00,\n                       -8.7124e-01, -2.7567e+00,  1.2481e+01, -2.6165e+00,  2.4733e-01,\n                       -3.8236e+00, -1.8778e+00, -2.8972e+00, -7.4177e-01,  7.2928e-01,\n                       -2.2824e+00, -2.0266e-01, -2.3329e-02, -2.9435e+00,  5.1849e-01,\n                       -1.7894e+00,  3.9948e-01,  6.9835e-01, -1.2510e+00, -1.0204e+00,\n                        4.6714e+00,  1.5277e+00,  1.8911e+00,  1.6684e+00, -3.7515e+00,\n                       -1.0861e+00, -7.2293e-01, -2.1381e+00, -2.5646e+00,  1.5898e+00,\n                       -9.9140e-01,  3.7396e-02,  1.2508e+00, -2.2843e+00, -2.7817e+00,\n                       -1.8488e+00, -9.7900e-01, -7.5064e-01, -8.2218e+00,  1.7336e+00,\n                       -8.0922e-01, -7.5297e-01,  5.6903e-01,  2.2106e+00, -1.0622e+00,\n                        3.2189e-01, -1.5029e+00,  1.5291e+00, -2.0004e+00, -3.5563e-03,\n                        7.8928e-01,  2.8396e-02, -2.1422e+00,  4.8837e+00, -3.0285e+00,\n                       -1.3110e+00,  1.6310e+00,  4.9913e-01, -8.0386e-01, -2.0166e+00,\n                       -3.1601e-01,  6.8577e-01, -2.1217e+00, -9.8348e-01,  1.4430e+00,\n                        6.6220e-01, -2.1214e+00,  6.7739e-01,  6.4172e-01,  8.2190e-02,\n                       -3.1556e-01,  1.6727e-01, -3.4611e+00, -1.6075e+00, -1.3062e+00,\n                       -1.7044e+00, -1.6196e+00, -1.7847e+00,  1.2365e+00,  2.5634e-01,\n                        1.0419e+00, -2.5504e-01,  9.6772e-01, -1.6396e-01, -2.4904e-01,\n                        1.2907e+00, -2.5229e+00, -7.8717e-01,  8.6036e-01, -1.5028e+00,\n                       -2.1048e-01, -2.0808e+00, -1.6059e+00, -4.0727e+00, -5.2240e-01,\n                       -1.2875e-01,  2.6795e+00, -1.3210e+00, -1.5612e+00,  6.9353e-01,\n                       -6.0323e-01, -2.9883e+00, -1.4909e+00,  8.9363e-01, -1.2360e+00,\n                       -3.2636e+00, -1.0612e+01, -2.0077e+00, -9.8174e-01, -5.8925e-01,\n                       -3.7716e+00,  7.1459e+00, -3.6712e+00, -1.2109e+00,  2.1471e+00,\n                       -9.7225e-01,  2.9958e+00, -3.5932e+00, -4.1444e+00, -8.0567e-01,\n                        1.7093e+00, -9.0598e-01, -3.3634e+00, -1.9190e+00, -2.7538e+00,\n                        4.9410e+00,  7.5862e-01, -2.9246e+00, -9.0834e-01, -3.6710e-03,\n                       -1.1210e+00, -1.3114e+00, -2.0583e+00, -6.0706e+00,  6.0324e+00,\n                       -3.1343e+00, -4.7096e-01, -1.9342e+00,  1.2318e+00,  2.6702e+00,\n                       -2.0119e+00, -1.1840e+00, -1.6507e+00, -1.6390e+00, -9.9991e-01,\n                       -8.2199e-01,  2.4914e+00,  1.1515e+00, -1.1811e-01,  2.3795e+00,\n                        3.4632e-02, -1.8821e+00, -1.2997e-01, -2.1413e+00, -1.6294e+00,\n                       -1.0951e+00, -1.5469e+00,  3.5084e+00, -7.8817e-01, -1.3948e+00,\n                        2.3917e+00, -2.9745e+00,  2.4886e-01, -2.4794e+00, -9.6118e-02,\n                        5.1041e-02,  2.4219e+00, -1.5876e+00,  2.8883e-01, -2.0351e+00,\n                        3.8028e-01, -1.3136e+00, -1.6888e+00, -1.7050e+00, -1.5664e+00,\n                       -3.6309e-02,  1.1635e-01, -1.6665e+00, -2.0086e+00, -4.6831e+00,\n                       -7.4545e-01, -1.0666e+00, -1.6971e+00,  2.7658e-01, -3.2131e-01,\n                       -9.4494e-02, -2.1773e+00, -2.1510e+00,  2.7382e+00, -2.1056e+00,\n                        6.2089e-01, -3.6030e-01,  1.7760e+00, -2.3328e+00, -8.9854e-01,\n                       -1.0666e+00, -4.2616e-01,  1.9010e+00, -9.3183e-01, -5.8628e-01,\n                       -8.3059e-02, -2.0983e+00,  1.3391e+00,  2.8467e-01, -1.8984e+00,\n                       -8.4018e-01,  1.5513e+00, -5.6876e-01, -2.4321e+00,  1.3384e+00,\n                       -1.3129e+00,  9.3714e-02, -6.1877e-01, -4.6175e-01, -3.0413e+00,\n                       -1.1130e+00, -3.6331e+00, -4.1217e+00, -4.7725e-01,  8.6974e-01,\n                       -5.5850e-01, -2.4107e-01,  2.3637e+00,  1.2467e+00,  2.4519e+00,\n                        1.6937e+00, -6.3480e-01,  8.2213e-01,  1.1194e+00, -6.8161e-01,\n                       -9.7614e-01,  1.9274e+00, -3.2903e-01,  1.5799e+00, -2.3356e+00,\n                       -1.0766e+00, -7.2959e-01,  1.2737e+00, -5.0939e+00, -5.1696e-01,\n                        1.4512e-01, -4.0434e-01, -1.7399e-01,  4.7594e-01, -1.1561e+00,\n                       -2.1840e-01, -5.0911e+00, -3.1693e-01,  1.0783e+00,  9.4215e-01,\n                        1.4236e+00,  5.5270e+00, -2.6717e+00, -1.5189e+00,  2.8041e+00,\n                        6.1792e+00, -1.7911e+00, -3.6038e+00,  8.8474e-01,  2.8474e+00,\n                        2.2969e+00, -7.0652e-01, -2.7325e+00, -1.6445e+00,  1.6492e+00,\n                       -1.6234e+00, -2.6919e-01,  2.3464e+00,  4.5580e+00, -9.8238e-01,\n                       -1.0820e+00, -1.3168e+00, -1.3538e+00,  1.1981e+00, -2.5502e+00,\n                        5.7535e-01,  5.0577e+00,  1.5943e+00,  1.0648e+00, -2.3596e+00,\n                        1.9884e+00,  2.7585e+00, -7.5412e-01,  8.4079e-01,  1.5425e+00,\n                       -1.7380e-02, -1.9683e+00, -1.4269e+00, -1.8424e-01,  4.1677e-01,\n                       -4.9715e+00,  4.2075e-01,  2.2032e+00, -3.9644e-01,  1.9747e-02,\n                       -2.8865e+00,  2.8264e+00, -1.0509e+00,  1.5449e+00, -8.2690e-01,\n                       -1.1983e-01, -8.0061e-01, -6.6552e-01,  3.2667e+00,  6.4550e-01,\n                       -4.7132e-01, -6.6722e-01,  4.1470e+00,  3.7251e-01, -1.6597e+00,\n                        5.9125e-01,  2.5778e+00,  7.5761e-01,  1.8550e+00,  1.9460e+00,\n                       -8.1630e-02, -4.4456e-01, -5.3132e+00, -1.0258e+00, -1.5505e+00,\n                       -1.1722e+00, -2.6566e+00, -1.5029e+00,  1.9252e+00, -9.7468e-01,\n                       -1.3131e+00, -1.8805e-01, -2.3049e+00,  1.8992e+00, -7.2385e-02,\n                        1.5916e+00, -1.2840e+00,  1.4328e+00, -9.0344e-01, -5.3980e-01,\n                        8.2211e-01, -2.3847e-01,  1.6956e-01,  1.9128e+00,  9.0113e-01,\n                        2.4307e-01, -1.9249e+00,  1.5011e+00, -1.9408e+00,  1.1683e+00,\n                        2.2107e+00, -2.0931e+00,  1.5041e-01, -1.6050e-01, -5.2398e-01,\n                       -2.0615e+00, -6.7116e-01, -1.9577e+00, -8.2462e-01, -3.3976e-01,\n                       -1.3306e+00, -7.4223e-01, -1.0857e+00, -3.1276e+00, -5.2374e+00,\n                        1.4743e+00,  2.1361e-01,  2.3811e-01,  3.8160e-01, -1.1659e+00,\n                       -1.9080e+00,  7.6921e-01, -5.2889e-01, -7.5018e-01, -9.7745e-01,\n                       -5.7327e-01,  6.1927e-01, -2.3749e+00, -2.4643e+00, -1.8498e-02,\n                       -9.7779e-01,  7.3623e-01])),\n              ('backbone.models.0.model.layer2.0.downsample.1.running_var',\n               tensor([0.1869, 0.7195, 0.1195, 0.3955, 0.6096, 0.1953, 0.5300, 0.2269, 0.2815,\n                       0.4914, 0.6620, 0.4398, 0.7562, 0.2461, 0.2224, 0.5308, 0.2772, 0.2714,\n                       0.2157, 0.3491, 0.3582, 0.3057, 0.2619, 0.5492, 0.1991, 0.1742, 0.2847,\n                       0.2038, 0.3783, 0.3589, 0.1901, 0.4225, 2.4179, 1.7400, 0.1286, 0.3758,\n                       0.3841, 0.4671, 0.2705, 0.5774, 0.3635, 0.2147, 0.2811, 0.2024, 0.5203,\n                       0.4683, 0.2489, 0.3272, 1.2871, 0.4308, 0.3757, 0.2568, 0.3637, 0.5364,\n                       0.2099, 0.1424, 0.8845, 0.3683, 0.1298, 0.4316, 0.4844, 0.3190, 0.8731,\n                       0.2856, 0.7210, 0.5256, 0.5085, 0.2239, 0.1498, 0.2371, 0.1706, 0.4727,\n                       0.1897, 0.2547, 0.4059, 0.2304, 0.8035, 0.8204, 0.2219, 0.1856, 0.1439,\n                       0.2068, 0.6398, 0.3699, 0.3326, 0.2682, 0.6194, 0.2740, 0.7435, 0.4940,\n                       0.4360, 1.4092, 0.3942, 1.1379, 0.2693, 0.4115, 0.7193, 0.2417, 0.3701,\n                       1.7504, 0.3270, 0.8942, 0.3138, 0.3018, 0.1594, 0.3244, 0.6698, 0.4573,\n                       0.4554, 0.2298, 0.4071, 0.4923, 0.1321, 0.1497, 0.5243, 1.2989, 0.2566,\n                       0.9479, 0.3903, 0.7367, 0.4056, 0.1318, 0.2459, 0.3673, 0.1812, 0.1279,\n                       0.2185, 0.2342, 0.5265, 0.3519, 0.2981, 0.4378, 0.2812, 1.4421, 0.2964,\n                       0.6505, 0.5259, 1.7494, 0.2562, 0.3061, 0.5038, 0.7705, 0.9472, 0.3308,\n                       0.2181, 0.5434, 0.7220, 0.1170, 0.3733, 0.2760, 0.6457, 0.9467, 0.4614,\n                       0.2656, 0.7447, 1.6861, 0.8001, 0.2105, 0.3031, 0.5672, 0.3290, 0.2164,\n                       0.1803, 0.6910, 0.1309, 0.3649, 0.1933, 0.3127, 1.0175, 0.5158, 0.4072,\n                       0.3252, 0.3325, 0.5159, 0.4607, 0.5131, 0.4629, 0.3658, 0.4042, 0.7349,\n                       0.2865, 0.3843, 0.2603, 0.3799, 0.2253, 0.2041, 0.3530, 0.5600, 0.6961,\n                       1.3387, 0.4186, 0.1476, 0.4567, 0.2452, 0.3593, 0.2060, 0.3016, 0.7873,\n                       0.9073, 0.3583, 0.5021, 0.4118, 0.3790, 2.0347, 0.3241, 0.1740, 0.2371,\n                       0.8507, 0.3119, 0.2638, 0.4753, 0.3187, 0.3733, 0.9247, 0.4541, 1.2278,\n                       0.4844, 0.5545, 0.2160, 0.2172, 0.3697, 0.3637, 0.3473, 0.3970, 0.4719,\n                       0.3998, 0.4476, 0.3143, 0.1954, 0.2181, 0.4295, 0.6072, 0.4869, 0.3923,\n                       0.5306, 0.4508, 0.2555, 0.4256, 0.2449, 0.1990, 0.3994, 1.2260, 0.1080,\n                       0.6303, 0.4103, 0.4967, 0.3050, 0.3618, 0.3128, 0.1966, 0.3546, 0.4299,\n                       0.3924, 0.3466, 0.3968, 0.3588, 0.2506, 0.2759, 0.7297, 0.9018, 0.3903,\n                       0.1400, 0.2227, 0.5183, 0.6615, 0.4329, 0.6815, 0.9734, 0.3197, 0.3896,\n                       1.0213, 0.1807, 0.2771, 0.4917, 0.3035, 0.4650, 0.2237, 0.2967, 0.6645,\n                       0.1736, 0.2770, 0.5801, 0.4151, 0.1410, 0.7205, 0.2470, 0.4331, 0.2277,\n                       0.8279, 0.4082, 0.6484, 0.2213, 1.3484, 0.1786, 0.2159, 1.0625, 0.6359,\n                       0.3346, 0.2369, 0.2422, 0.3074, 0.4045, 0.4455, 0.3330, 0.2138, 0.6532,\n                       0.2005, 1.2083, 0.3142, 0.6272, 0.2331, 0.2349, 0.8337, 0.1445, 0.4548,\n                       0.1261, 0.2802, 0.3088, 0.7528, 0.2608, 0.2522, 0.1778, 0.1268, 0.4938,\n                       0.4411, 0.3621, 0.3988, 0.2775, 0.3257, 0.3646, 0.8509, 0.3458, 0.2221,\n                       0.4854, 0.4050, 0.3446, 0.2137, 0.2720, 0.1560, 1.1986, 0.2169, 1.4891,\n                       0.3659, 0.2482, 0.4537, 0.2829, 0.3202, 0.2436, 0.2831, 0.5229, 0.1230,\n                       0.2350, 0.5069, 0.1680, 0.7640, 0.1568, 0.4654, 0.3005, 1.5600, 0.2511,\n                       0.4081, 0.5143, 0.8779, 0.1652, 0.4315, 0.3149, 0.1611, 0.2622, 0.2848,\n                       0.7548, 0.9974, 0.1772, 0.2062, 0.8646, 0.1399, 1.0479, 0.2263, 0.4622,\n                       0.4914, 0.3754, 0.4808, 0.4781, 0.1639, 1.0303, 0.3242, 0.2558, 0.1551,\n                       0.4589, 1.5696, 0.2252, 3.8428, 0.3867, 0.4651, 0.1532, 0.8501, 0.2989,\n                       0.4524, 0.2791, 0.2143, 0.5913, 0.2657, 0.3130, 0.3924, 0.3184, 0.2441,\n                       0.1738, 1.4670, 0.3666, 0.6177, 0.4438, 0.4673, 0.2754, 0.6296, 0.1861,\n                       0.2705, 0.5072, 0.2497, 0.7403, 0.2701, 0.1849, 0.4089, 0.1964, 0.3524,\n                       0.5236, 0.2098, 0.9989, 0.5475, 0.2670, 0.3894, 0.5716, 0.2594, 0.5869,\n                       0.2732, 0.2780, 0.1186, 0.2140, 0.1596, 0.2302, 0.3721, 0.2040, 0.1908,\n                       0.4963, 0.4479, 0.2789, 0.3290, 0.5991, 0.1755, 0.5206, 0.8268, 0.2264,\n                       0.3142, 0.5421, 0.9013, 0.4325, 0.5091, 0.4572, 0.2181, 0.2707, 0.2422,\n                       0.7409, 0.1173, 0.7146, 0.2419, 0.2075, 0.4396, 0.3617, 0.1979, 0.6274,\n                       0.2378, 0.5074, 0.3481, 0.1357, 0.4854, 0.7024, 0.3413, 0.8453, 0.9216,\n                       0.6062, 0.2736, 0.0918, 0.1259, 0.6648, 0.6855, 0.5881, 0.3609, 0.2937,\n                       0.5408, 0.6573, 0.2386, 0.1465, 0.1690, 0.3197, 0.4246, 0.4925, 0.7806,\n                       0.1877, 0.4286, 0.1219, 1.6337, 0.4756, 0.2665, 0.5455, 0.3729, 0.7118,\n                       0.3426, 0.1614, 0.5609, 0.2890, 1.6329, 0.2169, 0.2155, 0.3594])),\n              ('backbone.models.0.model.layer2.0.downsample.1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.1.conv1.weight',\n               tensor([[[[ 0.0350]],\n               \n                        [[ 0.2355]],\n               \n                        [[-0.1182]],\n               \n                        ...,\n               \n                        [[ 0.0563]],\n               \n                        [[-0.0290]],\n               \n                        [[-0.0189]]],\n               \n               \n                       [[[ 0.0178]],\n               \n                        [[-0.0990]],\n               \n                        [[ 0.0162]],\n               \n                        ...,\n               \n                        [[-0.0006]],\n               \n                        [[-0.0188]],\n               \n                        [[-0.2683]]],\n               \n               \n                       [[[-0.0530]],\n               \n                        [[-0.1343]],\n               \n                        [[ 0.0805]],\n               \n                        ...,\n               \n                        [[-0.0422]],\n               \n                        [[ 0.0100]],\n               \n                        [[-0.0023]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0388]],\n               \n                        [[ 0.0712]],\n               \n                        [[ 0.0040]],\n               \n                        ...,\n               \n                        [[ 0.0072]],\n               \n                        [[ 0.0314]],\n               \n                        [[ 0.0034]]],\n               \n               \n                       [[[ 0.0344]],\n               \n                        [[ 0.0252]],\n               \n                        [[ 0.0787]],\n               \n                        ...,\n               \n                        [[-0.0138]],\n               \n                        [[ 0.0385]],\n               \n                        [[-0.2388]]],\n               \n               \n                       [[[ 0.0203]],\n               \n                        [[-0.1513]],\n               \n                        [[ 0.0244]],\n               \n                        ...,\n               \n                        [[-0.0572]],\n               \n                        [[-0.0523]],\n               \n                        [[ 0.0540]]]])),\n              ('backbone.models.0.model.layer2.1.bn1.weight',\n               tensor([1.2297, 1.2862, 1.0327, 0.9841, 1.0766, 1.2121, 0.8002, 0.8596, 1.2946,\n                       0.7434, 0.8012, 0.9779, 1.0363, 0.8250, 0.8743, 0.7018, 0.9270, 0.8654,\n                       0.8483, 0.7965, 0.7549, 1.2214, 0.8968, 0.6896, 0.7879, 0.7330, 0.6286,\n                       1.2281, 1.3805, 0.7498, 0.7544, 1.1222, 1.3058, 0.8607, 1.0810, 0.8082,\n                       0.8055, 0.9893, 1.2075, 1.9476, 0.9657, 0.8505, 0.9329, 0.6383, 1.8344,\n                       1.1740, 0.9864, 0.8322, 0.9646, 0.9315, 1.1343, 0.8376, 0.7837, 0.8765,\n                       0.8426, 1.0637, 0.7300, 0.8749, 1.0074, 1.7429, 0.7695, 0.6600, 0.8518,\n                       0.8767, 0.9251, 0.8162, 0.9521, 0.9888, 0.7914, 0.9233, 1.0607, 0.8258,\n                       0.8272, 0.8636, 0.8571, 0.9672, 1.3698, 1.0049, 1.2082, 0.8751, 0.6152,\n                       0.8893, 0.8146, 1.2648, 1.8959, 0.8142, 0.6942, 0.8841, 1.1575, 0.8248,\n                       0.8239, 0.6187, 0.9913, 1.1645, 0.7026, 1.7171, 0.8433, 0.9860, 0.7510,\n                       1.3525, 0.8838, 1.6585, 0.9589, 0.9079, 0.7860, 0.7530, 0.7900, 1.0195,\n                       1.4280, 1.1035, 0.7935, 0.8398, 1.0502, 0.9436, 0.9977, 1.1225, 0.8744,\n                       0.8861, 0.8505, 0.7903, 1.0779, 1.4456, 0.8025, 0.7850, 0.7780, 1.2363,\n                       1.0266, 0.7645])),\n              ('backbone.models.0.model.layer2.1.bn1.bias',\n               tensor([-1.0725, -0.6949, -0.1867, -0.1477,  0.3331, -0.5297,  0.5905,  0.1677,\n                       -1.7157,  0.1052, -0.0605, -0.3772, -0.4567,  0.1876, -0.2633,  0.2840,\n                       -0.0991,  0.1472,  0.2690, -0.0565, -0.1194, -1.0430,  0.1618,  0.2807,\n                        0.5676,  0.0532,  0.8855, -0.2633, -1.9060,  0.7602,  0.1970, -0.8601,\n                       -1.1713,  0.0357, -0.1767,  0.1954,  0.0881,  0.3192, -0.5689, -1.1166,\n                       -0.5252, -0.3003, -0.1880,  0.5492, -0.4892, -0.4644, -0.4216,  0.2566,\n                        0.1811, -0.5741,  0.2121,  0.2253,  0.3244,  0.0289, -0.0833,  0.1229,\n                        0.0479,  0.2272, -0.8531, -1.6867,  0.4791,  0.5330,  0.6757, -0.0539,\n                        0.3508, -0.0586,  0.2239, -0.5330,  0.6917,  0.4296, -0.3379, -0.0071,\n                        0.0584,  0.0185,  0.3631,  0.3207, -0.9833, -0.1031, -0.4324,  0.5034,\n                        0.9571,  0.2590,  0.2169, -0.2908, -0.6305,  0.0649,  0.1345, -0.0314,\n                       -0.7141, -0.0986, -0.0029,  1.0701,  0.0623, -0.8030,  0.3040, -1.2557,\n                        0.5245,  0.1422,  0.2400, -0.2193,  0.0243, -1.5308, -0.2118,  0.1423,\n                        0.2513,  0.0145,  0.2818,  0.0132, -1.1155, -0.3389,  0.3430,  0.4431,\n                       -0.2538, -0.0952,  0.1474, -0.1771,  0.0358,  0.0098, -0.0822,  0.1553,\n                       -0.2432, -2.0773,  0.0355,  0.1765,  0.4786, -1.0914, -0.1849,  0.0853])),\n              ('backbone.models.0.model.layer2.1.bn1.running_mean',\n               tensor([-1.5673, -3.9003, -0.2931, -2.8427,  0.5908, -2.6094,  3.3594, -1.4481,\n                       -2.8509,  0.5895, -2.8111, -1.8064,  1.9411,  3.6629,  0.2533, -0.4234,\n                       -2.1124, -0.4043,  0.5800,  3.1075, -0.3123, -2.3457,  1.3657,  1.8900,\n                       -2.4704,  0.5681, -4.6686, -2.7545, -0.7763,  1.8772,  1.2120, -2.9645,\n                        1.2843, -3.4913, -0.5697, -3.9590, -0.8825, -1.5349, -2.2297, -3.3590,\n                        0.6612, -0.4049, -1.2193, -2.6684, -3.7581,  4.3114, -3.0154, -3.4034,\n                        0.9687, -1.2766,  0.6641, -0.2012, -1.6617, -5.8957, -2.8602, -0.6828,\n                       -0.1399, -1.1535,  1.3133, -1.2260, -1.6933, -3.4490,  1.8645,  1.4637,\n                        1.9905, -1.4175,  4.6833,  2.0097, -5.1645,  0.5664, -1.8759, -0.5858,\n                       -2.0852,  0.2295,  1.9619, -0.4094, -1.3194, -1.7764, -4.9710, -0.5367,\n                       -5.7914,  0.5289,  7.1841, -5.6258, -3.6751, -1.1567,  5.9319, -1.5003,\n                       -6.2021, -0.9555,  2.5562, -2.3430,  0.2410,  2.5740, -2.0824, -2.8306,\n                       -0.8853,  0.8289, -0.5873, -1.5063, -0.1203, -1.5814,  1.0169, -1.9665,\n                       -0.8742, -0.6181,  1.2430, -0.3340, -4.1976, -1.1160,  1.2396,  1.8312,\n                        0.6915, -6.8567, -1.1204, -1.6574, -0.5287, -1.0022, -1.6268, -1.6821,\n                       -1.6690, -3.7480, -0.1761,  2.8060, -0.9191, -1.0009,  0.3036, -1.3154])),\n              ('backbone.models.0.model.layer2.1.bn1.running_var',\n               tensor([ 2.8044,  7.3261,  8.3457,  3.6989,  9.1001,  8.3001,  8.8956,  6.2218,\n                        2.0324,  4.8171,  4.9374,  5.7564,  6.2948,  5.3683,  2.9389,  5.8205,\n                        4.7442,  6.6425,  6.2487,  6.2701,  3.3491,  3.3829,  5.1029,  7.7938,\n                       10.7669,  4.7304,  5.0088,  7.5776,  2.5488,  7.9616,  4.8274,  3.4687,\n                        4.6734,  6.3230, 14.0251,  6.1697,  3.3365, 11.1118,  1.8969, 14.2267,\n                        3.2837,  3.0151,  6.4804,  5.5554, 13.7157,  4.7827,  4.2068,  4.7150,\n                       13.6450,  1.9717, 11.5355,  7.8941,  6.5215,  5.1219,  2.4927, 10.1105,\n                        2.6879,  8.7653,  3.2583,  2.4395,  9.0725,  9.7042, 15.3116,  4.5448,\n                       12.2394,  5.2061, 13.9648,  5.0587, 10.2547,  9.1579,  4.4500,  5.1074,\n                        5.5891,  6.1489,  7.3549, 11.7746,  5.8157,  8.2238,  4.9171, 11.6985,\n                        6.7572,  6.2682,  8.7177,  4.4699, 13.6274,  6.4629,  2.7253,  5.8182,\n                        3.6123,  3.5579,  6.2104,  5.3102, 12.8686,  6.0557,  4.9921,  3.3921,\n                       11.9232, 12.9079,  4.9754, 19.9180,  3.8808,  5.6346,  4.7409,  9.4696,\n                        4.2651,  4.7348,  5.8225,  7.1572,  1.5761,  4.1691,  5.6614,  8.4120,\n                        3.5252,  5.2025,  7.3826,  9.6713,  4.9351,  6.8338,  7.4951,  4.1033,\n                        6.3699,  1.9056,  5.8588,  3.1201,  5.8610,  3.4089,  5.8104,  4.8012])),\n              ('backbone.models.0.model.layer2.1.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.1.conv2.weight',\n               tensor([[[[ 2.2185e-03,  2.4529e-02,  2.7421e-02],\n                         [-4.7752e-03, -3.8296e-03,  1.8546e-02],\n                         [ 1.5901e-02,  7.5408e-02,  2.4716e-02]],\n               \n                        [[-3.4061e-03,  1.1071e-02,  2.2833e-02],\n                         [-5.2984e-02,  4.4551e-02, -1.1116e-02],\n                         [-1.0765e-02,  1.8530e-01, -3.0750e-02]],\n               \n                        [[ 1.7190e-02,  1.2556e-02,  1.1762e-02],\n                         [ 3.1876e-02,  1.5896e-02,  1.1471e-03],\n                         [ 3.0703e-03,  6.2293e-02, -8.8184e-03]],\n               \n                        ...,\n               \n                        [[-1.3568e-02,  1.4378e-02, -2.2940e-02],\n                         [-7.8885e-03, -1.0092e-02, -1.8259e-02],\n                         [ 8.3750e-03,  5.9270e-02, -1.4763e-02]],\n               \n                        [[ 3.0195e-02,  3.6215e-02,  5.4509e-02],\n                         [-5.2206e-02, -5.6584e-02, -1.0691e-01],\n                         [ 4.8765e-02,  5.7694e-02, -7.6266e-02]],\n               \n                        [[ 4.0707e-02, -2.4820e-05, -2.1259e-02],\n                         [-5.4440e-02, -1.6405e-01, -1.4137e-01],\n                         [-4.2941e-03,  3.0354e-01,  3.6938e-02]]],\n               \n               \n                       [[[-2.0214e-02, -1.6261e-02, -9.9746e-03],\n                         [ 1.3630e-02,  1.2209e-02,  9.9822e-03],\n                         [-5.4691e-02, -3.1080e-03,  1.9267e-02]],\n               \n                        [[ 3.4706e-01,  1.4231e-01,  6.9086e-02],\n                         [ 8.6092e-02, -1.1005e-01, -3.1329e-01],\n                         [-4.6986e-02, -2.6043e-01, -3.6406e-01]],\n               \n                        [[-8.2652e-03, -3.6425e-02,  3.5812e-03],\n                         [-2.2782e-02, -6.1714e-03,  1.6453e-02],\n                         [-3.1780e-02,  1.4788e-02,  3.6664e-02]],\n               \n                        ...,\n               \n                        [[ 1.8578e-02, -4.7396e-02, -1.6955e-03],\n                         [-2.5170e-03, -2.3773e-02,  1.0616e-02],\n                         [-1.1946e-02,  1.1382e-02,  3.6917e-03]],\n               \n                        [[ 6.8866e-02,  1.6300e-03, -1.4381e-01],\n                         [-9.9243e-02, -5.2024e-01,  5.3250e-03],\n                         [-1.0317e-02, -2.7705e-01, -1.2844e-01]],\n               \n                        [[-2.4189e-02, -4.3244e-02, -8.2454e-02],\n                         [ 1.8417e-02, -3.0860e-02, -8.4316e-02],\n                         [ 1.7104e-02,  2.2073e-02,  2.8518e-02]]],\n               \n               \n                       [[[ 1.2286e-02,  1.0287e-03,  8.8068e-03],\n                         [ 1.5066e-02, -4.2388e-02,  1.8774e-02],\n                         [-8.0471e-03, -1.0548e-03, -3.4201e-03]],\n               \n                        [[ 4.6073e-02, -2.4948e-02,  5.5468e-03],\n                         [-8.6273e-02, -8.6188e-02,  4.6955e-02],\n                         [-1.1880e-01, -1.6399e-01, -9.3969e-03]],\n               \n                        [[-5.6836e-03,  7.2017e-04, -3.0113e-03],\n                         [-7.9335e-02, -1.7990e-02,  1.5118e-02],\n                         [-4.2545e-02, -1.5237e-02, -2.0618e-03]],\n               \n                        ...,\n               \n                        [[ 1.9539e-04,  6.1580e-02,  2.0957e-02],\n                         [ 2.7237e-02,  9.0762e-02, -4.8366e-03],\n                         [ 2.8996e-02,  1.2279e-02,  1.7976e-02]],\n               \n                        [[-1.8626e-03,  3.0578e-02,  5.0247e-03],\n                         [-2.6808e-02,  7.8274e-03, -3.1233e-02],\n                         [-2.3939e-02,  4.7235e-02,  7.6712e-03]],\n               \n                        [[ 4.9769e-02, -2.4214e-02, -1.5012e-02],\n                         [ 3.1537e-02,  4.5660e-02, -2.2371e-02],\n                         [-5.1952e-02,  6.8059e-02,  4.4787e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 3.4825e-02,  5.0474e-02,  2.1506e-02],\n                         [ 3.2504e-02, -5.7773e-03,  1.8264e-02],\n                         [ 4.8939e-02,  4.4255e-02,  2.0022e-02]],\n               \n                        [[-3.2647e-02,  3.5756e-03,  1.2716e-03],\n                         [-3.2942e-02,  1.8269e-02, -1.2804e-02],\n                         [ 1.7144e-02,  2.1838e-02, -1.6571e-02]],\n               \n                        [[-4.6319e-02,  2.3458e-01,  7.2288e-02],\n                         [-3.5455e-02, -3.9406e-02,  7.1543e-02],\n                         [ 5.7049e-02, -1.4157e-01,  1.0526e-01]],\n               \n                        ...,\n               \n                        [[-3.0648e-02, -7.5894e-02, -1.3329e-02],\n                         [ 4.2664e-02, -1.3383e-02,  1.2617e-02],\n                         [ 7.3633e-02,  1.5311e-01,  6.3624e-02]],\n               \n                        [[-3.5174e-02, -1.1814e-02, -3.1667e-02],\n                         [ 3.3884e-03,  2.2202e-02, -6.7385e-03],\n                         [-2.6866e-02,  5.4080e-02,  6.6047e-03]],\n               \n                        [[ 1.0338e-02,  1.4046e-02,  3.9071e-03],\n                         [-2.7101e-02, -3.5659e-02, -4.9320e-02],\n                         [-1.7135e-02,  2.1354e-02,  1.5974e-02]]],\n               \n               \n                       [[[-5.9443e-02, -4.7743e-02, -5.2870e-02],\n                         [-1.9157e-02,  1.8222e-01, -1.0053e-02],\n                         [-6.5893e-02,  5.2909e-02, -1.7780e-02]],\n               \n                        [[ 1.3727e-02,  6.1422e-03, -5.9653e-02],\n                         [-7.4131e-02, -5.5017e-02, -1.8316e-02],\n                         [-5.6143e-02, -5.4158e-02,  2.0217e-02]],\n               \n                        [[-1.9371e-02, -4.1147e-03, -4.6672e-02],\n                         [ 3.0791e-02,  8.4860e-02,  2.1345e-02],\n                         [-4.9420e-02, -8.8867e-02, -2.9856e-02]],\n               \n                        ...,\n               \n                        [[-7.3323e-03,  1.7511e-02, -3.0727e-02],\n                         [ 9.9446e-03,  9.9717e-02,  2.7641e-02],\n                         [-3.2898e-02,  7.1614e-03, -1.3387e-02]],\n               \n                        [[ 2.4993e-02, -5.7859e-02, -8.0371e-02],\n                         [-4.4422e-02, -1.1489e-02, -1.7549e-01],\n                         [-2.8256e-02, -1.0557e-01, -2.6500e-02]],\n               \n                        [[-1.3995e-01, -4.1763e-02, -8.7555e-02],\n                         [-6.6741e-02,  7.8106e-02, -1.5092e-01],\n                         [-1.1397e-02, -8.8273e-02,  1.4861e-02]]],\n               \n               \n                       [[[-1.5426e-02, -3.3087e-02, -6.3558e-02],\n                         [-5.2197e-02, -6.8334e-02, -4.4184e-02],\n                         [-4.6546e-02, -3.2531e-02, -5.7241e-02]],\n               \n                        [[ 1.8822e-02, -2.5280e-02,  5.3772e-03],\n                         [-1.5373e-02, -3.7645e-04, -1.9525e-02],\n                         [ 1.5127e-02,  3.9154e-03, -1.8661e-02]],\n               \n                        [[-1.9673e-02,  1.9571e-02, -1.4647e-02],\n                         [ 4.3220e-02, -1.7733e-01,  2.3328e-02],\n                         [ 6.5646e-03,  2.9393e-02, -5.9908e-03]],\n               \n                        ...,\n               \n                        [[ 3.8828e-03, -1.6786e-02, -2.9067e-02],\n                         [-5.4870e-02,  5.8027e-02, -3.3523e-02],\n                         [-6.5611e-02, -4.9576e-02, -7.5962e-02]],\n               \n                        [[-4.8931e-03,  1.8795e-02,  2.2022e-02],\n                         [ 2.4152e-03,  2.0520e-03,  1.6984e-02],\n                         [-6.1129e-04, -6.1635e-03, -2.8209e-02]],\n               \n                        [[-1.5873e-02,  1.6044e-02,  3.2559e-03],\n                         [ 4.6236e-03, -7.9600e-03,  3.5606e-03],\n                         [-1.5337e-03, -1.9620e-02, -2.0903e-02]]]])),\n              ('backbone.models.0.model.layer2.1.bn2.weight',\n               tensor([0.9133, 1.2088, 1.2168, 1.0910, 0.4601, 1.0147, 0.8988, 0.5453, 1.0746,\n                       0.5616, 0.9828, 1.2911, 1.0827, 0.8192, 0.8689, 1.1080, 0.9076, 0.7135,\n                       0.6807, 0.4904, 1.0298, 0.9863, 1.4978, 0.6538, 1.1865, 0.4763, 1.1265,\n                       0.4583, 0.9026, 0.5250, 0.7108, 0.8910, 0.5456, 0.6797, 1.1983, 0.9584,\n                       1.0902, 0.5924, 0.5561, 1.0096, 1.0339, 0.7265, 1.0806, 1.5221, 0.7888,\n                       1.3017, 1.0401, 1.2699, 0.4940, 0.8833, 0.4137, 0.5236, 0.7011, 0.7658,\n                       1.0963, 1.1172, 0.4871, 1.1469, 0.4841, 0.9768, 1.0429, 1.0008, 0.7264,\n                       0.9149, 0.4901, 1.3491, 1.1601, 0.8475, 0.8625, 1.0743, 0.4251, 0.8338,\n                       0.8345, 0.7755, 0.9822, 0.4710, 0.8847, 1.3398, 1.5327, 0.4649, 0.5868,\n                       1.1929, 0.7726, 0.4544, 0.7235, 1.4752, 0.5126, 0.4776, 0.9981, 0.4637,\n                       1.0361, 0.8964, 0.7212, 0.5357, 0.5110, 0.9151, 0.5246, 0.4756, 1.0240,\n                       0.6489, 1.0637, 0.6522, 1.3511, 0.8979, 0.8424, 2.1484, 0.8888, 0.9847,\n                       0.6816, 0.6783, 0.5908, 1.0048, 0.6644, 1.0779, 1.1663, 0.4865, 0.8806,\n                       1.0127, 1.1533, 0.6826, 0.6228, 0.8546, 0.9416, 0.8625, 1.0584, 0.9214,\n                       0.4365, 1.0998])),\n              ('backbone.models.0.model.layer2.1.bn2.bias',\n               tensor([-8.2823e-02, -8.9569e-01, -5.2069e-01, -7.2266e-01,  1.3907e+00,\n                       -4.5173e-01, -6.5730e-01,  1.4143e-01, -5.7639e-01,  2.0928e-01,\n                       -6.0551e-01, -1.6519e+00, -8.8330e-01, -1.6268e-01, -1.5192e-01,\n                       -5.1386e-01,  3.3634e-01, -6.7166e-02, -1.3655e-01,  2.4884e-01,\n                       -5.0547e-01, -3.2630e-01, -1.5664e+00,  2.9049e-02, -1.2079e+00,\n                        1.4226e+00, -1.9176e-01,  1.1587e+00, -3.8352e-01,  4.9331e-01,\n                       -6.7229e-02,  8.7988e-02,  3.6774e-01,  2.2859e-02, -7.5562e-01,\n                       -4.8651e-01, -7.5713e-01,  3.1207e-01,  4.2221e-01, -4.0537e-01,\n                       -1.8956e-01,  3.0665e-02, -5.9065e-01, -1.4224e+00, -2.7148e-01,\n                       -1.8097e+00, -6.1687e-01, -1.0823e+00,  7.3913e-01, -1.0641e-01,\n                        5.6588e-01,  3.9058e-01, -1.5041e-01, -1.0270e-01, -1.5207e-01,\n                       -4.0212e-01,  1.9866e-01, -7.9747e-01,  3.7573e-01, -4.0384e-01,\n                       -4.9575e-01,  2.7984e-01, -1.6039e-01, -3.6143e-01,  6.0785e-01,\n                       -1.3858e+00, -1.5821e+00, -8.9674e-01, -3.1309e-01, -9.2873e-01,\n                        1.1327e+00, -3.8811e-01, -1.7269e-01, -4.4938e-01, -3.8784e-01,\n                        3.8874e-01,  9.0384e-02, -1.0447e+00, -1.3917e+00,  5.7587e-01,\n                        8.8134e-02, -6.6436e-01, -2.3837e-01,  1.2187e+00, -3.7197e-01,\n                       -1.1883e+00,  1.4074e-01,  1.5956e+00, -7.3292e-01,  5.3492e-01,\n                       -5.6805e-01,  1.3342e-01, -2.4194e-01,  5.2778e-02,  2.7203e-01,\n                        9.3506e-02,  6.8397e-01,  1.3493e+00, -3.3389e-01, -7.4690e-02,\n                       -5.4658e-01,  3.4542e-04, -9.6474e-01, -5.6665e-01, -1.0205e-01,\n                       -2.9040e+00, -6.7052e-02, -2.0511e-01,  3.4326e-01,  3.8454e-01,\n                       -3.5660e-02, -7.0624e-01,  6.6813e-02, -4.2601e-01, -4.0759e-01,\n                        1.4356e+00, -1.4949e-01, -5.5935e-01, -9.0282e-01,  1.0590e-02,\n                        4.9102e-01, -3.5076e-01, -4.1892e-01,  1.2625e-01, -4.8007e-01,\n                       -3.0383e-01,  5.3102e-01, -1.4211e+00])),\n              ('backbone.models.0.model.layer2.1.bn2.running_mean',\n               tensor([  1.6860,   0.0937,  -1.5855,   0.0195,   2.2575,   0.5878,  -3.2102,\n                        -2.4001,   1.1516,  -1.4057,   0.7168,  -3.7895,  -0.0627,  -0.6735,\n                         1.3073,  -2.7696,   2.5186,   0.6556,   2.7734,  -1.9555,   1.0837,\n                         0.2509,  -5.0599,  -2.7404,  -2.1661,  -1.1152, -11.7240,   1.7135,\n                        -1.9409,  -0.5220,  -4.0826,   1.9583,  -1.6842,  -1.3322,  -6.5950,\n                         0.4255,  -0.8047,  -1.1864,  -1.1281,   0.4849,   0.6928,   1.2857,\n                         0.4613,  -1.6387,  -3.0950,  -2.4959,   1.0699,   0.1149,  -0.2162,\n                         1.4244,  -0.8872,  -0.8830,  -2.2201,  -2.3003,  -9.7944,   3.8322,\n                         0.0757,  -7.8137,  -2.5043,  -2.8622,   0.6544,   2.2387,  -1.8431,\n                         0.1729,   3.6288,   2.7731,  -1.4888,   0.1281,   0.4291,  -0.6440,\n                        -1.4595,  -0.3714,   2.2086,  -1.9833,   0.5147,  -0.4037,   1.0795,\n                        -2.0574,  -0.6071,   1.9257,  -1.4165,   0.5956,  -1.0930,   0.0385,\n                        -0.1553,  -2.3359,  -1.1074,  -0.8216,  -3.3469,  -1.9057,   0.6278,\n                        -0.7071,  -2.4107,  -2.5231,   2.1171,   2.7725,  -0.5915,   0.1626,\n                         0.2643,  -1.5943,   0.6203,  -1.7990,   0.2835,  -1.3305,   1.1701,\n                        -0.5496,   1.2791,   1.0057,  -0.7766,  -1.6719,  -2.2497,   1.2770,\n                        -1.4745,   0.9495,  -1.3206,   1.0209,  -0.3610,  -0.2543,  -0.2376,\n                         1.4260,  -0.3581,  -0.0360,   0.1157,   1.7968,   1.0082,   0.2300,\n                         0.0847,  -1.5168])),\n              ('backbone.models.0.model.layer2.1.bn2.running_var',\n               tensor([ 5.5775,  3.7796,  5.5408,  3.7660,  3.7901,  5.1296,  2.1955,  3.6884,\n                        3.6146,  3.1179,  3.2366,  2.6838,  2.9525,  5.4952,  4.0230,  6.3227,\n                       10.5330,  2.9421,  5.3651,  2.8660,  4.2614,  5.2755,  3.1309,  5.8685,\n                        1.9469,  3.7003, 16.5549,  2.8671,  5.0520,  2.7794,  3.5527,  7.7062,\n                        3.0490,  4.9021,  9.3984,  4.1296,  1.9591,  3.0387,  3.4265,  5.6285,\n                        6.7282,  3.7782,  3.3123,  2.7529,  4.6275,  1.8998,  3.7751,  8.8581,\n                        2.7263,  4.7780,  2.1948,  4.6442,  3.4658,  4.1432, 12.9969, 21.3684,\n                        3.0856,  6.8938,  3.5980,  3.9305,  5.2179, 11.1648,  4.6851,  4.4458,\n                        4.7729,  6.0392,  1.2667,  2.7478,  4.1571,  2.1151,  2.8624,  2.7066,\n                        5.6916,  2.6407,  4.3375,  5.0195,  6.5350,  4.1714,  4.6589,  2.0996,\n                        1.9337,  5.0705,  4.6485,  3.4304,  3.3435,  4.4874,  3.1484,  3.2442,\n                        3.5550,  2.3466,  3.6938, 11.9716,  3.1749,  2.9214,  1.6275,  8.9777,\n                        3.0504,  3.9662,  5.1308,  2.9945,  4.3843,  1.8011,  3.9587,  2.6901,\n                        5.0314,  5.2024,  5.2838,  5.9131,  8.1882,  2.9751,  2.2748,  2.5560,\n                        4.7501,  4.5869,  7.5974,  3.0491,  5.6911,  2.3891,  3.9855,  3.5340,\n                        5.5694,  2.4087,  3.2361,  6.4798,  6.1693,  4.4404,  3.0944,  1.3867])),\n              ('backbone.models.0.model.layer2.1.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.1.conv3.weight',\n               tensor([[[[ 0.0247]],\n               \n                        [[ 0.0532]],\n               \n                        [[ 0.1682]],\n               \n                        ...,\n               \n                        [[ 0.0608]],\n               \n                        [[-0.0015]],\n               \n                        [[ 0.0136]]],\n               \n               \n                       [[[-0.1668]],\n               \n                        [[ 0.0437]],\n               \n                        [[-0.0131]],\n               \n                        ...,\n               \n                        [[ 0.0012]],\n               \n                        [[-0.0322]],\n               \n                        [[ 0.0119]]],\n               \n               \n                       [[[-0.0105]],\n               \n                        [[ 0.0047]],\n               \n                        [[-0.0406]],\n               \n                        ...,\n               \n                        [[-0.0038]],\n               \n                        [[-0.0303]],\n               \n                        [[-0.0093]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0183]],\n               \n                        [[-0.0690]],\n               \n                        [[-0.0524]],\n               \n                        ...,\n               \n                        [[-0.0166]],\n               \n                        [[-0.0038]],\n               \n                        [[-0.0127]]],\n               \n               \n                       [[[ 0.0046]],\n               \n                        [[-0.0011]],\n               \n                        [[ 0.0093]],\n               \n                        ...,\n               \n                        [[-0.0005]],\n               \n                        [[-0.0038]],\n               \n                        [[ 0.0074]]],\n               \n               \n                       [[[ 0.1270]],\n               \n                        [[ 0.0539]],\n               \n                        [[ 0.1224]],\n               \n                        ...,\n               \n                        [[-0.0318]],\n               \n                        [[-0.0150]],\n               \n                        [[ 0.0233]]]])),\n              ('backbone.models.0.model.layer2.1.bn3.weight',\n               tensor([ 7.9325e-01,  1.4624e+00,  5.3365e-02,  3.3937e-01, -1.8546e-01,\n                       -7.7395e-01, -7.1608e-01,  5.6404e-01,  5.4568e-01,  7.0894e-01,\n                        1.3248e-01, -3.9177e-01,  7.2413e-01, -1.0763e-01,  4.6338e-01,\n                        7.1272e-01, -6.1564e-01, -1.1709e-01,  7.3372e-01, -7.0925e-01,\n                       -7.3761e-01,  9.1293e-01,  1.0050e-01,  7.3766e-01, -6.6997e-01,\n                        6.5486e-01, -1.9277e-02,  7.1302e-01, -3.3729e-01,  2.4915e-01,\n                        1.5485e-01,  8.8126e-02,  3.6249e+00, -7.6216e-01,  6.8259e-01,\n                       -1.5342e-01, -3.6093e-01,  5.4690e-01,  5.8214e-01,  6.4966e-01,\n                        3.3995e-01,  6.1266e-01, -5.2828e-01, -6.0359e-01,  3.9102e-02,\n                        5.1780e-01,  2.0369e-01,  6.4847e-01,  2.1978e-01,  4.2288e-01,\n                       -5.5248e-01, -2.2049e-01, -5.2650e-01, -5.8025e-01,  1.3557e-02,\n                       -5.9079e-01, -3.7058e-01, -2.1639e-01, -5.7431e-01, -6.1467e-01,\n                        6.9393e-01,  5.9591e-01,  3.2053e-01,  3.5887e-01, -4.3455e-01,\n                       -6.7133e-01, -1.0471e+00, -5.6129e-01, -4.5913e-01, -1.2852e-01,\n                        4.0462e-01,  3.1679e-01, -7.2841e-01,  3.1880e-01,  1.8772e-01,\n                        1.3613e+00, -2.4391e-01,  4.5321e-01,  6.4694e-01, -7.1934e-01,\n                        6.5912e-01,  7.1707e-01, -2.5791e-01, -3.3149e-01,  2.1512e-01,\n                       -5.9912e-02, -3.3738e-01,  9.4975e-01, -2.7045e-01,  4.0774e-01,\n                       -5.2860e-01,  3.1554e-01, -3.2130e-01,  4.4045e-02, -9.2198e-01,\n                        6.7827e-01, -6.8315e-01,  3.6689e-02,  5.4907e-01, -4.7638e-01,\n                        1.0022e+00, -4.2798e-01, -1.0244e+00, -5.9520e-01,  3.7277e-01,\n                        3.4566e-01,  1.9602e-01,  4.5016e-01, -7.5670e-01, -9.7171e-01,\n                        8.4971e-01,  1.0331e+00, -1.2319e+00,  8.5309e-01,  1.2543e+00,\n                        3.0031e-01,  8.6102e-01,  7.0069e-01,  7.6276e-02, -4.7710e-01,\n                        7.9681e-01,  9.1194e-01, -8.4706e-02, -2.6366e-01,  7.5287e-01,\n                       -1.0616e-01, -2.9553e-01, -8.5586e-01, -7.9267e-02, -5.6201e-01,\n                        7.0397e-01, -9.1684e-01, -5.5566e-01,  7.4590e-02,  9.3550e-01,\n                        3.2878e-01,  9.2799e-01, -6.2598e-02,  4.9296e-01,  7.8276e-01,\n                       -3.7335e-01, -4.4034e-01, -6.6081e-01,  4.8327e-01,  1.1061e+00,\n                        1.2780e+00, -5.5423e-01,  1.3030e-01,  1.8401e+00,  8.0705e-01,\n                       -1.0483e+00, -4.9756e-01, -4.1990e-01, -6.2462e-01, -1.3218e-01,\n                        1.5940e-01,  2.5671e-01, -8.6073e-01, -5.6786e-01, -5.5502e-01,\n                        5.4598e-01,  1.1174e-01,  6.0245e-01,  1.5563e-01, -1.7143e+00,\n                       -4.9244e-01, -1.2852e+00, -5.1826e-01,  1.1911e-03,  3.0453e-01,\n                        1.8577e-01, -5.5710e-01, -6.5032e-01, -1.6028e-01,  6.5148e-01,\n                       -4.7942e-01, -7.0916e-01,  5.7246e-01,  7.7302e-01,  3.9336e-01,\n                        3.9764e-01,  4.9792e-01, -3.7315e-01, -1.2957e-01,  1.4562e-01,\n                        2.8081e-01, -3.8188e-01, -4.9614e-01,  1.0669e+00,  1.3825e+00,\n                        6.2398e-01,  2.3118e-01, -8.8897e-01,  6.3087e-01, -7.6826e-02,\n                       -1.5334e+00, -3.5318e-01, -8.9909e-01,  1.3251e+00, -7.6891e-01,\n                       -2.4705e-01, -3.7105e-01, -6.9962e-01,  1.2254e-01,  5.9030e-01,\n                       -1.1523e-01, -9.8295e-01,  3.3875e-01, -2.8209e-01,  1.3731e-01,\n                        2.0857e-01, -1.9634e-01,  7.4059e-01,  4.9967e-01, -7.2770e-01,\n                        5.1854e-01,  2.0857e-01,  3.4993e-01, -7.5386e-01, -2.0564e-01,\n                       -3.6691e-01,  4.3416e-01,  9.3319e-01, -2.4237e+00,  4.4737e-01,\n                       -4.5346e-01, -3.1974e-01,  3.1848e-01, -4.5497e-01, -9.3662e-01,\n                        6.5537e-01,  1.1141e+00,  4.2397e-01, -6.8416e-01,  2.6768e-01,\n                        5.7772e-01, -3.1020e-01, -9.0173e-01,  4.9099e-01, -6.5042e-01,\n                        8.2745e-01,  3.4179e-01,  1.5437e-01, -1.0122e+00,  5.1167e-01,\n                        5.7046e-01,  1.6403e-01,  6.8449e-01,  1.7510e-01, -8.4384e-01,\n                        5.1151e-01,  4.7105e-01,  8.6051e-01, -1.5170e-01,  6.2482e-01,\n                        6.1207e-01, -2.5429e-01, -5.2661e-01,  4.0306e-01, -2.8343e-01,\n                       -3.9255e-01,  3.6963e-02, -2.2657e-01, -3.5530e-01,  2.2640e-01,\n                        1.5775e-01,  3.4071e-02,  6.4719e-01, -3.8682e-01,  6.3801e-01,\n                        3.9233e-01,  8.5389e-01,  4.3476e-01,  1.8670e-01, -7.2703e-01,\n                       -1.0359e+00,  7.7826e-01,  3.9977e-01,  4.7232e-01, -1.0048e+00,\n                        5.0573e-01,  3.3645e-01, -1.1612e+00, -1.3190e-01, -9.5393e-02,\n                       -8.9670e-01, -9.4114e-01, -1.5646e-01,  4.7456e-01,  6.9522e-01,\n                       -1.4308e+00, -5.9351e-02, -6.9366e-01,  4.2313e-01, -4.2129e-01,\n                        3.4400e-01,  2.8052e-02,  1.1147e+00, -1.2281e+00, -4.8415e-01,\n                        6.4364e-01,  6.7834e-01,  9.3388e-01, -5.1519e-01,  5.9629e-01,\n                       -9.6670e-02, -1.7664e+00,  4.2942e-01,  2.9061e-01,  2.6176e-01,\n                        3.6808e-01, -1.3111e+00, -5.3917e-01,  1.1729e+00, -1.8725e-01,\n                        1.3766e-01,  4.5330e-01,  4.7518e-01,  9.6940e-02, -6.3774e-01,\n                        3.6249e-01,  1.0031e-01, -1.3806e-01, -2.6464e-01, -7.2488e-01,\n                       -9.8597e-01,  5.8728e-01, -7.3391e-01, -6.8292e-01,  9.8147e-02,\n                       -9.3619e-02, -5.1556e-01, -5.3798e-01,  4.1841e-01,  6.2499e-01,\n                       -3.2972e-01,  5.1220e-01, -3.8719e-01,  8.3402e-01,  3.9394e-01,\n                       -1.9369e-01, -4.0211e-02, -3.2693e-01, -8.5907e-01, -2.0740e+00,\n                        6.7983e-01,  5.3257e-01,  1.1816e+00,  5.1460e-01,  2.8493e-01,\n                        1.5571e+00, -4.2136e-01,  5.6774e-01,  4.1210e-01,  6.5097e-01,\n                       -1.0948e+00,  8.0013e-01, -7.2644e-01, -1.1908e-01, -5.4513e-01,\n                        6.7135e-01, -4.3951e-01, -1.1343e+00, -9.7577e-02,  4.8040e-01,\n                        4.8762e-01, -1.8658e-01,  3.8389e-01,  5.1292e-01, -3.8149e-01,\n                        1.2270e-01,  2.0210e-01, -2.0771e-02, -7.4496e-01, -2.8904e-01,\n                        6.9126e-01, -6.2888e-01,  2.6971e-01, -6.6680e-01, -3.7256e-01,\n                        4.4762e-01,  1.0308e+00,  7.9202e-01,  7.8796e-01,  7.2851e-01,\n                       -5.5847e-01, -5.9350e-01, -3.1223e-02, -5.9311e-01,  9.4313e-01,\n                        1.1948e-01, -8.0033e-01,  2.0847e-01,  4.9206e-01, -5.1625e-01,\n                        7.9232e-01, -1.4415e+00, -5.8650e-01,  1.2274e+00, -5.7801e-01,\n                       -2.5166e-01, -3.8564e-01,  3.6908e-01, -2.6306e-01, -3.6880e-01,\n                        2.0231e-01, -1.3543e-01,  6.0466e-01, -5.2604e-01,  1.9741e-01,\n                       -9.7339e-02,  1.8508e-01,  6.2856e-01,  6.2532e-01, -7.6872e-01,\n                        4.1353e-01, -4.2179e-01,  5.7162e-01,  1.3026e-01,  6.9135e-01,\n                       -4.1721e-02,  8.6546e-01,  6.8879e-02,  4.9863e-01, -2.2110e-01,\n                        7.7284e-02,  7.0589e-01, -1.0506e+00,  3.9358e-01,  1.4466e+00,\n                       -6.8543e-01,  8.4605e-01, -7.8365e-01,  6.1247e-02,  1.3526e-01,\n                       -2.5648e-01, -8.8141e-01,  2.0581e-01,  5.5504e-01,  1.0079e+00,\n                       -8.8716e-01, -1.2971e-01,  4.6087e-01,  2.8878e-01,  9.1067e-01,\n                       -7.1665e-01,  2.8102e-01,  4.1169e-01,  4.2617e-01, -5.2931e-01,\n                        8.0302e-01,  1.2168e-01,  1.4800e-01, -8.0282e-01,  4.7449e-01,\n                        6.7233e-01,  1.1525e-01, -2.9612e-01,  9.9815e-01, -4.9054e-01,\n                        1.8435e-01, -4.0230e-01,  7.4545e-01,  1.4252e-01, -6.5151e-01,\n                       -1.8806e-01,  1.6849e+00, -6.0008e-01, -3.1565e-01, -5.0967e-02,\n                        6.5671e-01, -8.3588e-02,  8.0988e-01,  1.5057e-01, -6.2149e-01,\n                       -5.5981e-02, -1.4816e-01,  4.9356e-01, -3.0509e-01,  1.0004e+00,\n                        2.0351e-01,  2.1252e-01,  5.5202e-01,  1.5088e-01, -3.4349e-01,\n                       -6.5237e-01,  4.0930e-01,  2.4384e-01, -5.6029e-01,  6.7707e-02,\n                       -8.8529e-01,  1.3829e-01,  3.0640e-01,  4.9650e-01,  5.4407e-01,\n                       -9.1027e-02, -8.6798e-01,  3.5039e-01, -1.3013e+00,  4.3400e-01,\n                        3.9480e-01,  4.2331e-01, -5.3002e-01, -3.9549e-01, -1.3210e-01,\n                       -4.6622e-01,  8.2868e-01,  7.3477e-02, -7.1829e-01, -5.1746e-01,\n                       -4.8644e-03, -4.0841e-01])),\n              ('backbone.models.0.model.layer2.1.bn3.bias',\n               tensor([ 1.2038, -1.8939,  0.2135, -0.2482,  0.8910, -0.5985,  0.3567,  0.9267,\n                       -0.4411, -0.5547,  0.3925,  0.4203,  0.9409,  0.3106, -0.1677,  0.5443,\n                       -0.7263,  0.2845, -0.2615,  1.1880, -0.7638, -0.1867,  0.6769, -0.6803,\n                       -0.2848,  1.2899,  0.3770,  1.0441,  0.7751,  0.7672,  0.4777,  0.7130,\n                       -3.0439, -0.5929,  1.2621,  0.7829,  0.8457,  0.9064, -0.3593,  1.1581,\n                        0.8314, -0.3624,  1.1087,  0.8360,  0.6226, -0.4347,  0.2786, -0.1379,\n                        0.2538, -0.3226, -0.3008,  0.7986,  0.8829, -0.3342,  0.3437,  0.6454,\n                       -0.2218,  0.6146, -0.0331, -0.3035, -0.7180,  0.0156, -0.2606, -0.0494,\n                        0.8146, -0.6509, -0.8448,  1.0520, -0.2929,  0.2201, -0.4181,  0.6665,\n                        0.5314, -0.0887,  0.0196,  0.3564, -0.0093, -0.3350,  1.3397,  0.6712,\n                       -0.0194, -0.6171,  0.2593,  0.4821,  0.2994,  0.4941,  0.0428, -1.1833,\n                        0.6777,  0.1455,  0.1353, -0.1136,  0.8340,  0.5584,  0.0184,  0.7177,\n                       -0.3007,  0.2186,  0.5346, -0.2707, -0.2632, -0.3059, -1.3528, -0.1957,\n                        0.8666,  0.6483,  0.7463,  0.6185, -0.7307, -0.5637, -0.6405, -0.9039,\n                        0.7660,  1.6724, -1.4730, -0.0083,  1.3266, -0.5992,  0.3068, -0.4485,\n                       -0.8637, -0.0041,  0.2843, -0.2893,  0.8752,  0.6675,  0.2242,  0.7236,\n                        0.6753, -0.3176, -0.8307,  1.4878,  0.7955,  0.2386,  1.3844,  0.2943,\n                       -0.6463,  0.3093,  0.5205,  0.3674,  0.7373,  0.8560, -0.9771, -0.0966,\n                        0.1613, -0.8099, -0.4597,  0.7752,  0.9642, -0.8107,  1.4120, -0.4659,\n                        0.5965,  0.0605,  0.2107,  0.2200,  0.2744,  1.1301, -0.4264, -0.3920,\n                       -0.6042,  0.4509,  0.7454,  0.9241, -0.2675, -0.5032, -0.2367, -0.4554,\n                        0.6376, -0.3428,  0.6705, -0.0655, -0.4115,  0.9008, -0.2392,  0.5932,\n                        1.1191,  0.8204, -0.5470, -0.3057, -0.1554, -0.4227, -0.1544,  0.2899,\n                        0.8062,  0.9238,  0.4309, -0.2622,  1.1420,  0.6667, -0.5276,  0.0104,\n                        0.6081,  0.8329,  0.3096, -1.3928, -0.0883, -0.8379, -1.1594, -0.7156,\n                        0.3787,  0.8967, -0.5131,  0.5368, -0.2620,  0.3127, -0.5356,  0.7661,\n                       -0.0484,  0.7670, -0.2346, -0.0745, -0.5037, -0.7000, -0.6740, -0.6204,\n                        0.1454, -0.0448, -0.1970, -0.0699, -0.2776, -0.0544,  0.4637, -1.4601,\n                        0.2389, -0.2556, -0.1545, -0.1399,  0.1073,  1.4351,  0.0823, -0.7963,\n                       -0.2279,  1.2804,  0.3755, -0.1193,  0.4604, -0.2562,  0.8515,  0.0223,\n                       -0.5705, -0.0054,  0.8589, -0.6822,  1.2703,  0.9804,  0.4197, -0.7091,\n                        0.3955,  1.3122, -0.3336, -0.2918,  1.1016,  0.5742, -0.0404, -0.4891,\n                        0.6125, -0.4219, -0.4406,  0.3097,  0.2483,  0.4981,  0.0448,  0.7910,\n                        0.2021,  0.3008,  0.1754,  1.0954,  0.7551, -0.4897, -0.4338, -0.1726,\n                       -0.2847,  0.6401,  0.2586,  1.1908, -0.1809,  0.8275,  0.0246, -0.2101,\n                        1.0242,  0.5363, -1.4360,  0.5391,  0.3779, -0.1658, -0.4639,  0.6624,\n                        0.1226,  1.5245,  0.0406,  0.2642,  0.9456,  0.0369, -0.3699, -0.3882,\n                        0.3868, -1.7429,  1.6032,  0.6666, -0.2554,  0.9865, -0.1791, -0.2910,\n                        0.1604,  0.3903, -0.2719, -0.3052,  0.6203,  0.6196,  0.5842, -0.4261,\n                        0.9503,  0.0231,  0.3030,  0.8807, -0.4048, -0.4649,  0.4881, -0.1943,\n                       -0.1358,  0.6826,  0.8080,  0.8552, -0.4574, -0.7477, -0.2290,  0.5464,\n                        0.6847,  0.6476,  0.5644,  0.3784, -0.1817,  0.8266, -0.6466,  0.4733,\n                       -0.4724, -0.2247, -0.1355,  0.5787, -0.1317,  0.1057, -0.2273, -0.4542,\n                       -1.7184,  1.4164, -0.2304, -0.2631,  0.8555,  0.0379,  0.2921,  0.9925,\n                       -0.5377,  1.4138, -0.7904, -0.3716, -0.7774, -0.7979,  0.2841, -0.4643,\n                        0.1755, -0.4456, -1.0081,  1.0093, -0.4618, -0.1390,  1.1937, -0.3489,\n                        0.1452, -0.2448,  0.5761,  0.0140,  0.5123,  0.7071,  0.6098, -0.8497,\n                        0.8147, -0.2612, -0.5923,  0.8342, -0.4622,  0.7502, -0.7874, -0.8938,\n                       -0.7084, -0.2418,  0.2589,  0.6574,  0.2392, -0.7615,  0.2805,  1.1874,\n                        0.1917, -0.1168, -0.3732, -0.2446,  0.4777,  1.3737, -0.5828, -0.5661,\n                        0.0072,  0.0321, -0.2910,  0.2639, -0.0461,  0.3618,  0.3201, -0.4467,\n                       -0.5451,  0.7070,  0.8739,  0.3324, -0.6394, -0.3199, -0.1272,  0.7085,\n                       -0.1332, -0.7173,  0.2769,  1.4641,  0.1498, -0.5485,  0.3142, -0.5481,\n                        1.1507,  0.9302, -0.7448, -0.7599,  0.2240, -0.9345, -0.6389, -0.7898,\n                       -0.3874,  0.7526, -0.0353,  1.0058,  1.6473,  0.8488,  0.9291, -0.3114,\n                       -0.5068,  0.5040,  0.1778,  0.5359, -0.1772,  0.3078, -0.0958,  0.2781,\n                        0.4925,  0.7858, -0.2641,  0.3020,  0.5491, -0.4955, -0.4861, -0.6385,\n                        0.6790,  0.6394, -2.0501, -0.6136,  0.2102, -0.1128, -0.4084,  0.6022,\n                       -0.2603,  0.5808, -1.4280,  1.0588,  0.1202,  0.5122,  0.1520,  0.7278,\n                       -0.4101,  0.3949, -0.0357,  0.7106,  0.7288, -0.5313,  0.6167,  0.6787,\n                        0.4071,  0.1315, -0.5215,  0.4190, -0.0263, -0.4808, -0.2101, -0.1544,\n                        0.7971,  0.3449, -0.5058,  0.6094, -0.2818,  0.9889,  1.0366,  0.5472,\n                        1.4818,  0.8167, -0.1725, -0.6336, -0.2627, -0.5447, -0.3937,  0.5923,\n                        0.3008, -0.3568, -0.9532,  0.5562, -0.7334, -0.3126,  0.3051,  0.7955])),\n              ('backbone.models.0.model.layer2.1.bn3.running_mean',\n               tensor([-9.8822e-01,  3.3332e-01,  9.8036e-02, -1.4055e-01,  1.5058e-01,\n                        4.6087e-01, -1.0610e-01, -8.9699e-02, -4.0084e-01, -5.2295e-01,\n                       -1.1082e-01, -5.9156e-01,  6.6411e-01,  1.4650e-01,  1.2756e-01,\n                        5.7061e-01, -1.9010e-01,  4.6920e-01, -7.8404e-01, -2.0357e-01,\n                        1.5711e-01,  2.9030e-01, -2.2359e-01, -3.0121e-01,  2.3254e-01,\n                       -6.4039e-01,  3.6426e-03, -2.1986e-01,  1.9259e-02, -1.1489e-01,\n                       -4.2616e-01,  5.4321e-02, -1.4232e+00,  9.3242e-01, -1.1378e+00,\n                        1.2272e-01, -3.7411e-01, -3.2766e-01,  1.9091e-01,  2.2527e-01,\n                       -6.4094e-01, -1.6805e-01,  3.8002e-01, -8.4420e-01,  1.9317e-01,\n                       -2.1538e-01, -8.6033e-02,  1.7184e-01, -2.7667e-01, -1.1796e-01,\n                        8.7949e-01,  2.4316e-01,  4.8232e-02,  2.5396e-01,  5.4503e-02,\n                        3.1337e-01,  3.3360e-01,  3.4734e-01, -8.0217e-03,  4.6233e-01,\n                       -7.0555e-01, -4.1914e-01,  6.4963e-01, -2.3442e-01,  1.1105e+00,\n                       -2.4438e-01,  7.1327e-01,  2.8651e-01,  2.1798e-01,  2.2707e-01,\n                        4.1316e-01,  4.8387e-01, -5.3420e-01,  3.1298e-01, -5.7543e-01,\n                       -9.1869e-01, -1.0310e-01, -6.1361e-01, -3.1374e-01, -9.3442e-01,\n                        9.6712e-02, -8.0316e-01,  5.6573e-01, -1.5999e-01,  2.4629e-02,\n                       -5.7674e-02,  1.7517e-01, -1.6910e-01, -8.8084e-01,  4.0024e-01,\n                        3.0634e-02, -1.5281e-02, -1.3062e-01,  2.5829e-02, -2.9439e-02,\n                        1.0354e+00,  3.5090e-01,  8.0576e-02, -6.4197e-01,  1.1622e+00,\n                        2.2433e-01, -1.2980e-01, -5.6952e-01,  9.7480e-01,  6.1250e-02,\n                        2.2885e-01,  8.8752e-02, -3.8302e-01,  2.3046e-01,  6.1456e-01,\n                       -6.0457e-01,  1.4372e-02,  1.2511e+00,  1.7521e+00, -2.1526e-01,\n                        4.9318e-01, -1.7648e+00, -2.0534e-01, -5.3510e-02,  1.9192e-01,\n                       -2.5810e-01,  1.4408e+00,  4.2728e-02,  2.8776e-01, -3.8201e-02,\n                        1.9682e-01,  2.5384e-01,  1.0517e+00,  9.5148e-02,  8.8934e-01,\n                       -6.0195e-01, -3.8862e-01,  6.8687e-01, -4.3480e-02,  1.3885e+00,\n                       -2.6499e-01,  6.5546e-02, -1.7657e-01, -5.0269e-01, -5.9293e-02,\n                        1.2077e-02,  1.3667e+00,  1.1100e-01,  9.0062e-02,  3.7942e-01,\n                        2.3973e-01,  2.1700e-01, -1.7602e-01,  1.0050e+00,  7.8530e-01,\n                       -5.1187e-01, -3.9186e-01,  2.9969e-01, -8.9288e-01, -1.1224e-01,\n                       -2.4291e-01,  1.2877e-01,  1.7055e+00, -6.6126e-01, -2.7705e-02,\n                        3.7340e-01,  1.9429e-01,  9.9282e-01, -6.8837e-01, -9.3658e-01,\n                        1.2541e-01, -2.2453e-01,  7.1663e-01,  1.9829e-04, -7.0162e-01,\n                       -4.4705e-01,  1.7781e-01, -6.2630e-01,  1.7555e-01, -9.1607e-01,\n                        8.2286e-01,  3.2115e-01,  8.3791e-01, -4.3582e-01,  2.1572e-01,\n                       -4.5930e-01, -3.9660e-01, -1.6691e-01,  1.0665e-01, -1.8489e-01,\n                        5.9966e-01,  5.2606e-01,  2.8819e-01, -1.2992e+00,  1.9518e+00,\n                       -1.3312e-01, -5.8232e-01, -5.7523e-01,  1.6140e+00,  9.2054e-02,\n                        2.6626e-01,  6.5925e-02, -2.5566e-01, -6.5578e-02,  6.4262e-01,\n                       -2.3580e-01,  2.4887e-01,  4.1590e-01,  1.0540e-01, -1.7807e-01,\n                        2.5049e-01, -9.3995e-03,  1.3634e-01, -1.8094e-01, -8.8987e-02,\n                       -2.6605e-01, -2.2060e-02, -3.3550e-01,  6.6527e-02,  1.4241e-01,\n                        1.4938e-01, -4.3238e-01,  7.6981e-01,  4.4326e-01,  8.1600e-01,\n                        3.4584e-01, -7.8350e-01,  1.1262e+00,  9.1984e-02, -2.5241e-01,\n                        5.7895e-01,  1.9642e-01,  2.3532e-02,  1.9598e-01,  3.6315e-01,\n                        2.9152e-01, -6.9251e-02,  1.1305e-01, -8.6207e-01,  2.3867e-01,\n                        4.5375e-01, -4.3395e-01, -5.3433e-01, -4.5901e-01, -6.4522e-01,\n                        2.1154e-01, -1.2035e+00, -1.2466e-01,  7.0024e-02, -3.1424e-02,\n                        4.2473e-01, -4.9447e-01, -4.8781e-01, -3.0812e-01, -4.9743e-01,\n                       -6.4741e-01, -3.9379e-01, -3.7725e-01,  3.2616e-01, -2.7818e-01,\n                       -4.4023e-01, -3.7623e-01,  2.2872e-01, -1.2541e-01,  5.8420e-01,\n                       -4.9172e-01, -1.6000e-02,  3.3891e-01, -1.8382e-01,  6.5842e-02,\n                        7.0062e-02,  9.4255e-04,  1.8336e-01, -2.1257e-01,  1.0949e-01,\n                       -1.8721e-01, -2.2431e-01, -6.2075e-01,  8.5558e-02,  5.5073e-01,\n                        8.9355e-02,  4.1560e-01, -1.5228e-01, -1.8482e-01,  1.4163e-01,\n                       -3.7116e-02,  2.8539e-01,  2.4015e-01,  2.7297e-01, -4.5023e-02,\n                        4.1524e-01,  2.0745e-01,  2.6421e-01,  3.4360e-01, -6.4887e-01,\n                       -3.2114e-01,  2.6770e-01,  1.0712e+00, -3.6195e-01, -3.3086e-01,\n                       -1.5779e-01, -1.1009e-01, -3.8932e-01,  2.8520e-01, -5.1676e-01,\n                        2.3250e-01, -1.2842e-01, -2.1787e-01,  2.6852e-01,  3.1123e-01,\n                        3.0416e-01,  1.3186e+00, -3.0687e-01,  2.9254e-02, -2.1711e-01,\n                       -6.7605e-01, -6.9414e-01,  8.5878e-01, -4.1504e-01, -2.0471e-01,\n                       -1.3603e-01, -6.5261e-01,  8.5299e-02, -2.5178e-01,  1.4096e-01,\n                       -6.1074e-01, -1.5311e-01, -2.2858e-01,  2.6627e-01,  1.3871e-01,\n                        5.6506e-01, -2.9852e-01, -4.8581e-01,  1.5204e-01, -1.4008e-01,\n                        1.5409e-01, -2.8938e-02, -8.3041e-02,  6.0156e-01, -1.0733e+00,\n                       -3.9375e-01,  2.2935e-01, -4.7523e-01,  4.8951e-01, -9.8807e-02,\n                        6.6024e-01,  4.2428e-02,  3.0831e-01,  1.9961e-01, -4.0849e-01,\n                       -1.9570e-01, -4.1427e-01, -6.7448e-01,  2.8849e-01, -3.2525e-01,\n                        3.6438e-01,  1.0476e+00, -8.7438e-01, -4.7373e-01, -2.1996e-01,\n                       -2.3846e-01, -2.2551e-01,  9.7189e-01, -2.4293e-01,  4.5945e-01,\n                       -4.6536e-01,  1.9220e-01, -1.3576e-01, -2.5368e-01, -2.1088e-01,\n                       -8.8129e-01, -8.1800e-02, -6.9471e-01,  3.9786e-01,  3.0211e-01,\n                        2.8773e-01, -2.9939e-02,  5.9245e-02, -2.3547e-01, -6.2884e-02,\n                       -2.7964e-01,  2.1360e-01, -4.7314e-01, -2.7863e-02, -8.9287e-02,\n                        2.7152e-01, -1.6005e-02, -4.8431e-02,  4.5591e-01,  1.9112e-01,\n                        6.6707e-02, -8.2073e-02, -7.9990e-02,  5.4153e-01,  1.1499e-01,\n                       -2.1743e-01,  3.6644e-01, -1.9448e-01,  9.0491e-01,  4.5627e-01,\n                        7.3356e-01,  7.0498e-02,  6.3551e-01,  5.6353e-02, -2.4256e-01,\n                       -2.5684e-02, -2.6095e-01, -6.3020e-01, -4.0732e-03,  1.4100e-01,\n                        5.6240e-02,  1.8907e-01, -7.5718e-01, -4.7258e-01, -6.4459e-01,\n                        1.5388e-01, -3.1984e-01, -1.5854e-01,  6.4473e-02, -3.7112e-01,\n                       -2.2011e-01,  1.0640e-01,  3.9656e-01,  2.2223e-01,  2.4483e-01,\n                       -5.7717e-02, -1.7265e-03,  1.5227e-01, -2.6740e-01,  5.2794e-02,\n                       -1.4356e-01, -2.2154e-01,  9.6597e-01,  3.9168e-01, -1.5386e-01,\n                       -7.2155e-02,  1.2165e-01,  2.7091e-01,  8.3962e-02, -1.8065e-01,\n                       -1.2654e-01,  8.7639e-01,  3.6331e-01,  6.2810e-02, -2.3274e-01,\n                        1.7988e-01, -1.3279e-01, -1.9895e-01, -2.4899e-02, -1.2451e-01,\n                        6.7379e-01, -5.4090e-01, -1.4000e-01, -1.0393e-02,  2.9721e-01,\n                       -2.6333e-01, -2.1468e-01,  4.7315e-02,  4.1589e-01, -7.7358e-01,\n                       -3.8778e-01,  2.4513e-01,  5.2953e-01, -6.9887e-01,  5.0336e-01,\n                       -1.5636e-01,  1.9726e-01, -3.6281e-01,  1.4089e-01,  5.3636e-01,\n                       -1.1784e-02,  2.4717e-02, -8.8087e-01, -1.9547e-01,  1.2838e-01,\n                        5.2304e-02, -1.2921e-01,  1.5647e-01, -8.7037e-02, -4.3671e-01,\n                        5.9529e-02,  3.3617e-01, -3.5865e-01,  1.3892e-01, -1.2127e+00,\n                        1.5696e-01, -1.5220e-02, -7.2717e-01,  1.8604e-01, -2.2459e-01,\n                       -6.3129e-02,  4.5756e-01, -5.9193e-01, -3.2977e-01, -1.2696e-01,\n                        7.3312e-01,  3.3008e-02, -6.1756e-02, -2.2665e-01, -6.3293e-01,\n                       -1.4443e-01, -2.5443e+00, -2.7029e-01, -4.1186e-01,  3.6758e-02,\n                       -5.3293e-02,  2.4334e-01,  4.2941e-01,  2.9590e-01,  4.8185e-01,\n                       -6.1731e-02, -2.3174e-02,  1.4936e-02, -6.5532e-01,  1.8711e-01,\n                       -5.5162e-03, -4.3371e-01])),\n              ('backbone.models.0.model.layer2.1.bn3.running_var',\n               tensor([4.7356e-01, 2.0311e-01, 4.9103e-02, 2.7369e-01, 5.9131e-02, 1.3524e-01,\n                       2.5954e-01, 2.3535e-01, 1.0933e-01, 1.5462e-01, 7.4305e-02, 1.3517e-01,\n                       3.9979e-01, 1.3036e-01, 1.3485e-01, 1.8095e-01, 1.1186e-01, 6.5382e-02,\n                       1.5864e-01, 4.3359e-01, 1.9304e-01, 2.5064e-01, 1.3481e-01, 1.9889e-01,\n                       3.2614e-01, 2.9706e-01, 1.8788e-02, 3.3454e-01, 1.5741e-01, 1.4974e-01,\n                       1.8746e-01, 8.6494e-02, 5.7980e-01, 3.7535e-01, 3.9645e-01, 1.3293e-01,\n                       1.4176e-01, 2.4793e-01, 1.5725e-01, 2.4969e-01, 1.5885e-01, 1.5381e-01,\n                       2.5982e-01, 8.4539e-01, 7.5830e-02, 1.8814e-01, 6.2883e-02, 1.8841e-01,\n                       2.1141e-01, 6.0395e-02, 8.5358e-02, 1.7465e-01, 4.1621e-01, 1.1829e-01,\n                       1.7409e-02, 2.4817e-01, 1.2143e-01, 1.0841e-01, 1.6206e-01, 1.7002e-01,\n                       2.0892e-01, 4.0451e-01, 1.6759e-01, 1.2786e-01, 2.1676e-01, 1.2520e-01,\n                       1.8453e-01, 2.6429e-01, 1.0364e-01, 1.5377e-01, 1.5783e-01, 2.8206e-01,\n                       3.5353e-01, 9.2142e-02, 7.3176e-02, 8.4788e-01, 9.8248e-02, 1.2246e-01,\n                       2.8314e-01, 3.1310e-01, 1.7005e-01, 1.3906e-01, 1.1609e-01, 1.3162e-01,\n                       9.9940e-02, 3.4609e-03, 1.0110e-01, 1.0916e-01, 8.4837e-02, 1.7819e-01,\n                       1.9252e-01, 1.4195e-01, 1.0555e-01, 1.2751e-01, 3.8262e-01, 3.1961e-01,\n                       3.4993e-01, 4.3629e-02, 1.9035e-01, 2.2281e-01, 1.1593e-01, 8.9643e-02,\n                       1.5936e-01, 1.4439e-01, 1.6601e-01, 8.5927e-02, 1.1072e-01, 2.8679e-01,\n                       1.7157e-01, 5.1795e-01, 1.7423e-01, 2.1908e-01, 7.7586e-01, 3.5019e-01,\n                       2.2153e-01, 3.3956e-01, 5.4619e-01, 3.2179e-01, 3.0691e-02, 1.5260e-01,\n                       2.0715e-01, 2.3158e-01, 6.5352e-02, 9.3873e-02, 9.2875e-01, 7.4857e-02,\n                       7.2772e-02, 4.1623e-01, 1.1193e-01, 1.5901e-01, 1.0248e-01, 4.3752e-01,\n                       2.7894e-01, 1.9245e-01, 4.6314e-01, 1.0892e-01, 2.8579e-01, 9.0635e-02,\n                       1.7093e-01, 3.1405e-01, 1.9981e-01, 1.7547e-01, 1.8321e-01, 1.5887e-01,\n                       4.3353e-01, 3.8635e-01, 1.4200e-01, 1.1670e-01, 6.2798e+00, 1.7255e-01,\n                       4.9545e-01, 1.4572e-01, 1.5796e-01, 1.9317e-01, 6.0991e-02, 3.1471e-01,\n                       3.1240e-01, 4.1890e-01, 1.3523e-01, 1.4255e-01, 1.2125e-01, 1.4583e-01,\n                       2.2492e-01, 1.5618e-01, 3.9223e-01, 1.0320e-01, 6.5384e-01, 1.5778e-01,\n                       3.2777e-02, 2.5748e-01, 1.4315e-01, 1.7919e-01, 1.6978e-01, 5.9819e-02,\n                       1.7923e-01, 3.1787e-01, 3.0550e-01, 2.3029e-01, 2.4008e-01, 7.2868e-02,\n                       1.1231e-01, 1.3851e-01, 1.8425e-01, 3.1295e-01, 1.8219e-01, 1.1096e-01,\n                       1.5846e-01, 9.4396e-02, 6.4826e-01, 2.8791e+00, 1.9010e-01, 1.1333e-01,\n                       4.1859e-01, 2.1417e-01, 6.5099e-02, 2.3846e-01, 9.8573e-02, 1.3047e-01,\n                       2.2799e-01, 2.0141e-01, 1.2734e-01, 1.3514e-01, 2.2880e-01, 1.9845e-01,\n                       2.9845e-01, 4.0289e-02, 2.9067e-01, 1.8425e-01, 9.4152e-02, 6.0141e-02,\n                       8.7057e-02, 9.7048e-02, 1.8555e-01, 1.1375e-01, 1.0798e-01, 1.6149e-01,\n                       9.8063e-02, 9.2820e-02, 1.8540e-01, 7.6688e-02, 1.1396e-01, 7.9957e-02,\n                       3.3691e-01, 1.1571e+00, 7.5653e-01, 8.5708e-02, 6.7678e-02, 9.2113e-02,\n                       3.1645e-01, 5.2100e-01, 4.1249e-01, 2.5649e-01, 1.2618e-01, 3.1156e-01,\n                       1.5432e-01, 1.8999e-01, 8.3869e-02, 2.5012e-01, 2.4263e-01, 2.5111e-01,\n                       2.3174e-01, 2.3103e-01, 1.3957e-01, 4.1037e-01, 2.0485e-01, 2.2113e-01,\n                       7.6885e-02, 1.4418e-01, 1.0305e-01, 3.9544e-01, 1.5072e-01, 1.7287e-01,\n                       4.5333e-01, 6.2780e-02, 4.3035e-01, 1.5524e-01, 8.7508e-02, 1.1834e-01,\n                       1.4811e-01, 1.1354e-01, 1.1488e-01, 2.2670e-02, 8.7108e-02, 1.1962e-01,\n                       6.2023e-02, 8.5549e-02, 2.9061e-02, 4.0497e-01, 1.6940e-01, 1.5486e-01,\n                       1.2883e-01, 3.1030e-01, 1.7114e-01, 3.8170e-01, 4.3822e-01, 5.8748e-01,\n                       1.9163e-01, 2.1437e-01, 1.8993e-01, 2.7667e-01, 2.8339e-01, 1.3587e-01,\n                       1.9434e-01, 1.8304e-01, 2.7044e-01, 2.2216e-01, 3.3986e-01, 7.9106e-02,\n                       4.0532e-01, 2.7743e-01, 2.9494e-01, 1.3489e-01, 2.2834e-01, 1.2743e-01,\n                       6.6765e-02, 1.6944e-01, 6.5819e-02, 1.4715e-01, 4.1462e+00, 1.9835e-01,\n                       2.6003e-01, 2.8069e-01, 4.1412e-01, 1.5415e-01, 2.3163e-01, 2.1633e-02,\n                       1.8394e-01, 1.1678e-01, 8.1324e-02, 1.2549e-01, 1.5870e-01, 8.6974e-01,\n                       2.4389e-01, 3.0883e-01, 1.5603e-01, 4.5016e-02, 9.4553e-02, 1.8315e-01,\n                       1.0834e-01, 2.1469e-01, 1.6582e-01, 3.1241e-02, 4.5809e-02, 1.3839e-01,\n                       1.6316e-01, 3.0925e-01, 1.7148e-01, 2.8030e-01, 3.4831e-01, 3.7445e-02,\n                       6.9798e-02, 2.3773e-01, 1.6707e-01, 1.9102e-01, 1.7426e-01, 6.8718e-01,\n                       9.2813e-02, 1.1763e-01, 2.0468e-01, 2.0902e-01, 8.7427e-02, 4.6673e-02,\n                       1.0205e-01, 2.0558e-01, 1.3000e-01, 4.0407e-01, 1.9547e-01, 3.5933e-01,\n                       2.3677e-01, 2.0646e-01, 1.1453e+00, 1.5089e-01, 1.3487e-01, 1.7692e-01,\n                       1.7823e-01, 3.2354e-01, 1.4407e-01, 2.5138e-01, 3.9326e-01, 9.2802e-02,\n                       1.4997e+00, 1.1653e-01, 2.8558e-01, 9.0201e-02, 9.9688e-02, 1.4481e-01,\n                       7.6077e-02, 1.0499e-01, 1.7970e-01, 2.2110e-01, 2.7404e-01, 1.2524e-01,\n                       1.6352e-02, 7.5487e-01, 8.0538e-02, 1.5923e-01, 2.2843e-01, 6.7694e-02,\n                       2.1409e-01, 1.4059e-01, 1.0426e-01, 1.2769e+00, 2.1934e-01, 2.8411e-01,\n                       2.0626e-01, 3.5652e-01, 1.7083e-01, 9.8233e-02, 3.0399e-01, 1.4608e-01,\n                       7.6043e-01, 3.9065e-01, 3.8507e-01, 2.4944e-01, 6.0076e-01, 1.6311e-01,\n                       2.7646e+00, 3.2805e-01, 2.1193e-01, 3.1103e-01, 1.1812e-01, 1.4767e-01,\n                       2.1010e-01, 6.4924e-01, 9.7338e-02, 9.9028e-02, 2.7863e-01, 2.2436e-01,\n                       1.2292e-01, 1.0984e-01, 1.2296e-01, 2.4291e-01, 1.9137e-01, 1.3841e-01,\n                       2.9800e-01, 1.4652e-01, 1.2306e-01, 1.0720e-01, 5.7974e-02, 2.5451e-01,\n                       2.2174e-02, 2.4492e-01, 5.7526e-02, 1.1213e-01, 1.9981e-01, 1.5480e-01,\n                       2.2031e-01, 3.1811e-01, 2.4525e-01, 6.3476e-01, 1.4354e-01, 1.3891e-01,\n                       3.4349e-01, 3.6361e-02, 5.9091e-02, 1.3935e-01, 3.7176e-01, 1.0041e-01,\n                       2.6076e-01, 1.9085e-01, 2.2559e-01, 4.8474e-02, 2.6477e-01, 1.0152e-01,\n                       2.4875e-01, 3.2964e-01, 1.0683e-01, 1.6049e-01, 1.5496e-01, 2.4514e-01,\n                       1.7154e-01, 1.5295e-01, 2.3261e-01, 2.2003e-01, 2.0066e-01, 1.1127e-01,\n                       5.7265e-02, 1.9187e-01, 1.1069e-01, 1.5044e-01, 8.3553e-02, 1.1368e-01,\n                       2.0737e-01, 1.8647e-01, 2.1515e-01, 2.0371e-01, 1.6612e-01, 2.3396e-01,\n                       1.0576e-01, 1.5722e-02, 2.4066e-01, 1.2655e-01, 2.8764e-01, 3.3521e-01,\n                       2.6702e-01, 6.7688e-02, 2.5347e-01, 1.0633e-01, 1.2604e-01, 6.5666e-01,\n                       1.0971e-01, 7.6464e-01, 2.3428e-01, 8.4636e-02, 2.5751e-01, 1.1939e-01,\n                       1.1104e-01, 5.6899e-02, 3.0980e-01, 4.3730e-02, 2.6263e-01, 2.7597e-01,\n                       5.9266e-02, 1.9420e-01, 3.4757e-01, 9.0961e-02, 5.8966e-01, 1.4678e-01,\n                       1.8337e-01, 1.1901e-01, 8.2621e-02, 1.0832e-01, 1.8953e-01, 1.7720e-01,\n                       7.1596e-02, 1.1505e-01, 2.6355e-01, 3.7412e-02, 4.7469e-01, 1.1750e-01,\n                       4.1160e-02, 2.3847e-01])),\n              ('backbone.models.0.model.layer2.1.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.2.conv1.weight',\n               tensor([[[[-0.1271]],\n               \n                        [[-0.0893]],\n               \n                        [[ 0.1010]],\n               \n                        ...,\n               \n                        [[ 0.1148]],\n               \n                        [[ 0.0279]],\n               \n                        [[ 0.2487]]],\n               \n               \n                       [[[-0.1409]],\n               \n                        [[-0.1009]],\n               \n                        [[-0.0027]],\n               \n                        ...,\n               \n                        [[-0.0048]],\n               \n                        [[ 0.0682]],\n               \n                        [[ 0.0153]]],\n               \n               \n                       [[[-0.0052]],\n               \n                        [[ 0.0170]],\n               \n                        [[-0.0759]],\n               \n                        ...,\n               \n                        [[ 0.0346]],\n               \n                        [[ 0.0049]],\n               \n                        [[-0.0510]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0584]],\n               \n                        [[-0.0900]],\n               \n                        [[ 0.0868]],\n               \n                        ...,\n               \n                        [[-0.0302]],\n               \n                        [[ 0.0621]],\n               \n                        [[-0.1150]]],\n               \n               \n                       [[[-0.0251]],\n               \n                        [[-0.1154]],\n               \n                        [[ 0.0190]],\n               \n                        ...,\n               \n                        [[ 0.0744]],\n               \n                        [[ 0.0065]],\n               \n                        [[ 0.0291]]],\n               \n               \n                       [[[ 0.1074]],\n               \n                        [[ 0.0088]],\n               \n                        [[-0.1127]],\n               \n                        ...,\n               \n                        [[ 0.0427]],\n               \n                        [[-0.0505]],\n               \n                        [[ 0.0123]]]])),\n              ('backbone.models.0.model.layer2.2.bn1.weight',\n               tensor([0.8793, 1.0527, 1.1082, 0.9035, 0.9968, 0.9700, 0.9784, 0.8634, 1.0482,\n                       1.4611, 1.1326, 0.9986, 1.2972, 0.8984, 0.9333, 1.4483, 1.2598, 0.8123,\n                       1.1311, 0.7625, 1.6245, 0.6902, 1.0329, 0.7617, 0.9584, 0.9836, 1.1163,\n                       0.9225, 0.8079, 0.7920, 1.4860, 0.7039, 1.0777, 1.1786, 0.7605, 0.9105,\n                       0.7985, 1.0286, 0.8422, 1.0318, 0.9819, 0.8507, 0.9655, 0.7152, 0.9813,\n                       0.9602, 0.8056, 0.7423, 0.8949, 1.0254, 0.9549, 0.7805, 0.9397, 0.8633,\n                       0.9854, 0.9974, 1.1145, 0.9696, 1.3321, 0.8874, 0.8977, 1.0857, 0.6608,\n                       1.0944, 1.2433, 0.6809, 0.8387, 0.7447, 0.9310, 0.8327, 0.6999, 0.9545,\n                       0.8976, 0.7349, 0.9196, 0.8539, 0.9556, 0.8594, 1.9843, 0.7805, 1.1857,\n                       2.5353, 0.9836, 0.9792, 0.8909, 0.8173, 1.1461, 1.0406, 1.0451, 0.7781,\n                       1.0909, 0.9155, 0.9877, 0.9270, 1.0349, 1.0604, 0.6757, 1.0133, 0.8006,\n                       0.8521, 0.9705, 0.9143, 1.1351, 0.8936, 0.9896, 1.0178, 1.0579, 0.8714,\n                       0.9756, 1.0312, 0.8053, 1.3473, 0.8705, 0.8472, 0.7924, 1.0682, 0.8167,\n                       0.9324, 1.1422, 0.9203, 1.1914, 0.9221, 0.8932, 1.3599, 1.1146, 0.8963,\n                       1.1754, 1.0179])),\n              ('backbone.models.0.model.layer2.2.bn1.bias',\n               tensor([ 1.2061e-01, -7.1263e-01, -1.1510e+00, -2.3463e-01, -7.0566e-01,\n                       -5.6280e-01, -3.4604e-01, -3.2938e-02, -2.6883e-02, -1.8684e+00,\n                       -1.5441e+00, -7.8468e-01, -1.4044e+00, -5.6515e-01, -3.2944e-01,\n                       -1.0839e+00, -9.0042e-01,  2.3702e-01, -1.2974e+00,  2.1307e-01,\n                       -3.4730e-01,  3.0704e-01, -6.3659e-01,  7.9043e-02, -3.2783e-02,\n                       -2.2107e-01, -7.8127e-01, -1.3178e+00, -8.0802e-02,  5.6079e-02,\n                       -1.3217e+00,  4.3871e-01, -5.3549e-01, -1.2265e+00,  1.3889e-01,\n                       -5.5120e-01, -1.7201e-01, -4.5424e-01, -3.4587e-01, -1.6618e+00,\n                       -4.5020e-01,  3.9281e-02, -5.3243e-01,  2.2505e-01, -3.9596e-01,\n                       -3.0982e-01, -1.2238e-01,  1.2044e-01, -3.7658e-01, -4.3602e-01,\n                       -8.5578e-03, -2.6896e-02, -2.5303e-01, -6.7673e-01, -2.8108e-01,\n                       -4.9878e-01, -1.5932e-01, -1.8029e-01, -1.6018e+00, -4.7365e-01,\n                       -1.0364e-01, -6.5172e-01,  3.4032e-01, -6.2122e-01, -9.7454e-01,\n                        7.9064e-02, -1.7454e-01,  4.1642e-02, -8.4660e-02, -1.9920e-01,\n                        1.3487e-01, -2.9309e-01, -2.3002e-01,  2.8179e-02, -6.2777e-01,\n                        6.3814e-02, -2.6143e-01, -1.9663e-01, -1.1802e+00, -4.4203e-05,\n                       -7.7775e-01, -1.7954e+00, -4.2982e-01, -2.6287e-01, -9.6287e-02,\n                        7.5311e-02, -2.0686e-01, -6.8834e-01, -6.1266e-01,  4.9184e-02,\n                       -7.8292e-01, -6.3656e-01, -8.4873e-01, -7.5216e-01, -4.4855e-01,\n                       -7.6860e-01, -2.1851e-02, -4.7380e-01, -8.1221e-02,  1.7685e-01,\n                       -5.3983e-01,  8.8651e-02, -6.2018e-01, -1.2160e-01, -2.2353e-01,\n                       -6.0003e-01, -7.2403e-01,  3.2039e-03, -4.1050e-01, -1.0337e+00,\n                       -1.9546e-01, -9.3407e-01, -2.0221e-02,  1.1952e-01, -1.3145e-01,\n                       -5.6827e-01, -1.3004e-01, -1.4142e-01, -1.2298e+00, -1.7317e-01,\n                       -9.6823e-01, -4.8224e-01, -1.5622e-01, -1.0545e+00, -7.9184e-01,\n                       -1.4960e-01, -5.2975e-01, -8.2894e-01])),\n              ('backbone.models.0.model.layer2.2.bn1.running_mean',\n               tensor([ 1.8671e+00,  2.9360e+00, -6.5855e-01, -2.7233e+00, -8.6498e-01,\n                       -1.3891e+00, -4.0539e-01, -8.3981e-01, -3.0110e+00, -2.3717e+00,\n                       -1.7356e+00,  1.3845e+00, -3.3562e+00,  1.7998e+00, -2.9859e+00,\n                       -2.0576e+00, -2.7231e+00, -1.8564e+00, -1.9422e+00, -8.6435e-01,\n                       -2.4473e+00,  1.2567e+00, -2.6206e+00, -9.8207e-01, -1.6005e+00,\n                       -4.5664e-01, -9.2680e-01, -3.1206e+00,  3.8964e-01,  2.7707e-02,\n                       -1.0566e-01,  8.0099e-01, -3.4316e+00, -4.1675e-01, -2.9668e+00,\n                       -1.8343e+00, -2.5739e+00, -4.3110e+00, -2.2282e+00, -3.8283e+00,\n                       -2.4407e+00, -1.8025e+00, -4.0547e+00,  2.0815e+00, -3.1684e+00,\n                       -3.2131e+00, -1.8035e-01,  4.7075e-03, -1.0692e+00, -2.0142e+00,\n                       -2.4065e+00, -1.0923e+00, -1.6567e+00,  5.1960e-01, -2.8091e+00,\n                       -5.8207e+00, -2.8806e+00, -1.7332e+00, -1.9928e+00, -3.4547e-01,\n                       -1.5015e+00, -3.9653e+00,  1.0843e+00, -1.8060e+00, -2.2653e+00,\n                        1.1173e+00, -2.6175e+00,  1.9487e-01, -2.3637e+00, -1.9363e+00,\n                       -3.0860e+00, -2.8121e+00, -3.8883e+00, -3.3231e-01,  3.0060e+00,\n                       -9.8428e-01, -1.7304e+00,  2.8768e-02, -3.4011e+00,  4.5019e-01,\n                       -3.4376e+00, -4.9944e+00, -8.0954e-02,  1.0832e+00, -2.1377e+00,\n                       -8.9183e-01, -4.1512e-01, -3.2104e+00, -1.9835e+00, -9.4287e-01,\n                       -3.0897e+00, -2.5047e+00, -8.4065e-01, -2.2876e+00, -3.6723e+00,\n                       -2.5106e+00, -2.3175e+00, -3.4695e+00, -1.1573e+00, -7.1393e-01,\n                        1.6240e+00, -3.2339e+00,  8.6041e-02,  4.4356e-01, -4.5452e-01,\n                        6.6279e-01, -3.1405e+00, -2.6737e-02, -2.9109e+00, -3.9378e+00,\n                       -5.8641e+00, -4.1622e+00,  8.5449e-01,  1.0423e+00, -4.7447e-01,\n                        2.3693e-01, -7.6744e-01, -5.6388e-01, -3.3020e+00,  1.5275e-01,\n                       -2.3386e+00, -1.5019e+00, -5.5883e+00, -2.1443e+00, -5.6957e-02,\n                       -1.9339e+00, -3.4155e+00, -3.0125e+00])),\n              ('backbone.models.0.model.layer2.2.bn1.running_var',\n               tensor([ 9.7765,  4.6124,  3.4542,  6.6914,  4.4034,  4.6339,  6.9835, 10.6465,\n                        9.6384,  1.8345,  2.8126,  6.2904,  4.2157,  5.0267,  5.6033,  7.7755,\n                        9.2015, 10.1722,  7.5348,  9.4413, 20.2898,  9.8449,  4.7451,  6.7376,\n                       11.1276, 10.6189,  4.6048,  2.3208,  6.6516,  7.2749,  9.9430, 10.0680,\n                        7.7232,  3.5425,  7.5345,  3.9720,  5.5605,  7.2193,  5.3688,  1.6854,\n                        5.5374,  6.9640,  5.3475, 10.4477,  6.2996,  9.7273,  8.8025,  6.9294,\n                        3.9586,  9.0336, 11.4494,  7.8292,  8.0182,  7.4432,  8.4010,  7.0024,\n                        6.6105, 10.2572,  3.3156,  4.2092,  8.5900,  6.3891,  6.6493,  4.7855,\n                        6.3356,  8.3591,  6.7656,  6.8844,  8.2549,  5.3482,  6.3680,  8.0224,\n                        7.1317,  6.5007,  4.2213,  8.9368,  7.6604,  4.5356, 18.0510,  5.1282,\n                       42.2234, 41.8349,  2.4710,  7.4824,  6.1634,  9.9351, 10.4521,  4.3745,\n                        4.4958,  8.1204,  6.1116,  4.2428,  3.2644,  3.6395,  7.1154,  3.9615,\n                        7.2759,  6.4279,  9.7450,  7.8146,  6.1718, 11.6535,  6.7520,  9.3484,\n                        9.5171,  6.4060,  4.7030,  7.7491,  7.7395,  3.5375,  5.3631,  8.2983,\n                        8.8498, 14.2398,  6.5252,  9.0638,  5.4415, 10.1135,  2.5689,  7.2491,\n                        5.8492,  3.8657,  7.8692,  5.7998, 11.8158,  8.6016, 10.3272,  4.4407])),\n              ('backbone.models.0.model.layer2.2.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.2.conv2.weight',\n               tensor([[[[-5.8525e-04,  4.3207e-02, -4.9041e-02],\n                         [ 2.8368e-02,  4.8887e-02, -9.4899e-03],\n                         [ 4.1325e-02,  1.8127e-03, -8.1993e-03]],\n               \n                        [[ 5.7864e-04, -3.1763e-03, -2.0381e-02],\n                         [-2.4245e-02, -1.4600e-02, -1.1295e-02],\n                         [-1.4688e-02, -6.7387e-03, -2.9299e-02]],\n               \n                        [[ 4.4042e-03, -7.2156e-03, -1.6402e-02],\n                         [-2.0992e-02, -2.1965e-02, -2.4421e-02],\n                         [ 4.4006e-02, -1.1817e-02, -3.3215e-02]],\n               \n                        ...,\n               \n                        [[ 1.8376e-02,  1.7709e-02, -2.1639e-02],\n                         [ 3.3947e-02,  3.9461e-02,  4.4808e-02],\n                         [-2.3019e-02, -3.4767e-02,  5.2407e-02]],\n               \n                        [[-4.9169e-02, -5.5081e-02,  2.4343e-02],\n                         [-2.8712e-01, -7.0949e-02,  1.6044e-01],\n                         [-1.2025e-01,  2.3022e-02,  1.6663e-02]],\n               \n                        [[ 4.2863e-02, -2.6235e-03, -5.0522e-02],\n                         [ 2.0458e-02,  5.1796e-02,  1.8753e-02],\n                         [ 3.6977e-02,  8.7290e-03, -1.6130e-02]]],\n               \n               \n                       [[[-7.8020e-02, -3.9861e-02,  3.5820e-03],\n                         [-1.0052e-01,  1.1476e-01, -3.0766e-02],\n                         [-2.9908e-02, -2.8522e-02, -2.2006e-02]],\n               \n                        [[-4.7866e-02, -1.0732e-01, -6.3381e-02],\n                         [ 1.0017e-02,  5.5154e-03,  1.0714e-02],\n                         [-3.3231e-02,  4.1162e-02, -4.0135e-02]],\n               \n                        [[ 4.4732e-03, -2.4590e-03, -4.4036e-02],\n                         [-2.8926e-02, -1.2075e-01, -3.2089e-02],\n                         [ 2.6869e-04, -5.7832e-02, -1.2875e-02]],\n               \n                        ...,\n               \n                        [[-4.8946e-02, -2.0397e-02, -4.0749e-02],\n                         [ 7.2421e-02, -2.9393e-02,  2.4670e-03],\n                         [ 1.1051e-01,  1.5695e-01,  1.0683e-01]],\n               \n                        [[-3.2237e-02, -2.8522e-02, -1.8897e-02],\n                         [ 5.9103e-02, -8.6380e-02, -2.9102e-02],\n                         [ 1.2098e-02,  1.8270e-02, -1.6531e-02]],\n               \n                        [[ 9.1769e-03, -3.4043e-02,  3.4154e-03],\n                         [ 7.5061e-03,  9.5312e-03, -4.4012e-03],\n                         [ 2.7853e-02,  9.3263e-02, -7.6300e-03]]],\n               \n               \n                       [[[-3.4390e-02, -6.8105e-02, -2.5362e-02],\n                         [-1.2684e-01,  1.8586e-01, -8.7795e-02],\n                         [-1.4559e-01,  2.1313e-02,  8.5957e-02]],\n               \n                        [[-5.3593e-02, -5.9945e-02, -9.5680e-03],\n                         [-7.6564e-02, -1.4138e-01, -1.5978e-02],\n                         [-7.3037e-02, -4.4950e-02, -6.0640e-02]],\n               \n                        [[-5.1143e-02, -8.6749e-02, -3.8031e-02],\n                         [ 2.0781e-02,  2.2290e-02, -1.9546e-02],\n                         [-1.6016e-02, -2.3071e-02,  6.7072e-03]],\n               \n                        ...,\n               \n                        [[-8.4465e-03, -6.6635e-02, -6.0058e-03],\n                         [ 2.9505e-02,  3.9089e-02,  7.2333e-02],\n                         [ 3.9026e-03,  1.5796e-02, -1.7653e-03]],\n               \n                        [[ 6.5596e-02,  1.1119e-01,  8.9181e-02],\n                         [-5.5812e-03,  3.5411e-02,  4.4675e-02],\n                         [-2.6016e-02, -8.6252e-02, -5.7731e-03]],\n               \n                        [[ 2.8082e-02,  4.9603e-02,  6.4999e-02],\n                         [ 3.7213e-02,  4.9191e-02,  2.8333e-02],\n                         [ 1.8723e-02,  6.4000e-02,  4.3726e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 1.3676e-02, -1.6121e-01,  2.9470e-02],\n                         [ 4.7100e-02, -1.6516e-01,  5.9945e-02],\n                         [-2.4161e-02, -3.9597e-02, -5.0063e-03]],\n               \n                        [[ 4.3597e-02,  6.5643e-03,  2.3426e-02],\n                         [ 3.5615e-03,  2.7647e-02, -2.8733e-02],\n                         [ 4.3382e-02,  2.2256e-02, -5.3708e-02]],\n               \n                        [[ 6.3750e-02,  9.8542e-02,  1.7527e-02],\n                         [ 2.1784e-03, -1.2181e-02, -5.1481e-02],\n                         [-2.4177e-02, -1.0965e-01, -2.9985e-02]],\n               \n                        ...,\n               \n                        [[-8.1494e-02, -1.0090e-02,  8.1745e-02],\n                         [ 4.7323e-03, -2.8796e-02,  2.1318e-01],\n                         [ 4.2170e-02,  3.2351e-02,  3.8143e-02]],\n               \n                        [[-5.0831e-03,  9.8987e-03,  3.9001e-02],\n                         [-1.3870e-01,  1.7747e-02,  8.8000e-03],\n                         [-2.6630e-02,  8.6560e-03,  4.2035e-02]],\n               \n                        [[ 1.3529e-03,  1.5835e-02,  4.7327e-03],\n                         [-6.7172e-03,  6.8620e-03,  6.1073e-02],\n                         [-2.5740e-02,  5.3691e-03,  4.9251e-02]]],\n               \n               \n                       [[[-2.2742e-02,  5.0848e-03, -5.8924e-02],\n                         [ 1.9528e-01, -7.8641e-03, -2.2290e-01],\n                         [ 1.3258e-01,  8.2544e-03, -8.0442e-02]],\n               \n                        [[-3.7884e-02, -5.3682e-02, -3.1055e-02],\n                         [-2.0822e-02, -1.4132e-02,  3.0653e-02],\n                         [ 1.0684e-02, -3.8599e-02, -4.8153e-02]],\n               \n                        [[ 3.0637e-02, -2.2950e-02,  1.9361e-02],\n                         [-7.8801e-02, -2.3370e-01, -1.1989e-01],\n                         [ 7.7075e-03,  4.8211e-02,  1.6003e-02]],\n               \n                        ...,\n               \n                        [[-8.1421e-03, -2.1067e-02, -2.6764e-03],\n                         [ 1.5455e-02,  2.9291e-02,  6.5769e-02],\n                         [ 4.9829e-03, -1.9495e-02,  1.0862e-02]],\n               \n                        [[-3.5431e-02,  3.1021e-04, -3.6471e-02],\n                         [ 2.7178e-02, -9.7143e-02, -4.0666e-02],\n                         [ 6.2449e-03, -6.3176e-02,  2.7177e-02]],\n               \n                        [[-3.6023e-02,  4.1318e-02, -9.4386e-03],\n                         [ 7.1683e-02,  2.3349e-01,  9.2831e-02],\n                         [ 5.0505e-02,  2.7646e-01,  3.3455e-02]]],\n               \n               \n                       [[[ 1.4306e-02,  5.8825e-02,  4.9441e-02],\n                         [ 4.5964e-02,  1.2504e-01,  4.0041e-02],\n                         [-5.2099e-03, -1.9293e-02,  8.9409e-03]],\n               \n                        [[-1.7712e-03,  5.1106e-02,  3.4767e-02],\n                         [ 1.2302e-02,  2.5266e-02, -6.6524e-02],\n                         [ 3.8052e-02,  4.2364e-02, -4.3068e-03]],\n               \n                        [[-6.2581e-03,  2.9593e-02, -4.9220e-03],\n                         [ 1.4208e-02,  9.6778e-03,  1.9240e-02],\n                         [-6.8168e-03,  3.8188e-02, -2.0696e-02]],\n               \n                        ...,\n               \n                        [[ 2.7134e-02,  4.2836e-02,  3.1715e-02],\n                         [ 7.2171e-02,  6.0029e-02,  1.9124e-02],\n                         [ 3.5994e-02, -4.3854e-02, -2.4325e-02]],\n               \n                        [[-5.1153e-02, -3.0692e-02, -2.6221e-02],\n                         [ 2.8103e-02, -3.1104e-02, -5.3865e-02],\n                         [ 5.9541e-02, -6.2667e-03,  5.5931e-02]],\n               \n                        [[-9.3969e-03,  6.0577e-02,  2.0512e-02],\n                         [ 5.3248e-03,  3.2412e-02,  1.0285e-02],\n                         [ 5.4863e-02,  1.6072e-02,  1.3282e-02]]]])),\n              ('backbone.models.0.model.layer2.2.bn2.weight',\n               tensor([0.8766, 0.8568, 0.6120, 1.6753, 0.9111, 0.5438, 1.1519, 0.9486, 1.0476,\n                       0.8763, 0.6146, 1.4129, 0.8331, 0.5644, 0.5495, 1.0856, 1.1681, 1.1216,\n                       1.2213, 0.4350, 0.6089, 0.8126, 0.7464, 1.0470, 0.9078, 0.4994, 0.8250,\n                       0.4778, 1.7935, 1.1901, 0.6553, 0.8567, 0.8346, 0.7365, 0.5303, 0.4561,\n                       0.9441, 0.9093, 0.9939, 0.7765, 1.1025, 1.0301, 0.5186, 1.0444, 0.4721,\n                       0.8856, 1.1453, 1.0821, 1.1715, 0.9102, 0.6058, 1.2139, 1.2406, 0.4774,\n                       1.1751, 0.9148, 0.7056, 0.8923, 0.9552, 0.4458, 1.0689, 1.3178, 0.9557,\n                       0.5464, 0.5141, 0.4039, 0.8464, 1.8632, 1.4589, 0.9196, 0.8492, 0.6893,\n                       0.6604, 0.4720, 1.1564, 1.1068, 0.5301, 1.0246, 0.8476, 0.6372, 0.7757,\n                       0.6403, 0.8227, 1.1723, 1.0600, 0.6554, 0.5778, 0.9192, 1.1995, 0.9247,\n                       0.9103, 1.0351, 0.7526, 0.4664, 0.5577, 1.0254, 1.6306, 0.7601, 0.8770,\n                       1.0507, 0.9236, 0.8856, 1.2461, 1.1283, 0.9524, 1.2878, 0.9591, 1.1194,\n                       1.2617, 0.5530, 0.4696, 0.6976, 0.7902, 1.1301, 0.7621, 0.8097, 1.1338,\n                       0.5231, 0.8792, 0.9579, 1.7150, 1.0649, 1.3874, 0.7913, 0.7851, 0.9693,\n                       0.5868, 1.0852])),\n              ('backbone.models.0.model.layer2.2.bn2.bias',\n               tensor([-0.1863, -0.2752,  0.1831, -1.5083, -0.2030,  0.8654, -0.9694, -0.4287,\n                       -0.4300, -0.4097,  0.1872, -1.0029, -0.6588,  0.5296,  0.3307, -0.6777,\n                       -0.8964, -0.6660,  0.2965,  1.2474,  0.2319, -0.1819, -0.0446, -0.4980,\n                       -0.5692,  1.2648, -0.0820,  0.6309, -1.2304, -0.5074, -0.1499, -0.0888,\n                       -0.2211,  0.7536,  0.9988,  1.2839, -0.5239, -0.2733, -0.5364, -0.2649,\n                       -0.6005, -0.4248,  0.3314, -0.7325,  0.9849, -0.0992, -0.6294, -1.4209,\n                       -0.7572, -0.2633,  0.2869, -0.9804, -1.3689,  1.3958, -0.7951, -0.4947,\n                        0.0220, -0.3318, -0.2201,  0.6627, -0.6920, -0.8114, -0.3936,  0.1517,\n                        0.7015,  1.0336, -0.6333, -1.2992, -1.1966, -0.2209, -0.4012,  0.2119,\n                       -0.0681,  1.1930, -0.5640, -0.6573,  0.3755, -0.9120, -0.3308, -0.0627,\n                       -0.0031,  0.5499,  0.0032, -0.6109, -0.6146,  0.0751,  0.2684, -0.3570,\n                       -1.8371, -0.3288, -0.3172, -0.7829, -0.0997,  1.2747,  0.4238, -0.7094,\n                       -0.8923, -0.1521, -0.2718, -1.7122, -1.2992, -0.3101, -1.3586, -0.5730,\n                       -0.5510, -1.0300, -0.8195, -0.3021, -0.6631,  0.4170,  0.9779, -0.0265,\n                        0.0629, -0.8619, -0.2681, -0.0279, -1.1585,  0.5325, -0.2860, -0.2816,\n                       -1.2168, -0.7310, -0.8464, -0.2359, -0.2558, -0.7682,  0.1320, -0.5749])),\n              ('backbone.models.0.model.layer2.2.bn2.running_mean',\n               tensor([-0.5858, -0.6752,  0.3515, -2.6602, -0.3597, -0.6452, -0.9477, -0.6489,\n                       -0.7581, -0.5386, -0.5521, -1.5806, -0.4253,  0.3614, -0.6124, -0.3762,\n                        0.0691, -0.4553,  0.6795, -0.1145,  0.0087, -0.4889,  0.0601, -1.4580,\n                       -0.1152,  1.2026, -0.1125, -0.4161, -1.2974, -1.1444, -0.5004,  2.0753,\n                        0.0497,  0.6373,  0.6029,  1.1181, -1.0698, -0.2436, -0.0922,  0.0293,\n                       -1.2732, -1.3287, -0.0901, -0.5135,  0.4420, -1.4472, -0.7276, -1.2461,\n                       -0.8682, -0.3508, -0.3548, -0.6985, -1.1379,  0.9923, -0.5462, -0.8643,\n                        0.2520,  0.1995, -1.7551, -1.1021, -1.0808, -1.0657, -0.8770, -0.1547,\n                       -0.8185, -0.4307, -0.8461, -1.6640, -1.4737, -1.5586, -0.4365, -0.2030,\n                        0.4939, -0.5680, -1.7579, -0.5830,  0.5211, -0.9372,  0.9521,  0.4694,\n                       -0.9991, -0.4480, -0.7950, -0.5399, -0.8414,  0.0344, -1.0894,  0.0237,\n                       -1.3314, -0.6950, -0.5471, -1.3749, -1.5620,  1.1064,  0.2759, -0.6167,\n                       -1.1220, -0.8653, -0.3633, -0.7778, -1.7758, -0.5432, -1.2358, -0.2433,\n                       -0.7697, -1.0797, -0.8394, -0.3647, -1.9052, -0.5866,  1.2947, -0.2168,\n                       -0.2683,  0.1318, -0.3627, -0.1244, -0.6223,  1.1395, -0.4591, -1.5980,\n                       -1.6592, -0.8080, -1.9883,  0.5316, -0.1677, -0.9077, -0.8015, -0.6051])),\n              ('backbone.models.0.model.layer2.2.bn2.running_var',\n               tensor([ 3.4316,  1.7674,  1.5125,  3.1470,  2.3562,  1.9073,  1.5684,  1.8333,\n                        2.9435,  1.6662,  2.6215,  4.5975,  1.6221,  1.9154,  1.5052,  1.7062,\n                        2.2540,  2.7052, 13.3728,  1.6203,  2.4457,  1.3932,  2.1563,  2.1370,\n                        1.8568,  1.9802,  1.5575,  1.4691,  4.7085,  3.6504,  0.8755,  3.0255,\n                        1.9898,  0.9443,  1.9975,  1.7709,  1.6224,  2.7216,  1.4857,  1.0777,\n                        2.2252,  1.7445,  1.3097,  1.5636,  1.6427,  4.7846,  3.5010,  0.9935,\n                        1.6346,  2.4375,  1.6097,  1.6562,  1.2403,  2.4405,  1.6700,  1.4819,\n                        1.8059,  1.9688,  4.5218,  1.4201,  1.9497,  3.3198,  1.4434,  1.6919,\n                        1.8983,  1.4074,  0.7864,  3.4104,  1.6712,  4.5411,  1.2425,  2.5229,\n                        1.6056,  1.4708,  3.8966,  2.5537,  1.4022,  1.6201,  3.1508,  1.4944,\n                        2.1167,  1.4008,  3.9987,  2.7869,  1.9620,  1.4996,  1.4041,  1.5454,\n                        0.7446,  1.9642,  1.3657,  2.9818,  1.7760,  1.6349,  1.8396,  1.3955,\n                        4.3032,  1.8907,  1.8384,  0.5396,  1.1110,  1.4300,  1.4079,  2.3510,\n                        1.0875,  1.6087,  1.1284,  2.3065,  2.7177,  1.6339,  1.7020,  1.5153,\n                        1.8025,  2.0480,  1.6826,  2.5068,  1.2112,  1.8950,  1.8095,  2.0750,\n                        1.8632,  1.5137,  3.0436,  2.2152,  1.2278,  1.3979,  1.1077,  2.7703])),\n              ('backbone.models.0.model.layer2.2.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.2.conv3.weight',\n               tensor([[[[ 0.0862]],\n               \n                        [[-0.0327]],\n               \n                        [[-0.0348]],\n               \n                        ...,\n               \n                        [[ 0.0429]],\n               \n                        [[-0.0884]],\n               \n                        [[-0.1076]]],\n               \n               \n                       [[[-0.0251]],\n               \n                        [[ 0.1276]],\n               \n                        [[ 0.0673]],\n               \n                        ...,\n               \n                        [[ 0.0463]],\n               \n                        [[ 0.0225]],\n               \n                        [[ 0.0226]]],\n               \n               \n                       [[[-0.0210]],\n               \n                        [[-0.0279]],\n               \n                        [[ 0.0656]],\n               \n                        ...,\n               \n                        [[-0.0041]],\n               \n                        [[-0.0288]],\n               \n                        [[ 0.0014]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0693]],\n               \n                        [[-0.0464]],\n               \n                        [[ 0.1205]],\n               \n                        ...,\n               \n                        [[ 0.1344]],\n               \n                        [[ 0.0613]],\n               \n                        [[ 0.1144]]],\n               \n               \n                       [[[-0.0016]],\n               \n                        [[ 0.0126]],\n               \n                        [[ 0.0045]],\n               \n                        ...,\n               \n                        [[-0.0002]],\n               \n                        [[ 0.0086]],\n               \n                        [[ 0.0012]]],\n               \n               \n                       [[[ 0.0317]],\n               \n                        [[-0.0849]],\n               \n                        [[ 0.1623]],\n               \n                        ...,\n               \n                        [[ 0.0034]],\n               \n                        [[ 0.0883]],\n               \n                        [[-0.0692]]]])),\n              ('backbone.models.0.model.layer2.2.bn3.weight',\n               tensor([ 4.5737e-01, -1.3752e+00,  1.9033e-01,  7.6703e-01, -3.3767e-01,\n                        1.6984e+00, -7.0744e-01, -7.7497e-01, -9.0569e-01, -5.6457e-01,\n                        1.9138e-02,  5.2780e-01,  2.0815e-02, -2.2080e-01,  1.4783e-01,\n                       -3.9728e-01,  4.3085e-01, -3.4486e-01,  1.1919e+00, -6.7056e-02,\n                       -5.4322e-01, -2.2987e-01,  5.3885e-01,  7.0908e-01, -3.2250e-01,\n                       -6.4867e-01,  1.4744e-01,  7.0311e-01, -6.5425e-01,  5.2049e-01,\n                        8.7017e-02,  7.7318e-01,  2.8560e+00, -2.3159e-01,  6.3501e-01,\n                        1.0463e-02, -7.5857e-01,  1.0403e-01, -1.1623e-01,  1.1919e-01,\n                       -8.7779e-01,  1.2326e+00, -7.3114e-01, -8.2590e-01, -1.2435e-02,\n                       -7.8001e-01,  5.5111e-02, -3.2709e-02, -2.9059e-02, -6.1655e-01,\n                       -5.0257e-01, -8.1665e-01, -1.3562e-01,  9.6654e-01, -1.4281e-02,\n                       -2.6601e-01, -1.0650e-02,  1.5208e-01, -1.0196e+00, -8.6907e-01,\n                        9.2485e-01, -5.3853e-01,  2.8658e-01,  1.0859e+00,  4.3727e-01,\n                        3.6553e-01, -5.9394e-01,  8.7324e-01, -4.1960e-01,  6.2319e-02,\n                        1.7992e-01,  4.9820e-01,  1.0327e+00, -9.1580e-01, -1.8630e-01,\n                       -8.7259e-01, -1.6535e-01,  2.2683e-01,  6.8702e-01,  7.0876e-01,\n                       -9.3044e-01,  1.2645e+00,  7.5577e-02,  5.2065e-01,  2.9276e-01,\n                        6.7529e-01, -2.1216e-02, -3.5549e-02,  4.8940e-01,  5.9641e-02,\n                        1.0304e+00, -4.4146e-02, -1.6213e-01, -2.9618e-02, -5.4932e-01,\n                       -5.5136e-02,  8.1052e-01, -1.5541e-01,  1.7273e-01,  5.6642e-01,\n                       -3.1513e-01, -3.2533e-01, -7.5730e-01,  8.7381e-01, -9.0140e-01,\n                       -1.2931e-01,  5.4121e-01,  6.8481e-01,  3.9817e-01,  9.4750e-01,\n                        2.2199e-01, -2.8337e-01,  3.5449e-01, -2.9032e-01,  2.7802e-01,\n                        8.8288e-03,  7.2192e-01,  2.9075e-01,  6.8438e-01,  4.6874e-01,\n                       -9.7161e-01, -1.4315e+00, -7.2850e-02,  5.5382e-01, -7.8885e-01,\n                        8.6080e-01, -1.0400e+00,  7.6188e-01,  1.4634e-01,  5.7107e-01,\n                        4.4027e-01,  4.6720e-02, -7.3092e-02,  5.0647e-03, -3.4748e-01,\n                       -1.8103e-01, -5.5710e-01, -1.2215e-04,  1.0241e+00, -8.7047e-01,\n                       -1.0864e-02, -6.4508e-01, -3.6584e-01,  5.4151e-01, -1.6012e+00,\n                       -6.0100e-01, -4.0913e-01,  1.4757e-01,  9.9180e-01,  3.2738e-01,\n                        3.4893e-01,  2.0213e-02,  1.1080e-01, -8.5505e-01, -1.0460e-02,\n                       -4.3317e-02, -9.9800e-01, -5.0540e-01,  3.3249e-01,  7.3190e-01,\n                       -2.5775e-01,  5.8901e-01, -8.2298e-01, -6.5778e-02,  8.3994e-01,\n                        5.3035e-01, -1.2696e+00,  6.7987e-01,  1.1199e-02,  1.4955e-01,\n                       -3.7854e-02,  5.2340e-01, -1.3190e-01,  4.1282e-03, -7.7787e-01,\n                        6.1591e-01,  3.0870e-02,  5.3396e-01,  7.2205e-01, -4.0913e-01,\n                       -3.2828e-01,  7.9844e-01, -1.0446e+00,  5.3488e-02,  4.3183e-01,\n                        9.1041e-01, -3.4121e-01, -5.5742e-01,  1.3522e-01, -1.4257e+00,\n                       -1.2070e+00,  1.5172e-01,  5.1258e-01,  4.0960e-01,  2.5413e-01,\n                       -6.6042e-01, -3.7115e-01, -2.5688e-01, -3.2953e-01,  1.3912e+00,\n                       -6.7730e-01, -6.1187e-01,  1.3165e+00,  7.2599e-03, -4.2503e-01,\n                       -5.8495e-01,  1.0504e+00,  1.8136e-01, -3.8995e-01, -2.2013e-01,\n                        5.4914e-01, -5.5930e-01,  5.3003e-01, -2.5483e-01,  3.2239e-01,\n                       -1.9234e-02, -5.1623e-02,  1.5403e-01,  1.1046e+00, -3.1172e-01,\n                       -5.7407e-01,  5.3171e-01,  1.7724e-01, -2.1518e+00,  1.3009e-01,\n                        7.3200e-01,  1.5381e-01, -6.6531e-01, -6.7833e-01, -1.4318e-01,\n                       -7.0941e-01, -2.7705e-01,  1.2876e-01, -7.5328e-01, -8.3688e-01,\n                        1.0517e-01,  6.5300e-01,  3.4688e-01,  4.2486e-01,  1.2032e+00,\n                       -3.9951e-01, -1.9368e-01,  9.8841e-02, -6.4785e-01,  8.2430e-01,\n                       -2.0093e-01, -2.4389e-02,  1.8573e-01,  1.5561e-01,  5.8745e-01,\n                       -2.4588e-01, -1.9361e-01,  2.6137e-01,  1.7887e-02, -7.1634e-01,\n                        1.0983e+00,  5.9150e-02, -1.6802e-01,  2.3769e-01,  1.7658e-02,\n                       -2.5380e-02,  2.2953e-02, -4.1062e-02, -1.1335e-01,  2.3509e-02,\n                        6.6941e-01,  1.1167e-02,  5.5651e-02, -5.5945e-02,  4.7620e-01,\n                       -2.2262e-01, -1.2324e+00,  8.8112e-01, -2.6704e-01, -9.1603e-02,\n                        5.3968e-02, -1.1249e+00, -4.3343e-01,  2.7043e-01, -1.3997e+00,\n                        4.3107e-01, -4.5751e-01,  3.4924e-01, -2.3560e-02,  1.6697e-01,\n                       -1.1964e+00, -1.1037e+00,  6.5335e-01,  7.1565e-02, -2.2031e-01,\n                       -2.7473e-01,  5.5153e-02, -6.8173e-01,  8.7782e-01,  5.1692e-01,\n                        7.6260e-01, -1.2810e-02, -5.4162e-01,  7.8574e-01, -5.5008e-01,\n                       -7.5020e-01, -1.0510e+00, -7.7253e-01,  9.9860e-02,  5.4774e-01,\n                        7.1387e-02,  2.1343e+00,  8.7223e-02, -8.5243e-01, -2.1884e-02,\n                       -1.8431e-01, -9.1336e-01,  2.4295e-01,  1.2115e+00,  4.1970e-02,\n                       -1.0734e-02,  8.3656e-01, -4.7904e-01,  3.3877e-02, -4.8880e-01,\n                        4.3978e-03, -2.2900e-02, -9.0230e-01, -6.5774e-02, -8.7260e-01,\n                        1.2736e+00,  6.7911e-01, -5.3339e-01, -1.1933e-02,  7.4795e-01,\n                       -2.2209e-02, -8.8065e-01, -8.1953e-01,  6.5578e-01, -1.3627e+00,\n                        5.3104e-01,  3.1071e-01,  2.9252e-01, -1.2137e+00, -1.5397e-02,\n                       -2.9868e-01,  5.0254e-03, -1.6429e-01, -1.3349e+00,  1.8947e+00,\n                        5.9050e-01,  7.1015e-01, -9.1309e-01,  6.8341e-01,  6.5421e-02,\n                       -1.2294e+00, -5.8694e-02,  1.8265e-01, -6.4496e-01, -7.3184e-01,\n                       -1.5439e+00, -5.1432e-01,  2.5275e-01, -2.2121e-01, -1.9934e-01,\n                        8.7794e-01,  2.4616e-01,  3.9159e-01, -3.8347e-01,  2.4075e-01,\n                        3.5529e-01,  7.1757e-01,  6.0759e-01,  1.0980e-01, -4.6259e-01,\n                       -1.5060e-01,  4.6642e-02, -9.0838e-03, -2.2895e-01,  8.0667e-01,\n                        6.1661e-02,  6.4484e-01,  5.1915e-02,  8.5448e-01, -1.6711e-01,\n                        2.0765e-01,  8.6571e-02, -1.2523e+00,  2.1772e-01, -2.9992e-01,\n                        9.4126e-01, -2.9985e-01, -1.1128e-01,  3.9978e-01, -4.0714e-01,\n                        2.4969e-02, -5.8824e-01,  5.5755e-02,  1.4233e+00,  3.0393e-01,\n                       -3.7043e-01,  1.0482e+00, -3.6505e-01,  1.2271e+00, -1.0298e+00,\n                        1.4192e-02, -4.4004e-02, -9.2711e-01,  3.1042e-01, -2.0908e-01,\n                       -4.9796e-01,  1.2221e-01, -1.1568e+00,  1.9839e-01, -2.1440e-01,\n                       -4.6588e-02, -4.0605e-03, -9.3866e-01, -1.0452e+00, -5.5170e-01,\n                       -5.4796e-01, -1.5354e-01,  8.0709e-02,  1.7884e-01,  3.3116e-01,\n                       -4.3776e-02, -1.3432e+00, -2.1689e-01,  8.6362e-01, -8.5236e-01,\n                        9.9598e-03,  3.3268e-01, -6.7456e-01,  7.5205e-01,  8.7818e-01,\n                        2.5500e-01,  4.1382e-01,  2.9192e-01,  5.8415e-01,  3.1338e-01,\n                       -5.2459e-01,  1.6235e-01,  5.7791e-01,  2.2438e-01,  1.8812e+00,\n                       -1.0779e+00,  4.4465e-02, -1.3748e-01,  4.5376e-01, -5.7404e-01,\n                       -5.1174e-01,  3.1671e-01,  5.5331e-02,  1.3288e-01,  1.8680e-01,\n                        2.2556e-01,  2.6339e-02,  3.9146e-02, -1.7673e-01, -1.2240e+00,\n                       -7.1649e-01,  3.8709e-02, -2.4076e-01,  9.0732e-01, -2.2318e-01,\n                       -2.5033e-01, -3.0228e-01, -1.1498e+00, -5.5235e-01, -9.9517e-01,\n                       -5.3494e-01, -1.8686e+00,  3.2927e-01,  9.2608e-01, -8.8223e-02,\n                       -8.7206e-01, -1.1450e-01, -9.8061e-01,  2.2256e-01, -5.3107e-01,\n                        1.9109e-02,  3.0348e-01, -8.0463e-01, -5.9919e-01, -4.9275e-01,\n                       -2.5073e-01,  1.6356e-01,  2.7265e-01, -2.2041e-01, -1.1808e-01,\n                        1.2389e+00,  3.7231e-01,  4.8121e-01,  2.1120e-01, -1.2137e-01,\n                        1.3732e+00,  5.0903e-01,  3.8282e-01, -6.6562e-01,  8.8279e-02,\n                        1.8322e-01,  2.2668e-01, -2.4146e-01, -3.4851e-01,  9.6649e-01,\n                       -3.0801e-01,  4.2805e-01,  5.4246e-01,  1.5974e-02, -2.3302e-01,\n                        1.4059e+00, -5.3676e-01, -1.3696e-01, -1.5295e-01, -1.4067e+00,\n                        2.7732e-02, -9.0301e-01])),\n              ('backbone.models.0.model.layer2.2.bn3.bias',\n               tensor([ 0.7802, -1.3683,  0.2963, -0.3549,  0.4593, -0.8363, -0.1163,  0.7584,\n                       -0.5675, -0.5097,  0.5645,  0.6599,  0.6176,  0.1113, -0.0453,  0.2634,\n                       -0.4566,  0.5116, -0.4803,  0.5310, -0.3238, -0.1854,  0.7207, -0.2718,\n                       -0.1528,  0.9167,  0.2618,  0.5074,  0.3152,  0.5442,  0.3162,  0.5280,\n                       -1.9708, -0.2968,  0.7948,  0.5008,  0.6258,  0.7882, -0.1236,  0.7352,\n                        0.8997, -0.8354,  0.9262,  0.6882,  0.6064, -0.5325,  0.1968,  0.2299,\n                        0.3060, -0.4783, -0.3112,  0.4726,  0.8811, -0.2340,  0.1613,  0.4741,\n                        0.1687, -0.0059, -0.2717, -0.4808, -0.2667, -0.0222,  0.5296, -1.4390,\n                        0.3762, -0.3226, -0.6639,  0.7156, -0.1452,  0.3603, -0.2016,  0.5790,\n                       -0.3246, -0.3331,  0.1149, -0.1981, -0.1089, -0.2302,  0.9115,  1.0952,\n                       -0.1423, -0.6216,  0.7242,  0.6291,  0.3907,  0.0942,  0.0984,  0.3047,\n                        0.4396,  0.5297, -0.4047,  0.1089,  0.8278,  0.7617, -0.0868,  0.4734,\n                       -0.5949,  0.2410,  0.6594, -0.4488, -0.2548, -0.3403, -0.5057, -0.1894,\n                        0.6434,  0.5927,  0.3067,  0.5850, -0.2521, -0.3217, -0.0244, -0.2945,\n                        0.4055,  0.7724, -0.4146,  0.2186,  0.8088, -0.0721,  0.4298, -0.4026,\n                       -0.7194, -0.7564,  0.1864,  0.2456,  0.9203,  0.5229, -0.1780,  0.4414,\n                        0.1793,  0.0172, -0.1015,  0.8023,  0.1329,  0.2134,  0.9963,  0.2948,\n                       -0.5112,  0.5595, -0.1342,  0.5684,  0.7581,  0.6209, -0.2152, -0.1290,\n                        0.1806, -0.4572, -0.2383,  0.6126,  0.5234, -0.3964,  1.0190,  0.3747,\n                        0.5242, -0.6999,  0.0993,  0.1487,  0.4803,  1.0497, -0.1589, -0.2442,\n                       -0.3059,  0.1978,  0.7586,  0.9506, -0.7729, -0.5550, -0.8630, -0.5898,\n                        0.6242,  0.3157,  0.2550,  0.0338, -0.0729,  0.4498, -0.6536,  0.2278,\n                        0.7573,  0.6267,  0.2944, -0.2636, -0.2117, -0.5028,  0.1043,  0.5438,\n                        0.8848,  0.6538,  0.4601, -0.4107,  1.0993,  0.2234, -1.7257,  0.4800,\n                        0.5059,  0.8001,  0.7277, -0.3873, -0.2866, -0.2804, -0.5449, -0.9508,\n                        0.3656,  0.7973, -0.5213,  0.5695, -0.3787,  0.8433, -0.9146,  0.7271,\n                       -0.2550,  1.1006, -0.0351, -0.5502, -0.6663,  0.0583, -0.3508,  0.3757,\n                        0.2108, -0.0572, -0.9416, -0.1500, -0.6551,  0.5804,  0.2857, -1.2865,\n                        0.4627, -0.6152, -0.1213, -0.5249,  0.0266,  0.8637, -0.0454, -0.5304,\n                        0.3389,  0.9724,  0.3101,  0.3906,  0.0940, -0.2821,  0.7417, -0.3099,\n                       -0.4430, -0.2054,  0.5100,  0.3024,  1.0490,  0.6427,  0.2824, -0.2017,\n                        0.3372,  0.7238,  0.0655, -0.2881,  0.8408,  0.4293,  0.0573, -0.2148,\n                        0.7561, -0.0682, -0.1351,  0.3064,  0.5276,  0.7672,  0.0778,  0.6033,\n                        0.6407,  0.2133,  0.0495,  0.3434,  0.5531, -0.5089, -0.2197, -0.9366,\n                        0.0640,  0.3038,  0.6559,  1.0241, -0.6086,  0.5145, -0.0112, -0.6316,\n                        0.2086,  0.3107, -0.6259,  0.7458,  0.1947, -0.5842, -0.5101,  0.3309,\n                        0.0881,  1.3702,  0.1658,  0.3143,  0.5826, -0.5187, -0.4899, -1.3872,\n                        0.4865, -0.3917,  0.8140,  0.6365, -0.2594,  0.7799, -1.1638,  0.0888,\n                        0.2939,  0.3612, -0.8579,  0.0524,  0.2479,  0.6145,  0.7731, -0.5268,\n                        0.4896, -0.7961,  0.1120,  0.5922, -0.7609, -0.2023,  0.4847, -0.5973,\n                        0.1557,  0.5172,  0.7365,  0.7067, -0.4834, -1.5090, -0.4871,  0.0709,\n                        0.8625,  0.5170,  0.5360, -0.2464, -0.2962,  0.5396, -1.0753,  0.2969,\n                       -0.1571, -0.1259, -0.0530,  0.5166, -0.2233,  0.1980, -0.1650, -0.9006,\n                       -1.6454,  1.0943, -0.6558, -0.7574,  0.6525,  0.1401, -0.5692,  0.2840,\n                       -0.2490,  0.8946, -0.8719, -1.2611, -0.5125, -0.3216,  0.2062, -0.1729,\n                        0.0657, -0.0357, -0.4334,  1.3144, -0.1520, -0.2047,  0.9283,  0.1784,\n                        0.3374, -0.4919,  0.3762,  0.1956,  0.5676,  0.2785,  0.5164,  0.2536,\n                        0.7417,  0.1729, -0.3673,  0.6970,  0.2634,  0.1660, -0.7667, -0.1788,\n                       -0.2471,  1.0972,  0.3237,  0.0705, -0.1427, -0.1690,  0.2220,  0.3802,\n                        0.1210,  0.6708, -0.2312, -0.3756,  0.5695,  0.2845, -0.4021, -1.5295,\n                        0.7762,  0.1011, -0.5311, -0.0135, -0.1012,  0.4336,  0.4282, -1.0252,\n                       -0.3220,  0.4464,  0.5809,  0.2232, -1.2805, -0.0992,  0.5499,  0.2219,\n                        0.2363,  0.2841,  0.2066,  0.8447,  0.1206, -0.1160,  0.4395, -0.9474,\n                        0.7441,  0.5196, -0.2836, -0.2666,  0.7630, -0.9339, -0.2257, -0.6951,\n                        0.0068,  0.5061, -0.1004,  0.9512,  1.4242,  0.1939,  0.8578, -0.3752,\n                       -1.3256,  0.0174,  0.0511,  0.3245, -0.1603,  0.1671, -0.2230,  0.1033,\n                        0.4714,  0.4259, -0.3383,  0.0901,  0.3896, -0.0141, -0.9386, -0.5314,\n                        0.5253,  0.5249, -0.5877, -0.2239,  0.2780, -0.1106, -0.6485,  0.5321,\n                       -0.3794,  0.2635, -1.9452,  0.7321, -0.3208,  0.3805, -0.4009,  0.7262,\n                       -0.6805,  0.1734, -0.2528,  0.6347,  0.4341, -0.4112,  0.7488,  0.4315,\n                        0.5228,  0.3175, -0.3519, -0.0264,  0.2119, -0.9483, -0.3632, -0.4583,\n                        0.7096,  0.6820, -1.3618,  0.4094, -0.3823,  0.6623,  0.7690,  0.6130,\n                        0.5911,  1.0713, -0.1738, -0.1309,  0.0063, -0.4387, -0.6255,  0.2309,\n                        0.4383, -0.7403, -0.7748,  0.4271, -0.0176, -1.0119,  0.2950,  0.1887])),\n              ('backbone.models.0.model.layer2.2.bn3.running_mean',\n               tensor([ 3.5685e-01,  1.7721e-01,  2.0961e-01, -9.7832e-02, -1.3922e-02,\n                       -1.9374e-01, -1.9650e-02, -7.5620e-01,  6.7107e-02,  5.0628e-01,\n                        1.9741e-02, -3.8070e-01,  6.2845e-02, -5.7942e-01,  5.1732e-03,\n                       -1.6435e-01, -1.7214e-01,  6.6096e-01,  2.0175e-01, -1.0895e-01,\n                        6.4477e-01, -1.1646e-01, -7.1060e-01, -9.1559e-01, -7.5537e-02,\n                        2.8853e-01,  1.4780e-01,  6.4595e-01, -2.4475e-01, -2.3448e-01,\n                       -5.3372e-02,  3.7568e-01, -1.3599e+00,  5.4724e-01,  9.2078e-01,\n                       -1.1235e-02,  1.3789e-01,  1.2396e-01,  1.7522e-01,  3.4802e-01,\n                        4.7474e-02, -9.4851e-01, -1.1855e+00, -1.0633e+00, -7.3275e-02,\n                        5.6092e-01,  3.1936e-01, -5.0609e-02, -1.0576e-01,  1.7425e-01,\n                        5.6282e-01, -1.1827e+00,  1.3100e-01,  5.9173e-02, -5.6460e-02,\n                       -4.5897e-01, -5.5662e-02,  1.3221e-01, -1.0299e-01,  1.2161e-01,\n                       -5.9442e-01, -3.9817e-01,  2.8989e-01, -1.0599e+00,  6.9379e-02,\n                       -7.6745e-02,  1.8774e-01,  3.0609e-01,  6.0766e-02,  7.3648e-02,\n                       -2.0908e-01, -3.1296e-01, -5.5516e-01,  8.6496e-01,  5.7675e-01,\n                       -1.0659e-01,  2.0640e-03, -1.1583e-01, -9.7896e-01,  1.2552e+00,\n                        7.0899e-01, -5.1573e-01,  8.5101e-02, -1.4832e-01,  2.4373e-01,\n                        3.8020e-01, -8.8978e-03,  2.6542e-02, -2.6184e-01, -1.5431e-02,\n                        1.4841e-01,  3.3603e-03, -6.1149e-02, -1.7202e-01, -4.5268e-01,\n                       -2.0808e-02, -1.4174e-01, -5.0042e-02, -1.2363e-01, -2.5196e-03,\n                       -9.8598e-02,  5.2537e-01, -1.4480e-01,  6.0694e-01,  1.3095e-01,\n                       -3.5901e-01, -2.7231e-01,  1.2445e-01,  2.8409e-01, -1.9922e-01,\n                       -2.9061e-01, -1.4039e-01,  1.8761e-01, -5.5738e-01, -1.5410e-01,\n                        3.4413e-02, -1.1959e+00, -3.6835e-02, -5.3636e-01, -4.5535e-01,\n                        7.2884e-01,  2.2223e-01, -2.0120e-01, -1.8041e-02, -9.0085e-01,\n                       -5.8164e-01, -3.6123e-01,  5.3876e-01, -1.0572e-01,  1.2379e-01,\n                       -2.0000e-01,  1.7485e-01,  8.1055e-02, -3.5574e-02,  6.7169e-01,\n                        3.5051e-01, -6.8521e-03,  1.4877e-02,  6.0170e-01,  6.1288e-01,\n                        3.3307e-02,  4.7670e-01,  1.4841e-01, -4.0592e-01,  9.3974e-01,\n                        3.7014e-01, -9.0499e-02,  2.4996e-01,  5.4959e-01, -2.4194e-01,\n                       -1.4405e-01,  1.6166e-02,  1.1946e-01,  9.4167e-01,  1.6104e-02,\n                       -2.3211e-01, -2.5277e-02,  2.2905e-01, -9.0970e-02,  7.9857e-02,\n                       -8.2548e-02,  2.4030e-03, -1.1649e+00,  2.0343e-01, -1.8095e-01,\n                       -1.0615e-01, -1.6966e-01, -8.3424e-01,  6.0675e-03, -4.7655e-01,\n                       -8.0374e-02, -2.7474e-01, -1.5584e-02,  3.3485e-03,  8.3553e-01,\n                        3.2832e-01, -5.3615e-02, -2.2248e-01, -5.9764e-02, -7.9552e-02,\n                        6.8642e-01, -1.5959e-01,  3.3087e-01,  3.1659e-02,  4.6083e-01,\n                        8.1107e-01,  2.1844e-01,  4.6583e-01, -3.6225e-02, -1.4249e+00,\n                        1.1268e+00,  1.0766e-01, -6.4393e-02, -1.8915e-01, -2.3432e-01,\n                        4.5009e-01, -2.0092e-01, -3.4349e-01, -2.4596e-01, -3.3293e-01,\n                       -1.0904e-01, -2.4654e-01, -2.9750e-01, -1.5323e-02,  1.2243e-01,\n                       -7.7755e-01, -4.8809e-01, -4.0457e-01, -1.8157e-01,  1.4616e-02,\n                        4.9696e-01,  9.4996e-01, -3.8017e-01,  4.9220e-02,  8.9362e-02,\n                        1.1185e-02, -4.7179e-02,  1.6535e-01, -8.6984e-01,  3.7922e-01,\n                        4.7077e-01, -6.2768e-01, -6.0674e-02, -1.0353e-01, -4.1698e-01,\n                       -6.5680e-02, -1.5923e-01,  1.0604e-01, -9.7048e-02,  1.6739e-01,\n                       -5.4570e-01, -2.1771e-01,  2.1325e-01,  2.8136e-01,  3.4539e-01,\n                       -1.7544e-01, -2.3801e-01, -2.6905e-03, -5.1590e-01, -1.9694e-01,\n                        1.9260e-01,  5.6035e-01,  1.3222e-01,  1.7328e-01,  2.6151e-01,\n                        6.5955e-01, -2.8115e-02,  5.3317e-02, -3.0917e-01, -1.0186e-01,\n                        5.1878e-01,  2.5855e-02, -3.3928e-01,  3.6032e-02, -2.1614e-02,\n                       -5.3671e-01,  1.7164e-02, -1.4705e-01,  2.1331e-01, -3.9613e-02,\n                       -1.7299e-01,  5.6988e-02, -1.3003e-02,  2.0541e-01,  4.5222e-02,\n                        9.6487e-01,  5.1104e-02,  6.5224e-02, -5.2080e-02, -2.7952e-01,\n                       -2.2886e-01,  1.5917e-01,  7.0737e-01,  2.3269e-01,  4.1311e-02,\n                       -1.0208e-01,  1.0625e-01, -3.7462e-01, -3.9024e-01,  5.1863e-01,\n                       -3.6764e-01,  3.6985e-01, -2.2963e-01,  5.2127e-02,  6.0246e-01,\n                        3.7050e-01,  4.9639e-01, -1.2476e+00, -8.8562e-03, -2.2818e-01,\n                       -7.3674e-02, -1.4412e-01, -8.5633e-01,  6.1025e-01,  1.6871e-01,\n                        2.1558e-01,  2.0932e-02,  6.0846e-02,  6.2693e-01,  1.9329e-01,\n                        5.0050e-01,  1.1841e+00, -9.1449e-02,  3.4386e-01, -4.0160e-02,\n                        2.0508e-01,  4.5025e-01, -6.2650e-02,  4.4798e-01, -5.2482e-02,\n                        1.7309e-02, -3.0831e-01, -1.8482e-01, -6.9029e-01, -1.8367e-01,\n                       -7.5963e-02, -6.4915e-01, -2.6044e-01, -7.3006e-02,  8.5331e-01,\n                        6.3872e-03, -2.1219e-03, -5.2182e-01,  2.2507e-01,  6.4397e-01,\n                       -4.9723e-01, -1.1111e-01,  3.4550e-01, -8.4813e-02,  6.0197e-02,\n                        5.7298e-02,  6.9748e-01, -7.5725e-01,  1.1753e-01,  7.1779e-01,\n                        4.8648e-01,  1.6152e-01, -6.0968e-01, -3.4217e-01, -1.0115e-02,\n                        2.4875e-01, -2.1866e-03,  1.6174e-01,  4.2810e-01, -3.5803e-01,\n                        3.1881e-01, -7.4623e-01, -1.9725e-01, -2.8001e-01, -5.6238e-02,\n                        7.6410e-01, -1.8334e-01, -2.7167e-02,  7.0339e-02,  5.2209e-01,\n                        5.5089e-01,  2.3756e-01, -3.4155e-01, -2.8894e-01,  2.6979e-02,\n                       -1.0909e+00, -9.3255e-01, -9.0374e-01,  1.0538e+00, -6.6783e-01,\n                       -2.3638e-02,  7.6737e-01, -6.6054e-01,  2.0373e-01,  4.7020e-01,\n                       -1.0196e-01,  3.4908e-03,  2.9544e-05,  9.2944e-02,  1.1148e-01,\n                        1.6101e-01, -9.3411e-02, -6.0046e-04, -1.7501e-01, -3.3877e-01,\n                       -5.4419e-01,  6.8878e-02,  5.7735e-01, -3.2335e-03,  3.1352e-01,\n                        6.9915e-01,  6.3669e-02,  9.9441e-02, -8.5085e-01,  1.0554e-01,\n                        1.6844e-01,  6.4860e-01, -4.8015e-02, -8.8692e-01, -7.7684e-02,\n                        2.2310e-01, -3.8872e-01, -1.9548e-01, -6.4983e-01,  5.3762e-01,\n                       -4.9398e-02, -2.2357e-02,  5.2586e-01, -3.1644e-01,  6.8137e-03,\n                       -8.3546e-01,  1.5031e-01,  6.1374e-01, -6.8000e-02,  3.9899e-01,\n                       -7.0956e-02, -5.0849e-03,  7.9300e-01, -1.8019e-01,  3.2252e-01,\n                       -1.9254e-01, -4.7996e-01,  1.9736e-01, -3.7562e-01, -2.4192e-02,\n                        2.4083e-02,  2.1491e-01, -3.5405e-01, -7.6634e-01,  5.6074e-02,\n                       -1.1066e-02, -3.7447e-01,  4.4724e-01, -9.4184e-01,  5.9320e-03,\n                       -1.9587e-01, -8.6162e-02, -4.0488e-01,  2.8711e-01, -2.9983e-02,\n                        3.9190e-01, -7.3210e-01, -1.6171e-01,  2.6147e-01, -7.1614e-02,\n                        3.3550e-01, -2.6824e-02,  6.3646e-01, -1.0596e+00,  1.3287e-01,\n                        1.1137e+00, -1.3009e-01,  2.3458e-02, -3.4626e-02,  3.6258e-01,\n                        2.4915e-03, -4.4829e-02, -1.8484e-01, -2.9406e-01,  1.3107e+00,\n                        5.9456e-01,  7.0662e-02, -2.8126e-01,  4.0632e-02,  4.6878e-01,\n                       -1.6498e-01,  3.9351e-02,  1.0171e+00, -9.6827e-01, -2.1434e-01,\n                        7.5414e-01,  5.8174e-01, -2.2245e-01, -8.4526e-02,  3.3570e-02,\n                       -7.3234e-02,  6.3219e-02, -5.4485e-01,  1.6750e-01, -9.4679e-02,\n                       -1.0816e-01,  1.3615e-01, -1.0480e+00, -7.2247e-01, -8.3227e-01,\n                        6.8638e-02,  1.8262e-01, -2.9343e-01,  1.5930e-01, -1.4231e-01,\n                       -3.0196e-01, -2.9857e-01, -4.8227e-01, -1.5145e-01,  5.9916e-01,\n                       -1.2938e+00,  2.2021e-01, -2.5098e-01,  1.4031e-01,  2.6359e-01,\n                       -1.5902e-01,  4.3747e-01,  1.3836e-02, -8.1193e-02, -5.9917e-01,\n                        3.0745e-01,  1.6449e-01, -7.9355e-01,  5.7865e-03,  9.5452e-02,\n                       -1.0795e+00, -2.6237e-01,  2.7703e-01,  2.1090e-01,  2.8276e-01,\n                        5.0528e-02,  7.9464e-01])),\n              ('backbone.models.0.model.layer2.2.bn3.running_var',\n               tensor([0.3332, 0.1179, 0.0818, 0.4005, 0.1123, 0.3897, 0.1874, 0.2126, 0.1911,\n                       0.1438, 0.0172, 0.1732, 0.0119, 0.0621, 0.0317, 0.1017, 0.0825, 0.1466,\n                       0.2222, 0.0169, 0.2167, 0.1033, 0.1541, 0.1953, 0.0822, 0.2779, 0.0372,\n                       0.2709, 0.2410, 0.2146, 0.0288, 0.3014, 1.6209, 0.2501, 0.2781, 0.0072,\n                       0.2520, 0.0624, 0.0311, 0.0408, 0.3560, 0.1726, 0.2730, 0.2551, 0.0242,\n                       0.1692, 0.0126, 0.0103, 0.0281, 0.0978, 0.1005, 0.2288, 0.0403, 0.2624,\n                       0.0157, 0.0788, 0.0109, 0.0567, 0.2135, 0.2036, 0.2364, 0.3862, 0.1366,\n                       0.2121, 0.1847, 0.0773, 0.2188, 0.2665, 0.0856, 0.0363, 0.0778, 0.1738,\n                       0.3437, 0.2424, 0.0632, 0.3384, 0.0556, 0.0499, 0.3448, 0.2271, 0.2131,\n                       0.2116, 0.0275, 0.1761, 0.1363, 0.1755, 0.0057, 0.0111, 0.2081, 0.0283,\n                       0.3013, 0.0475, 0.0647, 0.0852, 0.1626, 0.0079, 0.3320, 0.0720, 0.0526,\n                       0.2396, 0.0314, 0.0728, 0.0901, 0.2570, 0.2668, 0.0382, 0.2136, 0.1998,\n                       0.0668, 0.3513, 0.1369, 0.0310, 0.1449, 0.0972, 0.0697, 0.0178, 0.2792,\n                       0.0659, 0.2319, 0.1150, 0.2156, 0.3705, 0.0579, 0.2261, 0.2717, 0.2941,\n                       0.3068, 0.2435, 0.0501, 0.1488, 0.1511, 0.0145, 0.0175, 0.0214, 0.1502,\n                       0.0566, 0.1207, 0.0208, 0.3574, 0.2395, 0.0069, 0.3222, 0.0787, 0.1314,\n                       0.6563, 0.2053, 0.1150, 0.0789, 0.3475, 0.0486, 0.1327, 0.0115, 0.0297,\n                       0.1771, 0.0090, 0.0570, 0.5520, 0.1872, 0.0552, 0.3101, 0.0457, 0.2045,\n                       0.2655, 0.0832, 0.1860, 0.1062, 0.2878, 0.1579, 0.0422, 0.0472, 0.0099,\n                       0.1713, 0.0287, 0.0070, 0.1667, 0.2109, 0.0078, 0.1844, 0.2170, 0.0773,\n                       0.0765, 0.2314, 0.4914, 0.0212, 0.1970, 0.2853, 0.1464, 0.1557, 0.0475,\n                       0.8149, 0.2552, 0.0855, 0.1519, 0.1082, 0.0867, 0.1801, 0.1018, 0.0621,\n                       0.0564, 0.2634, 0.2630, 0.2196, 0.2977, 0.0251, 0.1009, 0.2690, 0.1572,\n                       0.0765, 0.1115, 0.0552, 0.2106, 0.1605, 0.1098, 0.0681, 0.0606, 0.0109,\n                       0.0211, 0.0258, 0.1519, 0.0795, 0.1297, 0.1987, 0.0650, 0.7756, 0.0520,\n                       0.1466, 0.0353, 0.1399, 0.2104, 0.0745, 0.2983, 0.0515, 0.0322, 0.3205,\n                       0.2726, 0.0900, 0.2621, 0.0648, 0.1995, 0.3276, 0.0903, 0.1641, 0.0434,\n                       0.1891, 0.2714, 0.0879, 0.0072, 0.0341, 0.0516, 0.2350, 0.0868, 0.0516,\n                       0.0779, 0.0062, 0.2628, 0.2881, 0.0101, 0.0639, 0.0434, 0.0369, 0.0221,\n                       0.0146, 0.0064, 0.0725, 0.0106, 0.1980, 0.0119, 0.0429, 0.0333, 0.1191,\n                       0.0438, 0.2202, 0.2874, 0.1571, 0.0469, 0.0254, 0.1803, 0.1299, 0.0900,\n                       0.3986, 0.1340, 0.1598, 0.0463, 0.0148, 0.0901, 0.3311, 0.2952, 0.3076,\n                       0.0481, 0.0550, 0.0725, 0.0643, 0.2590, 0.1748, 0.0828, 0.2495, 0.0238,\n                       0.0928, 0.4535, 0.1742, 0.1466, 0.3930, 0.1666, 0.0205, 0.1698, 0.0198,\n                       0.1970, 0.0266, 0.2517, 0.0305, 0.0394, 0.3516, 0.0834, 0.2733, 0.0313,\n                       0.0117, 0.1301, 0.0938, 0.0154, 0.1003, 0.0056, 0.0089, 0.3343, 0.0239,\n                       0.2036, 0.2886, 0.1513, 0.1566, 0.0093, 0.2222, 0.0292, 0.3818, 0.2212,\n                       0.2281, 0.2919, 0.2166, 0.1180, 0.0596, 0.2746, 0.0108, 0.0786, 0.0190,\n                       0.0310, 0.2521, 0.2764, 0.2038, 0.1401, 0.1874, 0.2454, 0.0193, 0.1763,\n                       0.0161, 0.0498, 0.2321, 0.1919, 0.2752, 0.0954, 0.0625, 0.2393, 0.0213,\n                       0.3570, 0.1022, 0.1910, 0.2129, 0.0880, 0.0862, 0.2438, 0.2056, 0.0301,\n                       0.3422, 0.0959, 0.0113, 0.0133, 0.2458, 0.2390, 0.0367, 0.2327, 0.0159,\n                       0.2219, 0.0555, 0.0640, 0.0383, 0.2178, 0.0620, 0.0501, 0.3999, 0.1802,\n                       0.0475, 0.1361, 0.0705, 0.0542, 0.1758, 0.0137, 0.6806, 0.1873, 0.0563,\n                       0.2801, 0.1611, 0.2268, 0.2844, 0.0033, 0.0099, 0.3191, 0.1480, 0.0436,\n                       0.1483, 0.0923, 0.1951, 0.0526, 0.0668, 0.0132, 0.0132, 0.2445, 0.2835,\n                       0.1676, 0.1494, 0.1186, 0.0759, 0.0554, 0.1278, 0.0066, 0.3908, 0.0806,\n                       0.2260, 0.2641, 0.0149, 0.0514, 0.2112, 0.3470, 0.1230, 0.0452, 0.0450,\n                       0.0770, 0.1566, 0.1488, 0.1705, 0.0931, 0.1746, 0.1017, 0.2649, 0.1882,\n                       0.0128, 0.0588, 0.1825, 0.1253, 0.1485, 0.0631, 0.0126, 0.0510, 0.0796,\n                       0.0458, 0.0105, 0.0529, 0.0494, 0.2351, 0.1068, 0.0091, 0.0705, 0.2132,\n                       0.0750, 0.1025, 0.0769, 0.2226, 0.2489, 0.3162, 0.2297, 0.3294, 0.1151,\n                       0.2073, 0.0302, 0.2488, 0.0368, 0.2492, 0.0915, 0.1509, 0.0226, 0.1888,\n                       0.2212, 0.2530, 0.2599, 0.0963, 0.2241, 0.1054, 0.0942, 0.0717, 0.2321,\n                       0.0907, 0.1141, 0.0529, 0.0425, 0.2540, 0.2992, 0.1006, 0.2655, 0.0437,\n                       0.0911, 0.0837, 0.1679, 0.0888, 0.3407, 0.0598, 0.1246, 0.1256, 0.0061,\n                       0.1180, 0.3345, 0.1379, 0.0351, 0.0689, 0.2698, 0.0226, 0.2667])),\n              ('backbone.models.0.model.layer2.2.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.3.conv1.weight',\n               tensor([[[[ 0.0667]],\n               \n                        [[-0.1440]],\n               \n                        [[ 0.0145]],\n               \n                        ...,\n               \n                        [[-0.0344]],\n               \n                        [[ 0.0281]],\n               \n                        [[-0.0013]]],\n               \n               \n                       [[[-0.1080]],\n               \n                        [[ 0.0608]],\n               \n                        [[-0.0016]],\n               \n                        ...,\n               \n                        [[-0.0426]],\n               \n                        [[ 0.0228]],\n               \n                        [[ 0.0314]]],\n               \n               \n                       [[[-0.0190]],\n               \n                        [[ 0.1219]],\n               \n                        [[ 0.0506]],\n               \n                        ...,\n               \n                        [[-0.0214]],\n               \n                        [[ 0.0304]],\n               \n                        [[ 0.0063]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.1023]],\n               \n                        [[-0.0724]],\n               \n                        [[ 0.0275]],\n               \n                        ...,\n               \n                        [[-0.0358]],\n               \n                        [[-0.0328]],\n               \n                        [[-0.0909]]],\n               \n               \n                       [[[-0.0273]],\n               \n                        [[ 0.0897]],\n               \n                        [[ 0.0126]],\n               \n                        ...,\n               \n                        [[ 0.0160]],\n               \n                        [[-0.0078]],\n               \n                        [[-0.0721]]],\n               \n               \n                       [[[ 0.0173]],\n               \n                        [[-0.0136]],\n               \n                        [[ 0.0264]],\n               \n                        ...,\n               \n                        [[ 0.0413]],\n               \n                        [[-0.0488]],\n               \n                        [[-0.0687]]]])),\n              ('backbone.models.0.model.layer2.3.bn1.weight',\n               tensor([1.2187, 1.0729, 1.1526, 1.0022, 0.8555, 1.2416, 0.9192, 0.9314, 0.9147,\n                       1.0516, 0.9533, 0.8658, 1.1886, 1.2212, 0.8201, 1.1351, 0.9376, 0.8879,\n                       0.9822, 1.0334, 0.8988, 1.0012, 0.6900, 1.1171, 1.3658, 0.9698, 1.0715,\n                       0.8856, 0.9954, 0.9604, 0.9168, 1.0091, 1.0136, 0.9213, 0.8315, 0.9938,\n                       1.0332, 1.0676, 0.8288, 0.7385, 1.0702, 1.1925, 0.9778, 0.9579, 0.6163,\n                       1.0882, 0.9234, 1.0895, 1.0148, 0.9399, 0.9630, 0.9655, 1.0012, 1.0468,\n                       0.9450, 1.1596, 0.9747, 0.9476, 0.9931, 0.9474, 1.0140, 0.9725, 0.9376,\n                       0.8824, 1.1416, 0.9751, 1.0567, 0.9641, 0.8064, 0.9204, 0.9987, 1.0519,\n                       0.8788, 1.1558, 0.9255, 1.0949, 0.9912, 0.9864, 1.0936, 1.1968, 0.9011,\n                       0.8317, 1.2290, 1.1897, 0.9235, 1.1591, 1.1463, 0.8704, 0.8397, 0.9941,\n                       0.7910, 0.5123, 1.2258, 0.9629, 0.7439, 0.7501, 0.9319, 1.1032, 1.0062,\n                       0.9652, 1.0180, 1.2475, 1.0604, 0.9414, 0.7805, 1.0403, 0.7101, 0.9685,\n                       1.0612, 0.9634, 1.0703, 1.0492, 1.2662, 1.1952, 0.9585, 0.9375, 0.9132,\n                       0.9523, 1.1091, 0.9159, 0.9261, 0.8686, 0.9739, 0.7179, 1.0398, 1.0128,\n                       1.3605, 0.7992])),\n              ('backbone.models.0.model.layer2.3.bn1.bias',\n               tensor([-0.9309, -0.9541, -1.2096, -0.2326, -0.2520, -0.9078, -0.2014, -0.0932,\n                       -0.1461, -0.3068, -0.4981,  0.1098, -1.2566, -0.7170, -0.0981, -0.8504,\n                       -0.3800, -0.6654, -0.4966, -0.5130, -0.2902, -0.2467, -0.3705, -1.3873,\n                       -0.6822, -0.3020, -0.5174, -0.2240, -0.4245, -0.5070, -0.1690, -0.4989,\n                       -0.6071, -0.4192,  0.1206, -0.4621, -0.5813, -0.8991, -0.1473,  0.0281,\n                       -0.6427, -0.9803, -0.2742, -0.6360, -0.0482, -1.3066, -0.4713, -0.5420,\n                       -0.5573, -0.5504, -0.1507, -0.3760, -0.5852, -0.8349, -0.1248, -0.6846,\n                       -0.3543, -0.4551, -0.5470, -0.3358, -0.5636, -1.2245, -0.1912,  0.1449,\n                       -0.8429, -0.3941, -0.7020, -0.3557, -0.2802, -0.7213, -0.6587, -0.7629,\n                       -0.1349, -1.0795, -0.2394, -0.7414, -0.4892, -0.5595, -0.8879, -0.9664,\n                       -0.1987,  0.0836, -1.6969, -0.8633, -0.3701, -1.0990, -0.6074, -0.0136,\n                       -0.1813, -0.4015, -0.0553,  0.5227, -1.0935, -0.2684,  0.4379,  0.2813,\n                       -0.4015, -1.2014, -0.4745, -0.4836, -0.5789, -1.3892, -0.6221, -0.1434,\n                        0.7716, -0.1583,  0.0925, -0.5738, -0.8806, -0.4665, -0.8739, -0.5674,\n                       -0.9212, -1.9721, -0.5553, -0.3122, -0.3451, -0.4621, -0.6577, -0.3399,\n                       -0.4678,  0.0231, -0.6350,  0.0610, -0.9301, -0.4525, -0.3133, -0.1951])),\n              ('backbone.models.0.model.layer2.3.bn1.running_mean',\n               tensor([  1.5672,  -0.8981,  -3.1725,  -0.2183,  -0.6612,   0.2524,  -0.4529,\n                        -0.2642,   1.4926,   0.2550,  -0.5316,   0.2131,  -2.4400,  -2.0878,\n                        -2.6945,  -4.1031,   0.8889,  -2.9873,  -1.0939,   0.2508,  -2.1039,\n                         2.4968, -13.7114,  -5.6852,  -3.0790,  -3.3267,  -0.7884,  -1.7737,\n                        -1.3240,  -0.9656,  -0.5563,  -1.5586,  -2.5795,  -4.2798,  -0.1761,\n                        -0.7351,   0.3086,  -2.6690,  -0.9324,  -0.5939,  -3.2177,  -0.2050,\n                        -2.9317,  -4.4907,  -1.2058,  -4.6461,  -0.4004,   0.9952,  -3.7073,\n                        -2.4680,  -0.4155,  -0.1512,  -5.1123,   0.3773,   0.8295,  -0.1857,\n                         2.0774,  -1.9701,  -4.5220,  -0.5457,  -0.7486,  -4.0089,  -0.4008,\n                         1.4444,  -1.2030,  -1.7598,  -1.1611,  -4.8024,  -2.5603,   1.0971,\n                        -1.5845,  -0.5052,  -0.3282,  -4.0845,  -3.7012,   1.2678,  -1.0152,\n                        -1.5848,  -1.7390,  -0.2413,  -2.6586,   0.9189,  -5.2707,  -1.0479,\n                        -1.9102,  -0.3596,  -2.8223,   1.1404,  -4.3805,   0.8087,  -3.5667,\n                        -1.6360,  -3.5992,   0.3850,  -0.9298,   0.0328,  -0.2095,  -1.3003,\n                        -1.5391,  -1.9694,  -2.1409,  -1.8681,  -0.8490,   0.7127,   0.3429,\n                        -1.8469,  -1.9682,  -1.5118,  -0.5413,  -1.2407,  -1.9505,   0.2124,\n                        -2.2669,  -3.5678,   0.2109,   1.7891,  -0.8286,  -0.1425,  -0.6145,\n                        -1.5501,  -1.2420,  -2.1282,  -0.8605,  -0.0447,  -2.1142,  -4.1348,\n                        -3.0737,  -1.5399])),\n              ('backbone.models.0.model.layer2.3.bn1.running_var',\n               tensor([ 6.8647,  5.6899,  5.4137,  5.8962,  6.6959,  6.3916,  8.8950,  8.3789,\n                        9.4618, 11.4966,  5.3461, 10.6041,  6.5854,  8.6737,  6.3003,  4.2697,\n                        7.2956,  3.3369,  5.9069,  8.2744,  7.2282, 16.9423,  2.4124,  3.1177,\n                       21.4189,  5.3176,  6.1143,  8.2376,  8.0443,  8.0947,  6.3035,  6.7144,\n                        6.5512,  5.1995, 11.7608,  7.0387,  6.1707,  5.1462,  6.8206,  7.0827,\n                        6.4760,  5.1741,  9.2563,  4.5187,  5.8788,  3.1247,  4.9453,  6.5751,\n                        5.5449,  5.4630,  9.6486,  6.6899,  5.6441,  3.8851,  8.6527,  7.8849,\n                        7.9624,  6.6947,  5.7857,  6.4824,  6.1870,  2.2943,  7.9412,  8.8634,\n                        6.0724,  6.9611,  8.1614,  5.6632,  3.9032,  4.5595,  6.4374,  4.3493,\n                        6.7659,  5.2397,  7.3675,  5.2284,  8.1358,  6.6612,  6.0449,  6.4375,\n                        8.5356, 10.7306,  2.8530,  4.8322,  7.0043,  4.2816,  6.6173,  6.4374,\n                        5.8339,  7.7676,  7.3409,  5.5201,  4.7893,  8.6576, 10.1660,  9.2159,\n                        6.1297,  4.5458,  4.9410,  5.2205,  5.4162,  5.3394,  7.5009,  8.2484,\n                       12.3174,  3.0230,  5.4662,  5.6994,  4.1917,  5.7089,  4.8378,  5.1391,\n                        2.4446,  2.4570,  5.1324,  7.0234,  5.9108,  5.6390, 16.7302,  5.7767,\n                        8.5349,  8.4036,  4.7797,  5.4331,  4.1193,  6.0607, 17.3177,  4.9235])),\n              ('backbone.models.0.model.layer2.3.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.3.conv2.weight',\n               tensor([[[[-1.3814e-02,  3.2598e-03, -1.9428e-02],\n                         [-4.7672e-02, -1.4207e-01, -6.0412e-03],\n                         [-4.3301e-02, -1.1729e-02, -4.6630e-02]],\n               \n                        [[ 8.3195e-02,  1.5261e-01,  1.0853e-01],\n                         [ 5.7992e-02, -1.6348e-01,  2.8954e-02],\n                         [ 8.4196e-02,  3.8392e-02,  5.1153e-02]],\n               \n                        [[ 2.9520e-02,  2.1502e-02,  4.2048e-02],\n                         [ 6.3537e-02, -1.2332e-01,  2.3447e-02],\n                         [ 3.6014e-02, -7.8472e-02,  2.0291e-02]],\n               \n                        ...,\n               \n                        [[ 3.4060e-02,  6.6553e-02,  4.4874e-02],\n                         [ 5.3232e-02, -1.1620e-01,  7.8252e-02],\n                         [-1.4940e-02, -2.7180e-02,  5.6128e-03]],\n               \n                        [[-1.1095e-01, -4.6911e-02, -4.6106e-02],\n                         [ 6.9572e-02,  1.3539e-01,  2.7363e-02],\n                         [-9.1781e-03,  1.0423e-01, -2.7091e-02]],\n               \n                        [[ 3.6144e-02,  1.3069e-02,  7.6090e-02],\n                         [ 1.9101e-02,  4.3128e-02,  3.4438e-02],\n                         [-4.7343e-03, -1.9211e-01,  7.0738e-03]]],\n               \n               \n                       [[[ 1.1979e-04, -5.9091e-04, -1.7662e-03],\n                         [-5.2646e-03, -6.7419e-02,  2.1911e-02],\n                         [-3.1787e-02, -2.1482e-02,  2.1151e-02]],\n               \n                        [[ 3.6063e-03,  3.2741e-02, -1.7542e-03],\n                         [ 2.2466e-02,  4.8582e-02, -5.2599e-02],\n                         [-2.1117e-03, -1.3077e-02, -4.7098e-02]],\n               \n                        [[-6.3277e-03, -1.0318e-01, -2.4573e-02],\n                         [-3.0584e-02, -8.1566e-02, -2.7490e-02],\n                         [ 1.5752e-02,  4.1185e-02,  1.1271e-02]],\n               \n                        ...,\n               \n                        [[-7.0026e-03, -7.8591e-03, -5.2632e-03],\n                         [ 1.9432e-02,  2.5989e-02,  3.1549e-02],\n                         [ 6.4913e-02,  6.7123e-02,  4.3439e-02]],\n               \n                        [[-3.3691e-02, -3.8567e-03,  2.2621e-02],\n                         [-3.1167e-02, -2.2534e-01,  3.4353e-02],\n                         [ 1.1795e-01,  6.9437e-02,  1.2459e-01]],\n               \n                        [[ 3.3367e-02,  7.0502e-02,  1.2593e-02],\n                         [-1.2136e-02, -3.7408e-02, -4.2886e-02],\n                         [-2.3162e-02, -6.5708e-02, -5.0017e-02]]],\n               \n               \n                       [[[-6.1617e-02, -6.9051e-02, -4.5501e-02],\n                         [-7.2668e-02,  1.0805e-02, -5.7420e-02],\n                         [-6.6912e-02, -6.3427e-02, -7.5861e-02]],\n               \n                        [[-7.1542e-03, -5.7532e-02, -1.7785e-02],\n                         [-7.0531e-02, -3.3095e-02, -9.2970e-02],\n                         [-5.1580e-02, -1.1239e-01, -5.9784e-02]],\n               \n                        [[-3.1413e-02, -6.5836e-02, -4.7070e-03],\n                         [-5.8676e-02, -2.0483e-02, -4.5776e-02],\n                         [-1.3178e-02, -5.3304e-02, -1.2305e-02]],\n               \n                        ...,\n               \n                        [[ 9.8818e-02,  8.2991e-02,  4.5653e-02],\n                         [ 5.5287e-02, -3.3426e-02,  6.3207e-03],\n                         [ 2.2587e-02, -1.4501e-02,  1.5288e-02]],\n               \n                        [[-5.2157e-03, -2.2420e-02,  7.1079e-03],\n                         [-1.7612e-02, -5.7530e-02,  1.7901e-04],\n                         [ 4.8334e-02,  2.8059e-02,  4.8028e-02]],\n               \n                        [[-1.8487e-02,  2.5299e-02,  1.5338e-02],\n                         [-3.6713e-03, -3.4277e-02, -1.8710e-02],\n                         [-1.5317e-02, -9.7963e-02, -3.2295e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 7.6352e-04,  2.8886e-02,  8.5293e-03],\n                         [-1.6373e-02,  3.8602e-02,  1.1636e-02],\n                         [-2.5163e-02,  2.6819e-03, -4.1412e-02]],\n               \n                        [[-6.4414e-03, -1.5503e-02, -1.4613e-02],\n                         [-4.4977e-02,  1.6336e-02,  3.2266e-02],\n                         [-3.7458e-02,  3.0029e-02,  2.1134e-02]],\n               \n                        [[-1.6352e-02, -2.9797e-02, -7.0478e-03],\n                         [-2.5503e-02, -1.5347e-02, -7.6421e-03],\n                         [ 5.7858e-03, -4.0930e-02, -4.1133e-02]],\n               \n                        ...,\n               \n                        [[ 6.4903e-02,  1.1327e-01,  7.5611e-02],\n                         [ 1.0493e-01,  1.5934e-01,  2.5177e-02],\n                         [ 9.4736e-02,  3.1516e-02, -1.5530e-01]],\n               \n                        [[-2.8938e-02, -5.5478e-02,  9.6882e-03],\n                         [-6.9219e-03,  1.7721e-02,  3.9070e-03],\n                         [ 2.2832e-02, -4.6478e-02, -2.2885e-04]],\n               \n                        [[ 2.2891e-02, -8.2223e-03, -9.9837e-02],\n                         [ 9.4591e-02, -1.1250e-01, -8.8157e-02],\n                         [ 1.0491e-02,  1.6418e-02,  8.0475e-02]]],\n               \n               \n                       [[[ 2.7483e-02, -4.9645e-02,  5.5624e-03],\n                         [ 1.0320e-01,  7.4444e-03,  9.7860e-02],\n                         [ 5.8149e-02, -8.8817e-03,  5.4002e-02]],\n               \n                        [[ 1.9180e-02, -8.6911e-03,  2.2848e-03],\n                         [-1.5185e-02,  4.9047e-02, -2.7265e-02],\n                         [ 9.3535e-03, -3.1150e-03, -5.0163e-03]],\n               \n                        [[-3.9409e-02,  2.1982e-03, -5.2326e-03],\n                         [-7.2974e-02,  3.7548e-02, -2.4615e-02],\n                         [-2.6568e-02,  3.2303e-02, -4.4090e-03]],\n               \n                        ...,\n               \n                        [[-5.2775e-03, -2.4139e-02, -2.4882e-02],\n                         [ 2.7444e-02,  4.9690e-02, -6.4012e-04],\n                         [ 4.4174e-02,  4.9560e-02,  5.6711e-03]],\n               \n                        [[-2.8047e-02,  5.7409e-02,  4.8830e-02],\n                         [-7.2681e-02, -3.1929e-02,  2.3296e-02],\n                         [-4.6979e-02, -2.6015e-02, -6.1449e-03]],\n               \n                        [[-5.4238e-02,  1.0490e-01, -4.7496e-02],\n                         [-1.6239e-02,  1.0963e-01, -1.6923e-02],\n                         [-1.6191e-02, -4.7663e-02, -3.7217e-02]]],\n               \n               \n                       [[[ 5.0573e-02,  2.6759e-02,  5.5908e-02],\n                         [ 4.9050e-02, -1.2769e-02,  4.4104e-02],\n                         [ 3.1374e-02,  1.0689e-01,  7.6664e-02]],\n               \n                        [[-2.5116e-02,  2.5856e-04,  1.3042e-02],\n                         [ 4.9892e-03,  1.6754e-02,  9.5154e-03],\n                         [ 4.3867e-03,  4.3746e-02,  1.6016e-02]],\n               \n                        [[-2.9562e-02, -5.4369e-02, -5.9050e-02],\n                         [-4.3778e-03, -1.2424e-01, -1.5050e-02],\n                         [-2.4047e-02,  1.6256e-01,  2.1539e-02]],\n               \n                        ...,\n               \n                        [[ 5.6092e-02,  5.5845e-02,  4.1870e-03],\n                         [ 1.1485e-02,  4.2153e-02, -1.0871e-02],\n                         [-1.3621e-02, -5.9682e-02, -5.8946e-02]],\n               \n                        [[ 2.1207e-03, -1.7943e-02,  4.2952e-02],\n                         [-4.9277e-02, -1.7240e-01, -4.2407e-02],\n                         [ 5.2052e-02,  1.0982e-01,  4.7332e-02]],\n               \n                        [[-1.8686e-02,  1.6242e-01,  2.2981e-02],\n                         [-9.7391e-02,  8.2678e-02, -3.5348e-02],\n                         [-6.6356e-02, -1.9422e-01, -1.1660e-01]]]])),\n              ('backbone.models.0.model.layer2.3.bn2.weight',\n               tensor([1.1111, 0.5532, 0.6535, 1.1071, 0.6858, 1.2339, 0.8731, 1.0168, 1.0578,\n                       1.3067, 0.5804, 0.7037, 0.8525, 0.6888, 0.5049, 1.4765, 1.1878, 0.8361,\n                       0.6174, 1.0084, 0.5605, 1.3508, 0.9694, 0.9318, 0.5708, 0.7290, 0.6774,\n                       0.9074, 0.7253, 1.1777, 0.5717, 0.6627, 0.7225, 0.9688, 0.6002, 1.0517,\n                       1.3310, 1.2658, 1.1235, 1.1847, 1.2123, 1.0331, 1.2350, 0.9103, 0.6334,\n                       1.4295, 1.0397, 1.0277, 0.6814, 0.7841, 1.0181, 1.0907, 0.8528, 0.8971,\n                       0.6277, 0.6427, 0.6971, 0.7427, 0.7813, 0.5040, 1.1614, 1.3607, 0.7627,\n                       1.0517, 0.5639, 1.2531, 0.9627, 1.4024, 1.2552, 0.6172, 1.1524, 0.5606,\n                       0.7701, 0.9376, 0.5061, 0.7349, 0.7551, 0.6067, 0.5896, 0.5743, 0.6771,\n                       0.9472, 0.8399, 1.1658, 1.2034, 0.9166, 1.1262, 0.7142, 1.0978, 0.6026,\n                       1.1664, 0.7091, 1.0624, 0.6937, 0.5318, 1.1938, 1.0338, 0.6615, 0.9836,\n                       1.0274, 0.8054, 0.8098, 0.9954, 1.2675, 0.6831, 1.3472, 0.9691, 0.5302,\n                       0.5842, 0.9020, 0.9957, 0.6678, 0.8925, 0.5003, 0.5753, 0.6060, 1.0409,\n                       1.2138, 0.6321, 0.9406, 1.0625, 1.2746, 0.6523, 1.2842, 0.8125, 1.3125,\n                       0.9051, 0.8017])),\n              ('backbone.models.0.model.layer2.3.bn2.bias',\n               tensor([-0.7645,  0.7053,  0.3371, -0.9328,  0.4982, -0.6801, -0.2986, -0.3651,\n                       -0.1231, -0.9504,  0.5901, -0.0205, -0.6814,  0.3424,  0.9253, -1.5779,\n                       -0.3612,  0.0691,  0.0686, -0.4616,  0.9195, -0.8047,  0.2783, -0.4770,\n                        1.0617,  0.1105,  0.0980, -0.5905,  0.0785, -0.5210,  0.6596,  0.3387,\n                       -0.0713, -0.7172,  0.4515, -0.4378, -0.8684, -0.9907, -0.5134, -0.9981,\n                       -0.6210, -0.4673, -0.8005,  0.0949,  0.4699, -1.5638, -0.2611, -0.5022,\n                        0.3685,  0.0642, -0.4316, -0.4345, -0.2612, -0.2051,  0.4275,  0.2718,\n                        1.0131,  0.0512,  0.3950,  1.2789, -0.4887, -0.7028,  0.3704, -0.4763,\n                        0.3483, -0.5748, -0.3087, -0.7660, -0.6940,  0.4804, -0.6227,  0.9751,\n                        0.1967, -0.2060,  0.8592,  0.6399,  0.0717,  0.4606,  1.3710,  0.8404,\n                        0.3216, -0.3219,  0.0913, -0.5365, -0.5918, -0.2061, -0.3168, -0.0947,\n                       -0.4706,  0.6918, -0.9606, -0.0360, -0.4914,  0.4289,  0.9498, -0.6798,\n                       -0.1176,  0.1199, -0.7832, -0.0886,  0.0233, -0.1805,  0.9618, -0.2718,\n                        0.9790, -0.6049, -0.2816,  1.0715,  0.9769, -0.2476, -0.3564,  0.0120,\n                       -0.0635,  0.7704,  0.7150,  0.3039, -0.4048, -0.3925,  0.2229, -0.2349,\n                       -0.5348, -0.5353,  0.3545, -0.6259,  0.1970, -0.6741, -0.3111,  0.0881])),\n              ('backbone.models.0.model.layer2.3.bn2.running_mean',\n               tensor([-0.4695, -0.9092, -0.4445, -0.4783,  2.7944, -0.6325, -0.4133, -1.0290,\n                       -0.9089, -0.8569, -0.5483,  0.0906, -0.5350,  0.4583, -0.3253, -1.8450,\n                       -0.9792, -0.3126, -0.4859, -0.5596, -0.5446, -1.6813,  0.1128, -0.6767,\n                        0.3165, -0.4952, -0.2970, -0.4604, -0.7922, -0.6470, -0.6624, -0.4966,\n                        0.3319,  0.2703, -0.6624, -0.5969, -1.1511, -0.7924, -0.6432, -0.6161,\n                       -0.7158, -0.4433, -1.4992, -0.1638, -1.1552, -1.4886, -0.5213, -0.5833,\n                       -1.0523, -0.6802, -0.7871, -0.7842, -0.3861, -0.5971, -0.7077, -0.3495,\n                        0.8172, -0.1772, -1.7554, -0.8486, -0.5604, -0.8005, -1.0823,  0.1569,\n                       -0.6624, -0.8715, -0.4887, -1.0388, -0.6580,  0.2043, -0.9224, -0.1929,\n                       -1.1306, -1.1570,  0.2816, -0.0550, -0.3558, -1.1904,  1.4447, -0.8546,\n                       -1.3059, -0.3872, -0.7004, -0.9308, -0.6504, -0.6022, -0.4362, -0.4187,\n                       -0.5156, -0.4350, -0.4113,  1.2153, -0.3206, -0.6460, -0.4467, -1.1515,\n                       -0.5935, -1.3426, -1.0640, -1.1098, -0.8884, -0.4202, -0.7769, -1.0131,\n                        3.1180, -0.5423, -0.2056,  0.0057,  1.5249, -1.0262, -0.5678, -0.0535,\n                       -0.2022, -0.2071, -0.4159, -0.6324, -0.7599, -0.9157, -0.7639, -0.5695,\n                       -0.2847, -1.0032, -0.5928, -1.2042, -0.6220, -1.0021, -0.2500, -0.8252])),\n              ('backbone.models.0.model.layer2.3.bn2.running_var',\n               tensor([0.8176, 1.2103, 1.8424, 0.8307, 2.1407, 1.3977, 1.1772, 1.3057, 1.7197,\n                       1.1511, 0.9622, 0.9788, 0.7732, 3.2073, 0.9506, 0.7044, 2.1843, 1.0466,\n                       0.9738, 1.4707, 1.0214, 1.7398, 1.6827, 0.6140, 1.1091, 1.2313, 0.6659,\n                       0.9077, 1.3985, 1.5557, 1.5666, 1.3803, 1.3334, 0.9431, 2.2286, 1.1459,\n                       1.5507, 1.0507, 1.6301, 0.7592, 1.4094, 1.2673, 1.6260, 1.8642, 1.6162,\n                       1.3178, 1.4682, 0.9247, 1.3092, 1.3829, 1.4575, 1.2788, 1.1482, 1.3800,\n                       1.2353, 1.7071, 1.5623, 1.0699, 2.0120, 1.3228, 1.6304, 2.2576, 2.1953,\n                       1.0579, 0.9969, 2.1926, 1.2058, 2.1699, 1.4019, 1.3063, 1.6305, 1.3258,\n                       2.1420, 2.0051, 1.1604, 1.6584, 1.0961, 1.1414, 1.8563, 1.0252, 1.7589,\n                       1.1613, 1.5339, 1.3580, 1.5481, 1.3129, 1.7780, 0.8299, 1.4411, 1.0235,\n                       1.0994, 1.1141, 1.5536, 1.0547, 1.0525, 1.6117, 1.5182, 1.5154, 1.0640,\n                       2.7947, 2.2384, 0.8516, 1.8723, 1.9468, 1.2038, 2.0114, 1.2718, 2.1700,\n                       1.5063, 0.6935, 1.3369, 1.0854, 1.3125, 0.9912, 1.2938, 1.2692, 1.3928,\n                       2.4580, 1.6041, 1.5740, 1.5638, 2.5611, 1.5924, 2.3906, 1.5201, 1.6325,\n                       1.2549, 1.0804])),\n              ('backbone.models.0.model.layer2.3.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer2.3.conv3.weight',\n               tensor([[[[ 0.0078]],\n               \n                        [[ 0.0578]],\n               \n                        [[ 0.1183]],\n               \n                        ...,\n               \n                        [[-0.0272]],\n               \n                        [[-0.0204]],\n               \n                        [[ 0.0484]]],\n               \n               \n                       [[[ 0.0949]],\n               \n                        [[-0.0187]],\n               \n                        [[-0.0570]],\n               \n                        ...,\n               \n                        [[-0.1286]],\n               \n                        [[-0.0169]],\n               \n                        [[-0.0239]]],\n               \n               \n                       [[[-0.0179]],\n               \n                        [[-0.0162]],\n               \n                        [[-0.0040]],\n               \n                        ...,\n               \n                        [[ 0.0070]],\n               \n                        [[-0.0060]],\n               \n                        [[-0.0182]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0020]],\n               \n                        [[-0.1245]],\n               \n                        [[-0.0205]],\n               \n                        ...,\n               \n                        [[ 0.1099]],\n               \n                        [[-0.0932]],\n               \n                        [[-0.0128]]],\n               \n               \n                       [[[ 0.0150]],\n               \n                        [[-0.0721]],\n               \n                        [[ 0.0420]],\n               \n                        ...,\n               \n                        [[ 0.0116]],\n               \n                        [[-0.0417]],\n               \n                        [[ 0.1341]]],\n               \n               \n                       [[[-0.0193]],\n               \n                        [[-0.0849]],\n               \n                        [[-0.0053]],\n               \n                        ...,\n               \n                        [[-0.0046]],\n               \n                        [[ 0.0149]],\n               \n                        [[-0.0492]]]])),\n              ('backbone.models.0.model.layer2.3.bn3.weight',\n               tensor([ 5.9501e-01,  9.6756e-01, -1.6063e-02, -2.3415e-01, -1.7379e-01,\n                       -1.4318e+00, -1.5940e-01, -1.9370e-01, -1.4103e+00,  8.8768e-01,\n                        4.6723e-01,  3.9022e-01, -4.6943e-01,  3.2162e-02, -7.5681e-01,\n                        1.9478e-01, -6.4897e-01, -5.5231e-03,  6.5326e-01,  6.1969e-01,\n                        6.1943e-01, -6.9626e-01, -1.8487e-01,  3.1050e-02, -9.8105e-01,\n                        4.4285e-01,  5.9655e-02, -2.4670e-01, -2.1221e-01, -8.4853e-02,\n                       -2.5287e-01, -1.2687e-02, -1.7179e+00, -5.5852e-01,  4.2643e-01,\n                       -1.9907e-01,  1.2715e-01, -7.5507e-01, -8.8024e-01,  7.2512e-01,\n                        2.8148e-01,  9.4638e-01,  2.6184e-01, -4.5930e-01,  3.8000e-02,\n                        6.0135e-01,  7.6713e-01,  5.4182e-01,  1.1727e-01,  6.6824e-01,\n                       -2.7919e-01, -1.1964e-01, -4.5000e-01,  4.3321e-01,  2.1634e-01,\n                       -3.0709e-01, -2.1107e-01, -1.1655e-01, -3.9709e-01,  7.4337e-01,\n                        2.2594e-01,  2.8923e-03, -5.5470e-01,  2.5043e-01, -1.4931e-01,\n                       -5.6594e-01,  5.0318e-01, -2.1054e-01,  5.9655e-01, -3.1093e-02,\n                        1.0249e+00,  2.7106e-01, -4.0068e-01, -3.5765e-01,  2.2623e-03,\n                       -9.2523e-01,  6.3101e-01,  1.9864e-01, -5.3018e-01, -2.7273e-01,\n                       -9.2035e-01, -5.3602e-01,  3.5829e-02, -2.4690e-01,  7.6762e-02,\n                       -2.9844e-01,  4.3439e-01, -7.2346e-01,  1.0423e-01, -3.1881e-01,\n                       -2.8557e-01,  2.2512e-01,  8.5056e-01,  1.1515e-01,  6.8757e-01,\n                       -8.4752e-01,  6.4091e-01,  2.9043e-02,  8.7196e-01, -3.7680e-01,\n                        1.0489e+00, -4.4993e-01,  8.2351e-01,  6.3891e-01,  2.1290e-01,\n                        4.5639e-01, -1.5235e-01, -1.6863e-01, -1.0546e+00,  6.3273e-01,\n                        5.9726e-01,  8.0793e-01, -4.2459e-01, -4.1969e-01, -5.6793e-01,\n                        1.3632e-01, -2.3361e-01, -4.3542e-01, -5.4328e-02, -5.6705e-01,\n                       -9.3717e-02, -6.0523e-01,  2.8040e-01,  1.3258e-03, -4.1171e-01,\n                       -1.4854e-01, -2.3970e-01, -7.4982e-02,  5.4720e-02,  6.8561e-01,\n                       -9.6456e-01,  5.7317e-01,  5.1461e-01,  1.5755e-02,  4.1026e-01,\n                       -3.7830e-02,  3.8296e-01, -1.3439e-01,  5.9229e-01, -3.1482e-01,\n                        7.8156e-01,  5.6999e-01,  6.6631e-01, -8.9125e-01, -1.5002e+00,\n                        4.4153e-01, -5.6999e-01,  9.2070e-02, -5.3389e-01,  8.5751e-01,\n                        4.0200e-01, -6.2019e-01,  6.4542e-01,  5.1473e-01, -2.9751e-01,\n                        8.8014e-02, -3.0024e-01,  3.0735e-01, -7.8833e-01,  4.7589e-01,\n                       -9.4855e-01, -1.2938e-01, -3.5090e-01, -1.9543e-01,  1.2216e+00,\n                       -8.2232e-01,  9.5066e-01, -1.8473e-01,  5.0660e-02, -4.9055e-03,\n                       -4.4585e-01,  5.9816e-01, -7.8869e-01,  1.9498e-01,  5.2479e-01,\n                       -9.9051e-02,  6.1500e-01,  2.9623e-01,  8.2196e-02,  5.8297e-01,\n                        5.5783e-01, -4.9470e-01, -1.0419e-01,  8.9041e-02,  1.8122e-01,\n                        2.9440e-01,  1.6298e-01, -3.0178e-01,  6.0125e-01,  1.1352e+00,\n                        1.1470e+00,  1.5539e-01,  1.7909e-01,  3.6743e-01,  3.9164e-02,\n                        9.2711e-01,  8.5117e-01,  5.4612e-01, -5.4506e-01, -1.3771e-01,\n                        1.0163e-01, -1.8265e-01, -1.2540e+00,  2.0153e-01, -6.4002e-01,\n                       -7.5106e-02, -7.5278e-01,  1.2683e-01,  7.7283e-01,  4.2611e-01,\n                       -5.3835e-04,  2.1767e-02, -6.2144e-01, -7.5169e-01, -8.0291e-01,\n                        4.3790e-01, -5.3026e-01, -7.7464e-01, -9.0048e-01, -9.3990e-01,\n                        8.6079e-01, -3.0100e-01, -3.0598e-01, -1.0755e+00,  1.0164e-01,\n                        7.1937e-01, -2.4040e-01, -3.0796e-01,  1.1025e+00,  5.3437e-01,\n                       -4.6039e-01,  9.4001e-01, -7.5125e-01, -2.1821e-01, -4.1834e-02,\n                        3.6841e-01, -1.1112e+00,  5.7380e-01,  6.2675e-01,  7.5748e-01,\n                        6.0174e-01,  2.3323e-01, -3.7632e-01,  3.4549e-01,  3.1142e-01,\n                       -5.0475e-01,  1.8936e-01,  1.1164e+00,  5.1479e-02,  2.7255e-01,\n                        4.0929e-01, -5.2787e-01, -6.5424e-01,  8.1256e-01, -4.3921e-01,\n                        5.0099e-01,  1.1518e+00, -7.2523e-01,  5.5462e-01,  1.7798e-01,\n                       -2.4513e-01, -1.4673e-01,  6.7253e-01, -7.3659e-01, -3.0509e-01,\n                       -2.6192e-01, -1.3693e-01, -6.1792e-01, -6.3358e-01, -7.1541e-01,\n                        5.4554e-01, -7.0059e-01, -5.1771e-01, -9.6653e-02,  4.2919e-01,\n                       -4.5529e-01, -5.8469e-01,  3.5109e-01,  9.2495e-01, -1.0586e+00,\n                       -5.7975e-01, -1.6684e-01,  1.0582e+00, -1.0811e-01,  3.5408e-02,\n                       -3.7108e-01,  2.4045e-01,  8.4230e-02, -8.2957e-01, -7.0030e-01,\n                        2.0836e-01,  1.2459e-01, -4.9844e-01,  3.9759e-01,  3.0584e-01,\n                        4.4743e-01, -6.6725e-02,  4.1291e-01, -6.9917e-01, -1.8227e-01,\n                       -3.6311e-01,  3.7733e-01, -3.2138e-01,  3.8623e-01,  9.8590e-01,\n                       -6.5175e-01,  1.4306e+00,  4.7862e-01,  9.3375e-01, -3.7128e-01,\n                       -5.1017e-01, -7.0981e-01,  3.7045e-01, -8.0614e-01, -1.2021e-01,\n                       -2.2256e-01,  3.4793e-01,  2.4648e-01,  5.6046e-01,  1.4177e+00,\n                       -4.5673e-01, -7.9632e-01,  1.1875e-01, -5.9066e-01,  2.6094e-01,\n                        2.0675e-01,  8.0648e-01,  7.6829e-01, -9.7928e-01, -8.1445e-02,\n                        2.4395e-02,  5.4636e-01, -8.5145e-01,  5.9049e-02, -1.2975e+00,\n                       -2.2864e-01, -4.6282e-01, -2.7223e-01,  4.1528e-01,  1.4490e-01,\n                       -6.1467e-01,  2.3182e-01, -2.6366e-01, -1.1393e+00,  1.4461e+00,\n                        6.3957e-01,  6.7494e-01, -2.5520e-01,  1.9040e-01,  4.1304e-01,\n                       -5.9756e-01,  5.5830e-01,  3.9942e-01,  3.8719e-01, -6.1147e-01,\n                       -4.8096e-01,  6.2359e-01, -1.0318e+00,  1.1289e-02,  4.9327e-01,\n                       -1.2810e-01,  2.8894e-01,  5.6213e-01,  1.5066e-01,  2.7080e-01,\n                       -9.9676e-01, -1.9457e-01, -1.1216e-01, -8.7868e-01, -1.2146e-02,\n                        4.0954e-01,  8.9818e-01,  1.9875e-01,  1.2567e-01,  2.0539e-01,\n                        5.5973e-01, -2.0258e-01,  1.1290e+00,  4.8677e-01,  5.2199e-01,\n                        6.6779e-01,  4.2663e-01, -9.7391e-01,  3.6149e-01, -7.1459e-01,\n                        2.4962e-02,  4.8593e-01,  2.5453e-02,  1.8536e-01,  7.7774e-01,\n                        5.4595e-03,  3.0276e-01, -2.0073e-02, -1.9124e-01, -6.7285e-01,\n                       -4.9246e-01,  2.8514e-01, -7.9443e-01,  2.2557e-01, -4.9834e-01,\n                        3.9214e-01, -8.7248e-01, -2.1635e-01, -1.6462e-01,  6.1535e-01,\n                       -6.3143e-02,  1.1995e-03, -3.0738e-01,  5.1071e-01, -8.7797e-02,\n                       -2.9916e-01,  6.8784e-02, -1.2581e+00, -1.3896e+00,  2.2803e-02,\n                        2.1389e-01,  8.6959e-01, -6.3753e-01, -2.2307e-01, -6.0078e-01,\n                       -6.2136e-01, -1.1330e-01, -1.1771e-02,  2.3686e-02,  1.4423e-01,\n                        2.8906e-01, -7.1060e-01,  9.9680e-01,  6.5657e-02, -4.3104e-01,\n                       -4.6401e-01,  7.9652e-01, -8.4013e-01, -2.7780e-02, -6.1292e-02,\n                       -5.2496e-01, -6.1101e-01, -1.1059e-01,  5.4127e-01, -1.4235e+00,\n                        9.0571e-01,  1.8633e-01, -5.4551e-01,  1.2855e-01,  9.0421e-01,\n                        1.5161e-01, -5.7996e-01, -4.8507e-01, -2.4337e-01, -9.1368e-01,\n                       -9.1883e-01, -8.9574e-01, -3.0731e-01,  7.9170e-01,  2.8074e-01,\n                       -3.1545e-01,  7.9286e-01, -7.3601e-01, -8.6676e-01, -1.0808e+00,\n                       -1.9615e-01,  7.0695e-01, -6.2437e-01, -1.0205e-01, -2.8714e-01,\n                        3.5269e-02, -5.4818e-01,  3.6196e-01,  7.6057e-02,  4.7842e-01,\n                       -2.1905e-01,  4.8802e-02,  3.9313e-03,  1.8275e-01, -9.4377e-01,\n                        3.8715e-01, -1.0106e-02, -3.1148e-01,  1.5941e-01, -2.5391e-01,\n                        1.2411e-01,  2.0783e-02, -4.8531e-01,  1.0170e-01,  4.0730e-01,\n                        1.2306e+00,  6.6843e-01,  1.4963e-01,  4.4823e-01,  1.4047e-01,\n                       -1.1065e+00, -8.8172e-02,  9.1317e-01,  2.8178e-01,  2.8075e-01,\n                        1.5820e-01, -2.4758e-01, -4.5616e-01,  3.4119e-01,  1.6042e-01,\n                        7.5887e-01, -1.0351e+00, -1.5621e-01,  5.4281e-01, -1.6440e-02,\n                       -2.7743e-01,  2.1913e-01,  5.3992e-01,  8.0859e-01, -5.8624e-01,\n                        1.6961e-01,  1.6132e-01])),\n              ('backbone.models.0.model.layer2.3.bn3.bias',\n               tensor([ 1.4796e-01, -5.9776e-01,  5.5951e-02, -1.9008e-01,  1.8339e-01,\n                       -8.9509e-01, -1.6193e-01,  1.4037e-01, -8.0768e-01, -5.0621e-01,\n                       -1.7168e-01,  1.0613e-01,  4.7918e-01, -1.9503e-01, -7.9474e-02,\n                       -1.0689e-01, -1.3136e-01, -2.9486e-01, -4.3284e-01,  2.1907e-01,\n                       -4.1236e-01,  4.9778e-01, -1.1775e-01,  2.0321e-01, -3.9282e-01,\n                        4.4238e-01,  2.4165e-01,  1.6293e-01,  2.7799e-02,  2.4713e-01,\n                        3.4897e-02,  1.4661e-02, -1.2305e+00, -1.5693e-01,  1.4838e-01,\n                        4.2392e-02,  1.1121e-01,  3.1539e-01,  2.4112e-01,  1.0419e-01,\n                        1.5256e-01, -1.1206e+00,  4.4973e-02,  2.5168e-02,  1.1868e-01,\n                       -5.2511e-01,  2.5426e-01, -1.2386e-01,  7.6976e-02, -2.8426e-01,\n                       -3.0564e-01,  6.5192e-03,  2.0877e-02, -3.7506e-01, -1.0334e-01,\n                       -5.2385e-02, -9.1790e-02,  1.3274e-01, -3.1003e-01, -1.3799e-01,\n                       -2.6670e-01,  2.4587e-02, -6.0495e-01, -3.1531e-01, -1.0673e-01,\n                       -4.1228e-01, -5.0698e-01,  2.0527e-01, -4.2533e-01,  7.3822e-03,\n                        1.2200e-01, -9.7472e-02, -7.4490e-01, -4.1786e-01,  1.5866e-01,\n                       -9.9421e-02, -3.0752e-01, -2.0475e-01,  2.0695e-01,  6.0513e-02,\n                       -5.8703e-01, -5.6592e-01,  2.4331e-01,  6.1654e-02,  1.9161e-02,\n                       -1.2657e-01,  2.1629e-02,  2.3185e-01,  2.6908e-01,  2.5577e-01,\n                       -3.4718e-01,  2.3289e-02,  3.7644e-01, -8.3587e-02, -4.3401e-01,\n                       -1.8969e-02, -7.7510e-01,  2.1029e-01,  3.3916e-01, -4.6494e-01,\n                       -4.1585e-01, -3.4307e-01, -4.2543e-01, -4.0205e-01,  3.7987e-03,\n                       -5.2548e-01, -6.5737e-02,  2.4865e-01, -9.4517e-01,  1.0237e-01,\n                       -1.5717e-01, -5.2989e-01,  2.9298e-01, -1.0864e-01, -4.9327e-01,\n                       -5.1033e-02,  1.8797e-01, -2.1143e-01, -3.5831e-01, -2.8402e-01,\n                       -9.9752e-02, -7.4266e-01,  1.3845e-01,  2.3461e-02,  2.3606e-01,\n                       -5.3055e-02, -1.3884e-01,  8.6581e-02,  1.0268e-01, -2.4680e-01,\n                       -2.5309e-01,  1.1443e-01,  5.2301e-01,  6.3122e-02, -9.5030e-02,\n                        1.2719e-02, -2.9701e-01, -3.2370e-01, -9.5292e-02, -2.3396e-01,\n                        5.4171e-02,  5.5056e-01, -2.1248e-01, -5.9238e-02, -9.2751e-01,\n                       -2.6255e-01,  5.1441e-02,  1.8286e-01, -1.4226e-01,  5.6260e-01,\n                        3.0303e-01,  3.8545e-01,  2.0201e-01, -3.4538e-01,  2.2557e-01,\n                        2.6375e-01, -3.0839e-01,  1.8940e-02, -3.1448e-01, -3.3138e-02,\n                       -4.5681e-02,  7.5816e-02,  2.3061e-01, -6.6145e-02, -9.8786e-01,\n                       -4.6304e-01, -8.6810e-01, -2.4448e-01,  1.3484e-01,  4.0756e-01,\n                        2.0731e-01,  4.5195e-01, -6.8812e-02,  1.0905e-01, -7.5126e-01,\n                       -4.9537e-02,  1.8241e-02, -1.7187e-01,  3.4220e-01, -7.6962e-02,\n                       -1.6791e-01, -5.1551e-01,  3.6704e-02, -2.6293e-01, -2.8962e-01,\n                        1.2270e-01,  2.0958e-02, -3.5580e-01,  1.1705e-01, -2.2538e-02,\n                       -5.3157e-01, -1.4640e-01,  3.8394e-02,  1.2555e-01, -3.9378e-02,\n                        4.4985e-01, -6.2692e-01,  3.6560e-01, -1.1434e-01, -1.5547e-01,\n                       -7.3486e-02, -7.7430e-02, -1.2363e+00, -1.2891e-01, -6.8562e-01,\n                       -5.7696e-02, -6.1806e-01,  2.9498e-01, -7.3458e-01,  5.3740e-02,\n                        6.6865e-02,  1.7105e-01, -5.7671e-01, -2.5356e-01, -1.8240e-01,\n                        2.9394e-01, -4.6734e-02, -4.0430e-01, -9.4486e-01, -8.6166e-01,\n                        1.0214e-01, -3.7573e-01,  3.2053e-01, -1.1026e+00,  6.3753e-02,\n                       -7.9779e-01, -2.0901e-01, -3.1083e-01,  6.8590e-02,  4.9323e-01,\n                       -1.2606e-01, -7.7470e-01,  8.0052e-02,  1.3257e-01,  2.4882e-01,\n                        2.0974e-01, -9.0794e-02, -5.6599e-01,  2.2470e-01, -4.4187e-01,\n                       -4.4975e-01, -1.5329e-02,  2.3500e-01,  1.7280e-01,  1.7872e-01,\n                        2.7527e-01, -1.3683e-01, -6.9845e-01,  4.6440e-02,  1.1326e-01,\n                        1.2195e-01, -3.9423e-01,  1.2497e-01, -5.9853e-03, -1.2973e-01,\n                       -3.8012e-01,  3.9221e-01,  9.7982e-02, -1.4266e-01,  4.1081e-02,\n                        2.2284e-01,  1.1243e-01, -9.6793e-02, -6.8086e-04, -2.4912e-01,\n                        3.5425e-01,  4.9128e-01,  4.6066e-01,  2.6034e-01, -4.7316e-01,\n                       -2.1640e-01, -1.1741e+00, -2.0134e-01, -3.3255e-01,  3.5513e-01,\n                       -6.0631e-02, -2.0915e-01,  2.5648e-01, -2.7703e-01, -8.9665e-01,\n                        4.2178e-01, -2.7357e-01, -2.8444e-01,  2.7179e-01, -1.5901e-03,\n                        1.1431e-01, -3.7290e-01,  1.6843e-01,  1.5154e-01, -1.4875e-01,\n                        1.4568e-01,  4.8445e-01,  8.4801e-02, -3.7075e-01, -3.5981e-01,\n                       -5.0312e-01, -1.3052e-01, -4.7348e-02,  2.0083e-01,  1.4736e-01,\n                       -1.8490e-01, -4.8080e-02, -7.5036e-01,  4.4260e-01,  8.0336e-02,\n                       -1.3546e-01, -9.5811e-01, -1.3124e-01, -2.8690e-01,  1.9390e-01,\n                        1.1220e-01, -4.2277e-02, -2.1282e-01, -7.6032e-01,  1.5455e-01,\n                        5.1346e-01, -3.3419e-01, -1.3171e-01,  9.1413e-02, -4.9384e-01,\n                       -2.5431e-01,  1.1896e-01,  1.2688e-01,  7.7430e-02, -1.7060e-01,\n                       -2.1776e-01, -8.1347e-01,  2.1027e-01,  5.0839e-02, -4.8619e-02,\n                       -7.2289e-02, -3.7178e-01, -3.9015e-01,  1.0309e-01, -7.7935e-01,\n                        3.0626e-01, -4.7620e-01, -1.6148e-01, -2.6833e-01,  3.0595e-01,\n                       -2.7492e-01,  5.2769e-01, -2.2923e-01, -1.0367e+00, -1.6633e+00,\n                        2.9717e-01, -4.7776e-01, -3.2143e-01,  2.6531e-01, -1.8861e-01,\n                       -6.5421e-01, -2.5897e-01, -1.4096e-01,  1.9616e-02, -1.6960e-02,\n                       -5.1240e-01,  1.5219e-01, -8.0497e-02,  1.1692e-01, -2.0679e-01,\n                       -1.6313e-02, -3.5123e-01, -7.0475e-01, -4.0031e-02, -2.3915e-01,\n                       -4.4345e-01,  2.9282e-01,  7.7846e-02, -1.8921e-01,  1.6996e-01,\n                       -2.6848e-01,  3.2135e-01, -3.8064e-02,  3.7163e-01,  1.5179e-01,\n                        5.5174e-01,  1.0747e-02,  1.4386e-01, -2.6280e-01,  2.9306e-01,\n                       -2.7927e-01, -3.3421e-01, -8.9498e-01, -2.3896e-01, -1.1136e-01,\n                        4.8546e-02,  2.9936e-01, -1.1801e-01, -6.1123e-02, -5.2122e-01,\n                       -3.9776e-03,  4.6631e-02, -1.8893e-01,  3.8654e-03,  8.3408e-02,\n                       -5.4770e-01, -3.2963e-02,  3.3555e-02, -1.7723e-01, -8.4268e-01,\n                       -6.9766e-02,  8.1835e-02, -1.5111e-01, -1.6386e-02, -5.2424e-01,\n                        1.9903e-01,  4.7171e-01, -2.8708e-01,  8.3927e-03,  3.4756e-01,\n                        2.3376e-01,  6.7576e-01, -5.4807e-01, -5.2371e-01,  3.9593e-03,\n                        7.2806e-02,  3.3308e-02, -3.3476e-02,  2.5959e-01,  3.6872e-02,\n                       -2.4503e-01,  2.3551e-01, -7.5845e-02,  7.1742e-02, -5.7109e-02,\n                        4.4781e-01, -1.9830e-01, -5.2828e-01,  4.0133e-02, -5.9195e-01,\n                       -1.4117e-02, -8.2523e-01, -1.3885e-01,  1.0532e-01,  2.6254e-02,\n                        1.4133e-01,  1.6515e-03,  2.1581e-01,  1.3071e-01, -1.2274e+00,\n                       -4.7501e-01,  2.5664e-01,  5.8372e-02,  4.8516e-01, -6.8698e-01,\n                       -1.6491e-01, -6.6875e-01,  1.4227e-02,  1.6103e-01,  3.0177e-01,\n                        3.6606e-01, -8.4212e-02,  5.8315e-01, -1.7870e-01, -4.4909e-01,\n                       -4.1358e-01,  2.0746e-01,  2.7079e-01, -4.5127e-01,  4.0684e-01,\n                       -7.4821e-03, -2.6836e-01, -6.6947e-01,  2.2290e-01, -8.1696e-02,\n                       -1.1215e-01, -1.5657e+00,  1.8488e-01,  2.6690e-01,  1.1441e-01,\n                       -2.2747e-01,  1.7842e-01,  3.1052e-02, -3.1924e-01, -6.0312e-01,\n                        1.6726e-01,  1.8770e-01, -1.5641e-01,  1.0271e-01,  2.4671e-01,\n                        3.1453e-01, -2.3783e-01, -2.3437e-01,  6.3685e-02, -1.7121e-01,\n                       -1.1349e+00, -5.6450e-01, -2.1088e-01,  9.4954e-03, -1.2301e-01,\n                       -1.3261e+00,  5.7770e-01, -2.3764e-01, -4.3699e-02,  1.1389e-01,\n                        3.6627e-01, -1.2856e-01, -2.3807e-01, -5.3329e-01, -8.0013e-02,\n                        3.2490e-02, -1.1474e-01, -1.1606e-01,  7.3697e-02, -1.8047e-01,\n                       -3.0298e-01, -2.4210e-01,  2.9907e-01, -1.8944e-01, -7.5587e-01,\n                       -2.7572e-02,  2.2936e-01])),\n              ('backbone.models.0.model.layer2.3.bn3.running_mean',\n               tensor([ 3.6311e-01, -1.0918e-01, -6.0109e-02,  8.1819e-02, -2.3251e-01,\n                        7.0288e-01, -2.8428e-01,  6.2564e-02,  7.5337e-01, -1.9689e-01,\n                        5.8797e-01, -1.1570e+00, -3.7252e-01,  2.0076e-01, -5.8824e-01,\n                        4.6058e-01,  2.9169e-02, -3.3216e-02, -5.7858e-01,  6.7965e-01,\n                        1.3117e-01, -4.6040e-01, -2.5956e-01,  2.1535e-01,  5.5496e-03,\n                       -7.8733e-02,  2.7615e-02,  1.8571e-01, -8.5580e-01,  8.3038e-02,\n                        3.2611e-01,  5.2944e-02,  2.7624e+00,  4.4918e-01,  1.8936e-01,\n                       -3.2083e-01,  2.8511e-01,  2.1956e-01,  4.2305e-01, -4.7895e-01,\n                       -7.7146e-01, -5.0760e-01,  5.8133e-01, -1.8292e-01,  5.6166e-02,\n                        1.5917e-02,  3.7503e-01, -4.9346e-01,  3.9452e-01, -2.2730e-01,\n                        2.8876e-01, -1.5510e-01, -6.2117e-01, -4.2314e-02,  2.2659e-02,\n                        5.3285e-02,  3.1795e-01, -6.8784e-02, -1.0485e-02,  1.2714e-01,\n                       -4.4399e-01, -1.1621e-01, -6.3560e-01,  2.5314e-02, -4.0572e-01,\n                       -6.7517e-02, -5.0349e-01, -1.3482e-01, -7.9766e-01, -8.3879e-02,\n                        3.6287e-01, -5.1134e-01, -2.4223e-02,  3.3565e-01,  1.3057e-01,\n                       -9.6313e-02, -1.8502e-01, -2.5327e-01, -5.8997e-01,  9.6909e-02,\n                        4.3591e-01,  8.7834e-01,  3.4927e-03,  5.6053e-01, -2.5508e-01,\n                       -3.0873e-01, -2.5833e-01,  3.5546e-01,  2.1888e-01,  3.1731e-02,\n                        2.6150e-01,  1.2465e-01,  6.9445e-01,  3.0164e-01,  6.2407e-01,\n                       -1.6003e+00, -2.4510e-01,  4.9112e-02,  2.1313e+00,  6.7438e-01,\n                        7.1726e-01,  4.5449e-01,  3.4412e-01, -9.5722e-02,  5.2663e-01,\n                        2.2356e-01,  2.9306e-02,  3.3752e-01,  2.8159e-01,  4.8401e-01,\n                       -2.5861e-01, -3.0770e-01, -5.6848e-02,  4.4713e-01,  1.0149e+00,\n                       -1.3901e-01, -1.0602e+00,  4.8843e-01, -1.5522e-01, -2.1016e-02,\n                        1.5218e-01, -2.8311e-01,  2.5250e-01,  6.6651e-02,  1.9237e-01,\n                       -1.8864e-01,  2.3505e-01, -8.8651e-02,  7.4067e-03, -1.2397e-01,\n                        1.0151e-01,  3.1994e-04,  2.4055e-01,  1.0251e-01, -1.7898e-01,\n                        3.4707e-02, -7.2927e-01,  5.3383e-01, -2.1616e-01,  1.7419e-01,\n                        1.5409e-01, -2.9101e-01, -3.3326e-01, -5.7366e-01,  4.5600e-01,\n                       -9.7039e-01, -7.6196e-01, -1.8693e-01, -7.1059e-01,  6.1639e-03,\n                       -6.9755e-01, -7.7884e-01,  5.7076e-01, -3.2360e-01, -5.5445e-01,\n                        5.5913e-01,  3.3747e-01, -5.4175e-02,  6.2159e-01, -4.9353e-01,\n                        1.6893e-02,  5.8947e-02, -8.4654e-01, -3.0339e-01, -9.9074e-01,\n                        3.9802e-01, -5.5748e-01,  3.2950e-01, -3.0577e-01, -1.2386e-01,\n                        3.3999e-02, -1.2341e-01,  3.9271e-01, -1.8663e-01, -5.4835e-01,\n                       -5.0100e-01,  5.0003e-01, -8.4223e-02,  1.9473e-02,  2.7917e-02,\n                        4.5546e-01,  3.1529e-01,  1.5939e-02,  1.2385e-01,  4.9095e-01,\n                       -5.9043e-01, -3.8679e-03,  3.4415e-01, -7.5612e-01,  1.0827e+00,\n                       -1.0628e+00,  7.1995e-01, -6.2286e-02,  9.8508e-02, -5.8059e-03,\n                       -2.1925e-01, -3.7350e-01, -3.5550e-01,  4.8463e-01,  3.2315e-01,\n                       -9.0195e-02, -3.5275e-01,  5.3508e-01,  2.5683e-01,  4.5586e-01,\n                       -2.7116e-01,  6.2514e-01,  1.6144e-01, -3.3065e-01, -8.0684e-02,\n                       -1.6066e-02,  1.5075e-01,  3.1096e-01,  4.2432e-01, -7.5289e-01,\n                        7.4689e-02,  1.3696e-01,  1.3252e+00,  1.8356e-02,  1.2598e-01,\n                        3.6103e-01, -1.5479e-02, -1.4314e-01,  1.6340e+00,  1.3450e-01,\n                       -5.5797e-01, -6.8502e-01,  3.4062e-01,  2.7699e-01, -3.5051e-02,\n                       -1.7623e-01, -5.5238e-01,  2.2340e-01, -1.8833e-01, -3.0614e-01,\n                       -4.5649e-02,  7.2498e-01, -7.6377e-01,  5.3153e-01,  2.7051e-01,\n                        4.5906e-02, -9.8826e-01,  8.3438e-01,  2.3966e-01,  7.8446e-01,\n                        2.0612e-02,  1.3225e-01, -4.4523e-01,  9.9495e-02, -5.0307e-01,\n                        1.9300e-01,  2.3003e-01, -1.3252e+00,  8.1785e-01, -1.1998e-01,\n                       -1.3210e-01,  1.0087e+00, -9.3809e-01,  3.4664e-01, -7.0502e-02,\n                        2.0915e-01, -1.7552e-01,  2.1683e-01, -3.5802e-01,  1.7066e-02,\n                        2.3317e-01, -5.7730e-02,  7.3665e-02, -3.0091e-01,  1.0956e+00,\n                       -4.3425e-01,  7.8732e-02,  2.7595e-01, -2.5470e-01, -3.9132e-01,\n                        5.7087e-02, -1.5269e-01, -5.0328e-01, -1.8912e-01,  5.8194e-01,\n                       -2.6083e-01,  1.2012e-01, -1.0677e+00, -1.2283e-01,  9.3717e-02,\n                        2.6663e-01, -7.5806e-02,  6.7629e-02, -5.0401e-01, -5.6424e-01,\n                        3.4515e-01,  9.6475e-02, -4.3809e-01, -4.0382e-02,  2.8737e-01,\n                       -6.3911e-01, -2.6225e-01,  1.2244e-02, -5.8993e-01, -3.3957e-02,\n                        3.1832e-01,  7.4963e-01,  4.2641e-01, -5.9989e-03, -4.6373e-01,\n                        6.0155e-02, -1.2008e+00,  3.2971e-01, -6.1369e-01, -2.2144e-01,\n                       -3.4904e-01,  1.1676e+00,  3.6091e-01,  2.2620e-01,  2.6145e-01,\n                       -5.1131e-01, -2.3342e-01,  1.0431e-01, -1.4217e-01, -6.5570e-01,\n                        1.4043e-01, -7.3190e-02, -1.7417e-01, -1.2069e+00, -4.2270e-01,\n                       -8.9565e-02, -4.7169e-02, -4.9661e-01, -1.3602e+00, -2.3275e-01,\n                       -2.9059e-01,  3.6767e-01,  5.0517e-01, -4.1280e-02,  5.5027e-01,\n                        4.6268e-01, -5.9772e-02,  5.3120e-01,  6.4008e-01,  3.6654e-01,\n                       -4.1338e-01, -4.7438e-01,  7.1008e-01,  4.9235e-01, -7.9575e-01,\n                        2.7095e+00, -6.4631e-01, -1.4162e-01, -5.7544e-01, -4.7695e-01,\n                        2.3710e-01, -5.3105e-02,  1.4285e-01, -4.4025e-01, -6.2401e-02,\n                       -6.9656e-01, -6.2378e-01,  3.6861e-01, -7.3482e-03,  2.3271e-01,\n                       -4.6326e-02, -8.2436e-01, -9.7132e-01, -4.2346e-01,  4.5695e-01,\n                        6.4929e-01, -5.1961e-01, -2.0749e-01, -7.7813e-01,  9.9505e-02,\n                        3.5337e-01,  1.0768e+00,  4.4980e-01, -3.8301e-01,  2.5320e-01,\n                       -3.9737e-01, -3.7532e-01,  2.5180e-01, -3.0610e-02,  2.4282e-01,\n                       -3.8977e-01,  2.7162e-01,  7.8840e-01, -3.5805e-01,  6.9295e-01,\n                       -6.1275e-02,  5.2290e-01,  2.8478e-02, -2.6979e-01, -2.0460e-01,\n                        1.8859e-01,  3.5351e-01, -7.4302e-02, -1.4970e-01, -3.5878e-01,\n                        7.3716e-01,  3.5557e-01, -7.5993e-01,  7.9913e-01,  5.1467e-01,\n                        3.3370e-02, -4.4330e-01,  5.3328e-01, -1.4372e-01,  4.0065e-02,\n                       -4.7510e-02,  8.5916e-02,  1.1107e-01, -1.9285e-02,  1.9300e-01,\n                       -3.2849e-01,  5.0436e-01,  3.4780e-01,  8.0866e-01,  4.3676e-02,\n                        3.6736e-01,  9.0220e-01, -7.0476e-01, -3.3132e-01,  6.2367e-02,\n                       -6.0168e-03, -4.5116e-01,  1.2352e-01,  4.7178e-02,  1.7211e-01,\n                        1.0213e+00,  5.3359e-02, -2.0490e-01, -1.8388e-01,  2.7363e-01,\n                       -4.1826e-01, -4.4471e-01,  2.7773e-01, -8.7703e-02,  1.3172e-01,\n                       -8.1807e-01, -3.0320e-02,  2.9568e-01,  8.3727e-01, -1.9211e-01,\n                       -1.1599e+00,  4.4383e-01, -1.2097e+00, -1.1363e-01, -5.2545e-01,\n                        6.7864e-01,  7.5939e-01,  2.6708e-01, -2.2927e-01, -3.5975e-01,\n                       -6.1999e-01, -1.1666e+00, -3.0877e-01,  2.7839e-01, -2.0735e-01,\n                        8.8878e-01,  4.4747e-01,  1.2975e-01,  9.2340e-01,  4.9380e-01,\n                        2.1644e-01, -4.4340e-01,  5.9696e-01, -1.7463e-01, -2.8372e-01,\n                        2.6713e-01, -3.9976e-01, -1.8654e-01, -2.3009e-01,  2.4980e-01,\n                       -2.0661e-01,  3.1787e-02,  1.0130e-01, -3.9200e-01,  3.6195e-01,\n                        1.3594e-01,  1.1048e-01, -4.2395e-01,  5.9191e-01,  8.4612e-02,\n                        8.9014e-02,  1.0589e-01,  9.1966e-01, -1.1112e-01,  3.4096e-01,\n                       -1.2239e+00, -4.6169e-01, -1.5145e-01,  9.0561e-01, -1.8153e-01,\n                        8.4392e-01, -3.8646e-01, -5.1231e-01,  9.1246e-01,  2.6098e-01,\n                        1.0320e-02, -1.3063e+00,  4.7612e-01, -4.0003e-01, -1.9803e-01,\n                        6.1195e-01, -3.6351e-01,  5.0682e-01,  2.5471e-01, -1.1049e-01,\n                        7.6600e-01, -4.7808e-01,  2.4627e-02, -3.3596e-01,  1.7211e-01,\n                       -2.3522e-02, -1.4070e-01])),\n              ('backbone.models.0.model.layer2.3.bn3.running_var',\n               tensor([0.2446, 0.1691, 0.0046, 0.2156, 0.1107, 0.4665, 0.0513, 0.0892, 0.4859,\n                       0.1863, 0.2710, 0.2034, 0.2305, 0.0077, 0.2761, 0.0632, 0.1769, 0.0043,\n                       0.2036, 0.2511, 0.1941, 0.2587, 0.1137, 0.0098, 0.3650, 0.2096, 0.0270,\n                       0.1477, 0.1111, 0.0341, 0.1437, 0.0030, 0.7115, 0.2959, 0.2356, 0.1039,\n                       0.0606, 0.4866, 0.4050, 0.3652, 0.2098, 0.2210, 0.1110, 0.1990, 0.0331,\n                       0.2457, 0.2898, 0.2112, 0.0935, 0.1579, 0.0586, 0.0392, 0.1775, 0.1374,\n                       0.1358, 0.1445, 0.1031, 0.0494, 0.1243, 0.2599, 0.0696, 0.0059, 0.2965,\n                       0.0812, 0.0675, 0.1896, 0.1929, 0.0980, 0.1790, 0.0087, 0.4447, 0.1193,\n                       0.1450, 0.1293, 0.0053, 0.4674, 0.3357, 0.0968, 0.4098, 0.1154, 0.3806,\n                       0.1031, 0.0199, 0.1396, 0.0645, 0.1329, 0.2030, 0.2801, 0.0523, 0.1313,\n                       0.1004, 0.1660, 0.4281, 0.0799, 0.3000, 0.3342, 0.2578, 0.0066, 0.4182,\n                       0.3003, 0.2555, 0.1417, 0.2838, 0.2061, 0.0867, 0.1643, 0.0936, 0.0858,\n                       0.3089, 0.3106, 0.1708, 0.2484, 0.1793, 0.2470, 0.1714, 0.0515, 0.1363,\n                       0.1487, 0.0229, 0.2290, 0.0310, 0.2045, 0.2721, 0.0055, 0.1930, 0.1083,\n                       0.0865, 0.0263, 0.0130, 0.3221, 0.1959, 0.2984, 0.2018, 0.0085, 0.2367,\n                       0.0152, 0.1527, 0.2902, 0.3997, 0.1109, 0.3520, 0.2994, 0.1873, 0.2705,\n                       0.6319, 0.2940, 0.3996, 0.1053, 0.3161, 0.3071, 0.1830, 0.3257, 0.3249,\n                       0.1656, 0.4207, 0.0704, 0.2929, 0.1850, 0.1749, 0.2529, 0.3439, 0.0600,\n                       0.1755, 0.3515, 0.4035, 0.2943, 0.2841, 0.0482, 0.0502, 0.0060, 0.2024,\n                       0.2671, 0.3899, 0.1313, 0.1609, 0.0523, 0.2231, 0.1545, 0.0421, 0.2327,\n                       0.2006, 0.1427, 0.0619, 0.0440, 0.1910, 0.1021, 0.0797, 0.0957, 0.4112,\n                       0.3949, 0.5044, 0.1726, 0.0716, 0.1450, 0.0101, 0.4729, 0.3187, 0.3286,\n                       0.2961, 0.0397, 0.0446, 0.1086, 0.3827, 0.1951, 0.3058, 0.0264, 0.2022,\n                       0.0512, 0.3233, 0.2191, 0.0028, 0.0073, 0.1839, 0.2631, 0.1912, 0.3598,\n                       0.2630, 0.2661, 0.1757, 0.4626, 0.4742, 0.0995, 0.1089, 0.2410, 0.0473,\n                       0.1810, 0.0898, 0.1407, 0.5480, 0.2623, 0.3623, 0.1829, 0.3421, 0.1187,\n                       0.0352, 0.1506, 0.5439, 0.1606, 0.3319, 0.3033, 0.2771, 0.1444, 0.2014,\n                       0.1562, 0.1756, 0.2563, 0.0876, 0.3738, 0.0146, 0.1452, 0.1680, 0.1817,\n                       0.2914, 0.4316, 0.2654, 0.1484, 0.5726, 0.3348, 0.2883, 0.1250, 0.0910,\n                       0.0990, 0.2917, 0.2229, 0.1720, 0.1064, 0.0861, 0.3418, 0.2911, 0.4176,\n                       0.2524, 0.1550, 0.2515, 0.0409, 0.2374, 0.3128, 0.2587, 0.1541, 0.5517,\n                       0.2744, 0.3315, 0.0634, 0.2435, 0.0928, 0.0058, 0.1674, 0.0915, 0.0339,\n                       0.5325, 0.2610, 0.2323, 0.0920, 0.2101, 0.1358, 0.0925, 0.1514, 0.0984,\n                       0.1916, 0.4420, 0.1190, 0.1306, 0.2500, 0.1189, 0.1768, 0.3986, 0.2427,\n                       0.3148, 0.2333, 0.3863, 0.1802, 0.2370, 0.3905, 0.1691, 0.2319, 0.0681,\n                       0.1085, 0.0881, 0.0790, 0.3500, 0.6264, 0.1878, 0.3887, 0.0509, 0.2371,\n                       0.0750, 0.1020, 0.2236, 0.3692, 0.5467, 0.0536, 0.0152, 0.2186, 0.3671,\n                       0.0298, 0.4348, 0.1810, 0.1674, 0.1071, 0.1180, 0.0943, 0.3948, 0.4985,\n                       0.1057, 0.2800, 0.2869, 0.3621, 0.2476, 0.0440, 0.0804, 0.3190, 0.1384,\n                       0.2324, 0.1390, 0.2199, 0.2692, 0.1721, 0.3488, 0.5770, 0.0077, 0.1412,\n                       0.0641, 0.1088, 0.2318, 0.1003, 0.0996, 0.3577, 0.1170, 0.0567, 0.3376,\n                       0.0090, 0.3486, 0.8061, 0.1413, 0.0563, 0.0773, 0.3939, 0.0916, 0.6463,\n                       0.1743, 0.3730, 0.2475, 0.2199, 0.3249, 0.2120, 0.3224, 0.0256, 0.2122,\n                       0.0144, 0.0711, 0.1735, 0.0228, 0.2016, 0.0021, 0.1226, 0.4027, 0.1211,\n                       0.0916, 0.4662, 0.0872, 0.2442, 0.1561, 0.3151, 0.0760, 0.0596, 0.1555,\n                       0.0397, 0.0075, 0.1065, 0.1606, 0.0357, 0.1591, 0.0404, 0.4859, 0.6810,\n                       0.0159, 0.0778, 0.3317, 0.2998, 0.1009, 0.2378, 0.2561, 0.0640, 0.0038,\n                       0.0036, 0.0645, 0.3050, 0.2523, 0.4002, 0.0379, 0.1298, 0.1719, 0.1470,\n                       0.3219, 0.0041, 0.0166, 0.1981, 0.3300, 0.0822, 0.2902, 0.4295, 0.2291,\n                       0.1086, 0.4070, 0.0716, 0.2463, 0.0861, 0.1604, 0.1911, 0.1112, 0.4131,\n                       0.3528, 0.4835, 0.3755, 0.2357, 0.0902, 0.1066, 0.3824, 0.3800, 0.3355,\n                       0.4774, 0.0852, 0.2231, 0.2430, 0.0746, 0.1264, 0.0253, 0.0652, 0.2010,\n                       0.0236, 0.2062, 0.0905, 0.0343, 0.0051, 0.1351, 0.3376, 0.2686, 0.0141,\n                       0.1603, 0.1115, 0.1711, 0.0834, 0.0065, 0.1849, 0.0303, 0.1361, 0.3047,\n                       0.2303, 0.0533, 0.2042, 0.1201, 0.2151, 0.0929, 0.3617, 0.0999, 0.1472,\n                       0.1327, 0.2316, 0.2700, 0.0948, 0.0481, 0.3427, 0.5083, 0.0829, 0.2149,\n                       0.0084, 0.1278, 0.0869, 0.2533, 0.3974, 0.1412, 0.1432, 0.0652])),\n              ('backbone.models.0.model.layer2.3.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.0.conv1.weight',\n               tensor([[[[ 0.0249]],\n               \n                        [[-0.0085]],\n               \n                        [[ 0.0266]],\n               \n                        ...,\n               \n                        [[ 0.0846]],\n               \n                        [[ 0.1300]],\n               \n                        [[ 0.1600]]],\n               \n               \n                       [[[ 0.0226]],\n               \n                        [[ 0.0059]],\n               \n                        [[ 0.1258]],\n               \n                        ...,\n               \n                        [[ 0.0144]],\n               \n                        [[-0.0200]],\n               \n                        [[ 0.2598]]],\n               \n               \n                       [[[ 0.0233]],\n               \n                        [[ 0.0489]],\n               \n                        [[ 0.1867]],\n               \n                        ...,\n               \n                        [[ 0.1178]],\n               \n                        [[ 0.0483]],\n               \n                        [[ 0.0329]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0122]],\n               \n                        [[-0.0529]],\n               \n                        [[-0.0262]],\n               \n                        ...,\n               \n                        [[-0.0877]],\n               \n                        [[-0.0261]],\n               \n                        [[-0.0247]]],\n               \n               \n                       [[[-0.0614]],\n               \n                        [[-0.0260]],\n               \n                        [[-0.0654]],\n               \n                        ...,\n               \n                        [[ 0.0340]],\n               \n                        [[-0.0809]],\n               \n                        [[-0.0322]]],\n               \n               \n                       [[[ 0.1092]],\n               \n                        [[ 0.0105]],\n               \n                        [[ 0.0342]],\n               \n                        ...,\n               \n                        [[ 0.3032]],\n               \n                        [[-0.0587]],\n               \n                        [[ 0.0325]]]])),\n              ('backbone.models.0.model.layer3.0.bn1.weight',\n               tensor([0.9950, 0.9241, 0.6724, 1.2668, 0.8583, 1.1159, 1.1806, 0.9556, 0.7322,\n                       0.8480, 0.9682, 0.9280, 1.0897, 0.9429, 1.0172, 0.8336, 1.2247, 0.8329,\n                       0.8145, 0.8913, 1.0578, 1.0622, 1.0430, 0.7288, 0.9032, 0.8278, 0.8654,\n                       1.1553, 0.8027, 0.7567, 0.8773, 0.9917, 0.8218, 0.8345, 0.9497, 1.0296,\n                       0.9570, 1.0165, 0.7396, 0.9272, 0.7305, 1.0897, 0.9113, 0.8473, 1.0068,\n                       1.1878, 0.8590, 1.0410, 0.8978, 0.8657, 0.6919, 0.7579, 0.9685, 0.8864,\n                       1.1378, 0.9408, 0.6773, 0.9553, 0.9404, 0.9734, 0.7004, 1.0628, 0.6295,\n                       1.0539, 0.9790, 0.6436, 0.7686, 1.0109, 0.9800, 0.8642, 0.9803, 1.0450,\n                       0.8831, 0.7290, 0.9799, 1.2775, 0.8789, 1.4407, 0.8199, 0.7945, 0.8862,\n                       0.8568, 0.9383, 0.8782, 0.8881, 1.1001, 1.0980, 0.9754, 1.1696, 0.9439,\n                       0.9846, 1.0009, 0.9139, 0.7156, 0.8971, 0.9665, 0.8062, 0.9615, 0.9577,\n                       0.7997, 0.9709, 0.7812, 0.7927, 1.0053, 0.9963, 0.6697, 1.1688, 0.8715,\n                       0.9251, 1.1362, 0.9038, 1.0430, 1.1013, 0.9972, 0.8721, 1.1010, 0.8928,\n                       1.1099, 0.8521, 1.0624, 1.2706, 0.9990, 0.7530, 0.8334, 0.9771, 0.7531,\n                       0.8754, 0.8070, 1.2191, 0.9468, 0.8704, 0.7854, 0.9149, 0.9646, 0.7442,\n                       1.0438, 0.8752, 0.8604, 0.7984, 0.9289, 0.9651, 0.8473, 0.9152, 1.0084,\n                       1.0660, 0.9816, 1.1107, 1.0035, 0.8579, 0.6815, 1.0116, 0.9442, 0.9127,\n                       0.8698, 0.9502, 1.0463, 0.8545, 0.9747, 0.9034, 0.9616, 0.9653, 1.0640,\n                       0.9374, 1.0216, 0.8666, 0.8862, 0.6538, 1.0198, 0.7501, 0.8556, 0.9458,\n                       0.9872, 1.0672, 2.0190, 0.8529, 1.1510, 0.8820, 0.8739, 1.0459, 1.0178,\n                       1.0192, 0.9969, 0.7447, 1.0417, 0.8949, 1.0534, 0.9722, 0.8623, 0.9151,\n                       1.1805, 0.8598, 0.9943, 1.0089, 0.9705, 1.1716, 0.8856, 0.7786, 1.0281,\n                       0.8666, 0.9379, 0.8414, 1.1021, 1.0430, 1.0427, 1.1775, 1.0212, 0.8722,\n                       1.1762, 0.8933, 0.8254, 0.8245, 1.2202, 0.9320, 0.8802, 0.9346, 1.0185,\n                       0.9987, 0.9100, 0.9778, 1.1396, 0.8875, 1.0119, 1.1520, 0.9764, 1.1362,\n                       1.0592, 1.3576, 0.8719, 1.2362, 1.0580, 0.9057, 0.9940, 0.9734, 0.9927,\n                       0.9264, 0.8129, 0.8057, 0.8589, 0.9787, 0.7704, 0.8168, 0.7896, 0.8834,\n                       0.8339, 0.8871, 0.7071, 1.0666, 0.9330, 0.9581, 0.8702, 1.0580, 0.8887,\n                       0.9639, 0.9192, 0.9688, 0.8087])),\n              ('backbone.models.0.model.layer3.0.bn1.bias',\n               tensor([-8.8594e-01, -5.3947e-01, -2.0174e-01, -1.5748e+00, -5.8915e-01,\n                       -1.1440e+00, -1.6195e+00, -8.0720e-01, -2.1474e-01, -4.8871e-01,\n                       -9.1493e-01, -7.4803e-01, -1.1316e+00, -8.1973e-01, -8.7306e-01,\n                       -5.1483e-01, -1.3019e+00, -3.2550e-01, -4.1122e-01, -5.9642e-01,\n                       -1.3273e+00, -1.1393e+00, -9.4359e-01, -1.6585e-01, -7.3356e-01,\n                       -3.5776e-01, -5.0704e-01, -1.2107e+00, -2.7894e-01, -1.4006e-01,\n                       -3.2011e-01, -8.4433e-01, -3.7526e-01, -2.9559e-01, -9.5621e-01,\n                       -7.9769e-01, -5.8417e-01, -1.0274e+00, -3.8831e-01, -8.2458e-01,\n                       -3.4375e-01, -1.3483e+00, -6.4990e-01, -5.3851e-01, -7.7471e-01,\n                       -1.1624e+00, -2.5339e-01, -8.2958e-01, -4.8329e-01, -3.7793e-01,\n                        2.3401e-03, -3.6492e-01, -8.0362e-01, -5.1991e-01, -1.3148e+00,\n                       -4.1835e-01, -8.5570e-02, -7.7295e-01, -5.6447e-01, -5.7657e-01,\n                       -5.0458e-02, -9.3164e-01,  2.3195e-01, -1.1199e+00, -6.7724e-01,\n                        1.2857e-01, -7.6169e-02, -8.0141e-01, -6.9781e-01, -6.7371e-01,\n                       -8.5130e-01, -1.1826e+00, -5.4462e-01, -1.7001e-01, -9.0248e-01,\n                       -1.6665e+00, -6.4219e-01, -2.3654e+00, -3.6520e-01, -3.5734e-01,\n                       -5.0703e-01, -5.2937e-01, -5.0848e-01, -5.1317e-01, -4.9226e-01,\n                       -1.1226e+00, -9.5345e-01, -9.8057e-01, -1.4876e+00, -9.4703e-01,\n                       -6.8231e-01, -7.3137e-01, -7.2738e-01, -6.9433e-02, -5.8847e-01,\n                       -6.1642e-01, -2.4047e-01, -4.8736e-01, -5.7318e-01, -3.1970e-01,\n                       -7.9052e-01, -3.3583e-01, -4.1706e-01, -8.8796e-01, -1.0144e+00,\n                       -1.9099e-02, -1.2228e+00, -4.5088e-01, -7.0883e-01, -1.5033e+00,\n                       -5.8159e-01, -1.0338e+00, -8.6956e-01, -7.2522e-01, -6.8195e-01,\n                       -1.0173e+00, -4.5885e-01, -1.3192e+00, -5.8126e-01, -9.8961e-01,\n                       -1.7784e+00, -9.5801e-01, -3.7132e-01, -5.5188e-01, -8.9538e-01,\n                       -2.5452e-01, -7.4497e-01, -2.1152e-01, -2.1518e+00, -5.6036e-01,\n                       -5.2414e-01, -2.7759e-02, -6.6728e-01, -7.3649e-01, -4.3935e-02,\n                       -8.5664e-01, -5.6882e-01, -5.6250e-01, -2.4150e-01, -8.5428e-01,\n                       -7.4395e-01, -3.7896e-01, -5.5411e-01, -8.0341e-01, -1.0589e+00,\n                       -8.1729e-01, -1.1350e+00, -8.2772e-01, -4.8660e-01, -3.0690e-01,\n                       -8.2838e-01, -8.4861e-01, -5.8538e-01, -7.5348e-01, -9.1539e-01,\n                       -7.6455e-01, -2.8835e-01, -7.9953e-01, -5.6939e-01, -4.7647e-01,\n                       -7.4944e-01, -1.5712e+00, -3.7394e-01, -7.0523e-01, -5.1583e-01,\n                       -5.2760e-01,  6.4505e-02, -1.1047e+00, -1.3543e-01, -5.4586e-01,\n                       -6.8267e-01, -8.3079e-01, -1.1687e+00, -1.2578e+00, -4.7926e-01,\n                       -1.1387e+00, -4.7794e-01, -6.8296e-01, -8.1063e-01, -9.5392e-01,\n                       -9.9534e-01, -7.9785e-01, -4.1162e-01, -7.2370e-01, -4.4696e-01,\n                       -6.3290e-01, -6.0925e-01, -4.0504e-01, -5.9646e-01, -1.4221e+00,\n                       -4.7385e-01, -9.5956e-01, -7.2641e-01, -8.5531e-01, -1.2723e+00,\n                       -4.0538e-01, -2.1324e-01, -1.0138e+00, -5.8705e-01, -9.1971e-01,\n                       -5.1545e-01, -9.3586e-01, -1.0038e+00, -1.0219e+00, -1.4889e+00,\n                       -8.8694e-01, -5.6228e-01, -1.1248e+00, -6.7860e-01, -4.0110e-01,\n                       -2.8686e-01, -1.4922e+00, -5.8904e-01, -6.1160e-01, -7.1741e-01,\n                       -9.0883e-01, -7.9170e-01, -1.0039e+00, -1.0083e+00, -1.4409e+00,\n                       -5.5778e-01, -7.7828e-01, -1.2026e+00, -1.0496e+00, -1.3331e+00,\n                       -1.2872e+00, -2.0355e+00, -6.6453e-01, -1.6650e+00, -9.2849e-01,\n                       -6.8681e-01, -7.3425e-01, -7.3235e-01, -8.2813e-01, -6.6217e-01,\n                       -4.7837e-01, -3.6916e-01, -5.7594e-01, -6.9278e-01, -3.2866e-01,\n                       -4.2436e-01, -4.2883e-01, -3.8646e-01, -5.8383e-01, -7.1471e-01,\n                       -2.6374e-01, -9.2231e-01, -7.7646e-01, -7.6979e-01, -3.5284e-01,\n                       -1.1032e+00, -3.4965e-01, -5.3543e-01, -6.7916e-01, -7.1592e-01,\n                       -3.3165e-01])),\n              ('backbone.models.0.model.layer3.0.bn1.running_mean',\n               tensor([-5.3464, -1.8464, -3.3624, -3.1306, -2.8380, -1.3354, -3.7397, -3.2097,\n                        0.0614, -3.1214, -1.3480, -1.5048, -2.7297, -2.3310, -1.4031, -0.3281,\n                       -1.5011, -3.4804, -3.0267, -2.6763, -4.3146, -3.3147, -2.7536, -2.8974,\n                       -3.7875, -1.8100, -2.9359, -3.0919, -2.7871, -1.9041, -1.2629, -3.1277,\n                       -3.7803, -3.3963, -3.8510, -0.7717, -2.6659, -4.6269, -2.2540, -1.6833,\n                       -2.2289, -4.3505, -4.1364, -4.3045,  0.8489, -2.1870, -1.6302, -2.5483,\n                       -2.6982, -1.7425, -3.7503, -0.9179, -4.9151, -0.9046, -3.4612, -4.8550,\n                       -1.3601, -2.5261, -2.9509, -5.9639, -3.0330, -1.3663,  0.9706, -2.9855,\n                       -1.0881, -0.9583, -1.1193, -4.2112, -1.7221, -3.0646, -4.5136, -2.7735,\n                       -4.6848, -1.9544, -2.8435, -4.6410, -1.2960, -4.1975, -1.6703, -1.8982,\n                       -2.5738, -2.4106, -4.2159, -3.9942,  0.0237, -2.8714, -2.2449, -3.4231,\n                       -2.2194, -4.4727, -4.2212, -2.4457, -2.1676, -2.7086, -2.8898, -0.6060,\n                       -2.3350, -4.2408,  2.2688, -3.2295, -4.1618, -3.2661, -1.4662, -1.4439,\n                       -2.9834, -4.0456, -4.2183, -2.8873, -3.5070, -4.6340, -2.5856, -3.8251,\n                       -5.5578, -3.1482,  0.9000, -4.8231,  0.4372, -2.9255, -1.3559, -1.5718,\n                       -3.5323, -1.8691,  2.1899, -2.0335,  0.3060, -0.2148, -0.3887, -2.0575,\n                       -3.6233, -3.2862, -4.0544, -4.7741, -1.0290, -5.1159, -1.7404, -3.9978,\n                       -3.4767, -2.7775, -4.1654, -2.5005, -1.7688, -5.6418, -4.5348, -3.1167,\n                       -4.3685, -4.6664, -0.8424, -2.3828, -0.4306, -3.5913, -2.3921, -2.3451,\n                       -2.4911, -2.4325, -6.1137, -3.5649, -2.3848, -1.6088, -0.9097, -1.4098,\n                       -3.8277, -3.6020, -2.9321,  0.0184, -3.3103, -0.3212, -1.3003, -1.6303,\n                       -0.5200, -0.9796, -0.2262, -4.3842, -1.7805, -6.3475, -1.3451, -4.2603,\n                       -0.6657, -0.7088, -3.4755, -0.4419, -2.0645, -2.8624, -2.9471, -0.7176,\n                       -3.2021, -2.2699, -2.5679, -4.7713, -3.9473, -0.2560, -1.3580, -4.1184,\n                       -1.2062, -3.5712, -1.8290, -4.1062,  1.0821, -6.7637, -1.3900, -4.7936,\n                       -3.9758, -2.3920, -3.9884, -2.4484, -1.3697, -1.7721, -2.6809, -2.4769,\n                       -1.6629, -2.1542, -1.2068, -4.2144, -4.5703, -3.0179, -3.9233, -0.9091,\n                       -3.3684, -4.4227, -2.3798, -0.5314, -3.5264, -3.2754, -3.4804, -1.3445,\n                       -3.6292, -3.8042, -3.8779, -3.6722, -1.6513, -1.6596, -2.1337, -3.9067,\n                       -2.6948, -0.4295, -4.2679, -2.0939, -4.1415, -3.4195, -2.1805, -1.2924,\n                       -3.3283, -2.2773, -0.7792, -1.1773, -3.4258, -1.2487, -1.6685, -4.3159,\n                       -0.8297, -4.6274, -2.2375, -0.4762, -2.4241, -0.2020, -1.0552, -3.1989])),\n              ('backbone.models.0.model.layer3.0.bn1.running_var',\n               tensor([ 9.1741, 11.2993,  8.1187,  6.4345,  7.9484,  7.3383,  5.7676,  7.8317,\n                        8.3194,  8.6107,  7.0740,  8.3598,  6.0821,  7.0712,  7.9748,  5.8850,\n                        6.8583,  9.0321, 10.4605,  6.9434,  4.8446,  8.4528,  7.8121,  8.2293,\n                        6.7986, 10.2994,  7.7316,  6.3581, 11.5384, 11.0704,  9.1026,  8.8570,\n                        9.7319, 11.5753,  6.8712,  9.4481,  8.1406,  8.0547,  6.0410,  6.3936,\n                        7.3064,  6.3676, 11.3878,  8.0127,  7.1474,  8.8705, 15.5378,  8.2219,\n                        9.7054, 11.3428, 15.5094,  8.8065,  6.4537, 15.7217,  5.9412, 11.9708,\n                       10.5138,  6.2617,  9.8122, 12.9032,  8.4843,  8.0373, 14.4864,  6.4015,\n                        7.1696, 11.3614, 12.1819,  8.5073,  9.5256,  7.5665,  8.6681,  4.8284,\n                        9.2664,  9.5391,  5.9109,  6.0890,  6.1519,  5.3985, 10.1616,  9.4546,\n                       11.6299,  9.5314, 10.0692,  9.8403, 12.7847,  5.3862,  8.5952,  7.1139,\n                        4.5648,  5.0838,  8.5856,  9.0430,  7.6076, 10.7403,  9.0020, 12.9626,\n                       12.1384, 13.9979, 13.6331,  9.6337,  6.8355,  6.4084,  8.0443,  6.8879,\n                        6.7706, 12.2899,  6.9750, 10.2522,  7.0469,  5.0259, 10.0721,  7.5006,\n                       10.9674,  9.0389,  7.0727,  7.4897, 12.6643,  5.5844,  6.6713, 11.2249,\n                        4.8668,  9.7096,  9.7853,  7.8475,  8.0205,  7.5967,  5.9365, 11.2870,\n                        3.2575, 12.1788,  8.3540, 14.7027,  9.7320, 10.3365, 10.9682,  9.1302,\n                        9.1309,  8.1730,  9.4967,  6.3971,  4.9276,  9.5870,  9.5905,  8.2397,\n                        5.9344,  9.5534,  6.2837,  4.9658, 11.3686,  9.8314, 10.1973,  5.8119,\n                       12.0881,  4.7958,  6.4648, 12.0754, 14.2921,  8.7048,  9.3580, 10.8193,\n                        6.8086,  3.2202, 13.2355, 10.2667, 10.2022, 11.9290, 10.8438,  4.4212,\n                        8.4139, 10.1705,  9.1088, 10.6835,  7.4282, 15.3961,  8.1404,  9.4453,\n                        9.2229,  9.0622, 11.4401,  7.9689,  9.1404,  6.8721,  7.4522,  9.0090,\n                       13.3670,  8.1928, 12.4171,  9.1561, 10.2810,  5.6499, 10.1809,  8.0652,\n                        8.5231,  8.8251,  5.6815,  9.4290, 10.9111,  6.8733,  8.8067,  6.0550,\n                        9.2477,  9.2217,  8.4793,  8.8185,  6.6325,  8.4742,  8.4598,  7.4110,\n                        7.4342, 10.4990,  8.1390,  5.4027,  8.1016,  6.9793,  7.3579,  7.4785,\n                        7.2139,  4.7585,  5.8946,  5.2282,  7.7699,  8.4692,  8.1006,  5.7710,\n                        6.0163,  5.9324,  4.7343,  6.5254,  6.0672,  6.8580,  8.3437,  8.0897,\n                        9.8858,  7.6289,  7.6926,  9.3032,  9.5604,  9.5792, 11.2798,  7.3007,\n                        8.6102,  7.1027, 12.2211,  6.0135,  5.7665,  6.7348,  8.4964,  5.9247,\n                       10.6794, 10.1816,  5.6590, 14.0450,  8.9720,  7.6827,  7.8754,  9.9322])),\n              ('backbone.models.0.model.layer3.0.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.0.conv2.weight',\n               tensor([[[[ 0.0182,  0.0252,  0.0106],\n                         [-0.0077, -0.0147, -0.0435],\n                         [-0.0261, -0.0714, -0.0375]],\n               \n                        [[ 0.0049,  0.0211, -0.0027],\n                         [ 0.0204, -0.0619, -0.0088],\n                         [ 0.0048,  0.0021,  0.0533]],\n               \n                        [[ 0.0570,  0.1071,  0.0514],\n                         [ 0.0271,  0.0978,  0.0920],\n                         [ 0.0236,  0.0833,  0.0491]],\n               \n                        ...,\n               \n                        [[-0.0108, -0.0522, -0.0495],\n                         [-0.0558, -0.0496, -0.1059],\n                         [-0.0589, -0.0783, -0.0882]],\n               \n                        [[-0.0505, -0.0810, -0.0309],\n                         [-0.0445, -0.0571, -0.0309],\n                         [-0.0052, -0.0550, -0.0168]],\n               \n                        [[-0.0746, -0.1465, -0.0718],\n                         [-0.0941,  0.0164, -0.1194],\n                         [-0.0581, -0.1066, -0.0521]]],\n               \n               \n                       [[[-0.0136, -0.0716, -0.0254],\n                         [-0.0550, -0.0818, -0.0351],\n                         [-0.0259, -0.0472, -0.0517]],\n               \n                        [[ 0.0118,  0.0209,  0.0327],\n                         [ 0.0574,  0.0451,  0.0336],\n                         [ 0.0167,  0.0582,  0.0646]],\n               \n                        [[ 0.0120, -0.0290, -0.0085],\n                         [-0.0492, -0.0467, -0.0176],\n                         [-0.0257, -0.0179, -0.0262]],\n               \n                        ...,\n               \n                        [[-0.0742, -0.1232, -0.0855],\n                         [-0.1121, -0.0800, -0.1007],\n                         [-0.0502, -0.0813, -0.0740]],\n               \n                        [[ 0.0039,  0.0090, -0.0145],\n                         [-0.0229, -0.0048, -0.0321],\n                         [-0.0045, -0.0125, -0.0073]],\n               \n                        [[-0.0956, -0.1461, -0.1181],\n                         [-0.0865, -0.0793, -0.1422],\n                         [-0.0729, -0.0645, -0.0566]]],\n               \n               \n                       [[[ 0.0441, -0.0278, -0.0356],\n                         [ 0.0029, -0.0155, -0.0414],\n                         [ 0.0142,  0.0098, -0.0120]],\n               \n                        [[ 0.0250, -0.0004, -0.0151],\n                         [ 0.0751,  0.0292, -0.0294],\n                         [ 0.0418,  0.0046, -0.0231]],\n               \n                        [[ 0.0396,  0.0305, -0.0263],\n                         [ 0.0422,  0.0050, -0.0190],\n                         [ 0.0143, -0.0049, -0.0477]],\n               \n                        ...,\n               \n                        [[ 0.0293, -0.0067, -0.0189],\n                         [ 0.0083, -0.0621,  0.0226],\n                         [-0.0013, -0.0136,  0.0091]],\n               \n                        [[-0.0116, -0.0213,  0.0050],\n                         [-0.0334, -0.0029, -0.0068],\n                         [ 0.0252, -0.0047, -0.0028]],\n               \n                        [[ 0.0327,  0.0472,  0.0029],\n                         [ 0.0257,  0.0017, -0.0039],\n                         [ 0.0534,  0.0357, -0.0213]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0360,  0.0420,  0.0702],\n                         [ 0.0220,  0.0273,  0.0688],\n                         [-0.0022, -0.0184,  0.0079]],\n               \n                        [[-0.0312, -0.0230, -0.0168],\n                         [-0.0068, -0.0195, -0.0104],\n                         [-0.0163, -0.0327,  0.0051]],\n               \n                        [[ 0.0590,  0.1119,  0.0775],\n                         [-0.0122, -0.0627, -0.0207],\n                         [-0.0357, -0.0781, -0.0659]],\n               \n                        ...,\n               \n                        [[-0.0491, -0.1210, -0.0833],\n                         [ 0.1237,  0.1360,  0.1816],\n                         [ 0.1011,  0.1779,  0.1230]],\n               \n                        [[-0.0099,  0.0067, -0.0112],\n                         [-0.0198, -0.0184, -0.0403],\n                         [-0.0216, -0.0636, -0.0121]],\n               \n                        [[ 0.0684,  0.1254,  0.0766],\n                         [ 0.0166,  0.0051,  0.0141],\n                         [ 0.0106,  0.0408,  0.0307]]],\n               \n               \n                       [[[ 0.0550,  0.0771,  0.0563],\n                         [ 0.0485,  0.0607,  0.0621],\n                         [ 0.0208,  0.0194,  0.0338]],\n               \n                        [[-0.0055,  0.0071,  0.0101],\n                         [ 0.0228,  0.0032,  0.0190],\n                         [ 0.0169,  0.0452,  0.0456]],\n               \n                        [[-0.0419, -0.0191, -0.0257],\n                         [-0.0064, -0.0311, -0.0132],\n                         [-0.0238, -0.0031, -0.0132]],\n               \n                        ...,\n               \n                        [[-0.0146, -0.0226, -0.0267],\n                         [-0.0179,  0.0581,  0.0077],\n                         [ 0.0318,  0.0327,  0.0053]],\n               \n                        [[-0.0406, -0.0922, -0.0697],\n                         [-0.0661, -0.1066, -0.1047],\n                         [-0.0666, -0.0794, -0.0706]],\n               \n                        [[-0.0379, -0.0485, -0.0110],\n                         [-0.0124,  0.0013, -0.0170],\n                         [-0.0463, -0.0173,  0.0027]]],\n               \n               \n                       [[[-0.0207, -0.0116,  0.0193],\n                         [-0.0033,  0.0205,  0.0163],\n                         [-0.0093, -0.0251, -0.0081]],\n               \n                        [[-0.1162, -0.1506, -0.1365],\n                         [-0.1546, -0.1303, -0.1307],\n                         [-0.0724, -0.0485, -0.0564]],\n               \n                        [[ 0.0655,  0.0675,  0.0836],\n                         [ 0.0431,  0.0283,  0.0566],\n                         [ 0.0302,  0.0448,  0.0618]],\n               \n                        ...,\n               \n                        [[ 0.0430,  0.0519,  0.0129],\n                         [ 0.0779,  0.0797,  0.0677],\n                         [ 0.0463,  0.0811,  0.0904]],\n               \n                        [[-0.0475, -0.0747, -0.0254],\n                         [-0.0814, -0.0202, -0.0430],\n                         [-0.0587, -0.0560, -0.0662]],\n               \n                        [[-0.0613, -0.0816, -0.0233],\n                         [-0.0405, -0.0241, -0.0049],\n                         [ 0.0351, -0.0191,  0.0101]]]])),\n              ('backbone.models.0.model.layer3.0.bn2.weight',\n               tensor([0.7286, 0.5955, 1.0760, 0.6601, 0.6500, 0.7560, 0.7674, 0.6343, 0.6640,\n                       0.8267, 0.9150, 0.7933, 0.6250, 0.6977, 0.6172, 0.6867, 0.6249, 0.6258,\n                       0.6048, 0.9711, 1.0958, 0.6297, 0.6513, 0.7211, 0.6064, 0.6873, 0.9529,\n                       0.9588, 0.7256, 0.6011, 0.9009, 0.9129, 1.0292, 0.7140, 0.9289, 0.7557,\n                       1.1334, 0.6379, 0.6612, 1.2315, 0.6415, 1.1476, 0.6064, 0.6822, 0.6326,\n                       0.7431, 1.0017, 0.6335, 0.7482, 0.8044, 0.6160, 0.7079, 0.7510, 0.6143,\n                       1.0146, 0.7519, 0.6730, 0.7025, 0.7106, 0.9871, 0.7163, 0.6183, 0.6302,\n                       0.8794, 0.9464, 1.0092, 0.8724, 0.5843, 0.6073, 1.0094, 0.6271, 0.6057,\n                       0.6227, 0.7959, 0.8523, 0.7772, 1.0456, 1.0001, 0.5923, 1.1320, 0.6398,\n                       0.8774, 0.5965, 0.6652, 0.9202, 0.7205, 0.9210, 0.9365, 0.6261, 0.6665,\n                       0.7755, 0.7693, 0.8814, 0.8095, 0.6057, 0.6362, 0.6236, 0.6786, 1.1319,\n                       0.6308, 0.6391, 1.1616, 0.7528, 0.6379, 0.8952, 0.7379, 0.6290, 0.5874,\n                       0.6128, 0.9920, 0.7669, 0.6066, 0.8297, 0.6696, 0.6074, 0.6239, 0.7376,\n                       0.8309, 0.9663, 1.0213, 1.0437, 1.2078, 0.7575, 0.6285, 0.6041, 0.8965,\n                       0.8804, 1.0036, 0.5843, 0.7014, 0.6026, 0.9357, 0.7256, 0.7262, 0.7730,\n                       0.5860, 0.6278, 0.9535, 0.9339, 0.9286, 1.1192, 0.9112, 0.6587, 0.7873,\n                       0.6147, 0.8570, 0.7119, 0.5898, 1.0419, 0.7028, 0.7789, 0.7800, 0.7490,\n                       0.7128, 0.5918, 0.9594, 0.7110, 0.8816, 0.8468, 0.8928, 1.1178, 0.6736,\n                       0.9935, 0.6891, 0.6778, 0.5978, 1.2210, 0.8754, 0.6744, 0.9865, 0.9388,\n                       0.5884, 0.6459, 0.9675, 0.7364, 0.5887, 0.8016, 0.6954, 0.6948, 1.0496,\n                       0.7633, 0.6267, 0.6281, 0.8263, 0.6069, 0.6962, 0.6477, 0.8792, 0.6315,\n                       0.7373, 0.6956, 0.9030, 1.4906, 1.0305, 0.6495, 0.6764, 0.8975, 0.8542,\n                       1.0132, 0.6446, 0.6960, 0.8222, 0.8789, 0.6026, 0.9200, 0.6057, 0.8706,\n                       0.7025, 0.6452, 0.6207, 0.6490, 0.6167, 0.6263, 0.9796, 0.8337, 0.6422,\n                       0.7837, 0.6088, 0.6515, 0.5847, 0.9526, 0.9692, 0.6092, 0.6428, 0.8594,\n                       0.6254, 0.9270, 0.8795, 0.6066, 0.6622, 0.7852, 0.7413, 1.2926, 0.9561,\n                       0.7155, 0.9003, 1.1858, 0.6089, 0.6175, 0.8798, 0.8064, 0.6710, 0.6912,\n                       0.8718, 0.5721, 0.8098, 1.0318, 0.6491, 1.0433, 0.6457, 0.9259, 0.7606,\n                       1.0118, 0.8032, 0.6240, 0.9852])),\n              ('backbone.models.0.model.layer3.0.bn2.bias',\n               tensor([ 7.7062e-01,  1.2151e+00, -5.8192e-01,  1.3977e+00,  1.6163e+00,\n                        5.1341e-01,  1.1421e-01,  1.1156e+00,  7.6449e-01,  2.9369e-02,\n                       -5.3133e-01,  5.2150e-01,  1.3535e+00,  5.4749e-01,  1.1393e+00,\n                        1.0717e+00,  5.8360e-01,  1.3728e+00,  9.1639e-01, -3.0751e-01,\n                       -5.2185e-01,  5.9912e-01,  1.4355e+00,  8.8940e-01,  1.4620e+00,\n                        1.1595e+00, -1.0772e-01, -4.0198e-01,  6.4474e-01,  1.6097e+00,\n                       -4.1050e-02, -1.6313e-01, -3.0263e-01,  3.8710e-01,  2.7028e-01,\n                        7.2587e-01, -1.8924e-01,  1.3822e+00,  1.0111e+00, -7.4799e-01,\n                        1.3517e+00, -3.6514e-01,  1.2252e+00,  6.7826e-01,  5.7994e-01,\n                        2.0414e-01, -1.4879e-01,  8.9711e-01,  1.6528e-01,  4.8243e-01,\n                        1.5564e+00,  5.4450e-01,  4.2618e-01,  1.1795e+00, -4.4307e-01,\n                        4.7740e-01,  6.5923e-01,  8.3461e-01,  1.3959e+00, -2.1721e-01,\n                       -7.2669e-02,  1.4320e+00,  1.7051e+00, -2.4255e-01, -2.5458e-01,\n                       -4.9389e-01, -3.6123e-02,  1.4748e+00,  1.2977e+00, -3.2404e-01,\n                        1.2115e+00,  1.0558e+00,  5.2099e-01, -3.2830e-01,  4.7077e-02,\n                        7.8360e-01, -4.1444e-01, -3.6294e-01,  1.0316e+00, -5.3192e-01,\n                        1.5983e+00,  7.2818e-02,  8.1363e-01,  3.3587e-01, -4.4075e-01,\n                        7.8522e-02, -1.8611e-01, -3.5716e-01,  1.4986e+00,  7.7828e-01,\n                        2.4831e-01,  7.0815e-01, -2.9508e-01,  2.9435e-03,  1.3388e+00,\n                        1.5539e+00,  1.2232e+00,  5.4087e-01, -4.8123e-01,  1.4062e+00,\n                        6.3080e-01, -3.6217e-01,  1.4197e-01,  6.6223e-01, -8.5824e-02,\n                        3.7220e-02,  1.1926e+00,  1.3156e+00,  1.1217e+00, -2.8599e-01,\n                        4.6492e-01,  1.0280e+00, -2.0977e-01,  7.5934e-01,  1.3452e+00,\n                        6.1543e-01,  8.6675e-01, -1.8464e-01, -1.3115e-01, -4.2072e-01,\n                       -2.6362e-01, -3.4488e-01,  4.3663e-01,  7.5231e-01,  1.3958e+00,\n                       -1.6996e-01, -1.7237e-01,  3.5669e-02,  8.3633e-01,  7.7189e-01,\n                        7.6029e-01, -5.0520e-01,  6.6196e-01,  4.1772e-01,  4.2146e-02,\n                        8.8740e-01,  1.6308e+00, -4.3398e-01, -4.2347e-01, -1.7777e-01,\n                       -3.9689e-01, -2.6199e-01,  5.3701e-01, -2.5362e-02,  9.2466e-01,\n                        4.9085e-01,  1.4860e-01,  1.4760e+00, -5.3027e-02,  5.4780e-01,\n                        7.1897e-01,  8.0259e-01,  7.1183e-03,  8.6001e-01,  1.1545e+00,\n                       -4.5665e-01,  5.9690e-01,  5.3805e-04, -1.2908e-01, -2.1876e-01,\n                       -3.7367e-01,  3.6684e-01, -4.2000e-01,  6.7326e-01,  2.0559e-01,\n                        8.9011e-01, -3.5702e-01, -1.0902e-01,  8.5994e-01, -3.0600e-01,\n                       -1.2454e-01,  1.3017e+00,  8.0728e-01, -3.0238e-01,  9.1730e-01,\n                        1.0716e+00,  4.5314e-02,  1.7666e-01,  4.8414e-01, -5.5461e-01,\n                        1.6646e-01,  7.1422e-01,  1.4618e+00,  9.5277e-01,  9.8549e-01,\n                        8.6131e-01,  5.0257e-01, -2.5126e-01,  1.2257e+00,  4.7457e-01,\n                        1.2123e+00, -2.3606e-01, -6.0224e-01, -2.8622e-01,  6.1503e-01,\n                        5.1407e-01, -2.3720e-01, -2.0764e-01, -5.8395e-01,  1.1951e+00,\n                        1.4952e+00, -2.0528e-01,  7.6784e-02,  1.2159e+00, -3.5691e-01,\n                        1.4609e+00, -1.9157e-01,  6.2247e-01,  1.2940e+00,  8.2537e-01,\n                        1.2889e+00,  1.0837e+00,  1.1585e+00, -1.5810e-02,  1.6618e-01,\n                        1.4330e+00,  5.9356e-01,  1.2075e+00,  1.6079e+00,  1.1386e+00,\n                       -1.8255e-01, -2.3409e-01,  1.3287e+00,  1.6702e+00, -1.1798e-01,\n                        4.8721e-01, -2.9563e-01, -2.0118e-01,  1.2344e+00,  5.8208e-01,\n                        6.2897e-01,  1.0628e+00, -7.3013e-01, -1.5824e-01,  6.5658e-01,\n                       -7.6605e-02, -1.4482e-01,  1.5899e+00,  8.4203e-01,  2.5460e-01,\n                       -6.2933e-02,  7.5611e-01,  5.9923e-01, -2.1087e-01,  1.2551e+00,\n                       -8.5352e-02, -2.6801e-03,  6.1560e-01, -3.0198e-01,  1.1295e+00,\n                       -3.0742e-01,  1.3112e-01, -3.2235e-01, -1.4320e-01,  8.2229e-01,\n                       -8.2979e-03])),\n              ('backbone.models.0.model.layer3.0.bn2.running_mean',\n               tensor([-0.2187,  0.3056, -0.4658,  0.8975,  0.6240, -0.2822,  0.1059,  0.6533,\n                        0.4311, -0.2321, -0.4688, -0.0379,  0.6233, -0.2215,  0.6020,  0.5254,\n                        0.1577,  0.7018,  0.1036, -0.3255, -0.3934,  0.3140,  0.2518,  0.5669,\n                        0.6682,  1.0601, -0.2636, -0.2112,  0.0034,  0.3843, -0.0700, -0.2498,\n                       -0.5660, -0.0357, -0.7032,  0.1459, -0.5875,  0.6032,  0.6432, -0.9094,\n                        0.5911, -0.6349,  0.2353,  0.2184,  0.2552,  0.0247, -0.4735,  0.4529,\n                       -0.0462, -0.2251,  0.3447,  0.4265, -0.3560,  0.3664, -0.1855,  0.1503,\n                        0.0296,  0.4338,  0.7502, -0.3015, -0.1474, -0.0626,  0.2508, -0.2679,\n                       -0.1707, -0.2299, -0.3369,  0.1541,  0.4475, -0.4697,  0.5800,  0.5398,\n                        0.0133, -0.0689, -0.0887,  0.6174, -0.4300, -0.2517,  0.3807, -0.5571,\n                        0.5945, -0.0567,  0.3414,  0.3232, -0.3506, -0.0133, -0.2189, -0.1863,\n                        0.7125,  0.2786, -0.2612, -0.0556, -0.4894, -0.0285,  0.3818,  0.7096,\n                        0.5799, -0.1083, -0.5868,  0.2402,  0.3293, -0.6535,  0.0399,  0.5684,\n                       -0.1232, -0.0756,  0.3559,  0.7379,  0.3188, -0.3652,  0.0712,  0.9060,\n                       -0.1338,  0.1826,  0.6941,  0.3415,  0.4254, -0.1743, -0.6253, -0.3235,\n                       -0.4406, -1.0471, -0.3375,  0.3724,  0.1995, -0.2158, -0.3665, -0.8210,\n                        0.1280,  0.6466, -0.2121, -0.0926, -0.3214, -0.4712,  0.0371,  0.1596,\n                        0.2232, -0.6186, -0.2397, -0.2461, -0.4564, -0.1289,  0.0481,  0.1198,\n                        0.3287,  0.0644, -0.0171,  0.0326, -0.8073,  0.1080,  0.1430,  0.8899,\n                        0.0110,  0.4875,  0.3903, -0.3318, -0.2135, -0.2884, -0.1063, -0.1403,\n                       -0.5622,  0.1360, -0.7809, -0.0680,  0.1587,  0.7127, -1.0331, -0.1438,\n                       -0.0559, -0.5301, -0.1839,  0.0070,  0.1454, -0.2148,  0.2188,  0.2506,\n                       -0.2499,  0.1443,  0.1204, -0.5600, -0.2885,  0.3538,  0.9524, -0.0097,\n                        0.2421, -0.0025,  0.0347, -0.1974,  0.0504, -0.3128,  0.3207, -0.5636,\n                       -1.0262, -0.1685,  0.1112, -0.0121, -0.0970, -0.2415, -0.2846,  0.3897,\n                        1.2124, -0.3339, -0.5169,  0.3039, -0.2323,  0.1852, -0.1956,  0.1348,\n                        0.1858,  0.5292,  0.8618,  0.4698,  0.5465, -0.8796, -0.5298,  0.6315,\n                        0.1259,  0.5633,  0.7028,  0.0517, -0.3204, -0.3475,  0.0726,  0.8139,\n                       -0.3701, -0.0484, -0.3045, -0.0644,  0.2126, -0.3018,  0.1157,  0.1727,\n                       -0.5628, -0.2043, -0.2668, -0.1870, -1.2829,  0.4297, -0.0187, -0.6350,\n                        0.1009,  0.3319,  0.1044, -0.1058,  0.1281, -0.1747, -0.8539,  0.1845,\n                       -0.2768,  0.8296, -0.4106, -0.1631, -0.4212, -0.1214,  0.2811, -0.4340])),\n              ('backbone.models.0.model.layer3.0.bn2.running_var',\n               tensor([2.0586, 1.1383, 1.1065, 1.6333, 1.3774, 1.5915, 1.0282, 1.2387, 1.3885,\n                       0.7670, 0.8919, 2.1873, 1.2512, 1.1907, 1.2181, 1.4322, 1.1561, 1.2393,\n                       0.9700, 1.2086, 1.2491, 1.0826, 1.3232, 1.6085, 1.1094, 1.8560, 0.9626,\n                       1.1640, 1.5924, 1.2297, 0.9936, 1.0075, 1.1359, 1.1005, 1.8309, 1.9297,\n                       1.9097, 1.4316, 0.9710, 1.1685, 1.3148, 1.4128, 1.2726, 1.7803, 0.9122,\n                       1.0302, 1.0785, 0.8820, 0.9136, 1.9805, 1.2125, 1.5785, 1.6281, 1.1760,\n                       1.0527, 1.3869, 1.3729, 1.4595, 1.9372, 1.2582, 1.0028, 1.2092, 1.3885,\n                       0.9900, 1.1981, 0.8669, 1.2681, 1.2202, 1.1565, 1.3826, 1.5709, 1.1634,\n                       0.9717, 0.6227, 1.1626, 2.8081, 1.2733, 0.9371, 1.0206, 1.2495, 1.5873,\n                       1.4991, 1.0392, 0.9257, 0.7396, 0.7103, 1.0416, 0.9378, 1.7050, 1.0839,\n                       1.0441, 2.0830, 0.7870, 1.0386, 1.1968, 1.2275, 1.0691, 1.2075, 1.1331,\n                       1.4459, 1.1287, 1.2038, 1.0020, 0.9788, 0.9579, 0.7941, 1.3879, 1.0376,\n                       1.1716, 1.2612, 1.7561, 1.1925, 0.7297, 1.1548, 1.1593, 0.9304, 1.4330,\n                       0.7950, 0.9416, 1.0059, 1.7088, 1.1959, 1.2845, 0.9564, 1.1997, 0.7044,\n                       0.7733, 1.4880, 0.9160, 2.1402, 0.8749, 0.7976, 1.4935, 1.4029, 1.0346,\n                       1.0743, 1.1789, 1.1431, 0.7688, 1.1879, 1.3614, 0.9634, 0.9565, 0.7810,\n                       1.1079, 2.7261, 0.6381, 1.2463, 1.2686, 0.9574, 3.1908, 3.7157, 0.7665,\n                       2.9793, 1.1680, 1.2446, 1.6079, 0.9115, 0.9952, 0.9787, 0.9061, 1.1295,\n                       1.0370, 1.1620, 0.8070, 0.9507, 1.2033, 1.1236, 1.5166, 1.1626, 0.9795,\n                       1.1386, 1.2552, 0.8830, 1.7636, 1.1193, 0.8804, 0.8549, 1.0546, 1.0339,\n                       0.9789, 0.9418, 1.3319, 2.3685, 1.1236, 1.5867, 1.2359, 0.8680, 1.2384,\n                       2.0636, 1.4517, 1.0577, 1.3205, 1.3195, 1.1364, 0.9722, 0.9758, 0.8631,\n                       0.8576, 1.3901, 1.9047, 1.1459, 1.1887, 1.0288, 0.9183, 1.0522, 0.9477,\n                       1.4671, 1.3511, 1.0167, 1.3002, 1.2212, 1.4840, 1.3930, 1.0409, 1.1564,\n                       2.1255, 1.1534, 1.2838, 1.2775, 1.1021, 1.4040, 1.2243, 1.5661, 1.1635,\n                       0.6274, 0.8812, 1.1467, 0.9845, 1.0809, 2.0072, 2.1851, 1.0059, 1.1347,\n                       1.6803, 1.1229, 1.9863, 1.1246, 1.1482, 1.5295, 0.7708, 1.2366, 1.2517,\n                       0.9082, 0.8919, 1.1680, 1.6476, 1.0141, 1.4622, 1.5303, 0.8991, 0.9355,\n                       1.3019, 0.8465, 0.8224, 1.1935])),\n              ('backbone.models.0.model.layer3.0.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.0.conv3.weight',\n               tensor([[[[-0.0177]],\n               \n                        [[ 0.1483]],\n               \n                        [[ 0.0044]],\n               \n                        ...,\n               \n                        [[ 0.0616]],\n               \n                        [[-0.1038]],\n               \n                        [[ 0.0321]]],\n               \n               \n                       [[[ 0.0649]],\n               \n                        [[-0.0553]],\n               \n                        [[ 0.0317]],\n               \n                        ...,\n               \n                        [[ 0.0790]],\n               \n                        [[-0.0414]],\n               \n                        [[ 0.0224]]],\n               \n               \n                       [[[-0.0581]],\n               \n                        [[ 0.0222]],\n               \n                        [[-0.0096]],\n               \n                        ...,\n               \n                        [[-0.0209]],\n               \n                        [[-0.0156]],\n               \n                        [[-0.0219]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0476]],\n               \n                        [[ 0.0104]],\n               \n                        [[-0.0279]],\n               \n                        ...,\n               \n                        [[-0.0703]],\n               \n                        [[ 0.0114]],\n               \n                        [[ 0.0434]]],\n               \n               \n                       [[[ 0.0610]],\n               \n                        [[-0.0236]],\n               \n                        [[-0.0334]],\n               \n                        ...,\n               \n                        [[-0.0336]],\n               \n                        [[-0.0618]],\n               \n                        [[-0.0189]]],\n               \n               \n                       [[[ 0.0693]],\n               \n                        [[ 0.0698]],\n               \n                        [[-0.0678]],\n               \n                        ...,\n               \n                        [[ 0.0076]],\n               \n                        [[ 0.1235]],\n               \n                        [[ 0.0333]]]])),\n              ('backbone.models.0.model.layer3.0.bn3.weight',\n               tensor([ 0.5373, -0.8080,  0.6894,  ..., -0.6047,  0.9180,  0.8032])),\n              ('backbone.models.0.model.layer3.0.bn3.bias',\n               tensor([-0.3600, -0.3986, -0.6099,  ..., -0.1446, -0.4085, -0.5404])),\n              ('backbone.models.0.model.layer3.0.bn3.running_mean',\n               tensor([ 0.1313,  0.4689, -1.0392,  ...,  0.2624, -1.0836, -1.2897])),\n              ('backbone.models.0.model.layer3.0.bn3.running_var',\n               tensor([0.2891, 0.6961, 0.4683,  ..., 0.6292, 0.6408, 0.4629])),\n              ('backbone.models.0.model.layer3.0.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.0.downsample.0.weight',\n               tensor([[[[ 0.0525]],\n               \n                        [[-0.0171]],\n               \n                        [[-0.0112]],\n               \n                        ...,\n               \n                        [[-0.0003]],\n               \n                        [[ 0.0030]],\n               \n                        [[-0.0391]]],\n               \n               \n                       [[[-0.0073]],\n               \n                        [[ 0.0251]],\n               \n                        [[-0.0468]],\n               \n                        ...,\n               \n                        [[ 0.0221]],\n               \n                        [[-0.0114]],\n               \n                        [[ 0.0855]]],\n               \n               \n                       [[[-0.0245]],\n               \n                        [[ 0.0268]],\n               \n                        [[-0.0971]],\n               \n                        ...,\n               \n                        [[-0.0383]],\n               \n                        [[-0.0307]],\n               \n                        [[ 0.0464]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.1391]],\n               \n                        [[ 0.0652]],\n               \n                        [[-0.0197]],\n               \n                        ...,\n               \n                        [[ 0.0064]],\n               \n                        [[-0.0239]],\n               \n                        [[-0.0393]]],\n               \n               \n                       [[[ 0.0119]],\n               \n                        [[-0.0256]],\n               \n                        [[ 0.0850]],\n               \n                        ...,\n               \n                        [[ 0.0334]],\n               \n                        [[ 0.0126]],\n               \n                        [[-0.0368]]],\n               \n               \n                       [[[-0.0412]],\n               \n                        [[ 0.0186]],\n               \n                        [[ 0.0928]],\n               \n                        ...,\n               \n                        [[ 0.0368]],\n               \n                        [[ 0.0255]],\n               \n                        [[-0.0127]]]])),\n              ('backbone.models.0.model.layer3.0.downsample.1.weight',\n               tensor([0.8318, 0.5332, 0.9850,  ..., 0.6809, 0.5876, 0.7201])),\n              ('backbone.models.0.model.layer3.0.downsample.1.bias',\n               tensor([-0.0685,  0.3148, -0.1875,  ...,  0.1208,  0.1294,  0.0995])),\n              ('backbone.models.0.model.layer3.0.downsample.1.running_mean',\n               tensor([-1.5418, -2.4052, -3.4118,  ..., -1.5168, -2.0086, -0.4213])),\n              ('backbone.models.0.model.layer3.0.downsample.1.running_var',\n               tensor([2.9054, 2.2132, 4.3840,  ..., 3.6470, 1.5797, 2.0513])),\n              ('backbone.models.0.model.layer3.0.downsample.1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.1.conv1.weight',\n               tensor([[[[-0.0042]],\n               \n                        [[ 0.0016]],\n               \n                        [[-0.0364]],\n               \n                        ...,\n               \n                        [[-0.0362]],\n               \n                        [[ 0.0504]],\n               \n                        [[-0.0675]]],\n               \n               \n                       [[[ 0.0440]],\n               \n                        [[ 0.0232]],\n               \n                        [[-0.0205]],\n               \n                        ...,\n               \n                        [[-0.0024]],\n               \n                        [[ 0.0322]],\n               \n                        [[-0.0122]]],\n               \n               \n                       [[[ 0.0239]],\n               \n                        [[ 0.0297]],\n               \n                        [[ 0.0156]],\n               \n                        ...,\n               \n                        [[-0.0099]],\n               \n                        [[-0.0004]],\n               \n                        [[-0.0067]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0211]],\n               \n                        [[-0.0186]],\n               \n                        [[ 0.0941]],\n               \n                        ...,\n               \n                        [[ 0.0430]],\n               \n                        [[ 0.0171]],\n               \n                        [[-0.0277]]],\n               \n               \n                       [[[-0.0059]],\n               \n                        [[-0.0330]],\n               \n                        [[ 0.0162]],\n               \n                        ...,\n               \n                        [[-0.1116]],\n               \n                        [[ 0.0338]],\n               \n                        [[ 0.0257]]],\n               \n               \n                       [[[-0.0679]],\n               \n                        [[ 0.0663]],\n               \n                        [[-0.0088]],\n               \n                        ...,\n               \n                        [[-0.0189]],\n               \n                        [[ 0.0046]],\n               \n                        [[ 0.0254]]]])),\n              ('backbone.models.0.model.layer3.1.bn1.weight',\n               tensor([0.9305, 0.9333, 1.0643, 0.6569, 1.0067, 1.3375, 0.9335, 0.7435, 0.7384,\n                       1.0783, 0.6264, 1.0292, 1.1982, 0.7510, 0.7340, 0.9776, 1.0370, 0.7414,\n                       0.8420, 0.6920, 1.1545, 0.7447, 0.7152, 1.0178, 0.6058, 1.1091, 0.9205,\n                       0.7021, 0.8213, 0.6865, 0.6746, 0.8050, 0.7628, 0.7836, 0.6184, 1.3313,\n                       0.6552, 0.7808, 0.8397, 0.9680, 0.7556, 1.0025, 0.8104, 1.0573, 1.1098,\n                       0.7563, 0.7283, 0.7787, 0.7954, 0.6889, 1.4455, 1.0933, 0.6623, 0.8244,\n                       1.0135, 0.8146, 0.7689, 1.2466, 0.9405, 0.8039, 1.0267, 0.9387, 0.8646,\n                       0.7880, 0.8634, 0.8057, 1.5933, 1.0447, 1.1862, 0.8000, 0.8953, 0.6336,\n                       0.6548, 0.5821, 0.7231, 0.7469, 0.6781, 0.7193, 0.6275, 0.7117, 0.8679,\n                       0.7206, 0.8847, 0.9524, 0.7191, 0.7569, 1.2028, 0.7704, 0.9537, 0.8644,\n                       0.6381, 1.2164, 0.8020, 0.7742, 1.0335, 0.7518, 1.2729, 0.8839, 0.6847,\n                       1.3463, 0.7879, 0.6537, 1.3640, 0.7201, 0.9783, 0.8426, 0.6112, 0.8358,\n                       1.2785, 1.0959, 0.8341, 0.6558, 0.8627, 0.9245, 0.9091, 0.9881, 0.9096,\n                       1.3095, 0.7956, 0.8064, 1.2991, 0.8940, 0.7752, 0.6628, 1.2213, 0.7679,\n                       1.1292, 0.8809, 0.8537, 0.8633, 0.5925, 0.8046, 0.7172, 0.7121, 1.1784,\n                       1.1699, 0.8796, 1.1251, 1.0717, 1.0843, 0.8456, 0.6248, 0.8744, 0.9830,\n                       0.9925, 0.8538, 0.7958, 0.8674, 0.7924, 0.8135, 0.9355, 1.1356, 0.9326,\n                       0.8060, 0.7048, 1.4671, 0.9694, 0.7472, 0.6994, 0.7151, 0.8249, 1.0602,\n                       0.7808, 0.9756, 0.7072, 0.4706, 0.7539, 1.0838, 0.6979, 1.0954, 0.7691,\n                       0.7825, 0.7302, 0.8656, 0.6467, 1.1842, 0.8279, 0.9246, 0.7668, 0.9120,\n                       0.7119, 0.7238, 0.8988, 1.1874, 0.7092, 1.0432, 0.6704, 0.7655, 0.7776,\n                       0.7342, 1.4413, 2.0737, 0.6723, 0.6275, 0.6181, 1.0834, 0.8589, 1.1210,\n                       1.0704, 0.7161, 1.0860, 0.6725, 1.0666, 0.7803, 0.8877, 0.9973, 1.0287,\n                       0.6856, 0.8066, 0.6856, 1.2321, 0.7750, 1.0693, 0.6599, 1.3870, 0.8190,\n                       1.4123, 0.6822, 1.4255, 1.0711, 0.9665, 0.7380, 0.9173, 1.0462, 1.2023,\n                       0.8091, 1.2312, 0.8313, 1.2477, 0.7020, 0.7294, 0.9804, 0.8564, 0.9165,\n                       0.7341, 0.8531, 0.8351, 0.9235, 0.6441, 0.7330, 0.9024, 0.7759, 0.8880,\n                       0.8972, 0.7898, 0.8968, 0.9993, 0.6826, 0.7961, 0.9058, 0.7655, 0.7177,\n                       0.6922, 0.9270, 1.9539, 0.8670])),\n              ('backbone.models.0.model.layer3.1.bn1.bias',\n               tensor([-4.7648e-01, -6.3194e-01,  1.4726e-01,  1.7537e-01,  8.0381e-02,\n                       -1.1391e+00, -1.3410e+00, -4.0481e-01, -2.7841e-01, -9.7198e-01,\n                       -1.3717e-02, -6.4496e-01, -8.8511e-01,  7.5634e-02,  2.9369e-02,\n                       -6.9098e-01, -6.8991e-01, -6.7462e-01, -4.5996e-01,  3.3537e-03,\n                       -9.3055e-01,  5.5519e-02, -1.8160e-02, -8.6114e-01,  6.6071e-02,\n                       -8.4825e-01, -3.1706e-01, -1.4137e-01, -8.0931e-01, -8.4004e-02,\n                       -3.4359e-02, -4.4127e-01, -1.9157e-01, -1.1608e-01,  3.1675e-01,\n                       -1.1533e+00,  1.4520e-01, -1.3803e-01, -1.8744e-01, -5.8045e-01,\n                       -4.3114e-02, -5.3778e-01, -1.4378e-01, -9.3267e-01, -8.7628e-01,\n                       -4.1796e-01, -7.6541e-02, -3.5691e-01, -3.2136e-02, -7.3272e-02,\n                       -8.1269e-01, -4.7071e-03,  8.9496e-02, -4.7588e-01, -7.0949e-01,\n                       -3.6349e-01, -3.6823e-01, -1.7063e-01, -3.9480e-01, -1.2826e-01,\n                       -6.0098e-01, -4.6103e-01, -3.4687e-01, -1.2814e-01, -3.7008e-01,\n                       -6.1390e-01, -2.6070e+00, -6.0985e-01, -8.2899e-01, -4.4156e-01,\n                       -1.0319e+00,  2.1066e-01, -8.8144e-02,  1.4137e-01, -8.6393e-02,\n                       -1.7528e-01, -3.9353e-02, -5.0148e-02, -4.7520e-02, -2.1528e-01,\n                       -2.0035e-01, -6.4433e-02, -1.2964e-01, -7.7149e-01, -2.8518e-02,\n                       -2.0237e-02, -7.7018e-01, -5.2049e-01, -5.6089e-01, -2.6339e-01,\n                        4.4170e-02, -3.4980e-01, -2.3982e-01, -5.8987e-02, -1.0620e+00,\n                       -2.4518e-01, -1.2434e-01, -3.0183e-01, -1.0779e-01, -1.0897e+00,\n                       -4.2929e-01, -5.3027e-02, -8.2670e-01, -2.8409e-01, -4.2022e-01,\n                       -3.4964e-01,  2.0302e-01, -5.5572e-01, -6.8857e-01, -1.0472e+00,\n                       -7.2213e-01,  4.0117e-02,  2.8793e-01, -7.7326e-01, -5.7834e-01,\n                       -4.0017e-01, -5.0838e-01, -5.2398e-01, -5.9013e-02, -2.5132e-01,\n                        1.6386e-01, -3.7036e-01, -1.5272e-01,  5.2507e-02, -1.3007e+00,\n                        1.1563e-01, -5.2290e-01, -3.6650e-01, -5.2207e-02, -2.5920e-01,\n                        6.0776e-03, -3.1262e-01, -7.3703e-02, -3.1645e-02,  2.2329e-01,\n                       -1.3594e+00, -9.4790e-02, -1.0104e+00, -1.0151e+00, -9.1939e-01,\n                       -4.7368e-01,  9.9825e-02, -4.8737e-01, -8.8709e-01, -9.8107e-01,\n                       -4.7029e-02, -1.8447e-01, -4.0136e-01, -2.8174e-01, -2.9664e-01,\n                       -5.8118e-01, -9.1448e-01, -4.8286e-01, -4.3039e-01, -7.2464e-02,\n                       -2.0157e+00, -1.4561e-01, -2.2668e-01,  1.7336e-01, -3.2221e-01,\n                       -1.8536e-01, -9.4506e-01, -5.1769e-01, -1.6057e-01,  6.5138e-02,\n                        7.3207e-01, -3.6958e-01, -1.2258e+00, -1.6667e-01, -8.0006e-01,\n                       -3.2288e-01, -4.0400e-01, -1.0359e-01, -1.5480e-01,  9.2673e-02,\n                       -1.2586e+00, -3.3196e-01, -5.1400e-01, -3.1129e-01, -1.0700e+00,\n                       -1.9955e-01, -1.0762e-01, -3.7023e-01, -1.9871e-01,  1.0725e-01,\n                       -2.8435e-01,  2.1630e-01, -3.2843e-01, -4.1311e-02, -1.5028e-01,\n                       -8.4086e-01, -5.5119e-01,  4.5706e-02,  8.7652e-02,  7.0525e-02,\n                       -7.2657e-01, -6.1818e-01, -3.9904e-01, -7.8879e-01, -5.0665e-01,\n                       -9.1329e-01,  3.1712e-02, -9.1228e-01, -9.9855e-02, -3.4726e-01,\n                       -7.3097e-01,  1.1586e-01, -1.6140e-01, -2.4081e-01, -1.9142e-03,\n                       -9.6609e-01, -8.4912e-02, -8.2641e-01,  3.9403e-01, -5.4094e-01,\n                       -2.0121e-01, -1.5164e+00, -2.1115e-01, -1.1356e+00, -4.2051e-02,\n                       -3.3032e-01, -6.0984e-02, -7.9821e-01, -3.8756e-01, -9.6588e-01,\n                       -2.2416e-01, -1.0597e+00, -3.7489e-01, -1.3877e+00, -5.8521e-02,\n                       -2.7409e-01, -9.4624e-01, -2.0410e-01, -2.2190e-01, -2.2333e-01,\n                       -5.8635e-01, -4.8689e-01, -5.0191e-01, -9.9056e-02, -1.9615e-01,\n                       -2.4773e-01, -1.0475e-01, -4.1064e-01, -5.5711e-01, -1.4761e-01,\n                       -6.7209e-01, -7.0545e-01,  6.8820e-02, -3.2868e-01, -4.7558e-01,\n                       -8.3608e-03, -5.8857e-02, -1.2558e-02, -5.3585e-01, -6.2752e-01,\n                       -1.9787e-01])),\n              ('backbone.models.0.model.layer3.1.bn1.running_mean',\n               tensor([-1.3814, -1.8896,  0.1663, -0.6468,  1.0733, -2.4985, -0.4690,  0.9046,\n                       -0.0359, -0.5214, -1.1394, -0.9354, -2.2573, -2.1249,  0.0885, -1.6162,\n                       -1.0735, -0.9171,  2.0925, -0.0741, -2.5463, -0.8627, -0.1411,  0.4106,\n                        0.9742, -0.8517, -0.6622,  1.9004,  2.1985, -1.8737,  0.6341,  0.1578,\n                       -0.3461, -3.6770, -0.1162, -2.5142, -1.1724, -0.3544, -1.4401, -1.5982,\n                       -0.2320, -2.2397,  1.1231, -4.3427,  1.6500, -0.1572, -1.1110, -1.4697,\n                       -0.0126,  0.1558, -4.9253, -3.2457,  0.3118, -0.8452, -0.8983, -1.0174,\n                       -0.0508, -1.9762, -3.3440, -1.4086, -1.8417, -2.2687, -0.6634, -2.2463,\n                       -0.5080,  0.5921,  0.4772, -2.4607, -1.5596,  0.7239, -0.8126, -0.2000,\n                        0.2597, -0.5090, -0.3740,  0.2749, -0.6514, -1.5567, -0.4083, -0.0943,\n                       -0.3049, -2.1645, -0.8778,  1.5960,  0.6056, -0.5671, -2.3079,  0.0307,\n                       -0.9901,  0.4903, -1.3615, -1.7514, -0.2263, -0.4128, -1.8431, -1.2922,\n                       -2.0670, -0.7905, -0.0947, -0.9650, -0.6729, -0.8083, -3.1264, -0.0624,\n                       -1.0663, -0.2787,  1.5156,  2.8831, -0.7306, -0.1398, -0.4996, -0.0973,\n                       -0.6554, -0.0938, -0.6535, -1.8970,  2.2040, -1.2227, -3.7064, -1.3792,\n                       -0.8324, -1.1518, -0.7954, -4.1339, -1.3523, -2.3465, -0.5273, -2.2022,\n                       -0.9638, -1.0816,  1.6614, -0.3654, -1.9119, -2.7736, -0.8019, -2.6551,\n                       -4.3740, -2.0257, -1.5800, -1.2797,  0.5717, -0.2122, -2.2828, -0.9576,\n                       -1.4746, -6.6317, -1.2753,  0.0242,  1.5894, -1.5348, -1.2463, -2.2917,\n                       -1.2012,  0.1421,  0.5626, -1.6809, -0.9011, -0.7308, -3.4753, -0.2132,\n                       -1.4515, -1.5579, -0.8719, -1.0204,  0.5823, -3.4440,  2.8022, -2.4313,\n                       -2.1942,  4.3366,  0.6313,  1.6142, -3.6286, -1.1431,  0.0548, -0.0421,\n                       -1.4695, -2.4705, -0.6752, -2.4764,  0.3112, -0.3221, -1.5265, -0.6256,\n                        0.4192,  1.8306, -1.7213, -1.2291, -0.3434, -0.9889, -0.7984, -0.6752,\n                       -0.0624, -1.9431, -0.5603, -1.1225, -1.7068,  0.8179, -1.4665, -0.3670,\n                        0.7265,  0.0236,  5.5210,  0.3218, -0.9306, -1.5401, -2.3737, -1.3228,\n                       -0.5592, -0.0708, -2.5105, -0.3931, -3.7922,  0.0136, -2.4660, -2.5066,\n                       -1.3784, -1.2889, -0.8543, -0.7593, -1.6486, -0.9108, -1.8615, -4.8243,\n                       -2.2329, -0.8127, -1.2057,  2.0175, -1.0989,  0.0673, -0.0616,  1.3656,\n                       -1.6550, -0.0437, -1.3910,  0.1983, -1.2152, -0.6833, -2.0600, -0.5409,\n                       -1.9568, -0.8139, -2.0350, -2.6734, -1.7278, -1.1809, -1.3579, -0.8381,\n                       -0.9659, -1.3543,  0.3075, -0.6953,  0.8830, -1.2233, -1.5256, -0.2939])),\n              ('backbone.models.0.model.layer3.1.bn1.running_var',\n               tensor([ 2.3438,  2.0836,  5.6079,  4.4889,  6.5651,  2.6472,  1.7277,  2.0346,\n                        3.3436,  1.7396,  3.2889,  2.8731,  3.3434,  3.6992,  3.9439,  2.6351,\n                        1.6843,  1.1628,  4.0800,  2.9091,  2.6352,  6.2699,  4.2770,  3.5086,\n                        2.3983,  2.3646,  3.5742,  2.9398,  2.0479,  2.6840,  2.4826,  2.2939,\n                        3.6047,  2.8333,  2.8731,  4.0475,  3.0270,  4.0672,  4.8879,  3.3379,\n                        5.1174,  3.2298,  4.9648,  2.9735,  3.7360,  1.9950,  3.7635,  3.1921,\n                        3.1152,  3.2957,  4.0259,  6.0168,  3.8265,  2.5990,  2.3338,  3.5593,\n                        2.7008,  7.8473,  2.6793,  4.6866,  2.6759,  3.0358,  2.9454,  4.7062,\n                        3.1236,  2.2097,  0.7999,  2.9203,  2.3409,  2.5906,  1.4821,  5.0180,\n                        3.1163,  2.7722,  2.9951,  3.5425,  3.4370,  2.8467,  2.9528,  2.5406,\n                        3.3372,  3.6215,  5.0051,  2.5064,  3.1270,  4.1221,  3.3337,  2.2951,\n                        2.9659,  3.1545,  2.4328,  7.1194,  4.0693,  4.8188,  3.5129,  3.1505,\n                       10.7972,  3.2250,  2.6050,  1.4124,  1.6654,  3.4694,  4.6200,  2.1118,\n                        2.9751,  3.3144,  3.4208,  2.1203,  5.2028,  0.5818,  2.3170,  3.2993,\n                        5.0197,  2.5160,  2.9275,  2.2924,  2.6813,  4.4741,  2.9938,  3.5459,\n                       14.4757,  2.8801,  4.1615,  3.7252,  2.2761,  5.6374,  3.5520,  3.4004,\n                        4.9336,  3.0032,  2.0873,  2.6682,  4.9607,  2.7431,  6.8345,  3.1554,\n                        4.3503,  2.6052,  2.3408,  2.6978,  2.5911,  3.5069,  1.3134,  2.0313,\n                        3.0716,  4.3273,  2.7699,  3.1220,  4.0170,  3.0559,  2.2141,  2.3823,\n                        3.2566,  2.0601,  2.0693,  1.2276,  5.1957,  2.3299,  4.1053,  3.3077,\n                        3.2008,  2.3755,  1.9859,  8.7916,  4.1492,  3.1268,  3.0883,  2.2875,\n                        3.2301,  5.6393,  2.0114,  2.3540,  2.7637,  3.5793,  4.0298,  0.5104,\n                        3.0806,  5.0523,  2.5324,  2.4738,  3.0332,  2.5702,  2.1556,  5.8495,\n                        5.5807,  4.5257,  4.4875,  2.4803,  4.5183,  3.0264,  7.5414, 41.9230,\n                        3.2332,  2.5795,  3.4770,  3.1265,  2.7261,  7.2498,  2.3340,  2.3336,\n                        2.2431,  3.6759,  5.9705,  5.2821,  3.1022,  2.8827,  2.9371,  2.9496,\n                        3.3544,  2.9706,  3.1849,  2.6547,  3.2637,  7.6982,  8.7368,  4.4811,\n                        0.7933,  2.3973,  2.6008,  4.9107,  3.5728,  2.8721,  2.5965,  2.1496,\n                        2.6652,  2.9108,  1.8660,  4.1392,  2.7210,  4.2628,  2.4863,  2.8141,\n                        3.5698,  4.1202,  2.7555,  1.6052,  2.9028,  3.3568,  2.2883,  3.3504,\n                        5.7722,  3.0913,  3.2995,  2.9964,  2.8269,  2.2888,  2.3063,  5.3718,\n                        3.3824,  3.4688,  5.3406,  3.0242,  3.9843,  2.8331, 19.3624,  3.3684])),\n              ('backbone.models.0.model.layer3.1.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.1.conv2.weight',\n               tensor([[[[-2.1422e-02, -1.9248e-02, -2.8684e-02],\n                         [-5.8191e-04, -3.8615e-02, -1.7679e-02],\n                         [ 1.1166e-02, -1.5262e-02, -1.8408e-03]],\n               \n                        [[-2.2739e-02,  2.7287e-02, -1.5900e-02],\n                         [-1.1157e-02,  6.6596e-02, -1.1204e-02],\n                         [ 2.3761e-02,  3.2329e-02,  1.6592e-02]],\n               \n                        [[-8.3476e-03, -3.4005e-02,  1.1696e-02],\n                         [-1.9221e-02, -9.0146e-02, -6.7002e-03],\n                         [-1.4855e-02, -1.8367e-02, -1.4261e-02]],\n               \n                        ...,\n               \n                        [[-2.7600e-03, -1.0210e-02, -4.4558e-03],\n                         [-1.7339e-02,  1.6106e-02,  1.3311e-02],\n                         [ 3.0022e-02, -2.1894e-02,  4.4763e-02]],\n               \n                        [[-4.6838e-02,  1.0930e-01, -7.2353e-02],\n                         [-3.1106e-02,  2.4866e-02, -2.2291e-02],\n                         [ 3.9705e-02, -2.6187e-02,  3.1500e-02]],\n               \n                        [[-2.8999e-02, -5.1981e-02, -2.5188e-02],\n                         [ 2.9481e-03,  1.0450e-01, -1.4443e-02],\n                         [-1.2171e-02, -3.6590e-02, -2.5450e-02]]],\n               \n               \n                       [[[ 9.7227e-03, -4.9293e-02,  3.3560e-02],\n                         [-2.2096e-02, -6.7444e-02, -1.4352e-02],\n                         [-1.0163e-03, -3.0890e-02,  1.2790e-03]],\n               \n                        [[-2.8129e-02, -9.8627e-03, -4.2964e-02],\n                         [-5.6112e-02,  3.7270e-03, -7.5171e-02],\n                         [-2.3412e-02, -4.2610e-02, -2.2392e-02]],\n               \n                        [[-1.3822e-02, -1.3723e-02, -3.2055e-02],\n                         [-5.1205e-03, -3.3522e-02, -1.8651e-02],\n                         [-2.7155e-02,  4.9472e-03,  3.2760e-02]],\n               \n                        ...,\n               \n                        [[-2.0008e-02,  1.5155e-03, -1.6230e-02],\n                         [-2.5064e-02,  1.0894e-01, -2.7134e-02],\n                         [-5.7240e-02, -6.6427e-03, -2.1848e-02]],\n               \n                        [[ 3.4975e-02, -6.2796e-02,  4.1928e-02],\n                         [-2.0161e-02,  1.7004e-02,  5.6925e-03],\n                         [ 1.4540e-02,  1.0920e-01, -9.6377e-05]],\n               \n                        [[-1.6086e-02,  4.7695e-02, -3.3683e-02],\n                         [-4.3736e-02, -3.2402e-02, -9.8486e-03],\n                         [-3.2429e-02, -3.3113e-02, -3.7897e-02]]],\n               \n               \n                       [[[-1.7882e-02,  6.0290e-03,  1.5936e-02],\n                         [-8.6100e-02, -4.1543e-02,  4.2006e-02],\n                         [ 1.4179e-02,  2.1163e-02,  1.0200e-02]],\n               \n                        [[ 2.0019e-02, -1.3520e-03,  2.1028e-02],\n                         [ 9.2291e-04,  3.8762e-02, -2.0021e-02],\n                         [-2.7486e-02,  2.0329e-02,  4.5870e-02]],\n               \n                        [[-2.3111e-02, -4.9714e-02,  9.6851e-03],\n                         [ 3.8503e-03, -1.1780e-02,  9.1219e-02],\n                         [-3.4843e-02, -4.8307e-02,  3.9443e-02]],\n               \n                        ...,\n               \n                        [[ 2.4186e-03, -4.3683e-02, -2.4087e-03],\n                         [ 2.1273e-02, -3.2316e-03,  8.9941e-04],\n                         [-1.2542e-02, -3.4198e-03,  2.9374e-02]],\n               \n                        [[-4.6931e-02, -1.0310e-02, -3.9492e-02],\n                         [-1.8857e-02,  5.1279e-02,  5.5024e-02],\n                         [-1.0482e-02,  4.3308e-02, -5.8685e-02]],\n               \n                        [[-5.4851e-03, -2.1109e-02,  2.0130e-02],\n                         [-1.4187e-01, -1.6076e-02,  1.1409e-01],\n                         [-3.0608e-02,  3.2144e-02,  6.3483e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-6.9665e-03,  5.4240e-02,  3.1403e-02],\n                         [-5.1632e-04,  2.5216e-02, -2.2363e-02],\n                         [ 2.4057e-02, -3.5127e-02,  6.2816e-03]],\n               \n                        [[ 1.3837e-03, -4.4860e-02,  4.6023e-03],\n                         [-1.2045e-05, -2.4618e-02, -5.7175e-03],\n                         [ 6.4793e-03,  3.2676e-03, -1.2243e-02]],\n               \n                        [[-1.6829e-02,  1.7154e-02,  4.2257e-02],\n                         [-1.1351e-01, -4.8025e-02,  8.1505e-02],\n                         [-1.3377e-02, -3.9248e-02, -1.5846e-03]],\n               \n                        ...,\n               \n                        [[ 6.7525e-03,  6.6358e-02,  2.5211e-02],\n                         [-3.8962e-02,  2.6182e-02, -2.1812e-02],\n                         [ 1.4515e-02,  7.6874e-02, -9.1781e-03]],\n               \n                        [[ 2.2837e-02, -6.5116e-02,  1.2208e-04],\n                         [ 4.5087e-03, -5.8071e-02, -1.2113e-01],\n                         [-8.0064e-03,  1.8094e-02,  3.3703e-02]],\n               \n                        [[ 2.3670e-02,  2.9968e-02,  1.4604e-02],\n                         [-3.4266e-02,  3.7876e-02,  2.2018e-02],\n                         [ 1.1287e-02, -2.7229e-02,  2.9808e-03]]],\n               \n               \n                       [[[ 1.8399e-02,  2.0310e-03,  7.1770e-03],\n                         [ 3.7522e-02, -4.1284e-02, -6.1610e-02],\n                         [ 2.3409e-02, -1.1625e-02, -2.0690e-02]],\n               \n                        [[ 6.7259e-03,  2.1642e-02, -1.0757e-02],\n                         [ 3.7202e-02, -3.9283e-03,  1.5867e-03],\n                         [-3.4570e-02, -3.3498e-03,  2.2166e-02]],\n               \n                        [[ 4.0283e-02, -1.8281e-02,  3.8553e-03],\n                         [-2.5048e-02,  4.0935e-03,  9.5192e-03],\n                         [ 1.8750e-02, -1.0616e-01, -7.0575e-03]],\n               \n                        ...,\n               \n                        [[ 1.5230e-03,  9.4471e-03, -1.6123e-03],\n                         [ 9.0082e-03, -3.0546e-03,  5.9736e-03],\n                         [-2.0736e-02, -3.1485e-02, -1.3617e-03]],\n               \n                        [[ 1.4016e-02,  4.7810e-02,  3.7372e-02],\n                         [ 8.1596e-02,  4.8171e-02, -1.0029e-01],\n                         [ 4.0098e-02,  7.7849e-03, -4.0326e-02]],\n               \n                        [[-1.6488e-02, -6.8322e-03, -1.8932e-03],\n                         [ 1.5767e-02, -3.7599e-03, -2.9685e-02],\n                         [-1.6747e-02, -4.8963e-03,  7.2959e-03]]],\n               \n               \n                       [[[ 3.8818e-03, -2.6076e-02,  3.8652e-03],\n                         [ 2.8983e-02,  7.4748e-02,  3.9040e-02],\n                         [ 1.8465e-02,  6.4297e-02,  2.9647e-02]],\n               \n                        [[-1.3836e-02, -9.8921e-03, -2.2868e-02],\n                         [-1.5066e-02,  3.8738e-02,  1.1166e-03],\n                         [ 3.3886e-02,  7.0863e-02,  1.8975e-02]],\n               \n                        [[ 2.0185e-03,  1.7512e-02, -3.0157e-03],\n                         [ 9.0258e-03,  7.1100e-02, -2.3485e-02],\n                         [-2.5806e-03,  1.4024e-02, -2.5062e-02]],\n               \n                        ...,\n               \n                        [[-9.1555e-02, -1.4241e-01, -5.0606e-02],\n                         [-9.9929e-02, -4.7721e-02, -7.6321e-02],\n                         [-7.2271e-02, -9.4133e-02, -5.3081e-02]],\n               \n                        [[ 4.7392e-02,  4.9980e-02,  4.5143e-02],\n                         [ 2.9763e-02,  4.6948e-02,  1.9547e-02],\n                         [ 6.7805e-05,  1.2667e-02, -1.1117e-02]],\n               \n                        [[ 2.1379e-02,  3.5233e-02,  1.4780e-02],\n                         [ 2.9619e-02, -1.3351e-02,  2.6992e-02],\n                         [ 5.5629e-02,  6.9278e-02,  2.7937e-02]]]])),\n              ('backbone.models.0.model.layer3.1.bn2.weight',\n               tensor([0.7251, 0.5333, 1.0121, 1.1377, 0.8118, 0.6349, 0.4977, 0.9762, 0.9783,\n                       0.6753, 0.7776, 0.8763, 1.1343, 0.7773, 0.5048, 0.7225, 1.0193, 0.6867,\n                       0.9376, 0.6389, 0.9894, 0.7967, 0.6919, 1.4040, 0.8518, 0.5689, 0.7983,\n                       0.9051, 0.7158, 0.5834, 0.9273, 0.7042, 0.5177, 0.6285, 0.9998, 0.9195,\n                       0.8730, 0.7962, 0.9290, 1.0653, 0.6927, 0.8045, 0.9536, 0.7600, 0.6811,\n                       0.7893, 0.7771, 0.7269, 0.9881, 0.6179, 1.0094, 1.0058, 0.9127, 0.8765,\n                       0.5964, 0.5838, 0.6858, 0.5203, 1.0450, 0.9707, 1.0645, 0.6088, 0.8501,\n                       0.9066, 0.7856, 1.0001, 0.9658, 0.9946, 0.5172, 0.8330, 0.9035, 0.8536,\n                       1.0901, 0.9836, 0.9564, 0.9274, 0.9589, 0.7746, 0.7153, 0.5873, 0.5980,\n                       0.7617, 0.7213, 0.9422, 0.6994, 0.5103, 1.3123, 1.0485, 0.9635, 0.8764,\n                       0.4274, 0.7195, 0.8154, 0.4043, 0.9493, 0.9474, 0.7237, 0.9179, 0.9618,\n                       0.8235, 0.6873, 0.9759, 0.8992, 0.9333, 1.0122, 0.5782, 0.7941, 1.2559,\n                       0.7112, 0.4883, 0.6721, 1.8446, 0.6197, 0.9721, 0.9455, 0.7559, 0.6524,\n                       0.8369, 0.5592, 0.9784, 0.8043, 0.7363, 0.4737, 0.6834, 1.1200, 0.8095,\n                       0.7501, 0.8498, 1.0357, 0.5073, 0.7595, 0.7707, 0.7977, 0.7186, 0.6690,\n                       0.8734, 1.0408, 0.8682, 0.8622, 0.6929, 0.9250, 0.6512, 0.8021, 1.7052,\n                       0.9810, 1.0749, 0.4263, 0.9387, 1.0735, 0.6403, 0.7463, 1.0712, 0.8806,\n                       0.7017, 0.4845, 0.9383, 0.5572, 0.8726, 0.7861, 1.5366, 0.8333, 1.0670,\n                       0.5799, 1.0021, 0.5061, 0.6659, 0.7450, 0.9464, 0.8933, 0.5652, 1.3032,\n                       0.8592, 0.4711, 0.7084, 0.5930, 0.9864, 0.8090, 0.7500, 1.3797, 0.9180,\n                       1.0235, 0.8771, 0.6006, 0.9428, 0.8219, 0.8937, 0.5567, 1.2524, 0.7874,\n                       1.3875, 0.8394, 0.7363, 0.7960, 0.7258, 1.0103, 0.8020, 0.7278, 0.6135,\n                       0.8305, 0.7225, 0.4425, 0.6971, 0.9993, 0.8890, 0.8999, 1.3570, 0.9286,\n                       1.0423, 0.5116, 0.9826, 0.5860, 0.8689, 1.1444, 0.8671, 0.6969, 0.5518,\n                       0.9179, 0.9224, 0.8278, 0.5270, 0.7040, 0.7592, 0.6466, 1.1744, 0.4668,\n                       1.3131, 1.1544, 0.6525, 0.8181, 0.9030, 0.6923, 0.8125, 0.7595, 0.8133,\n                       1.0753, 1.5788, 0.9438, 0.9297, 0.7067, 0.9586, 0.7149, 0.8485, 0.9519,\n                       1.1864, 0.5937, 0.7656, 0.8650, 0.9322, 0.5539, 0.7017, 0.7697, 0.6951,\n                       0.9101, 1.0231, 0.9718, 0.7068])),\n              ('backbone.models.0.model.layer3.1.bn2.bias',\n               tensor([-0.4556,  0.0380, -0.8892, -0.6652, -0.7238, -0.2166,  0.7889, -0.7728,\n                       -0.8699, -0.0838, -0.6040, -0.4164, -1.3279, -0.1421,  0.0392, -0.4382,\n                       -0.4269, -0.1838, -0.7398, -0.2293, -0.6417, -0.5356, -0.2357, -1.5686,\n                       -0.4388, -0.1069, -0.8834, -0.5163, -0.4587,  0.1389, -1.1783, -0.4855,\n                       -0.2017, -0.1087, -0.5550, -0.7796, -0.4218, -0.4520, -1.0776, -1.0922,\n                       -0.6418, -0.2858, -0.6818, -0.4001, -0.2546, -0.3428, -0.3989, -0.4564,\n                       -0.6114, -0.0836, -0.7758, -0.6090, -0.7796, -0.7327,  0.1059, -0.0766,\n                       -0.2342,  0.1145, -0.5794, -1.3889, -1.1122, -0.1466, -0.8426, -0.8584,\n                       -0.5312, -0.5994, -0.6661, -0.6465, -0.0431, -0.8609, -0.2133, -0.4245,\n                       -0.7864, -1.4373, -0.3721, -0.7475, -0.8419, -0.2872, -0.1996, -0.0748,\n                        0.0205, -0.5091, -0.2228, -0.5163, -0.3077,  0.2645, -1.5104, -0.8919,\n                       -1.0219, -0.3688,  0.3557, -0.5089,  0.0209,  0.2621, -0.1647, -0.5869,\n                       -0.1132, -0.3059, -0.6878, -0.8810, -0.3822, -0.8469, -0.3558, -0.3883,\n                       -0.6003, -0.3069, -0.3821, -0.9147, -0.3435,  0.1624, -0.2553, -1.4525,\n                       -0.1827, -0.8904, -1.0069, -0.3548, -0.3555, -0.3612,  0.1964, -1.0065,\n                       -0.7869, -0.6188,  0.2244, -0.3341, -0.9526, -0.1776, -0.1994, -0.1773,\n                       -0.5122, -0.0052, -0.2618, -0.5536, -0.1339, -0.5071, -0.2833, -0.6472,\n                       -0.6658, -0.3060, -0.4846, -0.1113, -0.3614, -0.1063, -0.3129, -2.2826,\n                       -0.5014, -0.9528,  0.6708, -0.5841, -1.3994, -0.3263, -0.4492, -1.2926,\n                       -0.2559, -0.0313,  0.0258, -1.0736, -0.0062, -1.2824, -0.7995, -1.0858,\n                       -0.3134, -0.7799,  0.0155, -1.0234,  0.0766, -0.3252, -0.3400, -0.7543,\n                       -0.0269, -0.0269, -0.5843, -0.7606,  0.0563, -0.4060, -0.0255, -0.9666,\n                       -0.3692, -0.1327, -0.7314, -0.5473, -1.8570, -0.4544, -0.1789, -0.6068,\n                       -0.3147, -0.8870, -0.0953, -1.1975, -0.1365, -1.5431, -0.2035, -0.2204,\n                       -0.4258, -0.5087, -0.4642, -0.4762, -0.4106, -0.1739, -0.1112, -0.4003,\n                        0.9812, -0.2242, -0.7435, -0.4429, -0.4970, -1.9149, -0.5819, -0.5727,\n                       -0.0544, -1.4108, -0.0745, -0.6658, -1.0859, -0.7738, -0.0628, -0.0861,\n                       -0.3650, -0.5705, -0.6229,  0.0183, -0.3185, -0.3768, -0.1335, -0.8049,\n                        0.4542, -1.8889, -1.6569, -0.2774, -0.8501, -0.4178, -0.2834, -0.6289,\n                       -0.5196, -0.1774, -0.7712, -1.9867, -0.6255, -1.0560, -0.2736, -1.0469,\n                       -0.0596, -0.4694, -0.5233, -0.6606, -0.1540, -0.5145, -0.7856, -0.6504,\n                       -0.1413, -0.4264, -0.4810, -0.2389, -0.5991, -0.5372, -0.6103, -0.2024])),\n              ('backbone.models.0.model.layer3.1.bn2.running_mean',\n               tensor([-0.9264, -0.5822, -0.1638, -2.3442, -0.6538, -1.0579,  1.8160, -0.0406,\n                        0.2472,  0.2098, -0.6351, -0.1302,  3.1878,  1.6829, -0.1627, -0.4108,\n                       -0.3096, -0.4989,  0.9827, -0.3972, -0.1234, -0.1005, -0.4126, -0.7275,\n                        0.4026, -1.1258, -0.9631, -1.2394, -0.5118,  0.0107, -0.7287, -0.3359,\n                       -0.4439, -1.3657, -1.1394, -0.7147,  0.0111, -2.3887, -0.7166, -0.2565,\n                        0.2851,  0.1065, -0.5591,  0.3056, -0.4516, -0.1112, -0.9929, -0.3840,\n                       -1.6354, -0.6187, -0.1667,  0.7671, -0.8736,  0.4826, -0.5057, -0.8820,\n                       -1.5814, -2.3352, -1.1115, -1.4793, -0.3284, -0.3746, -0.3826, -0.1596,\n                       -1.3890, -1.7704,  0.0218,  0.0084, -0.5346, -0.3882, -0.2125,  0.9906,\n                       -0.9860,  0.2618,  0.2624, -1.2281, -0.1831,  0.6232, -0.4012, -1.5503,\n                        0.1247, -0.6228, -0.4332, -0.4211, -0.3414,  0.5961, -0.4001, -0.0656,\n                       -0.6728, -0.4010, -0.6643,  0.0225,  1.6144, -1.2735, -2.6218,  0.4482,\n                       -1.1577,  0.8491,  0.0981, -1.1972, -0.5229, -0.3694,  0.3758, -1.5330,\n                        0.0089,  0.2364,  0.2388, -0.8789, -0.7790, -0.9141, -0.4692, -1.0001,\n                       -0.7905, -0.1258, -1.5341,  0.7683, -0.4614,  0.7198,  1.4349, -0.4142,\n                       -0.7711, -1.0213, -1.4666, -0.4768, -0.2982, -0.3438,  1.0663,  0.7259,\n                       -0.3826,  0.0229,  0.5132, -0.3209,  0.4576, -0.6599, -0.6462, -0.0786,\n                       -1.0367, -3.2708, -0.1783, -0.5492,  0.3452, -0.3324, -0.6003, -0.6084,\n                       -1.4689, -0.1419, -1.7650,  0.1319, -1.8436,  0.5795, -0.6678, -1.7529,\n                       -2.7029, -0.4171, -0.2997, -0.7877, -0.8763, -0.8629, -0.5307, -0.3191,\n                        0.3749, -0.2492,  0.9135, -0.4137, -0.3146, -0.3983, -0.3653, -0.0274,\n                        0.1912, -0.6694, -2.7144, -0.8450, -0.4270, -0.4051, -0.7375, -0.8324,\n                       -0.1596, -1.3540, -2.4862,  0.4949, -1.2483, -1.4001, -0.0527, -1.3441,\n                        1.1337, -0.3223, -1.2358,  0.0680,  0.1622,  3.1532, -4.3109, -1.2676,\n                       -0.9540, -0.2793, -1.1670, -0.5533, -0.5764, -0.0804,  0.1999,  0.5852,\n                        0.2555, -0.9378, -0.4220,  0.0508,  0.7472, -0.9667,  0.5971, -3.2980,\n                       -0.0350, -1.4644, -0.5184,  0.3771, -1.7238, -0.3306, -1.3548, -0.1988,\n                       -0.3180, -0.1857,  0.0446, -0.3792, -1.1803, -0.9751, -0.8035, -0.4326,\n                       -2.9260, -2.3030, -2.1997, -0.4813, -0.5691,  0.6760, -0.2531,  0.2993,\n                       -1.0778,  0.6070,  0.3213, -0.5850, -0.1352, -0.8897,  0.6429, -0.1648,\n                        0.8512, -1.1651,  0.0330, -1.1806, -0.3174, -0.0536,  0.3547,  0.1571,\n                       -0.9803, -0.2289,  0.1351, -0.4561,  0.1258, -0.8089, -0.3118, -0.3156])),\n              ('backbone.models.0.model.layer3.1.bn2.running_var',\n               tensor([1.0325, 1.9260, 2.0927, 2.1693, 1.0838, 2.1324, 1.6281, 2.2061, 2.0582,\n                       1.9206, 1.4346, 2.4002, 8.7929, 3.1051, 1.8512, 1.2011, 2.7392, 1.5487,\n                       1.8047, 1.3534, 3.2675, 1.7886, 2.0568, 7.0567, 2.9794, 1.1850, 0.7302,\n                       3.2669, 1.2363, 1.1643, 1.0210, 1.0844, 1.2928, 1.1874, 1.1255, 1.3402,\n                       2.4393, 2.1441, 1.2037, 1.8814, 1.6087, 2.5111, 1.6397, 2.1095, 1.6109,\n                       2.3115, 1.5230, 1.3222, 2.5435, 1.8440, 1.8123, 2.3583, 1.3161, 2.4492,\n                       1.8174, 1.2363, 1.3142, 1.3866, 1.8874, 1.4143, 1.7733, 1.3317, 1.1942,\n                       1.4677, 1.2938, 1.3415, 2.1856, 2.6579, 1.3349, 1.4896, 4.1397, 1.7674,\n                       1.1976, 1.1328, 3.2096, 2.1164, 1.9947, 1.9591, 1.9208, 1.3265, 1.3442,\n                       1.5427, 1.8962, 1.3323, 2.0381, 1.6335, 6.8506, 2.2097, 0.9093, 3.2268,\n                       1.4090, 2.1464, 4.4617, 0.9620, 2.9173, 2.0487, 2.1350, 3.3685, 2.1057,\n                       0.9434, 1.1306, 2.0217, 3.0485, 2.5207, 2.7302, 1.2770, 2.3873, 1.2930,\n                       1.7121, 1.1899, 1.9542, 2.3212, 1.4848, 1.9911, 1.7797, 1.6860, 0.8481,\n                       2.0022, 1.5423, 1.3504, 1.0371, 1.0787, 1.2789, 2.1795, 2.3859, 1.6612,\n                       3.3841, 4.3058, 4.5951, 1.4877, 2.0365, 1.0398, 3.4976, 1.3738, 1.5486,\n                       2.1249, 1.3641, 1.8466, 2.6310, 1.6141, 4.2143, 2.1244, 1.8256, 8.5682,\n                       1.3688, 2.6461, 1.3515, 1.7243, 1.3964, 1.2427, 1.3312, 1.8272, 2.2682,\n                       2.0703, 1.8475, 1.0864, 1.3969, 1.5623, 0.6960, 2.0163, 2.8230, 2.2432,\n                       1.6110, 2.1125, 1.4534, 1.3697, 1.4094, 1.8788, 5.0995, 1.4542, 4.9944,\n                       1.0420, 1.4573, 1.3781, 1.9644, 1.4661, 2.3689, 3.1207, 4.2019, 4.6416,\n                       0.9280, 1.7745, 1.2863, 2.3860, 2.6487, 1.0601, 1.3332, 2.4059, 3.6701,\n                       9.4932, 3.0537, 1.5057, 1.7134, 1.3477, 1.7447, 2.8209, 1.6650, 1.7117,\n                       4.3264, 1.8166, 1.6055, 1.7081, 1.9537, 2.7536, 2.3352, 1.8251, 3.3907,\n                       4.8897, 1.4781, 1.6263, 1.2409, 1.8803, 1.1050, 1.7927, 1.6304, 1.2502,\n                       4.5889, 1.5249, 2.2245, 1.9885, 1.4849, 1.2065, 2.1018, 0.9151, 1.2544,\n                       2.0606, 2.0626, 1.8637, 0.8568, 3.4812, 1.3164, 1.0388, 1.7755, 3.3951,\n                       2.3173, 7.9837, 2.4829, 1.7309, 1.6703, 1.7515, 2.9764, 1.7661, 3.1396,\n                       1.4630, 2.0385, 2.1157, 2.3243, 2.2434, 1.1098, 1.3189, 2.1104, 2.1463,\n                       2.0002, 1.3859, 3.1869, 1.9075])),\n              ('backbone.models.0.model.layer3.1.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.1.conv3.weight',\n               tensor([[[[-0.0191]],\n               \n                        [[-0.0614]],\n               \n                        [[-0.0370]],\n               \n                        ...,\n               \n                        [[ 0.0189]],\n               \n                        [[-0.0123]],\n               \n                        [[ 0.1234]]],\n               \n               \n                       [[[-0.0399]],\n               \n                        [[-0.0219]],\n               \n                        [[ 0.0733]],\n               \n                        ...,\n               \n                        [[-0.0066]],\n               \n                        [[-0.0451]],\n               \n                        [[-0.0763]]],\n               \n               \n                       [[[ 0.0696]],\n               \n                        [[-0.0425]],\n               \n                        [[ 0.0288]],\n               \n                        ...,\n               \n                        [[ 0.0319]],\n               \n                        [[-0.0097]],\n               \n                        [[ 0.0078]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0353]],\n               \n                        [[-0.0297]],\n               \n                        [[ 0.0233]],\n               \n                        ...,\n               \n                        [[ 0.0628]],\n               \n                        [[-0.0299]],\n               \n                        [[-0.0370]]],\n               \n               \n                       [[[-0.0260]],\n               \n                        [[-0.0470]],\n               \n                        [[-0.0082]],\n               \n                        ...,\n               \n                        [[ 0.0620]],\n               \n                        [[-0.0280]],\n               \n                        [[ 0.0203]]],\n               \n               \n                       [[[ 0.0082]],\n               \n                        [[ 0.0145]],\n               \n                        [[-0.0051]],\n               \n                        ...,\n               \n                        [[ 0.0289]],\n               \n                        [[ 0.0040]],\n               \n                        [[-0.0207]]]])),\n              ('backbone.models.0.model.layer3.1.bn3.weight',\n               tensor([-0.4185, -0.2139,  0.3039,  ...,  0.2802,  0.4777,  0.2912])),\n              ('backbone.models.0.model.layer3.1.bn3.bias',\n               tensor([-0.4206, -0.1684,  0.3125,  ...,  0.2375, -0.4195, -0.1377])),\n              ('backbone.models.0.model.layer3.1.bn3.running_mean',\n               tensor([ 0.1052,  0.2889, -0.1644,  ..., -0.2458, -0.2238, -0.2861])),\n              ('backbone.models.0.model.layer3.1.bn3.running_var',\n               tensor([0.0596, 0.0503, 0.1050,  ..., 0.1065, 0.1197, 0.0826])),\n              ('backbone.models.0.model.layer3.1.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.2.conv1.weight',\n               tensor([[[[ 0.0088]],\n               \n                        [[-0.0052]],\n               \n                        [[ 0.0572]],\n               \n                        ...,\n               \n                        [[ 0.0842]],\n               \n                        [[-0.0511]],\n               \n                        [[ 0.0031]]],\n               \n               \n                       [[[ 0.0348]],\n               \n                        [[-0.0058]],\n               \n                        [[ 0.0474]],\n               \n                        ...,\n               \n                        [[-0.0176]],\n               \n                        [[-0.0330]],\n               \n                        [[-0.0163]]],\n               \n               \n                       [[[ 0.0237]],\n               \n                        [[-0.0253]],\n               \n                        [[-0.0116]],\n               \n                        ...,\n               \n                        [[ 0.0244]],\n               \n                        [[ 0.0053]],\n               \n                        [[-0.0179]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.1135]],\n               \n                        [[-0.0385]],\n               \n                        [[ 0.0125]],\n               \n                        ...,\n               \n                        [[-0.0014]],\n               \n                        [[ 0.0100]],\n               \n                        [[-0.0030]]],\n               \n               \n                       [[[-0.0119]],\n               \n                        [[-0.0087]],\n               \n                        [[-0.0611]],\n               \n                        ...,\n               \n                        [[-0.0347]],\n               \n                        [[ 0.1091]],\n               \n                        [[-0.0061]]],\n               \n               \n                       [[[-0.0498]],\n               \n                        [[ 0.0275]],\n               \n                        [[-0.0117]],\n               \n                        ...,\n               \n                        [[ 0.0209]],\n               \n                        [[-0.0336]],\n               \n                        [[-0.0296]]]])),\n              ('backbone.models.0.model.layer3.2.bn1.weight',\n               tensor([0.7421, 0.8255, 0.8531, 0.7329, 0.6510, 0.7488, 0.7754, 0.7941, 1.0358,\n                       0.7520, 0.8790, 1.1294, 0.9440, 0.9970, 0.7679, 0.9567, 0.5769, 0.8204,\n                       1.0087, 0.7585, 0.7198, 0.9578, 0.8943, 1.2025, 0.8546, 1.1058, 0.7044,\n                       0.7883, 0.8421, 1.0423, 0.7250, 0.6985, 0.7810, 1.3969, 1.0401, 0.7080,\n                       0.8632, 0.7746, 1.0470, 0.9077, 0.9858, 0.8859, 1.0196, 0.9417, 0.7961,\n                       1.1893, 0.7846, 1.2040, 0.7843, 0.7896, 0.8362, 1.0412, 0.6607, 0.7969,\n                       1.0194, 0.7350, 0.7973, 0.8797, 0.9813, 0.7985, 0.8202, 1.1513, 0.7326,\n                       0.8806, 0.8617, 1.0851, 0.8192, 0.8599, 0.7715, 1.0186, 0.6552, 0.7115,\n                       0.6865, 0.7263, 0.7340, 0.8216, 0.9973, 1.0803, 1.1954, 0.6602, 0.8069,\n                       0.9345, 1.0072, 1.0004, 0.8650, 0.9112, 0.8890, 0.9134, 0.9116, 0.7498,\n                       0.4665, 0.6879, 0.9003, 0.6552, 0.9565, 0.7834, 0.7667, 0.9383, 1.0229,\n                       0.6790, 0.7940, 0.9473, 1.2655, 0.9402, 0.7021, 0.8420, 0.9227, 0.8905,\n                       0.6875, 0.9299, 0.8247, 0.8007, 0.8690, 0.8026, 0.7287, 0.6350, 0.7236,\n                       0.8491, 0.7760, 1.0487, 0.7103, 0.9652, 0.9993, 0.7454, 1.0111, 1.0171,\n                       1.0114, 0.9192, 0.8540, 0.7075, 0.9496, 0.8364, 0.9983, 0.6639, 1.0818,\n                       1.0043, 0.8066, 0.8515, 0.7861, 1.0553, 0.7004, 1.3328, 0.8246, 0.8835,\n                       0.7291, 0.8903, 1.0623, 0.7229, 0.8818, 0.7814, 1.0247, 0.8385, 0.8406,\n                       0.8397, 0.6865, 0.7509, 0.7693, 1.0893, 0.8070, 0.8791, 0.8917, 1.0256,\n                       0.7364, 0.8686, 0.9438, 0.6897, 1.1506, 0.7248, 0.9938, 1.0582, 0.8945,\n                       0.9518, 0.8227, 0.8628, 0.8048, 0.7019, 0.7491, 0.7542, 0.8710, 1.2220,\n                       0.6716, 0.6833, 1.0322, 0.7485, 1.0737, 0.7037, 0.8414, 0.7977, 0.7630,\n                       0.9948, 0.9172, 0.7546, 0.9159, 1.0513, 1.0634, 0.7199, 0.8835, 1.0148,\n                       0.9573, 0.7170, 0.9387, 0.8040, 0.9046, 0.7711, 0.7209, 1.0753, 0.8231,\n                       0.7681, 0.7521, 0.7185, 0.9637, 0.5679, 0.6615, 1.0427, 0.8211, 0.7004,\n                       0.7219, 0.8334, 0.6799, 0.9337, 0.7755, 0.8014, 0.6629, 0.7376, 0.7283,\n                       0.8285, 0.6876, 0.9830, 0.8928, 0.8789, 0.9422, 0.6933, 0.8501, 0.7430,\n                       0.7483, 0.6845, 1.0841, 0.7857, 0.6230, 0.8789, 0.8235, 0.9869, 1.0654,\n                       1.0505, 0.8503, 1.0636, 0.8398, 0.8578, 0.6625, 0.6795, 0.7642, 0.7192,\n                       1.0104, 0.7890, 0.8880, 1.1769])),\n              ('backbone.models.0.model.layer3.2.bn1.bias',\n               tensor([-0.2217, -0.4443, -0.3301, -0.3142, -0.2168, -0.3571, -0.3619, -0.8156,\n                       -0.8847, -0.2372, -0.7192, -1.5519, -0.5333, -0.9950, -0.3890, -0.8160,\n                       -0.0172, -0.2359, -1.0058, -0.3276, -0.1950, -0.9949, -0.5324, -1.1690,\n                       -0.5861, -1.2747, -0.1865, -0.5045, -0.7016, -1.1991, -0.2696, -0.1784,\n                       -0.4748, -0.9659, -1.3341, -0.2100, -0.7096, -0.3641, -1.1706, -0.7440,\n                       -0.9095, -0.6703, -0.9923, -0.6758, -0.5785, -1.3972, -0.3852, -0.8202,\n                       -0.3345, -0.2774, -0.6627, -0.8108, -0.1988, -0.4248, -0.9194, -0.4574,\n                       -0.4868, -0.6647, -0.6503, -0.5739, -0.3975, -1.0263, -0.5205, -0.5862,\n                       -0.6696, -0.9585, -0.5648, -0.6139, -0.3583, -0.8387, -0.1261, -0.1795,\n                       -0.5530, -0.2830, -0.1677, -0.6624, -0.9277, -1.1738, -1.8764, -0.1044,\n                       -0.6637, -0.6469, -0.9187, -0.8976, -0.6490, -0.7951, -0.8775, -0.6584,\n                       -0.2808, -0.5490,  0.9242, -0.2567, -0.7108, -0.1625, -0.8830, -0.4702,\n                       -0.3509, -0.7779, -0.9564, -0.1395, -0.4457, -0.8256, -1.4426, -0.6044,\n                       -0.1475, -0.6552, -0.7037, -0.6774, -0.1287, -0.6625, -0.5076, -0.4159,\n                       -0.6183, -0.3572,  0.1932, -0.1997, -0.3037, -0.9471, -0.3565, -0.8001,\n                       -0.0859, -0.6683, -0.8932, -0.2496, -0.6612, -0.8306, -1.0889, -0.6804,\n                       -0.6108, -0.3876, -0.6200, -0.4949, -0.8768, -0.1599, -1.4265, -0.7400,\n                       -0.5116, -0.6758, -0.2900, -0.9587, -0.3657, -1.9847, -0.2759, -0.7021,\n                       -0.2993, -0.8106, -1.2604, -0.2435, -0.5510, -0.3538, -1.1317, -0.6124,\n                       -0.6870, -0.6968, -0.2032, -0.3553, -0.2948, -1.0882, -0.3653, -0.7852,\n                       -0.7121, -1.3190, -0.2236, -0.6238, -1.0378,  0.0068, -1.2930, -0.2460,\n                       -0.8411, -1.0142, -0.5981, -0.8038, -0.5592, -0.0899, -0.2348, -0.1726,\n                       -0.2450, -0.3788, -0.4778,  0.3421, -0.1094, -0.1946, -0.5324, -0.3668,\n                       -0.9358, -0.2270, -0.4787, -0.5069, -0.2742, -0.8678, -0.8833, -0.2076,\n                       -0.5462, -0.9333, -0.6115, -0.2956, -0.7017, -0.9814, -0.5822, -0.4611,\n                       -0.9947, -0.3853, -0.7129, -0.4672, -0.3785, -1.2874, -0.5219, -0.3637,\n                       -0.2288, -0.3038, -0.7207,  0.1504, -0.1961, -1.1572, -0.4133, -0.0218,\n                       -0.1830, -0.5382, -0.0919, -0.5853, -0.4147, -0.5080, -0.1652, -0.3747,\n                       -0.2964, -0.5199, -0.1998, -0.6236, -0.6825, -1.0750, -0.9682, -0.0199,\n                       -0.5542, -0.1065, -0.3077, -0.2137, -1.0119, -0.4579,  0.0524, -0.6027,\n                       -0.5940, -0.5488, -0.8301, -0.3737, -0.8294, -0.7840, -0.4588, -0.8211,\n                        0.0103, -0.1012, -0.4015,  0.0529, -0.6657, -0.2801, -0.6227, -0.0956])),\n              ('backbone.models.0.model.layer3.2.bn1.running_mean',\n               tensor([-3.0464e-01, -9.6551e-01,  8.5001e-02, -3.2097e-01, -5.7129e-01,\n                       -2.3800e-01, -1.0352e+00, -3.7738e-01, -5.3928e-01,  1.0012e+00,\n                       -1.0024e+00, -2.0942e+00, -1.1069e+00, -1.2266e+00, -7.0984e-02,\n                       -4.7723e-01, -1.2198e+00, -6.0351e-01,  1.0996e-01, -2.8039e-01,\n                        5.2449e-01, -3.5138e-01, -9.5793e-01, -1.1476e+00,  3.4477e-01,\n                       -8.3507e-01, -2.3858e+00, -7.9084e-01,  8.5070e-02, -6.3830e-01,\n                       -6.5673e-01, -1.7937e+00, -7.3609e-01, -1.0182e+00, -1.4328e+00,\n                       -2.0212e-01, -7.4273e-01, -2.0436e+00, -1.2031e+00, -1.8851e+00,\n                       -1.5076e+00, -7.3030e-01, -1.1230e+00, -1.2892e+00, -1.1212e+00,\n                       -2.1455e+00, -3.6879e-01, -7.1408e-01,  6.2189e-01, -7.5495e-01,\n                       -1.5447e-01, -4.0748e-01, -8.8475e-01, -9.7832e-01, -4.8764e-01,\n                       -7.2743e-01, -5.3543e-03, -1.1164e+00, -8.7524e-01, -3.9993e-01,\n                        2.5874e-01, -2.4851e+00, -1.6151e-01, -1.7294e+00, -1.7572e+00,\n                       -7.8223e-01, -5.0074e-01, -8.3415e-01, -5.3411e-01, -1.6325e+00,\n                       -2.2815e-01, -7.4652e-01, -2.1408e-01, -1.0416e+00, -1.3007e+00,\n                       -3.3952e-01, -1.7743e+00, -1.8607e+00, -5.2503e+00, -1.2406e+00,\n                       -9.5627e-02, -1.1910e-01, -6.4299e-01, -1.9576e+00, -9.7060e-01,\n                       -1.5258e+00,  4.3685e-01, -1.2920e+00, -9.4523e-01,  8.6430e-02,\n                       -4.0646e+00,  1.2449e+00, -1.2968e+00, -3.3856e-01,  5.8160e-01,\n                        2.7072e-01, -1.3262e+00,  8.1119e-01, -7.5742e-01, -8.7035e-01,\n                        4.0452e-01, -1.4021e+00, -2.0439e+00, -9.0059e-01,  9.4609e-01,\n                       -2.3770e+00, -2.6773e-01, -1.4769e+00, -9.2733e-01, -2.8923e-01,\n                        1.6776e-01, -7.8065e-01, -1.8288e+00,  4.2426e-01, -9.3125e-01,\n                       -1.1628e-01,  1.2784e+00, -3.7701e-01,  4.3392e-01, -6.7702e-01,\n                       -1.3046e+00, -2.7229e-01, -7.2145e-01, -1.4389e+00, -4.6299e-01,\n                       -2.0552e+00, -7.6620e-01, -4.3099e-01, -2.4055e-01,  4.6059e-01,\n                       -2.0268e-02,  8.2173e-01, -1.1499e+00, -7.1932e-01, -3.6125e+00,\n                       -1.3829e+00, -7.7891e-01, -7.3808e-01, -2.7065e-01, -1.1554e+00,\n                       -3.3103e-01, -6.0025e+00, -1.2289e+00, -4.2107e-01, -8.0728e-01,\n                       -7.3089e-01, -2.4946e+00, -2.0522e-01, -5.6135e-01, -1.2088e+00,\n                       -9.1571e-01, -1.1097e+00,  3.6448e-01, -2.0272e+00, -1.0763e+00,\n                       -4.4378e-01, -9.3714e-01, -1.2893e+00, -7.6953e-01, -9.1832e-01,\n                       -4.0583e-01, -1.4231e+00, -1.2435e+00, -8.7612e-01, -7.1492e-01,\n                        2.2562e-01, -1.8323e+00, -5.0669e-01, -5.6866e-01, -1.4074e+00,\n                       -9.0960e-01, -3.6789e-01, -7.3731e-02, -1.4073e-01, -2.1428e-02,\n                        7.4595e-01,  3.0032e-01, -5.8695e-01, -5.0895e-01, -4.9745e-01,\n                       -2.4724e+00, -1.9219e+00, -1.7633e+00,  2.9736e-03, -6.9869e-01,\n                       -9.2519e-01,  7.4879e-02, -9.7362e-01, -1.0980e+00, -1.2174e-01,\n                       -7.2164e-02,  7.0026e-01, -1.2963e+00, -1.2688e+00, -1.0535e+00,\n                       -6.3636e-01, -9.2205e-01, -2.4671e+00, -2.0102e+00, -1.7567e+00,\n                       -1.8681e+00, -2.0992e+00, -1.2604e-01, -3.3625e-01,  3.7215e-01,\n                       -1.0413e+00, -4.5762e-01, -9.4208e-01,  7.0682e-01, -5.2164e-01,\n                       -1.8314e+00, -1.2140e+00,  2.0440e-02, -2.6248e+00,  1.9882e-01,\n                       -1.4366e+00, -6.4447e-01, -2.1043e-01, -2.0218e-01, -5.8681e-01,\n                       -1.2767e+00, -6.9135e-01,  1.6381e-01, -1.3646e+00, -1.9201e-03,\n                        4.8545e-01, -1.5882e+00, -9.6642e-01, -8.2666e-01, -1.8296e+00,\n                       -7.2872e-01, -2.3411e-01, -7.3125e-01, -5.0041e-01, -7.1499e-01,\n                       -8.6958e-01, -1.4169e+00,  1.6303e+00, -9.1185e-01, -5.2493e-01,\n                       -8.8677e-01, -8.8981e-01, -1.2488e+00, -5.1089e-01, -1.9087e-01,\n                       -7.6174e-01, -8.2244e-01, -2.9322e-01, -5.1944e-01,  5.3200e-01,\n                       -1.9072e+00, -2.4870e+00, -5.7633e-01, -1.1689e-01, -7.0614e-01,\n                       -5.5277e+00])),\n              ('backbone.models.0.model.layer3.2.bn1.running_var',\n               tensor([3.2071, 2.3789, 3.4613, 2.9814, 2.2261, 2.3603, 2.3920, 1.8169, 2.1328,\n                       3.9472, 2.5107, 1.9799, 2.7222, 2.1264, 2.3768, 1.7899, 2.3274, 3.9605,\n                       1.9296, 2.8743, 3.3601, 2.4173, 2.5697, 2.8396, 2.1741, 2.0154, 3.3736,\n                       2.9926, 2.6318, 1.6245, 3.3467, 3.4082, 1.9433, 5.4484, 0.9404, 2.6159,\n                       2.9491, 2.0966, 2.0169, 2.0254, 1.7462, 1.7880, 1.9432, 2.6080, 2.1213,\n                       2.3806, 2.9501, 4.3635, 2.8725, 4.4027, 2.1680, 2.6522, 2.1146, 2.3835,\n                       2.4279, 3.3566, 2.5753, 2.6216, 2.5273, 2.2165, 3.0033, 2.6003, 2.5296,\n                       2.5019, 3.4356, 2.4856, 2.2624, 2.9962, 3.7398, 2.8655, 3.5840, 3.5982,\n                       1.6237, 2.7185, 2.9420, 3.0310, 1.8224, 2.6449, 3.3964, 3.3680, 1.7648,\n                       2.1616, 2.2020, 3.3073, 3.0701, 2.2958, 2.4435, 2.9532, 4.1669, 2.4982,\n                       2.8246, 2.5170, 1.7856, 3.3191, 2.2060, 3.2413, 2.6078, 2.5832, 2.4591,\n                       3.0572, 2.7188, 2.0513, 2.2539, 3.5178, 4.0132, 2.2459, 3.1847, 2.0979,\n                       3.1362, 2.8292, 2.9564, 3.0570, 2.2084, 3.2495, 2.4196, 2.2858, 2.6242,\n                       1.6185, 4.2918, 2.5744, 3.2473, 2.1652, 2.7290, 2.4232, 3.1513, 2.4078,\n                       1.9149, 2.4616, 2.3916, 2.9270, 2.5883, 4.2595, 2.1946, 2.7154, 2.8788,\n                       2.5084, 1.8924, 2.2094, 4.0043, 2.2211, 2.1623, 3.5883, 3.9137, 2.4271,\n                       2.6310, 2.4100, 3.3178, 4.3420, 2.7591, 3.1885, 1.8919, 2.9644, 2.0557,\n                       1.9455, 3.2033, 2.5902, 3.4894, 2.2726, 3.2547, 2.8623, 2.8178, 1.8237,\n                       3.7206, 2.8382, 1.4565, 4.2467, 2.2351, 3.4743, 2.5306, 2.4951, 3.0088,\n                       2.6773, 2.3629, 4.2737, 3.8176, 2.9544, 3.5302, 2.6807, 2.7478, 7.1789,\n                       3.1692, 2.2766, 4.4968, 2.9649, 2.3841, 2.9756, 3.3351, 2.1017, 2.3813,\n                       2.4551, 2.5866, 4.0682, 2.6940, 1.9544, 3.1529, 2.6328, 2.0372, 2.1756,\n                       2.4653, 1.7529, 1.3379, 2.8800, 2.2449, 2.5839, 2.8595, 1.9669, 2.5117,\n                       3.0537, 3.7375, 2.8296, 3.3826, 2.8866, 2.3471, 1.8174, 3.1896, 4.3810,\n                       3.8491, 2.6689, 3.6875, 2.3516, 3.1740, 2.4442, 3.4659, 1.8696, 3.1313,\n                       2.4775, 2.6486, 2.3568, 2.2261, 1.9470, 2.3507, 3.9261, 2.4637, 2.9749,\n                       3.5624, 2.2100, 2.1683, 3.0254, 3.9222, 2.1803, 2.3473, 2.8540, 2.1004,\n                       5.5402, 1.8902, 2.3177, 2.0103, 2.2956, 3.0444, 3.3595, 2.4998, 2.6858,\n                       2.9706, 2.9573, 2.1426, 3.9841])),\n              ('backbone.models.0.model.layer3.2.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.2.conv2.weight',\n               tensor([[[[ 5.0741e-03,  5.3850e-04, -1.4217e-02],\n                         [ 5.9640e-04,  3.5377e-02, -2.7814e-02],\n                         [ 3.3886e-02, -5.9269e-03, -1.0160e-02]],\n               \n                        [[ 2.9776e-02, -2.2685e-03,  2.0341e-03],\n                         [ 2.8408e-02,  1.5620e-02,  1.0836e-03],\n                         [-2.2819e-03, -1.9810e-02, -1.1061e-02]],\n               \n                        [[ 7.3332e-03,  3.4988e-03,  3.3325e-02],\n                         [-1.1508e-02,  9.7900e-03,  1.0163e-01],\n                         [-3.9076e-02,  4.8253e-02,  9.1094e-02]],\n               \n                        ...,\n               \n                        [[ 2.1742e-02, -1.2312e-02, -3.4376e-02],\n                         [ 3.3499e-02, -8.8685e-03, -4.9171e-02],\n                         [ 3.5417e-03,  2.5551e-02,  1.4727e-02]],\n               \n                        [[ 1.8157e-02, -7.0311e-03, -1.4783e-02],\n                         [ 9.1384e-03,  3.6440e-02, -6.9637e-02],\n                         [ 2.7932e-02, -1.9669e-02, -5.2318e-02]],\n               \n                        [[ 3.9928e-03, -8.1507e-02, -1.0664e-02],\n                         [ 5.4622e-02,  5.0130e-02, -3.8909e-02],\n                         [ 2.8550e-02,  9.7324e-02,  1.0966e-02]]],\n               \n               \n                       [[[ 7.6743e-05,  4.0231e-02, -2.7559e-04],\n                         [ 4.2610e-03,  4.4249e-02,  7.1213e-03],\n                         [-1.2696e-02, -3.3116e-02, -5.4179e-02]],\n               \n                        [[-3.1871e-02, -7.2865e-02, -4.8479e-02],\n                         [-8.3127e-02, -5.8257e-02, -1.0268e-01],\n                         [-4.3150e-02, -4.4717e-02, -5.2314e-02]],\n               \n                        [[ 1.5574e-02, -1.3353e-02,  2.0913e-02],\n                         [ 2.0278e-02, -1.6334e-02,  2.9687e-02],\n                         [ 4.4579e-02,  3.3484e-03,  6.8434e-03]],\n               \n                        ...,\n               \n                        [[ 1.7944e-03,  1.4421e-02,  3.1807e-02],\n                         [ 5.3639e-02,  3.4170e-02,  4.3659e-02],\n                         [ 7.6852e-03,  1.3995e-02,  2.2802e-02]],\n               \n                        [[-1.2668e-02, -4.8118e-02, -4.6344e-02],\n                         [-5.5690e-02, -2.6360e-02, -4.6204e-02],\n                         [-1.0628e-02, -1.3433e-03, -2.2034e-02]],\n               \n                        [[-4.6189e-03,  1.3255e-02, -3.3829e-02],\n                         [ 1.7373e-02, -4.0297e-02,  2.4562e-02],\n                         [-5.8211e-02, -2.4728e-02,  1.3531e-01]]],\n               \n               \n                       [[[ 2.1758e-02, -1.3633e-02,  2.4262e-03],\n                         [ 5.3083e-02, -4.8605e-02,  3.8514e-02],\n                         [ 1.5621e-02, -8.8118e-03,  7.8433e-03]],\n               \n                        [[ 4.9008e-02,  3.4027e-02,  4.0187e-02],\n                         [ 3.4619e-02, -1.7090e-02,  1.9268e-04],\n                         [ 3.0496e-02, -6.2671e-03, -1.3768e-02]],\n               \n                        [[-3.4913e-02, -1.5327e-02, -2.9959e-02],\n                         [-2.1456e-02, -4.3403e-02, -3.5336e-02],\n                         [-8.1580e-03, -3.9034e-02, -1.8619e-02]],\n               \n                        ...,\n               \n                        [[-8.1905e-03,  7.9027e-03, -7.5059e-03],\n                         [ 1.5830e-02, -3.4559e-02,  2.3262e-02],\n                         [-2.2498e-02, -3.3957e-02, -9.2560e-03]],\n               \n                        [[-5.4641e-03, -4.4318e-02, -8.1518e-03],\n                         [ 3.3883e-02, -5.8204e-02,  1.8770e-02],\n                         [-2.0277e-02, -8.7619e-02, -2.4559e-02]],\n               \n                        [[ 1.3151e-02,  5.7415e-02,  2.6207e-02],\n                         [ 5.0742e-02,  1.2364e-03, -8.4471e-03],\n                         [ 1.4104e-02,  3.0610e-03,  2.1260e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 5.7612e-03,  5.1607e-02,  3.0335e-02],\n                         [ 1.9947e-02, -1.2337e-02,  8.2630e-02],\n                         [ 1.6931e-02,  5.3065e-02,  7.9387e-02]],\n               \n                        [[-4.4828e-02, -5.7270e-02, -1.9886e-02],\n                         [ 1.3431e-03, -3.3522e-02, -2.6624e-03],\n                         [ 4.9912e-03, -4.3886e-02, -2.6895e-02]],\n               \n                        [[ 1.9321e-03,  2.6570e-02,  9.6053e-03],\n                         [ 3.0944e-02,  3.2561e-02,  5.5872e-02],\n                         [-5.0829e-03,  1.9069e-02,  2.0029e-03]],\n               \n                        ...,\n               \n                        [[-6.1997e-03,  4.6441e-03, -1.6740e-02],\n                         [ 4.1769e-03,  4.1958e-03,  4.4609e-02],\n                         [ 1.0935e-02,  3.3272e-02,  3.7197e-02]],\n               \n                        [[-2.0447e-02, -7.8985e-03, -1.5314e-02],\n                         [ 2.0977e-02,  1.6390e-02,  1.6604e-02],\n                         [ 1.8023e-02,  1.4712e-02,  3.6441e-02]],\n               \n                        [[ 1.9499e-02,  3.2937e-02, -1.3191e-02],\n                         [ 2.4565e-03,  2.9314e-02,  4.5418e-02],\n                         [-3.6029e-02, -5.4493e-03,  9.2875e-02]]],\n               \n               \n                       [[[-1.9917e-02, -3.3033e-02, -2.2270e-03],\n                         [-2.7456e-02,  1.3945e-03, -3.9684e-02],\n                         [-6.1267e-03,  3.3860e-02, -5.5280e-03]],\n               \n                        [[ 2.6722e-02, -4.2355e-03, -1.8646e-04],\n                         [-4.5527e-02, -6.5199e-02, -3.8737e-02],\n                         [-9.1981e-03, -1.5868e-02, -1.1233e-02]],\n               \n                        [[ 3.9574e-02,  5.3018e-04,  3.2258e-02],\n                         [ 1.0522e-02,  3.0628e-02,  3.9334e-03],\n                         [ 2.2378e-02, -4.6851e-03,  7.1815e-03]],\n               \n                        ...,\n               \n                        [[ 1.2317e-02, -1.6507e-02,  2.7861e-02],\n                         [-1.9820e-02, -9.8567e-02, -7.7657e-03],\n                         [ 1.9508e-02, -6.5917e-02, -1.9667e-02]],\n               \n                        [[ 3.1594e-02,  1.1778e-02, -2.4118e-03],\n                         [ 1.5943e-02, -8.8093e-03, -4.6474e-03],\n                         [ 2.6614e-02, -1.2560e-02,  1.1399e-02]],\n               \n                        [[-3.2134e-03,  4.4939e-02, -3.9483e-02],\n                         [-2.7632e-02,  7.9533e-02,  2.7602e-03],\n                         [-2.9383e-02, -3.4074e-04,  6.8113e-03]]],\n               \n               \n                       [[[-4.3621e-04, -5.2723e-03, -1.6022e-02],\n                         [-3.4245e-02, -4.7207e-02, -4.7790e-02],\n                         [ 7.7140e-03,  4.2935e-03, -8.8866e-03]],\n               \n                        [[ 6.8116e-03,  5.5972e-02, -1.0371e-02],\n                         [-2.4203e-02,  1.3520e-01,  2.1249e-02],\n                         [-4.7257e-02, -4.0948e-02, -2.1260e-02]],\n               \n                        [[ 4.2636e-03, -1.9856e-02,  2.2416e-02],\n                         [-1.4363e-02, -1.0293e-01, -3.1224e-02],\n                         [-4.1590e-03, -1.9609e-02, -2.2277e-02]],\n               \n                        ...,\n               \n                        [[ 2.9268e-02,  3.6568e-02,  2.8575e-02],\n                         [ 4.1253e-02, -1.1090e-02,  6.2592e-02],\n                         [ 2.1362e-02,  7.3000e-02,  2.8468e-02]],\n               \n                        [[-1.3482e-02, -9.6427e-03,  1.3326e-02],\n                         [ 1.3689e-02,  5.4315e-02,  2.2311e-03],\n                         [-1.6204e-03, -8.8678e-04,  5.1695e-03]],\n               \n                        [[ 2.5378e-04,  2.5848e-02,  1.5759e-02],\n                         [ 2.0874e-02,  6.8446e-02, -1.2870e-02],\n                         [-1.8065e-02, -2.7708e-02, -3.0966e-02]]]])),\n              ('backbone.models.0.model.layer3.2.bn2.weight',\n               tensor([0.9199, 0.7958, 0.9710, 1.1156, 0.6747, 0.6473, 1.0341, 0.9943, 0.9048,\n                       0.7367, 0.8827, 0.8609, 0.5674, 0.8289, 0.6205, 0.9032, 0.6928, 0.9833,\n                       1.0478, 0.7883, 0.8930, 0.8057, 0.7953, 0.8296, 0.9546, 0.9418, 0.7988,\n                       0.7195, 0.7311, 0.5628, 0.6984, 1.1732, 1.0000, 1.0041, 0.7666, 0.8757,\n                       1.0434, 0.7910, 0.9465, 0.6637, 0.7480, 1.3634, 0.7362, 0.9037, 0.6716,\n                       0.7839, 0.7868, 0.8396, 0.8562, 0.8787, 0.8367, 0.7443, 0.8103, 0.8377,\n                       0.8297, 0.9914, 0.9304, 0.8860, 0.9699, 0.7194, 0.7906, 1.0938, 1.0304,\n                       0.8091, 0.8670, 0.7832, 0.8263, 0.9258, 0.8104, 0.7898, 0.8219, 1.0068,\n                       0.7924, 0.8411, 0.7773, 0.7109, 0.8881, 0.8467, 0.9360, 0.8737, 0.8640,\n                       0.8319, 0.7826, 0.7945, 0.7607, 0.8787, 0.8286, 1.0091, 0.7901, 0.6853,\n                       0.8821, 0.9466, 0.7767, 0.9400, 1.2000, 0.9158, 0.8118, 1.0333, 0.7331,\n                       0.8890, 1.1201, 1.2763, 0.8337, 1.0048, 0.5705, 0.8422, 0.9205, 0.9972,\n                       0.9348, 0.6456, 0.5840, 0.7695, 0.7794, 0.8244, 0.8615, 0.9740, 0.8250,\n                       0.9111, 0.8421, 0.8516, 0.5910, 1.2354, 1.2049, 1.0330, 0.9244, 0.5704,\n                       0.7202, 0.7094, 0.6555, 0.9610, 0.9152, 0.8453, 0.7377, 0.6235, 0.7656,\n                       0.8503, 0.9481, 1.1519, 0.8645, 0.8055, 0.8625, 0.9359, 0.8164, 1.0254,\n                       0.9446, 0.7599, 0.9334, 0.8708, 1.0453, 1.1094, 0.9541, 1.0622, 0.9135,\n                       0.9801, 0.8435, 0.8878, 0.8357, 0.9311, 1.1523, 0.8277, 0.9218, 1.0628,\n                       0.8503, 0.5099, 0.7056, 0.7860, 0.8342, 0.9358, 0.7468, 0.8539, 0.8071,\n                       0.8599, 0.7773, 0.7964, 0.8398, 0.8235, 0.8471, 0.8596, 0.9078, 0.9271,\n                       0.9176, 0.8812, 0.6783, 0.9756, 0.9260, 0.7704, 0.8787, 0.7103, 1.0865,\n                       0.7594, 0.9531, 0.8719, 0.9165, 0.9273, 0.8529, 0.8671, 0.8604, 0.8989,\n                       0.9833, 0.8442, 0.9139, 0.9366, 1.0840, 0.9713, 0.8629, 0.9216, 0.7052,\n                       0.6197, 1.1204, 0.8961, 0.8570, 0.8966, 0.7094, 0.9447, 0.9728, 0.8799,\n                       0.8316, 0.8702, 0.8346, 0.9484, 1.0101, 0.8966, 0.8700, 0.7997, 0.8884,\n                       0.6960, 0.8868, 0.7663, 1.0051, 1.0557, 0.9005, 0.7861, 0.8967, 0.6849,\n                       0.9281, 0.6384, 0.9330, 0.7632, 0.9658, 0.8961, 0.9032, 0.8575, 0.8092,\n                       0.7491, 0.9714, 0.5939, 0.9841, 0.9355, 0.8348, 0.7388, 0.7882, 0.7986,\n                       0.8784, 0.6860, 0.9480, 0.9952])),\n              ('backbone.models.0.model.layer3.2.bn2.bias',\n               tensor([-0.5519, -0.2777, -0.8844, -1.2168, -0.0079, -0.1471, -0.6886, -0.5832,\n                       -0.5491, -0.1921, -0.7789, -0.6729,  0.1359, -0.6132, -0.0415, -0.5392,\n                       -0.3151, -0.7546, -1.0023, -0.2814, -0.3678, -0.4643, -0.4951, -0.3388,\n                       -0.7032, -0.8931, -0.3290, -0.1725, -0.0861,  0.1590, -0.1161, -1.6128,\n                       -1.0731, -0.7137, -0.2942, -0.3946, -0.8023, -0.4651, -0.7659,  0.2425,\n                       -0.1838, -2.0235, -0.0092, -0.5843, -0.1015, -0.4576, -0.2868, -0.2450,\n                       -0.2159, -0.5618, -0.7286, -0.1136, -0.2987, -0.5268, -0.2641, -0.8163,\n                       -0.5111, -0.5999, -1.0083, -0.4455, -0.5228, -0.8122, -0.9206, -0.3646,\n                       -0.6311, -0.1875, -0.5531, -0.6203, -0.1759, -0.3600, -0.4056, -0.8013,\n                       -0.2182, -0.3618, -0.3092, -0.2068, -0.7561, -0.4016, -0.5310, -0.8397,\n                       -0.5872, -0.1088, -0.1567, -0.2962, -0.1780, -0.7541, -0.5324, -0.5239,\n                       -0.3825, -0.2860, -0.6861, -0.5861, -0.3423, -0.5616, -0.6026, -0.7535,\n                       -0.6159, -0.9553, -0.2432, -0.5513, -1.3736, -1.8519, -0.6223, -0.7848,\n                        0.1257, -0.4171, -0.7307, -0.9162, -0.7146,  0.2437,  0.5135, -0.4025,\n                       -0.0945, -0.6652, -0.4609, -0.8210, -0.4226, -0.9232, -0.5684, -0.1763,\n                        0.1848, -1.7785, -1.1381, -0.8662, -0.6669,  0.0998, -0.0889, -0.2075,\n                       -0.0192, -0.8950, -0.6062, -0.5432, -0.2595,  0.0681, -0.1364, -0.4749,\n                       -0.5799, -1.5652, -0.4718, -0.1956, -0.8371, -0.7854, -0.2857, -0.9339,\n                       -1.1887, -0.2120, -0.6261, -0.2202, -1.5021, -1.6900, -0.8877, -1.2157,\n                       -0.7882, -0.7823, -0.3162, -0.4020, -0.3590, -0.7518, -1.7602, -0.2583,\n                       -0.4669, -1.4192, -0.4047,  1.2913, -0.2279, -0.5120, -0.6070, -0.3257,\n                       -0.2968, -0.5736, -0.5130, -0.1771, -0.2383, -0.6670, -0.3006, -0.5462,\n                       -0.5234, -0.2777, -0.4292, -0.6533, -0.7941, -0.4301,  0.0506, -0.7167,\n                       -0.7639, -0.2996, -0.3932, -0.2985, -0.6522, -0.1773, -1.3128, -0.6952,\n                       -0.3461, -1.1229, -0.4062, -0.5217, -0.5304, -0.1299, -0.9892, -0.2922,\n                       -0.6472, -0.6323, -1.5455, -0.9505, -0.7394, -0.5987, -0.4850,  0.2222,\n                       -1.3543, -0.4157, -0.5893, -0.7159, -0.2790, -0.0634, -0.5976, -0.4335,\n                       -0.4009, -0.5842, -0.4954, -0.5738, -0.7130, -0.5727, -0.4849, -0.4856,\n                       -0.7231,  0.0024, -0.6999, -0.7881, -0.7881, -1.0166, -0.8368, -0.2742,\n                       -0.1899, -0.0714, -0.6201,  0.1370, -0.7884, -0.3746, -1.1461, -0.5859,\n                       -0.6451, -0.4939, -0.4445, -0.1883, -0.8482,  0.0404, -0.6690, -0.3522,\n                       -0.4146, -0.3855, -0.4074, -0.3945, -0.4448, -0.1173, -0.4753, -1.3083])),\n              ('backbone.models.0.model.layer3.2.bn2.running_mean',\n               tensor([-0.5081, -0.8045, -0.6611, -1.1383,  0.0168, -0.0697, -0.8536, -0.8892,\n                       -0.7598, -0.1046, -0.5940, -0.3655, -0.4594, -0.1972,  0.4312, -0.3858,\n                       -0.1518, -0.2130, -0.4567, -0.1351, -0.4980, -0.1171, -0.2815, -0.4520,\n                       -0.3089, -0.6521, -0.3826, -0.0745, -0.1242,  0.8138, -0.1573, -1.0064,\n                       -0.5986, -0.4831, -0.1985, -0.3448, -0.3664, -0.1900, -0.3395, -0.7267,\n                        0.5063, -1.6800, -0.5377, -0.3334, -0.4447, -0.3668, -0.2013, -0.4825,\n                       -0.2707, -0.2081, -0.3959, -0.3089, -0.3833, -0.5743, -0.0832, -0.4557,\n                       -0.4243, -0.4662, -0.6103,  2.9245, -0.2909, -0.9536, -0.9011,  0.2755,\n                       -0.4009, -0.3720, -0.1818, -0.7732, -0.2532, -0.4031, -0.5245, -0.6058,\n                       -0.4277, -0.0703, -0.3554, -0.4012, -0.0929, -0.2280, -0.4645, -0.3541,\n                       -0.6155, -0.0954, -0.1244, -0.3492, -0.1557, -0.4912, -0.6424,  0.1624,\n                       -0.2726, -0.1483, -0.4556, -0.5070, -0.3107, -0.5331, -1.3227, -0.2631,\n                       -0.5260, -0.9495, -0.0283, -0.3002, -1.0139, -1.7219, -0.5599, -0.6332,\n                       -0.0551, -0.5272, -0.3570, -0.4736, -0.6196,  1.2438,  0.4493, -0.3711,\n                       -0.1993, -0.1271,  0.2676, -0.6262, -0.2951, -0.5892, -0.2647, -0.4547,\n                       -0.1365, -1.0189, -0.6410, -0.8898, -0.7663, -0.0892, -0.0717, -0.3170,\n                       -0.1380, -0.4597, -0.6012, -0.1348, -0.3707, -0.0658, -0.2240, -0.3196,\n                       -0.8202, -1.0770, -0.0717, -0.5147, -0.3825, -0.3251, -0.2986, -0.5127,\n                       -0.2564, -0.3380, -0.3904, -0.1646, -1.2258, -1.4100, -0.2718, -1.0639,\n                       -0.7867, -0.3728, -0.3370,  0.0649, -0.4057, -0.2232, -1.0075, -0.1340,\n                       -0.3991, -0.9764, -0.1407, -1.0657,  0.3396, -0.4632, -0.7263,  0.7057,\n                       -0.5074, -0.5129, -0.4128, -0.1818, -0.0890, -0.6656, -0.6706, -0.4792,\n                       -0.4645, -0.5993, -0.7423, -0.2936, -0.4840, -0.6213,  0.0401, -0.7177,\n                       -0.1617, -0.4246, -0.8374, -0.2325, -1.0531, -0.0531, -0.8634, -0.4559,\n                       -0.6349, -0.3939, -0.4562, -0.4201, -0.5615, -0.6586, -0.8144, -0.5203,\n                       -0.1147, -0.6983, -1.4207, -0.6653, -0.4592, -0.4657, -0.0076,  1.7979,\n                       -0.7792, -0.4514, -0.2640, -0.6131,  0.0285, -0.7200, -0.3976, -0.5485,\n                       -0.3498, -0.3360, -0.4311, -0.6333, -0.2578, -0.7836, -0.7076, -0.5836,\n                       -0.6354, -0.3816, -0.1887,  0.4253, -0.8316, -0.8224, -0.7106, -0.3342,\n                       -0.3237, -0.1230, -0.5772,  0.6098, -0.6338, -0.3141, -0.5129, -0.5953,\n                       -0.5455, -0.2224, -0.3227, -0.4304, -0.3330, -0.3298, -0.7320, -0.6053,\n                       -0.3942, -0.1927,  0.4185, -0.4745,  0.0081, -0.2616, -0.6553, -1.0982])),\n              ('backbone.models.0.model.layer3.2.bn2.running_var',\n               tensor([1.4563, 1.2749, 0.6431, 1.4622, 1.2847, 0.7317, 1.9874, 1.2583, 1.3359,\n                       1.1199, 0.7698, 1.0615, 0.9938, 0.7310, 0.8048, 0.9339, 0.5925, 1.0821,\n                       0.9819, 1.1502, 1.6914, 0.7718, 0.7993, 1.0437, 0.9489, 1.0668, 1.0040,\n                       1.2259, 1.1420, 0.7319, 1.4042, 1.0142, 0.8969, 0.9846, 0.9537, 1.1935,\n                       1.3311, 0.4753, 0.9563, 1.3952, 1.6588, 1.7256, 1.7308, 1.1540, 0.9072,\n                       0.9194, 1.2605, 1.5235, 1.5561, 0.8998, 0.8070, 1.1350, 1.4009, 0.9917,\n                       1.1024, 1.0542, 1.3499, 1.1030, 1.1752, 0.4474, 0.7757, 1.9450, 1.4574,\n                       1.4040, 0.6261, 1.5925, 1.0208, 1.0003, 1.3854, 1.1164, 1.0071, 1.0715,\n                       1.2540, 1.0094, 1.0342, 0.8882, 0.8323, 1.3079, 1.1924, 0.5619, 1.1258,\n                       1.3292, 1.3256, 1.0262, 1.1744, 1.0938, 0.7562, 1.6736, 0.7825, 0.7043,\n                       0.7639, 1.0854, 0.8281, 1.2948, 1.0361, 0.9647, 0.7462, 1.2890, 0.9866,\n                       0.8355, 1.0957, 1.6073, 1.0855, 1.2163, 0.8510, 1.0064, 0.9559, 0.8657,\n                       1.3222, 1.3957, 1.2996, 0.8996, 1.6939, 0.9601, 1.4176, 0.8301, 0.8975,\n                       0.9015, 1.0375, 1.1687, 0.9933, 1.3251, 1.1695, 1.4163, 0.8616, 0.7824,\n                       1.2275, 1.1079, 0.8943, 0.7832, 1.3665, 1.2310, 0.8811, 1.1802, 1.4391,\n                       1.1366, 1.2410, 1.2739, 1.0757, 1.6522, 0.7894, 0.9768, 1.9019, 1.0477,\n                       0.8479, 1.0867, 1.4498, 2.0119, 0.8958, 1.4031, 0.8868, 1.3039, 1.0035,\n                       1.3774, 1.2597, 1.7818, 1.1297, 0.7482, 0.7617, 1.2058, 1.0663, 0.8094,\n                       1.3285, 1.5500, 1.6652, 0.6033, 1.2510, 1.0891, 1.1592, 0.9956, 0.6383,\n                       1.5285, 0.9993, 0.7637, 1.3114, 0.8504, 1.1148, 1.8885, 1.8304, 1.1734,\n                       0.8877, 1.6288, 1.3068, 1.3661, 1.0503, 1.0937, 1.3650, 0.8186, 0.8384,\n                       1.2038, 0.4837, 0.7760, 1.6551, 0.8702, 1.0509, 0.7878, 1.0174, 2.2646,\n                       0.5716, 0.9901, 1.0711, 1.2673, 0.9657, 0.9948, 0.6881, 1.1674, 0.4063,\n                       1.4507, 1.1898, 1.9050, 1.0140, 0.6487, 0.7712, 2.3145, 1.0601, 0.9298,\n                       1.0294, 0.8143, 0.8087, 1.3216, 1.2748, 1.2040, 0.8124, 0.8257, 1.2106,\n                       1.1509, 1.0047, 0.7560, 1.2735, 1.1368, 0.9834, 1.4420, 2.3159, 1.0610,\n                       1.0477, 1.0396, 1.0855, 0.7778, 0.5994, 1.1303, 0.9351, 1.2265, 1.1167,\n                       0.9167, 0.8047, 0.7835, 1.1397, 1.6652, 1.2524, 0.6255, 1.0410, 1.0453,\n                       1.0823, 0.9163, 1.1894, 1.1752])),\n              ('backbone.models.0.model.layer3.2.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.2.conv3.weight',\n               tensor([[[[ 0.0261]],\n               \n                        [[ 0.0350]],\n               \n                        [[ 0.0095]],\n               \n                        ...,\n               \n                        [[ 0.0152]],\n               \n                        [[ 0.0691]],\n               \n                        [[-0.0113]]],\n               \n               \n                       [[[-0.0227]],\n               \n                        [[-0.0092]],\n               \n                        [[ 0.0474]],\n               \n                        ...,\n               \n                        [[-0.0433]],\n               \n                        [[-0.0159]],\n               \n                        [[-0.0513]]],\n               \n               \n                       [[[-0.0292]],\n               \n                        [[ 0.0213]],\n               \n                        [[-0.0096]],\n               \n                        ...,\n               \n                        [[ 0.0169]],\n               \n                        [[ 0.0123]],\n               \n                        [[-0.0316]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0182]],\n               \n                        [[-0.0402]],\n               \n                        [[ 0.0052]],\n               \n                        ...,\n               \n                        [[-0.0496]],\n               \n                        [[ 0.0544]],\n               \n                        [[-0.0224]]],\n               \n               \n                       [[[ 0.0163]],\n               \n                        [[-0.0544]],\n               \n                        [[ 0.0191]],\n               \n                        ...,\n               \n                        [[ 0.0691]],\n               \n                        [[ 0.0111]],\n               \n                        [[ 0.0854]]],\n               \n               \n                       [[[ 0.0013]],\n               \n                        [[-0.0165]],\n               \n                        [[-0.0791]],\n               \n                        ...,\n               \n                        [[-0.0038]],\n               \n                        [[ 0.0210]],\n               \n                        [[ 0.0829]]]])),\n              ('backbone.models.0.model.layer3.2.bn3.weight',\n               tensor([-0.4070, -0.1984, -0.0696,  ...,  0.1234, -0.2746, -0.1757])),\n              ('backbone.models.0.model.layer3.2.bn3.bias',\n               tensor([-0.4031, -0.0701,  0.3368,  ...,  0.3540, -0.1511,  0.1304])),\n              ('backbone.models.0.model.layer3.2.bn3.running_mean',\n               tensor([ 0.3050,  0.1059, -0.0261,  ..., -0.0889, -0.0614,  0.0299])),\n              ('backbone.models.0.model.layer3.2.bn3.running_var',\n               tensor([0.0910, 0.0549, 0.0176,  ..., 0.0632, 0.0546, 0.0605])),\n              ('backbone.models.0.model.layer3.2.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.3.conv1.weight',\n               tensor([[[[-0.0559]],\n               \n                        [[-0.0017]],\n               \n                        [[ 0.0385]],\n               \n                        ...,\n               \n                        [[ 0.0621]],\n               \n                        [[-0.0135]],\n               \n                        [[ 0.0287]]],\n               \n               \n                       [[[ 0.0462]],\n               \n                        [[ 0.0442]],\n               \n                        [[-0.0889]],\n               \n                        ...,\n               \n                        [[-0.0885]],\n               \n                        [[-0.0764]],\n               \n                        [[ 0.0792]]],\n               \n               \n                       [[[ 0.0410]],\n               \n                        [[ 0.0284]],\n               \n                        [[-0.0367]],\n               \n                        ...,\n               \n                        [[-0.0457]],\n               \n                        [[ 0.0233]],\n               \n                        [[ 0.0129]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0286]],\n               \n                        [[-0.0219]],\n               \n                        [[-0.0432]],\n               \n                        ...,\n               \n                        [[ 0.1253]],\n               \n                        [[ 0.0210]],\n               \n                        [[ 0.0043]]],\n               \n               \n                       [[[-0.0503]],\n               \n                        [[ 0.0150]],\n               \n                        [[-0.0615]],\n               \n                        ...,\n               \n                        [[ 0.0266]],\n               \n                        [[ 0.0744]],\n               \n                        [[ 0.0431]]],\n               \n               \n                       [[[ 0.1428]],\n               \n                        [[-0.1035]],\n               \n                        [[ 0.1066]],\n               \n                        ...,\n               \n                        [[ 0.0311]],\n               \n                        [[-0.0708]],\n               \n                        [[ 0.0740]]]])),\n              ('backbone.models.0.model.layer3.3.bn1.weight',\n               tensor([0.9402, 0.7810, 0.9278, 0.9006, 0.8476, 0.9638, 0.8465, 0.9912, 0.8415,\n                       0.7004, 0.8403, 0.9018, 0.8002, 0.8551, 0.8888, 0.8335, 0.6417, 0.8337,\n                       0.8106, 0.9188, 0.7385, 1.1690, 0.7255, 0.7817, 0.9569, 0.9602, 0.8050,\n                       0.9638, 0.8222, 1.2478, 0.8811, 0.9897, 0.8080, 0.8367, 0.6454, 0.8518,\n                       0.9440, 0.6651, 0.8508, 0.8485, 0.8457, 0.8538, 0.8146, 0.6297, 0.8352,\n                       0.6380, 1.1479, 1.0899, 0.8826, 0.7363, 1.0120, 1.1278, 1.0665, 1.3174,\n                       0.7366, 0.7965, 0.7602, 0.4766, 1.0183, 0.6597, 0.8339, 0.9344, 0.9534,\n                       0.6482, 0.7864, 0.9613, 1.0091, 0.9430, 0.8827, 0.9052, 1.3358, 0.7622,\n                       0.9269, 0.7493, 0.7167, 0.8263, 0.9175, 1.0233, 0.9020, 0.8440, 0.8503,\n                       0.8781, 0.8253, 1.1138, 0.7132, 0.8978, 1.0092, 0.9189, 1.3402, 0.9988,\n                       0.7653, 0.9098, 1.0640, 0.6495, 0.8496, 0.9087, 0.8126, 0.9167, 0.6628,\n                       1.0847, 0.8967, 1.2582, 0.9682, 0.9153, 0.6983, 0.8602, 0.8812, 0.8854,\n                       0.8872, 0.9059, 0.8204, 0.7105, 0.9276, 0.7729, 0.8241, 1.0289, 1.1426,\n                       0.7483, 0.7562, 1.0401, 0.7398, 0.8570, 0.9212, 0.8097, 0.7836, 0.8083,\n                       0.6742, 0.8558, 0.8114, 0.8138, 0.8173, 0.8892, 1.1001, 1.0932, 1.0682,\n                       0.8394, 0.9104, 0.8613, 0.6762, 0.7479, 0.8828, 0.7847, 1.0024, 0.8517,\n                       0.9089, 0.9215, 1.0445, 0.8938, 0.7545, 0.7860, 0.7356, 0.7104, 1.1004,\n                       0.7556, 0.8891, 0.7999, 0.8299, 0.9739, 1.0242, 0.7943, 0.9539, 0.6517,\n                       0.7501, 0.8849, 0.9912, 1.1170, 1.0846, 0.9755, 1.0893, 1.0043, 0.8594,\n                       0.9103, 0.8873, 0.8777, 0.8995, 0.8148, 0.8076, 0.8547, 0.8197, 0.9029,\n                       0.9201, 0.7862, 1.0235, 1.0162, 0.9599, 0.4598, 0.6973, 0.7828, 0.8326,\n                       0.7613, 0.9308, 0.9381, 0.7510, 1.0463, 0.8529, 0.8595, 0.8263, 0.9656,\n                       1.0180, 0.8215, 1.0315, 0.8984, 0.7794, 0.7455, 0.7894, 0.8051, 0.7925,\n                       0.8664, 1.0013, 0.8070, 1.0104, 0.8142, 0.8364, 0.7425, 0.6808, 0.9853,\n                       0.6997, 0.8170, 0.8345, 0.9265, 0.6728, 0.7180, 1.0271, 0.8989, 0.8153,\n                       0.8274, 0.9061, 0.8247, 0.9456, 1.1134, 0.8909, 1.0087, 0.8703, 0.9247,\n                       1.3840, 0.8161, 0.8599, 1.0142, 0.9656, 0.9054, 0.8901, 0.8089, 0.8153,\n                       0.9965, 0.8105, 0.7735, 0.7552, 0.7393, 0.7205, 0.8876, 0.8298, 0.9793,\n                       0.7334, 0.7400, 1.0935, 0.6962])),\n              ('backbone.models.0.model.layer3.3.bn1.bias',\n               tensor([-0.5321, -0.4179, -0.4449, -0.3359, -0.6490, -0.5856, -0.6837, -1.0818,\n                       -0.4430,  0.0043, -0.5106, -0.8504, -0.3455, -0.5653, -0.5847, -0.4189,\n                       -0.0109, -0.3687, -0.4531, -0.7566, -0.3068,  0.4380, -0.0947, -0.4227,\n                       -1.0540, -0.9361, -0.6032, -0.3877, -0.3835, -1.1073, -0.7852, -0.9369,\n                       -0.2417, -0.3326, -0.1484, -0.5878, -0.7722, -0.1001, -0.5466, -0.4798,\n                       -0.2071, -0.6490, -0.4817,  0.0197, -0.5127,  0.0142, -1.1557, -1.1500,\n                       -0.6174, -0.2548, -0.7081, -0.8701, -1.7913, -1.5750, -0.3908, -0.4627,\n                       -0.2972,  0.6399, -0.7541, -0.0932, -0.3403, -0.9051, -0.6857,  0.1322,\n                       -0.2512, -0.5571, -1.6090, -0.4379, -0.4516, -0.6683, -0.8890, -0.2509,\n                       -0.7049, -0.2422, -0.1842, -0.3820, -0.8341, -0.8534, -0.8107, -0.9787,\n                       -0.5890, -0.6221, -0.4500, -0.7807, -0.2173, -0.5437, -0.9094, -0.7846,\n                       -1.6385, -0.4234, -0.3065, -0.6144, -1.5321, -0.1123, -0.6705, -0.4280,\n                       -0.3954, -0.5578, -0.0088, -1.1887, -0.7114, -1.1027, -0.8823, -0.4672,\n                       -0.0129, -0.7284, -0.4120, -0.7392, -0.7473, -0.7254, -0.1500, -0.2585,\n                       -0.6146, -0.2201, -0.3894, -0.7833, -0.5734, -0.1085, -0.6340, -1.4986,\n                       -0.2207, -0.5912, -0.9315, -0.5708, -0.2507, -0.4798, -0.0048, -0.6198,\n                       -0.6948, -0.3541, -0.4356, -0.7662, -0.5901, -0.8615, -1.0335, -0.1710,\n                       -0.5596, -0.8013, -0.1397, -0.3803, -0.8325, -0.3860, -1.3767, -0.4590,\n                       -0.7521, -0.8447, -0.9599, -0.5513, -0.3685, -0.6128, -0.3177, -0.2179,\n                       -0.9203, -0.4068, -0.4195, -0.3669, -0.3455, -0.3451, -0.6766, -0.4884,\n                       -0.7048, -0.0643, -0.3503, -0.4706, -0.4131, -0.6883, -0.8276, -0.7510,\n                       -0.7866, -0.7703, -0.6568, -0.6500, -0.7025, -0.6933, -1.4115, -0.3374,\n                       -0.4608, -0.5643, -0.4095, -0.3138, -0.7460, -0.2760, -0.8226, -1.4860,\n                       -0.7279,  0.5108, -0.1710, -0.3934, -0.4940, -0.1944, -0.5348, -0.7417,\n                       -0.4320, -0.6985, -0.4866, -0.4009, -0.3524, -1.0389, -1.0850, -0.4196,\n                       -0.9089, -0.4660, -0.5785, -0.2479, -0.4536, -0.3995, -0.3951, -0.8214,\n                       -0.8719, -0.5684, -0.6915, -0.6070, -0.6416, -0.2870, -0.2167, -0.4922,\n                       -0.0836, -0.6094, -0.3936, -0.7213, -0.0517, -0.2715, -0.7919, -0.8857,\n                       -0.5368, -0.3758, -0.4746, -0.1982, -0.7880, -0.1383, -0.7047, -0.8272,\n                       -0.4278, -0.7603, -1.9497, -0.4651, -0.3389, -0.7539, -0.4024, -0.5598,\n                       -0.3305, -0.4069, -0.3800, -0.9496, -0.4171, -0.2354, -0.5486, -0.4376,\n                       -0.0843, -0.4331, -0.3791, -0.7669, -0.3192, -0.3024, -1.7178, -0.2230])),\n              ('backbone.models.0.model.layer3.3.bn1.running_mean',\n               tensor([-8.3006e-01, -1.4951e-01, -1.8736e+00, -1.8431e+00, -9.0645e-01,\n                        7.0018e-02, -1.4711e+00, -2.9410e+00, -1.3768e+00, -2.6056e+00,\n                       -2.0588e+00, -1.6147e+00, -8.7250e-01, -5.9883e-01, -1.7352e+00,\n                       -9.8732e-01, -6.6177e-01, -1.8186e+00, -1.5940e+00, -1.1975e+00,\n                       -8.7792e-01, -1.8401e+00, -2.5517e+00, -4.0750e-01, -5.3628e-01,\n                       -2.7936e+00, -6.4261e-01, -2.5817e+00,  9.5890e-02, -1.6924e+00,\n                       -9.8414e-01, -6.6782e-01, -2.1989e+00, -9.3138e-01, -3.4750e-01,\n                       -1.1806e+00, -1.7373e+00, -2.0827e-01, -1.4353e+00, -1.6206e+00,\n                       -2.6271e+00, -1.2951e+00, -4.5300e-01,  1.6090e-02, -1.5203e-01,\n                       -1.1209e+00, -2.5307e+00, -1.0947e+00, -2.2891e-01, -1.6920e+00,\n                       -1.6549e+00, -2.2667e+00, -4.4561e+00, -2.7403e+00,  1.2538e-02,\n                       -7.0363e-01, -2.8709e+00, -9.7346e+00, -9.0747e-01,  9.9329e-02,\n                       -1.1759e+00, -1.1290e+00, -3.1177e+00, -9.4988e-01, -2.1138e+00,\n                       -1.6242e+00, -4.8289e+00, -1.3104e+00, -1.9287e+00, -4.0975e-01,\n                       -1.7773e+00, -1.0401e+00,  9.3368e-02, -1.3961e-01, -1.1678e-01,\n                        7.0061e-01, -6.2498e-01, -2.1908e+00, -1.8189e+00, -1.5356e+00,\n                       -1.4024e+00, -1.0365e+00, -2.0475e+00, -2.2989e+00, -2.0727e-01,\n                       -2.1958e+00, -2.2943e+00, -9.3483e-01, -3.7151e+00, -2.3721e+00,\n                       -1.2023e+00, -1.6812e+00, -3.8922e+00,  5.4561e-01, -1.1566e+00,\n                       -9.5523e-01, -8.0878e-02, -2.1507e+00, -1.6557e+00, -8.3125e-01,\n                       -9.5251e-01, -2.9703e+00, -2.4177e+00, -2.6508e+00, -1.8941e+00,\n                       -2.5954e+00, -1.3837e+00, -2.4655e-01, -1.9045e+00, -8.2516e-01,\n                       -6.2887e-01, -1.1817e+00, -7.9128e-01, -5.5867e-01, -4.8482e-02,\n                       -8.8826e-01, -1.6175e+00, -4.4423e-01, -2.0876e+00, -1.6401e+00,\n                       -2.0299e+00, -2.6177e+00, -2.4220e+00,  2.8122e-01, -1.2114e+00,\n                       -1.4943e+00, -1.9431e+00, -1.3634e+00,  1.3457e+00, -2.1547e+00,\n                       -1.4329e+00, -1.3813e+00, -5.1236e-01, -2.2075e+00, -2.9721e+00,\n                       -2.5148e+00, -1.4605e-01, -6.8391e-01, -4.9408e-01,  1.1258e+00,\n                       -7.8903e-01, -1.6018e+00, -7.8512e-01,  8.4870e-01, -1.3233e+00,\n                       -1.6270e+00, -2.3753e+00, -1.3598e+00, -9.8629e-01, -1.4157e+00,\n                       -9.8313e-01,  2.9809e-01, -7.8908e-01,  1.0619e+00, -1.9870e+00,\n                       -8.0350e-01, -1.8137e+00, -1.8129e+00, -1.7605e+00, -8.6469e-01,\n                       -1.3455e+00, -1.4641e-01, -2.1276e+00, -7.7475e-01, -3.3535e+00,\n                       -1.9026e+00, -2.4401e+00, -1.8686e+00, -2.5645e+00, -8.1996e-01,\n                       -4.9246e-01, -5.7310e-01, -4.2197e-01, -1.5869e+00, -4.5837e+00,\n                       -7.9955e-01,  1.8240e-01, -1.7498e+00, -3.6436e-01, -1.4569e+00,\n                       -1.3293e+00, -2.3202e+00, -1.4636e+00, -3.9147e+00, -1.1452e+00,\n                       -5.2373e+00,  2.3804e-01, -2.8221e-01, -1.6744e+00, -1.7231e+00,\n                       -6.9544e-01, -1.2568e+00,  1.7241e-02, -1.9358e+00, -1.2466e+00,\n                       -1.5119e+00, -1.2286e+00, -2.6434e-01, -2.8946e+00, -5.2680e-01,\n                       -1.1076e+00, -2.8359e-01, -8.0714e-01, -7.0289e-01, -7.6163e-01,\n                        2.4871e-01, -1.0602e+00, -1.8170e+00, -1.7703e+00, -1.1087e+00,\n                       -2.1309e+00, -1.4316e+00, -1.3359e+00, -7.2206e-01, -3.7164e-01,\n                       -9.0709e-01, -2.0256e+00,  1.7030e-02,  5.4975e-01, -1.2087e+00,\n                       -1.1453e+00, -6.6755e-01, -2.4989e+00, -1.1576e-01, -2.8860e+00,\n                       -2.0976e+00, -1.5822e+00, -2.4264e+00, -4.5575e-01, -1.1280e+00,\n                       -1.1431e+00, -1.6153e+00, -1.0460e+00, -9.0468e-01, -2.6726e+00,\n                       -8.4115e-01, -2.4991e+00, -2.3500e+00, -2.4345e+00, -1.0823e+00,\n                       -2.0077e+00, -9.3825e-01, -1.6349e+00, -1.0368e+00,  7.7394e-03,\n                       -2.7129e-01, -1.0491e+00,  3.9180e-01,  1.2794e+00, -1.7803e+00,\n                       -5.5661e-01, -1.5787e+00, -2.4283e+00,  3.5313e-01, -4.7643e+00,\n                       -9.4435e-01])),\n              ('backbone.models.0.model.layer3.3.bn1.running_var',\n               tensor([ 3.7485,  2.7781,  3.5099,  3.8367,  2.2988,  4.5299,  2.4549,  2.7079,\n                        3.3352,  2.4621,  3.1878,  2.6330,  3.8224,  2.9675,  3.3293,  3.0000,\n                        4.5922,  3.7328,  3.4141,  3.4103,  3.6002, 11.8628,  3.7091,  2.8779,\n                        2.2936,  2.3243,  3.0196,  3.5406,  3.2740,  3.7811,  2.3221,  2.7023,\n                        3.5046,  4.5262,  2.5950,  2.7245,  2.4715,  3.7774,  3.7763,  3.7148,\n                        3.9495,  3.4895,  3.5576,  3.8952,  3.8581,  2.7476,  2.9757,  2.3680,\n                        3.1594,  3.0401,  3.4467,  3.0110,  2.4632,  2.6469,  2.5139,  3.8365,\n                        3.0962,  2.9207,  3.3762,  3.4674,  3.3113,  2.2231,  3.9611,  3.5461,\n                        3.4000,  3.5649,  2.3745,  4.3060,  2.9181,  2.9464,  6.3025,  2.8205,\n                        3.8271,  5.1489,  3.3486,  4.3075,  2.0063,  3.1149,  2.6028,  1.6891,\n                        2.5866,  2.7827,  2.6866,  3.1599,  3.4377,  4.6255,  2.8179,  3.1607,\n                        3.2707,  6.9779,  4.6906,  3.0178,  1.9461,  3.2810,  2.3952,  3.7497,\n                        3.7142,  3.2171,  4.2083,  2.5145,  3.2117,  3.7915,  2.7140,  5.2504,\n                        3.2150,  2.8082,  3.2415,  2.4885,  2.4656,  3.5228,  3.1855,  2.9019,\n                        2.5251,  3.5447,  4.6798,  2.7519,  5.6900,  4.2034,  1.6527,  1.9111,\n                        4.9995,  2.7749,  1.8722,  3.3522,  4.2079,  3.1799,  3.3320,  2.1255,\n                        2.1086,  4.3304,  2.9141,  3.3500,  4.0302,  3.2790,  2.9713,  3.8561,\n                        4.7124,  2.7455,  2.6245,  3.3059,  2.2495,  3.5771,  1.7427,  2.8235,\n                        1.9640,  2.7935,  3.1401,  2.8318,  1.8988,  2.3002,  3.0073,  4.5530,\n                        3.2979,  2.8047,  3.4744,  3.0745,  3.4785,  6.2476,  3.9248,  2.6878,\n                        5.0248,  3.5302,  3.2598,  3.0752,  3.7230,  3.8629,  3.0158,  3.4747,\n                        3.2030,  2.6049,  2.9295,  3.1320,  3.0127,  3.0470,  2.3845,  3.1262,\n                        2.8046,  3.3386,  2.6919,  4.1903,  2.3950,  3.1151,  3.0926,  2.7352,\n                        2.8700,  2.4568,  4.1736,  3.1359,  2.8411,  3.7691,  4.3418,  3.2604,\n                        3.2930,  3.7201,  3.2386,  3.9978,  4.0211,  1.9121,  1.8129,  3.8929,\n                        2.5439,  4.4423,  2.7076,  3.9036,  3.3797,  2.9332,  3.7451,  2.5852,\n                        2.8624,  2.7145,  3.9747,  2.8942,  3.3127,  3.4025,  3.6247,  3.9800,\n                        3.9567,  2.4814,  4.6245,  3.1282,  2.3889,  2.9642,  3.0887,  2.5218,\n                        3.0806,  4.2204,  2.8121,  3.9347,  4.0434,  6.5818,  1.9611,  2.7658,\n                        3.6553,  3.7740,  3.2099,  2.5580,  3.4757,  3.2266,  4.0716,  4.6265,\n                        3.8469,  4.1271,  4.3009,  3.2909,  3.8172,  4.6522,  2.2856,  3.0916,\n                        5.9644,  4.1410,  3.9999,  2.6602,  2.5610,  3.9346,  2.6119,  2.6258])),\n              ('backbone.models.0.model.layer3.3.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.3.conv2.weight',\n               tensor([[[[-2.7250e-02, -1.9789e-02, -1.2554e-02],\n                         [-4.0098e-04, -4.5663e-02, -2.5358e-02],\n                         [-2.7624e-03,  5.4567e-03, -3.9057e-02]],\n               \n                        [[-1.7939e-02,  2.0423e-03, -4.5766e-04],\n                         [ 5.9736e-02,  3.4569e-02,  2.3249e-02],\n                         [ 2.8686e-02,  4.7331e-02,  6.8866e-02]],\n               \n                        [[ 8.8108e-03, -1.2264e-02, -5.2221e-03],\n                         [ 2.0919e-02, -1.9865e-02,  2.9318e-02],\n                         [ 8.8680e-03,  3.7151e-02,  2.0723e-02]],\n               \n                        ...,\n               \n                        [[ 2.8983e-02,  8.4148e-03, -1.2220e-02],\n                         [-1.7484e-02,  1.2618e-02, -4.2983e-02],\n                         [ 1.0467e-02,  6.0595e-05, -2.6740e-02]],\n               \n                        [[-2.2082e-02, -6.3002e-03,  1.1237e-02],\n                         [ 2.7289e-03,  5.9109e-02,  1.8904e-02],\n                         [-9.4810e-05, -1.2604e-02, -3.5728e-02]],\n               \n                        [[-3.9840e-02, -6.3022e-03, -7.0184e-03],\n                         [-1.7568e-02, -6.3014e-02, -2.7075e-02],\n                         [-2.6330e-02, -6.5869e-03, -2.8598e-03]]],\n               \n               \n                       [[[ 2.2439e-03,  2.8599e-02,  1.9607e-02],\n                         [ 5.4544e-02,  4.6814e-02,  5.5928e-02],\n                         [ 1.5617e-02,  6.6946e-02,  7.8973e-02]],\n               \n                        [[ 1.6739e-02,  6.5402e-02,  5.6682e-02],\n                         [ 7.1733e-02,  5.8830e-02,  1.4871e-01],\n                         [ 6.1201e-02,  8.8019e-02,  1.2118e-01]],\n               \n                        [[ 9.0347e-03, -1.6187e-02, -2.6559e-02],\n                         [-2.9342e-02, -2.6756e-02, -4.5384e-02],\n                         [-1.0444e-02, -5.1155e-02, -7.8571e-02]],\n               \n                        ...,\n               \n                        [[-2.8950e-02, -7.6605e-02, -7.1806e-02],\n                         [-3.5667e-02, -5.0883e-02, -6.1863e-02],\n                         [-5.1091e-02, -6.7103e-02, -6.2961e-02]],\n               \n                        [[ 7.1644e-03,  4.0523e-02,  1.9049e-02],\n                         [-6.8177e-03,  6.3880e-02,  2.3620e-02],\n                         [-1.7066e-03,  3.1383e-02,  4.8277e-02]],\n               \n                        [[-2.3986e-02, -6.2972e-02, -8.3718e-02],\n                         [-6.8025e-02, -5.0735e-02, -9.5954e-02],\n                         [-5.1604e-02, -8.5854e-02, -9.9214e-02]]],\n               \n               \n                       [[[-2.5034e-03, -2.4801e-03, -2.1539e-02],\n                         [ 1.1793e-02, -3.6304e-03,  2.8095e-02],\n                         [-1.7914e-02, -5.2726e-02, -1.2968e-02]],\n               \n                        [[ 3.8194e-02,  3.9020e-03,  3.6169e-02],\n                         [ 1.7471e-02, -3.2464e-02,  2.5730e-02],\n                         [-2.8666e-02, -4.2684e-02,  7.4365e-03]],\n               \n                        [[-8.5239e-03, -1.5683e-02,  1.9527e-02],\n                         [-7.8618e-04,  7.8098e-03, -2.7415e-02],\n                         [ 6.1835e-02,  6.9632e-03, -3.0642e-02]],\n               \n                        ...,\n               \n                        [[-2.9752e-03,  6.7661e-03,  3.4746e-03],\n                         [-2.7261e-02, -2.9183e-02,  1.4877e-01],\n                         [-1.1535e-02,  1.2358e-02,  6.0739e-02]],\n               \n                        [[-4.7215e-03,  1.7618e-03, -6.6707e-03],\n                         [ 2.7804e-02,  4.6437e-03, -1.2035e-02],\n                         [-1.4141e-02, -2.8110e-02, -1.3678e-02]],\n               \n                        [[ 3.4379e-02,  2.3084e-02, -1.0450e-02],\n                         [ 2.4369e-02,  3.6898e-02,  3.0141e-03],\n                         [-1.5763e-03, -9.3178e-03,  3.3453e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-5.6755e-03, -1.1800e-02, -1.0928e-02],\n                         [-1.0431e-02, -5.8617e-02, -1.4790e-02],\n                         [ 1.1165e-02, -7.7697e-03,  1.1086e-02]],\n               \n                        [[-4.4431e-03,  9.6597e-02,  2.6739e-02],\n                         [ 3.7843e-02,  1.1521e-01,  5.9787e-02],\n                         [-2.4791e-02, -3.5328e-02,  4.0247e-03]],\n               \n                        [[ 5.4660e-02,  6.2528e-02,  5.7105e-02],\n                         [ 4.4487e-02,  3.0110e-02,  5.4368e-02],\n                         [ 2.4976e-03, -5.0150e-02, -4.3978e-04]],\n               \n                        ...,\n               \n                        [[ 2.1536e-02,  3.4583e-02,  4.7232e-02],\n                         [ 2.1164e-02,  6.9631e-02,  5.1530e-02],\n                         [ 5.3081e-02,  3.4581e-02,  8.2721e-02]],\n               \n                        [[-3.5466e-02, -2.4395e-02, -4.2341e-02],\n                         [-9.0791e-03,  2.0390e-01,  1.8948e-03],\n                         [-6.0079e-02, -7.1275e-02, -5.9902e-02]],\n               \n                        [[-2.6355e-02, -6.4935e-02, -2.2406e-02],\n                         [ 3.4341e-02, -5.0841e-02,  4.7826e-02],\n                         [ 5.0673e-03,  2.8058e-02, -9.3238e-04]]],\n               \n               \n                       [[[ 2.8038e-02,  3.9006e-02,  5.1178e-02],\n                         [ 7.7259e-03,  1.6921e-03,  1.7961e-02],\n                         [-2.1754e-03, -4.8450e-03, -8.8837e-03]],\n               \n                        [[ 9.4270e-03,  3.4286e-02,  1.9212e-02],\n                         [ 2.2743e-02,  2.7821e-03, -1.7858e-02],\n                         [-2.4066e-02, -1.9669e-02, -2.6568e-03]],\n               \n                        [[ 5.9679e-04, -4.8157e-03, -2.4495e-02],\n                         [ 1.1736e-02, -2.4535e-02, -3.5278e-03],\n                         [-6.7539e-03, -2.9497e-03, -2.8262e-02]],\n               \n                        ...,\n               \n                        [[ 4.5443e-02,  3.8422e-02,  3.5528e-02],\n                         [ 4.5381e-02,  7.6462e-02,  8.6014e-02],\n                         [ 3.2675e-02,  6.4886e-02,  6.6435e-02]],\n               \n                        [[-1.8549e-03, -6.2384e-03, -1.4484e-02],\n                         [-1.4645e-02,  3.4695e-02, -1.0964e-03],\n                         [ 1.2859e-02,  2.6863e-02, -4.2222e-03]],\n               \n                        [[-2.7474e-03,  4.8062e-03, -1.7213e-02],\n                         [ 1.3192e-02,  2.8551e-03, -1.9019e-02],\n                         [-2.4624e-02, -3.9579e-02, -3.1060e-02]]],\n               \n               \n                       [[[-1.8056e-02,  9.8577e-03, -3.1304e-02],\n                         [-1.1123e-02,  4.3628e-03, -8.3055e-03],\n                         [ 4.9930e-02,  6.4851e-02,  4.5206e-02]],\n               \n                        [[-5.6967e-03,  1.7343e-02, -2.2814e-02],\n                         [-3.8346e-02, -7.5968e-02, -4.9979e-02],\n                         [ 1.8701e-02,  5.6059e-02,  1.4799e-02]],\n               \n                        [[-9.6717e-03, -1.8267e-02, -2.0591e-02],\n                         [-4.1478e-02, -2.8672e-02, -2.4076e-02],\n                         [-2.0804e-02, -1.8164e-02, -4.3903e-02]],\n               \n                        ...,\n               \n                        [[ 1.3951e-02, -8.4678e-02, -4.4312e-02],\n                         [ 3.1013e-02,  5.7650e-02,  3.4854e-02],\n                         [ 6.9711e-03, -3.8304e-02, -2.5668e-02]],\n               \n                        [[ 4.1833e-03, -6.7835e-02, -3.1905e-02],\n                         [ 1.9500e-02,  2.2143e-01,  3.4178e-02],\n                         [-3.0025e-02, -6.0961e-02, -4.9901e-02]],\n               \n                        [[ 2.5759e-02,  1.4650e-02,  1.6189e-02],\n                         [-1.7343e-02, -7.7468e-02,  3.9436e-02],\n                         [-5.4393e-02, -1.4473e-01, -6.7148e-02]]]])),\n              ('backbone.models.0.model.layer3.3.bn2.weight',\n               tensor([0.9924, 0.9665, 0.9530, 0.7333, 1.1197, 0.7499, 0.8005, 0.8813, 0.7956,\n                       0.9165, 0.9605, 0.9292, 0.8214, 0.8830, 0.9454, 0.7919, 0.7910, 0.8901,\n                       1.0834, 0.8039, 1.1619, 0.8194, 0.8937, 0.9916, 1.0665, 0.7946, 1.0168,\n                       0.8331, 1.0698, 0.8726, 0.7923, 0.9785, 1.1816, 1.2036, 0.9594, 0.9363,\n                       0.8167, 0.7908, 0.8424, 0.9283, 1.1681, 1.0126, 0.6650, 0.7668, 1.0082,\n                       1.1567, 1.0363, 0.8936, 0.8642, 0.7271, 0.9556, 1.1193, 0.9094, 0.9370,\n                       0.7242, 1.2420, 1.1364, 0.8737, 0.8659, 0.7570, 0.9427, 0.8218, 1.1436,\n                       0.9927, 0.9433, 1.1949, 0.9582, 0.7900, 0.6835, 1.0620, 1.0170, 0.8520,\n                       0.8325, 1.0465, 0.9214, 0.8620, 0.7299, 0.8107, 0.8157, 1.0624, 0.8754,\n                       0.8010, 0.7237, 0.8187, 1.0667, 0.9541, 1.1304, 1.0913, 0.8261, 0.8056,\n                       0.6823, 0.8283, 1.0155, 0.8068, 0.8499, 0.7877, 0.9069, 0.9398, 1.0369,\n                       0.9641, 0.9061, 0.9174, 1.0252, 0.7570, 0.8528, 0.9422, 0.9552, 0.8127,\n                       1.0034, 1.1044, 0.7092, 0.8030, 1.0347, 1.0514, 0.9200, 0.8312, 1.1652,\n                       1.3302, 0.9533, 0.7516, 1.0405, 0.9134, 0.9852, 1.0887, 0.9011, 0.7793,\n                       1.0418, 0.9584, 0.8941, 0.8461, 0.8069, 1.5801, 0.8585, 0.7773, 1.0211,\n                       0.9424, 1.1599, 0.9827, 1.1209, 1.1001, 0.9299, 0.9782, 1.1908, 0.9467,\n                       0.9847, 1.0196, 0.9923, 0.7680, 1.2207, 1.0234, 1.1328, 1.0318, 0.8569,\n                       1.1042, 0.7738, 0.5614, 1.2020, 0.8399, 0.9647, 1.2352, 1.2871, 0.8766,\n                       0.8701, 0.6564, 1.2148, 1.0594, 1.0439, 1.0301, 0.7950, 0.8553, 1.1275,\n                       0.8975, 0.7032, 1.0404, 0.8486, 1.0900, 0.7650, 0.9698, 1.2198, 1.0133,\n                       0.8885, 0.8580, 0.7653, 0.9243, 0.9165, 1.0704, 1.0065, 0.6471, 0.8691,\n                       0.8646, 0.7372, 0.9095, 0.8548, 1.0109, 0.7714, 0.7593, 0.7799, 0.8610,\n                       0.7667, 1.1520, 0.9673, 0.9327, 0.9834, 1.0322, 0.8320, 0.8180, 0.8550,\n                       0.9246, 0.8817, 0.8513, 1.0261, 0.7601, 0.8469, 1.0422, 0.9658, 0.9317,\n                       0.9446, 0.8706, 0.8857, 0.9227, 0.9785, 1.0308, 1.0662, 0.5974, 0.7519,\n                       1.0088, 0.7991, 1.1803, 0.9107, 0.7976, 1.0979, 0.8750, 0.9065, 1.2460,\n                       0.9955, 0.8114, 1.0071, 0.8873, 1.1609, 0.8003, 0.7751, 1.0756, 0.7914,\n                       0.8239, 0.8232, 0.8823, 0.9356, 0.8596, 1.3801, 0.8210, 0.8657, 1.1502,\n                       0.8133, 0.9953, 0.9870, 0.9299])),\n              ('backbone.models.0.model.layer3.3.bn2.bias',\n               tensor([-0.5094, -0.4041, -0.6072,  0.0713, -0.8305,  0.0458,  0.1864, -0.2469,\n                       -0.2965, -0.4134, -0.2964, -0.6477, -0.9445, -0.2091, -0.1282,  0.0609,\n                        0.1771, -0.3130, -0.8311, -0.0483, -0.9324, -0.2249, -0.3578, -0.5736,\n                       -0.6735,  0.0292, -0.4052, -0.2242, -0.3522, -0.1956, -0.0733, -0.4464,\n                       -0.7269, -0.8349, -0.4919, -0.4110, -0.4424, -0.1871, -0.3269, -0.2463,\n                       -0.7648, -0.5067,  0.1962, -0.2853, -0.3558, -0.5761, -0.3590, -0.2727,\n                       -0.3541,  0.2761, -0.5732, -1.0253, -0.2915, -0.5340,  0.1645, -0.4776,\n                       -0.6291, -0.2107, -0.4074, -0.0844, -0.3157, -0.0111, -0.6487, -0.5156,\n                       -0.2216, -0.6947, -0.5278, -0.0540,  0.1422, -0.9951, -0.5824, -1.0575,\n                       -0.9539, -0.6530, -0.5330, -0.4759,  0.0848, -0.1422, -0.0268, -0.3944,\n                       -0.2968, -0.0354,  0.0064,  0.0094, -0.4166, -0.2790, -1.4082, -0.4396,\n                       -0.0660, -0.1372,  0.3298, -0.3352, -0.6220, -0.1982, -0.0952,  0.1486,\n                       -0.3025, -0.5969, -0.5180, -0.3329, -0.7174, -0.4129, -0.7060, -0.1318,\n                       -0.9159, -0.3462, -0.7589, -0.0878, -0.8619, -0.7718,  0.0116, -0.1912,\n                       -0.6664, -0.5136, -0.3635, -0.3274, -1.1392, -0.9468, -0.5996,  0.0034,\n                       -0.6582, -0.5404, -0.6441, -0.8311, -0.2875,  0.0527, -0.6345, -0.6603,\n                       -0.3794, -0.2677,  0.0091, -1.0259, -0.3110, -0.1155, -0.5922, -1.4426,\n                       -0.9569, -0.3785, -0.4839, -0.8787, -0.3042, -0.7637, -0.7265, -1.0998,\n                       -0.5703, -0.8234, -0.5369, -0.2059, -0.6322, -0.6026, -0.6838, -0.8388,\n                       -0.1186, -0.6897, -0.3736,  0.5555, -0.4724, -0.2698, -0.3987, -0.4079,\n                       -0.8130, -0.4320, -0.2700,  0.3203, -0.8325, -0.8250, -0.6421, -0.6400,\n                       -0.1366, -0.2016, -1.2658, -0.3963,  0.8249, -0.4561, -0.1601, -0.6125,\n                        0.0331, -0.8925, -0.6930, -0.4504, -0.2616, -0.2869,  0.1670, -0.5038,\n                       -0.5621, -0.6485, -0.6451,  0.4010, -0.2362, -0.1934,  0.1457, -0.2701,\n                       -0.2615, -1.1659, -0.0176,  0.0892, -0.2211, -0.1276,  0.1410, -0.6153,\n                       -0.3356, -0.3260, -0.7017, -0.7184, -0.1285, -0.1463, -0.1301, -0.5585,\n                       -0.2327, -0.3139, -0.4721, -0.0225, -0.0530, -0.6815, -0.5549, -0.2835,\n                       -0.4004, -0.2524, -0.3143, -0.3886, -0.3448, -0.7711, -0.5910,  0.1731,\n                       -0.0759, -0.4313, -0.2426, -0.6443, -0.4139, -0.1763, -0.7363, -0.3344,\n                       -0.3109, -0.8903, -0.4631, -0.1212, -0.6936, -0.4512, -0.5023, -0.1135,\n                       -0.0728, -0.8412, -0.0104,  0.0309, -0.1282, -0.2669,  0.0897, -0.1655,\n                       -0.3382, -0.0490, -0.2773, -0.7928, -0.2184, -0.4719, -0.5340, -0.4082])),\n              ('backbone.models.0.model.layer3.3.bn2.running_mean',\n               tensor([ 0.0107, -0.1243, -0.4387,  0.0506, -0.3746,  0.1303, -0.3040,  0.4142,\n                       -0.0118, -0.6681, -0.3314, -0.3589, -0.4306, -0.4444,  0.7750,  0.0442,\n                       -0.4241, -0.1355, -0.4264, -0.1599, -0.4496, -0.2202, -0.3433, -0.8294,\n                       -0.1668, -0.4133, -0.5014, -0.2588, -0.4675, -0.3756,  0.1549,  0.1109,\n                       -0.9821, -0.8898,  0.2051, -0.3514,  0.2387, -0.2674,  0.5552, -0.4649,\n                        0.0442, -0.0329, -0.2695,  2.1149, -0.5982, -0.8514, -0.1259, -0.1537,\n                       -0.4644, -0.3618, -0.6332, -1.0575, -0.8959,  0.2095, -0.4543, -0.8388,\n                       -0.3404,  0.0289, -0.0301,  0.0399, -0.4547,  0.8205, -0.6500, -1.5384,\n                       -0.2726, -0.8155, -0.2345, -0.2300, -0.2665, -0.7168, -0.7048, -0.3525,\n                       -0.3157, -0.3221, -0.1726, -0.3161, -0.3563, -0.2970, -0.2248, -0.3539,\n                       -0.2319, -0.3937, -0.1989, -0.4410, -0.7296, -0.6214, -0.3553,  1.6842,\n                       -0.1804, -0.1523, -0.5456, -0.0656, -0.3186, -0.1591, -0.1647, -0.6871,\n                       -0.2608, -0.3276, -0.5768, -0.3274, -0.5772, -0.3048,  0.5732, -0.0615,\n                       -0.7619, -0.1812, -0.4573,  0.0946,  0.0845, -0.8747, -0.0319,  0.2797,\n                       -0.2712, -0.2736, -0.3186, -0.4814, -0.5725, -0.3279,  0.2887, -0.4833,\n                       -0.3165, -0.0628, -0.2936, -0.2950, -0.2526, -0.2783, -0.6276, -0.2539,\n                        0.2091, -0.5628,  0.2840, -0.6165, -0.2306, -0.2834, -0.7173, -0.3975,\n                       -0.7064, -0.0910, -0.8427,  1.2701, -0.4017, -0.5481, -0.4817, -0.2920,\n                       -0.1110, -0.7722, -0.3578, -0.1377, -0.9245, -0.3424, -0.5762, -0.2568,\n                        0.3103, -0.6841, -0.3572,  0.5081, -1.5374,  0.1000,  0.2162, -0.6735,\n                       -0.7616, -0.5568, -0.2331, -0.4834, -0.7979, -0.3768, -0.6438, -0.3177,\n                       -0.0488, -0.0952, -0.2882,  0.4455, -0.3601, -0.3034, -0.4933, -0.7081,\n                       -0.2621, -0.2671, -1.1838, -0.2260, -0.4341, -0.2202, -0.6134, -0.5328,\n                       -0.5419, -0.4131, -0.4720,  1.0926,  0.0673, -0.4239, -0.4193,  0.0225,\n                       -0.1889, -0.0646, -0.1665, -0.2675, -0.6356, -0.1428, -0.0272, -0.9913,\n                       -0.3858, -0.0432, -0.2506, -0.8669, -0.3238, -0.0132, -0.1547, -0.1162,\n                       -0.5700,  0.0263, -0.3145, -0.0033,  0.0682, -0.1800, -0.5225, -0.1901,\n                       -0.4523, -0.3396, -0.3421, -0.1905, -0.5464, -0.4732, -0.5477,  0.0969,\n                       -0.2471, -0.3417, -0.1951, -0.6549, -0.2858, -0.1542, -0.7777, -0.1524,\n                       -0.1692, -0.8205, -0.4179, -0.3616,  0.1201, -0.1780, -0.5567, -0.0582,\n                       -0.4026,  0.0963, -0.4276, -0.3964, -0.0193, -0.5206, -0.9597, -0.4668,\n                       -1.5609, -0.0195, -0.4262, -0.3943, -0.0442, -0.0750, -0.2807, -0.4866])),\n              ('backbone.models.0.model.layer3.3.bn2.running_var',\n               tensor([1.0930, 1.2090, 0.8311, 1.0031, 1.1795, 1.1099, 1.4832, 1.2908, 0.8627,\n                       0.8056, 1.0016, 0.9625, 0.5493, 1.0113, 1.8165, 1.3409, 1.1161, 1.1205,\n                       1.1048, 1.1327, 0.7492, 0.9664, 1.1912, 1.0721, 1.2598, 1.2313, 1.4952,\n                       0.7536, 1.1292, 1.5785, 1.0381, 1.2684, 1.2178, 1.3074, 0.8439, 0.9016,\n                       0.8727, 0.8459, 1.1822, 0.8225, 1.3440, 1.1596, 1.0626, 0.4086, 1.5998,\n                       1.6931, 1.3230, 1.2056, 0.8135, 1.2199, 0.8329, 0.8786, 1.1592, 1.4148,\n                       1.1156, 1.6928, 1.3081, 1.0761, 0.9237, 1.0878, 0.9565, 1.8359, 1.0607,\n                       0.9649, 0.9145, 1.1264, 1.2872, 1.2236, 0.9461, 0.7370, 0.9033, 0.4601,\n                       0.5808, 1.4787, 0.8266, 0.9459, 0.9629, 1.1631, 0.8114, 1.2802, 0.8732,\n                       1.1611, 0.8728, 1.2624, 1.3869, 1.1725, 0.9654, 1.5973, 1.2823, 0.9434,\n                       1.0549, 0.6732, 1.1105, 0.9231, 1.3640, 1.1810, 1.2933, 0.7755, 1.1889,\n                       1.4550, 0.6149, 0.9053, 1.4139, 0.8392, 0.6641, 1.1245, 0.6781, 1.1450,\n                       1.0590, 0.9942, 0.9554, 1.0785, 0.9154, 0.9890, 0.9594, 1.2366, 1.0161,\n                       1.1718, 1.4558, 0.6755, 0.9098, 1.0556, 0.7395, 1.1603, 0.9634, 1.2334,\n                       1.1959, 0.8429, 0.9654, 1.1661, 1.1513, 1.2868, 1.2007, 0.9305, 0.9438,\n                       0.4431, 0.8137, 0.9472, 1.3845, 1.7289, 0.9278, 0.7756, 1.4885, 0.6345,\n                       1.1121, 0.8838, 1.0730, 0.8511, 1.3495, 1.1325, 1.2712, 0.8547, 1.6590,\n                       0.9456, 0.5270, 0.7665, 1.2453, 0.8837, 1.2642, 1.7251, 1.2821, 0.9108,\n                       1.0872, 1.0342, 0.9778, 1.0549, 1.1981, 1.2876, 0.9536, 0.9494, 0.7565,\n                       1.6911, 0.9299, 1.3861, 1.0945, 1.2771, 1.1214, 0.7278, 1.3723, 0.8779,\n                       0.8129, 1.1889, 1.2056, 1.0544, 0.7085, 1.0631, 0.9996, 1.0516, 1.2652,\n                       1.3485, 1.1301, 1.2081, 0.9236, 0.5563, 1.1010, 1.2567, 0.8463, 1.2314,\n                       1.2307, 1.2265, 1.6394, 1.2771, 1.0083, 1.1461, 1.2419, 0.9463, 1.5032,\n                       0.7807, 0.8461, 1.1716, 0.8929, 1.1596, 1.2054, 1.1250, 1.0788, 1.4523,\n                       1.1467, 1.1363, 1.1295, 1.2704, 1.3821, 0.8415, 1.1293, 0.8645, 0.7777,\n                       0.9860, 0.7905, 1.3541, 0.8527, 0.8421, 1.1028, 1.0335, 0.9906, 1.1264,\n                       1.4213, 1.0489, 0.9490, 0.9719, 1.4041, 1.3285, 1.0520, 1.1110, 1.3605,\n                       1.2822, 0.7919, 1.0806, 1.6008, 1.1448, 1.6253, 1.7003, 1.1600, 1.3028,\n                       0.8062, 1.0136, 1.1724, 1.2645])),\n              ('backbone.models.0.model.layer3.3.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.3.conv3.weight',\n               tensor([[[[ 0.0282]],\n               \n                        [[-0.1238]],\n               \n                        [[-0.0230]],\n               \n                        ...,\n               \n                        [[-0.0426]],\n               \n                        [[-0.0390]],\n               \n                        [[ 0.0592]]],\n               \n               \n                       [[[-0.0465]],\n               \n                        [[-0.0839]],\n               \n                        [[-0.0606]],\n               \n                        ...,\n               \n                        [[-0.0264]],\n               \n                        [[-0.0750]],\n               \n                        [[-0.0092]]],\n               \n               \n                       [[[ 0.0336]],\n               \n                        [[-0.0573]],\n               \n                        [[ 0.0199]],\n               \n                        ...,\n               \n                        [[ 0.0441]],\n               \n                        [[-0.0368]],\n               \n                        [[-0.0150]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0412]],\n               \n                        [[-0.0264]],\n               \n                        [[-0.0326]],\n               \n                        ...,\n               \n                        [[ 0.0816]],\n               \n                        [[ 0.0565]],\n               \n                        [[-0.0833]]],\n               \n               \n                       [[[ 0.0542]],\n               \n                        [[ 0.0757]],\n               \n                        [[ 0.0182]],\n               \n                        ...,\n               \n                        [[ 0.0441]],\n               \n                        [[ 0.0016]],\n               \n                        [[ 0.0337]]],\n               \n               \n                       [[[-0.0013]],\n               \n                        [[ 0.0472]],\n               \n                        [[ 0.0433]],\n               \n                        ...,\n               \n                        [[-0.0176]],\n               \n                        [[ 0.0124]],\n               \n                        [[ 0.0317]]]])),\n              ('backbone.models.0.model.layer3.3.bn3.weight',\n               tensor([ 0.8086,  0.3740, -0.2529,  ...,  0.2369, -0.6111, -0.3833])),\n              ('backbone.models.0.model.layer3.3.bn3.bias',\n               tensor([-0.4338, -0.1973,  0.1344,  ...,  0.2029, -0.4293,  0.2657])),\n              ('backbone.models.0.model.layer3.3.bn3.running_mean',\n               tensor([ 0.0302, -0.1069, -0.1740,  ..., -0.1268,  0.2087, -0.1033])),\n              ('backbone.models.0.model.layer3.3.bn3.running_var',\n               tensor([0.3771, 0.1472, 0.1095,  ..., 0.1165, 0.2124, 0.1635])),\n              ('backbone.models.0.model.layer3.3.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.4.conv1.weight',\n               tensor([[[[-0.0135]],\n               \n                        [[-0.0216]],\n               \n                        [[ 0.0025]],\n               \n                        ...,\n               \n                        [[ 0.0162]],\n               \n                        [[-0.0527]],\n               \n                        [[ 0.0300]]],\n               \n               \n                       [[[-0.0272]],\n               \n                        [[-0.0241]],\n               \n                        [[ 0.0183]],\n               \n                        ...,\n               \n                        [[-0.0056]],\n               \n                        [[ 0.0067]],\n               \n                        [[ 0.0250]]],\n               \n               \n                       [[[ 0.0181]],\n               \n                        [[ 0.0388]],\n               \n                        [[-0.0037]],\n               \n                        ...,\n               \n                        [[-0.0495]],\n               \n                        [[-0.0332]],\n               \n                        [[ 0.0021]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0496]],\n               \n                        [[ 0.0360]],\n               \n                        [[ 0.0562]],\n               \n                        ...,\n               \n                        [[ 0.0454]],\n               \n                        [[ 0.0237]],\n               \n                        [[ 0.0143]]],\n               \n               \n                       [[[ 0.0260]],\n               \n                        [[ 0.0569]],\n               \n                        [[ 0.1631]],\n               \n                        ...,\n               \n                        [[-0.0424]],\n               \n                        [[ 0.0038]],\n               \n                        [[ 0.0442]]],\n               \n               \n                       [[[ 0.0084]],\n               \n                        [[ 0.0096]],\n               \n                        [[ 0.0307]],\n               \n                        ...,\n               \n                        [[-0.0737]],\n               \n                        [[-0.0465]],\n               \n                        [[-0.0393]]]])),\n              ('backbone.models.0.model.layer3.4.bn1.weight',\n               tensor([0.8521, 0.7083, 0.5810, 0.7622, 0.9972, 0.9847, 1.3017, 0.7786, 0.7687,\n                       0.9980, 0.8384, 0.9037, 0.6952, 0.9789, 0.8374, 0.9164, 0.6939, 0.7909,\n                       1.0309, 0.7736, 1.0885, 0.6725, 0.7226, 0.7272, 1.0594, 1.4546, 0.8906,\n                       0.6880, 0.8011, 0.7951, 0.8363, 0.8665, 0.7939, 0.8629, 0.5565, 0.6236,\n                       0.8988, 0.6497, 0.7046, 0.7585, 0.8939, 1.0065, 0.6919, 0.6813, 0.8022,\n                       0.9283, 0.7537, 0.7400, 0.9701, 0.6400, 0.8207, 0.5644, 0.7006, 0.9005,\n                       0.8226, 1.0546, 0.8977, 0.6682, 0.7052, 0.7304, 0.7851, 0.6309, 1.0099,\n                       0.5205, 0.8321, 0.7562, 0.9802, 0.6360, 0.7145, 0.8011, 0.7205, 0.8481,\n                       0.6453, 0.7566, 0.6989, 1.0555, 0.5735, 0.8690, 0.6632, 0.8139, 0.7212,\n                       0.7631, 0.7861, 0.7423, 0.9431, 0.7613, 0.9450, 0.7915, 0.6391, 0.9577,\n                       0.9632, 0.8837, 1.0076, 0.5248, 1.0807, 1.0197, 0.6739, 0.8752, 0.7876,\n                       0.6966, 0.8246, 0.8287, 0.9911, 1.0301, 0.9410, 0.9235, 0.7618, 0.8362,\n                       0.8586, 1.0004, 0.7477, 0.9324, 1.0809, 0.7077, 0.7838, 0.8233, 0.7105,\n                       0.7588, 0.6331, 0.8690, 0.9728, 0.8780, 1.0256, 0.9116, 0.8191, 0.7792,\n                       0.8141, 0.8493, 0.7607, 0.7268, 1.0279, 0.8677, 0.7350, 1.0479, 0.7220,\n                       0.8278, 0.8924, 0.9368, 1.5437, 0.7465, 0.9471, 0.8773, 0.8106, 0.6821,\n                       1.0858, 0.9042, 0.9108, 0.8869, 1.2114, 0.7562, 0.9045, 0.7328, 0.6791,\n                       0.7519, 0.9467, 0.7919, 0.8009, 0.9877, 0.9028, 0.9150, 1.2351, 0.8935,\n                       0.8017, 0.9498, 0.6124, 0.8102, 0.8263, 1.1065, 0.8466, 0.9413, 0.7872,\n                       0.9046, 1.0317, 0.8057, 1.0097, 1.0638, 0.6505, 0.7017, 0.3449, 0.7244,\n                       0.7733, 1.0334, 0.4874, 1.0445, 0.7726, 0.8857, 0.9798, 0.6984, 0.6746,\n                       0.8403, 0.7635, 0.8952, 0.9483, 0.9221, 0.9551, 0.9778, 0.5819, 0.8149,\n                       0.7919, 0.8208, 0.8408, 0.9055, 0.6289, 0.8180, 0.8489, 0.8660, 0.7224,\n                       0.8681, 0.9080, 0.6911, 0.8564, 0.8091, 0.8706, 0.9375, 0.6147, 0.8202,\n                       0.7707, 0.7058, 0.8366, 0.8175, 0.9500, 1.0765, 1.1254, 0.8116, 0.8570,\n                       0.7325, 0.5224, 0.6681, 0.7079, 0.8968, 1.1638, 0.6729, 0.7163, 0.9316,\n                       0.9476, 0.9761, 1.1405, 0.8622, 0.9890, 0.7254, 0.8779, 0.9438, 0.7681,\n                       0.8626, 0.9473, 0.7079, 0.7639, 0.8898, 0.8227, 0.8265, 0.9187, 0.6692,\n                       0.8446, 1.0379, 0.7736, 0.7275])),\n              ('backbone.models.0.model.layer3.4.bn1.bias',\n               tensor([-0.7669, -0.1185, -0.0799, -0.4663, -1.2953, -1.4139, -1.8476, -0.5866,\n                       -0.5918, -1.0115, -0.4903, -0.7582, -0.2370, -0.9957, -0.4875, -1.0925,\n                       -0.3221, -0.3108, -1.4186, -0.4743, -1.4503, -0.2434, -0.0990, -0.5209,\n                       -1.1886, -2.3031, -0.3059, -0.6390, -0.4379, -0.5003, -0.8773, -1.1165,\n                       -0.4055, -0.4391,  0.0502, -0.1122, -0.6038, -0.0816, -0.3880, -0.2973,\n                       -0.8318, -0.8781, -0.4850, -0.2321, -0.5843, -0.8261, -0.6563, -0.3237,\n                       -0.8016, -0.0305, -0.5516, -0.0397, -0.2799, -1.0298, -0.6360, -0.5922,\n                       -0.1517, -0.3798, -0.1760, -0.4907, -0.4575, -0.0131, -1.3335,  0.1432,\n                       -0.6738, -0.4204, -0.8113, -0.1242, -0.1852, -0.6194, -0.4702, -0.1558,\n                       -0.0497, -0.4104, -0.4181, -1.4065, -0.1212, -0.9176, -0.2939, -0.3314,\n                       -0.3668, -0.4459, -0.5562, -0.4340, -1.3284, -0.5325, -0.3898, -0.1395,\n                        0.0166, -0.8773, -0.9410, -0.8165, -0.8316,  0.0402, -1.5387, -1.6213,\n                       -0.0287, -0.8997, -0.6564, -0.3756, -0.4441,  0.0799, -1.0756, -0.7315,\n                       -1.0092, -0.7875, -0.5687, -0.7112, -0.7507, -1.2821, -0.5310, -0.5893,\n                       -1.4090, -0.3533, -0.3539, -0.6991, -0.4653, -0.4904, -0.1038, -0.7135,\n                       -0.8596, -0.6029, -1.2676, -0.3560, -0.1191, -0.4409, -0.5193, -0.9801,\n                       -0.4446, -0.3192, -1.0081, -0.7955, -0.3253, -1.2059, -0.1543, -0.5898,\n                       -0.7036, -0.5168, -1.2480, -0.3921, -0.6379, -0.7754, -0.5470, -0.1547,\n                       -1.0434, -1.3198, -0.9784, -0.9373, -1.0864, -0.5793, -0.0319, -0.3066,\n                       -0.1977, -0.4072, -0.8489, -0.5816, -0.3149, -0.8549, -0.8456, -1.0158,\n                       -1.1502, -0.7594, -0.4310, -1.0381, -0.0223, -0.8886, -0.7185, -1.1749,\n                       -0.7187, -0.6194, -0.4641, -0.9358, -1.1622, -0.4614, -0.6705, -0.9397,\n                       -0.1982, -0.2367,  0.4535, -0.3882, -0.2693, -0.6418,  0.0717, -0.9178,\n                       -0.2426, -0.8753, -1.1680, -0.2640, -0.0948, -0.5315, -0.5034, -1.2656,\n                       -0.4740, -0.4262, -0.7689, -0.7994,  0.1162, -0.7201, -0.4325, -0.7562,\n                       -0.7481, -1.0045, -0.1677, -0.3534, -0.4549, -0.8052, -0.0938, -0.8971,\n                       -1.1787, -0.1618, -0.9296, -0.4302, -0.6803, -0.8270, -0.0406, -0.7204,\n                       -0.1742, -0.2180, -0.6844, -0.9061, -0.9519, -0.7191, -0.8768, -0.3412,\n                       -0.8166, -0.2898,  0.1598, -0.2708, -0.3595, -0.8519, -1.7605, -0.0118,\n                       -0.3121, -0.6985, -1.2092, -0.5762, -1.1007, -0.9254, -1.2899, -0.4495,\n                       -0.5885, -0.8854, -0.4567, -0.7765, -1.1780, -0.2715, -0.6324, -0.9447,\n                       -0.5813, -0.7731, -1.0665, -0.2851, -0.7213, -0.5772, -0.5278, -0.0312])),\n              ('backbone.models.0.model.layer3.4.bn1.running_mean',\n               tensor([-1.5536e+00,  1.4398e+00, -7.9083e-01, -2.1410e+00, -4.0974e+00,\n                       -6.0413e-01, -3.8769e+00, -8.6185e-01, -1.4320e+00, -2.3781e+00,\n                       -1.7504e+00, -1.3271e+00, -8.6954e-01, -3.6452e+00, -2.3643e+00,\n                       -3.2764e+00, -3.2363e-01, -2.7998e+00, -1.3639e+00, -1.4078e+00,\n                       -1.4300e+00,  1.5282e+00, -1.4490e+00,  4.2824e-01, -2.7653e+00,\n                        6.3894e-01, -3.8203e+00, -2.3157e+00, -2.0318e+00, -2.1089e+00,\n                       -1.4987e+00, -2.0409e+00, -1.0230e+00, -1.4288e+00,  5.8973e-01,\n                       -3.0741e-01, -2.4377e+00,  2.1728e-01, -6.0750e-01, -2.2658e+00,\n                       -1.6255e+00, -2.2742e+00, -7.6724e-01, -9.0130e-01, -9.6366e-01,\n                       -3.4499e+00, -2.7180e+00, -1.4295e+00, -1.9232e+00,  5.1771e-02,\n                       -1.4092e+00, -1.7852e+00, -2.0248e+00, -1.8453e+00, -1.6776e+00,\n                       -2.0193e+00, -2.6373e+00, -2.1785e+00, -1.6630e+00, -9.4895e-01,\n                       -2.0209e+00, -1.5395e-01, -3.2845e+00, -3.0726e-01, -1.4068e+00,\n                       -1.6665e+00, -1.8811e+00, -1.4444e+00, -1.6470e+00, -7.3078e-01,\n                       -1.6271e+00, -1.9449e+00, -1.1908e+00,  1.3248e-02, -1.7512e+00,\n                       -2.6432e+00, -3.3283e-01, -2.7114e+00, -2.0256e+00, -3.3924e+00,\n                       -2.1614e+00, -8.9271e-01, -1.2967e+00, -7.8225e-01, -3.5595e+00,\n                       -3.5545e-01, -1.8737e+00, -4.9522e-01,  1.1394e+00, -2.0864e+00,\n                        6.5987e-02, -6.8411e-01, -2.7136e+00, -1.0128e+00, -1.8715e+00,\n                       -2.3489e+00, -1.4829e+00, -2.6175e+00, -1.9070e+00, -9.4306e-01,\n                       -9.3003e-01, -1.6948e+00, -2.0513e+00, -2.2190e+00, -2.9556e+00,\n                       -2.7675e+00, -1.7007e+00, -1.5992e+00, -2.1638e+00, -1.2668e+00,\n                       -2.3177e+00, -3.0796e+00, -1.8048e+00, -3.8027e-01, -1.6896e+00,\n                       -1.0030e+00, -1.9391e+00, -3.0314e-01, -9.6977e-01, -1.5303e+00,\n                       -1.1344e+00, -2.3052e+00, -1.8538e+00, -1.8508e+00, -5.1540e-01,\n                       -3.4654e+00, -1.9662e+00, -2.0744e+00, -1.7195e+00, -1.1156e+00,\n                       -3.8561e+00, -1.7783e+00, -2.3648e+00, -3.1945e+00, -1.3532e+00,\n                       -2.4558e+00, -1.7840e+00, -2.5512e+00, -1.8609e+00, -1.1662e+00,\n                       -2.3657e+00, -1.3324e+00, -2.1988e+00, -6.7109e-01, -3.3596e+00,\n                       -1.6356e+00, -1.9649e+00, -5.6824e-01, -3.3727e+00, -9.7298e-01,\n                       -1.6601e+00, -1.7199e+00, -4.7378e-01, -2.3668e+00, -2.8341e+00,\n                       -1.9418e+00, -1.5956e+00, -1.5297e+00, -2.6611e+00, -1.9494e+00,\n                       -2.7523e+00, -3.0791e+00, -5.0051e-01, -1.7496e+00, -9.6698e-01,\n                       -1.5962e+00, -8.4345e-01, -1.6998e+00, -1.2359e+00, -1.9326e+00,\n                       -1.8109e+00, -1.9186e+00, -3.0286e+00, -6.7943e-01, -2.4992e+00,\n                       -2.0658e+00, -1.8000e+00, -2.3898e+00, -1.5304e+01, -1.1403e+00,\n                       -2.3195e-01, -2.8679e+00,  8.4236e-01, -2.1194e+00, -1.2429e+00,\n                       -2.2208e+00, -2.1276e+00, -8.5363e-01,  2.1973e+00, -2.2358e+00,\n                       -9.7036e-01, -1.1999e+00, -1.8785e+00, -1.4724e+00, -1.8140e+00,\n                       -3.3071e+00,  1.1916e+00, -1.0444e+00, -1.6298e-03, -9.7656e-01,\n                       -1.5187e+00, -1.0830e+00,  6.1700e-01, -2.0473e+00, -2.7645e-01,\n                       -2.6567e+00, -1.4729e-01, -2.8731e+00, -2.8367e-01,  3.7077e-01,\n                       -2.0046e+00, -1.8668e+00, -1.6228e+00, -1.8188e+00, -1.3825e+00,\n                       -2.7303e+00, -6.2980e-01, -2.2638e+00, -1.6277e+00, -1.5968e+00,\n                       -3.0574e+00, -2.4717e+00, -3.4040e+00,  4.3247e-01, -8.2154e-01,\n                       -1.2919e+00, -6.0686e-01, -2.7267e-01, -2.3020e-01, -2.3838e+00,\n                       -3.9376e+00, -2.3657e-01, -1.5938e+00, -3.4773e+00, -3.1423e-01,\n                       -1.1719e+00, -3.0769e+00, -2.4405e+00, -2.5173e+00, -1.6127e+00,\n                       -1.8253e+00, -4.3698e+00, -1.0834e+00, -3.3233e+00, -5.0941e-01,\n                       -4.6920e-01, -1.4423e+00, -1.1160e+00, -1.1269e+00, -8.5161e-01,\n                       -1.9572e+00, -3.2707e-01, -9.5847e-02, -2.4504e+00, -7.8816e-01,\n                       -9.4813e-01])),\n              ('backbone.models.0.model.layer3.4.bn1.running_var',\n               tensor([2.8292, 6.1899, 3.4361, 3.2003, 3.3595, 1.7380, 3.5708, 3.0231, 2.4420,\n                       2.2118, 3.0038, 2.6661, 2.9755, 2.9280, 3.9699, 2.8942, 3.6226, 3.2104,\n                       1.4077, 3.2948, 2.2039, 4.3661, 3.3916, 3.7015, 2.4741, 0.8692, 7.2337,\n                       1.8960, 3.1897, 3.1042, 1.9762, 1.6406, 3.0286, 4.0781, 3.4629, 3.9538,\n                       4.9347, 4.4721, 2.7331, 3.2804, 3.1973, 2.7207, 2.3522, 2.8348, 2.4997,\n                       2.7101, 2.8062, 4.6717, 2.7017, 4.7468, 3.5599, 3.2972, 3.9731, 1.8880,\n                       2.9786, 4.4939, 3.5764, 2.6505, 3.5649, 2.9192, 2.4110, 3.5017, 2.3869,\n                       3.4931, 3.0327, 3.4928, 3.0769, 4.0658, 3.4148, 3.2890, 2.6300, 3.7061,\n                       3.4220, 3.5951, 3.2105, 1.9702, 3.0216, 1.9845, 2.6122, 4.6378, 2.8347,\n                       3.4221, 2.8510, 2.9953, 2.1197, 2.8076, 4.9431, 7.0488, 4.5835, 3.7643,\n                       0.7475, 2.9949, 2.9156, 2.9243, 1.6678, 1.5939, 3.5200, 2.2213, 4.0379,\n                       2.4360, 3.8098, 5.0133, 2.0064, 3.8835, 2.4654, 2.5192, 2.9423, 2.7923,\n                       2.8011, 1.9036, 3.2501, 3.4240, 1.9958, 3.0308, 3.1845, 2.7309, 3.1430,\n                       4.2990, 3.1298, 3.0614, 2.3460, 3.1477, 2.5503, 5.3993, 8.5490, 3.6536,\n                       3.2441, 2.4511, 3.4299, 3.1139, 3.9053, 2.3004, 4.1540, 2.9401, 3.7080,\n                       2.9916, 2.5573, 5.0112, 5.2649, 3.1726, 3.9514, 2.8347, 3.8602, 3.3701,\n                       3.1508, 1.7645, 2.5743, 2.9592, 3.3834, 3.3888, 6.0271, 3.5871, 4.7433,\n                       3.3910, 2.5180, 2.7544, 3.6225, 2.9666, 2.3058, 2.2041, 3.0786, 3.0778,\n                       3.8652, 2.3496, 2.8633, 1.9573, 3.3324, 2.9915, 2.9659, 5.1420, 2.9629,\n                       1.9975, 2.5514, 3.1773, 5.9437, 3.2012, 3.3311, 3.4189, 1.5909, 4.2008,\n                       4.0914, 4.7224, 3.3257, 2.5655, 3.7320, 3.4042, 2.3982, 3.6956, 4.1379,\n                       3.7544, 3.3548, 1.8358, 4.5516, 5.8715, 3.4091, 2.4429, 4.9055, 2.5661,\n                       2.8918, 2.5013, 2.3276, 2.8043, 3.5448, 3.4449, 4.1874, 2.1710, 4.9491,\n                       2.8449, 2.3334, 4.2328, 2.1328, 3.3679, 3.4824, 2.4570, 3.7811, 2.7159,\n                       5.5704, 5.3331, 2.1580, 1.7265, 2.8476, 4.5584, 4.1318, 6.3328, 2.9207,\n                       3.7983, 4.0781, 3.9783, 3.0441, 2.8911, 1.9689, 4.2370, 3.9010, 4.7171,\n                       2.6264, 3.6466, 3.2060, 2.6032, 1.5642, 3.1269, 2.9688, 4.1835, 2.6998,\n                       3.7891, 1.7257, 3.9172, 2.7305, 1.7091, 2.8011, 3.1459, 2.2937, 2.7889,\n                       2.9233, 4.0991, 2.5680, 5.8847])),\n              ('backbone.models.0.model.layer3.4.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.4.conv2.weight',\n               tensor([[[[ 0.0170, -0.0659, -0.0482],\n                         [ 0.0055,  0.0010, -0.0580],\n                         [ 0.0253, -0.0201, -0.0374]],\n               \n                        [[-0.0278,  0.0770,  0.0439],\n                         [ 0.0192, -0.1211, -0.0150],\n                         [ 0.0017, -0.1506,  0.0091]],\n               \n                        [[-0.0143, -0.0353,  0.0465],\n                         [ 0.0123, -0.0172, -0.0006],\n                         [ 0.0127,  0.0025,  0.0284]],\n               \n                        ...,\n               \n                        [[ 0.0401, -0.0346, -0.0367],\n                         [-0.0165,  0.0058, -0.0421],\n                         [ 0.0156, -0.0463, -0.0501]],\n               \n                        [[ 0.0080, -0.0044,  0.0137],\n                         [ 0.0398, -0.0899, -0.0312],\n                         [ 0.0083, -0.0910, -0.0292]],\n               \n                        [[ 0.0178,  0.0333, -0.0104],\n                         [-0.0223,  0.0122,  0.0221],\n                         [-0.0094,  0.0155,  0.0290]]],\n               \n               \n                       [[[-0.0077, -0.0280, -0.0368],\n                         [-0.0515,  0.0037, -0.0179],\n                         [ 0.0139,  0.0168,  0.0390]],\n               \n                        [[-0.0104,  0.0288,  0.0746],\n                         [ 0.0270, -0.0261, -0.1270],\n                         [-0.0130, -0.0044,  0.0079]],\n               \n                        [[-0.0038, -0.0513, -0.0123],\n                         [-0.0137,  0.0938, -0.0086],\n                         [ 0.0056,  0.0491,  0.0201]],\n               \n                        ...,\n               \n                        [[-0.0344, -0.0573, -0.0458],\n                         [-0.0179, -0.0835, -0.0245],\n                         [-0.0392,  0.0076,  0.0050]],\n               \n                        [[-0.0295, -0.0506, -0.0403],\n                         [-0.0545,  0.0014, -0.0209],\n                         [ 0.0284,  0.0461,  0.0122]],\n               \n                        [[ 0.0225,  0.0692,  0.0498],\n                         [ 0.0067, -0.0365, -0.0003],\n                         [ 0.0149,  0.0304,  0.0134]]],\n               \n               \n                       [[[-0.0050,  0.0444,  0.0268],\n                         [ 0.0226,  0.0475,  0.0375],\n                         [ 0.0224,  0.0149,  0.0438]],\n               \n                        [[-0.0145, -0.0240,  0.0067],\n                         [-0.0400,  0.0292,  0.0069],\n                         [-0.0092, -0.0538, -0.0487]],\n               \n                        [[-0.0078,  0.0060,  0.0280],\n                         [-0.0050, -0.0074,  0.0018],\n                         [-0.0429, -0.0270, -0.0310]],\n               \n                        ...,\n               \n                        [[ 0.0375,  0.0554,  0.0731],\n                         [ 0.0369,  0.0281,  0.0576],\n                         [ 0.0265,  0.0592,  0.0641]],\n               \n                        [[ 0.0369,  0.0039,  0.0055],\n                         [ 0.0387, -0.0218, -0.0069],\n                         [-0.0119,  0.0067,  0.0236]],\n               \n                        [[-0.0063, -0.0036,  0.0011],\n                         [-0.0159, -0.0253,  0.0097],\n                         [-0.0059,  0.0046, -0.0228]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0288,  0.0106,  0.0179],\n                         [ 0.0177, -0.0103,  0.0127],\n                         [ 0.0346, -0.0264, -0.0018]],\n               \n                        [[-0.0256, -0.0598,  0.0155],\n                         [-0.0872, -0.1195,  0.0853],\n                         [-0.0562, -0.0847,  0.0104]],\n               \n                        [[-0.0266, -0.0105, -0.0245],\n                         [ 0.0044,  0.0478,  0.0194],\n                         [-0.0032,  0.0455, -0.0003]],\n               \n                        ...,\n               \n                        [[ 0.0018, -0.0106, -0.0265],\n                         [-0.0105, -0.0490, -0.0287],\n                         [-0.0406, -0.1460, -0.0691]],\n               \n                        [[-0.0360, -0.0394, -0.0417],\n                         [-0.0420, -0.0271, -0.0274],\n                         [-0.0548, -0.0340, -0.0382]],\n               \n                        [[ 0.0007, -0.0474, -0.0280],\n                         [-0.0070, -0.0402, -0.0521],\n                         [ 0.0348, -0.0011, -0.0055]]],\n               \n               \n                       [[[ 0.0099,  0.0095,  0.0215],\n                         [-0.0187,  0.0011, -0.0004],\n                         [-0.0043, -0.0315, -0.0704]],\n               \n                        [[ 0.0308,  0.0177, -0.0034],\n                         [-0.0449, -0.1296, -0.0201],\n                         [-0.0016, -0.0988, -0.0552]],\n               \n                        [[ 0.0803,  0.0022, -0.0426],\n                         [ 0.0820,  0.0375, -0.0904],\n                         [ 0.0717, -0.0230, -0.0754]],\n               \n                        ...,\n               \n                        [[-0.0014,  0.0121, -0.0044],\n                         [ 0.0319,  0.0033, -0.0589],\n                         [ 0.0281,  0.0240,  0.0004]],\n               \n                        [[-0.0238,  0.0072,  0.0324],\n                         [-0.0913, -0.0029,  0.0876],\n                         [-0.0487, -0.0166,  0.0526]],\n               \n                        [[ 0.0050, -0.0238,  0.0140],\n                         [ 0.0389,  0.0270,  0.0113],\n                         [ 0.0092,  0.0056,  0.0767]]],\n               \n               \n                       [[[-0.0091,  0.0081,  0.0111],\n                         [ 0.0037,  0.0172,  0.0604],\n                         [-0.0299,  0.0397,  0.0229]],\n               \n                        [[ 0.0844,  0.1766,  0.1262],\n                         [-0.0441, -0.0689,  0.0523],\n                         [-0.1468, -0.2386, -0.1181]],\n               \n                        [[-0.0121, -0.0266,  0.0136],\n                         [-0.0303, -0.0217,  0.0274],\n                         [ 0.0166, -0.0407, -0.0245]],\n               \n                        ...,\n               \n                        [[-0.0231, -0.0249,  0.0120],\n                         [-0.0436,  0.0125,  0.0464],\n                         [ 0.0043, -0.0135, -0.0072]],\n               \n                        [[ 0.0041,  0.0237, -0.0456],\n                         [-0.0081,  0.0385,  0.0095],\n                         [ 0.0145,  0.0004,  0.0315]],\n               \n                        [[ 0.0065,  0.0241,  0.0308],\n                         [-0.0088, -0.0329, -0.0171],\n                         [ 0.0168,  0.0157, -0.0056]]]])),\n              ('backbone.models.0.model.layer3.4.bn2.weight',\n               tensor([1.0633, 0.9600, 0.7472, 0.9374, 0.6312, 0.5372, 1.0700, 0.7456, 0.9469,\n                       0.8973, 0.7625, 0.9807, 0.7997, 1.0694, 0.6887, 1.0722, 0.9965, 0.8468,\n                       0.8779, 0.8932, 0.5868, 1.0500, 0.8463, 0.8060, 1.1160, 1.0390, 1.1021,\n                       0.7601, 0.9007, 0.5426, 0.8877, 0.6448, 0.8560, 1.0454, 1.0552, 0.6340,\n                       0.8678, 0.9025, 0.9052, 0.6783, 0.7892, 1.0849, 0.7225, 1.0412, 0.5252,\n                       0.8894, 1.0495, 0.7150, 0.9121, 0.9341, 0.7752, 0.7563, 1.0054, 0.8636,\n                       0.6494, 0.9396, 1.0667, 0.9095, 0.6294, 1.1871, 0.7011, 1.0721, 0.8559,\n                       1.3458, 0.7447, 1.0709, 0.9270, 1.0023, 0.7704, 0.8101, 0.9197, 1.0506,\n                       1.0407, 0.7681, 0.7544, 0.9320, 0.6987, 0.9730, 0.9264, 1.1536, 0.9281,\n                       0.7107, 1.0024, 1.0457, 0.9848, 0.8392, 0.5728, 0.9569, 0.8215, 1.0509,\n                       0.9235, 0.8400, 1.0268, 1.1629, 1.0157, 0.7668, 0.9190, 0.8909, 0.8619,\n                       0.9142, 0.8654, 0.8954, 0.9591, 0.9431, 0.9887, 0.9693, 0.7581, 0.9220,\n                       0.7869, 0.9386, 0.9980, 0.9227, 0.6069, 0.8286, 1.0231, 1.0845, 1.0764,\n                       0.8470, 1.0411, 0.9671, 0.8946, 1.0989, 1.1094, 1.0386, 0.8420, 0.9158,\n                       0.6330, 1.0895, 0.8064, 0.8858, 1.2393, 0.4729, 0.8379, 0.7789, 0.9677,\n                       0.8622, 1.0517, 0.9396, 0.9915, 0.9121, 0.8958, 0.9164, 0.8923, 0.8556,\n                       0.7862, 0.8401, 0.9135, 1.1187, 0.7739, 0.9099, 0.4732, 1.0972, 0.8549,\n                       0.6244, 0.6784, 0.7416, 0.9957, 0.9207, 0.9851, 0.9145, 1.0643, 1.0053,\n                       0.7141, 0.9965, 0.7562, 0.9281, 0.8019, 1.0253, 0.9558, 0.9324, 0.6099,\n                       0.7335, 0.7023, 0.8080, 0.5691, 0.9652, 0.6801, 1.2040, 0.7242, 0.8810,\n                       0.7642, 0.6427, 1.0258, 0.5788, 0.6951, 0.7019, 0.9010, 1.0632, 0.8193,\n                       0.4738, 0.7269, 0.5803, 0.7041, 0.8151, 0.9098, 0.9827, 0.6820, 0.8699,\n                       1.0008, 0.8625, 0.8395, 1.3545, 0.9224, 0.9272, 1.0823, 0.6902, 1.1062,\n                       0.8440, 0.5645, 0.9568, 1.0230, 0.9708, 0.8553, 0.9300, 0.6930, 1.0505,\n                       0.6228, 1.1047, 0.8380, 0.8157, 1.1232, 0.8958, 0.8208, 0.9138, 0.7984,\n                       1.1544, 0.9756, 0.8887, 0.8091, 0.7636, 1.0714, 0.8307, 0.5597, 0.9634,\n                       0.8995, 0.9417, 0.7242, 0.9938, 0.6137, 0.9859, 1.1233, 0.8038, 1.0659,\n                       0.7544, 1.1706, 0.6587, 0.9926, 0.6924, 0.8092, 0.5710, 0.9503, 0.7739,\n                       0.7966, 0.8105, 0.8833, 1.1272])),\n              ('backbone.models.0.model.layer3.4.bn2.bias',\n               tensor([-8.6152e-01, -8.4289e-01, -2.6830e-01, -8.7086e-01,  3.7041e-01,\n                        1.6724e-01, -5.9141e-01, -1.4214e-01, -6.4783e-01, -3.7117e-01,\n                       -1.8182e-01, -7.2028e-01, -4.1239e-01, -7.4420e-01, -2.6979e-01,\n                       -1.2127e+00, -6.5798e-01, -4.1148e-01, -5.2807e-01, -5.2162e-01,\n                        1.1106e-01, -6.7084e-01, -3.8859e-01, -1.3521e-01, -9.1749e-01,\n                       -8.2939e-01, -1.3422e+00, -2.3406e-01, -5.1680e-01,  3.0986e-01,\n                       -5.1248e-01, -1.9107e-01, -6.5174e-01, -1.4406e+00, -5.5336e-01,\n                        1.0632e-01, -4.8684e-01, -4.7001e-01, -6.5304e-01, -6.3123e-02,\n                       -4.7153e-01, -4.6773e-01, -1.1615e-01, -1.0027e+00,  3.3107e-01,\n                       -8.3580e-01, -1.5766e+00, -6.3737e-03, -4.0722e-01, -6.1671e-01,\n                       -3.4517e-01, -2.3801e-01, -8.2520e-01, -5.1817e-01, -1.4132e-01,\n                       -7.1911e-01, -4.1831e-01, -7.9419e-01,  4.0887e-03, -1.3959e+00,\n                       -1.7379e-01, -1.0534e+00, -5.0474e-01, -1.0484e+00, -3.4099e-01,\n                       -9.0288e-01, -4.2689e-01, -7.3027e-01, -4.3696e-01, -2.3771e-01,\n                       -3.6615e-01, -7.7533e-01, -9.8212e-01, -2.0315e-01, -2.4040e-01,\n                       -7.2924e-01, -1.1591e-01, -9.6938e-01, -6.5366e-01, -8.6500e-01,\n                       -5.3476e-01, -1.4392e+00, -7.9029e-01, -5.5436e-01, -1.0007e+00,\n                       -3.2138e-01, -1.2129e-02, -6.1757e-01, -4.8240e-01, -8.6271e-01,\n                       -3.7229e-01, -6.4480e-01, -5.9752e-01, -1.3573e+00, -7.2582e-01,\n                       -1.6643e-01, -1.6784e+00, -8.6080e-01, -7.4848e-01, -6.8161e-01,\n                       -5.5800e-01, -3.7475e-01, -3.7656e-01, -4.8676e-01, -4.7875e-01,\n                       -6.0442e-01, -3.3800e-01, -5.6574e-01, -3.1444e-01, -7.0743e-01,\n                       -9.8649e-01, -8.2899e-01,  1.4376e-01, -3.4058e-01, -6.4332e-01,\n                       -1.3054e+00, -1.0272e+00, -2.4891e-01, -7.7134e-01, -6.4655e-01,\n                       -7.5246e-01, -8.6317e-01, -1.2664e+00, -9.6028e-01, -5.4524e-01,\n                       -6.4978e-01, -1.9580e-01, -1.4825e+00, -3.3557e-01, -3.9547e-01,\n                       -5.2826e-01,  5.2205e-01, -4.2403e-01, -2.6869e-01, -1.0067e+00,\n                       -3.1488e-01, -6.9198e-01, -5.3245e-01, -6.3954e-01, -7.0602e-01,\n                       -5.6846e-01, -1.2751e+00, -6.1004e-01, -5.0499e-01, -1.3776e-01,\n                       -5.7965e-01, -6.7448e-01, -9.5518e-01, -9.6101e-02, -4.1028e-01,\n                        4.0258e-01, -5.9275e-01, -5.4576e-01, -6.5226e-03, -2.1039e-01,\n                       -1.9376e-01, -1.2514e+00, -4.7260e-01, -7.6735e-01, -8.1966e-01,\n                       -8.9322e-01, -1.1743e+00, -2.5453e-01, -6.4814e-01,  1.7790e-01,\n                       -4.2704e-01, -3.1346e-01, -5.0327e-01, -4.3756e-01, -3.2129e-01,\n                       -4.5198e-03, -2.4816e-01, -1.7650e-01, -6.1489e-01,  2.4953e-01,\n                       -6.5442e-01, -9.2524e-02, -9.1291e-01, -4.0597e-01, -3.9527e-01,\n                       -2.8498e-01, -4.3321e-02, -7.2262e-01,  1.6532e-01, -8.4209e-02,\n                       -2.4069e-01, -5.5845e-01, -7.4992e-01, -8.1547e-01,  5.4080e-01,\n                       -1.3287e-01,  1.3145e-01, -1.3730e-01, -2.8447e-01, -4.1340e-01,\n                       -9.9708e-01, -1.7576e-01, -6.2142e-01, -3.2204e-01, -4.1189e-01,\n                       -3.7497e-01, -7.1159e-01, -8.9126e-01, -5.2635e-01, -7.4841e-01,\n                       -2.7919e-01, -9.4457e-01, -3.7342e-01,  9.1020e-02, -6.2663e-01,\n                       -6.1753e-01, -1.4939e+00, -4.1930e-01, -4.9465e-01, -1.7428e-01,\n                       -1.2310e+00, -6.3117e-02, -1.3460e+00, -5.5085e-01, -4.2570e-01,\n                       -1.3055e+00, -4.6116e-01, -3.2347e-01, -5.0842e-01, -2.2680e-01,\n                       -9.3812e-01, -3.4925e-01, -6.1587e-01, -3.8853e-01, -2.5315e-01,\n                       -9.3544e-01, -5.2501e-01,  4.5034e-01, -8.2730e-01, -6.7425e-01,\n                       -5.6943e-01, -9.6139e-02, -7.0256e-01, -9.6605e-04, -6.0502e-01,\n                       -7.2302e-01, -1.9743e-01, -6.5315e-01, -2.2478e-01, -1.2073e+00,\n                       -8.7614e-02, -7.4782e-01,  3.3759e-01, -4.4659e-01,  1.8259e-01,\n                       -5.9755e-01, -2.5736e-01, -3.8117e-01, -4.1322e-01, -4.6096e-01,\n                       -1.0513e+00])),\n              ('backbone.models.0.model.layer3.4.bn2.running_mean',\n               tensor([-0.7252, -0.3259,  0.1421,  0.0989, -0.5363,  0.1086, -0.1258, -0.3931,\n                       -0.4092, -0.1347, -0.0666, -0.2214, -0.3072, -0.8648, -0.1385, -0.7678,\n                       -0.5262, -0.4660, -0.3785, -0.5504,  0.3703, -0.6407, -0.2659, -0.6409,\n                       -0.5144, -0.5211, -0.4943, -0.0905, -0.4337, -0.0427, -0.6366,  0.0265,\n                       -0.3705, -0.8526, -0.8886, -0.0191, -0.5648, -0.4689, -0.0190, -0.0636,\n                       -0.5765, -0.9753, -0.3769, -0.5004,  0.5652, -0.3326, -0.8533, -0.1819,\n                       -0.8456, -0.3311,  0.0677, -0.3767, -0.4164,  0.0938, -0.3033, -0.1548,\n                       -0.8283, -0.1262, -0.1946, -0.9077, -0.0286, -0.4594, -0.3681, -0.7106,\n                       -0.4512, -0.4725, -0.2657, -0.5960, -0.3344, -0.3198, -0.3698, -0.9197,\n                       -0.3896, -0.2101, -0.4943, -0.4789, -0.0211, -0.6413, -0.4945, -0.7201,\n                       -0.7408, -0.0542, -0.3469, -0.5998,  0.7470, -0.7250,  0.3199, -0.5439,\n                       -0.7070, -0.5968, -0.3334, -0.2899, -0.5618, -0.5547, -0.4432,  0.2670,\n                       -0.1500, -0.6437, -0.2748, -0.4680, -0.4362, -0.7414, -0.7917, -0.5632,\n                       -0.4194,  0.5422,  0.3299, -0.2981, -0.6635, -0.7987, -0.5407, -0.4978,\n                       -0.3242, -0.2293, -0.4563, -0.6330, -0.6807, -0.5939, -0.7567, -0.5011,\n                       -0.5514, -0.9320, -0.9292, -0.6872,  0.0058, -0.6398, -0.1559, -0.7534,\n                        0.6528, -0.2160, -0.9708,  0.7029, -0.8144, -0.1394,  0.1186, -0.4960,\n                       -0.4672, -0.3380, -0.3043, -0.5178, -0.7964, -0.2632, -0.7975, -0.3635,\n                       -0.2549, -0.0362, -0.3313, -0.5092, -0.9033,  0.0043,  0.2005, -0.6091,\n                       -0.2885, -0.0679, -0.3401, -0.5131, -0.4704, -0.5668, -0.7135, -0.6475,\n                       -0.3936, -0.7646, -0.1351, -0.5401, -0.2910, -0.3340, -0.8594, -0.3405,\n                       -0.7997, -0.8925, -0.3658,  0.3465, -0.1234, -0.2720, -0.2028, -0.5642,\n                       -0.0827,  0.3414, -0.8450, -0.0294, -0.4834, -0.0740, -0.4927, -0.1026,\n                       -0.0389,  0.0843, -0.5297, -0.9253,  0.2246,  0.0760, -0.2761,  0.1326,\n                       -0.2544, -0.0254, -0.6907, -0.8829,  0.4255, -0.6876, -0.6724, -0.2540,\n                       -0.3221, -0.9164, -0.2982, -0.0572, -0.4241, -0.3728, -0.8352, -0.3495,\n                        0.0504, -0.7600, -0.4121, -0.1902, -0.3174, -0.4020,  0.1818, -0.7755,\n                        0.0605, -0.9430, -0.4853, -0.2897, -0.6834, -0.4916, -0.3706, -0.5531,\n                       -0.0731, -1.0488, -0.9188, -0.5612, -0.3113, -0.1910, -0.5127,  0.2105,\n                       -0.7412,  1.3831,  0.1001, -0.4655, -0.2246, -0.5146,  0.2533, -0.7776,\n                       -1.4741, -0.7105, -0.4966, -0.4755, -0.8794, -0.1644, -0.5682, -0.7449,\n                       -0.3585, -0.0670, -0.4083,  0.2489,  0.2854, -0.1272, -0.5003, -0.5321])),\n              ('backbone.models.0.model.layer3.4.bn2.running_var',\n               tensor([0.9614, 0.6273, 0.7318, 0.9707, 1.3587, 0.6939, 1.7236, 0.8222, 0.8820,\n                       1.1747, 1.1413, 0.8840, 0.6434, 1.7659, 0.8820, 0.6876, 0.9703, 0.8066,\n                       0.6910, 0.6003, 1.0017, 1.8002, 0.9339, 1.0169, 1.0264, 1.2105, 0.5577,\n                       1.0136, 0.8490, 0.8291, 0.6802, 0.5246, 0.6254, 0.5787, 1.5335, 0.7666,\n                       1.1508, 0.9285, 0.9099, 0.6739, 0.5114, 1.3298, 0.9084, 0.7662, 0.7228,\n                       0.6611, 0.4377, 1.4571, 1.0912, 1.0790, 0.9341, 0.9941, 1.0769, 0.8930,\n                       0.6832, 0.9476, 0.9918, 0.8270, 0.6739, 0.6439, 0.7673, 0.9899, 0.8583,\n                       2.2650, 0.6410, 0.7258, 1.0034, 0.8524, 0.6913, 0.8604, 0.9356, 1.2155,\n                       1.0308, 1.0812, 1.0386, 0.7919, 0.6915, 0.7290, 0.8885, 1.3052, 0.8801,\n                       0.1214, 1.0191, 1.4733, 0.9317, 1.0365, 0.6723, 1.6342, 0.5606, 0.9240,\n                       1.2942, 0.9255, 1.0040, 0.6609, 1.0714, 1.8582, 0.1680, 0.5396, 0.5837,\n                       0.7603, 0.5849, 0.8720, 1.1669, 1.1255, 0.8626, 1.4312, 0.9765, 1.2140,\n                       0.6657, 0.8496, 0.8032, 0.5571, 0.7449, 1.0479, 1.0548, 0.5544, 1.4939,\n                       0.7721, 0.8217, 1.2628, 0.5050, 1.8877, 1.3865, 0.6997, 1.0464, 0.8041,\n                       0.5177, 1.1816, 1.2579, 0.9528, 1.2708, 0.3659, 0.6577, 1.1997, 0.8559,\n                       0.8370, 0.8954, 1.4019, 0.8891, 0.6493, 0.8516, 0.4265, 0.7241, 0.7179,\n                       0.9466, 0.9218, 0.7862, 1.1599, 1.3022, 1.3436, 0.6608, 1.1067, 0.6558,\n                       0.7858, 0.6397, 0.8467, 0.6069, 1.1026, 0.8563, 0.6178, 0.9982, 0.7548,\n                       0.9861, 1.0072, 1.4441, 1.1157, 1.1543, 1.2050, 1.2257, 0.8825, 0.6776,\n                       1.1627, 0.6572, 0.5103, 0.7552, 1.6758, 0.9613, 1.7565, 0.8367, 0.9444,\n                       0.8597, 0.9998, 1.2247, 0.7690, 0.7478, 0.8187, 1.0114, 1.0543, 0.5558,\n                       0.6114, 0.7790, 0.7057, 0.7130, 1.1451, 0.9556, 0.7272, 0.8777, 0.7873,\n                       1.5492, 1.3649, 0.9110, 1.2674, 0.9152, 1.4696, 1.9290, 1.1311, 0.6971,\n                       0.7406, 0.5192, 0.7694, 1.4150, 0.6561, 0.7103, 1.1765, 0.8493, 0.6418,\n                       0.6277, 0.4889, 0.5141, 0.6725, 0.6509, 0.7689, 0.7551, 0.9580, 1.7671,\n                       1.2452, 1.0255, 0.7920, 0.9516, 1.0756, 0.8379, 0.9135, 0.9569, 1.8861,\n                       0.5697, 0.9357, 0.9326, 1.0167, 0.9694, 1.2255, 1.8164, 1.1698, 2.1777,\n                       0.7810, 1.5592, 0.7097, 0.9761, 1.6211, 0.7546, 0.7241, 0.9573, 1.2620,\n                       1.2575, 1.1500, 0.8016, 0.9340])),\n              ('backbone.models.0.model.layer3.4.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.4.conv3.weight',\n               tensor([[[[ 0.0509]],\n               \n                        [[-0.0359]],\n               \n                        [[-0.0451]],\n               \n                        ...,\n               \n                        [[-0.0067]],\n               \n                        [[-0.0245]],\n               \n                        [[ 0.0061]]],\n               \n               \n                       [[[-0.0178]],\n               \n                        [[-0.1220]],\n               \n                        [[-0.0515]],\n               \n                        ...,\n               \n                        [[-0.0136]],\n               \n                        [[-0.0121]],\n               \n                        [[ 0.0844]]],\n               \n               \n                       [[[-0.0883]],\n               \n                        [[ 0.0105]],\n               \n                        [[-0.0075]],\n               \n                        ...,\n               \n                        [[ 0.0390]],\n               \n                        [[-0.0400]],\n               \n                        [[-0.0147]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0113]],\n               \n                        [[ 0.0063]],\n               \n                        [[-0.0457]],\n               \n                        ...,\n               \n                        [[-0.0016]],\n               \n                        [[-0.0423]],\n               \n                        [[-0.0016]]],\n               \n               \n                       [[[ 0.0204]],\n               \n                        [[ 0.0900]],\n               \n                        [[-0.0836]],\n               \n                        ...,\n               \n                        [[-0.0475]],\n               \n                        [[ 0.0191]],\n               \n                        [[ 0.0702]]],\n               \n               \n                       [[[ 0.0202]],\n               \n                        [[-0.0325]],\n               \n                        [[-0.0265]],\n               \n                        ...,\n               \n                        [[-0.0118]],\n               \n                        [[-0.0333]],\n               \n                        [[-0.0150]]]])),\n              ('backbone.models.0.model.layer3.4.bn3.weight',\n               tensor([-0.0952,  0.7639, -0.1543,  ..., -0.1624, -0.7294,  0.1337])),\n              ('backbone.models.0.model.layer3.4.bn3.bias',\n               tensor([ 0.0539, -0.4993,  0.1478,  ...,  0.0047, -0.6568,  0.1802])),\n              ('backbone.models.0.model.layer3.4.bn3.running_mean',\n               tensor([-0.1958, -0.3871, -0.0783,  ..., -0.1256,  0.3263, -0.0512])),\n              ('backbone.models.0.model.layer3.4.bn3.running_var',\n               tensor([0.0296, 0.2596, 0.0461,  ..., 0.0542, 0.1636, 0.0381])),\n              ('backbone.models.0.model.layer3.4.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.5.conv1.weight',\n               tensor([[[[ 0.1274]],\n               \n                        [[-0.0464]],\n               \n                        [[ 0.0162]],\n               \n                        ...,\n               \n                        [[ 0.0625]],\n               \n                        [[-0.0909]],\n               \n                        [[ 0.0200]]],\n               \n               \n                       [[[ 0.0058]],\n               \n                        [[-0.0197]],\n               \n                        [[ 0.0206]],\n               \n                        ...,\n               \n                        [[-0.0782]],\n               \n                        [[ 0.0295]],\n               \n                        [[-0.0282]]],\n               \n               \n                       [[[ 0.0238]],\n               \n                        [[ 0.0490]],\n               \n                        [[-0.0413]],\n               \n                        ...,\n               \n                        [[-0.0247]],\n               \n                        [[-0.0259]],\n               \n                        [[-0.0618]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0378]],\n               \n                        [[ 0.1373]],\n               \n                        [[ 0.0628]],\n               \n                        ...,\n               \n                        [[ 0.0053]],\n               \n                        [[ 0.0366]],\n               \n                        [[-0.0741]]],\n               \n               \n                       [[[-0.1165]],\n               \n                        [[-0.1226]],\n               \n                        [[-0.0321]],\n               \n                        ...,\n               \n                        [[-0.0494]],\n               \n                        [[-0.0448]],\n               \n                        [[-0.0141]]],\n               \n               \n                       [[[-0.0147]],\n               \n                        [[-0.0564]],\n               \n                        [[-0.0015]],\n               \n                        ...,\n               \n                        [[-0.0417]],\n               \n                        [[-0.0342]],\n               \n                        [[ 0.0402]]]])),\n              ('backbone.models.0.model.layer3.5.bn1.weight',\n               tensor([0.7896, 0.7519, 0.8334, 0.8595, 0.7469, 0.8936, 0.5936, 0.7518, 1.1722,\n                       0.5631, 0.9237, 0.7923, 0.7580, 0.7477, 0.8066, 0.7134, 0.9392, 0.9311,\n                       1.0508, 0.7548, 0.8774, 0.8216, 0.8828, 0.8919, 0.7958, 0.8527, 0.9682,\n                       0.8503, 0.9700, 0.8526, 0.7352, 0.8305, 0.8032, 0.9293, 0.7563, 0.9086,\n                       0.7861, 0.9385, 0.9758, 0.7756, 0.3758, 0.9081, 0.6928, 0.8988, 0.7653,\n                       0.9380, 1.0698, 0.6536, 0.7794, 0.8323, 0.7813, 0.7997, 0.6868, 0.8304,\n                       0.9388, 0.9368, 0.9425, 0.8327, 0.9469, 0.7372, 0.6990, 1.0544, 0.6461,\n                       0.8359, 0.8250, 0.8680, 0.7482, 0.6003, 0.7674, 0.7665, 1.0472, 0.6938,\n                       0.9611, 0.8826, 0.7746, 0.8501, 0.8188, 0.7470, 0.7700, 1.0686, 0.9848,\n                       0.6932, 0.9311, 0.7516, 0.5960, 0.8391, 0.7962, 0.8906, 0.8824, 0.7065,\n                       0.9445, 0.7884, 1.0286, 0.6818, 0.5602, 0.9976, 0.8065, 0.9383, 0.7714,\n                       0.9171, 0.7586, 0.7821, 0.8649, 0.6883, 0.7179, 0.8069, 0.7323, 0.7337,\n                       0.8321, 0.8193, 1.3192, 0.7820, 0.8029, 0.8823, 0.8364, 0.8556, 0.6133,\n                       0.8328, 0.8150, 0.7110, 0.8594, 0.9677, 0.8197, 1.1904, 0.9165, 0.9224,\n                       0.7516, 0.7897, 0.8412, 0.9319, 0.9303, 0.8331, 0.8312, 0.8668, 0.9062,\n                       0.8909, 0.8306, 0.9086, 0.7353, 0.8192, 0.8564, 0.8612, 0.7916, 0.8172,\n                       0.8578, 0.8651, 0.7816, 0.7548, 1.0942, 0.8922, 0.8428, 0.7768, 0.7361,\n                       0.9181, 0.9271, 0.7122, 0.7165, 0.8830, 1.0536, 1.1224, 0.6553, 0.9735,\n                       0.8912, 0.7231, 0.9735, 0.8103, 1.0129, 0.8311, 0.7354, 0.9506, 1.0406,\n                       0.8581, 0.6622, 0.7379, 0.8600, 1.0175, 0.8266, 0.7311, 0.7932, 1.0282,\n                       0.7979, 0.7881, 0.8511, 0.8886, 1.0408, 1.0297, 0.8243, 0.7479, 0.9762,\n                       0.8055, 0.8146, 0.7132, 0.8893, 1.1814, 0.7652, 0.8379, 0.8497, 1.1193,\n                       1.0110, 0.9481, 0.7713, 0.8805, 0.4457, 0.9775, 0.8191, 1.0501, 0.7721,\n                       0.7195, 0.9595, 0.7586, 0.5692, 0.8377, 0.9373, 0.9277, 0.7314, 0.8193,\n                       0.7613, 0.7515, 0.7621, 0.7198, 1.0166, 0.8550, 0.7683, 1.1520, 0.7555,\n                       0.7346, 0.9053, 1.0535, 0.7573, 0.9688, 1.0061, 0.9578, 0.8486, 0.7746,\n                       0.9502, 0.8711, 0.7046, 0.7569, 1.0822, 0.9394, 0.6238, 0.7513, 0.8028,\n                       0.9077, 0.8119, 0.7589, 0.9679, 0.8644, 0.6641, 0.8606, 0.8291, 0.9052,\n                       0.8611, 0.8035, 0.8360, 0.7666])),\n              ('backbone.models.0.model.layer3.5.bn1.bias',\n               tensor([-0.6505, -0.5921, -0.5511, -0.8707, -0.6093, -0.1821, -0.1761, -0.6391,\n                       -1.5514, -0.0305, -0.9015, -0.5180, -0.4870, -0.2905, -0.5984, -0.4223,\n                       -1.0176, -1.0094, -1.2841, -0.5319, -1.1243, -0.6122, -0.8622, -0.7137,\n                       -0.6546, -0.6939, -1.2671, -0.8778, -0.9442, -0.9277, -0.4339, -0.6048,\n                       -0.6166, -0.7541, -0.4285, -0.9208, -0.6244, -0.8876, -0.8527, -0.5947,\n                        0.4195, -0.9009, -0.4832, -0.7921, -0.6256, -0.9952, -1.4810, -0.2667,\n                       -0.6511, -0.6621, -0.6032, -0.5770, -0.2818, -0.7040, -1.0931, -0.9208,\n                       -0.9774, -0.7814, -0.6148, -0.5513, -0.3623, -0.8263, -0.1128, -0.7761,\n                       -0.6740, -0.8626, -0.4692, -0.0153, -0.4542, -0.7400, -1.5754, -0.3737,\n                       -0.9294, -0.6505, -0.6298, -0.7569, -0.8407, -0.4213, -0.6143, -0.9204,\n                       -1.0197, -0.2836, -1.0986, -0.3982, -0.0719, -0.7790, -0.6632, -0.7027,\n                       -0.7583, -0.3549, -0.9162, -0.5715, -1.0550, -0.3128,  0.4635, -1.1716,\n                       -0.6899, -0.8581, -0.6793, -0.8065, -0.2842, -0.7247, -0.7664, -0.3299,\n                       -0.5959, -0.6045, -0.4908, -0.4774, -0.5033, -0.6216,  0.1450, -0.6230,\n                       -0.5388, -1.0797, -0.8037, -0.8206,  0.0126, -0.6741, -0.4685, -0.3846,\n                       -0.9084, -0.7498, -0.8076, -1.4096, -0.5796, -0.8514, -0.6018, -0.5302,\n                       -0.4666, -0.7181, -1.0764, -0.8119, -0.9065, -0.7721, -1.1846, -0.9745,\n                       -0.9393, -0.7660, -0.5277, -0.3477, -0.5785, -0.7816, -0.6143, -0.6823,\n                       -0.7670, -0.9158, -0.5502, -0.6570, -0.9820, -0.7762, -0.7225, -0.7073,\n                       -0.4428, -1.0636, -1.0413, -0.4423, -0.3801, -0.2731, -1.2986, -1.8443,\n                       -0.2904, -1.1194, -0.8805, -0.3561, -0.8170, -0.8470, -1.0939, -0.4836,\n                       -0.3903, -1.0170, -1.1365, -0.8641, -0.2935, -0.4418, -0.6541, -0.8688,\n                       -0.2875, -0.4963, -0.5575, -0.8066, -0.7332, -0.6306, -0.9032, -0.8835,\n                       -1.0730, -0.9532, -0.7944, -0.4141, -1.0804, -0.3665, -0.5699, -0.3025,\n                       -1.0862, -1.2467, -0.6589, -0.7273, -0.8043,  0.4658, -1.0967, -0.9728,\n                       -0.6819, -0.9313,  0.6581, -1.3338, -0.6246, -1.2911, -0.4912, -0.4510,\n                       -1.0828, -0.5620, -0.0753, -0.5640, -0.9633, -1.1062, -0.6099, -0.9159,\n                       -0.6253, -0.4737, -0.5757, -0.4310, -1.2432, -0.9702, -0.4836, -1.3151,\n                       -0.4251, -0.5111, -0.6714, -1.2476, -0.5585, -1.0960, -1.5995, -0.6606,\n                       -0.6098, -0.6179, -0.7071, -0.8634, -0.3138, -0.5008, -1.6885, -0.5822,\n                       -0.1843, -0.5288, -0.6885, -0.8590, -0.6355, -0.4820, -0.7042, -0.8868,\n                       -0.3602, -0.9540, -0.5600, -0.7181, -0.7241, -0.4958, -0.8050, -0.5655])),\n              ('backbone.models.0.model.layer3.5.bn1.running_mean',\n               tensor([-1.8646e+00, -5.2730e-01, -7.2617e-01, -2.6788e+00, -2.0531e+00,\n                        3.0803e+00, -1.1417e+00, -2.3207e+00, -2.2333e+00, -1.5066e+00,\n                       -1.3862e+00, -2.1498e+00, -1.7544e+00, -1.0094e+00, -9.9143e-01,\n                       -2.0029e+00, -3.3631e+00, -1.8805e+00, -2.6520e+00, -1.3628e+00,\n                       -1.3890e+00, -2.4190e+00, -1.7538e+00, -1.3836e+00, -7.6401e-01,\n                        1.0209e-01, -2.0957e+00, -1.3830e+00, -1.1992e+00, -2.4206e+00,\n                       -1.2070e+00, -8.2766e-01, -1.7676e+00, -2.5390e+00, -2.2321e+00,\n                       -2.7970e-02, -1.0675e+00, -1.5056e+00, -2.6188e+00,  5.3763e-01,\n                       -8.5438e+00, -3.1324e+00, -1.0263e+00, -6.4738e-01, -8.0128e-01,\n                       -3.3880e+00, -3.6423e+00, -8.1810e-01, -8.7267e-01, -1.8722e+00,\n                       -8.8535e-01, -1.4729e+00, -2.6831e+00, -8.7360e-01, -3.0544e+00,\n                       -1.4589e+00, -2.9016e+00, -2.2898e+00, -2.3400e+00, -2.7554e-01,\n                       -2.8612e+00, -5.1971e+00, -1.1221e+00, -2.0921e+00, -9.1076e-01,\n                       -6.6681e-01, -1.8042e+00,  9.4477e-03, -2.9335e-01, -2.4251e+00,\n                       -3.0464e+00, -2.8089e+00, -2.2415e+00, -3.1191e+00, -2.0611e+00,\n                       -8.7336e-01, -1.9381e+00, -1.6668e+00, -1.7412e+00, -2.7040e+00,\n                       -2.2896e+00, -3.3384e+00, -2.7634e+00, -2.3558e+00, -3.9786e-01,\n                       -2.3070e-02, -2.4411e+00, -4.2911e+00, -2.1714e+00, -1.7949e+00,\n                       -1.5257e+00, -2.3004e+00, -4.2913e+00, -7.2041e-01, -5.7116e+00,\n                       -2.0568e+00, -1.3338e+00, -2.4731e+00, -1.5443e+00, -3.1494e+00,\n                       -2.9161e-01, -1.1371e+00, -2.3783e+00, -1.3782e+00, -2.4420e+00,\n                       -2.5731e+00, -1.6754e+00, -1.3736e+00, -2.8139e+00, -7.4373e-01,\n                        4.3118e+00, -1.1722e+00, -4.0596e-01, -2.6744e+00, -2.1525e+00,\n                       -1.1835e+00, -8.2019e-01, -1.0305e+00, -3.3769e+00, -1.7047e+00,\n                       -1.9543e+00, -2.1880e+00, -2.2720e+00, -4.4445e+00, -3.6358e+00,\n                       -4.5276e+00, -2.4158e+00, -2.1899e+00, -4.4612e-01, -2.8008e+00,\n                       -2.0971e-01, -1.5072e+00, -1.4675e+00, -2.6026e+00, -3.2855e+00,\n                       -3.0055e+00, -2.2347e+00, -4.0948e+00, -1.3544e+00, -2.6996e+00,\n                       -2.0185e+00, -1.5547e+00, -9.0701e-01, -2.3062e+00, -2.4914e+00,\n                       -1.6696e+00, -8.7857e-01, -1.7080e+00, -4.7364e+00,  5.2730e-01,\n                       -2.2710e+00, -1.3552e+00, -7.9622e-01, -9.7814e-01, -2.3072e+00,\n                       -2.2373e+00, -4.7273e-01, -1.6280e+00, -4.0247e+00, -4.1640e+00,\n                       -1.7828e+00, -1.2573e+00, -1.4811e+00, -6.4025e-01, -4.4038e+00,\n                       -1.8885e+00, -4.2876e+00, -2.9968e+00, -1.9045e+00, -1.8116e+00,\n                       -2.4706e+00, -3.1385e+00, -1.2972e+00, -3.0751e-01, -1.2508e+00,\n                       -2.3378e+00, -2.1298e+00, -2.3204e+00, -3.2348e+00, -3.8874e+00,\n                       -1.7384e+00, -1.1332e+00, -1.1557e+00, -1.4156e+00, -3.0137e+00,\n                       -3.4287e+00, -1.3258e+00, -1.2651e+00, -1.4665e+00, -2.7910e+00,\n                       -2.9119e+00, -2.3886e+00, -3.7081e-01, -3.2393e+00, -1.5004e+00,\n                       -2.6194e+00, -1.8094e+00, -5.7800e+00, -4.2221e+00, -3.2112e+00,\n                       -1.3715e+00, -2.8740e-01,  9.7914e+00, -4.6063e+00, -1.3755e+00,\n                       -2.0191e+00, -2.5458e+00, -2.5479e+00, -2.3716e+00, -3.0042e-01,\n                       -3.9964e+00,  9.2528e-01, -1.2745e+00, -1.8953e+00, -1.0943e+00,\n                       -2.0772e+00, -1.0675e+00, -1.6825e+00, -2.1911e+00, -3.0018e-01,\n                       -4.9459e+00, -1.7292e+00, -1.5286e+00, -3.9264e+00, -1.6790e+00,\n                       -1.8240e+00, -2.6563e+00, -3.1444e+00, -1.5604e+00, -3.5191e+00,\n                       -3.9550e+00, -2.4202e+00, -3.2999e+00, -2.4727e+00, -2.6955e+00,\n                       -1.3099e+00, -1.6718e+00,  9.7523e-02, -4.8412e+00, -1.7684e+00,\n                       -2.8091e+00, -2.0971e+00, -1.2319e+00, -1.5799e+00, -6.3826e-01,\n                       -9.7700e-01, -2.4259e+00, -1.7433e+00, -1.4462e+00, -3.4131e+00,\n                       -3.3985e-01, -1.0648e+00, -9.6030e-01, -2.8742e+00, -2.6567e+00,\n                       -1.0581e+00])),\n              ('backbone.models.0.model.layer3.5.bn1.running_var',\n               tensor([ 3.3447,  3.2306,  4.7888,  2.5555,  2.9169,  5.6589,  3.5364,  3.5122,\n                        3.0503,  3.9382,  3.2311,  3.2928,  4.6521,  4.7237,  3.3243,  3.7832,\n                        3.6381,  2.5580,  2.8589,  3.6957,  2.6281,  4.4193,  3.9936,  4.4326,\n                        3.6584,  5.4283,  2.3747,  3.1745,  4.5845,  3.3697,  4.0415,  4.8850,\n                        3.9989,  4.5044,  3.7124,  4.2068,  3.4349,  3.5194,  3.3871,  4.5385,\n                        2.3989,  3.8491,  3.2058,  4.8841,  3.3837,  3.0607,  2.6220,  3.7196,\n                        3.1505,  4.2097,  3.1634,  3.5309,  4.3817,  3.6115,  3.9101,  2.8773,\n                        3.8452,  2.7384,  4.2843,  4.4242,  4.6151,  6.0879,  5.0947,  2.9402,\n                        3.4554,  3.2441,  4.1869,  4.9680,  6.0776,  2.7162,  2.3196,  4.7165,\n                        3.2921,  3.7494,  2.6978,  3.1914,  2.8799,  3.8515,  3.3470,  3.3038,\n                        4.1646,  5.0405,  3.1834,  3.6599,  4.6680,  3.9696,  2.9113,  3.6689,\n                        4.7000,  3.4000,  4.0294,  4.0364,  2.9752,  5.6524,  3.8054,  3.2007,\n                        2.6426,  2.9749,  3.8939,  3.1004,  4.8864,  2.8691,  3.4396,  3.2967,\n                        2.8199,  4.2900,  3.5753,  3.5477,  3.6998,  5.1127, 22.2935,  3.5356,\n                        4.5413,  2.2050,  4.4684,  3.4730,  4.3650,  3.1276,  3.1995,  3.7043,\n                        3.1929,  3.7351,  2.4892,  3.9723,  4.6994,  3.2603,  3.4286,  4.4163,\n                        6.5678,  3.4442,  3.4816,  3.1825,  3.5930,  3.5409,  2.1307,  3.5586,\n                        3.0498,  3.4127,  4.3996,  6.0779,  4.2358,  3.1225,  4.3142,  3.6845,\n                        3.6729,  2.9925,  6.1053,  3.3548,  4.6161,  3.2179,  4.2918,  2.4672,\n                        3.5965,  3.5530,  2.8685,  3.5157,  5.8806,  6.1951,  2.5393,  3.6195,\n                        3.7603,  2.8734,  3.9425,  3.6249,  5.9043,  2.8112,  4.9343,  4.2689,\n                        4.9521,  3.5227,  3.3543,  3.5568,  4.0565,  4.1355,  4.1457,  3.8249,\n                        5.1440,  3.3786,  3.6230,  3.6582,  3.9034,  3.5181,  3.0774,  4.2082,\n                        3.0746,  3.8721,  3.0470,  4.9228,  4.0929,  6.9858,  3.8431,  4.8549,\n                        2.4128,  3.9074,  3.7559,  3.1115,  3.7094, 12.9652,  2.9286,  4.4814,\n                        4.2048,  3.9639,  5.6827,  2.9554,  4.1330,  3.0430,  4.3290,  3.0833,\n                        3.2532,  3.7671,  4.1708,  4.9889,  5.0055,  3.1191,  3.3386,  2.4647,\n                        4.3089,  3.4665,  3.8909,  3.6550,  3.7263,  3.3792,  4.0845,  3.3751,\n                        4.2164,  3.9544,  3.6284,  3.1802,  3.2466,  2.6080,  2.1507,  4.2076,\n                        5.3379,  3.5382,  4.3154,  3.8753,  3.9206,  4.9483,  2.8442,  4.6213,\n                        4.2003,  4.0341,  3.4164,  3.4793,  5.5102,  4.6345,  4.1400,  3.7983,\n                        3.9670,  2.7891,  5.0714,  5.5195,  4.0611,  3.6280,  3.4552,  3.2693])),\n              ('backbone.models.0.model.layer3.5.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.5.conv2.weight',\n               tensor([[[[ 1.2067e-02, -4.6124e-02, -2.3333e-02],\n                         [-2.3072e-02,  1.4295e-02, -1.8371e-02],\n                         [-2.5654e-02, -4.7045e-02, -6.6263e-02]],\n               \n                        [[-1.1534e-02,  4.2482e-02,  2.4503e-02],\n                         [ 3.9570e-02,  2.0177e-02,  7.5459e-02],\n                         [ 1.6685e-02,  2.1764e-02,  1.0630e-02]],\n               \n                        [[-9.1451e-03, -1.0594e-02, -8.6405e-03],\n                         [ 2.4071e-02, -8.2690e-03, -1.6349e-03],\n                         [-3.6864e-02, -5.2665e-02,  7.2098e-03]],\n               \n                        ...,\n               \n                        [[ 2.8567e-02, -6.6388e-03, -2.5410e-02],\n                         [-9.1456e-03, -1.0920e-02,  6.4440e-03],\n                         [ 2.1373e-02,  2.0515e-02,  1.0434e-02]],\n               \n                        [[ 2.4128e-02,  1.4223e-02,  4.7189e-02],\n                         [ 2.1166e-02, -3.6905e-02,  4.9974e-02],\n                         [ 4.5915e-02,  1.5035e-02,  7.2065e-02]],\n               \n                        [[-1.1883e-02, -1.0740e-02,  2.9365e-02],\n                         [ 3.6043e-02,  4.7815e-02,  6.6370e-02],\n                         [ 3.3248e-02,  4.7281e-02,  7.0840e-02]]],\n               \n               \n                       [[[-3.1549e-02,  2.3547e-02,  1.0949e-02],\n                         [-7.0744e-03,  1.0045e-01, -4.9880e-02],\n                         [ 7.5921e-03,  6.5582e-02, -1.1274e-02]],\n               \n                        [[-2.9983e-02, -1.0423e-02, -1.9873e-02],\n                         [ 1.2769e-02, -5.0569e-02,  9.3951e-03],\n                         [ 6.9326e-04, -2.4025e-02,  3.9149e-03]],\n               \n                        [[ 1.6379e-02,  1.8089e-02,  3.7953e-02],\n                         [ 3.9267e-02, -2.6007e-02,  6.0001e-02],\n                         [ 8.5022e-03,  3.6397e-03,  1.9413e-02]],\n               \n                        ...,\n               \n                        [[ 7.1899e-04,  8.7133e-03,  3.2667e-03],\n                         [-2.6036e-02,  5.9603e-02, -2.9920e-02],\n                         [ 2.2903e-02, -1.3884e-02, -2.5545e-02]],\n               \n                        [[ 1.2725e-02, -4.5785e-03, -1.4131e-02],\n                         [ 3.6410e-02,  1.2314e-02,  1.8741e-02],\n                         [ 5.0863e-02,  1.4011e-02,  1.8770e-02]],\n               \n                        [[ 1.4610e-02,  5.1200e-02, -1.3298e-03],\n                         [ 2.4897e-02,  7.9332e-02, -3.7655e-02],\n                         [-1.3145e-02, -2.7731e-02, -1.9369e-02]]],\n               \n               \n                       [[[ 3.3242e-02,  3.0612e-02,  2.3650e-02],\n                         [ 4.5418e-02,  4.2183e-03,  2.5360e-02],\n                         [-5.5771e-03,  1.5656e-02,  2.5117e-02]],\n               \n                        [[ 4.4413e-02,  2.8243e-03,  4.1594e-02],\n                         [ 5.8841e-03,  1.5999e-02,  1.2506e-02],\n                         [-1.1289e-03, -8.6911e-03,  1.6447e-02]],\n               \n                        [[-4.4375e-02, -4.0997e-02, -1.0538e-02],\n                         [-4.9336e-02, -1.3546e-01, -4.8425e-02],\n                         [ 1.7660e-02, -3.6599e-03,  1.0709e-03]],\n               \n                        ...,\n               \n                        [[-1.0540e-02, -2.9158e-02, -3.1609e-02],\n                         [ 1.3840e-02,  4.0324e-02,  1.9946e-02],\n                         [ 2.2820e-02,  8.0148e-02,  7.8059e-02]],\n               \n                        [[-6.2260e-03, -5.0335e-02, -5.6303e-02],\n                         [-2.4546e-02, -3.4125e-02, -6.3322e-02],\n                         [-3.6896e-02, -4.6927e-02, -3.9445e-02]],\n               \n                        [[-8.5130e-04,  1.2969e-02, -9.8923e-03],\n                         [ 3.0417e-03, -3.5387e-02, -5.0245e-02],\n                         [-1.4966e-02, -2.0752e-02, -3.7089e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 2.7655e-02,  2.0128e-02,  1.1390e-02],\n                         [ 4.3842e-02,  8.5860e-02,  1.1141e-02],\n                         [ 3.9764e-03,  1.1007e-01,  5.4238e-02]],\n               \n                        [[-3.6978e-02, -6.3399e-02, -3.7301e-02],\n                         [-9.6961e-03, -7.0890e-03, -1.2540e-02],\n                         [ 3.1650e-02,  4.4657e-02,  1.1875e-02]],\n               \n                        [[ 1.3450e-02,  1.2530e-02,  1.3203e-02],\n                         [-2.1849e-03,  8.6390e-03, -1.7650e-02],\n                         [-2.4878e-02, -2.1788e-02, -3.6819e-02]],\n               \n                        ...,\n               \n                        [[ 2.2019e-03,  3.9584e-02,  3.1010e-02],\n                         [ 3.8773e-02,  8.6286e-02,  3.7464e-02],\n                         [ 5.2503e-02,  8.1797e-02,  9.8998e-02]],\n               \n                        [[-4.2027e-02, -1.1654e-02, -3.1611e-02],\n                         [-5.1290e-03,  2.6188e-02,  1.0695e-02],\n                         [-5.2972e-02, -1.3816e-03, -5.3326e-02]],\n               \n                        [[ 6.6067e-02,  9.2973e-02,  7.4033e-02],\n                         [ 7.4787e-02,  9.4670e-02,  6.4632e-02],\n                         [ 3.4727e-02,  4.2038e-02,  6.2761e-02]]],\n               \n               \n                       [[[-1.8429e-02, -2.7288e-02, -1.8724e-02],\n                         [ 2.7134e-03, -2.5536e-03, -4.6263e-02],\n                         [-2.4384e-02, -6.5149e-02, -7.7576e-02]],\n               \n                        [[ 6.1267e-05,  7.5440e-03, -1.2395e-02],\n                         [-2.4873e-02, -7.0924e-02, -4.8420e-02],\n                         [-1.0368e-02, -4.0369e-02, -3.1087e-03]],\n               \n                        [[-3.5765e-02,  4.3920e-03, -1.0807e-02],\n                         [-3.9939e-02, -1.5440e-02, -3.0306e-02],\n                         [-3.8841e-03, -9.9032e-03, -1.5745e-02]],\n               \n                        ...,\n               \n                        [[-4.9980e-03, -2.8642e-03, -6.4151e-03],\n                         [-2.0684e-02,  2.5578e-03, -6.2439e-02],\n                         [-3.2891e-02, -3.9453e-02, -5.4379e-02]],\n               \n                        [[ 3.0538e-02,  2.0629e-02,  1.8447e-02],\n                         [ 1.5620e-02, -3.1305e-02,  1.8852e-02],\n                         [ 1.6149e-04, -2.6495e-02,  8.2872e-04]],\n               \n                        [[-1.4210e-02,  1.3734e-02,  1.3276e-02],\n                         [-3.6382e-02,  7.1285e-03,  2.8413e-03],\n                         [-4.7920e-03,  1.4296e-02,  1.4003e-02]]],\n               \n               \n                       [[[ 1.6198e-05,  1.0831e-02,  4.6506e-02],\n                         [ 6.5765e-04,  1.8568e-02,  2.5861e-03],\n                         [ 1.8371e-02, -1.6226e-02, -3.8801e-02]],\n               \n                        [[-2.3650e-02,  2.1097e-02,  2.2383e-02],\n                         [ 9.3560e-03,  1.2789e-02, -2.7971e-02],\n                         [-3.0632e-02, -3.6419e-02, -4.3881e-02]],\n               \n                        [[ 4.3862e-03,  7.5597e-03, -3.5672e-02],\n                         [-1.8011e-02,  3.7026e-02, -1.6140e-02],\n                         [-2.0029e-02, -1.1916e-02,  2.5721e-03]],\n               \n                        ...,\n               \n                        [[-3.9331e-02, -3.0484e-02, -1.1937e-02],\n                         [-4.6809e-02, -5.7017e-02,  6.3560e-02],\n                         [-4.2948e-03, -8.9173e-03,  4.6761e-02]],\n               \n                        [[ 2.4020e-02,  2.3197e-02,  7.9270e-03],\n                         [ 1.1556e-02,  3.1076e-02, -3.9530e-02],\n                         [ 6.7976e-02,  2.7610e-02, -9.3305e-03]],\n               \n                        [[-5.2455e-02, -3.8656e-02, -5.8238e-02],\n                         [-3.9340e-02, -3.0020e-02, -2.4194e-02],\n                         [-6.6006e-02, -7.2968e-02, -7.4877e-03]]]])),\n              ('backbone.models.0.model.layer3.5.bn2.weight',\n               tensor([0.8606, 0.9488, 0.9865, 0.8144, 0.9141, 0.9730, 0.9470, 0.7425, 0.9229,\n                       0.9444, 1.0459, 1.1179, 1.0399, 0.8922, 1.0908, 0.8137, 1.0533, 0.8536,\n                       1.1695, 0.9904, 0.9028, 1.2295, 1.6561, 0.8088, 0.8301, 0.8703, 1.0895,\n                       0.8307, 0.9774, 0.8339, 0.7905, 0.7800, 0.8422, 0.9802, 0.7186, 0.8630,\n                       0.8476, 1.0806, 0.9845, 1.1709, 0.7601, 0.8121, 0.8537, 1.2291, 1.0341,\n                       0.8759, 0.8011, 0.7861, 1.0482, 0.7966, 0.7957, 0.8958, 0.9746, 0.7909,\n                       0.8487, 1.1976, 1.1574, 0.8987, 1.0923, 0.8057, 1.5395, 0.9410, 0.8687,\n                       1.2094, 1.0341, 0.7667, 0.9078, 0.8079, 1.1161, 0.8125, 0.8485, 0.9457,\n                       0.8332, 0.9941, 0.7945, 0.8714, 0.7661, 0.9159, 1.4031, 0.9326, 0.9895,\n                       0.8849, 1.0347, 0.9431, 0.7908, 1.0857, 1.0530, 1.0272, 0.9740, 0.9155,\n                       1.4405, 0.9302, 0.8935, 0.7537, 0.9272, 1.0284, 0.6809, 0.8205, 1.0399,\n                       0.8745, 0.8387, 0.7838, 0.9227, 0.7819, 0.7401, 0.7728, 1.0448, 0.8962,\n                       0.9000, 1.2119, 1.0306, 0.7724, 0.8059, 0.9406, 0.8524, 0.8636, 0.8524,\n                       0.7917, 0.9933, 0.8573, 0.9458, 1.0075, 0.8967, 0.8250, 0.7838, 1.0021,\n                       0.9633, 1.1031, 0.9271, 1.0517, 0.9648, 0.8947, 0.8116, 0.7937, 1.0193,\n                       0.9291, 0.9063, 0.8953, 0.7780, 0.7500, 0.9610, 0.9595, 0.8918, 1.0836,\n                       0.9692, 0.9008, 0.8955, 0.9816, 0.9181, 0.9782, 0.8282, 1.0759, 0.8316,\n                       0.8248, 0.9226, 0.8292, 0.8471, 0.7652, 0.8845, 0.7974, 0.9203, 0.8217,\n                       0.9821, 0.7553, 0.7687, 0.7838, 0.8249, 0.7748, 0.7963, 0.9447, 0.9562,\n                       0.7901, 0.8297, 0.6963, 0.8845, 0.8890, 1.1707, 0.8113, 0.8710, 0.9702,\n                       0.9174, 1.0110, 0.8695, 0.8846, 0.9553, 1.3237, 0.7837, 0.8815, 0.7737,\n                       0.9517, 0.7760, 0.9891, 1.1148, 1.0222, 0.9395, 0.7505, 0.7011, 0.9656,\n                       0.8404, 1.0152, 0.7879, 0.8248, 0.8590, 0.8440, 0.9757, 1.0906, 0.9796,\n                       0.9506, 0.9702, 1.0338, 0.7778, 0.8947, 0.8127, 0.9671, 0.8948, 0.7991,\n                       1.0081, 0.8291, 0.9090, 1.0186, 0.7756, 0.7760, 0.9788, 0.8645, 1.0532,\n                       0.9866, 0.9353, 1.1488, 1.0835, 0.8853, 0.8738, 1.0148, 0.9304, 0.9575,\n                       0.7253, 0.9118, 0.9239, 1.2129, 1.2081, 0.8488, 1.0496, 1.0333, 0.8579,\n                       0.8464, 0.8626, 1.0409, 0.9875, 1.2532, 0.9200, 0.9758, 0.8157, 0.8336,\n                       1.1094, 1.1711, 0.7922, 0.9613])),\n              ('backbone.models.0.model.layer3.5.bn2.bias',\n               tensor([-0.2471, -0.6598, -0.5140,  0.1569, -0.5100, -0.6408, -0.2894,  0.0722,\n                       -0.3396, -0.5669, -0.7043, -0.9400, -0.6847, -0.4576, -0.7396, -0.1772,\n                       -0.6208, -0.1650, -1.4718, -0.6903, -0.4832, -1.0546, -1.3943, -0.2320,\n                       -0.2040, -0.3562, -0.7326, -0.0386, -0.4221, -0.3158,  0.0901,  0.0603,\n                       -0.4107, -0.5137,  0.0126, -0.1632, -0.4561, -0.6749, -0.6264, -1.3463,\n                        0.1371, -0.1973, -0.3322, -1.2762, -0.5901, -0.2243,  0.0635, -0.2143,\n                       -0.7598,  0.1060,  0.1877, -0.2066, -0.4833, -0.0061, -0.2213, -0.7584,\n                       -0.7769, -0.3383, -0.8253, -0.1869, -1.0235, -0.2894, -0.4765, -0.9492,\n                       -0.4948, -0.0967, -0.5793, -0.0810, -1.0214, -0.1977, -0.1648, -0.5765,\n                       -0.1896, -0.5008,  0.0286, -0.6067, -0.1575, -0.5387, -0.5793, -0.5837,\n                       -0.5551, -0.4253, -0.8488, -0.3841, -0.2026, -0.7567, -0.7512, -1.0063,\n                       -0.3376, -0.5649, -0.8232, -0.4498, -0.2317, -0.0125, -0.5577, -0.3316,\n                        0.3350, -0.2971, -1.0523, -0.4377, -0.3343,  0.0761, -0.3425, -0.0048,\n                        0.1537,  0.2844, -0.6800, -0.3348, -0.4663, -1.0256, -0.6515, -0.3030,\n                       -0.1720, -0.5226, -0.2545, -0.1691, -0.4029,  0.0310, -0.5514, -0.0952,\n                       -0.5783, -0.3189, -0.3490, -0.2216, -0.0987, -0.5335, -0.5595, -0.7524,\n                       -0.6712, -0.7260, -0.5453, -0.5401, -0.0563, -0.0668, -0.8029, -0.1139,\n                       -0.5035, -0.3681,  0.0178, -0.1516, -0.5588, -0.4478, -0.2231, -0.6957,\n                       -0.3901, -0.4385, -0.3720, -0.2058, -0.5374, -0.5042, -0.0194, -0.6236,\n                       -0.2375, -0.1772, -0.3753, -0.2848, -0.1654,  0.0419, -0.0795, -0.3198,\n                       -0.1611, -0.5288, -0.5016,  0.0915, -0.0837, -0.0929, -0.1792, -0.0577,\n                       -0.0945, -0.4652, -0.1679, -0.1498, -0.4855,  0.2105, -0.3709, -0.6397,\n                       -0.6401,  0.0268, -0.3482, -0.4471, -0.6022, -0.7799, -0.1996, -0.3134,\n                       -0.5624, -0.6976,  0.0980, -0.3047,  0.0570, -0.4592,  0.1995, -0.4855,\n                       -0.6050, -0.8193, -0.7223,  0.2311,  0.3293, -0.3015, -0.2561, -0.8784,\n                       -0.2517, -0.2900, -0.2637, -0.3213, -0.3313, -0.7181, -0.8101, -0.5636,\n                       -0.5107, -0.7366, -0.0405, -0.5370, -0.1245, -0.5876, -0.5697, -0.2476,\n                       -0.6458, -0.1096, -0.4430, -0.7047, -0.0362, -0.0701, -0.5473, -0.2234,\n                       -0.4480, -0.4343, -0.4400, -0.8332, -0.2325, -0.2239, -0.3254, -0.5246,\n                       -0.2632, -0.4535,  0.6136, -0.3908, -0.4937, -0.7543, -0.8652, -0.3447,\n                       -0.7085, -0.6178, -0.2161, -0.1284, -0.4178, -0.5895, -0.6228, -0.7301,\n                       -0.6318, -0.7030, -0.2443, -0.1313, -0.7213, -0.5463,  0.0171, -0.5705])),\n              ('backbone.models.0.model.layer3.5.bn2.running_mean',\n               tensor([-0.2137, -0.3408, -0.1700, -0.8429, -0.5771, -0.5998, -0.5990, -0.7056,\n                       -0.5629, -0.5338, -0.3782, -0.4715, -0.4733, -0.6092, -0.2152, -0.2522,\n                       -0.2418, -0.5729,  0.3337, -0.4981, -0.3551, -0.7191, -0.7249, -0.2081,\n                       -0.6751, -0.2444, -0.5023, -0.3696, -0.5880, -0.4354, -1.7024, -0.6843,\n                       -0.4371, -0.5394, -0.3386, -0.7568, -0.2554, -0.6774, -0.5682, -0.6038,\n                       -0.7077, -0.4116, -0.5892, -0.7705, -0.6155, -0.2501, -0.6877, -0.8348,\n                       -0.7190, -0.5511, -0.6473, -0.2269, -0.3229, -0.4539, -0.4816, -1.0478,\n                       -0.4929, -0.5990, -0.6712, -0.0709, -0.8479, -0.4629, -0.2323, -0.4521,\n                       -0.4708, -0.3147, -0.6004, -0.5138, -0.1484, -0.4158, -0.5325, -0.5287,\n                       -0.5781, -0.5131, -0.6209, -0.2289, -0.0460, -0.1749, -0.4747, -0.2339,\n                       -0.3860, -0.4001, -0.5056, -0.6412, -0.2875, -0.5264, -0.4703, -0.7334,\n                       -0.5656, -0.2675,  3.3939, -0.4867, -0.3098, -0.7115, -0.4202, -0.8164,\n                       -0.4105, -0.3277, -0.5406, -0.1596, -0.3304, -0.5955, -0.3875, -0.6717,\n                       -0.4033, -0.4003, -0.4948, -0.7837, -0.4554,  1.2110, -0.4952, -0.3409,\n                       -0.6149,  0.1695, -0.5954, -0.7657, -0.2352, -0.6851, -1.0880, -0.9619,\n                       -0.3389, -0.6879, -0.7060, -0.2071, -0.6398, -0.6122, -0.5012, -0.8112,\n                       -0.2458, -0.4233,  0.0364,  0.0101, -0.5797, -0.5932, -0.3260, -0.3941,\n                       -0.5541, -0.6558, -0.4893, -0.4661, -0.4961, -0.8263, -0.5696, -0.6684,\n                       -0.6155, -0.3004, -0.3784, -0.6538, -0.1878, -0.3678, -0.4517, -0.7066,\n                       -0.2140, -0.1071, -0.7142, -0.5581, -0.0557, -0.6604,  0.2562, -0.3554,\n                       -0.8554, -0.4270, -0.5942, -0.7697, -0.4739, -0.5342, -0.2529, -0.6207,\n                       -0.2455, -0.4840, -0.8225, -0.4142, -0.3165, -0.4685, -0.5647,  0.0074,\n                       -0.4877, -0.5406, -0.2655, -0.2481, -0.4918, -0.7132, -0.6472, -0.5274,\n                       -0.5227,  0.1342, -0.3835, -0.6637, -0.4228, -0.5625, -0.5746, -0.5219,\n                       -0.7486, -0.3624, -0.1937, -0.3519, -0.9959, -0.4264, -0.6019, -0.5886,\n                       -0.3321, -0.5266, -0.4233, -0.5386, -0.5112, -0.4645, -0.4491, -0.2505,\n                       -0.6049, -0.3811, -0.1746, -0.6470, -0.5193, -0.4320, -0.5815, -0.5458,\n                       -0.5927, -0.9441, -0.4562, -0.7042, -0.4447, -0.2828, -0.5545, -0.4012,\n                       -0.0317, -0.4200, -0.4062, -0.8217,  1.5878, -0.4679,  0.0738, -0.5352,\n                       -0.5712, -0.4724, -0.4550, -0.7429, -0.0907, -0.7016, -0.7788, -0.5590,\n                       -0.4178, -0.6720, -0.3081, -0.8847, -0.4289, -0.9021, -0.4906,  2.0337,\n                       -0.2126, -0.3614, -0.3811, -0.6311, -0.7352,  1.4874, -0.5145, -0.3509])),\n              ('backbone.models.0.model.layer3.5.bn2.running_var',\n               tensor([0.9355, 0.6017, 1.2365, 1.2748, 0.8834, 0.7810, 1.1025, 0.9798, 1.0988,\n                       0.7714, 0.9318, 0.9913, 0.8084, 0.9814, 0.8178, 0.7733, 0.9142, 1.0440,\n                       0.6629, 0.7309, 0.9732, 0.7271, 1.3079, 0.9081, 0.9705, 0.8248, 0.9345,\n                       1.4345, 1.0966, 0.7910, 0.8940, 1.0374, 0.9485, 0.9167, 0.7304, 1.1192,\n                       0.5129, 0.9929, 0.9765, 0.7786, 1.1686, 0.8650, 0.7418, 0.6900, 0.8770,\n                       1.3676, 1.1879, 0.9590, 1.0093, 1.1851, 1.2011, 0.9467, 0.7582, 1.1923,\n                       0.9628, 0.9925, 0.9767, 0.9295, 0.7534, 0.7456, 1.0451, 1.3264, 0.6532,\n                       1.0707, 0.7998, 0.9694, 0.7138, 1.0612, 0.4991, 0.8416, 0.9934, 0.6248,\n                       1.0380, 1.3383, 1.1063, 0.5217, 0.7398, 0.6588, 1.5012, 0.7735, 1.0096,\n                       0.9160, 0.7438, 0.9972, 0.8099, 0.7628, 1.1170, 0.6515, 1.5026, 1.0111,\n                       2.6525, 0.6613, 1.5112, 1.0447, 0.6271, 1.6121, 1.0233, 0.7186, 0.7260,\n                       1.0725, 0.7664, 0.9849, 0.7216, 1.0295, 1.0593, 1.1092, 0.9440, 0.8057,\n                       0.9204, 1.3688, 0.6517, 0.5903, 0.9778, 0.7828, 1.1905, 0.9039, 0.9834,\n                       1.0985, 0.8420, 1.2942, 1.0205, 1.3796, 0.4691, 0.8572, 0.8172, 0.9736,\n                       0.8687, 0.8616, 0.5942, 0.8705, 0.9284, 0.6699, 1.0631, 1.0708, 0.7796,\n                       1.2119, 0.7001, 0.9171, 0.9438, 0.7885, 0.7879, 0.6936, 0.9525, 0.8833,\n                       0.8165, 0.5829, 0.9377, 1.6458, 0.6623, 1.0007, 0.9990, 0.9521, 1.0745,\n                       0.6773, 1.1614, 0.7265, 1.1215, 1.0127, 1.2860, 0.6857, 1.4794, 0.6142,\n                       1.2087, 1.0152, 0.9950, 1.0078, 1.0867, 0.9795, 1.0773, 1.1363, 1.3542,\n                       0.7742, 0.6130, 0.8542, 1.0333, 0.7139, 1.2396, 1.1324, 1.0281, 0.8969,\n                       0.6683, 0.6455, 0.9621, 0.9303, 0.8980, 1.4974, 1.1400, 1.0097, 1.3055,\n                       0.9422, 1.3168, 0.9683, 0.9958, 0.6235, 0.7846, 1.1951, 0.9210, 1.3067,\n                       0.8118, 0.7602, 0.9014, 0.7871, 1.1296, 0.6940, 0.8708, 1.2742, 0.6713,\n                       0.6466, 0.9901, 1.2076, 1.0186, 0.7444, 0.9346, 0.7883, 0.8060, 0.8076,\n                       0.6623, 0.9688, 0.9582, 0.8822, 0.9559, 0.9336, 0.7187, 1.0729, 1.8343,\n                       1.0700, 0.8694, 1.0555, 0.8791, 1.1194, 0.9467, 0.6213, 1.1613, 0.9683,\n                       1.0737, 1.0587, 0.7718, 0.9579, 0.6693, 0.5608, 0.7819, 1.0651, 0.8920,\n                       1.0430, 0.7208, 1.0948, 0.5974, 2.0125, 0.5469, 0.5973, 0.8435, 1.0193,\n                       1.0157, 1.9234, 1.0176, 0.7450])),\n              ('backbone.models.0.model.layer3.5.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer3.5.conv3.weight',\n               tensor([[[[-0.1140]],\n               \n                        [[ 0.0155]],\n               \n                        [[-0.0220]],\n               \n                        ...,\n               \n                        [[ 0.0128]],\n               \n                        [[-0.0371]],\n               \n                        [[-0.0654]]],\n               \n               \n                       [[[-0.0480]],\n               \n                        [[ 0.0123]],\n               \n                        [[-0.0742]],\n               \n                        ...,\n               \n                        [[-0.0152]],\n               \n                        [[ 0.0465]],\n               \n                        [[-0.0057]]],\n               \n               \n                       [[[-0.0366]],\n               \n                        [[ 0.0575]],\n               \n                        [[-0.0401]],\n               \n                        ...,\n               \n                        [[-0.0014]],\n               \n                        [[ 0.0758]],\n               \n                        [[-0.0318]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0161]],\n               \n                        [[-0.0032]],\n               \n                        [[-0.0302]],\n               \n                        ...,\n               \n                        [[-0.0004]],\n               \n                        [[-0.0015]],\n               \n                        [[ 0.0122]]],\n               \n               \n                       [[[-0.1005]],\n               \n                        [[-0.0438]],\n               \n                        [[ 0.0268]],\n               \n                        ...,\n               \n                        [[-0.0739]],\n               \n                        [[ 0.0055]],\n               \n                        [[ 0.0637]]],\n               \n               \n                       [[[ 0.0265]],\n               \n                        [[-0.0872]],\n               \n                        [[-0.0170]],\n               \n                        ...,\n               \n                        [[ 0.0127]],\n               \n                        [[-0.0119]],\n               \n                        [[ 0.0143]]]])),\n              ('backbone.models.0.model.layer3.5.bn3.weight',\n               tensor([ 0.4098, -0.7637, -0.2654,  ..., -0.0934,  0.7733,  0.1999])),\n              ('backbone.models.0.model.layer3.5.bn3.bias',\n               tensor([-0.2451, -0.6047,  0.0157,  ...,  0.0928, -0.6238,  0.1591])),\n              ('backbone.models.0.model.layer3.5.bn3.running_mean',\n               tensor([ 0.0639, -0.0139, -0.1175,  ..., -0.0272, -0.3131,  0.1004])),\n              ('backbone.models.0.model.layer3.5.bn3.running_var',\n               tensor([0.1533, 0.2890, 0.0831,  ..., 0.0349, 0.2678, 0.0576])),\n              ('backbone.models.0.model.layer3.5.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer4.0.conv1.weight',\n               tensor([[[[ 0.0548]],\n               \n                        [[-0.0708]],\n               \n                        [[ 0.0668]],\n               \n                        ...,\n               \n                        [[-0.0891]],\n               \n                        [[-0.0488]],\n               \n                        [[-0.0127]]],\n               \n               \n                       [[[-0.1477]],\n               \n                        [[-0.0067]],\n               \n                        [[-0.0504]],\n               \n                        ...,\n               \n                        [[-0.0219]],\n               \n                        [[-0.0123]],\n               \n                        [[-0.0005]]],\n               \n               \n                       [[[ 0.0328]],\n               \n                        [[-0.0668]],\n               \n                        [[ 0.0344]],\n               \n                        ...,\n               \n                        [[-0.0325]],\n               \n                        [[-0.1122]],\n               \n                        [[-0.0118]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0250]],\n               \n                        [[ 0.0329]],\n               \n                        [[-0.0106]],\n               \n                        ...,\n               \n                        [[-0.0542]],\n               \n                        [[-0.0116]],\n               \n                        [[-0.0766]]],\n               \n               \n                       [[[ 0.0055]],\n               \n                        [[-0.0508]],\n               \n                        [[-0.0302]],\n               \n                        ...,\n               \n                        [[ 0.0060]],\n               \n                        [[-0.0243]],\n               \n                        [[-0.0076]]],\n               \n               \n                       [[[-0.0870]],\n               \n                        [[-0.0311]],\n               \n                        [[-0.0734]],\n               \n                        ...,\n               \n                        [[-0.0326]],\n               \n                        [[-0.0870]],\n               \n                        [[ 0.0364]]]])),\n              ('backbone.models.0.model.layer4.0.bn1.weight',\n               tensor([0.7759, 0.9659, 0.8460, 0.8817, 0.7896, 0.7436, 0.7518, 0.9123, 0.9239,\n                       0.8531, 0.8391, 0.7583, 0.9136, 0.7840, 0.7871, 0.7023, 0.6792, 0.7677,\n                       0.8260, 0.7159, 0.8045, 0.7673, 0.8951, 0.6512, 0.8253, 0.6354, 0.6732,\n                       0.7750, 0.8449, 0.6958, 0.7147, 0.7457, 0.7464, 0.8690, 1.0233, 0.8580,\n                       0.7403, 0.7600, 0.8241, 0.8374, 0.7420, 0.7193, 0.7255, 0.8069, 0.7639,\n                       0.8097, 0.7417, 0.8611, 0.9199, 0.8104, 0.8149, 0.6835, 0.8368, 0.8216,\n                       0.6476, 0.7963, 0.7685, 0.8959, 0.7689, 0.8185, 0.9888, 0.8706, 0.8429,\n                       0.8410, 0.8600, 0.9247, 0.8521, 0.7627, 0.9386, 0.9287, 0.7285, 0.6889,\n                       0.7957, 0.8249, 0.6608, 0.7587, 0.8180, 0.7233, 0.7878, 0.9036, 0.7369,\n                       0.7042, 0.8452, 0.7770, 0.7960, 0.9304, 0.9627, 0.8279, 1.0060, 0.7451,\n                       0.8442, 0.7138, 0.7210, 0.7707, 0.8421, 0.7988, 0.8498, 0.7868, 0.8915,\n                       0.7527, 0.6390, 0.7279, 0.8380, 0.7673, 0.8671, 0.7058, 0.5131, 0.7610,\n                       0.8819, 0.7528, 0.7116, 0.7133, 0.7816, 0.7731, 0.9263, 0.7713, 0.8504,\n                       0.6997, 0.7218, 0.8790, 0.8107, 0.8854, 0.7747, 0.7353, 0.8825, 0.7581,\n                       0.7871, 0.7149, 0.7704, 0.8527, 0.6853, 0.8080, 0.7530, 0.6894, 0.7184,\n                       0.7195, 0.8254, 0.7540, 0.6974, 0.8126, 0.9052, 0.7075, 0.9346, 0.7529,\n                       0.8804, 0.7935, 0.8108, 0.9325, 0.7623, 0.8956, 0.8143, 0.7710, 0.7292,\n                       0.7419, 0.7735, 0.8787, 0.7667, 0.7144, 0.8172, 0.7353, 0.7674, 0.6702,\n                       0.8674, 0.8252, 0.7484, 0.8048, 0.7099, 0.8288, 0.7736, 0.8003, 0.7288,\n                       0.9566, 0.7027, 0.6936, 0.7770, 0.8377, 0.7503, 0.8187, 0.7945, 0.8613,\n                       0.7555, 0.7174, 0.7262, 0.7150, 0.7733, 0.8401, 0.7858, 0.8785, 0.8028,\n                       0.7952, 0.8719, 0.7096, 0.8133, 0.7431, 0.8261, 0.6949, 0.9012, 0.7658,\n                       0.8251, 0.6982, 0.7376, 0.7982, 0.8148, 0.7307, 0.7991, 0.8247, 0.7757,\n                       0.9832, 0.8075, 0.9865, 0.8275, 0.7390, 0.8458, 0.7715, 0.7347, 0.7380,\n                       0.8589, 0.8041, 0.7769, 0.7527, 0.8005, 0.8761, 0.7625, 0.8156, 0.8608,\n                       0.6400, 0.9116, 0.7530, 0.9222, 0.7501, 0.8514, 0.7464, 0.9434, 0.8996,\n                       0.6516, 0.8396, 0.7230, 0.7105, 0.7630, 0.7592, 0.7361, 0.8717, 0.6898,\n                       0.8215, 0.8289, 0.7369, 0.6567, 0.8052, 0.8729, 0.8206, 0.7376, 0.7364,\n                       0.8466, 0.8633, 0.8440, 0.7038, 0.8120, 0.7748, 0.7316, 0.7732, 0.9338,\n                       0.6703, 0.9152, 0.7100, 0.7227, 0.7647, 0.9491, 0.7561, 0.8713, 0.7698,\n                       0.7711, 0.7940, 0.7806, 1.0125, 0.6319, 0.6901, 0.7415, 0.7370, 0.7382,\n                       0.8870, 0.7321, 0.8567, 0.9315, 0.7794, 0.8830, 0.7179, 0.7536, 0.8619,\n                       0.8642, 0.7541, 0.7082, 0.8153, 0.7872, 0.8139, 0.7820, 0.8173, 0.7844,\n                       0.7928, 0.7693, 0.7698, 0.8017, 0.7829, 0.7415, 0.6221, 0.6905, 0.7063,\n                       0.7342, 0.7904, 0.9042, 0.7356, 0.7739, 0.8859, 0.8505, 0.7794, 0.8129,\n                       0.8729, 0.7455, 0.8583, 0.8094, 0.6636, 0.9237, 0.8945, 0.7548, 0.7551,\n                       0.8422, 0.8891, 0.7088, 0.7606, 0.8303, 0.7818, 0.7761, 0.7602, 0.9375,\n                       0.9216, 0.8975, 0.7914, 0.7932, 0.8431, 0.7030, 0.8112, 0.6678, 0.7230,\n                       0.6852, 0.7318, 0.7442, 0.8272, 0.8941, 0.9208, 0.7208, 0.8812, 0.7759,\n                       0.7894, 0.8342, 0.8063, 0.8575, 0.5103, 0.7009, 0.8130, 0.8619, 0.7293,\n                       0.8147, 0.9828, 0.6967, 0.7558, 0.6643, 0.7022, 0.8568, 0.7485, 0.8583,\n                       0.7575, 0.8388, 0.8017, 0.7938, 0.7489, 0.7186, 0.7064, 0.8232, 0.8380,\n                       0.8056, 0.7489, 0.7087, 0.7947, 0.9047, 0.8141, 0.8452, 0.8320, 0.8506,\n                       0.7761, 0.9158, 0.8195, 0.7352, 0.8507, 0.7638, 0.3250, 0.8750, 0.7299,\n                       0.8017, 0.8541, 0.7942, 0.7083, 0.8010, 0.8582, 0.7645, 1.0001, 0.7360,\n                       0.7127, 0.6873, 0.8588, 0.7427, 0.7539, 0.7999, 0.8360, 0.9030, 0.8746,\n                       0.8201, 0.7132, 0.8734, 0.9817, 0.8091, 0.8366, 0.7622, 0.7991, 0.7950,\n                       0.8169, 0.8385, 0.6828, 0.8437, 0.8362, 0.7645, 0.7868, 0.7417, 0.8248,\n                       0.8692, 0.6831, 0.9913, 0.7556, 0.7931, 0.8961, 0.7339, 0.8729, 0.8832,\n                       0.8464, 0.6917, 0.8787, 0.8279, 0.9201, 0.9339, 0.8150, 0.8183, 0.8439,\n                       1.0271, 1.0714, 0.7861, 0.8736, 0.7796, 0.8774, 0.7247, 0.8302, 0.8412,\n                       0.6625, 0.7411, 0.9102, 0.6986, 0.6967, 0.6809, 0.7528, 0.7665, 0.8240,\n                       0.7741, 1.0499, 0.7733, 0.7144, 0.7152, 0.8610, 0.8243, 0.7520, 0.7909,\n                       0.9674, 0.8397, 0.7255, 0.8481, 0.8007, 0.9215, 0.6950, 0.6489, 0.8178,\n                       0.6960, 0.8212, 0.8388, 0.8355, 0.8968, 0.7809, 0.8647, 0.7606, 0.7939,\n                       0.8406, 0.8092, 0.7727, 0.6594, 0.7359, 0.8292, 0.8856, 0.9958, 0.8099,\n                       0.7167, 0.7665, 0.9287, 0.9434, 0.9048, 0.7679, 0.9259, 0.7959])),\n              ('backbone.models.0.model.layer4.0.bn1.bias',\n               tensor([-0.6634, -1.1819, -0.9444, -1.0862, -0.8999, -0.5211, -0.7678, -1.1601,\n                       -1.1958, -1.2001, -0.9814, -0.6869, -1.1788, -0.7829, -0.8315, -0.5778,\n                       -0.4073, -0.8623, -0.8272, -0.5783, -0.7775, -0.6932, -1.2274, -0.4691,\n                       -0.8446, -0.2880, -0.4754, -0.8531, -1.0607, -0.6615, -0.6575, -0.6810,\n                       -0.7573, -1.1630, -1.4497, -1.0053, -0.5681, -0.7909, -1.0155, -0.9589,\n                       -0.6361, -0.6639, -0.6672, -0.9083, -0.7695, -0.7754, -0.6877, -1.0594,\n                       -1.1455, -0.8252, -0.9767, -0.6311, -0.8559, -0.8896, -0.3336, -0.8982,\n                       -0.7274, -1.0614, -0.7908, -0.9049, -0.9598, -1.1767, -0.8895, -0.9663,\n                       -1.0927, -1.4987, -1.0489, -0.8317, -1.3501, -1.1023, -0.8047, -0.6190,\n                       -0.8548, -0.8598, -0.4816, -0.6534, -0.9984, -0.6641, -0.8337, -1.0824,\n                       -0.5054, -0.6078, -1.2420, -0.9032, -0.7560, -1.2479, -1.2352, -0.7912,\n                       -1.3411, -0.7500, -0.9869, -0.4772, -0.5572, -0.6721, -0.8450, -0.9952,\n                       -0.9354, -0.7412, -1.0948, -0.7054, -0.5510, -0.6598, -0.9893, -0.8046,\n                       -1.1571, -0.4927, -0.2618, -0.7745, -0.9196, -0.7098, -0.5936, -0.6865,\n                       -0.6025, -0.8519, -1.4602, -0.7512, -0.9788, -0.6325, -0.5862, -0.9376,\n                       -0.7887, -1.0000, -0.8701, -0.5147, -1.1455, -0.6533, -0.8491, -0.4526,\n                       -0.7341, -1.0939, -0.4758, -1.0152, -0.8181, -0.5888, -0.5531, -0.5115,\n                       -1.0016, -0.7192, -0.5459, -0.9475, -1.2555, -0.7220, -0.9741, -0.7607,\n                       -0.8555, -0.9193, -0.9206, -1.0142, -0.7988, -1.1080, -0.7198, -0.6981,\n                       -0.6663, -0.7227, -0.9377, -0.7865, -0.8454, -0.6586, -1.0116, -0.5980,\n                       -0.6576, -0.4386, -1.0276, -1.0060, -0.7737, -0.6940, -0.6141, -0.8793,\n                       -0.7178, -0.7181, -0.5529, -1.1280, -0.4754, -0.5911, -0.7506, -0.8436,\n                       -0.5107, -0.7366, -0.8892, -1.1173, -0.6515, -0.5511, -0.6568, -0.5828,\n                       -0.8030, -1.1408, -0.7735, -1.0306, -0.7500, -0.8405, -1.0881, -0.5321,\n                       -0.9536, -0.6421, -0.9463, -0.5242, -1.1305, -0.6867, -0.8766, -0.5765,\n                       -0.6433, -0.7314, -0.9074, -0.6157, -0.8795, -0.8694, -0.8057, -1.4884,\n                       -0.8943, -1.4564, -1.0121, -0.7183, -0.9584, -0.8510, -0.6958, -0.6501,\n                       -0.8220, -0.9638, -0.7272, -0.6864, -0.7762, -1.1538, -0.7304, -0.9474,\n                       -0.9414, -0.4179, -1.1004, -0.7639, -1.0010, -0.7213, -1.0820, -0.5803,\n                       -0.9208, -1.1018, -0.4518, -1.0794, -0.6628, -0.7406, -0.8358, -0.5257,\n                       -0.7795, -1.0357, -0.4186, -0.9272, -0.8857, -0.7632, -0.5718, -0.6268,\n                       -1.1190, -0.9009, -0.6725, -0.6445, -1.0182, -0.8708, -0.9037, -0.5898,\n                       -0.8903, -0.8531, -0.5430, -0.6906, -1.1713, -0.5830, -1.0994, -0.6022,\n                       -0.6012, -0.5345, -1.3310, -0.7998, -1.0134, -0.7649, -0.7790, -0.8919,\n                       -0.8308, -1.3863, -0.3792, -0.5821, -0.6608, -0.7341, -0.7418, -1.1862,\n                       -0.5705, -0.9102, -1.1229, -0.6485, -1.0580, -0.5175, -0.8727, -0.9552,\n                       -0.9066, -0.7643, -0.6029, -1.0363, -0.8475, -1.0018, -0.5563, -0.9040,\n                       -0.8034, -0.8748, -0.8569, -0.9209, -0.8770, -0.6768, -0.6407, -0.4616,\n                       -0.5472, -0.5949, -0.6949, -0.8880,  0.2090, -0.6698, -0.7038, -1.0282,\n                       -0.9066, -0.8031, -0.6735, -1.0161, -0.5299, -1.0820, -0.7855, -0.4265,\n                       -1.2439, -1.0409, -0.6682, -0.6431, -0.8864, -0.9021, -0.6481, -0.7475,\n                       -0.9530, -0.9037, -0.7709, -0.7960, -1.2804, -1.3050, -0.9665, -0.7060,\n                       -0.8222, -1.0092, -0.5266, -0.8255, -0.5230, -0.6995, -0.4873, -0.6671,\n                       -0.7727, -0.9374, -1.0355, -1.0939, -0.7310, -0.7601, -0.6028, -0.9875,\n                       -0.8991, -0.8384, -1.0308, -0.1865, -0.6788, -0.8735, -1.2627, -0.6092,\n                       -0.8317, -1.1351, -0.6071, -0.8663, -0.5826, -0.4834, -1.0980, -0.6773,\n                       -0.1508, -0.6228, -0.6676, -0.9055, -0.7965, -0.7467, -0.6562, -0.5047,\n                       -1.0255, -0.7679, -0.7796, -0.7334, -0.5350, -0.8268, -1.0787, -0.7930,\n                       -0.9978, -0.9557, -1.0513, -0.7724, -1.0329, -0.8977, -0.8767, -1.0591,\n                       -0.7942,  0.1291, -1.0315, -0.6489, -0.7696, -1.0541, -0.6549, -0.6032,\n                       -0.8563, -0.8635, -0.7078, -1.0578, -0.5455, -0.6097, -0.5883, -0.8743,\n                       -0.5976, -0.6610, -0.8031, -0.9352, -1.1343, -1.1705, -0.9224, -0.6090,\n                        0.4991, -1.4415, -0.7943, -0.9326, -0.6651, -0.9748, -0.7285, -0.8809,\n                       -0.6646, -0.6392, -1.1163, -0.7653, -0.7137, -0.8699, -0.5268, -1.3804,\n                       -0.8333, -0.4601, -1.3050, -0.7414, -0.9687, -1.0679, -0.7746, -1.0747,\n                       -1.1362, -0.7644, -0.5051, -1.1127, -0.7346, -1.1858, -1.2313, -0.7941,\n                       -0.8964, -0.6214, -1.2062, -1.4584, -0.8695, -1.0897, -0.8364, -0.9777,\n                       -0.6161, -0.9445, -1.0759, -0.4530, -0.7181, -1.2554, -0.4548, -0.6298,\n                       -0.5109, -0.7006, -0.7113, -0.8097, -0.7080, -1.4003, -0.7477, -0.6160,\n                       -0.6183, -1.0326, -0.7871, -0.5823, -0.8247, -1.3707, -0.9229, -0.4917,\n                       -1.2025, -0.8287, -1.0214, -0.5547, -0.4434, -1.0687, -0.5855, -0.6666,\n                       -1.2342, -1.0863, -0.9576, -0.8859, -1.1181, -0.8219, -0.9076, -0.9447,\n                       -0.8865, -0.7258, -0.5565, -0.8227, -0.6422, -1.4183, -0.9433, -0.8952,\n                       -0.5067, -0.8299, -1.2149, -1.4510, -0.9661, -0.7427, -1.2065, -0.8616])),\n              ('backbone.models.0.model.layer4.0.bn1.running_mean',\n               tensor([-2.7250, -1.7959, -2.2946, -1.2851, -1.8691, -2.8658, -3.3559, -3.7145,\n                       -2.8979, -2.6207, -2.5511, -2.1853, -1.9692, -2.3246, -2.4735, -1.7864,\n                       -1.6942, -3.0694, -2.9565, -1.5551, -3.2116, -2.1186, -1.3858, -1.6207,\n                       -1.3325, -1.1798, -1.6622, -3.1649, -2.0131, -1.9080, -1.5395, -2.5039,\n                       -2.7266, -2.1412, -0.9478, -2.0978, -1.6591, -1.4390, -2.2914, -1.3578,\n                       -0.7627, -2.0508, -1.9344, -2.2299, -3.0341, -0.5205, -2.2932, -2.0342,\n                       -1.5845, -2.6414, -1.3836, -2.2836, -1.7487, -0.8354, -1.5555, -2.5745,\n                       -1.9497, -3.6428, -2.5877, -2.3542, -4.4132, -3.4502, -1.0209, -2.4464,\n                       -1.2657, -2.1124, -2.2799, -3.4853, -2.7363, -1.2685, -2.2889, -2.8523,\n                       -3.0344, -1.4903, -2.5788, -2.4926, -2.0748, -2.3344, -0.8201, -2.1866,\n                       -2.2769, -2.3480, -2.7944, -1.2703, -3.9170, -1.9123, -2.8742, -4.5766,\n                       -3.5140, -2.5328, -2.0982, -1.3612, -1.5189, -3.1205, -1.8798, -3.2541,\n                       -2.8371, -2.0848, -2.5173, -2.1015, -2.7587, -3.4389, -2.5518, -1.4717,\n                       -3.1520, -1.5108, -0.4625, -1.9846, -3.0666, -1.4699, -1.3609, -1.5625,\n                       -2.4231, -1.4732, -2.8862, -1.5844, -1.9723, -1.2747, -2.9758, -0.9388,\n                       -2.2359, -4.4122, -1.3679, -1.3494, -2.1209, -1.5977, -1.6001, -1.1688,\n                       -1.6111, -2.1501, -2.0400,  0.1367, -3.9059, -1.7490, -1.1899, -2.0529,\n                       -1.1037, -2.6038, -1.2930, -2.0444, -2.1093, -0.9525, -4.1479, -1.8108,\n                       -2.6243, -2.0579, -1.3749, -4.7074, -2.1796, -3.5727, -2.7381, -1.1040,\n                       -2.2952, -2.4602, -2.3039, -3.6152, -2.3918, -2.3838, -2.0706, -2.1012,\n                       -3.4972, -2.7126, -1.8460, -3.2154, -2.1360, -2.9385, -2.2160, -1.3167,\n                       -2.1273, -1.2684, -2.9091, -2.1838, -1.3164, -1.9375, -1.7492, -1.2451,\n                       -1.8248, -2.3046, -5.2722, -1.2587, -3.9166, -1.3992, -1.4577, -2.7738,\n                       -1.4185, -0.5102, -1.7960, -1.7923, -1.3840, -1.6897, -2.9983, -2.5913,\n                       -2.2717, -2.4758, -3.6176, -1.3573, -2.0526, -0.6800, -2.2716, -2.0326,\n                       -2.5172, -3.0358, -2.1691, -2.1796, -0.7814, -1.4964, -2.4269, -3.7659,\n                       -2.8143, -2.6369, -2.6510, -1.8158, -0.7288, -2.6186, -2.6737, -1.4244,\n                       -2.3025, -1.4952, -1.8493, -0.6298, -2.5264, -2.2456, -1.6289, -1.6151,\n                       -2.5092, -1.3941, -3.2425, -2.4438, -1.7503, -1.8707, -2.0654, -1.0635,\n                       -3.4628, -1.3617, -1.9485, -1.5134, -2.6976, -2.4747, -3.0646, -2.1204,\n                       -2.3927, -1.3247, -1.2008, -1.9210, -1.5616, -2.7194, -2.4091, -1.5684,\n                       -2.2013, -1.4563, -1.8806, -2.3840, -1.6741, -3.0629, -1.7892, -1.4271,\n                       -1.5320, -2.1990, -2.2414, -0.5024, -2.2877, -2.9498, -1.6326, -2.2599,\n                       -2.1424, -3.7618, -3.0556, -2.6474, -1.2747, -1.9773, -0.3912, -2.8703,\n                       -2.1836, -2.4309, -1.4566, -3.0988, -1.9574, -1.9806, -1.9101, -0.4376,\n                       -1.2914, -0.5793, -2.4821, -2.2515, -2.3494, -1.8655, -2.1199, -3.0765,\n                       -1.6628, -2.4440, -2.3100, -1.3813, -2.0616, -2.1165, -3.5218, -2.3548,\n                       -2.4723, -1.7823, -2.5889, -1.6527, -0.9742, -0.5575, -2.1525, -2.0001,\n                       -1.4637, -2.7423, -1.4563, -3.4655,  8.4127, -1.8319, -2.4995, -5.8674,\n                       -2.6831, -2.4313, -2.3235, -2.7375, -1.8173, -2.4407, -2.8112, -0.7462,\n                       -2.4216, -0.8903, -1.7133, -1.8040, -0.8935, -2.2858, -1.5981, -2.2211,\n                       -2.9329, -2.6695, -2.3433, -1.7239, -2.1280, -2.3954, -1.1998, -1.3855,\n                       -2.6602, -1.7284, -2.7893, -0.9475, -2.2145, -1.9373, -1.1281, -2.4559,\n                       -1.6089, -1.0790, -0.6805, -1.3565, -2.2560, -1.8138, -2.0725, -2.5112,\n                       -1.5981, -2.7193, -1.3252, -3.2236, -1.7186, -2.1548, -2.5567, -2.6823,\n                       -2.5288, -2.7422, -2.6873, -1.9433, -1.9941, -2.0809, -3.4617, -1.2215,\n                       -6.2406, -2.4063, -4.2190, -1.4665, -2.5253, -1.3046, -1.6763, -1.2575,\n                       -2.7429, -2.7748, -2.0897, -2.0598, -1.8590, -1.5049, -2.4721, -2.9635,\n                       -1.7104, -2.1028, -2.1545, -1.8783, -4.2816, -1.6058, -2.7001, -1.4299,\n                       -2.6677, -2.2785, -3.0918, -0.9574, -1.9760, -2.4051, -1.6391, -1.6667,\n                       -3.6674, -0.9451, -2.8948, -3.0620, -1.4555, -2.1910, -1.7965, -2.2709,\n                       -2.5955, -1.9968, -3.5012, -1.7087, -1.6415, -2.9209, -1.7783, -2.1850,\n                       13.4534, -3.2173, -5.1382, -2.8578, -3.4716, -2.5134, -1.7728, -2.7266,\n                       -2.2660, -1.6302, -2.0299, -2.2980, -3.1057, -2.6534, -1.7487, -3.7082,\n                       -4.5373, -1.6699, -3.1890, -3.9861, -2.0248, -1.5844, -3.0408, -2.6565,\n                       -2.6208, -5.1624, -1.1827, -3.2465, -1.6414, -1.5357, -2.4483, -2.6541,\n                       -2.3395, -3.3314, -1.8271, -3.2035, -2.5561, -3.0980, -2.1430, -2.7224,\n                       -1.9723, -1.3866, -2.4826, -2.1716, -2.8229, -2.5115, -4.7300, -1.8593,\n                       -2.1122, -2.1317, -2.3691, -2.6693, -3.0069, -3.8727, -1.5827, -1.8183,\n                       -2.3359, -1.0305, -2.5739, -3.5469, -3.1375, -2.9792, -1.6377, -3.4467,\n                       -3.3900, -1.2392, -1.2130, -1.4961, -2.0584, -2.7070, -1.1453, -1.8105,\n                       -2.0341, -2.5267, -4.3187, -2.6943, -2.8715, -2.6534, -1.2784, -2.9784,\n                       -1.8348, -2.1511, -2.9930, -0.7905, -3.7370, -2.8151,  1.1024, -2.4204,\n                       -1.9103, -2.2378, -1.9886, -3.9446, -3.3983, -1.6254, -5.6185, -0.7612])),\n              ('backbone.models.0.model.layer4.0.bn1.running_var',\n               tensor([ 4.1361,  4.7351,  4.8056,  4.8927,  3.4940,  6.1442,  3.5524,  4.4959,\n                        3.4211,  4.0140,  3.3685,  4.3113,  3.8863,  4.5769,  4.3899,  4.4187,\n                        4.5202,  4.2909,  5.1169,  4.8331,  4.4885,  5.3955,  3.5193,  4.7988,\n                        4.5142,  6.5914,  5.1157,  3.9280,  3.7734,  4.8195,  4.9016,  4.5417,\n                        4.4155,  3.1509,  4.8930,  3.5052,  4.9924,  3.1902,  4.0141,  4.4070,\n                        4.5192,  4.8097,  4.3830,  4.4657,  4.4157,  5.4349,  4.5710,  3.6614,\n                        3.7682,  4.8237,  4.1667,  4.3033,  4.4994,  4.7827,  4.6161,  4.6928,\n                        4.7723,  3.8217,  4.5014,  3.8775,  5.1367,  3.1623,  4.3926,  4.0084,\n                        3.4568,  3.0188,  3.8560,  4.0044,  3.4258,  3.2634,  4.1438,  4.7382,\n                        4.2874,  4.5695,  5.2480,  5.3505,  3.3762,  3.9026,  4.4964,  3.6334,\n                        4.7290,  4.5080,  3.4103,  4.4655,  5.8565,  3.3119,  3.4592,  5.2431,\n                        3.6612,  3.6068,  4.1371,  5.7622,  5.8799,  5.9258,  4.6591,  3.5061,\n                        4.6693,  4.1752,  3.3587,  5.6293,  4.3939,  4.8864,  4.0094,  4.9714,\n                        3.6596,  5.4074,  3.7884,  4.5857,  4.3296,  4.0637,  5.0059,  4.5030,\n                        5.8281,  4.7188,  2.7569,  5.0643,  4.1670,  4.3944,  3.9053,  3.8386,\n                        4.3391,  5.1009,  4.7332,  5.0628,  4.0318,  4.6594,  4.1813,  6.1878,\n                        4.4019,  4.4461,  4.8708,  3.1818,  3.8979,  4.3372,  5.2706,  5.7165,\n                        4.7838,  4.2842,  4.6288,  3.6909,  2.7635,  4.2853,  6.1225,  3.7140,\n                        5.1151,  3.7560,  4.5587,  5.5372,  3.7942,  4.0552,  5.2894,  4.8278,\n                        4.1553,  4.9627,  4.1731,  4.9974,  5.0659,  4.4506,  3.8738,  4.1120,\n                        4.9660,  4.6219,  4.5863,  3.3659,  4.1483,  5.2705,  4.6080,  4.5511,\n                        4.7620,  5.6718,  5.5199,  4.7082,  5.2959,  4.0815,  5.4002,  4.7172,\n                        5.9638,  4.3953,  5.0252,  3.8853,  5.3771,  4.1211,  4.5809,  4.1101,\n                        5.0475,  3.7310,  3.8298,  4.0890,  4.2906,  4.0889,  4.2395,  5.6306,\n                        4.1476,  4.7683,  4.5252,  4.5624,  4.4694,  3.3349,  4.3489,  4.2866,\n                        4.1180,  4.4114,  3.8318,  4.7567,  3.6640,  5.2875,  3.7089,  4.3026,\n                        4.3348,  3.7926,  3.7697,  4.5236,  4.5375,  4.0825,  3.9924,  4.0301,\n                        4.5596,  3.2928,  4.4553,  4.5428,  4.5619,  3.3433,  5.2210,  3.9548,\n                        5.0006,  4.3754,  4.8413,  4.1344,  4.3438,  4.1170,  3.9997,  4.0746,\n                        4.7393,  3.5715,  3.8529,  3.5805,  5.0658,  4.1015,  3.3395,  5.2762,\n                        4.2175,  4.6451,  4.7431,  3.8923,  4.2512,  5.1259,  4.0918,  6.7740,\n                        4.1935,  3.6702,  5.0016,  4.2958,  4.5627,  5.0533,  4.2795,  5.1224,\n                        3.8140,  3.7820,  5.2201,  5.3310,  4.8626,  4.3616,  4.2672,  4.3153,\n                        4.7901,  6.2617,  4.3755,  4.3233,  4.5452,  4.7097,  3.6399,  4.0976,\n                        3.8707,  3.4438,  4.2260,  4.4869,  4.1198,  3.4418,  4.1482,  2.7389,\n                        4.5747,  4.5150,  4.1674,  5.3355,  3.5213,  5.1672,  3.6438,  4.6436,\n                        4.0158,  4.3284,  4.5027,  3.4514,  4.7150,  4.7236,  5.1034,  4.3296,\n                        4.0116,  3.6353,  3.4581,  4.1233,  4.1637,  4.8713,  3.9412,  4.1622,\n                        3.8579,  4.5425,  3.8343,  4.0941, 20.1768,  4.2357,  5.3321,  7.1340,\n                        5.3606,  4.3781,  5.0422,  4.4049,  4.4899,  3.9551,  4.9187,  6.2540,\n                        3.5155,  3.7674,  3.7776,  5.0690,  4.8069,  4.8107,  4.7346,  4.9917,\n                        3.5627,  4.6920,  4.3962,  4.4900,  3.7540,  3.0521,  6.4956,  5.3391,\n                        4.0765,  4.0463,  5.3833,  4.9411,  4.7274,  4.7189,  4.9096,  4.5723,\n                        3.5895,  4.9107,  4.6992,  3.6343,  4.0588,  4.7996,  4.2788,  3.5831,\n                        4.9165,  4.5740,  4.1480,  2.3057,  3.8710,  4.2656,  3.0396,  5.6157,\n                        4.2872,  5.3819,  3.9013,  3.8065,  4.7712,  5.4900,  2.9883,  4.3747,\n                        9.2768,  4.3203,  6.5330,  3.9372,  4.0825,  4.2037,  3.8461,  5.9285,\n                        3.9801,  4.1563,  4.0855,  4.1498,  4.4572,  4.3510,  4.3066,  4.4650,\n                        4.6981,  4.0301,  4.3327,  5.0303,  4.4158,  4.1092,  3.3009,  4.2825,\n                        4.3378,  2.0825,  3.9653,  4.1268,  4.2364,  4.3956,  5.5567,  5.1831,\n                        5.9694,  5.2863,  5.0646,  4.2965,  4.4424,  4.2871,  4.4436,  5.4040,\n                        4.2277,  5.6165,  4.4874,  4.1961,  4.0359,  3.7994,  3.4862,  5.3641,\n                       19.4946,  3.3246,  5.0209,  4.1615,  5.1513,  3.9546,  3.9275,  4.4822,\n                        5.9377,  4.5202,  3.6107,  4.7148,  4.4105,  3.8983,  5.4119,  2.3421,\n                        5.6571,  5.8578,  4.1099,  4.4171,  3.4438,  4.7916,  4.2019,  3.3860,\n                        3.7811,  6.5014,  5.4215,  3.8846,  5.2077,  4.4156,  3.2732,  4.4056,\n                        4.2583,  7.9685,  5.3854,  4.3696,  3.9546,  4.3655,  4.3988,  4.6128,\n                        4.0175,  3.9691,  3.6743,  4.9953,  4.1900,  3.5672,  6.0993,  3.7920,\n                        4.4076,  4.0541,  5.5804,  5.3744,  4.1377,  3.6578,  4.5790,  4.4278,\n                        5.0044,  4.7129,  4.4562,  5.0132,  4.0551,  3.5383,  4.3992,  5.3718,\n                        3.3564,  4.0837,  3.9977,  4.9905,  4.9296,  3.3398,  4.9510,  5.6639,\n                        3.1087,  3.3432,  5.3275,  3.7489,  3.3375,  4.7144,  3.9457,  3.6693,\n                        3.9164,  4.2148,  3.8292,  4.2066,  7.2001,  3.0626,  4.0711,  4.5509,\n                        4.1369,  3.4134,  3.6325,  3.9405,  3.9515,  4.2582,  3.7936,  4.4162])),\n              ('backbone.models.0.model.layer4.0.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer4.0.conv2.weight',\n               tensor([[[[-5.0918e-03, -9.3885e-03,  7.3836e-03],\n                         [-1.6589e-02,  8.8443e-03,  3.8825e-02],\n                         [ 9.5661e-03,  2.0816e-02,  1.1258e-02]],\n               \n                        [[-4.2672e-02, -2.5619e-02, -1.8219e-02],\n                         [-5.1028e-02, -5.3940e-02, -1.2368e-02],\n                         [-1.3428e-02,  3.0177e-03, -2.0499e-02]],\n               \n                        [[-2.9326e-02, -7.9275e-03, -9.7545e-03],\n                         [-4.7453e-02, -3.5533e-02, -6.8525e-02],\n                         [-7.6119e-03, -4.4000e-02, -4.5015e-02]],\n               \n                        ...,\n               \n                        [[ 1.9793e-02, -1.1479e-02, -1.6569e-03],\n                         [-3.6386e-02,  7.9380e-03, -6.9015e-03],\n                         [-3.7634e-02, -8.2089e-02, -5.1626e-02]],\n               \n                        [[ 1.4194e-02, -3.1023e-02, -3.8866e-02],\n                         [ 1.4031e-02, -1.7925e-02, -6.3652e-02],\n                         [ 1.3518e-02, -3.0967e-02, -8.4648e-03]],\n               \n                        [[-2.3979e-02, -8.5323e-03, -2.7221e-02],\n                         [ 1.1126e-02, -5.1828e-03,  6.7359e-03],\n                         [ 1.5464e-02, -9.0675e-05,  1.7066e-02]]],\n               \n               \n                       [[[ 3.3696e-02,  6.0065e-02,  4.1214e-02],\n                         [ 3.5555e-02,  5.1079e-02,  6.3679e-02],\n                         [ 8.1350e-03,  2.6081e-02,  6.1723e-02]],\n               \n                        [[-2.1643e-02, -5.0119e-02, -2.9624e-02],\n                         [-1.9462e-02, -5.9491e-02, -3.9951e-02],\n                         [-2.1688e-03,  1.4633e-02, -1.6612e-02]],\n               \n                        [[ 2.5071e-02,  3.6419e-02,  3.7570e-02],\n                         [ 2.9111e-02, -1.1446e-02,  1.0779e-02],\n                         [ 5.3119e-03,  3.8899e-02,  1.5395e-02]],\n               \n                        ...,\n               \n                        [[ 6.5673e-03,  1.4609e-02,  2.5573e-04],\n                         [-1.3782e-02,  6.7168e-03, -1.5854e-02],\n                         [-6.9811e-03,  8.3589e-03,  2.6354e-03]],\n               \n                        [[-8.9107e-04, -1.4967e-02, -1.9689e-02],\n                         [ 6.3732e-03,  4.3269e-04, -1.6124e-02],\n                         [ 2.8786e-02,  2.8798e-02,  1.3431e-02]],\n               \n                        [[ 3.4807e-02,  1.8409e-03, -3.1484e-04],\n                         [ 6.1743e-03, -4.4164e-02, -4.6573e-02],\n                         [-1.0233e-02, -1.0733e-02, -9.5263e-03]]],\n               \n               \n                       [[[-2.7297e-03,  1.2254e-02, -1.0568e-02],\n                         [ 8.3272e-03,  2.7661e-02,  5.2564e-03],\n                         [ 1.1039e-02,  8.9722e-03, -2.0901e-02]],\n               \n                        [[-7.0405e-03, -2.3775e-02, -2.7986e-02],\n                         [-8.4868e-03, -4.8781e-02, -5.1570e-02],\n                         [-3.4826e-02, -5.4531e-02, -5.5889e-02]],\n               \n                        [[ 3.6453e-02,  3.9110e-02,  4.4265e-02],\n                         [ 1.1567e-02,  2.7157e-02,  6.1271e-02],\n                         [ 9.1173e-03,  4.4400e-02,  1.6273e-02]],\n               \n                        ...,\n               \n                        [[-9.8020e-03,  6.7697e-03,  3.6299e-02],\n                         [-1.1715e-02,  1.1448e-02,  3.1728e-02],\n                         [-1.3336e-02,  1.9252e-02, -5.7718e-04]],\n               \n                        [[ 5.5546e-02,  3.8494e-02,  6.8604e-02],\n                         [ 2.6792e-02,  5.9128e-02,  5.5561e-02],\n                         [ 7.1173e-02,  5.9856e-02,  5.1326e-02]],\n               \n                        [[ 2.4236e-03, -2.0674e-02, -1.3549e-02],\n                         [-2.8924e-02, -1.9761e-02, -3.0345e-02],\n                         [-1.5865e-02, -1.2049e-02, -1.2352e-02]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 1.6015e-02,  2.5711e-02,  1.6846e-02],\n                         [ 3.3062e-02, -4.3189e-03,  3.8857e-02],\n                         [ 2.3824e-02,  6.9434e-02,  7.3931e-02]],\n               \n                        [[ 1.9296e-02,  4.7808e-02,  5.0671e-02],\n                         [ 1.7341e-02,  6.2541e-03, -6.5486e-03],\n                         [ 7.2133e-03, -2.6200e-02, -2.9167e-02]],\n               \n                        [[-2.8748e-02, -2.8635e-02, -3.1579e-02],\n                         [-5.0594e-02, -4.8734e-02, -5.2743e-02],\n                         [-1.0060e-02, -3.7319e-02, -4.1411e-02]],\n               \n                        ...,\n               \n                        [[ 3.4328e-02,  6.2765e-02,  2.5321e-02],\n                         [ 4.6362e-02,  5.4378e-02,  6.4286e-02],\n                         [ 5.3497e-02,  6.3031e-02,  5.1035e-02]],\n               \n                        [[ 1.3598e-02,  1.4960e-02,  1.0800e-02],\n                         [ 1.4375e-02,  4.7529e-02,  3.1245e-02],\n                         [-2.1414e-03,  1.1261e-02, -8.2617e-03]],\n               \n                        [[ 1.8041e-03, -5.4648e-03, -2.8483e-02],\n                         [ 9.6899e-03, -2.6290e-03,  2.2973e-03],\n                         [-1.4089e-02, -1.7189e-02, -1.5463e-02]]],\n               \n               \n                       [[[-1.2052e-03, -3.0074e-02, -1.8337e-02],\n                         [-5.9564e-03, -6.2508e-03, -9.9841e-03],\n                         [-1.9496e-02, -5.0514e-02, -2.3646e-02]],\n               \n                        [[ 1.2725e-02,  2.7654e-02,  2.2456e-02],\n                         [ 1.4950e-02,  3.6528e-02,  6.6225e-02],\n                         [ 4.9541e-02,  1.8741e-02,  5.6566e-02]],\n               \n                        [[ 1.4616e-03,  4.3772e-02,  4.4051e-02],\n                         [ 3.0468e-02,  3.7499e-02,  5.2621e-02],\n                         [ 2.5623e-02,  1.6264e-02,  4.0711e-02]],\n               \n                        ...,\n               \n                        [[-2.8684e-02,  1.0877e-02,  2.2014e-02],\n                         [ 6.3569e-03, -2.4912e-02, -5.6721e-03],\n                         [-1.1113e-02, -2.4870e-02, -2.2962e-02]],\n               \n                        [[ 7.0844e-03, -4.9266e-03, -1.2325e-02],\n                         [-6.2680e-03,  2.0620e-03,  1.1417e-02],\n                         [-2.8774e-02, -2.2194e-02,  3.0835e-04]],\n               \n                        [[ 3.3981e-03,  1.3970e-02,  2.2019e-02],\n                         [ 1.5848e-02,  1.4387e-02,  5.0555e-02],\n                         [ 7.7154e-03,  7.4287e-02,  4.0126e-02]]],\n               \n               \n                       [[[-3.7750e-02, -3.6443e-02, -4.6864e-02],\n                         [ 1.3497e-02, -2.4231e-02, -3.5744e-02],\n                         [-3.8720e-03, -5.7122e-03, -2.1505e-02]],\n               \n                        [[ 1.9824e-02,  1.8243e-02, -7.0799e-03],\n                         [-1.8990e-02,  1.8707e-04,  1.9774e-02],\n                         [-6.0568e-03, -2.4434e-02, -1.7673e-02]],\n               \n                        [[-9.1695e-03, -3.6016e-02, -1.4538e-02],\n                         [-2.2202e-02, -9.9641e-03, -6.7299e-03],\n                         [-1.5540e-02, -5.7131e-03,  9.9001e-03]],\n               \n                        ...,\n               \n                        [[-8.0375e-03, -1.3329e-02, -6.7723e-03],\n                         [-3.9553e-02, -2.9124e-02, -1.1810e-02],\n                         [-9.4324e-03, -2.2665e-02, -8.5350e-03]],\n               \n                        [[-3.2773e-03, -2.1703e-02,  7.5508e-03],\n                         [ 2.7254e-02,  5.3732e-02,  2.8156e-02],\n                         [ 3.4987e-03,  4.6932e-02,  3.5224e-02]],\n               \n                        [[ 3.1901e-02,  3.3310e-02,  1.7194e-02],\n                         [ 2.2237e-02, -1.7468e-02,  1.6038e-02],\n                         [ 4.9735e-03, -2.9900e-02, -7.2845e-03]]]])),\n              ('backbone.models.0.model.layer4.0.bn2.weight',\n               tensor([0.9388, 0.9682, 0.9240, 1.0702, 1.0412, 0.8890, 1.0745, 0.8799, 1.0458,\n                       1.1439, 0.7769, 1.1234, 1.0660, 0.8727, 1.1579, 0.9953, 0.8904, 1.0044,\n                       1.0679, 0.9575, 0.9152, 0.9446, 1.0344, 0.9929, 1.0322, 0.9733, 1.1723,\n                       1.0144, 0.8142, 0.9935, 0.7961, 1.0787, 0.7694, 0.9672, 1.2298, 0.9046,\n                       0.9485, 1.0210, 0.9572, 0.9869, 0.9089, 0.9160, 1.0886, 0.9816, 0.8047,\n                       1.0165, 1.0321, 0.9588, 0.9434, 0.9575, 0.9234, 0.9655, 1.0070, 0.8982,\n                       0.9354, 0.9183, 0.7917, 0.9601, 0.9705, 0.9546, 1.0923, 1.0160, 1.2205,\n                       0.9960, 1.0594, 1.0779, 0.8585, 1.0799, 0.9152, 1.0527, 1.0396, 0.9049,\n                       1.0577, 0.9977, 1.0937, 1.0146, 1.1135, 1.0480, 1.0054, 0.9077, 0.9873,\n                       0.9331, 0.8987, 1.0530, 0.9905, 1.1341, 1.0242, 0.9548, 1.2281, 1.0006,\n                       0.9212, 1.1849, 1.0205, 1.0691, 0.8357, 1.0181, 0.9031, 1.0678, 0.9204,\n                       0.8717, 0.8615, 1.0934, 1.0175, 0.8467, 1.1195, 0.8799, 1.0121, 0.8614,\n                       1.1227, 1.0504, 1.0982, 0.9376, 1.0962, 0.8791, 0.8722, 1.2207, 1.0388,\n                       0.9945, 1.0946, 1.2274, 0.7996, 1.0035, 0.8695, 0.9834, 0.9717, 0.7631,\n                       1.0250, 1.0336, 0.9171, 1.1585, 0.9488, 1.1298, 0.9848, 0.8949, 0.8788,\n                       0.9444, 0.9726, 0.8357, 1.0421, 0.8170, 0.8973, 0.9528, 1.0114, 1.1041,\n                       0.8652, 1.0486, 1.0945, 0.9413, 1.0808, 0.9884, 1.1180, 0.8571, 0.8791,\n                       0.9537, 0.9435, 0.9347, 0.9044, 0.8020, 1.1009, 0.9631, 0.9277, 0.9907,\n                       1.1400, 1.1283, 1.0760, 1.0594, 1.1066, 0.8579, 1.1805, 0.9782, 0.9173,\n                       1.0658, 1.1560, 1.0179, 0.8595, 0.9693, 1.0072, 1.0254, 1.0451, 0.9485,\n                       1.1733, 0.9956, 0.9569, 0.9480, 0.8578, 1.0682, 1.0352, 1.0469, 0.9343,\n                       0.8789, 1.0733, 1.0433, 1.0051, 0.9424, 0.9574, 1.2085, 0.9319, 1.0074,\n                       1.1362, 1.1467, 0.9439, 0.8633, 0.9393, 1.0296, 0.9270, 1.0550, 0.9804,\n                       1.0674, 0.9083, 1.1427, 0.9361, 1.0823, 1.1624, 0.9702, 1.0009, 1.1056,\n                       1.0379, 1.0696, 1.0192, 0.9804, 0.8106, 0.7524, 1.0590, 1.0907, 1.1603,\n                       1.0818, 1.0339, 1.0340, 1.0448, 0.9649, 0.9632, 0.8990, 1.1438, 0.9364,\n                       0.8757, 0.9261, 1.2967, 0.9742, 1.0044, 0.9261, 1.1135, 0.9579, 0.9309,\n                       1.0987, 0.9212, 1.0757, 1.0707, 0.8115, 0.9698, 1.0098, 0.7926, 0.8885,\n                       0.9531, 0.8933, 0.9973, 0.8380, 1.2053, 0.9010, 0.8106, 0.9755, 0.7302,\n                       1.1417, 1.0147, 1.0233, 0.8597, 1.2386, 0.8125, 1.1678, 1.0662, 0.8736,\n                       0.8392, 1.1523, 0.9001, 0.9778, 1.0113, 1.0044, 0.9062, 1.0117, 1.0412,\n                       1.1014, 0.8369, 0.9883, 0.9651, 1.1468, 0.8908, 1.1692, 1.0237, 1.0968,\n                       0.9002, 0.7949, 0.9002, 1.2071, 1.1061, 1.1237, 0.9142, 0.9431, 1.1371,\n                       1.0951, 1.0050, 0.9114, 0.8706, 0.8730, 0.9408, 0.8762, 0.9533, 1.0923,\n                       0.8405, 1.0445, 0.8509, 1.0580, 1.2064, 0.8851, 0.9623, 0.8650, 1.0006,\n                       1.0782, 0.9115, 0.9858, 1.1663, 0.7993, 0.9217, 1.3131, 0.8612, 1.2706,\n                       1.0378, 0.9430, 1.0842, 1.1941, 0.9961, 0.8431, 1.0795, 1.1029, 0.8935,\n                       1.0501, 1.1740, 0.9398, 0.8901, 1.0035, 0.8359, 1.0084, 1.0973, 0.9705,\n                       0.8665, 0.9212, 1.0993, 0.8687, 1.1070, 0.8849, 0.9400, 0.8669, 1.0106,\n                       0.9954, 0.9400, 0.9135, 0.9987, 0.8840, 1.0617, 0.9198, 1.1278, 0.7663,\n                       1.0166, 0.8822, 0.9439, 1.0066, 1.1412, 0.7855, 1.2160, 1.0942, 0.8830,\n                       0.9511, 0.9055, 0.9692, 0.9244, 0.8345, 1.1295, 0.9556, 1.0681, 0.9973,\n                       1.1363, 0.8396, 0.9550, 0.8303, 0.8675, 1.0239, 1.0547, 0.9679, 0.9274,\n                       1.0494, 0.8838, 0.9322, 0.8485, 1.0040, 0.9601, 1.0416, 1.1911, 0.9759,\n                       1.0587, 0.9953, 1.0790, 0.9898, 1.1377, 0.9660, 0.8676, 0.9273, 0.9076,\n                       1.0175, 0.9555, 0.9530, 1.0741, 1.0250, 0.8414, 1.2750, 0.9786, 1.0093,\n                       1.1323, 0.9581, 0.8911, 1.1120, 1.0258, 0.9571, 1.0126, 0.9985, 1.1173,\n                       0.9410, 0.8995, 1.0200, 1.0330, 0.6928, 1.1233, 0.9715, 1.0418, 0.9461,\n                       0.9564, 1.1119, 1.0952, 1.0545, 0.8124, 0.8697, 1.0983, 1.0677, 1.1532,\n                       0.9931, 0.9395, 1.0034, 0.9630, 1.0187, 1.0229, 0.9398, 0.9373, 1.1010,\n                       1.1134, 1.0768, 0.9816, 1.0749, 0.7721, 1.0870, 1.0894, 1.0888, 0.9798,\n                       0.9976, 0.8968, 1.1706, 1.0190, 1.0948, 1.3075, 1.0318, 0.7458, 1.0532,\n                       1.0727, 0.9840, 1.2841, 0.9590, 0.9437, 0.8601, 0.9524, 1.0639, 1.0004,\n                       0.9651, 0.9011, 1.0401, 0.8647, 0.9352, 0.9348, 0.9776, 0.9876, 0.9600,\n                       0.8746, 0.8013, 0.8685, 0.9910, 1.1825, 0.9425, 1.0272, 0.8073, 0.8715,\n                       0.9424, 0.9981, 1.0265, 0.9670, 1.0671, 0.7711, 0.7946, 1.0720, 0.8658,\n                       0.6945, 1.1057, 0.9949, 1.0581, 1.0474, 1.0787, 0.9033, 0.8827])),\n              ('backbone.models.0.model.layer4.0.bn2.bias',\n               tensor([-0.2020, -0.1963, -0.2092, -0.3273, -0.2470, -0.0244, -0.2363, -0.0361,\n                       -0.4215, -0.4219,  0.1292, -0.7284, -0.3431, -0.0223, -0.5051, -0.3255,\n                       -0.0729, -0.1847, -0.2434, -0.1314, -0.0270, -0.1920, -0.2512, -0.3300,\n                       -0.2965, -0.3193, -0.4748, -0.1713,  0.1920, -0.2277,  0.2029, -0.3037,\n                        0.2290, -0.4091, -0.6393,  0.0291, -0.1583, -0.3151, -0.0767, -0.3186,\n                       -0.0786, -0.2237, -0.5401, -0.2287,  0.1246, -0.3195, -0.3267, -0.1986,\n                       -0.0592, -0.1167, -0.1304, -0.3116, -0.3259, -0.0471, -0.1233, -0.0296,\n                        0.1485, -0.2313, -0.1092, -0.0027, -0.4522, -0.4067, -0.6670, -0.2590,\n                       -0.2564, -0.3183,  0.0633, -0.3299, -0.0177, -0.2812, -0.3059, -0.0370,\n                       -0.4109, -0.2512, -0.4145, -0.4505, -0.4643, -0.3545, -0.2106, -0.0341,\n                       -0.2792, -0.1084, -0.0942, -0.4307, -0.4547, -0.4790, -0.2399, -0.0371,\n                       -0.6764, -0.2531, -0.0219, -0.6286, -0.4729, -0.4214,  0.0817, -0.3261,\n                        0.2424, -0.2237, -0.1716,  0.1634,  0.0064, -0.5899, -0.3290,  0.0321,\n                       -0.3859, -0.0394, -0.1999,  0.1034, -0.4349, -0.5105, -0.4177, -0.0151,\n                       -0.3663, -0.0573,  0.0703, -0.8116, -0.3719, -0.2328, -0.5276, -0.5073,\n                        0.1473, -0.2910, -0.0714, -0.1673, -0.1527,  0.1916, -0.3210, -0.1435,\n                       -0.0735, -0.4978, -0.1145, -0.3783, -0.3424, -0.1090,  0.0663, -0.0949,\n                       -0.2509, -0.0174, -0.4359,  0.1775,  0.0090, -0.1609, -0.2719, -0.5857,\n                        0.0354, -0.3403, -0.4240, -0.1179, -0.5130, -0.2643, -0.4930,  0.0835,\n                       -0.0167, -0.1823, -0.1290,  0.0305, -0.1076,  0.1355, -0.5699, -0.1017,\n                       -0.1523, -0.2526, -0.6255, -0.3801, -0.2731, -0.2592, -0.3515, -0.0188,\n                       -0.5971, -0.2570, -0.2098, -0.4762, -0.7348, -0.2723,  0.0176, -0.2076,\n                       -0.2871, -0.3790, -0.2663, -0.1460, -0.5553, -0.3804, -0.2503, -0.1323,\n                       -0.0121, -0.4365, -0.4371, -0.2271, -0.0206,  0.0264, -0.3807, -0.1796,\n                       -0.0926, -0.1676, -0.1599, -0.7160, -0.0438, -0.1220, -0.6759, -0.4659,\n                       -0.3108,  0.1014,  0.3727, -0.2091, -0.2041, -0.3791, -0.1917, -0.3438,\n                       -0.1690, -0.4502, -0.1914, -0.5002, -0.4238, -0.2854, -0.1728,  0.4012,\n                       -0.1944, -0.4998, -0.2493, -0.1495,  0.1870,  0.1366, -0.4934, -0.4165,\n                       -0.4847, -0.3075, -0.4059, -0.3152, -0.3661, -0.2153, -0.1354, -0.0302,\n                       -0.4679, -0.0854,  0.0386, -0.2017, -1.0373, -0.2247, -0.2447, -0.1554,\n                       -0.4239, -0.2573, -0.1502, -0.4178, -0.2208, -0.4224, -0.3510,  0.1730,\n                       -0.1331, -0.3400,  0.1722, -0.1029, -0.0647,  0.0318, -0.1688,  0.0763,\n                       -0.6067, -0.0872,  0.1499,  0.2657,  0.3874, -0.5387, -0.0951, -0.1872,\n                       -0.0658, -0.7127,  0.0265, -0.7410, -0.3998,  0.0546, -0.0047, -0.3620,\n                       -0.0300, -0.1449, -0.3442, -0.2638, -0.0352, -0.2368, -0.4132, -0.5167,\n                        0.1360, -0.1848, -0.2227, -0.5338, -0.1026, -0.7112, -0.2761, -0.3771,\n                       -0.0838,  0.1270, -0.0624, -0.9130, -0.4714, -0.5932, -0.0686, -0.1170,\n                       -0.7825, -0.4379, -0.2596, -0.0298,  0.0776, -0.0641, -0.0932,  0.0142,\n                       -0.1495, -0.3474,  0.0927, -0.2888,  0.0219, -0.3335, -0.4815, -0.0253,\n                       -0.0467,  0.0920, -0.1975, -0.4195, -0.0197, -0.2864, -0.6200,  0.1974,\n                       -0.0801, -0.8632,  0.0663, -0.8376, -0.3944, -0.1112, -0.4577, -0.6363,\n                       -0.3720,  0.0199, -0.4154, -0.3292, -0.0044, -0.1368, -0.7286, -0.3034,\n                        0.0120, -0.2456,  0.0647, -0.3219, -0.3828, -0.1461,  0.1232, -0.1051,\n                       -0.5498, -0.0667, -0.6829,  0.0385, -0.1354, -0.0565, -0.2015, -0.2785,\n                       -0.1201, -0.1709, -0.3156, -0.0430, -0.3055, -0.3933, -0.3938,  1.0342,\n                       -0.3589, -0.0354,  0.2930, -0.1966, -0.4780,  0.1423, -0.8149, -0.4870,\n                       -0.0068, -0.2096, -0.0461, -0.0714, -0.1672,  0.1160, -0.5681, -0.1220,\n                       -0.4846, -0.1900, -0.5321,  0.0915, -0.1442,  0.2030, -0.0340, -0.3642,\n                       -0.3554, -0.1854,  0.2016, -0.3995, -0.0343, -0.0468,  0.0506, -0.3254,\n                        0.0171, -0.4124, -0.6351, -0.1410, -0.4125, -0.2292, -0.3253, -0.3105,\n                       -0.3942, -0.2181,  0.0100, -0.1266, -0.0551, -0.3228, -0.1965, -0.2086,\n                       -0.3045, -0.1803, -0.0051, -0.7147, -0.2873, -0.3690, -0.4215, -0.3649,\n                       -0.1014, -0.5902, -0.1348, -0.2466, -0.3805, -0.2655, -0.5494, -0.1393,\n                       -0.0523, -0.3379, -0.2981,  0.4763, -0.5975, -0.2535, -0.4435, -0.1238,\n                       -0.2882, -0.5448, -0.5005, -0.2673,  0.1884,  0.0842, -0.2476, -0.5170,\n                       -0.4274, -0.2528, -0.0452, -0.1028, -0.1495, -0.2296, -0.4444, -0.0886,\n                       -0.0499, -0.4413, -0.6064, -0.2902, -0.3252,  0.0029,  0.1645, -0.3949,\n                       -0.2954, -0.6963, -0.2014, -0.2293, -0.0575, -0.7808, -0.4099, -0.4307,\n                       -0.6393, -0.2370,  0.2850, -0.3090, -0.4636, -0.1545, -0.9993, -0.0991,\n                       -0.0729,  0.0150, -0.1511, -0.2696, -0.3702, -0.2560, -0.0851, -0.2550,\n                       -0.0230, -0.1260, -0.0585, -0.1520, -0.1547, -0.1954,  0.0489,  0.1283,\n                        0.0533, -0.2222, -0.7284, -0.1446, -0.1619,  0.1477, -0.0712, -0.2047,\n                       -0.2631, -0.4341, -0.2347, -0.2825,  0.0810,  0.1894, -0.3422,  0.0040,\n                        0.4332, -0.4453, -0.2012, -0.3104, -0.5221, -0.3532, -0.0446, -0.1531])),\n              ('backbone.models.0.model.layer4.0.bn2.running_mean',\n               tensor([-0.5031, -0.5016, -0.5766, -0.6603, -0.5072, -0.2666, -0.3983, -0.4352,\n                       -0.6367, -0.6281, -0.2339, -0.6106, -0.4499, -0.3538, -0.7565, -0.5424,\n                       -0.3679, -0.5456, -0.5890, -0.4396, -0.4668, -0.4029, -0.5598, -0.3853,\n                       -0.5347, -0.5323, -0.8631, -0.7020, -0.3412, -0.6854, -0.1477, -0.6536,\n                       -0.2433, -0.4789, -0.6237, -0.3035, -0.3923, -0.4777, -0.4913, -0.5625,\n                       -0.3778, -0.5083, -0.5316, -0.7300, -0.4320, -0.5091, -0.6278, -0.4429,\n                       -0.3686, -0.5404, -0.4417, -0.3542, -0.6450, -0.3474, -0.7345, -0.3727,\n                       -0.2662, -0.4161, -0.3484, -0.4917, -0.6351, -0.4431, -0.7340, -0.5323,\n                       -0.4570, -0.6938, -0.1423, -0.4469, -0.3355, -0.5632, -0.6870, -0.4878,\n                       -0.5502, -0.5182, -0.5351, -0.4567, -0.5889, -0.6274, -0.5278, -0.4138,\n                       -0.3359, -0.6108, -0.3916, -0.5393, -0.2566, -0.5348, -0.4255, -0.6405,\n                       -0.6398, -0.5501, -0.4342, -0.6970, -0.5832, -0.4783, -0.4198, -0.2686,\n                       -2.0691, -0.6465, -0.4364, -0.5368, -0.2707, -0.3439, -0.5242, -0.4410,\n                       -0.5484, -0.4099, -0.6514, -0.3907, -0.7519, -0.4277, -0.6095, -0.6518,\n                       -0.4951, -0.3968, -0.4972, -0.7196, -0.5357, -0.6065, -0.5462, -0.5584,\n                       -0.4015, -0.5273, -0.4385, -0.5547, -0.4704, -0.4289, -0.4501, -0.6230,\n                       -0.4961, -0.6856, -0.5075, -0.5685, -0.5354, -0.4301, -0.5285, -0.4111,\n                       -0.3162, -0.3963, -0.6191, -0.4202, -0.4422, -0.4564, -0.3510, -0.6016,\n                       -0.2701, -0.6285, -0.6731, -0.5926, -0.4704, -0.4859, -0.5976, -0.2398,\n                       -0.4882, -0.4277, -0.2402, -0.3877, -0.4045, -0.2729, -0.5212, -0.4831,\n                       -0.3882, -0.4882, -0.4646, -0.7567, -0.3694, -0.5690, -0.7209, -0.3847,\n                       -0.5657, -0.4476, -0.3865, -0.4586, -0.5881, -0.5700, -0.2721, -0.4139,\n                       -0.4762, -0.4346, -0.3618, -0.4447, -0.6100, -0.4553, -0.3870, -0.5185,\n                       -0.3719, -0.5160, -0.5309, -0.4766, -0.4053, -0.3591, -0.4856, -0.5441,\n                       -0.5389, -0.4768, -0.4893, -0.6954, -0.5345, -0.4335, -0.4781, -0.6551,\n                       -0.3408, -0.4409, -0.2640, -0.4061, -0.4230, -0.7890, -0.4268, -0.5308,\n                       -0.2936, -0.5981, -0.5322, -0.5607, -0.5407, -0.3645, -0.4799, -1.0857,\n                       -0.4382, -0.4662, -0.6523, -0.6922, -0.3530, -0.1660, -0.5160, -0.6723,\n                       -0.6699, -0.6217, -0.4162, -0.7162, -0.4867, -0.4324, -0.6005, -0.3626,\n                       -0.5817, -0.4585, -0.3528, -0.4828, -0.6131, -0.6227, -0.4483, -0.5438,\n                       -0.5729, -0.5090, -0.4176, -0.5251, -0.2568, -0.4860, -0.5578, -0.4638,\n                       -0.5352, -0.4968, -0.2359, -0.4148, -0.3972, -0.3059, -0.4655, -0.2818,\n                       -0.6158, -0.4400, -0.2195, -0.4646,  0.3430, -0.5122, -0.4408, -0.4803,\n                       -0.3872, -0.6541, -0.3691, -0.6695, -0.5633, -0.4070, -0.4111, -0.7275,\n                       -0.3696, -0.5786, -0.5279, -0.4000, -0.4587, -0.5246, -0.4979, -0.5787,\n                       -0.3086, -0.3367, -0.5525, -0.7362, -0.2920, -0.7563, -0.4975, -0.6903,\n                       -0.4561, -0.4309, -0.4242, -0.6832, -0.5776, -0.6631, -0.5282, -0.5928,\n                       -0.7633, -0.4375, -0.5835, -0.4474, -0.2687, -0.3437, -0.4811, -0.3163,\n                       -0.4065, -0.6315, -0.3399, -0.3438, -0.4589, -0.5590, -0.6575, -0.4087,\n                       -0.4723, -0.4074, -0.6433, -0.4467, -0.4664, -0.5201, -0.5502, -0.2068,\n                       -0.3624, -0.7914, -0.5302, -0.6215, -0.4421, -0.4436, -0.7226, -0.4936,\n                       -0.7195, -0.3789, -0.5748, -0.6448, -0.4368, -0.6954, -0.7977, -0.4304,\n                       -0.3854, -0.6026, -0.2244, -0.5429, -0.5691, -0.5499, -0.3739, -0.4335,\n                       -0.4031, -0.3687, -0.3666, -0.2767, -0.4840, -0.3479, -0.5366, -0.4739,\n                       -0.3621, -0.4445, -0.3111, -0.3717, -0.5837, -0.5976, -0.6521,  0.5450,\n                       -0.3481, -0.5242, -0.0492, -0.7142, -0.6896, -0.2583, -0.6201, -0.4360,\n                       -0.3435, -0.4988, -0.3756, -0.4395, -0.4113, -0.3423, -0.6714, -0.5288,\n                       -0.6183, -0.5051, -0.5743, -0.3245, -0.5325, -0.3932, -0.4197, -0.4773,\n                       -0.6793, -0.4837, -0.4661, -0.6234, -0.5206, -0.5194, -0.2839, -0.4843,\n                       -0.4079, -0.6184, -0.6068, -0.4948, -0.5775, -0.5203, -0.5548, -0.5521,\n                       -0.6266, -0.4289, -0.2077, -0.4660, -0.4462, -0.6243, -0.4511, -0.4861,\n                       -0.4153, -0.5517, -0.4175, -0.6844, -0.7056, -0.4538, -0.6330, -0.4709,\n                       -0.4305, -0.3979, -0.5591, -0.5338, -0.3037, -0.5840, -0.5111, -0.4689,\n                       -0.3596, -0.7633, -0.5263, -0.1610, -0.4854, -0.4179, -0.5277, -0.5545,\n                       -0.4566, -0.5382, -0.5931, -0.5071, -0.3127, -0.4253, -0.6631, -0.5441,\n                       -0.6433, -0.4573, -0.4444, -0.4875, -0.5114, -0.6602, -0.7676, -0.4492,\n                       -0.5393, -0.5757, -0.5914, -0.4646, -0.2978,  2.0982, -0.2346, -0.5404,\n                       -0.6649, -0.5493, -0.4308, -0.4334, -0.4499, -0.7840, -0.7059, -0.5864,\n                       -0.5855, -0.5907, -0.1914, -0.6826, -0.4939, -0.6521, -0.7863, -0.2656,\n                       -0.6139, -0.3216, -0.4957, -0.5063, -0.4785, -0.5139, -0.4262, -0.3653,\n                       -0.4104, -0.4449, -0.3625, -0.3572, -0.4404, -0.3417, -0.4355, -0.2803,\n                       -0.3267, -0.3842, -0.5452, -0.6079, -0.5702, -0.4378, -0.4724, -0.3707,\n                       -0.6124, -0.4466, -0.4616, -0.5971, -0.2775, -0.2208, -0.5297, -0.5035,\n                       -0.2497, -0.6811, -0.7262, -0.5048, -0.5198, -0.6461, -0.3417, -0.3028])),\n              ('backbone.models.0.model.layer4.0.bn2.running_var',\n               tensor([0.8159, 0.9250, 0.8627, 0.9850, 0.8175, 0.7643, 0.9463, 0.7554, 0.7381,\n                       1.1481, 0.7186, 0.7263, 0.8552, 0.7446, 0.8498, 0.8101, 0.7585, 0.8712,\n                       0.8984, 0.8588, 0.8542, 0.6654, 0.7644, 0.6617, 0.8976, 0.7842, 0.9530,\n                       1.0213, 0.8094, 0.6872, 1.0017, 0.8363, 0.7578, 0.7740, 0.9067, 0.8086,\n                       0.8911, 0.7799, 0.9050, 0.8086, 0.7649, 0.6676, 0.7346, 0.8907, 0.7396,\n                       0.7397, 0.8176, 0.7948, 0.8402, 0.8780, 0.6938, 0.7505, 0.9277, 0.7112,\n                       1.0071, 1.0756, 0.7270, 0.6570, 0.7983, 0.8506, 0.8558, 0.7603, 1.1482,\n                       0.7232, 0.8928, 0.8798, 0.7705, 0.7423, 0.8909, 1.1032, 0.9124, 0.7937,\n                       0.6788, 0.7604, 0.8967, 0.7315, 0.8235, 0.9280, 0.8290, 1.0204, 0.7665,\n                       0.9130, 0.7897, 0.7717, 0.4537, 0.8533, 0.7954, 0.8666, 1.2587, 0.8868,\n                       0.8085, 0.8083, 0.7161, 0.8922, 0.7480, 0.7013, 1.1495, 0.9799, 0.7366,\n                       1.1722, 0.7919, 0.7264, 0.8600, 0.7430, 0.9131, 0.7792, 0.8812, 0.9185,\n                       0.9325, 0.7426, 0.7778, 0.9861, 0.9881, 0.7380, 0.8723, 0.6444, 0.7245,\n                       0.8432, 0.7302, 1.0622, 0.9165, 0.8166, 0.7987, 0.9349, 0.8441, 0.7815,\n                       0.6879, 0.8987, 0.8038, 0.9622, 0.9236, 1.0282, 0.7335, 0.7165, 0.8266,\n                       0.8902, 0.7039, 0.8548, 0.7393, 0.9411, 0.7741, 0.8283, 0.7170, 0.8446,\n                       0.6954, 0.7556, 0.8681, 0.8060, 0.7453, 0.7570, 0.8048, 0.7557, 0.8973,\n                       0.8298, 0.8337, 1.0137, 0.7059, 0.6586, 0.7226, 0.9951, 0.7562, 0.8035,\n                       0.6233, 0.8466, 1.1393, 0.7986, 0.9502, 0.8000, 0.6435, 0.8021, 0.7555,\n                       0.6474, 0.8394, 0.8965, 0.7217, 0.7367, 0.9825, 0.7106, 0.8763, 0.8189,\n                       0.7844, 0.7592, 1.0316, 0.8527, 0.7598, 0.9240, 0.7468, 0.9719, 0.8553,\n                       0.7693, 0.7933, 0.9776, 1.0472, 0.7726, 1.0189, 0.7889, 0.8302, 0.9241,\n                       0.7667, 0.7672, 0.6521, 0.8240, 0.7705, 0.8247, 0.8196, 0.9052, 0.9493,\n                       0.9223, 0.7664, 0.8996, 1.0029, 0.7749, 0.8038, 0.9129, 0.7658, 2.2033,\n                       0.9200, 0.6932, 0.9659, 0.9373, 0.7973, 0.7448, 0.8138, 0.7420, 0.7656,\n                       0.9612, 0.8053, 1.0875, 0.7996, 0.8764, 0.9562, 0.8470, 0.8548, 0.7521,\n                       0.9615, 0.7360, 0.7759, 0.7984, 0.7209, 0.8111, 0.8356, 0.7473, 0.6889,\n                       0.8451, 0.6857, 0.8609, 0.8326, 0.7910, 0.9794, 0.7476, 0.7525, 0.8211,\n                       0.9084, 0.8873, 0.8257, 0.7868, 0.9268, 0.7226, 0.7068, 0.8019, 0.6364,\n                       0.7848, 1.0261, 1.0284, 0.7543, 0.9008, 0.8138, 0.6690, 0.8513, 0.7964,\n                       0.8214, 1.1226, 0.8399, 1.0225, 0.8235, 0.7226, 0.8255, 0.8436, 0.7863,\n                       0.7565, 0.7948, 0.7785, 0.7818, 0.8579, 0.6342, 0.7102, 0.8145, 1.0955,\n                       0.8741, 0.8546, 0.8414, 0.6964, 0.7882, 0.9295, 0.8806, 0.8432, 0.8163,\n                       0.8099, 0.8731, 0.7578, 0.9115, 0.7226, 0.7812, 0.7920, 0.7434, 0.8837,\n                       0.8186, 0.8415, 0.7899, 0.8464, 0.9832, 0.8779, 0.8826, 0.9278, 0.9796,\n                       0.9263, 0.9278, 0.7375, 0.8255, 0.8069, 0.7999, 1.0244, 0.8419, 0.8037,\n                       0.8456, 0.7940, 0.7625, 0.8079, 0.8135, 0.7637, 0.7166, 0.9439, 0.8153,\n                       1.0610, 0.8029, 0.6662, 0.7552, 1.0093, 0.7794, 0.6771, 0.8105, 0.7881,\n                       0.8471, 0.8361, 0.6375, 0.7784, 0.6761, 0.8815, 0.7854, 0.6981, 1.0595,\n                       0.7581, 0.9168, 0.7329, 0.6920, 0.8630, 0.8421, 0.7493, 1.1781, 1.7738,\n                       0.6371, 0.7732, 0.6652, 1.0603, 0.7846, 0.7175, 0.6942, 0.8161, 0.7917,\n                       0.8265, 0.8253, 0.9116, 0.7767, 0.8216, 0.7173, 0.8405, 0.7743, 0.9701,\n                       0.7402, 0.8885, 0.7958, 0.8571, 0.7348, 0.8318, 0.9207, 0.7251, 1.6414,\n                       0.7558, 0.8050, 0.8133, 0.8293, 0.7126, 0.9274, 0.7743, 0.8171, 0.9105,\n                       0.8147, 0.9374, 0.8595, 0.8919, 0.8348, 0.7005, 0.8570, 0.8521, 0.7275,\n                       0.7559, 0.7724, 0.8406, 0.7223, 1.0518, 0.6962, 0.6688, 0.8434, 0.7865,\n                       0.9015, 0.8398, 0.7653, 0.6302, 1.1329, 0.7084, 0.6912, 0.8481, 0.7920,\n                       0.8434, 0.7917, 0.8472, 0.8622, 0.7465, 0.7224, 0.7493, 0.7267, 0.7968,\n                       0.6908, 0.7809, 0.8333, 0.8796, 0.9008, 0.8027, 1.1592, 0.7340, 0.8253,\n                       0.7542, 0.9464, 0.9276, 0.8533, 0.8459, 0.9165, 0.8158, 0.8291, 0.7538,\n                       0.8161, 0.8182, 0.6630, 1.0048, 0.7432, 0.8647, 1.0088, 0.7158, 0.7271,\n                       0.9425, 0.9045, 0.8890, 0.7348, 0.6801, 1.0993, 0.7972, 0.7610, 0.9321,\n                       0.8183, 1.0025, 0.8516, 0.7686, 0.7405, 0.8164, 0.7604, 0.8402, 0.7143,\n                       0.6214, 0.6711, 0.9023, 0.7610, 0.8357, 0.9006, 0.7670, 0.7450, 0.7962,\n                       0.8958, 0.7650, 0.8330, 0.7700, 0.8217, 0.7346, 0.8463, 0.8629, 0.7727,\n                       0.7202, 0.8735, 0.7045, 0.7670, 0.8542, 0.7635, 0.7267, 0.8640, 0.7868,\n                       0.7774, 0.8094, 0.9036, 0.8236, 0.7527, 0.9353, 0.8181, 0.4904])),\n              ('backbone.models.0.model.layer4.0.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer4.0.conv3.weight',\n               tensor([[[[-0.0138]],\n               \n                        [[ 0.0230]],\n               \n                        [[ 0.0113]],\n               \n                        ...,\n               \n                        [[-0.0013]],\n               \n                        [[ 0.0149]],\n               \n                        [[-0.0094]]],\n               \n               \n                       [[[ 0.0062]],\n               \n                        [[-0.0175]],\n               \n                        [[ 0.0050]],\n               \n                        ...,\n               \n                        [[-0.0176]],\n               \n                        [[ 0.0794]],\n               \n                        [[-0.0016]]],\n               \n               \n                       [[[-0.0467]],\n               \n                        [[-0.0319]],\n               \n                        [[ 0.0060]],\n               \n                        ...,\n               \n                        [[ 0.0243]],\n               \n                        [[-0.0033]],\n               \n                        [[-0.0971]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0702]],\n               \n                        [[-0.0424]],\n               \n                        [[ 0.0066]],\n               \n                        ...,\n               \n                        [[-0.0318]],\n               \n                        [[-0.0483]],\n               \n                        [[ 0.0314]]],\n               \n               \n                       [[[ 0.0430]],\n               \n                        [[-0.0323]],\n               \n                        [[-0.0507]],\n               \n                        ...,\n               \n                        [[-0.0028]],\n               \n                        [[ 0.0115]],\n               \n                        [[ 0.0277]]],\n               \n               \n                       [[[ 0.0878]],\n               \n                        [[ 0.1698]],\n               \n                        [[-0.0557]],\n               \n                        ...,\n               \n                        [[-0.0351]],\n               \n                        [[-0.0589]],\n               \n                        [[-0.0655]]]])),\n              ('backbone.models.0.model.layer4.0.bn3.weight',\n               tensor([-0.7624, -0.8013, -0.8192,  ...,  0.8200,  0.7224,  0.7435])),\n              ('backbone.models.0.model.layer4.0.bn3.bias',\n               tensor([-0.5366, -0.5699, -0.6106,  ..., -0.3826, -0.3010, -0.5701])),\n              ('backbone.models.0.model.layer4.0.bn3.running_mean',\n               tensor([ 0.3063,  0.4393,  0.2511,  ..., -0.4656, -0.3664, -0.3399])),\n              ('backbone.models.0.model.layer4.0.bn3.running_var',\n               tensor([0.3528, 0.3924, 0.3632,  ..., 0.3441, 0.3020, 0.3373])),\n              ('backbone.models.0.model.layer4.0.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer4.0.downsample.0.weight',\n               tensor([[[[-0.0092]],\n               \n                        [[-0.0265]],\n               \n                        [[ 0.0183]],\n               \n                        ...,\n               \n                        [[-0.0013]],\n               \n                        [[-0.0601]],\n               \n                        [[ 0.0280]]],\n               \n               \n                       [[[-0.0435]],\n               \n                        [[-0.0054]],\n               \n                        [[-0.0078]],\n               \n                        ...,\n               \n                        [[ 0.0656]],\n               \n                        [[ 0.0382]],\n               \n                        [[ 0.0168]]],\n               \n               \n                       [[[ 0.0339]],\n               \n                        [[-0.0279]],\n               \n                        [[ 0.0090]],\n               \n                        ...,\n               \n                        [[-0.0324]],\n               \n                        [[ 0.0052]],\n               \n                        [[ 0.0312]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0994]],\n               \n                        [[-0.0140]],\n               \n                        [[-0.0231]],\n               \n                        ...,\n               \n                        [[ 0.0009]],\n               \n                        [[-0.0793]],\n               \n                        [[ 0.0221]]],\n               \n               \n                       [[[-0.0416]],\n               \n                        [[-0.0123]],\n               \n                        [[-0.0629]],\n               \n                        ...,\n               \n                        [[-0.0241]],\n               \n                        [[ 0.0180]],\n               \n                        [[-0.0177]]],\n               \n               \n                       [[[-0.0941]],\n               \n                        [[-0.0463]],\n               \n                        [[-0.0003]],\n               \n                        ...,\n               \n                        [[-0.0206]],\n               \n                        [[-0.0464]],\n               \n                        [[ 0.0419]]]])),\n              ('backbone.models.0.model.layer4.0.downsample.1.weight',\n               tensor([1.0927, 1.2133, 1.1744,  ..., 1.1851, 1.1950, 1.0336])),\n              ('backbone.models.0.model.layer4.0.downsample.1.bias',\n               tensor([-0.5097, -0.7312, -0.6276,  ..., -0.4984, -0.6144, -0.4290])),\n              ('backbone.models.0.model.layer4.0.downsample.1.running_mean',\n               tensor([-1.6696, -1.4732, -1.1487,  ..., -1.6667, -1.5859, -0.4103])),\n              ('backbone.models.0.model.layer4.0.downsample.1.running_var',\n               tensor([2.4216, 3.4362, 2.9067,  ..., 2.7891, 2.9100, 2.9664])),\n              ('backbone.models.0.model.layer4.0.downsample.1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer4.1.conv1.weight',\n               tensor([[[[ 0.0176]],\n               \n                        [[-0.0349]],\n               \n                        [[-0.0209]],\n               \n                        ...,\n               \n                        [[-0.0281]],\n               \n                        [[ 0.0388]],\n               \n                        [[-0.0463]]],\n               \n               \n                       [[[-0.0149]],\n               \n                        [[-0.0762]],\n               \n                        [[ 0.0024]],\n               \n                        ...,\n               \n                        [[-0.0499]],\n               \n                        [[ 0.0204]],\n               \n                        [[ 0.0118]]],\n               \n               \n                       [[[ 0.0286]],\n               \n                        [[-0.0336]],\n               \n                        [[-0.0227]],\n               \n                        ...,\n               \n                        [[ 0.0048]],\n               \n                        [[ 0.1260]],\n               \n                        [[ 0.0084]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0027]],\n               \n                        [[ 0.0075]],\n               \n                        [[ 0.0320]],\n               \n                        ...,\n               \n                        [[ 0.0152]],\n               \n                        [[ 0.0383]],\n               \n                        [[ 0.1054]]],\n               \n               \n                       [[[-0.0519]],\n               \n                        [[ 0.0666]],\n               \n                        [[-0.0183]],\n               \n                        ...,\n               \n                        [[ 0.0180]],\n               \n                        [[-0.0233]],\n               \n                        [[-0.0016]]],\n               \n               \n                       [[[-0.0189]],\n               \n                        [[ 0.0363]],\n               \n                        [[-0.0037]],\n               \n                        ...,\n               \n                        [[ 0.0257]],\n               \n                        [[ 0.0059]],\n               \n                        [[-0.0195]]]])),\n              ('backbone.models.0.model.layer4.1.bn1.weight',\n               tensor([0.9007, 0.8530, 0.8944, 0.8346, 0.8096, 0.7614, 0.8525, 0.7146, 0.9145,\n                       0.7723, 0.7900, 0.6272, 0.7218, 0.6801, 0.7876, 0.8657, 0.7530, 0.7766,\n                       0.8493, 0.8740, 0.7199, 0.7215, 0.8188, 0.6864, 0.8211, 0.8099, 0.8583,\n                       0.8475, 0.7545, 0.8210, 0.8646, 0.7928, 0.7343, 0.7879, 0.8095, 0.7733,\n                       0.8519, 0.9441, 0.7839, 0.7247, 0.6985, 0.8017, 0.6841, 0.7537, 0.8450,\n                       0.8331, 0.5621, 0.6854, 0.8289, 0.8945, 0.6873, 0.8238, 0.9279, 0.8599,\n                       0.6990, 0.7851, 0.7234, 0.6106, 0.8169, 0.7961, 0.8395, 0.8473, 0.7215,\n                       0.8441, 0.8612, 0.8765, 0.8956, 0.6939, 0.8348, 0.7427, 0.8327, 0.7378,\n                       0.7705, 0.7992, 0.7633, 0.8659, 0.8037, 0.8275, 0.7489, 0.8513, 0.7421,\n                       0.8390, 0.7212, 0.7418, 0.8510, 0.7938, 0.8210, 0.7040, 0.8455, 0.8828,\n                       0.7562, 0.7696, 0.8355, 0.7598, 0.7459, 0.6622, 0.7461, 0.9042, 0.7321,\n                       0.7429, 0.9809, 0.8487, 0.7914, 0.8043, 0.7925, 0.8094, 0.7610, 0.7637,\n                       0.9441, 0.8508, 0.7526, 0.8181, 0.9541, 0.7746, 0.7145, 0.7433, 0.8421,\n                       0.8072, 0.7874, 0.7892, 0.6832, 0.6724, 0.7760, 0.7684, 0.7899, 0.9093,\n                       0.5594, 0.8610, 0.7603, 0.7966, 0.6972, 0.8225, 0.7871, 0.8688, 0.7576,\n                       0.8074, 0.8382, 0.8231, 0.7401, 0.9994, 0.8642, 0.7862, 0.7953, 0.8915,\n                       1.0028, 0.8034, 0.8438, 0.9034, 0.7472, 0.8157, 0.7891, 0.7217, 0.6960,\n                       0.8340, 0.8513, 1.0010, 0.7811, 0.7506, 0.7900, 0.8377, 0.7844, 0.7895,\n                       0.7021, 0.7946, 0.7727, 0.6989, 0.7881, 0.7672, 0.7765, 0.8195, 0.7294,\n                       0.7950, 0.7511, 0.8057, 0.7642, 0.7719, 0.8137, 0.7010, 0.8432, 0.7747,\n                       0.6704, 0.7193, 0.7765, 0.7822, 0.7801, 0.3742, 0.8184, 0.7217, 0.7273,\n                       0.9564, 0.7054, 0.7844, 0.7406, 0.8657, 0.9943, 0.7572, 0.7913, 0.7727,\n                       0.7532, 0.9094, 0.7924, 0.7656, 0.7754, 0.7663, 0.8598, 0.7385, 0.8337,\n                       0.3220, 0.7665, 0.7999, 0.9343, 0.7209, 0.8526, 0.7581, 0.9452, 0.8157,\n                       0.8345, 0.2871, 0.7516, 0.7633, 0.7696, 0.8346, 0.7048, 0.7023, 0.7714,\n                       0.7517, 0.7720, 0.7566, 0.8704, 0.9701, 0.7850, 0.5331, 0.8203, 0.9087,\n                       0.8154, 0.8177, 0.7096, 0.8212, 0.6934, 0.8496, 0.6656, 0.9231, 0.8022,\n                       0.7878, 0.7434, 0.9597, 0.9149, 0.7262, 0.7251, 0.7771, 0.8940, 0.7055,\n                       0.7832, 0.7373, 0.7052, 0.6836, 0.6647, 0.7948, 0.7610, 0.7676, 0.7389,\n                       0.8331, 0.8533, 0.7533, 0.8108, 0.7797, 0.9041, 0.7178, 0.8674, 0.8099,\n                       0.7614, 0.8916, 0.7729, 0.8283, 0.7532, 0.7784, 0.8217, 0.7511, 0.9774,\n                       0.7727, 0.7458, 0.9124, 0.7382, 0.8724, 0.9031, 0.7598, 0.8952, 0.7593,\n                       0.8513, 0.7926, 0.4221, 0.7024, 0.7044, 0.7001, 0.8136, 0.8348, 0.8752,\n                       0.7800, 0.8361, 0.7465, 0.8215, 0.7624, 0.7182, 0.7290, 0.6848, 0.7939,\n                       0.9119, 0.7619, 0.7969, 0.7824, 0.7691, 0.7330, 0.8216, 0.8826, 0.8156,\n                       0.8100, 0.9031, 0.7479, 0.8608, 0.8549, 0.8442, 0.7673, 0.7684, 0.8452,\n                       0.9103, 0.7921, 0.8051, 0.8688, 0.7412, 0.7993, 0.7490, 0.7362, 0.8334,\n                       0.8125, 0.7238, 0.9353, 0.8006, 0.8310, 0.7525, 0.7186, 0.8598, 0.7176,\n                       0.7500, 0.8214, 0.7843, 0.7855, 0.8740, 0.8801, 0.8438, 0.7200, 0.8355,\n                       0.7608, 0.7290, 0.8196, 0.9199, 0.7298, 0.7297, 0.8337, 0.6458, 0.8065,\n                       0.8358, 0.7971, 0.8234, 0.6923, 0.8665, 0.6360, 0.7965, 0.8197, 0.7503,\n                       0.8911, 0.6849, 0.6532, 0.8003, 0.7279, 0.7771, 0.7884, 0.8625, 0.7600,\n                       0.7569, 0.7957, 0.6694, 0.5914, 0.8045, 0.7961, 0.9211, 0.7717, 0.7924,\n                       0.7091, 0.7109, 0.9606, 0.9367, 0.7594, 0.9765, 0.7236, 0.9435, 0.8331,\n                       0.8248, 0.8119, 0.7728, 0.9005, 0.8309, 0.8354, 0.8401, 0.8322, 0.8483,\n                       0.6622, 0.7877, 0.7647, 0.8331, 0.9517, 0.8373, 0.8228, 0.8498, 0.8845,\n                       0.7985, 0.7609, 0.7189, 0.9334, 0.7453, 0.7589, 0.7511, 0.7863, 0.8279,\n                       0.6571, 0.9055, 0.9689, 0.8169, 0.8202, 0.8372, 0.7661, 0.7732, 0.8114,\n                       0.8232, 0.7647, 0.8639, 0.8140, 0.7692, 0.9238, 0.7648, 0.7456, 0.8257,\n                       0.7388, 0.9148, 0.7211, 0.7041, 0.8011, 0.5304, 0.8059, 0.8965, 0.8455,\n                       0.7036, 0.7611, 0.7830, 0.8360, 0.7240, 0.7639, 0.7840, 0.7688, 0.7328,\n                       0.8099, 0.7632, 0.8286, 0.4193, 0.7645, 0.8518, 0.7945, 0.7984, 0.8360,\n                       0.7567, 0.7768, 0.7161, 0.9273, 0.8760, 0.8219, 0.8356, 0.7213, 0.8027,\n                       0.7445, 0.7990, 0.8315, 0.8690, 0.6941, 0.7973, 0.7017, 0.8923, 0.9233,\n                       0.7561, 0.7300, 0.6795, 0.8206, 0.8641, 0.8491, 0.8019, 0.7311, 0.7789,\n                       0.7262, 0.8220, 0.8153, 0.8365, 0.8545, 0.8336, 0.7672, 0.8422, 0.9624,\n                       0.6795, 0.8512, 0.7654, 0.8325, 0.7560, 0.7657, 0.7673, 0.7555])),\n              ('backbone.models.0.model.layer4.1.bn1.bias',\n               tensor([-1.0058, -1.1392, -1.0132, -0.7648, -0.8179, -0.6796, -0.8907, -0.6887,\n                       -0.9595, -0.6094, -0.7024, -0.3538, -0.5093, -0.4294, -0.6991, -0.8086,\n                       -0.6930, -0.6644, -0.9231, -0.8894, -0.5179, -0.4802, -0.7078, -0.4632,\n                       -0.6964, -0.7439, -0.8353, -0.7979, -0.5491, -0.6756, -0.9479, -0.8385,\n                       -0.5308, -0.6321, -0.8116, -0.9176, -0.7789, -0.9195, -0.6994, -0.7223,\n                       -0.5439, -0.8802, -0.5749, -0.7370, -0.8093, -0.7145, -0.0973, -0.5203,\n                       -0.7603, -0.7920, -0.4607, -0.7785, -0.9619, -0.8270, -0.5281, -0.7676,\n                       -0.5478, -0.2920, -0.7433, -0.6274, -0.7990, -0.8072, -0.6930, -0.7854,\n                       -0.7830, -0.8775, -0.9074, -0.6572, -0.9878, -0.6053, -0.8175, -0.6654,\n                       -0.6730, -0.6997, -0.5607, -0.9338, -0.7297, -0.7746, -0.6958, -0.8995,\n                       -0.6096, -0.6965, -0.5679, -0.5785, -0.8844, -0.6834, -0.7886, -0.4766,\n                       -0.7930, -1.0307, -0.5973, -0.7386, -0.7627, -0.6649, -0.6012, -0.4069,\n                       -0.6157, -0.9198, -0.6667, -0.7709, -1.1384, -0.6777, -0.6481, -0.7387,\n                       -0.6633, -0.7475, -0.6973, -0.6402, -0.9244, -0.8957, -0.5547, -0.8708,\n                       -0.9773, -0.7527, -0.5043, -0.5895, -0.8545, -0.7293, -0.5298, -0.7090,\n                       -0.5156, -0.4253, -0.6635, -0.8956, -0.6004, -1.0604, -0.0693, -0.8686,\n                       -0.4220, -0.7463, -0.5093, -0.8078, -0.7925, -0.8008, -0.6902, -0.7070,\n                       -0.7667, -0.8330, -0.5632, -1.1069, -0.8555, -0.7037, -0.8977, -1.0702,\n                       -1.2176, -0.7108, -0.7307, -1.1686, -0.6459, -0.7443, -0.6918, -0.5101,\n                       -0.5315, -0.7573, -1.0397, -1.1305, -0.6831, -0.6852, -0.6757, -0.6581,\n                       -0.6864, -0.5628, -0.5504, -0.6774, -0.9583, -0.3570, -0.8871, -0.5965,\n                       -0.5868, -0.8420, -0.6114, -0.7922, -0.6956, -0.8049, -0.6044, -0.5974,\n                       -0.8091, -0.4668, -0.8160, -0.6759, -0.3796, -0.7171, -0.6972, -0.5597,\n                       -0.6513,  0.1720, -0.8033, -0.5783, -0.6438, -1.0964, -0.4954, -0.7778,\n                       -0.6633, -0.9807, -1.2740, -0.6326, -0.6766, -0.6242, -0.5463, -0.9376,\n                       -0.8020, -0.7280, -0.7548, -0.7046, -0.9149, -0.5529, -0.7754,  0.0890,\n                       -0.7075, -0.7620, -1.0347, -0.4968, -0.9821, -0.6587, -1.0141, -0.8135,\n                       -0.7493,  0.3183, -0.5772, -0.6540, -0.7463, -0.8658, -0.4690, -0.4593,\n                       -0.6905, -0.5248, -0.6877, -0.5462, -0.9181, -1.1231, -0.8847, -0.1921,\n                       -0.7508, -1.2045, -0.7985, -0.7914, -0.4694, -0.8194, -0.5697, -0.7608,\n                       -0.4191, -0.9784, -0.7149, -0.7018, -0.6635, -1.1764, -0.9834, -0.6847,\n                       -0.7203, -0.7717, -0.9227, -0.4332, -0.8271, -0.5436, -0.5823, -0.4530,\n                       -0.4595, -0.8886, -0.6446, -0.7376, -0.5847, -0.7958, -0.9196, -0.5599,\n                       -0.7014, -0.7396, -1.0096, -0.5098, -0.7710, -0.5944, -0.6203, -0.8642,\n                       -0.6297, -0.8635, -0.5480, -0.7341, -0.6595, -0.6038, -1.0000, -0.6568,\n                       -0.5915, -1.0387, -0.7511, -0.7887, -0.9441, -0.5798, -1.0026, -0.6753,\n                       -0.7371, -0.7896,  0.1970, -0.6326, -0.6547, -0.5601, -0.9422, -0.9001,\n                       -0.9354, -0.6639, -0.7477, -0.5996, -0.8377, -0.5471, -0.5353, -0.6797,\n                       -0.3264, -0.8068, -0.8863, -0.5541, -0.7614, -0.7219, -0.6897, -0.5979,\n                       -0.8730, -0.8863, -0.7244, -0.8451, -0.9541, -0.6352, -0.8202, -0.7444,\n                       -0.8986, -0.7405, -0.5736, -0.8838, -0.9251, -0.7772, -0.6553, -0.9022,\n                       -0.6777, -0.7464, -0.5529, -0.6818, -0.7730, -0.6831, -0.7348, -1.1107,\n                       -0.6360, -0.7805, -0.7671, -0.5751, -0.9073, -0.7023, -0.6733, -0.8280,\n                       -0.6881, -0.6858, -1.0853, -0.9569, -0.7947, -0.6217, -0.7091, -0.9474,\n                       -0.4848, -0.7391, -0.8871, -0.4867, -0.5762, -0.8132, -0.3901, -0.8191,\n                       -0.7214, -0.7554, -0.8461, -0.6156, -0.8095, -0.4749, -0.7731, -0.7032,\n                       -0.5596, -0.8293, -0.6114, -0.3128, -0.6865, -0.6908, -0.6359, -0.7725,\n                       -0.7767, -0.7129, -0.6627, -0.7647, -0.4520, -0.3266, -0.7230, -0.8343,\n                       -0.9213, -0.5991, -0.6125, -0.6627, -0.4679, -1.1358, -0.9746, -0.7054,\n                       -1.2465, -0.6208, -1.1613, -1.0832, -0.7430, -0.8259, -0.7646, -1.1308,\n                       -0.7872, -0.8554, -0.8605, -0.8379, -0.8349, -0.4138, -0.6452, -0.6269,\n                       -0.6746, -1.0997, -0.7645, -0.8501, -0.7452, -1.0381, -0.7774, -0.6169,\n                       -0.5879, -1.0375, -0.6097, -0.5632, -0.6286, -0.6360, -0.7835, -0.5157,\n                       -1.0190, -1.1731, -0.7143, -0.8272, -0.7554, -0.5893, -0.8027, -0.6439,\n                       -0.8859, -0.7283, -0.8654, -0.7534, -0.6278, -0.9430, -0.7001, -0.7306,\n                       -0.9190, -0.6957, -1.0577, -0.4250, -0.5560, -0.5675,  0.0358, -0.7456,\n                       -0.9017, -0.8614, -0.5317, -0.7118, -0.9080, -0.8104, -0.6955, -0.5612,\n                       -0.6254, -0.5732, -0.5512, -0.8524, -0.6401, -0.7906,  0.3425, -0.5608,\n                       -0.8263, -0.7077, -0.8853, -0.8981, -0.7357, -0.7890, -0.6132, -1.0177,\n                       -0.7958, -0.8303, -0.4317, -0.4835, -0.6623, -0.6862, -0.7016, -0.7679,\n                       -0.8557, -0.4640, -0.7048, -0.5185, -1.1388, -0.9212, -0.7217, -0.6281,\n                       -0.4879, -0.8239, -1.0189, -0.9923, -0.8183, -0.6061, -0.8165, -0.5946,\n                       -0.6954, -0.6098, -0.8069, -0.8553, -0.6842, -0.6022, -0.9588, -1.2141,\n                       -0.4668, -0.9227, -0.7806, -0.7517, -0.6971, -0.6810, -0.8813, -0.6509])),\n              ('backbone.models.0.model.layer4.1.bn1.running_mean',\n               tensor([-2.1379, -2.8150, -2.2786, -1.7869, -1.5750, -2.3306, -1.8904, -2.3693,\n                       -2.0442, -1.8798, -1.8994, -2.5743, -2.8561, -2.1234, -1.4172, -1.4592,\n                       -1.9787, -2.1981, -1.5923, -1.6046, -2.4269, -2.0744, -2.4339, -2.0946,\n                       -1.6478, -2.3714, -1.7346, -1.8429, -2.1269, -2.4072, -2.0365, -2.1455,\n                       -1.3245, -1.8780, -2.1943, -1.8947, -2.1752, -2.2727, -2.1007, -2.3308,\n                       -1.9926, -1.4026, -2.0078, -2.0445, -2.0014, -1.9194,  1.9414, -2.1172,\n                       -2.0216, -2.3602, -2.3306, -1.4619, -1.0928, -1.8387, -1.8957, -1.9968,\n                        0.2351, -2.2000, -1.8000, -2.4179, -2.3646, -2.2040, -2.0731, -1.7526,\n                       -1.4751, -2.4037, -1.7989, -2.1974, -1.8276, -2.2093, -2.2425, -1.1709,\n                       -1.9210, -2.0723, -2.0151, -2.2355, -2.0445, -2.1777, -2.1818, -2.1036,\n                       -1.8373, -1.5924, -1.7461, -1.7462, -2.2973, -1.7198, -2.0423, -1.5454,\n                       -1.9843, -1.6286, -1.8596, -1.4907, -1.6729, -3.0060, -1.9194, -2.2425,\n                       -1.8775, -1.8261, -1.7542, -2.1108, -1.9523, -1.2855, -1.3451, -1.9646,\n                       -2.0880, -1.8938, -2.2317, -2.3722, -2.0544, -1.9657, -2.0262, -2.2523,\n                       -1.9282, -1.9929, -2.8820, -1.8036, -1.8490, -1.6615, -2.7407, -1.7718,\n                       -2.6878, -2.3936, -1.7468, -2.1477, -2.0913, -2.3501, -4.3408, -1.4880,\n                        0.8320, -2.3411, -1.7299, -1.8026, -2.0839, -2.5879, -2.1541, -1.8216,\n                       -2.2532, -1.9634, -2.0285, -1.8299, -2.2823, -1.8802, -2.4436, -1.6733,\n                       -1.7042, -2.0659, -2.1644, -2.0791, -1.4995, -1.6860, -1.8132, -2.2296,\n                       -1.5819, -1.5405, -1.6629, -1.6236, -2.1501, -1.9324, -2.0087, -1.8871,\n                       -2.6167, -1.8272, -2.0878, -2.3338, -2.9738, -2.5513, -2.7544, -2.2295,\n                       -1.9055, -2.0920, -1.7599, -2.1213, -1.8743, -2.1278, -1.9183, -1.5237,\n                       -1.3786, -2.0219, -1.9692, -2.3545, -1.8122, -2.2484, -1.7726, -1.8501,\n                       -2.4328, 14.4964, -2.2062, -2.2199, -1.7912, -2.1217, -2.0010, -1.8179,\n                       -2.2936, -2.0054, -1.8686, -2.0597, -1.4230, -1.7454, -2.0847, -1.8421,\n                       -1.9470, -2.1990, -1.9128, -1.8047, -1.5632, -2.0512, -1.3793, -9.4458,\n                       -2.5815, -1.9039, -1.8490, -2.0692, -1.9811, -2.6305, -1.9335, -2.1169,\n                       -1.4810, -8.9394, -2.0526, -1.6944, -1.7672, -1.8005, -1.8872, -2.1288,\n                       -1.8701, -1.5094, -1.6475, -1.3352, -1.6994, -1.6923, -2.1055, -8.8504,\n                       -2.3908, -1.8867, -1.8203, -1.9913, -3.0465, -2.3226, -2.5349, -1.4462,\n                       -1.8062, -1.8060, -2.5054, -1.3395, -1.4096, -2.2533, -2.1824, -2.3493,\n                       -1.5085, -2.4575, -2.3446, -2.0726, -2.3179, -1.7164, -2.0835, -2.5730,\n                       -2.3171, -1.6799, -1.5943, -2.3047, -2.3026, -1.5199, -1.6331, -1.5514,\n                       -1.7690, -1.7746, -1.8424, -2.1384, -1.4262, -2.1155, -1.1997, -2.0480,\n                       -2.1086, -2.1671, -2.1012, -2.0193, -1.6678, -2.1177, -1.7897, -1.9714,\n                       -2.0659, -1.7896, -2.0618, -2.1039, -2.2750, -1.5021, -2.1640, -2.1145,\n                       -1.9669, -1.8214, -7.1763, -2.2099, -2.0749, -2.1226, -2.2443, -2.3339,\n                       -2.2549, -1.9199, -2.8370, -1.5983, -2.2443, -1.4149, -1.9339, -1.6734,\n                       -1.2378, -2.1538, -2.1656, -2.5981, -2.1769, -2.0163, -2.1045, -2.2322,\n                       -2.1063, -1.9182, -2.2824, -1.7912, -2.2882, -2.2754, -2.0755, -1.6509,\n                       -2.0292, -2.3600, -1.7591, -2.1521, -1.7689, -1.8148, -1.9807, -2.0318,\n                       -1.5481, -2.1537, -1.9427, -2.0495, -2.0043, -2.1820, -2.0458, -1.7478,\n                       -2.0650, -2.4706, -2.1966, -1.4416, -1.8058, -2.1501, -2.2055, -2.1848,\n                       -2.0558, -1.9509, -2.1797, -2.6563, -1.9441, -1.6791, -2.1293, -2.1083,\n                       -1.6896, -2.0117, -2.0465, -2.5835, -2.4630, -2.2618, -2.4513, -2.1976,\n                       -1.8835, -2.0372, -2.3381, -2.3687, -2.0976, -1.6168, -2.2731, -1.5929,\n                       -1.9655, -1.6659, -1.9577, -2.2859, -2.1558, -1.9913, -2.2345, -1.8554,\n                       -2.0048, -2.3145, -1.8604, -1.1321, -1.7108, -1.8712, -1.5350, -2.2025,\n                       -2.2357, -2.5281, -1.8748, -1.8520, -1.9467, -2.2586, -1.9470, -1.8193,\n                       -1.4484, -2.8293, -2.1278, -1.4190, -2.0654, -1.8860, -2.1887, -1.9465,\n                       -2.2862, -2.1771, -1.8930, -2.2154, -2.0320, -2.0211, -1.6526, -2.2268,\n                        0.9013, -1.6447, -1.8479, -2.1397, -2.0689, -2.4692, -2.0979, -2.0269,\n                       -2.0028, -1.9624, -2.0360, -2.1603, -1.5057, -2.0626, -1.8190, -1.5568,\n                       -1.4620, -1.9942, -1.7064, -2.2359, -2.2665, -2.6780, -2.1630, -1.2898,\n                       -1.9172, -2.0483, -1.6275, -1.5015, -1.8995, -2.0699, -1.8206, -1.9889,\n                       -2.0828, -1.7532, -1.3880,  0.9586, -1.6115, -2.1177,  8.3857, -2.1999,\n                       -1.8136, -2.4767, -1.9005, -2.0447, -1.6419, -1.7029, -1.9355, -2.1889,\n                       -1.6987, -1.9070, -1.9162, -2.2724, -1.8000, -1.4947,  6.6082, -2.0174,\n                       -2.2132, -2.9987, -1.6396, -1.7900, -1.8938, -2.1185, -1.8584, -1.6864,\n                       -1.9248, -2.6706,  3.0471, -3.2161, -2.0824, -2.4839, -1.8159, -1.9321,\n                       -1.9952, -1.2328, -2.0626, -2.7245, -1.9419, -2.1015, -1.7512, -1.4338,\n                       -1.8530, -1.8996, -2.8912, -2.4138, -1.6832, -1.8327, -2.2875, -2.1032,\n                       -1.6266, -3.1561, -2.0174, -1.6783, -2.3727, -1.7805, -2.0852, -2.1663,\n                       -1.8238, -1.9673, -2.5353, -2.2002, -2.2522, -2.1956, -3.9275, -1.9242])),\n              ('backbone.models.0.model.layer4.1.bn1.running_var',\n               tensor([2.8724, 2.3701, 2.5952, 3.0986, 2.6553, 3.0303, 2.7101, 2.4846, 2.8707,\n                       3.7534, 2.8989, 4.0770, 4.3205, 2.9430, 3.0997, 2.7291, 3.1603, 2.8028,\n                       2.6708, 2.8943, 2.9620, 3.8250, 4.3471, 3.2640, 3.0207, 2.7577, 3.4401,\n                       3.0536, 3.3878, 3.4557, 2.7760, 2.5580, 3.9492, 3.1616, 3.0700, 1.7164,\n                       2.9605, 3.2412, 3.8294, 2.0544, 3.5092, 2.5875, 3.2905, 2.5912, 2.5173,\n                       3.0858, 4.9073, 3.4438, 3.9463, 3.6199, 3.4503, 3.1242, 3.1475, 2.9282,\n                       3.0058, 2.7230, 3.4963, 3.5616, 3.3520, 4.4407, 2.8135, 2.9653, 2.9188,\n                       2.7452, 2.8304, 3.4279, 3.0164, 3.1915, 1.8421, 3.2178, 3.3603, 3.9649,\n                       3.5135, 2.9346, 4.2665, 3.5247, 3.6577, 3.1596, 2.9486, 3.1099, 2.9397,\n                       3.2954, 2.8185, 3.2406, 3.3382, 3.3588, 3.2743, 3.4728, 3.3524, 2.2991,\n                       3.5872, 2.8669, 2.8102, 3.7201, 3.4609, 3.5296, 2.8260, 3.5967, 2.4798,\n                       2.3346, 2.9492, 4.2200, 3.3326, 3.2009, 3.3243, 2.7660, 3.0731, 3.4101,\n                       3.3581, 3.0802, 3.8110, 2.8520, 2.7280, 3.1381, 4.3849, 2.7254, 2.8301,\n                       2.9149, 3.8127, 3.5675, 3.1457, 4.0145, 3.4803, 3.0098, 3.6399, 2.5948,\n                       3.9370, 2.6991, 5.9610, 3.2031, 3.0553, 3.1306, 2.2587, 3.0153, 3.1098,\n                       3.2728, 3.5283, 3.0096, 3.8995, 3.3525, 2.9605, 3.8007, 3.2308, 1.9021,\n                       2.8047, 3.2733, 3.1302, 2.1320, 2.8330, 2.8441, 2.7871, 3.1310, 2.8694,\n                       3.2257, 2.2985, 2.6085, 3.3905, 4.0385, 3.9937, 3.4385, 3.0243, 3.5953,\n                       3.0262, 2.7300, 1.9017, 3.7741, 3.9517, 2.9228, 3.5391, 2.1071, 3.0470,\n                       3.4062, 2.5019, 3.5645, 3.6365, 3.4157, 3.2580, 3.3497, 2.8012, 3.6571,\n                       3.4053, 3.2465, 2.7865, 3.2081, 2.6754, 6.3420, 3.8355, 3.3898, 2.6506,\n                       2.6854, 2.9385, 2.8199, 3.2718, 2.5738, 1.7154, 3.1866, 2.6716, 3.1131,\n                       3.3257, 3.7592, 3.2192, 2.8992, 2.6455, 2.6304, 2.4213, 3.1884, 2.4065,\n                       3.8612, 2.4481, 3.2289, 2.4494, 3.2823, 2.1934, 3.4635, 2.9072, 3.1095,\n                       3.2954, 1.8492, 3.2249, 2.8271, 2.7451, 2.9714, 2.9305, 3.5378, 3.0492,\n                       3.1861, 3.4262, 2.4645, 2.1499, 2.8142, 2.4933, 4.9397, 3.8352, 1.8931,\n                       2.5155, 3.1648, 5.2571, 2.8944, 2.9688, 3.4195, 3.3887, 2.2509, 2.6755,\n                       2.7179, 3.9862, 2.1361, 3.0597, 3.0620, 2.8428, 3.1749, 3.3544, 4.1517,\n                       2.6508, 3.2285, 2.9233, 3.4141, 3.2348, 2.6042, 2.8392, 3.0282, 4.6992,\n                       3.4339, 3.1719, 3.4613, 4.0925, 2.6783, 2.0068, 3.1322, 3.0401, 3.8071,\n                       3.0073, 3.7007, 3.1192, 3.3407, 4.8724, 3.2219, 3.7518, 2.5374, 2.7593,\n                       3.0822, 3.2110, 2.7773, 2.7424, 3.7825, 2.8930, 3.0901, 2.5427, 3.5537,\n                       3.6159, 2.5985, 2.3721, 3.2704, 3.0978, 3.0492, 3.1404, 2.4791, 3.0818,\n                       2.9752, 3.7072, 2.9098, 3.2850, 3.2039, 3.4365, 2.5075, 3.8826, 2.4411,\n                       3.6581, 3.9915, 3.1040, 2.9307, 3.2556, 3.3956, 2.8585, 3.2262, 2.5010,\n                       3.9556, 3.2535, 3.5560, 3.1932, 2.9584, 3.0791, 2.5840, 4.0269, 2.8325,\n                       3.0203, 3.2906, 3.4180, 2.7971, 3.2138, 3.4546, 3.6125, 3.7708, 3.2929,\n                       3.4747, 2.2816, 2.0842, 4.0799, 3.3314, 3.0768, 2.5101, 2.3680, 2.4763,\n                       3.2806, 3.1756, 2.7234, 2.9016, 2.6956, 3.0714, 3.3313, 2.7875, 3.0885,\n                       1.9694, 3.5316, 3.2909, 4.2907, 2.9779, 3.0477, 3.2970, 3.2183, 4.0931,\n                       3.3947, 3.1219, 2.9646, 3.8434, 3.3953, 2.8166, 2.9962, 2.7819, 3.4697,\n                       3.3482, 2.4643, 3.9460, 2.7512, 2.6943, 3.4864, 2.9686, 3.3515, 3.2060,\n                       2.6131, 3.4195, 3.4903, 3.9925, 3.1268, 3.0670, 3.8867, 4.4410, 3.2742,\n                       2.7676, 3.3734, 1.8906, 3.4569, 3.6063, 2.2101, 3.5115, 2.3597, 1.8701,\n                       2.7588, 3.3655, 2.7388, 1.8318, 3.0090, 2.6199, 3.3456, 2.9720, 3.4269,\n                       3.0692, 3.7038, 3.0506, 4.5136, 2.0806, 2.4966, 2.7474, 3.1505, 2.5938,\n                       2.7293, 3.6925, 3.4096, 2.4567, 2.7377, 4.1072, 3.4775, 3.7914, 3.0356,\n                       3.3313, 2.1171, 2.5727, 3.1061, 3.9435, 3.1486, 4.1306, 3.6902, 4.1882,\n                       2.2850, 3.0196, 3.5426, 3.6951, 2.9331, 2.2672, 3.5008, 2.6945, 2.4936,\n                       2.4672, 2.5384, 3.1699, 2.4388, 3.5356, 6.4566, 3.2377, 2.8824, 3.5685,\n                       3.1355, 2.6113, 2.1039, 2.6703, 3.1988, 3.6755, 3.5619, 3.3830, 3.3106,\n                       2.6461, 3.1832, 3.5832, 3.5262, 3.3844, 2.7709, 3.7011, 3.3993, 2.9324,\n                       2.9900, 2.4215, 3.1236, 2.8816, 3.1247, 3.2430, 8.1690, 3.0606, 3.9942,\n                       2.3144, 3.2771, 2.9240, 3.0598, 3.9084, 2.6162, 3.7373, 2.0140, 2.9266,\n                       2.9655, 3.0286, 3.4301, 2.8835, 3.2186, 2.0800, 3.2202, 2.8701, 2.4050,\n                       3.3386, 3.5722, 4.1257, 3.3858, 2.7093, 3.3480, 3.6452, 2.3581, 2.1020,\n                       3.5197, 2.8580, 3.0199, 3.3853, 2.9451, 3.5726, 4.0162, 2.7390])),\n              ('backbone.models.0.model.layer4.1.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer4.1.conv2.weight',\n               tensor([[[[-1.3663e-02, -4.7616e-02,  2.1670e-03],\n                         [-4.2239e-02, -1.2070e-01, -4.9109e-02],\n                         [-7.3599e-03, -4.9198e-02, -1.1306e-02]],\n               \n                        [[ 3.4454e-02,  3.7228e-02,  1.6117e-02],\n                         [-1.2321e-02,  4.7937e-02,  2.7608e-03],\n                         [ 1.9934e-02,  9.2818e-02,  2.8747e-02]],\n               \n                        [[ 9.2571e-03,  2.4646e-02,  1.6102e-02],\n                         [ 4.0002e-03,  2.8846e-02, -2.0650e-04],\n                         [ 1.7882e-02,  3.4528e-02,  1.5679e-02]],\n               \n                        ...,\n               \n                        [[-2.8352e-02, -4.9500e-03, -3.8587e-02],\n                         [-1.7767e-02, -2.0652e-02, -2.2830e-02],\n                         [-2.6930e-02, -2.0233e-02, -8.1086e-03]],\n               \n                        [[-4.3188e-02, -5.4371e-02, -4.5112e-02],\n                         [-4.7642e-02, -2.1968e-02, -5.0621e-02],\n                         [-3.7287e-02, -1.4977e-02, -1.7455e-02]],\n               \n                        [[ 3.0201e-03, -1.6010e-02, -1.1414e-03],\n                         [-2.7423e-02,  8.2536e-03,  1.0654e-02],\n                         [-2.6800e-02, -3.2877e-02, -2.5473e-02]]],\n               \n               \n                       [[[-3.6527e-03, -8.8592e-02, -3.6790e-02],\n                         [ 4.5283e-03, -1.6068e-02, -7.0527e-03],\n                         [ 2.6564e-02,  7.1168e-02,  1.6277e-02]],\n               \n                        [[ 4.1321e-02,  7.2179e-02,  2.5320e-02],\n                         [-2.0516e-02,  5.9048e-03, -1.0160e-02],\n                         [-2.0824e-02, -3.2948e-02, -1.5381e-02]],\n               \n                        [[-2.4206e-02, -2.3274e-02, -2.6489e-02],\n                         [-3.8398e-02,  5.6139e-03,  1.7188e-03],\n                         [-3.4111e-04,  1.8373e-02,  3.7698e-02]],\n               \n                        ...,\n               \n                        [[ 1.8208e-02, -2.1158e-02, -1.1017e-02],\n                         [ 1.8292e-02, -2.1818e-02,  1.7601e-02],\n                         [ 1.7715e-02,  5.8518e-02,  3.2497e-02]],\n               \n                        [[-1.8022e-02, -9.9016e-03, -9.5906e-03],\n                         [ 1.5965e-03, -3.9366e-02,  1.1907e-02],\n                         [ 1.4027e-02,  4.2892e-02,  2.5099e-02]],\n               \n                        [[ 3.0696e-03, -1.9521e-03, -4.6649e-03],\n                         [ 1.3682e-02,  7.6056e-02,  1.6691e-02],\n                         [-1.9618e-02, -4.6164e-02, -1.3308e-02]]],\n               \n               \n                       [[[ 2.5393e-03, -2.0958e-02, -8.6202e-03],\n                         [-1.0461e-02, -5.2316e-02, -9.0964e-03],\n                         [-1.6659e-02, -3.8706e-02, -9.4885e-03]],\n               \n                        [[ 2.2994e-02,  1.3015e-03,  1.3916e-03],\n                         [-4.2627e-02, -9.2589e-02, -4.0680e-02],\n                         [-6.2890e-02, -1.0198e-01, -5.9228e-02]],\n               \n                        [[-4.2711e-03, -2.5422e-02, -3.0775e-03],\n                         [ 8.8090e-03,  4.0710e-02,  9.3942e-03],\n                         [ 2.3377e-02,  2.1105e-02, -8.9093e-03]],\n               \n                        ...,\n               \n                        [[-1.4555e-02, -2.2270e-02,  2.8967e-03],\n                         [-1.6137e-03,  2.1974e-04,  4.7383e-03],\n                         [-1.9053e-02, -1.5070e-02, -1.2467e-03]],\n               \n                        [[ 1.2665e-02,  5.1509e-04,  1.3107e-02],\n                         [-1.6844e-02, -6.2317e-02, -3.5553e-02],\n                         [ 9.7971e-03,  1.3514e-03, -5.2209e-04]],\n               \n                        [[ 1.5527e-03,  3.0660e-02, -1.0956e-02],\n                         [-1.3637e-02,  7.2338e-03, -5.2761e-03],\n                         [-8.3310e-03,  2.3722e-02, -9.0074e-03]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 2.6249e-02,  2.1598e-03,  7.4292e-04],\n                         [ 6.0059e-05, -2.8299e-02, -1.5144e-02],\n                         [ 1.4519e-02,  1.3630e-02,  2.9709e-02]],\n               \n                        [[-1.2863e-02, -4.3934e-02, -1.1064e-02],\n                         [-1.5052e-02, -8.9619e-02, -1.1198e-02],\n                         [-1.5720e-02, -7.3948e-02, -1.8406e-02]],\n               \n                        [[-1.0685e-02, -2.5002e-03,  4.7231e-03],\n                         [ 3.1081e-03, -2.0368e-03, -1.1305e-02],\n                         [-4.1441e-03,  1.1771e-02,  1.0130e-02]],\n               \n                        ...,\n               \n                        [[ 1.3295e-03,  9.1967e-03,  2.3474e-03],\n                         [ 1.9105e-02, -1.2102e-03,  6.9536e-03],\n                         [-6.5845e-03, -3.0372e-02, -1.7279e-02]],\n               \n                        [[-2.3968e-02, -4.9874e-02, -3.0525e-02],\n                         [-1.4180e-02, -4.6838e-02, -3.8122e-02],\n                         [ 3.8502e-04,  6.2917e-03, -2.1217e-02]],\n               \n                        [[ 2.1555e-02,  7.8528e-02,  7.5179e-03],\n                         [-1.2211e-02, -2.4098e-02, -2.6919e-03],\n                         [-3.8878e-03, -1.4510e-02, -2.0782e-02]]],\n               \n               \n                       [[[ 1.2549e-02,  6.3465e-02, -6.9627e-03],\n                         [ 5.8446e-03,  8.6316e-02,  1.3683e-03],\n                         [-1.5868e-02, -4.4261e-03, -1.0403e-02]],\n               \n                        [[-3.1990e-02, -3.2437e-02, -1.2511e-02],\n                         [-2.1059e-02, -3.3250e-02, -1.3539e-02],\n                         [-2.2136e-02,  2.9023e-03, -1.1938e-02]],\n               \n                        [[ 1.0654e-02,  2.5299e-02,  4.2708e-03],\n                         [-1.7904e-02, -1.9064e-02,  2.2159e-03],\n                         [-1.3747e-02, -1.8134e-02, -1.2592e-02]],\n               \n                        ...,\n               \n                        [[ 2.2272e-02,  1.5771e-02,  8.9079e-03],\n                         [-1.7204e-02, -2.5888e-02, -1.2292e-02],\n                         [ 6.9698e-04, -1.7771e-02, -5.1995e-03]],\n               \n                        [[ 3.7933e-03, -3.2013e-02, -1.6810e-02],\n                         [-2.2040e-02, -1.2892e-02, -2.6896e-02],\n                         [ 2.1911e-02, -4.4476e-03, -9.9821e-03]],\n               \n                        [[ 1.5611e-02, -2.0008e-02,  2.1879e-03],\n                         [-3.0433e-03,  3.3015e-02,  1.9069e-02],\n                         [ 1.8950e-02,  5.4763e-02,  3.2780e-02]]],\n               \n               \n                       [[[ 4.7367e-03, -2.1048e-02, -2.0655e-02],\n                         [ 8.3703e-03, -4.7273e-02, -2.3061e-02],\n                         [ 1.4486e-02, -2.3606e-02,  6.8134e-03]],\n               \n                        [[-2.5092e-02, -7.6705e-02, -4.8837e-02],\n                         [ 3.8470e-03, -2.3874e-02, -3.3209e-02],\n                         [ 3.7975e-03, -3.1953e-02, -1.8797e-02]],\n               \n                        [[ 9.4051e-03,  5.5902e-02,  1.4458e-02],\n                         [ 1.1552e-03,  7.7858e-02,  4.9533e-03],\n                         [-1.4977e-02, -3.1070e-02, -3.2034e-02]],\n               \n                        ...,\n               \n                        [[ 9.8008e-03,  1.2053e-02,  6.3828e-03],\n                         [ 2.0768e-02,  7.2729e-02,  2.7089e-02],\n                         [ 3.9711e-03,  6.2784e-04, -3.8791e-03]],\n               \n                        [[ 5.6324e-03, -1.7531e-02, -1.4237e-02],\n                         [ 2.5802e-02,  4.7006e-02,  2.6693e-03],\n                         [ 4.5322e-04, -4.3586e-03,  1.5820e-02]],\n               \n                        [[-8.9932e-04,  6.4916e-02,  1.6379e-02],\n                         [ 7.0526e-03,  1.5946e-02, -2.1794e-02],\n                         [-4.4877e-03, -1.0184e-02, -1.9013e-02]]]])),\n              ('backbone.models.0.model.layer4.1.bn2.weight',\n               tensor([0.6102, 0.5760, 0.8124, 0.9450, 0.8939, 0.8372, 0.8609, 0.7559, 0.8467,\n                       0.8658, 0.7802, 0.5299, 0.9096, 0.6386, 0.8136, 0.7897, 0.7493, 0.7616,\n                       0.8942, 0.8063, 0.8130, 0.7877, 0.8395, 0.5843, 0.6408, 0.6648, 0.7448,\n                       0.8325, 0.7546, 0.7738, 0.9636, 0.7698, 0.5672, 0.7431, 0.7044, 0.8091,\n                       0.7219, 0.6189, 0.9277, 0.8254, 0.8767, 0.6912, 0.6459, 0.8861, 0.8267,\n                       0.6785, 0.9253, 0.9186, 0.8059, 0.7199, 0.8951, 0.7960, 0.8147, 0.5969,\n                       0.7091, 0.7425, 0.9373, 0.6991, 0.5999, 0.7228, 0.7894, 0.7433, 0.9305,\n                       0.8498, 0.8703, 0.8489, 0.9335, 0.8293, 0.7781, 0.6955, 0.7027, 0.9023,\n                       0.7144, 0.6611, 0.8916, 0.8115, 0.8238, 0.9009, 0.6640, 0.8633, 0.8729,\n                       0.9157, 0.7039, 0.9218, 0.6867, 0.6195, 0.9479, 0.9010, 0.8915, 0.8072,\n                       0.7747, 0.7944, 0.6801, 0.8503, 0.8105, 0.8533, 0.8979, 0.7502, 0.6460,\n                       1.0402, 0.7892, 0.8506, 0.8615, 0.7896, 0.7923, 0.8088, 0.9237, 0.7523,\n                       0.7706, 0.8665, 0.8546, 0.7053, 0.6157, 0.9205, 0.7559, 0.7209, 0.9000,\n                       0.7570, 0.7922, 0.7967, 0.8056, 0.7864, 0.8657, 0.7173, 0.8393, 0.8817,\n                       0.7666, 0.8678, 0.7832, 0.8008, 0.6418, 0.8529, 0.8936, 0.7674, 0.7110,\n                       0.8808, 0.8512, 0.7149, 0.7587, 0.9619, 0.6342, 0.5739, 0.7770, 0.8618,\n                       0.7166, 0.8558, 0.8693, 0.8891, 0.8422, 0.6828, 0.9439, 0.8376, 0.7639,\n                       0.5280, 0.8330, 0.9429, 0.9024, 0.8224, 0.8104, 0.6022, 0.8697, 0.7306,\n                       0.7081, 0.8702, 0.8821, 0.7225, 0.8441, 0.8045, 0.7222, 0.7976, 0.9366,\n                       0.7660, 0.7407, 0.7569, 0.8096, 0.7288, 0.7124, 0.7835, 0.8201, 0.8198,\n                       0.6790, 0.9597, 0.8836, 0.6527, 0.5712, 0.8581, 0.8296, 0.9079, 0.5784,\n                       0.6170, 0.8298, 0.3698, 0.6373, 0.7598, 0.9449, 0.7675, 1.2158, 0.6109,\n                       0.7388, 0.8169, 0.7942, 0.7366, 0.7875, 0.8520, 0.5824, 0.4937, 0.8979,\n                       0.7821, 0.8967, 0.7728, 0.9031, 0.8886, 0.7918, 0.8864, 0.8156, 0.7171,\n                       0.8011, 0.7791, 0.7290, 0.8275, 0.8783, 0.6411, 0.7447, 0.6903, 0.9049,\n                       0.8036, 0.4286, 0.4386, 0.9030, 0.7478, 0.6791, 0.9000, 0.6542, 0.7170,\n                       0.6664, 0.7487, 0.7550, 0.9935, 0.8851, 0.8090, 0.8008, 0.7593, 0.7153,\n                       0.7689, 0.8133, 0.7681, 0.4989, 0.9009, 0.8280, 0.7904, 0.9061, 0.8920,\n                       0.8084, 0.8955, 0.7094, 0.6934, 0.8302, 0.8065, 0.8550, 0.7846, 0.8382,\n                       0.7361, 0.7481, 0.8243, 0.5767, 0.7186, 0.9046, 0.6443, 0.6320, 0.8623,\n                       0.7992, 0.6775, 0.8646, 0.6322, 0.8767, 0.7704, 0.8649, 0.9313, 0.8769,\n                       0.7472, 0.8887, 0.8602, 0.6450, 0.7756, 0.7078, 0.8823, 0.9148, 0.9378,\n                       0.8268, 0.6892, 0.7908, 0.8181, 0.6704, 0.3891, 0.7062, 0.6471, 0.8110,\n                       0.7921, 0.8305, 0.7750, 0.7691, 0.7630, 0.8523, 0.6110, 0.7599, 0.6350,\n                       0.5679, 0.7617, 0.8497, 0.8350, 0.8905, 0.6552, 0.6257, 0.4374, 0.8477,\n                       0.8563, 0.8264, 0.8641, 0.8388, 0.7452, 0.8657, 0.8181, 0.7280, 0.9148,\n                       0.6246, 0.8967, 0.8451, 0.8575, 0.7857, 0.7345, 0.6042, 0.7422, 0.8307,\n                       0.6086, 0.7215, 0.8986, 0.9493, 0.7688, 0.8749, 0.8623, 0.7637, 0.8146,\n                       0.8841, 0.8497, 0.9136, 0.8045, 0.7353, 0.7786, 1.0640, 0.8400, 0.7546,\n                       0.7702, 0.7634, 0.7695, 0.8170, 0.7551, 0.8307, 0.8930, 0.6891, 0.7546,\n                       0.9182, 0.8510, 0.6412, 0.8400, 0.8609, 0.7835, 0.7795, 0.7475, 0.7185,\n                       0.7477, 0.7009, 0.8418, 0.6528, 0.8889, 0.8439, 0.5930, 0.8628, 0.7815,\n                       0.9816, 0.6993, 0.9048, 0.8142, 0.8364, 0.5286, 0.8755, 0.8489, 0.8028,\n                       0.8410, 0.6053, 0.7689, 0.9107, 0.9153, 0.6596, 0.8558, 0.7918, 0.8802,\n                       0.6415, 0.6208, 0.7217, 0.8270, 0.8643, 0.6941, 0.8890, 0.8036, 0.7195,\n                       0.7556, 0.8522, 0.7286, 0.8588, 0.5341, 0.5863, 0.7593, 0.7771, 0.8437,\n                       0.8921, 0.6328, 0.7327, 0.7014, 0.8805, 0.8428, 0.7864, 0.8305, 0.6874,\n                       0.8405, 0.9123, 0.9010, 0.9356, 0.4123, 0.8566, 0.5393, 0.8578, 0.8327,\n                       0.7588, 0.7328, 0.9081, 0.7213, 0.8521, 0.8804, 0.9672, 0.5086, 0.6285,\n                       0.9050, 0.7355, 0.9030, 0.6792, 0.6671, 0.6508, 0.6793, 0.6125, 0.6729,\n                       0.6399, 0.7346, 0.9138, 0.6612, 0.5915, 0.5234, 0.6315, 0.7347, 0.8338,\n                       0.7256, 0.7062, 0.6221, 0.7153, 0.7945, 0.7479, 0.7486, 0.8735, 0.6734,\n                       0.5110, 0.7275, 0.9093, 0.7622, 0.7302, 0.9970, 0.8847, 0.9013, 0.8381,\n                       0.8150, 0.8826, 0.7738, 0.7824, 0.9119, 0.7881, 1.1439, 0.7720, 0.8335,\n                       0.7095, 0.8358, 0.6681, 0.7499, 0.8890, 0.6895, 0.7829, 0.6614, 0.9474,\n                       0.8332, 0.8216, 0.7997, 0.8620, 0.7876, 0.7834, 0.8908, 0.7859, 0.8688,\n                       0.6215, 0.6851, 0.9200, 0.8853, 0.5941, 0.8300, 0.8503, 0.7248])),\n              ('backbone.models.0.model.layer4.1.bn2.bias',\n               tensor([-0.3143, -0.2645, -0.7631, -1.1856, -0.9465, -0.8973, -0.7917, -0.5856,\n                       -0.9463, -1.2151, -0.6935, -0.1257, -1.1555, -0.3887, -0.7917, -0.6732,\n                       -0.6178, -0.8443, -1.1263, -0.7409, -0.9206, -0.6860, -0.8509, -0.2628,\n                       -0.2553, -0.3486, -0.6113, -0.7282, -0.6028, -0.7168, -1.0605, -0.4321,\n                       -0.2622, -0.5756, -0.4709, -0.9341, -0.5144, -0.3196, -0.8722, -1.0230,\n                       -0.8830, -0.3276, -0.3985, -0.8474, -0.7191, -0.3853, -1.0384, -1.1071,\n                       -0.8107, -0.5831, -0.9671, -0.7616, -0.6361, -0.2120, -0.5452, -0.4823,\n                       -1.0840, -0.5716, -0.2859, -0.4873, -0.6750, -0.4732, -1.1190, -0.9127,\n                       -0.9624, -0.9909, -0.9836, -0.8733, -0.6633, -0.4699, -0.4719, -1.1697,\n                       -0.5229, -0.4516, -1.0836, -0.7819, -0.7484, -0.9169, -0.4125, -0.9159,\n                       -0.9105, -1.0181, -0.4794, -1.0572, -0.4072, -0.3965, -1.0601, -1.0082,\n                       -0.9815, -0.6024, -0.7247, -0.7866, -0.4467, -0.9229, -0.6949, -0.9443,\n                       -1.2521, -0.5591, -0.4317, -1.3155, -0.8585, -0.7956, -0.8534, -0.7358,\n                       -0.7412, -0.4622, -1.0422, -0.5763, -0.6793, -0.9322, -0.8781, -0.5754,\n                       -0.3625, -0.9786, -0.8055, -0.4334, -0.8560, -0.6415, -0.7300, -0.7429,\n                       -0.8641, -0.5183, -0.7622, -0.4383, -1.0408, -0.8309, -0.8945, -0.9720,\n                       -0.6519, -0.8336, -0.3543, -0.8349, -0.9068, -0.6312, -0.5923, -0.8431,\n                       -0.8413, -0.3238, -0.5610, -1.0723, -0.3624, -0.1765, -0.6875, -0.9738,\n                       -0.6230, -0.8795, -0.9249, -1.1000, -1.1569, -0.4206, -1.0148, -0.7762,\n                       -0.6811, -0.0097, -0.7734, -1.3369, -1.0460, -0.8556, -0.7449, -0.2561,\n                       -0.9244, -0.5768, -0.5098, -0.8377, -0.9194, -0.5709, -0.8060, -0.6600,\n                       -0.5215, -0.7223, -1.0079, -0.5526, -0.5711, -0.3673, -0.9843, -0.5408,\n                       -0.4545, -0.7630, -0.9043, -0.7966, -0.3678, -1.1263, -0.9540, -0.3202,\n                       -0.2130, -0.9605, -0.7562, -0.9900, -0.1774, -0.2527, -0.8156,  1.3007,\n                       -0.3531, -0.5213, -1.0756, -0.5996, -1.0082, -0.2983, -0.6523, -0.7319,\n                       -0.7022, -0.6041, -0.5634, -0.9267, -0.1892, -0.0333, -1.0272, -0.6228,\n                       -1.7790, -0.6854, -1.0190, -0.9040, -0.5229, -0.9047, -0.7978, -0.4520,\n                       -0.7560, -0.6565, -0.5517, -0.5015, -1.0090, -0.3358, -0.4493, -0.4196,\n                       -1.1218, -0.6377,  0.1567,  0.1522, -0.8910, -0.5494, -0.4055, -0.9811,\n                       -0.3196, -0.4114, -0.3699, -0.7020, -0.6494, -1.2667, -0.8122, -0.6964,\n                       -0.8690, -0.6908, -0.4878, -0.6320, -0.7551, -0.6992, -0.0653, -1.4786,\n                       -0.6983, -0.5314, -0.8497, -0.9546, -0.8214, -0.8936, -0.5175, -0.2172,\n                       -0.6236, -0.8748, -0.9156, -0.7005, -0.8087, -0.5742, -0.5433, -0.9380,\n                       -0.2567, -0.4514, -0.6534, -0.3280, -0.3234, -0.8498, -0.7293, -0.4000,\n                       -0.7796, -0.3247, -0.8674, -0.7311, -1.1000, -1.2001, -0.9172, -0.5640,\n                       -1.1675, -0.9784, -0.4484, -0.6804, -0.5634, -0.8772, -0.9161, -1.1584,\n                       -0.6860, -0.4744, -0.7650, -0.8321, -0.5679,  0.1299, -0.4285, -0.3550,\n                       -0.7452, -0.6866, -0.8181, -0.6165, -0.7729, -0.6053, -0.9159, -0.2336,\n                       -0.5784, -0.3269, -0.2454, -0.5601, -0.7303, -0.8729, -0.9097, -0.4217,\n                       -0.3333,  0.0718, -0.9487, -0.9713, -0.7790, -0.9570, -0.9263, -0.4557,\n                       -1.0050, -0.7400, -0.4010, -0.9549, -0.3262, -0.9682, -1.0716, -1.0833,\n                       -0.6461, -0.6053, -0.3165, -0.8732, -0.3327, -0.2556, -0.6814, -0.8782,\n                       -0.9296, -0.4306, -0.8475, -0.7635, -0.5691, -0.7929, -1.0142, -0.8193,\n                       -1.0355, -0.8954, -0.5174, -0.7633, -1.2073, -0.8075, -0.6286, -0.9597,\n                       -0.5123, -0.6784, -0.8426, -0.6782, -0.7397, -1.0125, -0.4540, -0.6415,\n                       -1.1786, -0.9257, -0.3477, -0.8619, -0.9217, -0.7138, -0.6510, -0.6006,\n                       -0.5319, -0.4605, -0.5947, -0.8496, -0.3677, -0.8722, -0.7714, -0.2264,\n                       -0.8682, -0.8031, -1.1819, -0.4255, -1.0066, -0.6516, -0.8339, -0.1658,\n                       -0.8220, -0.9176, -0.6837, -0.7206, -0.2647, -0.5278, -1.0551, -0.9330,\n                       -0.3354, -0.8561, -0.7698, -1.1116, -0.3913, -0.4573, -0.5207, -0.8988,\n                       -0.8582, -0.5280, -1.1691, -0.8099, -0.4836, -0.5693, -0.9157, -0.5485,\n                       -0.7569, -0.1390, -0.2675, -0.5366, -0.8515, -0.9015, -1.0184, -0.3085,\n                       -0.6186, -0.5812, -0.8710, -0.8811, -0.5889, -0.6468, -0.3622, -0.8659,\n                       -1.2074, -0.8561, -1.1070,  0.1630, -0.9682, -0.0467, -0.9432, -0.8693,\n                       -0.5885, -0.5989, -1.1071, -0.5073, -0.7791, -0.8343, -1.0305, -0.1295,\n                       -0.2856, -1.1590, -0.5999, -1.0027, -0.4692, -0.3984, -0.3567, -0.4371,\n                       -0.2738, -0.4014, -0.2847, -0.4877, -0.9079, -0.3169, -0.2772, -0.1246,\n                       -0.3094, -0.5267, -0.7412, -0.5535, -0.4732, -0.2969, -0.4292, -0.6492,\n                       -0.5379, -0.4516, -0.9362, -0.4563, -0.1248, -0.5106, -1.0211, -0.5796,\n                       -0.6994, -1.2155, -1.2029, -0.8504, -0.8777, -0.8198, -1.2087, -0.7021,\n                       -0.8379, -0.9170, -0.7953, -1.1510, -0.6071, -1.1585, -0.5078, -1.0039,\n                       -0.4722, -0.6017, -1.0200, -0.4003, -0.6499, -0.4686, -1.1994, -0.7570,\n                       -0.7889, -0.7647, -1.0835, -0.8100, -0.6077, -1.0031, -0.7151, -0.9797,\n                       -0.2929, -0.4883, -1.0632, -1.0239, -0.2985, -0.8582, -0.9695, -0.5336])),\n              ('backbone.models.0.model.layer4.1.bn2.running_mean',\n               tensor([-0.2467, -0.3508, -0.4807, -0.5345, -0.4656, -0.3069, -0.4194, -0.2398,\n                       -0.2858, -0.4314, -0.3877, -0.0520, -0.2320, -0.2016, -0.5077, -0.4614,\n                       -0.3329, -0.2820, -0.1005, -0.4116, -0.2311, -0.5926, -0.2055, -0.3030,\n                       -0.2237, -0.4117, -0.3492, -0.3063, -0.3759, -0.3806, -0.1878, -0.2561,\n                       -0.3276, -0.2958, -0.3263, -0.6732, -0.5576, -0.2283, -0.4184, -0.2289,\n                       -0.3883, -0.2346, -0.4074, -0.3913, -0.2008, -0.3413, -0.2816, -0.2224,\n                       -0.4297, -0.1943, -0.4785, -0.3055, -0.3767,  0.2307, -0.2990, -0.3128,\n                       -0.4789, -0.2876, -0.0828, -0.4369, -0.3118, -0.3293, -0.4110, -0.4747,\n                       -0.3499, -0.4303, -0.1495, -0.3397, -0.1554, -0.2088, -0.3599, -0.3460,\n                       -0.2994, -0.3414, -0.3719, -0.5366, -0.3033, -0.5476, -0.3544, -0.3629,\n                       -0.2378, -0.2999, -0.4425, -0.3008, -0.6106, -0.4703, -0.5531, -0.5180,\n                       -0.4222, -0.3184, -0.3472, -0.3933, -0.1425, -0.4883, -0.3377, -0.3251,\n                       -0.5841, -0.1183, -0.1325,  0.2106, -0.2150, -0.3598, -0.3232, -0.3482,\n                       -0.3223, -0.1696, -0.4231, -0.3614, -0.2578, -0.4696, -0.5004, -0.5392,\n                       -0.5714, -0.3745, -0.2649, -0.3057, -0.3907, -0.3365, -0.1599, -0.2889,\n                       -0.2144, -0.2749, -0.4099, -0.4236,  0.0855, -0.4131, -0.2498, -0.5192,\n                       -0.4447, -0.3468, -0.2951, -0.4248, -0.3635, -0.3712, -0.1584, -0.4550,\n                       -0.2796, -0.1192, -0.4272, -0.4849, -0.2635, -0.3648, -0.5028, -0.3038,\n                       -0.3962, -0.4109, -0.2877, -0.5709, -0.6046, -0.3563, -0.5524, -0.3343,\n                       -0.4255, -0.9300, -0.5327, -0.3340, -0.3292, -0.6996, -0.4144, -0.4241,\n                       -0.3872, -0.2430, -0.4074, -0.3366, -0.1656, -0.2794, -0.4681, -0.4253,\n                       -0.4762, -0.4192, -0.5044, -0.2355, -0.3919, -0.2751, -0.2467, -0.1812,\n                        0.0145, -0.3151, -0.3426, -0.3952, -0.4031, -0.5408, -0.4404, -0.1896,\n                       -0.6277, -0.1937, -0.2186, -0.3964, -0.4384, -0.2877, -0.4736, -0.4034,\n                       -0.3045, -0.3625, -0.4329, -0.3219,  1.3416, -0.1752, -0.2984, -0.3144,\n                       -0.3138, -0.4201, -0.4727, -0.4250, -0.3428, -0.3541, -0.6213, -0.3326,\n                       -1.6765, -0.4452, -0.3686, -0.4221, -0.3311, -0.3978, -0.3340, -0.4120,\n                       -0.3041, -0.3214, -0.3848, -0.7575, -0.3897, -0.3460, -0.4112, -0.3939,\n                       -0.4596, -0.3074, -0.6920, -0.6459, -0.3628, -0.3378, -0.2314, -0.1153,\n                       -0.7501, -0.4579, -0.2351, -0.2285, -0.4113, -0.4084, -0.3279, -0.3533,\n                       -0.2977, -0.2707, -0.2758, -0.4594, -0.3302, -0.4424, -0.3150, -0.5964,\n                       -0.5425,  0.2568, -0.5058, -0.3291, -0.3525, -0.3304, -0.4357, -0.2702,\n                       -0.4010, -0.3926, -0.4569, -0.2840, -0.2027, -0.1850, -0.3138, -0.4441,\n                       -0.1129, -0.3573,  0.1170, -0.2361, -0.3261, -0.4548, -0.4314, -0.1552,\n                       -0.3186, -0.1852, -0.4830, -0.3171, -0.4363, -0.2955, -0.3319, -0.4552,\n                       -0.4131, -0.4516, -0.1460, -0.3254, -0.4206, -0.2841,  0.3480, -0.5232,\n                       -0.3933, -0.3327, -0.3671, -0.4192, -0.2622,  0.0675, -0.2809, -0.4542,\n                       -0.3475, -0.4508, -0.3284, -0.2282, -0.4025, -0.3811, -0.2739, -0.3664,\n                       -0.3007, -0.2405, -0.4986, -0.3898, -0.4152, -0.3357, -0.5660, -0.4431,\n                       -0.3295, -0.8382, -0.3956, -0.5633, -0.4523, -0.1432, -0.3501, -0.3564,\n                        0.0402, -0.2132, -0.1550, -0.4060, -0.4728, -0.3375, -0.5134, -0.2012,\n                       -0.2653, -0.3910, -0.2391, -0.1568,  0.2945, -0.1067, -0.4015, -0.4512,\n                        0.9792, -0.1725, -0.5113, -0.2614, -0.4007, -0.4074, -0.5379, -0.4206,\n                       -0.2947, -0.2673, -0.4441, -0.3392, -0.5939, -0.3186, -0.3078, -0.4668,\n                       -0.5187, -0.2433, -0.4749, -0.3997, -0.4664, -0.4597, -0.3360, -0.1974,\n                       -0.2801, -0.3622, -0.2331, -0.4060, -0.4174, -0.4382, -0.3830, -0.3328,\n                       -0.4279, -0.3965, -0.3122, -0.3543, -0.3909, -0.3716, -0.4079, -0.2599,\n                       -0.2528, -0.4169, -0.6097, -0.3981, -0.4185, -0.3055, -0.4312, -0.3829,\n                       -0.3492, -0.4844, -0.3456, -0.5166, -0.1366, -0.3919, -0.5686, -0.3920,\n                       -0.2807, -0.3789, -0.4106, -0.3452, -0.2458, -0.2584, -0.3212, -0.2354,\n                       -0.2781, -0.2592, -0.3211, -0.4028, -0.2943, -0.4108, -0.5035, -0.2389,\n                       -0.2763, -0.4846, -0.3335, -0.2242, -0.2607, -0.4363, -0.4113, -0.4882,\n                       -0.3280, -0.4240, -0.4622, -0.4024, -0.4349, -0.5137, -0.2902, -0.4509,\n                       -0.4186, -0.4174, -0.5026, -0.2445, -0.1306, -0.1424, -0.3488, -0.3731,\n                       -0.3392, -0.1616, -0.1560, -0.3548, -0.3926, -0.4348, -0.4509, -0.1650,\n                       -0.2402, -0.4978, -0.2952, -0.0867, -0.4394, -0.4846, -0.2613, -0.1261,\n                       -0.3085, -0.5546, -0.5088, -0.3050, -0.4398, -0.5723, -0.1869, -0.5176,\n                       -0.2111, -0.5752, -0.4556, -0.1964, -0.2952, -0.3604, -0.2723, -0.4038,\n                       -0.4571, -0.8812, -0.4431, -0.2108, -0.3011, -0.2641, -0.5160, -0.3665,\n                       -0.3852, -0.5453, -0.3669, -0.5185,  0.2254, -0.3658, -0.4152, -0.3955,\n                       -0.3589, -0.0706, -0.2958,  0.2880, -0.3280, -0.4173, -0.4596, -0.4721,\n                       -0.3951, -0.3293, -0.6734, -0.3135, -0.1598, -0.2418, -0.4329, -0.3949,\n                       -0.3953, -0.3716, -0.3624, -0.4149, -0.3175, -0.4787, -0.1686, -0.4003,\n                       -0.4361, -0.2524, -0.3460, -0.3668, -0.4097, -0.4569, -0.3003, -0.3592])),\n              ('backbone.models.0.model.layer4.1.bn2.running_var',\n               tensor([0.3839, 0.3168, 0.4299, 0.3962, 0.4932, 0.4200, 0.4879, 0.5337, 0.4073,\n                       0.3970, 0.3876, 0.3280, 0.3374, 0.3414, 0.4937, 0.4733, 0.4313, 0.3670,\n                       0.4038, 0.4526, 0.3700, 0.4249, 0.5068, 0.3247, 0.6125, 0.3362, 0.3379,\n                       0.4453, 0.4469, 0.3488, 0.4433, 1.3194, 0.4322, 0.3749, 0.3528, 0.4040,\n                       0.3716, 0.3542, 0.3953, 0.3414, 0.4244, 0.6248, 0.3388, 0.5006, 0.5395,\n                       0.4341, 0.4387, 0.2883, 0.3897, 0.3884, 0.2629, 0.3740, 0.4623, 0.3302,\n                       0.3645, 0.6221, 0.4085, 0.2992, 0.3796, 0.4355, 0.4164, 0.4801, 0.3719,\n                       0.4633, 0.4498, 0.4486, 0.4880, 0.4050, 0.4150, 0.4725, 0.4522, 0.4378,\n                       0.4379, 0.3480, 0.4379, 0.4460, 0.4789, 0.4339, 0.3227, 0.4182, 0.4232,\n                       0.4933, 0.3810, 0.4483, 0.4205, 0.3489, 0.4731, 0.3847, 0.4052, 0.6082,\n                       0.3672, 0.3774, 0.3212, 0.4007, 0.3958, 0.4116, 0.4531, 0.4634, 0.4110,\n                       0.4312, 0.2350, 0.5086, 0.4261, 0.3898, 0.4643, 1.2248, 0.4388, 0.4192,\n                       0.3440, 0.4812, 0.3590, 0.3871, 0.3396, 0.4096, 0.4071, 0.4310, 0.4958,\n                       0.4656, 0.4584, 0.4523, 0.4564, 0.5417, 0.4934, 0.4489, 0.4382, 0.4434,\n                       0.3887, 0.4073, 0.3712, 0.4235, 0.3579, 0.4145, 0.4453, 0.4694, 0.2448,\n                       0.4015, 0.3538, 0.5727, 0.4367, 0.4794, 0.3815, 0.3610, 0.3940, 0.4336,\n                       0.3740, 0.3948, 0.4653, 0.4456, 0.3484, 0.3609, 0.4918, 0.4534, 0.3714,\n                       0.3699, 0.4874, 0.4540, 0.3955, 0.4152, 0.4433, 0.3892, 0.4345, 0.3464,\n                       0.5177, 0.4238, 0.4591, 0.3059, 0.4240, 0.4116, 0.3745, 0.4500, 0.4206,\n                       0.4690, 0.4496, 0.8468, 0.2918, 0.3718, 0.5090, 0.2867, 0.2796, 0.4270,\n                       0.3713, 0.4689, 0.3500, 0.5734, 0.3488, 0.4172, 0.4772, 0.4690, 0.3065,\n                       0.4125, 0.4855, 0.5324, 0.3894, 0.9364, 0.3093, 0.4612, 0.7587, 0.2719,\n                       0.2675, 0.4342, 0.4033, 0.5146, 0.4121, 0.3736, 0.3662, 0.3143, 0.3628,\n                       0.6560, 1.2303, 0.3327, 0.4387, 0.4377, 0.5451, 0.4311, 0.4169, 0.4080,\n                       0.3703, 0.5166, 0.3514, 0.5256, 0.4538, 0.3939, 0.3839, 0.4175, 0.4130,\n                       0.4942, 0.3686, 0.3895, 0.4182, 0.4091, 0.3260, 0.4045, 0.4164, 0.5234,\n                       0.4205, 0.3126, 0.4089, 0.4388, 0.4630, 0.3841, 0.3722, 0.3396, 0.4086,\n                       0.4346, 0.4585, 0.3079, 0.3193, 0.2911, 0.5103, 0.4733, 0.4372, 0.3942,\n                       0.4701, 0.4710, 0.3760, 0.7384, 0.5324, 0.6182, 0.4214, 0.4349, 0.3979,\n                       0.4674, 0.4385, 0.4474, 0.3616, 0.4392, 0.9976, 0.4638, 0.4864, 0.4359,\n                       0.3798, 0.3412, 0.5434, 0.3417, 0.4107, 0.2565, 0.4020, 0.5135, 0.5066,\n                       0.5872, 0.3802, 0.3696, 0.3274, 0.3019, 0.4320, 0.4508, 0.5567, 0.4451,\n                       0.5451, 0.5216, 0.4991, 0.4273, 0.5105, 0.3192, 0.4915, 0.4067, 0.4287,\n                       0.2714, 0.2514, 0.4832, 0.3783, 0.4262, 0.4495, 0.3823, 0.4378, 0.3989,\n                       0.3143, 0.4578, 0.4453, 0.4316, 0.4677, 0.3595, 0.3225, 0.3360, 0.5007,\n                       0.3873, 0.5257, 0.4274, 0.4946, 0.5710, 0.4283, 0.5087, 0.8742, 0.3897,\n                       0.3047, 0.4097, 0.3641, 0.3829, 0.4403, 0.4173, 0.3752, 0.2884, 1.6335,\n                       0.3907, 0.2936, 0.4731, 0.6677, 1.0458, 0.4564, 0.4734, 0.3302, 0.4339,\n                       0.3847, 0.4635, 0.3637, 0.2443, 0.5574, 0.4652, 0.7685, 0.3226, 0.2987,\n                       0.3058, 0.5855, 0.4467, 0.3947, 0.3146, 0.4340, 0.4578, 0.3665, 0.3529,\n                       0.4696, 0.4137, 0.3697, 0.3511, 0.4082, 0.4501, 0.4436, 0.3981, 0.3879,\n                       0.5822, 0.2769, 0.4864, 0.3872, 0.4468, 0.4533, 0.4923, 0.4356, 0.3104,\n                       0.4712, 0.5058, 0.4845, 0.4067, 0.4967, 0.3157, 0.4552, 0.4237, 0.4666,\n                       0.5181, 0.2747, 0.5969, 0.5558, 0.4829, 0.3780, 0.4488, 0.3873, 0.4135,\n                       0.3726, 0.2998, 0.3621, 0.4058, 0.4220, 0.3449, 0.4768, 0.4169, 0.3765,\n                       0.4697, 0.4126, 0.3444, 0.5397, 0.3392, 0.3447, 0.4562, 0.4261, 0.4540,\n                       0.4907, 0.3078, 0.3381, 0.3300, 0.4190, 0.6125, 0.4410, 0.4465, 0.5177,\n                       0.3727, 0.4252, 0.4479, 0.4081, 0.3321, 0.2654, 0.5698, 0.4297, 0.4593,\n                       0.3821, 0.3842, 0.4305, 0.4458, 0.4675, 0.4714, 0.4199, 0.3005, 0.3816,\n                       0.4609, 0.4429, 0.5454, 0.2842, 0.3501, 0.3575, 0.4197, 0.3382, 0.3460,\n                       0.3545, 0.4145, 0.5360, 0.3735, 0.3687, 0.3611, 0.4076, 0.4567, 0.4944,\n                       0.4157, 0.3979, 0.3191, 0.4357, 0.4941, 0.3926, 0.4892, 0.5149, 0.3934,\n                       0.3205, 0.4350, 0.4215, 0.4220, 0.4910, 0.4311, 0.3778, 0.4601, 0.4868,\n                       0.4770, 0.3529, 0.4334, 0.4463, 0.4306, 0.2470, 0.6672, 0.4138, 0.3496,\n                       0.3714, 0.4324, 0.3632, 0.4168, 0.4237, 0.3661, 0.4304, 0.3470, 0.3764,\n                       0.4942, 0.4520, 0.5076, 0.3994, 0.4542, 0.4685, 0.4566, 0.4368, 0.3954,\n                       0.3902, 0.3116, 0.4630, 0.2873, 0.3135, 0.4262, 0.4236, 0.3748])),\n              ('backbone.models.0.model.layer4.1.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer4.1.conv3.weight',\n               tensor([[[[ 0.0107]],\n               \n                        [[-0.0491]],\n               \n                        [[ 0.0512]],\n               \n                        ...,\n               \n                        [[ 0.0255]],\n               \n                        [[-0.0296]],\n               \n                        [[ 0.0142]]],\n               \n               \n                       [[[-0.0571]],\n               \n                        [[ 0.0787]],\n               \n                        [[-0.0033]],\n               \n                        ...,\n               \n                        [[ 0.0489]],\n               \n                        [[ 0.0701]],\n               \n                        [[-0.0081]]],\n               \n               \n                       [[[ 0.0652]],\n               \n                        [[-0.0059]],\n               \n                        [[-0.0541]],\n               \n                        ...,\n               \n                        [[-0.0423]],\n               \n                        [[ 0.0535]],\n               \n                        [[-0.0290]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0297]],\n               \n                        [[-0.0037]],\n               \n                        [[-0.0048]],\n               \n                        ...,\n               \n                        [[ 0.0293]],\n               \n                        [[ 0.0126]],\n               \n                        [[ 0.0009]]],\n               \n               \n                       [[[ 0.0828]],\n               \n                        [[ 0.0135]],\n               \n                        [[ 0.0242]],\n               \n                        ...,\n               \n                        [[-0.0047]],\n               \n                        [[-0.0317]],\n               \n                        [[ 0.0530]]],\n               \n               \n                       [[[ 0.0049]],\n               \n                        [[ 0.0557]],\n               \n                        [[-0.0535]],\n               \n                        ...,\n               \n                        [[ 0.0473]],\n               \n                        [[-0.0770]],\n               \n                        [[-0.0323]]]])),\n              ('backbone.models.0.model.layer4.1.bn3.weight',\n               tensor([-0.5812,  0.6083, -0.5313,  ..., -0.6710, -0.6590, -0.4349])),\n              ('backbone.models.0.model.layer4.1.bn3.bias',\n               tensor([-0.3858, -0.6047, -0.3144,  ..., -0.5427, -0.4420,  0.0132])),\n              ('backbone.models.0.model.layer4.1.bn3.running_mean',\n               tensor([ 0.2157, -0.1509,  0.0989,  ...,  0.1558,  0.1565,  0.1482])),\n              ('backbone.models.0.model.layer4.1.bn3.running_var',\n               tensor([0.0782, 0.0569, 0.0690,  ..., 0.0749, 0.0770, 0.0762])),\n              ('backbone.models.0.model.layer4.1.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer4.2.conv1.weight',\n               tensor([[[[-0.0479]],\n               \n                        [[ 0.0306]],\n               \n                        [[-0.0589]],\n               \n                        ...,\n               \n                        [[ 0.0038]],\n               \n                        [[-0.0159]],\n               \n                        [[ 0.0209]]],\n               \n               \n                       [[[-0.0240]],\n               \n                        [[ 0.0586]],\n               \n                        [[ 0.0354]],\n               \n                        ...,\n               \n                        [[-0.0609]],\n               \n                        [[-0.0542]],\n               \n                        [[-0.0353]]],\n               \n               \n                       [[[-0.0163]],\n               \n                        [[ 0.0403]],\n               \n                        [[ 0.0081]],\n               \n                        ...,\n               \n                        [[ 0.0275]],\n               \n                        [[-0.0182]],\n               \n                        [[-0.0004]]],\n               \n               \n                       ...,\n               \n               \n                       [[[-0.0102]],\n               \n                        [[ 0.0405]],\n               \n                        [[-0.0262]],\n               \n                        ...,\n               \n                        [[-0.0906]],\n               \n                        [[ 0.0140]],\n               \n                        [[ 0.0311]]],\n               \n               \n                       [[[-0.0217]],\n               \n                        [[ 0.0183]],\n               \n                        [[ 0.0556]],\n               \n                        ...,\n               \n                        [[-0.0332]],\n               \n                        [[ 0.0171]],\n               \n                        [[-0.1127]]],\n               \n               \n                       [[[ 0.0066]],\n               \n                        [[ 0.0330]],\n               \n                        [[-0.0083]],\n               \n                        ...,\n               \n                        [[-0.0348]],\n               \n                        [[-0.0190]],\n               \n                        [[-0.0188]]]])),\n              ('backbone.models.0.model.layer4.2.bn1.weight',\n               tensor([0.6349, 0.5512, 0.2389, 0.2199, 0.4869, 0.4920, 0.7074, 0.5804, 0.6479,\n                       0.1503, 0.5999, 0.4755, 0.5984, 0.6813, 0.6541, 0.5339, 0.6735, 0.5855,\n                       0.5414, 0.6640, 0.7031, 0.1325, 0.4438, 0.5957, 0.6889, 0.4475, 0.6216,\n                       0.4159, 0.3734, 0.5216, 0.5320, 0.3416, 0.5636, 0.7717, 0.4175, 0.5947,\n                       0.5095, 0.7497, 0.5764, 0.5242, 0.6390, 0.7353, 0.6206, 0.6307, 0.6149,\n                       0.6548, 0.6068, 0.2046, 0.6286, 0.1960, 0.5572, 0.7035, 0.7940, 0.6316,\n                       0.7139, 0.5538, 0.7017, 0.7617, 0.1582, 0.5534, 0.5401, 0.7156, 0.6104,\n                       0.6683, 0.5835, 0.6514, 0.5098, 0.8054, 0.6884, 0.4491, 0.7089, 0.6266,\n                       0.7258, 0.7471, 0.3430, 0.3815, 0.8143, 0.2554, 0.6082, 0.7394, 0.4765,\n                       0.6299, 0.7648, 0.6322, 0.4235, 0.6037, 0.6091, 0.5680, 0.1512, 0.6470,\n                       0.5932, 0.6454, 0.2786, 0.5783, 0.6823, 0.7187, 0.5349, 0.5346, 0.6834,\n                       0.4275, 0.5584, 0.5221, 0.1278, 0.5038, 0.5975, 0.2847, 0.6405, 0.6376,\n                       0.5647, 0.6028, 0.6569, 0.7166, 0.6876, 0.5850, 0.7748, 0.6149, 0.7032,\n                       0.7090, 0.6421, 0.1666, 0.4421, 0.6978, 0.6225, 0.6945, 0.4713, 0.6320,\n                       0.5880, 0.4281, 0.4277, 0.5041, 0.7484, 0.6460, 0.6530, 0.6889, 0.6827,\n                       0.6547, 0.1414, 0.6896, 0.7022, 0.6056, 0.5122, 0.6750, 0.5593, 0.5438,\n                       0.6212, 0.6075, 0.4875, 0.5988, 0.6235, 0.6225, 0.5941, 0.4404, 0.6986,\n                       0.6571, 0.5892, 0.7032, 0.6838, 0.7483, 0.7010, 0.6791, 0.7142, 0.3844,\n                       0.5076, 0.6085, 0.6848, 0.5726, 0.6187, 0.6032, 0.5200, 0.5963, 0.1293,\n                       0.5642, 0.3490, 0.6779, 0.6155, 0.3219, 0.6234, 0.7139, 0.4205, 0.3121,\n                       0.6584, 0.1610, 0.3342, 0.7357, 0.2277, 0.4889, 0.6909, 0.6270, 0.6770,\n                       0.6150, 0.5969, 0.5439, 0.6204, 0.6557, 0.7477, 0.6664, 0.5175, 0.5801,\n                       0.4877, 0.7196, 0.5496, 0.5021, 0.6011, 0.6501, 0.3873, 0.5768, 0.5047,\n                       0.4711, 0.5206, 0.6256, 0.7712, 0.7155, 0.5201, 0.5997, 0.6500, 0.6822,\n                       0.1860, 0.6849, 0.6657, 0.5087, 0.7025, 0.5676, 0.7318, 0.4962, 0.7044,\n                       0.6768, 0.4831, 0.6419, 0.6316, 0.6149, 0.1678, 0.4483, 0.6247, 0.5671,\n                       0.6323, 0.4604, 0.6470, 0.6762, 0.5951, 0.1645, 0.1761, 0.6813, 0.6693,\n                       0.3172, 0.4712, 0.6491, 0.1533, 0.6403, 0.6779, 0.3845, 0.4388, 0.6097,\n                       0.7078, 0.4982, 0.7359, 0.4524, 0.2598, 0.5738, 0.6996, 0.5350, 0.3057,\n                       0.6582, 0.7699, 0.6595, 0.5324, 0.6167, 0.6377, 0.6599, 0.7046, 0.6829,\n                       0.4095, 0.5637, 0.5774, 0.7036, 0.7182, 0.4608, 0.6312, 0.6241, 0.3906,\n                       0.4587, 0.4278, 0.6522, 0.5809, 0.6816, 0.7773, 0.3147, 0.5908, 0.6695,\n                       0.5111, 0.5254, 0.5842, 0.6910, 0.4618, 0.7196, 0.2634, 0.5517, 0.6621,\n                       0.7291, 0.7120, 0.2650, 0.3141, 0.6982, 0.7193, 0.4691, 0.6133, 0.3985,\n                       0.6877, 0.5255, 0.7038, 0.2868, 0.2724, 0.5790, 0.6330, 0.5308, 0.5162,\n                       0.4724, 0.5038, 0.6678, 0.7003, 0.3071, 0.3085, 0.6199, 0.6287, 0.5003,\n                       0.7107, 0.5581, 0.6254, 0.5157, 0.6409, 0.6145, 0.6094, 0.5426, 0.5487,\n                       0.6216, 0.5913, 0.6136, 0.6841, 0.7122, 0.6223, 0.7158, 0.6582, 0.4355,\n                       0.5320, 0.4491, 0.6186, 0.5495, 0.5027, 0.5861, 0.3901, 0.6501, 0.5904,\n                       0.7086, 0.5545, 0.6512, 0.6459, 0.1901, 0.6845, 0.6663, 0.6477, 0.5350,\n                       0.7023, 0.4198, 0.5947, 0.5547, 0.6029, 0.6389, 0.7079, 0.3644, 0.2441,\n                       0.6159, 0.4333, 0.6536, 0.7770, 0.7675, 0.4691, 0.4013, 0.4655, 0.4972,\n                       0.6383, 0.6483, 0.6822, 0.4819, 0.4532, 0.4645, 0.7469, 0.5440, 0.6403,\n                       0.5653, 0.6318, 0.6165, 0.4609, 0.1903, 0.4383, 0.6753, 0.5786, 0.6909,\n                       0.3825, 0.4478, 0.4545, 0.3497, 0.1580, 0.3928, 0.6081, 0.6729, 0.6046,\n                       0.5981, 0.7973, 0.3220, 0.6635, 0.7035, 0.6475, 0.6938, 0.6980, 0.4805,\n                       0.1003, 0.5288, 0.6156, 0.6390, 0.7307, 0.6964, 0.4882, 0.5864, 0.7377,\n                       0.3205, 0.6340, 0.4128, 0.4633, 0.6593, 0.7453, 0.4514, 0.5404, 0.7352,\n                       0.6222, 0.5252, 0.6313, 0.7074, 0.6477, 0.5544, 0.4551, 0.6005, 0.4680,\n                       0.7039, 0.7140, 0.1471, 0.4907, 0.4242, 0.6790, 0.5329, 0.5983, 0.6632,\n                       0.5429, 0.5227, 0.4324, 0.5810, 0.6437, 0.3704, 0.5692, 0.6540, 0.5988,\n                       0.6962, 0.6304, 0.6827, 0.5672, 0.1708, 0.7362, 0.5033, 0.3596, 0.3348,\n                       0.4770, 0.5778, 0.6933, 0.4898, 0.6175, 0.5650, 0.6197, 0.7164, 0.2616,\n                       0.6674, 0.5491, 0.6555, 0.5446, 0.5857, 0.6318, 0.4994, 0.9078, 0.1956,\n                       0.6648, 0.6039, 0.7220, 0.5415, 0.7036, 0.5956, 0.6588, 0.6683, 0.3477,\n                       0.5571, 0.6999, 0.7824, 0.5659, 0.7497, 0.7887, 0.4158, 0.5367, 0.5334,\n                       0.7175, 0.5655, 0.6658, 0.7218, 0.5906, 0.5375, 0.6214, 0.1437])),\n              ('backbone.models.0.model.layer4.2.bn1.bias',\n               tensor([-1.2697e+00, -8.9676e-01, -2.8470e-01, -1.1253e-01, -7.9222e-01,\n                       -7.7275e-01, -1.3870e+00, -1.1545e+00, -1.2204e+00,  3.7530e-02,\n                       -1.1375e+00, -8.3351e-01, -1.1426e+00, -1.2753e+00, -1.3135e+00,\n                       -9.6046e-01, -1.3151e+00, -1.0685e+00, -9.2904e-01, -1.2497e+00,\n                       -1.4203e+00,  7.9118e-02, -7.3233e-01, -1.1335e+00, -1.3321e+00,\n                       -7.3662e-01, -1.0514e+00, -6.6742e-01, -4.7677e-01, -8.7339e-01,\n                       -1.0251e+00, -4.1240e-01, -9.1431e-01, -1.5749e+00, -5.7989e-01,\n                       -1.1064e+00, -8.4135e-01, -1.6272e+00, -1.0353e+00, -9.3185e-01,\n                       -1.2137e+00, -1.4411e+00, -1.1821e+00, -1.2128e+00, -1.2439e+00,\n                       -1.2420e+00, -1.1086e+00, -5.3910e-03, -1.1133e+00, -6.8046e-02,\n                       -9.8159e-01, -1.4394e+00, -1.5921e+00, -1.1859e+00, -1.2638e+00,\n                       -1.0127e+00, -1.3350e+00, -1.5317e+00,  2.3811e-02, -1.0792e+00,\n                       -1.0093e+00, -1.5171e+00, -1.2006e+00, -1.2132e+00, -1.0432e+00,\n                       -1.2750e+00, -8.9051e-01, -1.6746e+00, -1.3680e+00, -7.0936e-01,\n                       -1.2751e+00, -1.3560e+00, -1.4642e+00, -1.4538e+00, -3.8865e-01,\n                       -6.3085e-01, -1.6294e+00, -2.2557e-01, -1.1386e+00, -1.6294e+00,\n                       -7.4307e-01, -1.2193e+00, -1.5562e+00, -1.2549e+00, -6.3874e-01,\n                       -1.2569e+00, -1.1342e+00, -1.0894e+00,  1.9684e-02, -1.3188e+00,\n                       -1.1586e+00, -1.2740e+00, -2.9283e-01, -9.9846e-01, -1.3515e+00,\n                       -1.3875e+00, -9.9854e-01, -1.0180e+00, -1.3089e+00, -6.3289e-01,\n                       -9.2470e-01, -9.6824e-01,  7.1698e-02, -9.5608e-01, -1.0860e+00,\n                       -1.2368e-01, -1.1570e+00, -1.1745e+00, -1.0932e+00, -1.1531e+00,\n                       -1.3511e+00, -1.3337e+00, -1.4483e+00, -1.0143e+00, -1.5148e+00,\n                       -1.2710e+00, -1.2596e+00, -1.3505e+00, -1.2303e+00,  2.1205e-03,\n                       -7.7165e-01, -1.4238e+00, -1.2367e+00, -1.3987e+00, -7.9027e-01,\n                       -1.1622e+00, -1.0573e+00, -5.8256e-01, -6.1934e-01, -7.4827e-01,\n                       -1.4839e+00, -1.2246e+00, -1.1841e+00, -1.2949e+00, -1.2623e+00,\n                       -1.2754e+00,  1.0363e-01, -1.3960e+00, -1.4745e+00, -1.1394e+00,\n                       -9.0428e-01, -1.2505e+00, -9.6683e-01, -9.0923e-01, -1.1284e+00,\n                       -1.1817e+00, -8.2125e-01, -1.1633e+00, -1.1575e+00, -1.1186e+00,\n                       -1.0864e+00, -6.3630e-01, -1.4427e+00, -1.3228e+00, -1.0670e+00,\n                       -1.4792e+00, -1.3369e+00, -1.3992e+00, -1.2360e+00, -1.2655e+00,\n                       -1.3827e+00, -5.5909e-01, -9.5091e-01, -1.0619e+00, -1.4002e+00,\n                       -1.1196e+00, -1.2853e+00, -1.0657e+00, -8.8073e-01, -1.1114e+00,\n                        1.6196e-01, -1.0765e+00, -5.1388e-01, -1.3213e+00, -1.2459e+00,\n                       -3.1977e-01, -1.0378e+00, -1.3457e+00, -7.7043e-01, -3.6033e-01,\n                       -1.2940e+00,  3.8783e-03, -3.9117e-01, -1.5000e+00, -4.5088e-02,\n                       -8.2652e-01, -1.3108e+00, -1.1906e+00, -1.2045e+00, -1.1572e+00,\n                       -1.0808e+00, -9.1292e-01, -1.1568e+00, -1.2975e+00, -1.5399e+00,\n                       -1.2020e+00, -8.9215e-01, -1.0043e+00, -8.0932e-01, -1.3868e+00,\n                       -9.4563e-01, -8.1954e-01, -1.1240e+00, -1.2662e+00, -4.8773e-01,\n                       -9.7877e-01, -7.6469e-01, -8.3445e-01, -8.9547e-01, -1.1712e+00,\n                       -1.4005e+00, -1.4472e+00, -8.7012e-01, -1.1811e+00, -1.1908e+00,\n                       -1.3778e+00,  2.0425e-02, -1.1661e+00, -8.9351e-01, -8.4454e-01,\n                       -1.4704e+00, -1.0561e+00, -1.5660e+00, -9.2575e-01, -1.4010e+00,\n                       -1.3490e+00, -8.4169e-01, -1.2027e+00, -1.1933e+00, -1.2285e+00,\n                        1.1923e-01, -7.5215e-01, -1.1088e+00, -9.7375e-01, -1.1845e+00,\n                       -7.3253e-01, -1.3593e+00, -1.1926e+00, -1.0715e+00,  2.6767e-02,\n                       -3.7840e-02, -1.2624e+00, -1.3068e+00, -4.0989e-01, -7.5689e-01,\n                       -1.2416e+00,  2.1605e-02, -1.2552e+00, -1.3568e+00, -5.5395e-01,\n                       -8.1846e-01, -1.1073e+00, -1.4851e+00, -8.6460e-01, -1.4971e+00,\n                       -7.0831e-01, -3.2266e-01, -9.5564e-01, -1.3034e+00, -8.5204e-01,\n                       -2.6824e-01, -1.3246e+00, -1.5615e+00, -1.2375e+00, -7.8917e-01,\n                       -1.1395e+00, -1.3430e+00, -1.2652e+00, -1.3924e+00, -1.3182e+00,\n                       -3.4279e-01, -1.0114e+00, -1.0505e+00, -1.2706e+00, -1.4940e+00,\n                       -7.3977e-01, -1.0903e+00, -1.1724e+00, -6.0584e-01, -7.0002e-01,\n                       -5.6859e-01, -1.1793e+00, -1.1462e+00, -1.3041e+00, -1.4335e+00,\n                       -3.3890e-01, -1.0649e+00, -1.3080e+00, -8.5813e-01, -7.7245e-01,\n                       -1.0174e+00, -1.2960e+00, -7.1453e-01, -1.4200e+00, -2.1318e-01,\n                       -8.7566e-01, -1.2929e+00, -1.3744e+00, -1.3219e+00, -2.4697e-01,\n                       -4.2560e-01, -1.5104e+00, -1.4506e+00, -8.1285e-01, -1.1919e+00,\n                       -5.9475e-01, -1.2881e+00, -9.0012e-01, -1.4114e+00, -7.4085e-02,\n                       -2.5056e-01, -1.0208e+00, -1.3171e+00, -8.8626e-01, -8.0835e-01,\n                       -7.2384e-01, -8.6992e-01, -1.2085e+00, -1.5062e+00, -3.6073e-01,\n                       -3.0685e-01, -1.1709e+00, -1.1084e+00, -9.3372e-01, -1.3630e+00,\n                       -9.4338e-01, -1.0883e+00, -8.6686e-01, -1.3431e+00, -1.1482e+00,\n                       -1.2615e+00, -8.4916e-01, -9.6304e-01, -1.1169e+00, -1.0586e+00,\n                       -1.1190e+00, -1.2833e+00, -1.3971e+00, -1.1984e+00, -1.3988e+00,\n                       -1.2071e+00, -7.1660e-01, -9.4428e-01, -7.9405e-01, -1.1733e+00,\n                       -9.8024e-01, -7.7589e-01, -1.1162e+00, -5.0048e-01, -1.2010e+00,\n                       -1.0292e+00, -1.3989e+00, -1.0266e+00, -1.3505e+00, -1.1691e+00,\n                        4.4984e-02, -1.3607e+00, -1.3641e+00, -1.1914e+00, -1.0505e+00,\n                       -1.3681e+00, -6.8468e-01, -1.0179e+00, -1.0462e+00, -1.0811e+00,\n                       -1.2262e+00, -1.4167e+00, -5.7599e-01, -2.2414e-01, -1.1529e+00,\n                       -6.4085e-01, -1.1887e+00, -1.4943e+00, -1.4821e+00, -7.5642e-01,\n                       -6.1339e-01, -8.4912e-01, -8.3630e-01, -1.1713e+00, -1.2248e+00,\n                       -1.2884e+00, -7.9102e-01, -7.8730e-01, -7.4527e-01, -1.5546e+00,\n                       -1.0786e+00, -1.3414e+00, -9.4769e-01, -1.1207e+00, -1.1175e+00,\n                       -7.7152e-01,  3.2253e-02, -6.2735e-01, -1.2337e+00, -1.0414e+00,\n                       -1.4191e+00, -6.3725e-01, -7.6938e-01, -7.6675e-01, -5.0413e-01,\n                        4.4348e-02, -5.6852e-01, -1.1943e+00, -1.2694e+00, -1.2349e+00,\n                       -1.1214e+00, -1.6293e+00, -3.3411e-01, -1.3571e+00, -1.3264e+00,\n                       -1.3162e+00, -1.2840e+00, -1.3660e+00, -7.7246e-01,  2.3454e-01,\n                       -8.4695e-01, -1.2081e+00, -1.2117e+00, -1.4369e+00, -1.5245e+00,\n                       -8.9754e-01, -1.0441e+00, -1.5620e+00, -3.8090e-01, -1.2595e+00,\n                       -5.7480e-01, -7.2559e-01, -1.2827e+00, -1.4959e+00, -6.9722e-01,\n                       -9.9103e-01, -1.5526e+00, -1.1451e+00, -9.9236e-01, -1.1808e+00,\n                       -1.3901e+00, -1.2607e+00, -9.4807e-01, -7.4036e-01, -1.1688e+00,\n                       -7.5310e-01, -1.3387e+00, -1.4124e+00,  4.1704e-02, -8.5791e-01,\n                       -6.7888e-01, -1.3834e+00, -9.6896e-01, -1.1397e+00, -1.3583e+00,\n                       -8.9277e-01, -9.5523e-01, -5.8847e-01, -9.1299e-01, -1.2262e+00,\n                       -5.1540e-01, -1.0254e+00, -1.3574e+00, -1.0921e+00, -1.2996e+00,\n                       -1.3172e+00, -1.3117e+00, -1.1183e+00, -1.0187e-01, -1.3990e+00,\n                       -8.7892e-01, -5.4691e-01, -3.9975e-01, -7.1531e-01, -1.0374e+00,\n                       -1.3373e+00, -8.8418e-01, -1.1037e+00, -1.0031e+00, -1.1896e+00,\n                       -1.4335e+00, -2.0627e-01, -1.3320e+00, -9.7586e-01, -1.3403e+00,\n                       -1.0755e+00, -9.5013e-01, -1.1073e+00, -9.3709e-01, -2.6421e+00,\n                        7.1726e-03, -1.2588e+00, -1.0785e+00, -1.3845e+00, -8.9567e-01,\n                       -1.3222e+00, -1.0602e+00, -1.3274e+00, -1.3297e+00, -5.6778e-01,\n                       -9.9984e-01, -1.2980e+00, -1.5904e+00, -1.0107e+00, -1.5115e+00,\n                       -1.5593e+00, -5.8916e-01, -9.9831e-01, -9.4934e-01, -1.3912e+00,\n                       -1.1369e+00, -1.2122e+00, -1.3468e+00, -1.1535e+00, -1.0219e+00,\n                       -1.1304e+00,  5.7404e-02])),\n              ('backbone.models.0.model.layer4.2.bn1.running_mean',\n               tensor([ -3.0801,  -2.0664,  -1.7651,  -2.1643,  -2.4281,  -2.1644,  -2.9366,\n                        -2.1656,  -2.5281,   4.3778,  -2.0411,  -1.7813,  -2.7098,  -2.4482,\n                        -2.9573,  -2.0357,  -2.1968,  -2.0247,  -3.0109,  -3.4679,  -2.9954,\n                         2.4055,  -2.2160,  -2.6909,  -2.4180,  -2.8470,  -2.9019,  -2.3768,\n                        -1.8448,  -1.7926,  -2.7093,  -1.9484,  -1.9127,  -3.1249,  -0.8735,\n                        -2.5988,  -2.7023,  -3.0225,  -3.5478,  -2.3101,  -2.8777,  -2.7932,\n                        -2.5620,  -3.1890,  -2.6394,  -2.5615,  -2.2312,  -0.8591,  -2.6107,\n                        -1.3954,  -2.8477,  -3.1998,  -3.1996,  -2.5403,  -2.3537,  -2.2758,\n                        -2.6035,  -2.5467,  -1.6546,  -2.7751,  -3.2069,  -2.8829,  -2.4287,\n                        -2.4531,  -2.1562,  -2.8289,  -2.0885,  -3.0115,  -3.1210,  -2.5757,\n                        -2.5484,  -2.7899,  -2.6867,  -2.6225,  -1.7300,  -3.0316,  -3.1602,\n                        -0.8909,  -2.4553,  -2.9982,  -2.2616,  -2.2349,  -3.1473,  -2.2794,\n                        -2.1068,  -2.5899,  -2.0317,  -2.7955,  -0.9498,  -2.5297,  -2.9158,\n                        -2.7934,  -1.8730,  -3.0552,  -3.1330,  -2.5048,  -2.2715,  -2.2512,\n                        -2.5262,  -2.8054,  -1.7817,  -2.0300,  -1.3584,  -2.5169,  -2.8164,\n                         4.3322,  -2.7675,  -2.7708,  -2.7514,  -2.5876,  -2.9428,  -2.8975,\n                        -2.8082,  -2.0341,  -3.3133,  -3.2467,  -2.2319,  -2.5457,  -3.0683,\n                         0.9729,  -2.7087,  -2.6445,  -3.2508,  -2.9458,  -2.5970,  -2.7235,\n                        -2.5788,  -2.4206,  -1.8097,  -1.4954,  -2.9982,  -2.4807,  -2.5791,\n                        -2.4977,  -2.2794,  -3.0819,   1.0780,  -3.3056,  -2.6801,  -2.4776,\n                        -1.9157,  -2.4136,  -2.6444,  -2.1649,  -2.5115,  -2.4142,  -1.7727,\n                        -2.7753,  -3.0057,  -2.3474,  -2.9995,  -2.5684,  -2.7038,  -2.8474,\n                        -2.4690,  -3.0366,  -3.0081,  -3.1098,  -2.3756,  -2.8409,  -2.8285,\n                        -2.3693,  -2.6253,  -2.3642,  -3.0938,  -3.0826,  -2.6781,  -2.4985,\n                        -2.5692,  -2.4044,   5.0020,  -2.9125,  -2.2170,  -2.8332,  -2.9396,\n                        -1.4494,  -2.8153,  -2.7885,  -2.0341,  -1.6419,  -2.6871,  -1.3948,\n                        -2.5173,  -2.8807,  -1.5688,  -2.6881,  -2.6872,  -2.7938,  -2.4636,\n                        -2.7447,  -2.9211,  -1.7946,  -3.2370,  -2.7283,  -2.9109,  -2.9081,\n                        -2.3186,  -1.9416,  -3.3477,  -3.0736,  -2.5381,  -1.8686,  -2.5834,\n                        -3.3167,  -2.6499,  -2.1601,  -2.3359,  -1.7749,  -2.3124,  -2.7017,\n                        -2.7342,  -3.0163,  -2.3614,  -2.4083,  -2.3418,  -2.7708,   0.6640,\n                        -2.3518,  -2.7876,  -2.6204,  -2.7200,  -2.0263,  -2.9818,  -1.8143,\n                        -3.3776,  -3.0413,  -2.8265,  -2.8935,  -2.4738,  -3.0819,   2.6621,\n                        -2.3944,  -2.9264,  -2.0993,  -2.4148,  -2.0291,  -3.0817,  -2.4569,\n                        -2.4494,  -3.4487,  -2.2098,  -2.7545,  -2.6565,  -1.3554,  -1.9754,\n                        -2.7088,   0.9843,  -2.5236,  -2.8575,  -2.1924,  -2.3382,  -2.2860,\n                        -2.5931,  -2.4528,  -3.1050,  -2.7177,  -2.0188,  -2.5554,  -2.6680,\n                        -2.9873,  -1.4627,  -2.3763,  -2.6658,  -2.7404,  -2.7063,  -2.4328,\n                        -3.1277,  -3.0014,  -2.2879,  -2.8761,  -2.3548,  -2.2016,  -2.2068,\n                        -2.7892,  -2.8358,  -2.0941,  -2.2705,  -2.3811,  -2.6982,  -3.0800,\n                        -3.3225,  -2.3621,  -2.5900,  -2.9128,  -3.0793,  -1.1563,  -2.3704,\n                        -2.7108,  -2.5364,  -2.2794,  -2.7799,  -2.6918,  -2.6178,  -2.7539,\n                        -2.5255,  -2.2624,  -2.6645,  -2.5949,  -2.5484,  -2.5038,  -2.1501,\n                        -2.2784,  -2.8124,  -2.4352,  -2.7091,  -2.1233,  -2.7418,  -2.7219,\n                        -2.9800, -21.3312,  -2.0350,  -2.3827,  -2.6372,  -1.5131,  -2.5350,\n                        -1.7777,  -2.6696,  -2.3205,  -3.2627,  -2.2158,  -1.1342,  -2.2471,\n                        -2.1017,  -2.4446,  -3.1198,  -1.8551,  -2.9403,  -1.8848,  -2.4918,\n                        -2.5244,  -2.8379,  -2.5230,  -1.8763,  -2.5943,  -2.6824,  -2.4445,\n                        -2.5631,  -2.8330,  -2.3841,  -3.7552,  -2.6718,  -2.8441,  -2.4921,\n                        -2.4361,  -3.0346,  -2.3962,  -1.5641,  -2.5333,  -1.3072,  -2.7304,\n                        -1.8516,  -2.7893,  -2.8556,  -2.7608,  -2.5820,  -2.0454,  -2.6275,\n                        -2.7309,  -2.4137,  -3.2842,  -2.5153,  -2.3105,  -2.8595,  -2.5593,\n                        -2.4420,  -2.7436,  -2.3555,  -2.0149,  -1.3037,  -2.2995,  -1.5335,\n                        -2.7074,  -2.7437,  -2.8789,  -2.4744,  -2.3074,  -2.5113,  -2.1068,\n                        -2.3813,  -2.6033,  -2.4228,  -2.4168,  -2.6380,  -1.9126,  -3.1479,\n                        -2.5353,  -2.8792,  -2.1498,  -2.2868,  -2.7940,  -2.2833,  27.4268,\n                        -2.5031,  -2.8133,  -2.6255,  -2.2690,  -2.7444,  -2.2350,  -2.2335,\n                        -2.6110,  -2.3701,  -1.4983,  -3.1122,  -2.8789,  -2.5799,  -2.8415,\n                        -3.1462,  -2.1994,  -2.8021,  -2.6334,  -2.8361,  -2.9295,  -3.1188,\n                        -2.0235,   8.5877,  -1.8214,  -2.6148,  -2.9764,  -2.8090,  -2.8970,\n                        -1.9239,  -2.3530,  -2.8861,  -1.8126,  -2.7335,  -1.7097,  -2.1182,\n                        -2.8184,  -3.0909,  -1.8225,  -2.6101,  -3.1981,  -2.3654,  -2.5513,\n                        -3.1556,  -2.6359,  -2.7407,  -2.6028,  -2.4613,  -2.3600,  -2.3358,\n                        -2.5480,  -2.5798,  -2.2615,  -2.4804,  -2.2481,  -2.9445,  -2.5488,\n                        -2.3714,  -2.8996,  -2.5394,  -1.9597,  -1.6078,  -2.3627,  -2.7768,\n                        -2.1183,  -2.6808,  -2.7486,  -2.3682,  -2.6301,  -3.0060,  -2.7110,\n                        -2.4987,  -1.0221,  -3.0838,  -2.2128,  -2.2920,  -0.9884,  -2.3003,\n                        -2.0334,  -2.5727,  -2.5044,  -2.5144,  -2.8247,  -3.0454,  -2.7609,\n                        -1.9039,  -2.8492,  -1.7760,  -2.4031,  -2.9131,  -2.5048,  -2.8334,\n                        -2.0949, -11.3670,   1.3467,  -2.8303,  -2.4326,  -2.7380,  -2.6993,\n                        -2.4225,  -2.5428,  -2.3607,  -2.6312,  -2.7059,  -2.5963,  -2.4220,\n                        -3.1112,  -2.3551,  -2.7314,  -2.9250,  -2.0962,  -2.2627,  -3.3424,\n                        -2.9280,  -2.7442,  -2.8519,  -2.9326,  -2.6592,  -2.6756,  -3.2826,\n                        -0.1667])),\n              ('backbone.models.0.model.layer4.2.bn1.running_var',\n               tensor([ 1.4972,  1.7080,  1.6804,  3.3024,  2.2300,  1.7348,  1.7060,  1.5299,\n                        2.0471,  4.8314,  1.7104,  1.4154,  1.9387,  1.8037,  2.1272,  1.3743,\n                        1.4951,  1.7794,  1.7864,  2.7162,  1.4752,  1.9454,  2.7243,  1.4236,\n                        1.6906,  1.8381,  2.3826,  2.0199,  1.6991,  1.5368,  2.2024,  2.1882,\n                        1.4683,  2.3135,  1.3320,  1.6330,  2.2675,  1.9331,  2.2458,  2.2136,\n                        1.7800,  1.7153,  2.0217,  2.3578,  1.9000,  1.7292,  1.7690,  4.0968,\n                        2.0898,  3.0186,  1.9955,  1.8703,  2.1141,  1.8150,  1.7899,  1.7083,\n                        1.8795,  1.6337,  3.6793,  1.6729,  2.2181,  1.7402,  1.4983,  1.5858,\n                        1.7657,  1.9068,  1.6163,  1.7701,  1.6558,  2.4742,  2.2204,  1.5898,\n                        1.9373,  1.7228,  1.6896,  2.1395,  2.0645,  2.5117,  1.9107,  1.7759,\n                        1.8965,  1.7467,  2.0958,  1.5953,  1.6515,  1.6355,  1.8025,  2.0133,\n                        3.3324,  1.6128,  2.1257,  2.0154,  2.1017,  2.4331,  2.2631,  1.6792,\n                        2.1305,  1.5959,  1.6939,  2.4994,  1.8946,  1.6058,  3.3181,  1.8479,\n                        1.8985,  3.6486,  2.1002,  2.8475,  1.8431,  1.8073,  1.6936,  2.3674,\n                        2.2340,  2.1883,  2.0042,  2.1546,  2.0891,  1.8251,  2.2211,  1.5968,\n                        2.0804,  1.7878,  2.1580,  1.9838,  1.7019,  1.7851,  1.6556,  2.1615,\n                        2.0663,  1.6218,  1.6134,  1.6534,  2.1237,  1.9617,  2.1372,  2.2658,\n                        4.2563,  2.0385,  1.8155,  1.9235,  1.8312,  1.7582,  2.0675,  1.6733,\n                        1.6629,  1.4267,  1.3878,  1.8830,  1.7733,  1.8204,  1.8973,  2.7927,\n                        1.9533,  1.6050,  1.8216,  1.8881,  2.1733,  2.0691,  2.0778,  2.1673,\n                        1.8145,  1.7541,  1.8453,  1.8680,  2.0185,  1.8334,  1.6515,  1.7556,\n                        2.0177,  1.4741,  5.2737,  1.8365,  1.5550,  2.1225,  1.6294,  2.0671,\n                        2.0152,  2.1654,  1.3514,  1.6136,  1.8325,  4.0200,  2.0965,  2.1050,\n                        2.8875,  1.9948,  1.7057,  1.9657,  2.2623,  1.9956,  1.8598,  1.5052,\n                        2.2188,  1.6325,  2.2516,  1.9498,  1.7699,  1.4459,  2.4767,  2.1558,\n                        1.9548,  1.5659,  2.1165,  1.9130,  2.2213,  1.7815,  2.0200,  1.4452,\n                        1.9636,  1.9463,  2.2110,  2.0112,  1.7274,  1.8819,  1.5712,  1.7302,\n                        4.8655,  2.1399,  1.0784,  2.2090,  1.9853,  1.4828,  1.9793,  1.6355,\n                        2.6773,  1.8614,  1.8053,  1.8624,  1.8560,  2.1113,  3.0851,  2.3250,\n                        1.9806,  1.7647,  1.9421,  2.0845,  1.7060,  2.2815,  2.0878,  8.1726,\n                        4.0368,  2.1995,  1.7148,  1.5958,  1.8460,  1.7430,  3.2589,  1.6927,\n                        2.0163,  1.5577,  1.5957,  2.0810,  1.7367,  2.1102,  2.0269,  2.6344,\n                        1.7027,  1.7866,  2.0871,  2.3286,  2.1671,  1.8006,  2.1739,  2.1985,\n                        1.9612,  2.1001,  2.0517,  1.9614,  1.9416,  2.1003,  2.8011,  1.6076,\n                        1.7677,  2.4759,  2.0859,  1.7596,  1.9593,  1.9972,  2.2253,  2.5901,\n                        2.9654,  1.9133,  2.0347,  1.8294,  2.0730,  1.5385,  1.9909,  1.7466,\n                        1.9569,  2.1807,  2.3506,  1.8591,  2.3922,  2.2244,  2.9340,  1.9423,\n                        1.9504,  2.0650,  2.0836,  2.6770,  2.0417,  1.6258,  1.7232,  2.0507,\n                        2.0231,  1.6658,  2.0453,  2.0891,  1.9191,  7.6605,  2.0084,  1.6866,\n                        1.6586,  1.5007,  1.9543,  2.0566,  2.3571,  1.9358,  1.8874,  2.4049,\n                        1.9310,  2.1939,  1.8196,  1.7749,  2.0847,  1.4990,  2.6247,  1.3808,\n                        1.7549,  1.8149,  1.9845,  2.2938,  1.7957,  2.4626,  2.2785,  1.7807,\n                        2.0599,  1.9312,  1.6971,  2.2311,  2.1250,  1.8377,  1.5348,  2.0612,\n                        2.1421,  2.0123,  1.5688,  1.5652,  1.7143,  2.5214,  1.8438,  1.7806,\n                        1.9622,  1.5045,  1.8864,  5.2832,  1.8493,  2.1163,  2.0749,  2.0816,\n                        1.8678,  1.7534,  2.0581,  2.0057,  1.7262,  1.9818,  1.8196,  1.6561,\n                        1.7840,  2.0969,  2.0955,  1.8340,  1.8742,  1.8899,  1.7222,  1.9106,\n                        1.7108,  1.6557,  1.8895,  1.7641,  1.8110,  1.7538,  2.0333,  1.5742,\n                        1.5831,  1.4792,  1.8948,  1.9108,  2.0840,  1.8654,  1.5516, 12.8287,\n                        2.5471,  2.0605,  1.9321,  2.0084,  2.0003,  1.9313,  1.6541,  1.7898,\n                        5.3207,  1.6685,  1.8082,  1.6823,  1.7495,  2.0470,  2.0779,  2.8253,\n                        1.6018,  1.8692,  1.7972,  2.1963,  1.8395,  1.3761,  2.1714,  1.7599,\n                        1.7256,  1.8028,  1.6448,  2.0579,  1.4082,  1.7720,  1.8338,  1.6030,\n                        1.7810,  1.9838,  1.6456,  2.4215,  1.9747,  1.8036,  1.6499,  1.7256,\n                        1.5513,  1.8208,  1.8737,  2.3195,  1.9435,  2.0294,  1.8643,  1.3427,\n                        1.4600,  1.9394,  1.7999,  3.8497,  1.9808,  1.9372,  1.6932,  1.5506,\n                        1.5662,  2.0933,  2.4866,  1.9608,  1.5305,  2.1312,  1.9103,  2.2170,\n                        1.6866,  2.0803,  1.7233,  1.7584,  1.9633,  2.0672,  1.8090,  1.8701,\n                        2.9252,  1.7596,  2.0908,  1.6455,  2.2765,  1.6980,  1.8509,  1.9687,\n                        1.9014,  1.8826,  2.0111,  1.8542,  1.8223,  1.5839,  1.4739,  1.8460,\n                        1.9237,  2.0275,  2.2917,  1.7932,  5.6357,  3.8551,  1.9267,  1.7724,\n                        1.5993,  2.4053,  1.5778,  1.6571,  1.6909,  1.8556,  2.2904,  1.9492,\n                        1.6090,  1.8299,  1.8423,  2.1169,  2.0461,  2.2223,  1.5928,  2.1434,\n                        1.9129,  1.6990,  1.9292,  2.4580,  1.6903,  2.2468,  2.5467,  3.9093])),\n              ('backbone.models.0.model.layer4.2.bn1.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer4.2.conv2.weight',\n               tensor([[[[-0.0108, -0.0530, -0.0167],\n                         [-0.0369, -0.0667, -0.0330],\n                         [-0.0311, -0.0355, -0.0252]],\n               \n                        [[-0.0125,  0.0034,  0.0011],\n                         [ 0.0092,  0.0412,  0.0011],\n                         [-0.0269, -0.0178, -0.0058]],\n               \n                        [[ 0.0166,  0.0107, -0.0042],\n                         [-0.0089,  0.0343,  0.0137],\n                         [ 0.0128,  0.0209,  0.0102]],\n               \n                        ...,\n               \n                        [[-0.0117, -0.0475,  0.0030],\n                         [-0.0278,  0.0085, -0.0068],\n                         [-0.0169, -0.0136, -0.0043]],\n               \n                        [[-0.0116, -0.0249, -0.0337],\n                         [-0.0144,  0.0189,  0.0026],\n                         [ 0.0088,  0.0102,  0.0134]],\n               \n                        [[ 0.0074, -0.0093, -0.0029],\n                         [-0.0032, -0.0011, -0.0267],\n                         [ 0.0043,  0.0129,  0.0183]]],\n               \n               \n                       [[[ 0.0259,  0.0269,  0.0230],\n                         [ 0.0271, -0.0218, -0.0110],\n                         [-0.0013,  0.0062, -0.0108]],\n               \n                        [[-0.0183, -0.0109, -0.0220],\n                         [-0.0172, -0.0042, -0.0177],\n                         [ 0.0019,  0.0016,  0.0013]],\n               \n                        [[-0.0340, -0.0206, -0.0249],\n                         [-0.0556,  0.0267, -0.0267],\n                         [-0.0189, -0.0050, -0.0134]],\n               \n                        ...,\n               \n                        [[-0.0065,  0.0059, -0.0060],\n                         [-0.0184,  0.0327, -0.0078],\n                         [ 0.0001,  0.0108, -0.0121]],\n               \n                        [[-0.0157,  0.0023, -0.0076],\n                         [-0.0010, -0.0002, -0.0007],\n                         [-0.0160, -0.0130, -0.0118]],\n               \n                        [[-0.1149, -0.0511, -0.0508],\n                         [-0.0544,  0.0304, -0.0515],\n                         [-0.0492, -0.0732, -0.0488]]],\n               \n               \n                       [[[-0.0079, -0.0248, -0.0199],\n                         [-0.0210, -0.0441, -0.0140],\n                         [-0.0082, -0.0403, -0.0111]],\n               \n                        [[ 0.0072,  0.0095, -0.0017],\n                         [-0.0051,  0.0076,  0.0111],\n                         [-0.0197, -0.0386, -0.0204]],\n               \n                        [[-0.0125, -0.0076, -0.0077],\n                         [-0.0229, -0.0121, -0.0275],\n                         [-0.0019, -0.0505, -0.0169]],\n               \n                        ...,\n               \n                        [[-0.0052,  0.0002, -0.0103],\n                         [-0.0015, -0.0033, -0.0024],\n                         [ 0.0059,  0.0084, -0.0116]],\n               \n                        [[-0.0192, -0.0287, -0.0178],\n                         [-0.0280, -0.0284, -0.0030],\n                         [ 0.0051, -0.0013,  0.0107]],\n               \n                        [[-0.0003,  0.0093, -0.0152],\n                         [-0.0098, -0.0414, -0.0045],\n                         [-0.0078, -0.0258, -0.0210]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0065,  0.0039, -0.0015],\n                         [ 0.0025, -0.0062,  0.0103],\n                         [ 0.0124, -0.0136, -0.0085]],\n               \n                        [[ 0.0210,  0.0376,  0.0303],\n                         [ 0.0274,  0.0148,  0.0138],\n                         [ 0.0136,  0.0297,  0.0104]],\n               \n                        [[-0.0195,  0.0094, -0.0116],\n                         [ 0.0013,  0.0812, -0.0147],\n                         [-0.0211, -0.0169, -0.0124]],\n               \n                        ...,\n               \n                        [[ 0.0154, -0.0244, -0.0155],\n                         [-0.0057, -0.0352, -0.0069],\n                         [ 0.0113,  0.0279,  0.0316]],\n               \n                        [[-0.0038, -0.0148, -0.0108],\n                         [-0.0233, -0.0285, -0.0254],\n                         [-0.0115, -0.0231, -0.0132]],\n               \n                        [[ 0.0130, -0.0034, -0.0057],\n                         [-0.0058, -0.0401, -0.0147],\n                         [-0.0085, -0.0487, -0.0200]]],\n               \n               \n                       [[[-0.0112, -0.0050, -0.0098],\n                         [ 0.0184, -0.0046,  0.0087],\n                         [-0.0003,  0.0047,  0.0004]],\n               \n                        [[-0.0158, -0.0198,  0.0040],\n                         [-0.0083, -0.0330, -0.0028],\n                         [-0.0006, -0.0317, -0.0078]],\n               \n                        [[ 0.0138,  0.0146, -0.0128],\n                         [ 0.0259,  0.0389,  0.0302],\n                         [-0.0084,  0.0037,  0.0028]],\n               \n                        ...,\n               \n                        [[-0.0048, -0.0207, -0.0131],\n                         [ 0.0159, -0.0316, -0.0085],\n                         [-0.0004, -0.0287, -0.0001]],\n               \n                        [[-0.0126, -0.0121, -0.0180],\n                         [-0.0208, -0.0367, -0.0222],\n                         [ 0.0011, -0.0118, -0.0049]],\n               \n                        [[-0.0187, -0.0279, -0.0060],\n                         [ 0.0080,  0.0309, -0.0040],\n                         [-0.0451,  0.0298, -0.0246]]],\n               \n               \n                       [[[-0.0092, -0.0070, -0.0083],\n                         [-0.0075, -0.0245, -0.0187],\n                         [-0.0119, -0.0146,  0.0004]],\n               \n                        [[ 0.0263,  0.0109,  0.0012],\n                         [ 0.0085,  0.0275,  0.0342],\n                         [ 0.0083,  0.0023,  0.0199]],\n               \n                        [[ 0.0179,  0.0159,  0.0066],\n                         [ 0.0191,  0.0665,  0.0151],\n                         [ 0.0081,  0.0274,  0.0254]],\n               \n                        ...,\n               \n                        [[-0.0156, -0.0369, -0.0396],\n                         [-0.0357, -0.0406, -0.0490],\n                         [-0.0198, -0.0199, -0.0091]],\n               \n                        [[-0.0108, -0.0109, -0.0155],\n                         [-0.0014, -0.0021, -0.0078],\n                         [ 0.0043,  0.0097, -0.0017]],\n               \n                        [[ 0.0196,  0.0024,  0.0073],\n                         [-0.0013, -0.0046,  0.0061],\n                         [ 0.0128, -0.0097,  0.0283]]]])),\n              ('backbone.models.0.model.layer4.2.bn2.weight',\n               tensor([0.5158, 0.7391, 0.9946, 0.8677, 0.6743, 0.8132, 0.7810, 0.6932, 0.5628,\n                       0.9561, 0.9906, 0.4824, 0.7462, 0.6331, 0.6074, 0.9487, 0.7795, 0.9698,\n                       0.9435, 0.8900, 0.9478, 0.5801, 0.6050, 0.7200, 1.3468, 0.7389, 0.4476,\n                       0.7907, 0.5509, 0.4892, 0.6615, 0.5511, 0.5939, 0.7286, 1.0795, 0.6566,\n                       0.7571, 1.3883, 0.7023, 0.9231, 0.6756, 0.8448, 1.6720, 0.8687, 0.8830,\n                       1.0525, 0.8029, 0.5400, 0.6633, 1.2266, 0.5145, 0.5641, 0.5094, 1.0020,\n                       0.5199, 0.7985, 0.5493, 0.9711, 0.8833, 0.4845, 0.6789, 0.7222, 0.6039,\n                       0.5788, 0.9244, 0.4942, 0.5938, 0.5147, 0.6637, 0.8495, 0.8930, 0.8735,\n                       0.7032, 0.9618, 0.8016, 0.8684, 0.8111, 0.9109, 0.7869, 0.4424, 0.7064,\n                       0.6979, 0.5360, 0.4395, 0.5576, 0.8345, 0.8854, 0.7964, 0.9348, 0.6867,\n                       1.2883, 0.7139, 0.8288, 0.7299, 0.7906, 0.6352, 0.6208, 0.8979, 0.6806,\n                       0.9264, 0.4940, 0.4806, 1.3990, 0.8057, 0.6458, 0.5382, 0.4357, 0.8837,\n                       0.7754, 0.4722, 0.6503, 0.5700, 0.8787, 0.6585, 0.6616, 0.8664, 0.5104,\n                       0.4736, 0.7176, 0.4991, 0.4742, 0.5070, 0.4302, 0.6808, 0.8582, 0.6640,\n                       1.0465, 0.8903, 0.9812, 0.8304, 1.0507, 0.8936, 0.9643, 0.9059, 1.0748,\n                       1.0936, 0.5577, 0.7022, 1.0025, 0.5237, 0.9080, 0.6798, 0.8522, 0.7460,\n                       0.8678, 0.8449, 0.9099, 0.8752, 0.5923, 0.8589, 0.8046, 0.5083, 0.5166,\n                       0.6658, 0.9005, 0.9043, 0.5231, 0.8853, 0.9476, 0.6281, 0.7324, 0.6903,\n                       0.9123, 0.4666, 0.8244, 0.5163, 0.5258, 0.7374, 0.9032, 0.8638, 0.5209,\n                       0.5092, 0.9343, 0.4876, 0.9178, 0.7338, 0.8017, 0.5054, 0.9752, 0.7392,\n                       0.6391, 0.9060, 0.6947, 0.7392, 0.5687, 0.4954, 0.8115, 0.7060, 0.7395,\n                       1.0193, 0.5509, 0.9676, 0.9259, 0.7929, 0.6107, 0.5957, 0.6350, 0.6714,\n                       0.8067, 0.5471, 0.9824, 1.2247, 0.4947, 0.5211, 0.4887, 0.4199, 0.7339,\n                       0.7849, 0.5936, 0.6501, 0.8302, 0.8693, 0.4473, 0.6275, 0.7342, 0.7211,\n                       0.7668, 1.3700, 0.5441, 0.7984, 0.8115, 0.7835, 0.8412, 0.5112, 0.8206,\n                       0.4061, 0.7175, 0.4755, 0.7287, 0.4328, 0.8215, 0.8062, 0.4843, 0.4631,\n                       0.5029, 0.7982, 0.6534, 1.1261, 0.8594, 0.5288, 0.7028, 0.9517, 0.7516,\n                       0.9477, 0.8931, 0.7673, 0.7580, 0.4684, 0.8926, 0.4373, 0.7043, 0.4718,\n                       0.9979, 0.8598, 0.4944, 1.2236, 0.5233, 0.7252, 0.4642, 0.8418, 0.7570,\n                       0.6340, 0.7047, 0.8055, 0.5936, 1.0881, 1.0236, 0.8604, 0.6309, 0.8492,\n                       1.4764, 0.6650, 0.4329, 0.5566, 0.6425, 0.7465, 0.6494, 0.5006, 0.8285,\n                       0.9467, 0.7483, 0.5791, 0.6167, 0.9394, 0.5608, 0.5568, 0.9565, 0.5179,\n                       0.4210, 0.8336, 0.4469, 0.9309, 0.5440, 0.8005, 0.7177, 0.9600, 0.5745,\n                       0.9080, 0.4511, 0.8328, 0.9464, 0.5295, 0.6864, 0.4211, 0.5199, 0.7442,\n                       0.4268, 0.8774, 1.0551, 0.5328, 0.7363, 0.9310, 0.8222, 1.0155, 0.7335,\n                       0.7821, 0.9053, 0.5600, 0.4793, 0.4342, 0.4391, 0.6321, 0.6034, 0.7524,\n                       0.5419, 0.6422, 0.5059, 0.7841, 0.7475, 1.0422, 0.6369, 0.7980, 0.6308,\n                       0.4755, 0.7992, 0.4797, 0.8329, 0.4129, 0.5395, 0.8770, 0.5462, 0.5594,\n                       0.6808, 1.0192, 0.6857, 0.8729, 0.7614, 0.4445, 0.6018, 0.6951, 1.2686,\n                       0.4844, 0.7274, 0.5997, 0.4742, 0.7037, 0.4225, 0.9582, 0.9030, 0.6701,\n                       0.7681, 0.9368, 0.8208, 0.8746, 0.7765, 0.4877, 0.9856, 0.8568, 0.6668,\n                       0.7797, 0.7730, 0.6930, 0.9426, 0.9683, 0.8741, 0.9009, 0.5006, 0.7535,\n                       0.5538, 0.8711, 0.5480, 0.6099, 0.4499, 1.0296, 0.9414, 1.0200, 0.6006,\n                       0.5744, 0.5417, 0.7693, 0.5857, 0.8123, 0.5166, 0.4533, 0.7341, 0.4551,\n                       0.4943, 0.7351, 0.7575, 0.4783, 0.5353, 0.5632, 0.4896, 0.6100, 0.8673,\n                       0.5219, 0.9163, 0.8247, 0.8381, 0.6924, 0.4584, 0.6891, 0.5188, 0.8038,\n                       0.8431, 0.5890, 0.5218, 0.6095, 0.4684, 0.9041, 0.6168, 0.8886, 0.5102,\n                       0.4988, 0.4581, 0.8091, 0.6656, 1.3861, 1.0264, 0.5334, 1.7201, 1.4136,\n                       1.0537, 0.4363, 0.4884, 0.7122, 0.6214, 0.7105, 0.8526, 0.4926, 0.7824,\n                       0.7700, 0.8195, 0.4355, 0.5650, 0.4184, 0.9121, 0.9364, 0.5977, 0.5139,\n                       1.8852, 0.8489, 0.6944, 0.6010, 0.5126, 0.8059, 0.6170, 0.6904, 0.8286,\n                       0.6979, 0.6887, 0.5227, 0.8516, 0.5083, 1.1921, 0.8198, 0.8245, 0.6601,\n                       0.7737, 0.6823, 0.6845, 0.8651, 0.4825, 0.6990, 0.8501, 0.5538, 0.6313,\n                       0.7840, 0.6152, 0.7108, 0.5849, 0.5321, 1.0614, 0.4320, 0.9747, 0.9011,\n                       0.7215, 0.5842, 1.2331, 0.4626, 0.6449, 0.4719, 0.6795, 0.4142, 0.5676,\n                       0.5289, 0.9174, 1.4587, 0.6471, 0.9895, 0.7769, 0.8693, 1.1046, 1.0939,\n                       0.8736, 0.7542, 0.7976, 1.3600, 0.6759, 0.4940, 0.7907, 0.7016])),\n              ('backbone.models.0.model.layer4.2.bn2.bias',\n               tensor([ 9.1064e-02, -3.3643e-01, -1.1471e+00, -8.5623e-01, -2.0167e-01,\n                       -7.7002e-01, -7.1329e-01, -3.8135e-01,  5.2739e-03, -1.3554e+00,\n                       -4.2751e-01,  2.2865e-01, -7.2033e-01,  1.2053e-01, -6.4021e-02,\n                       -5.1435e-01, -4.3851e-01, -1.0189e+00, -1.1659e+00, -8.2104e-01,\n                       -1.1862e+00, -2.2336e-01, -3.9464e-01, -3.3651e-01, -7.9179e-01,\n                       -3.7756e-01,  3.3218e-01, -5.6369e-01,  9.2909e-02,  2.8472e-01,\n                       -2.4592e-01,  9.6797e-02, -1.0210e-01, -9.0396e-01, -1.7681e+00,\n                       -1.5192e-01, -2.3238e-01, -1.7727e+00, -4.1534e-01, -1.1089e+00,\n                       -3.2092e-01, -9.9704e-01, -1.2712e+00, -8.3041e-01, -1.0782e+00,\n                       -9.4070e-01, -8.8617e-01,  6.6000e-02,  1.8644e-02, -1.3365e+00,\n                        2.4130e-01,  7.0461e-03,  1.6292e-01, -1.1994e+00,  1.9497e-01,\n                       -9.0461e-01,  1.0118e-01, -1.0912e+00, -1.0935e+00,  9.5108e-02,\n                       -5.4501e-01, -2.3389e-01, -2.8692e-03,  8.4202e-02, -1.0983e+00,\n                        1.7664e-01,  1.1384e-01,  4.8445e-02, -1.7683e-01, -8.8187e-01,\n                       -1.1426e+00, -7.7361e-01, -1.2152e-01, -1.3707e+00, -1.0049e+00,\n                       -8.1061e-01, -4.9564e-01, -1.0819e+00,  1.9362e-03,  2.5270e-01,\n                       -2.9123e-01, -6.2491e-01,  1.8411e-01,  3.2259e-01,  4.5447e-02,\n                       -6.7121e-01, -8.4417e-01, -4.7692e-01, -1.1922e+00, -3.1299e-01,\n                       -8.9475e-01, -7.3786e-01, -1.0456e+00, -1.8119e-01, -9.1097e-01,\n                       -1.1893e-01, -4.1882e-01, -1.0723e+00, -1.0610e-01, -1.1116e+00,\n                        7.2321e-02,  2.4784e-01, -2.2036e+00, -5.6158e-01, -7.5324e-02,\n                        1.5384e-01,  3.1311e-01, -1.0269e+00, -5.5122e-01,  2.2823e-01,\n                       -4.5289e-01, -3.1539e-02, -9.8095e-01, -1.2550e-01, -6.0000e-01,\n                       -8.8621e-01,  2.3090e-01,  1.9236e-01, -1.2018e-01,  1.1493e+00,\n                        2.8022e-01,  5.4300e-02,  4.5288e-01, -2.7958e-01, -7.8469e-01,\n                       -3.2760e-01, -1.2715e+00, -1.2074e+00, -1.2354e+00, -6.4913e-01,\n                       -1.6171e+00, -1.0766e+00, -1.3839e+00, -1.2217e+00, -1.5200e+00,\n                       -4.7782e-01,  7.2029e-02, -2.2826e-01, -5.7718e-01,  1.3483e-01,\n                       -1.0826e+00, -5.3442e-01, -8.1111e-01, -5.5755e-01, -1.0713e+00,\n                       -7.0612e-01, -1.1533e+00, -8.3191e-01,  1.5686e-01, -7.2613e-01,\n                       -6.3617e-01,  2.1088e-01,  1.0379e-01, -6.3759e-01, -1.0600e+00,\n                       -1.1086e+00,  1.3817e-01, -1.1448e+00, -1.3093e+00, -1.8867e-01,\n                       -6.3622e-01, -1.6494e-01, -1.0866e+00,  1.5177e-01, -8.1406e-01,\n                        1.8498e-01,  5.7871e-02, -4.8924e-01, -8.8832e-01, -1.0582e+00,\n                        1.8317e-01,  2.4597e-01, -1.3231e+00,  1.0043e-01, -8.7653e-01,\n                       -3.3171e-01, -6.4671e-01,  1.1332e-01, -1.2001e+00, -4.7536e-01,\n                       -1.3179e-01, -1.9382e-01, -2.9105e-01, -4.8540e-01,  6.2910e-02,\n                        2.6045e-01, -8.0625e-01, -5.9749e-01, -4.1243e-01, -3.5123e-01,\n                        1.5237e-01, -1.1987e+00, -1.2788e+00, -7.6001e-01, -1.1785e-02,\n                       -9.8987e-02,  1.4577e-02, -2.2312e-01, -2.1042e-01,  1.4855e-01,\n                       -1.0664e+00, -9.2824e-01,  1.8591e-01,  1.5847e-01,  1.7188e-01,\n                        2.8390e-01, -1.9850e-01, -6.5921e-01, -1.0380e-01, -8.4267e-02,\n                       -9.0508e-01, -1.2612e+00,  2.5779e-01, -4.0490e-01, -4.5693e-01,\n                       -1.5596e-01, -5.7267e-01, -2.4769e+00,  2.8448e-03, -6.0531e-01,\n                       -6.4752e-01, -5.0532e-01, -5.2283e-01,  2.0772e-01, -8.8898e-01,\n                        4.9052e-01, -4.6000e-01,  2.3873e-01, -3.4632e-01,  1.8748e-01,\n                       -8.1135e-01, -8.6543e-01,  3.0824e-01,  1.6628e-01,  9.8662e-02,\n                       -8.7485e-01, -6.8707e-01, -1.4774e+00, -1.0373e+00,  1.0289e-01,\n                       -4.1375e-01, -1.2791e+00, -1.6535e-01, -1.2328e+00, -1.0192e+00,\n                       -5.6077e-01, -9.4436e-01,  1.6648e-01, -1.1115e+00,  4.1510e-01,\n                       -2.8155e-01,  3.3676e-01, -9.6336e-01, -7.2862e-01,  2.3675e-01,\n                       -1.5388e+00,  1.7928e-01, -5.8087e-01,  2.3734e-01, -8.9119e-01,\n                       -3.3255e-01, -7.3283e-02, -7.2685e-01, -6.9336e-01,  2.6863e-02,\n                       -1.4079e+00, -1.0152e+00, -7.5872e-01, -2.2386e-01, -3.8857e-01,\n                       -2.0278e+00, -5.4073e-01,  3.0434e-01,  1.1392e-01,  1.2439e-01,\n                       -4.3611e-01, -8.5473e-02,  2.2607e-01, -7.8296e-01, -1.2174e+00,\n                       -5.0722e-01, -4.9017e-02, -1.3063e-01, -4.3634e-01,  5.4584e-02,\n                        1.9994e-01, -1.1954e+00,  1.9025e-01,  1.5926e+00, -6.7552e-01,\n                        2.8597e-01, -1.2116e+00,  1.9934e-01, -6.6534e-01, -3.7769e-01,\n                       -1.0690e+00,  2.5579e-01, -1.3687e+00,  2.3851e-01, -9.3391e-01,\n                       -1.0052e+00,  1.3849e-01, -1.2567e-01,  3.6540e-01,  7.7302e-03,\n                       -2.8625e-01,  4.5494e-01, -1.0762e+00, -1.1721e+00,  7.2441e-02,\n                       -3.5675e-01, -1.1943e+00, -8.0020e-01, -1.4364e+00, -4.5658e-01,\n                       -5.8994e-01, -7.4397e-01,  3.5448e-02,  2.0177e-01,  3.6998e-01,\n                        4.2055e-01, -1.2245e-01, -6.4721e-02, -4.7509e-01,  3.3853e-01,\n                       -5.8495e-02,  1.9278e-01, -7.3598e-01, -4.2114e-01, -1.3690e+00,\n                       -1.0786e-01, -1.0021e+00, -2.6037e-01,  2.1382e-01, -9.2005e-01,\n                        2.3990e-01, -5.9099e-01,  3.3589e-01,  1.7446e-01, -1.1489e+00,\n                        1.9748e-01,  1.3173e-01, -1.0405e-01, -1.3971e+00, -1.7080e-01,\n                       -9.4985e-01, -7.9066e-01,  4.2426e-01, -5.7869e-01, -6.4533e-01,\n                       -1.8725e+00,  1.9270e-01, -6.8050e-01, -3.0534e-01,  2.0811e-01,\n                       -7.4846e-01,  5.8607e-01, -7.6311e-01, -9.6319e-01, -3.5861e-01,\n                       -5.7967e-01, -1.2671e+00, -8.2548e-01, -1.0460e+00, -8.1889e-01,\n                        1.9274e-01, -1.2824e+00, -7.7421e-01, -2.2469e-01, -8.6691e-01,\n                       -7.9103e-01, -8.9485e-01, -1.2540e+00, -1.4497e+00, -9.3647e-01,\n                       -1.3315e+00, -2.0286e-01, -2.0505e+00,  1.9617e-01, -9.4063e-01,\n                        2.5895e-01, -1.7183e-01,  3.0444e-01, -1.4837e+00, -1.3021e+00,\n                       -1.6797e+00, -1.0953e-01,  6.3308e-02,  6.3817e-02, -6.7594e-01,\n                       -6.0992e-02, -6.0201e-01,  5.4058e-02,  3.7039e-01, -5.3417e-01,\n                        3.3865e-01, -1.1216e-01, -9.2187e-01, -1.6113e-01,  2.2922e-01,\n                        2.2304e-01,  8.0189e-02,  1.8032e-01, -2.9749e-01, -9.6494e-01,\n                        1.2286e-01, -9.0945e-02, -5.9570e-01, -7.8013e-01, -4.6698e-01,\n                        2.5036e-01, -5.4308e-01,  1.7503e-01, -6.3040e-01, -8.2904e-01,\n                       -5.6277e-03,  9.2505e-02, -1.0977e-01,  2.3660e-01, -1.1665e+00,\n                       -2.3958e-02, -1.1734e+00,  1.1351e-01,  2.2991e-01,  3.2569e-01,\n                       -9.2123e-01, -3.1437e-01, -2.0457e+00, -1.2833e+00,  8.5935e-02,\n                       -1.3077e+00, -1.4619e+00, -1.2006e+00,  5.8454e-01,  2.4942e-01,\n                       -3.8245e-01,  9.0111e-02, -4.0409e-01, -4.6692e-01,  3.1046e-01,\n                       -9.9879e-01, -4.8882e-01, -1.0265e+00,  3.2204e-01, -2.9124e-01,\n                        4.6786e-01, -8.9062e-01, -9.5167e-01, -1.4708e-02,  2.4556e-01,\n                       -1.5649e+00, -7.3013e-01, -2.6297e-01, -7.1693e-02, -3.7758e-02,\n                       -7.4810e-01, -6.3331e-02, -2.3759e-01, -9.8854e-01, -2.8637e-01,\n                       -8.1374e-02,  1.7402e-01, -4.8529e-01,  1.6984e-01, -2.1874e+00,\n                       -9.7392e-01, -7.0541e-01, -3.9896e-01, -8.4109e-01, -1.0796e-01,\n                       -5.7816e-01, -1.0989e+00,  1.9251e-01, -3.6463e-01, -1.6586e-01,\n                        1.4126e-01,  9.5666e-02, -6.0635e-01,  6.4906e-02,  8.6713e-02,\n                       -1.0013e-01,  8.1101e-02, -4.9592e-01,  2.6843e-01, -1.3243e+00,\n                       -7.6122e-01, -2.3938e-01,  7.3758e-02, -1.6256e+00,  3.0815e-01,\n                       -1.3157e-01,  2.4939e-01, -4.8665e-01,  5.1851e-01, -4.0881e-04,\n                        5.5041e-02, -1.0648e+00, -1.9761e+00, -7.1313e-02, -1.3702e+00,\n                       -5.9474e-01, -1.0092e+00, -9.2581e-01, -1.6935e+00, -1.0344e+00,\n                       -7.1818e-01, -5.8967e-01, -2.2616e+00, -4.5177e-01,  1.1076e-01,\n                       -6.3042e-01, -3.6315e-01])),\n              ('backbone.models.0.model.layer4.2.bn2.running_mean',\n               tensor([-8.5316e-02, -4.3081e-02, -1.6459e-01, -9.5112e-02, -1.2907e-01,\n                       -9.8289e-02, -2.4905e-02, -1.3865e-01, -1.3810e-01, -2.0676e-01,\n                       -1.9890e-01, -4.4052e-02, -8.4423e-02, -2.2273e-01, -6.5978e-02,\n                       -8.0754e-02, -1.1964e-01, -1.4366e-01, -1.7507e-01, -1.6217e-01,\n                       -9.5888e-02, -7.1389e-02, -3.5791e-02, -1.2564e-01, -2.0106e-01,\n                       -1.3020e-01,  7.7805e-03, -8.8999e-02, -9.2805e-02, -3.2458e-02,\n                       -1.3065e-01, -8.0514e-02, -1.1396e-01, -8.6914e-02, -8.3194e-02,\n                       -1.2244e-01, -6.6717e-02, -4.7090e-02, -1.6017e-01, -1.2387e-01,\n                       -4.3019e-02, -5.7119e-02, -1.9909e-01, -6.9144e-02, -9.0185e-02,\n                       -1.0184e-01, -2.2672e-02, -3.7117e-02, -1.4897e-01, -1.4882e-02,\n                       -3.2450e-02, -8.1160e-02, -3.5314e-02, -1.3707e-01, -9.1456e-02,\n                       -4.9837e-02, -6.9519e-02, -9.2694e-02, -1.7351e-01, -9.2379e-02,\n                       -1.0632e-01, -8.7696e-02, -8.9602e-02, -7.0433e-02, -1.2485e-01,\n                       -5.6193e-02, -9.8043e-02, -7.2747e-02, -4.9148e-03, -1.1405e-01,\n                       -6.0618e-02, -1.5149e-01, -1.6283e-01, -1.0665e-01, -1.3768e-01,\n                       -1.3406e-01, -1.4913e-01, -1.1355e-01, -1.1188e-01, -1.0163e-02,\n                       -1.1718e-01, -3.8184e-02, -4.5425e-02, -6.8804e-02, -9.8966e-02,\n                       -1.5577e-01, -1.6756e-01,  1.8927e-01, -1.2704e-01, -4.1294e-02,\n                       -1.9413e-01, -5.0589e-02, -6.5632e-02, -9.4543e-02, -3.9228e-02,\n                       -1.4609e-01, -1.5897e-01, -1.1450e-01, -3.9173e-02, -1.3011e-01,\n                       -9.5502e-02, -4.5432e-02, -7.1336e-02, -1.1694e-01, -1.0962e-01,\n                       -7.9834e-02, -2.4956e-03, -1.3277e-01, -1.1252e-01, -5.6110e-02,\n                       -5.9768e-02, -1.4170e-01, -1.1083e-01, -1.2143e-01, -2.0663e-02,\n                       -8.3522e-02, -1.0068e-01, -6.1062e-02, -9.2831e-02, -1.2139e-01,\n                        1.7315e-02, -9.1673e-02,  2.1567e-02, -8.0025e-02, -1.2153e-01,\n                       -1.1872e-01, -8.5467e-02, -1.4090e-01, -1.7252e-01, -1.5360e-01,\n                       -1.5464e-01, -7.8400e-02, -6.5511e-02, -6.4333e-02, -8.0149e-02,\n                       -1.8594e-01, -1.0629e-01, -1.0403e-01, -1.2210e-01, -9.2175e-02,\n                       -7.1686e-02, -8.9199e-02, -1.5343e-01,  6.8178e-02, -1.1758e-01,\n                       -1.8266e-01, -1.1857e-01, -1.5853e-01, -6.6691e-02, -9.2094e-02,\n                       -9.2558e-02, -5.8772e-02, -8.4086e-02, -3.3079e-02, -7.7686e-02,\n                       -6.7992e-02, -6.2780e-02, -8.8208e-02, -1.1441e-01, -1.0397e-01,\n                       -1.0109e-01, -2.4493e-02, -8.8701e-02, -1.1808e-01, -1.4229e-01,\n                       -4.9979e-02, -6.1369e-02, -1.1308e-01, -1.9339e-01, -9.0109e-02,\n                       -5.2112e-02, -2.4457e-02, -7.9885e-02, -7.8936e-02, -1.6184e-01,\n                       -6.6739e-02, -7.8788e-02, -4.0679e-02, -1.3518e-01, -1.5425e-01,\n                       -2.2258e-02, -1.4309e-01, -8.4340e-02, -1.9299e-02, -6.0651e-02,\n                       -1.0000e-01, -1.3626e-01, -1.1882e-01, -5.5482e-02, -2.9298e-01,\n                       -8.2210e-02, -1.3289e-01, -1.0097e-01, -8.8206e-02, -7.9258e-02,\n                       -6.0351e-02, -1.0752e-01, -8.6910e-02, -2.6894e-01, -9.8201e-02,\n                       -1.4984e-01, -2.4039e-01, -1.9474e-02, -9.9209e-02, -8.6409e-02,\n                       -7.6078e-02, -3.7014e-02, -7.7231e-02, -1.0392e-01, -4.3304e-02,\n                       -7.3255e-02, -7.3474e-02, -8.8044e-03, -1.7358e-02, -1.3435e-01,\n                        1.1354e-02, -1.4306e-01, -9.6203e-02, -1.2967e-01, -1.4985e-01,\n                       -1.6422e-01, -1.3363e-01, -1.4533e-01, -3.7175e-02, -1.1735e-01,\n                       -3.7160e-02, -1.0376e-01, -1.3241e-02, -1.3712e-01, -6.6781e-02,\n                       -1.0394e-01, -9.8024e-02, -2.6789e-02, -9.0838e-02, -1.1867e-02,\n                       -4.9607e-02, -5.0155e-02, -1.9574e-01, -7.3460e-02, -2.6207e-02,\n                       -8.3333e-02, -1.7060e-01, -9.5959e-02, -1.6205e-01, -1.1464e-01,\n                       -8.4413e-02, -8.2670e-02, -5.2374e-02, -2.5453e-02, -8.4986e-02,\n                       -1.2531e-01, -4.6274e-02, -9.1641e-02, -1.1852e-01, -8.1764e-02,\n                       -2.6753e-02, -9.5489e-02, -1.3273e-01, -4.4600e-02, -8.3097e-02,\n                       -1.2845e-01, -1.0287e-01, -9.5099e-02, -1.0578e-01, -1.0434e-01,\n                       -5.6891e-02, -4.2645e-02, -1.5218e-01, -9.7518e-02, -5.6220e-02,\n                       -2.6126e-02, -3.5333e-02,  3.9100e-03, -8.9155e-02, -1.2995e-02,\n                       -1.0825e-01,  2.3295e-02, -8.1129e-02, -1.1426e-01, -8.8064e-02,\n                       -7.5780e-02, -8.7176e-02, -1.4660e-01, -1.4555e-01, -1.2820e-01,\n                       -1.1479e-01, -1.2910e-01, -8.8581e-02, -2.9994e-01, -1.1539e-01,\n                       -6.8554e-02, -1.3062e-01, -6.1137e-02, -1.5080e-01, -4.1744e-01,\n                       -2.7418e-03, -1.1954e-01, -1.2453e-01, -5.9687e-02, -7.1087e-02,\n                       -1.3822e-01, -8.9225e-02, -5.6459e-02, -6.0292e-02, -8.6675e-02,\n                       -4.4566e-02, -2.2063e-02, -8.5683e-02, -7.6399e-02, -1.1573e-01,\n                       -1.1144e-01, -1.2357e-01, -1.1022e-01, -1.9060e-01, -9.8204e-02,\n                       -1.3035e-01, -1.8307e-01, -1.4196e-01, -5.8465e-02, -2.1834e-02,\n                       -2.5701e-02, -9.8323e-02, -1.0467e-01, -7.3360e-02, -1.2158e-01,\n                       -2.7254e-02, -6.8803e-02, -1.0755e-01, -9.9933e-02, -8.0039e-02,\n                       -1.2138e-01, -6.5036e-02, -6.1607e-02, -4.4499e-02, -9.7140e-02,\n                       -1.3534e-01, -1.0039e-01, -2.2720e-02, -1.1307e-01, -9.6204e-02,\n                       -8.9480e-02, -1.0695e-01, -5.0072e-02, -7.1591e-02, -1.2480e-01,\n                       -9.5175e-02, -1.9446e-02, -2.4213e-05, -6.8266e-02, -1.1926e-01,\n                       -1.2377e-01, -2.9139e-02, -8.5734e-02, -9.5704e-02, -3.7249e-02,\n                        1.5617e-01,  3.3996e-02, -1.3352e-01,  1.9824e-03, -8.5888e-02,\n                       -1.5001e-01, -1.4643e-01, -1.1567e-01, -7.9248e-02, -2.5544e-02,\n                       -1.8406e-02, -1.2868e-01, -1.5231e-01, -9.9659e-02, -1.1050e-01,\n                       -6.8233e-02, -4.6983e-02, -1.3797e-01, -1.2310e-01, -7.3129e-02,\n                       -1.3825e-01,  6.4608e-03, -6.4219e-02, -1.2673e-01, -1.5864e-01,\n                       -9.0555e-02, -1.2894e-01, -3.2980e-02, -3.0431e-02, -1.3758e-01,\n                       -1.5037e-01, -8.8222e-02, -1.5391e-01, -1.3699e-01, -1.2019e-01,\n                        3.0417e-02, -1.2118e-01, -4.4510e-02, -5.3562e-04, -1.0238e-01,\n                       -5.5133e-02, -1.0277e-01, -5.4268e-02, -1.9824e-01, -4.0353e-02,\n                       -7.1319e-02, -7.9223e-02, -6.5026e-02, -7.4742e-02, -1.0414e-01,\n                       -4.0668e-02, -7.0881e-02, -8.5276e-02, -8.8400e-02, -9.2976e-02,\n                       -2.9816e-02, -4.6811e-02, -2.7697e-03, -1.7073e-01, -9.7544e-02,\n                       -8.6838e-02, -9.9329e-02, -5.7090e-02, -4.2923e-02, -1.2859e-01,\n                       -1.3729e-01, -8.5212e-02, -1.1026e-01, -7.8835e-02, -9.0530e-02,\n                       -8.2830e-02, -9.0244e-02, -6.4277e-02, -1.4355e-01, -8.0708e-02,\n                       -1.7037e-01, -6.8918e-02, -1.6229e-01, -2.0174e-02,  1.9298e-02,\n                       -9.8716e-02, -3.0356e-02, -1.2479e-01, -7.6124e-02, -5.1357e-02,\n                       -6.1506e-02, -1.1102e-01, -5.7284e-02, -5.2661e-02, -1.6183e-02,\n                       -4.8454e-03, -1.4169e-01, -1.3995e-01, -1.1442e-01, -1.0361e-02,\n                       -3.3451e-01, -1.2507e-01, -8.3066e-02, -1.2359e-01, -8.8800e-02,\n                       -8.5871e-02, -1.1502e-01, -1.3959e-01, -5.7718e-02, -1.1559e-01,\n                       -1.1756e-01, -6.1959e-02, -5.1183e-02, -3.9836e-02, -6.3742e-02,\n                       -7.0268e-02, -1.0400e-01, -1.3202e-01, -9.8357e-02, -7.5507e-02,\n                       -7.5759e-02, -8.2508e-02, -1.0343e-01, -1.2899e-01, -2.1968e-01,\n                       -8.3258e-02, -1.1571e-01, -1.1666e-01, -1.7329e-01, -1.2331e-01,\n                       -9.3889e-02, -2.2548e-02, -1.8184e-01, -2.1384e-02, -4.7560e-02,\n                       -1.4205e-01, -1.4784e-01, -6.3471e-02, -2.7241e-02, -3.0314e-02,\n                       -1.2047e-01, -3.4324e-03, -1.2964e-03, -4.9495e-02, -8.6996e-02,\n                       -6.4365e-03, -1.1514e-01, -5.0407e-02, -1.3358e-01, -1.2206e-01,\n                       -1.6013e-01, -1.4764e-01, -4.8796e-02, -1.5519e-01, -9.8024e-02,\n                       -1.0839e-01, -1.4899e-01, -7.1578e-02, -5.4381e-02, -5.8773e-03,\n                       -8.3468e-02, -1.0268e-01])),\n              ('backbone.models.0.model.layer4.2.bn2.running_var',\n               tensor([0.0222, 0.0257, 0.0237, 0.0187, 0.0281, 0.0175, 0.0203, 0.0226, 0.0221,\n                       0.0188, 0.0286, 0.0271, 0.0116, 0.0258, 0.0194, 0.0197, 0.0218, 0.0200,\n                       0.0169, 0.0191, 0.0231, 0.0144, 0.0127, 0.0217, 0.0799, 0.0234, 0.0363,\n                       0.0172, 0.0244, 0.0280, 0.0212, 0.0212, 0.0237, 0.0167, 0.0176, 0.0252,\n                       0.0228, 0.0293, 0.0202, 0.0188, 0.0192, 0.0119, 0.0932, 0.0205, 0.0179,\n                       0.0234, 0.0246, 0.0272, 0.0651, 0.0312, 0.0418, 0.0239, 0.0219, 0.0219,\n                       0.0329, 0.0316, 0.0200, 0.0178, 0.0190, 0.0242, 0.0154, 0.0250, 0.0316,\n                       0.0323, 0.0157, 0.0248, 0.0487, 0.0302, 0.0214, 0.0202, 0.0224, 0.0274,\n                       0.0245, 0.0169, 0.0215, 0.0209, 0.0260, 0.0206, 0.0640, 0.0282, 0.0262,\n                       0.0183, 0.0366, 0.0241, 0.0236, 0.0220, 0.0183, 0.0190, 0.0144, 0.0262,\n                       0.0822, 0.0260, 0.0169, 0.0241, 0.0199, 0.0222, 0.0165, 0.0178, 0.0208,\n                       0.0203, 0.0229, 0.0350, 0.0217, 0.0193, 0.0259, 0.0226, 0.0286, 0.0167,\n                       0.0199, 0.0271, 0.0158, 0.0240, 0.0189, 0.0249, 0.0159, 0.0153, 0.0479,\n                       0.0248, 0.0294, 0.0630, 0.0336, 0.0175, 0.0332, 0.0246, 0.0176, 0.0222,\n                       0.0164, 0.0148, 0.0177, 0.0222, 0.0173, 0.0140, 0.0223, 0.0166, 0.0236,\n                       0.0526, 0.0295, 0.0238, 0.0290, 0.0329, 0.0199, 0.0144, 0.0183, 0.0306,\n                       0.0158, 0.0171, 0.0161, 0.0217, 0.0535, 0.0213, 0.0157, 0.0311, 0.0222,\n                       0.0209, 0.0178, 0.0245, 0.0292, 0.0221, 0.0159, 0.0232, 0.0237, 0.0182,\n                       0.0136, 0.0222, 0.0203, 0.0282, 0.0227, 0.0192, 0.0175, 0.0199, 0.0339,\n                       0.0446, 0.0171, 0.0222, 0.0195, 0.0177, 0.0276, 0.0246, 0.0202, 0.0242,\n                       0.0222, 0.0572, 0.0194, 0.0167, 0.0279, 0.0318, 0.0266, 0.0137, 0.0357,\n                       0.0697, 0.0315, 0.0191, 0.0138, 0.0221, 0.0190, 0.0234, 0.0265, 0.0297,\n                       0.0583, 0.0460, 0.0230, 0.0310, 0.0316, 0.0321, 0.0298, 0.0225, 0.0254,\n                       0.0159, 0.0208, 0.0189, 0.0151, 0.0114, 0.0317, 0.0131, 0.0209, 0.0256,\n                       0.0227, 0.0154, 0.0176, 0.0169, 0.0172, 0.0222, 0.0223, 0.0385, 0.0149,\n                       0.0265, 0.0210, 0.0337, 0.0175, 0.0186, 0.0218, 0.0200, 0.0329, 0.0237,\n                       0.0219, 0.0260, 0.0189, 0.0241, 0.0251, 0.0283, 0.0240, 0.0263, 0.0276,\n                       0.0215, 0.0192, 0.0211, 0.0136, 0.0280, 0.0221, 0.0272, 0.0245, 0.0370,\n                       0.0206, 0.0187, 0.0383, 0.0254, 0.0293, 0.0183, 0.0216, 0.0194, 0.0237,\n                       0.0241, 0.0163, 0.0152, 0.0300, 0.0183, 0.0330, 0.0177, 0.0218, 0.0233,\n                       0.0050, 0.0211, 0.0295, 0.0361, 0.0562, 0.0214, 0.0228, 0.0351, 0.0160,\n                       0.0199, 0.0203, 0.0269, 0.0244, 0.0284, 0.0244, 0.0391, 0.0208, 0.0319,\n                       0.0413, 0.0217, 0.0212, 0.0267, 0.0445, 0.0174, 0.0180, 0.0270, 0.0272,\n                       0.0133, 0.0279, 0.0186, 0.0155, 0.0303, 0.0268, 0.0265, 0.0213, 0.0196,\n                       0.0361, 0.0183, 0.0280, 0.0230, 0.0189, 0.0159, 0.0203, 0.0209, 0.0203,\n                       0.0197, 0.0238, 0.0319, 0.0234, 0.0259, 0.0323, 0.0215, 0.0204, 0.0203,\n                       0.0524, 0.0232, 0.0341, 0.0168, 0.0199, 0.0184, 0.0247, 0.0186, 0.0244,\n                       0.0249, 0.0179, 0.0296, 0.0213, 0.0226, 0.0399, 0.0196, 0.0481, 0.0358,\n                       0.0233, 0.0171, 0.0202, 0.0144, 0.0167, 0.0364, 0.0147, 0.0162, 0.0232,\n                       0.0311, 0.0116, 0.0249, 0.0282, 0.0096, 0.0346, 0.0225, 0.0192, 0.0137,\n                       0.0182, 0.0182, 0.0173, 0.0094, 0.0175, 0.0308, 0.0175, 0.0153, 0.0210,\n                       0.0182, 0.0188, 0.0148, 0.0179, 0.0126, 0.0187, 0.0218, 0.0116, 0.0051,\n                       0.0499, 0.0153, 0.0525, 0.0267, 0.0285, 0.0172, 0.0188, 0.0226, 0.0217,\n                       0.0309, 0.0273, 0.0224, 0.0194, 0.0218, 0.0202, 0.0339, 0.0256, 0.0324,\n                       0.0120, 0.0171, 0.0260, 0.0245, 0.0373, 0.0279, 0.0250, 0.0176, 0.0188,\n                       0.0272, 0.0428, 0.0214, 0.0171, 0.0226, 0.0258, 0.0161, 0.0390, 0.0210,\n                       0.0178, 0.0278, 0.0237, 0.0164, 0.0219, 0.0194, 0.0246, 0.0214, 0.0196,\n                       0.0309, 0.0275, 0.0174, 0.0190, 0.0310, 0.0314, 0.0306, 0.0786, 0.0461,\n                       0.0229, 0.0340, 0.0457, 0.0229, 0.0196, 0.0193, 0.0227, 0.0386, 0.0192,\n                       0.0205, 0.0190, 0.0264, 0.0342, 0.0263, 0.0206, 0.0205, 0.0263, 0.0348,\n                       0.0807, 0.0205, 0.0149, 0.0198, 0.0208, 0.0165, 0.0198, 0.0225, 0.0149,\n                       0.0206, 0.0264, 0.0301, 0.0206, 0.0302, 0.0167, 0.0172, 0.0234, 0.0195,\n                       0.0160, 0.0242, 0.0226, 0.0136, 0.0289, 0.0198, 0.0870, 0.0472, 0.0692,\n                       0.0208, 0.0284, 0.1073, 0.0226, 0.0249, 0.0621, 0.0275, 0.0190, 0.0229,\n                       0.0251, 0.0244, 0.0280, 0.0390, 0.0303, 0.0287, 0.0345, 0.0280, 0.0162,\n                       0.0298, 0.0194, 0.0340, 0.0292, 0.0162, 0.0149, 0.0163, 0.0241, 0.0204,\n                       0.0155, 0.0147, 0.0176, 0.0208, 0.0176, 0.0288, 0.0185, 0.0191])),\n              ('backbone.models.0.model.layer4.2.bn2.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.layer4.2.conv3.weight',\n               tensor([[[[-0.0158]],\n               \n                        [[-0.0171]],\n               \n                        [[ 0.0303]],\n               \n                        ...,\n               \n                        [[ 0.0035]],\n               \n                        [[ 0.0343]],\n               \n                        [[-0.0180]]],\n               \n               \n                       [[[-0.0563]],\n               \n                        [[-0.0168]],\n               \n                        [[ 0.0436]],\n               \n                        ...,\n               \n                        [[-0.0178]],\n               \n                        [[ 0.0024]],\n               \n                        [[ 0.0230]]],\n               \n               \n                       [[[ 0.0627]],\n               \n                        [[ 0.0058]],\n               \n                        [[-0.0150]],\n               \n                        ...,\n               \n                        [[-0.0081]],\n               \n                        [[-0.0046]],\n               \n                        [[-0.0275]]],\n               \n               \n                       ...,\n               \n               \n                       [[[ 0.0161]],\n               \n                        [[ 0.0110]],\n               \n                        [[-0.0334]],\n               \n                        ...,\n               \n                        [[-0.0278]],\n               \n                        [[-0.0086]],\n               \n                        [[-0.0169]]],\n               \n               \n                       [[[ 0.0163]],\n               \n                        [[-0.0008]],\n               \n                        [[ 0.0111]],\n               \n                        ...,\n               \n                        [[ 0.0259]],\n               \n                        [[-0.0009]],\n               \n                        [[-0.0144]]],\n               \n               \n                       [[[ 0.0443]],\n               \n                        [[-0.0278]],\n               \n                        [[ 0.0252]],\n               \n                        ...,\n               \n                        [[ 0.0554]],\n               \n                        [[-0.0036]],\n               \n                        [[-0.0190]]]])),\n              ('backbone.models.0.model.layer4.2.bn3.weight',\n               tensor([-0.5612, -0.4450,  0.4642,  ...,  0.3919, -0.5489, -0.4000])),\n              ('backbone.models.0.model.layer4.2.bn3.bias',\n               tensor([-0.3569, -0.1289, -0.1623,  ..., -0.3066, -0.4122, -0.2226])),\n              ('backbone.models.0.model.layer4.2.bn3.running_mean',\n               tensor([ 0.3719,  0.5025, -0.2834,  ..., -0.2561,  0.4722,  0.2906])),\n              ('backbone.models.0.model.layer4.2.bn3.running_var',\n               tensor([0.0803, 0.0765, 0.0756,  ..., 0.0548, 0.0752, 0.0891])),\n              ('backbone.models.0.model.layer4.2.bn3.num_batches_tracked',\n               tensor(54200)),\n              ('backbone.models.0.model.fc.weight',\n               tensor([[-0.0419,  0.0257,  0.0709,  ...,  0.0563,  0.0675, -0.0920],\n                       [-0.0381, -0.0113,  0.0021,  ..., -0.0665, -0.0499,  0.1144],\n                       [-0.0521, -0.0574, -0.0193,  ..., -0.0400,  0.2319, -0.1346],\n                       ...,\n                       [-0.0329, -0.0587, -0.0778,  ..., -0.0762, -0.0573, -0.1138],\n                       [ 0.0087,  0.0054,  0.0215,  ..., -0.0827, -0.0723, -0.0055],\n                       [-0.0548, -0.0023,  0.0126,  ...,  0.2156,  0.0070, -0.1120]])),\n              ('backbone.models.0.model.fc.bias',\n               tensor([-0.6761, -0.7533, -0.6970, -0.6467, -0.6993, -0.7049, -0.7113, -0.6955,\n                       -0.7309, -0.7596, -0.6745, -0.6593, -0.6961, -0.7079, -0.6676, -0.7302,\n                       -0.6650, -0.6932, -0.6084, -0.7755, -0.6585, -0.6221, -0.6553, -0.7052,\n                       -0.6570, -0.7236, -0.6819, -0.7021, -0.6522, -0.6739, -0.7427, -0.6294,\n                       -0.6181, -0.6542, -0.6526, -0.6531, -0.7621, -0.6677, -0.7038, -0.7602,\n                       -0.7318, -0.6337, -0.6486, -0.6991, -0.7089, -0.7215, -0.7066, -0.7027,\n                       -0.7075, -0.6434, -0.7031, -0.6653, -0.7546, -0.6515, -0.7305, -0.6757,\n                       -0.6532, -0.7078, -0.6572, -0.7560, -0.6683, -0.6395, -0.7021, -0.6510,\n                       -0.6525, -0.7261, -0.6849, -0.6698, -0.6785, -0.6928, -0.6919, -0.7297,\n                       -0.7320, -0.6721, -0.6260, -0.7376, -0.6385, -0.5952, -0.7300, -0.7410,\n                       -0.7431, -0.7454, -0.6641, -0.7356, -0.7235, -0.6443, -0.7097, -0.7191,\n                       -0.6710, -0.7017, -0.6634, -0.6696, -0.6754, -0.6593, -0.6880, -0.6659,\n                       -0.7442, -0.7188, -0.6886, -0.7138])),\n              ('backbone.classifiers.0.weight',\n               tensor([[-0.0419,  0.0257,  0.0709,  ...,  0.0563,  0.0675, -0.0920],\n                       [-0.0381, -0.0113,  0.0021,  ..., -0.0665, -0.0499,  0.1144],\n                       [-0.0521, -0.0574, -0.0193,  ..., -0.0400,  0.2319, -0.1346],\n                       ...,\n                       [-0.0329, -0.0587, -0.0778,  ..., -0.0762, -0.0573, -0.1138],\n                       [ 0.0087,  0.0054,  0.0215,  ..., -0.0827, -0.0723, -0.0055],\n                       [-0.0548, -0.0023,  0.0126,  ...,  0.2156,  0.0070, -0.1120]])),\n              ('backbone.classifiers.0.bias',\n               tensor([-0.6761, -0.7533, -0.6970, -0.6467, -0.6993, -0.7049, -0.7113, -0.6955,\n                       -0.7309, -0.7596, -0.6745, -0.6593, -0.6961, -0.7079, -0.6676, -0.7302,\n                       -0.6650, -0.6932, -0.6084, -0.7755, -0.6585, -0.6221, -0.6553, -0.7052,\n                       -0.6570, -0.7236, -0.6819, -0.7021, -0.6522, -0.6739, -0.7427, -0.6294,\n                       -0.6181, -0.6542, -0.6526, -0.6531, -0.7621, -0.6677, -0.7038, -0.7602,\n                       -0.7318, -0.6337, -0.6486, -0.6991, -0.7089, -0.7215, -0.7066, -0.7027,\n                       -0.7075, -0.6434, -0.7031, -0.6653, -0.7546, -0.6515, -0.7305, -0.6757,\n                       -0.6532, -0.7078, -0.6572, -0.7560, -0.6683, -0.6395, -0.7021, -0.6510,\n                       -0.6525, -0.7261, -0.6849, -0.6698, -0.6785, -0.6928, -0.6919, -0.7297,\n                       -0.7320, -0.6721, -0.6260, -0.7376, -0.6385, -0.5952, -0.7300, -0.7410,\n                       -0.7431, -0.7454, -0.6641, -0.7356, -0.7235, -0.6443, -0.7097, -0.7191,\n                       -0.6710, -0.7017, -0.6634, -0.6696, -0.6754, -0.6593, -0.6880, -0.6659,\n                       -0.7442, -0.7188, -0.6886, -0.7138]))]),\n 'loops': {'fit_loop': {'state_dict': {},\n   'epoch_loop.state_dict': {'_batches_that_stepped': 2046},\n   'epoch_loop.batch_progress': {'total': {'ready': 2046,\n     'completed': 2046,\n     'started': 2046,\n     'processed': 2046},\n    'current': {'ready': 93, 'completed': 93, 'started': 93, 'processed': 93},\n    'is_last_batch': True},\n   'epoch_loop.scheduler_progress': {'total': {'ready': 2046,\n     'completed': 2046},\n    'current': {'ready': 93, 'completed': 93}},\n   'epoch_loop.automatic_optimization.state_dict': {},\n   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 2046,\n       'completed': 2046},\n      'current': {'ready': 93, 'completed': 93}},\n     'zero_grad': {'total': {'ready': 2046,\n       'completed': 2046,\n       'started': 2046},\n      'current': {'ready': 93, 'completed': 93, 'started': 93}}}},\n   'epoch_loop.manual_optimization.state_dict': {},\n   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n     'completed': 0},\n    'current': {'ready': 0, 'completed': 0}},\n   'epoch_loop.val_loop.state_dict': {},\n   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 5,\n     'completed': 5,\n     'started': 5,\n     'processed': 5},\n    'current': {'ready': 5, 'completed': 5, 'started': 5, 'processed': 5},\n    'is_last_batch': True},\n   'epoch_progress': {'total': {'ready': 22,\n     'completed': 21,\n     'started': 22,\n     'processed': 22},\n    'current': {'ready': 22,\n     'completed': 21,\n     'started': 22,\n     'processed': 22}}},\n  'validate_loop': {'state_dict': {},\n   'batch_progress': {'total': {'ready': 0,\n     'completed': 0,\n     'started': 0,\n     'processed': 0},\n    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n    'is_last_batch': False}},\n  'test_loop': {'state_dict': {},\n   'batch_progress': {'total': {'ready': 0,\n     'completed': 0,\n     'started': 0,\n     'processed': 0},\n    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n    'is_last_batch': False}},\n  'predict_loop': {'state_dict': {},\n   'batch_progress': {'total': {'ready': 0,\n     'completed': 0,\n     'started': 0,\n     'processed': 0},\n    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n 'callbacks': {\"ModelCheckpoint{'monitor': 'val_0/loss', 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': 'val_0/loss',\n   'best_model_score': tensor(3.4514),\n   'best_model_path': './checkpoints/epoch=21_step=2046_val_0_loss=3.4514.ckpt',\n   'current_score': tensor(3.4514),\n   'dirpath': './checkpoints',\n   'best_k_models': {'./checkpoints/epoch=17_step=1674_val_0_loss=4.9583.ckpt': tensor(4.9583),\n    './checkpoints/epoch=18_step=1767_val_0_loss=4.9362.ckpt': tensor(4.9362),\n    './checkpoints/epoch=19_step=1860_val_0_loss=4.8586.ckpt': tensor(4.8586),\n    './checkpoints/epoch=20_step=1953_val_0_loss=3.5342.ckpt': tensor(3.5342),\n    './checkpoints/epoch=21_step=2046_val_0_loss=3.4514.ckpt': tensor(3.4514)},\n   'kth_best_model_path': './checkpoints/epoch=17_step=1674_val_0_loss=4.9583.ckpt',\n   'kth_value': tensor(4.9583),\n   'last_model_path': './checkpoints/last-v20.ckpt'}},\n 'optimizer_states': [{'state': {0: {'exp_avg': tensor([-8.6630e-04,  4.1536e-03,  2.3014e-03,  2.2731e-04,  2.4320e-04,\n              4.1539e-04, -2.8704e-03,  1.1969e-04,  1.8673e-03,  7.9322e-04,\n              2.6622e-03, -7.0271e-04,  2.8717e-04,  4.9199e-04,  3.4715e-03,\n              9.2913e-04, -3.9761e-03, -1.3630e-03, -2.2214e-05, -2.0715e-03,\n             -5.0542e-04,  8.5029e-04, -2.5268e-03,  2.1804e-03, -9.4408e-04,\n              9.1311e-04, -1.8016e-03,  1.5771e-03, -2.5125e-03, -5.5625e-04,\n             -3.0443e-03, -1.6771e-03,  9.4802e-04,  2.6025e-03,  6.7443e-04,\n             -2.6803e-03, -5.7450e-04, -1.2624e-03,  3.1909e-03, -4.4006e-03,\n             -6.0592e-05,  6.5256e-04, -2.3725e-03,  6.8315e-04, -6.2356e-04,\n             -5.1573e-05, -1.6204e-04, -2.1371e-03, -3.4163e-05, -8.0431e-04,\n             -1.1930e-03,  3.0992e-03,  5.4762e-04,  2.9483e-03,  9.0981e-04,\n              1.1645e-03, -9.7601e-04,  2.4249e-04, -8.4979e-04, -3.4082e-04,\n              1.8856e-03,  2.0890e-03, -6.4792e-05,  1.2390e-03]),\n     'exp_avg_sq': tensor([2.1798e-05, 7.9751e-06, 1.2044e-05, 3.8874e-06, 5.5135e-06, 3.7431e-05,\n             1.8548e-05, 3.7140e-05, 9.8765e-06, 1.0261e-05, 3.6997e-05, 9.8650e-06,\n             1.3157e-05, 3.5061e-06, 1.0030e-05, 1.2492e-05, 1.3538e-05, 1.2235e-05,\n             1.8932e-05, 1.2073e-05, 1.3856e-05, 1.1613e-05, 6.2105e-05, 1.2555e-05,\n             2.2036e-05, 1.3807e-05, 1.8727e-05, 1.3384e-05, 1.2980e-05, 1.0705e-05,\n             9.8612e-06, 9.1198e-06, 8.6855e-06, 5.7293e-06, 4.5157e-06, 6.3511e-05,\n             9.8251e-06, 8.8264e-06, 9.4638e-06, 1.5849e-05, 7.4648e-06, 4.4499e-06,\n             7.5025e-06, 1.8595e-05, 1.2811e-05, 1.1873e-05, 2.8626e-06, 1.2700e-05,\n             1.0195e-05, 7.0802e-06, 6.2094e-05, 1.2689e-05, 1.2651e-05, 1.4431e-05,\n             1.0334e-05, 9.0182e-06, 8.3758e-06, 8.0555e-06, 3.2655e-06, 1.6168e-05,\n             1.0032e-05, 6.8697e-06, 5.3101e-06, 1.9498e-05])},\n    1: {'exp_avg': tensor([-2.5434e-04,  3.0653e-05,  1.6506e-10,  1.5529e-04,  1.0568e-05,\n             -6.0444e-05,  7.9229e-07, -1.0167e-05, -6.0093e-04,  9.2509e-06,\n             -4.6143e-05, -4.0799e-06,  5.1617e-10, -4.3531e-04, -4.2436e-05,\n             -8.3725e-11,  6.9333e-11, -1.2077e-05,  1.2240e-06, -5.8469e-06,\n             -4.4480e-05,  1.8217e-03,  2.4752e-05,  2.1749e-04,  2.5917e-09,\n             -1.2565e-09,  1.1117e-05,  1.8513e-06,  1.2201e-09,  2.5102e-05,\n              1.3082e-08,  5.3267e-05, -2.9694e-06,  5.6296e-04,  4.7618e-05,\n             -1.3302e-05, -1.4213e-04,  2.5922e-05,  1.8056e-04,  1.0849e-09,\n              1.0056e-04,  5.9517e-05, -2.8658e-04, -2.6887e-05, -1.1551e-09,\n              2.7952e-06,  4.2987e-10,  6.1186e-07, -3.0116e-06,  4.5397e-06,\n             -1.5499e-04,  9.5457e-06,  9.0891e-06,  6.6638e-05,  2.9196e-06,\n              7.6682e-05,  5.0398e-08, -1.2170e-09,  6.5568e-05, -6.4162e-09,\n              4.3841e-07,  1.0755e-04, -8.0192e-05,  1.1705e-04]),\n     'exp_avg_sq': tensor([3.0003e-07, 1.5121e-09, 4.4061e-18, 2.0563e-06, 1.9843e-10, 4.1440e-09,\n             1.1846e-10, 9.9932e-11, 2.5791e-06, 3.6460e-09, 1.3116e-08, 7.7374e-11,\n             7.2079e-18, 6.3173e-07, 1.7861e-08, 4.4469e-18, 6.8581e-18, 3.2544e-09,\n             4.1519e-10, 1.9842e-10, 3.7595e-08, 5.5898e-06, 6.2059e-09, 7.7816e-08,\n             1.0878e-17, 5.8520e-18, 6.6031e-09, 4.1617e-11, 6.7069e-18, 1.0221e-09,\n             2.3628e-15, 3.7582e-08, 3.0083e-11, 2.9919e-07, 7.8176e-07, 3.9909e-09,\n             7.5628e-08, 4.0358e-09, 1.1315e-07, 6.7679e-18, 5.0712e-08, 8.9461e-07,\n             1.1935e-07, 6.4613e-09, 5.7400e-18, 2.1283e-10, 1.1732e-17, 3.1674e-12,\n             1.0017e-09, 3.1973e-11, 2.1426e-08, 3.6656e-08, 3.4044e-10, 1.4216e-09,\n             2.2522e-09, 3.0697e-08, 1.7851e-13, 7.3879e-18, 3.6528e-08, 3.4464e-15,\n             2.2405e-11, 2.1122e-07, 2.6203e-07, 4.4839e-07])},\n    2: {'exp_avg': tensor([-2.8744e-04, -8.4427e-04, -7.1773e-04, -1.3866e-03, -7.3580e-04,\n              7.2148e-03,  3.3205e-04, -8.4795e-04, -5.8341e-04, -1.2819e-04,\n              1.0920e-03, -3.6619e-04,  4.1582e-04, -1.0394e-04,  4.3398e-04,\n              2.4897e-04, -2.6329e-04,  7.4608e-04,  3.1667e-04, -1.3926e-04,\n              7.7644e-06, -5.6543e-04,  1.1488e-04,  5.6999e-04,  2.8874e-04,\n             -2.6518e-04,  5.5062e-04,  2.4974e-04, -3.7835e-04,  4.4134e-04,\n              1.3322e-04, -2.4363e-04, -2.2320e-04, -2.3369e-04,  6.1719e-04,\n             -1.8633e-03, -5.5818e-04,  1.7762e-04, -4.6947e-05,  2.9964e-04,\n              6.0903e-04, -9.4623e-04,  4.6870e-04, -1.2583e-05,  8.4224e-04,\n             -2.2528e-04, -8.9754e-05, -9.4923e-04,  6.1523e-04,  1.8520e-05,\n              1.8467e-05,  1.9655e-04, -8.6021e-04,  3.5913e-04,  9.8617e-05,\n             -1.3102e-03,  7.1338e-04, -1.3669e-04,  2.2535e-04, -3.9295e-04,\n             -3.1174e-04,  2.1049e-04,  2.2220e-04, -9.4001e-04]),\n     'exp_avg_sq': tensor([7.1375e-07, 2.0607e-06, 1.0024e-06, 3.0133e-06, 6.3054e-07, 3.5789e-05,\n             6.6148e-07, 1.8449e-06, 1.6019e-06, 6.1713e-07, 4.7275e-06, 1.3594e-06,\n             5.6953e-07, 9.0322e-07, 1.5779e-06, 5.2067e-07, 6.1144e-07, 4.2069e-06,\n             5.3252e-07, 9.1971e-06, 3.8124e-07, 1.1757e-06, 8.7803e-07, 1.0054e-06,\n             2.5718e-07, 1.4560e-06, 6.2597e-07, 1.2138e-06, 6.3791e-07, 1.0402e-06,\n             6.6675e-07, 2.2529e-06, 1.1853e-06, 1.2894e-06, 4.5448e-07, 3.2770e-06,\n             4.5436e-07, 5.3131e-07, 7.9371e-07, 1.3659e-06, 6.4443e-07, 3.9218e-06,\n             6.5203e-07, 3.5206e-07, 5.6070e-06, 4.8350e-07, 9.9749e-07, 9.4264e-07,\n             5.1240e-07, 2.2129e-06, 7.0538e-07, 5.6126e-07, 1.0390e-06, 5.7463e-06,\n             9.7003e-07, 4.9296e-07, 5.5018e-07, 5.7464e-07, 4.0860e-07, 4.3541e-07,\n             3.5503e-07, 4.6498e-07, 3.8387e-07, 2.1361e-06])},\n    3: {'exp_avg': tensor([-1.5245e-04,  1.0526e-03,  5.1570e-05, -2.2079e-05, -7.7784e-04,\n              3.8612e-03,  4.2989e-04, -4.2373e-04, -5.5657e-04, -2.6492e-04,\n              1.2982e-04, -1.1230e-03,  2.0811e-04, -1.3555e-04,  4.7512e-04,\n              2.7322e-04, -3.3937e-04, -9.1984e-05,  2.2816e-04,  4.1020e-04,\n             -7.1576e-05,  1.1739e-04, -9.6513e-05,  1.0333e-03,  2.8953e-04,\n             -3.9908e-04,  2.2063e-04, -8.4062e-05, -5.3519e-04,  7.0128e-05,\n              1.1850e-04,  2.9371e-04, -3.4678e-04, -4.9268e-05,  5.3185e-04,\n              5.7295e-04, -1.3643e-03,  2.6907e-04, -1.5009e-04,  6.5187e-04,\n              9.7776e-04, -5.9080e-04,  3.5178e-06, -1.8938e-04,  4.0051e-04,\n              2.1446e-04, -9.4395e-04, -1.4004e-04,  4.9848e-04,  6.8517e-04,\n             -1.1710e-03,  7.7556e-05, -1.1583e-04, -7.4947e-04, -3.8923e-05,\n             -1.9435e-03,  8.9980e-04, -9.4598e-04,  3.7128e-04, -9.3215e-05,\n              4.8893e-04,  2.4461e-04,  1.8843e-04, -5.7973e-04]),\n     'exp_avg_sq': tensor([1.0954e-06, 1.5277e-06, 6.6939e-07, 6.0859e-07, 5.0690e-07, 1.2122e-05,\n             7.5256e-07, 3.1658e-07, 1.0487e-06, 6.6162e-07, 4.3493e-07, 4.5808e-07,\n             2.0941e-07, 1.4870e-06, 9.3126e-07, 7.4545e-07, 6.5525e-07, 4.5292e-07,\n             4.8876e-07, 6.5104e-07, 4.9826e-07, 5.5350e-07, 3.0592e-07, 1.6064e-06,\n             2.9336e-07, 2.4172e-06, 7.8431e-07, 5.9133e-07, 1.3009e-06, 6.6255e-07,\n             2.8822e-07, 2.5813e-07, 9.3890e-07, 3.9311e-07, 8.2473e-07, 4.3896e-07,\n             1.3977e-06, 1.1332e-06, 8.9927e-07, 2.8771e-07, 8.2823e-07, 4.6064e-07,\n             8.9035e-07, 8.8684e-07, 5.5587e-07, 1.2088e-06, 1.4810e-06, 7.9796e-07,\n             6.9335e-07, 5.2780e-07, 2.1758e-06, 2.0028e-06, 6.8848e-07, 9.6003e-07,\n             7.6218e-07, 1.2603e-06, 1.6491e-06, 1.1967e-06, 1.9065e-06, 3.1266e-07,\n             3.4097e-07, 5.0442e-07, 2.8615e-07, 1.2750e-06])},\n    4: {'exp_avg': tensor([ 4.0209e-04, -5.8865e-04,  6.7135e-04, -4.2223e-04,  6.4887e-05,\n              6.0454e-04, -2.0317e-04,  3.7062e-04,  4.6986e-05,  4.7568e-04,\n              9.1154e-05,  7.7260e-04,  1.7923e-03,  3.8230e-03,  1.3839e-04,\n              1.0369e-03,  2.9754e-03,  2.0373e-04,  9.2701e-04, -3.3326e-03,\n              6.2975e-04, -6.3194e-04, -6.9177e-04,  1.1693e-04,  3.4102e-04,\n             -3.0352e-03, -6.6652e-04,  6.6806e-04, -2.3777e-04, -5.5274e-04,\n             -1.1037e-03,  5.0672e-04, -6.1532e-05, -3.3386e-04,  4.7082e-04,\n              4.2467e-04,  3.7072e-05,  3.6210e-04, -3.0628e-04, -6.5986e-04,\n             -9.3618e-04, -1.4386e-03, -5.0039e-04,  1.5856e-04, -2.9884e-03,\n             -3.1120e-04,  6.7775e-04,  0.0000e+00, -6.4008e-05,  2.4626e-05,\n             -9.8427e-04, -4.0944e-04, -9.8353e-04,  6.3540e-05,  2.8310e-04,\n              5.5470e-04, -2.7025e-05, -1.1397e-03,  2.4654e-03,  5.2518e-04,\n              9.3766e-04, -7.0457e-04, -7.0663e-04,  7.6353e-05]),\n     'exp_avg_sq': tensor([1.5313e-06, 1.2978e-06, 4.5315e-06, 5.5667e-07, 9.4461e-06, 7.3234e-06,\n             9.2737e-07, 5.7002e-07, 6.6775e-07, 2.3281e-06, 4.9742e-06, 1.2225e-05,\n             6.2319e-06, 1.3971e-05, 1.5590e-06, 5.5852e-07, 2.0376e-05, 1.1545e-06,\n             7.2648e-07, 8.7355e-06, 7.6115e-07, 1.4930e-06, 1.5236e-06, 2.1555e-06,\n             1.2987e-06, 6.2198e-06, 5.4376e-07, 2.7410e-05, 3.0126e-06, 1.8629e-06,\n             1.0472e-06, 1.2399e-06, 1.9331e-06, 5.7700e-07, 8.0498e-07, 7.5438e-07,\n             2.2267e-06, 1.0929e-06, 2.1684e-06, 6.3051e-06, 9.2595e-07, 1.1115e-06,\n             8.4304e-07, 6.2061e-07, 1.1934e-05, 1.1519e-06, 3.1286e-06, 0.0000e+00,\n             9.8774e-07, 2.8427e-06, 1.0240e-06, 4.8918e-06, 8.3666e-07, 1.1277e-06,\n             1.6651e-06, 1.9049e-06, 7.4463e-06, 1.4303e-06, 3.8828e-06, 6.9229e-07,\n             2.5550e-07, 1.6005e-06, 6.7554e-07, 7.2500e-07])},\n    5: {'exp_avg': tensor([-2.3440e-04, -7.2069e-04,  4.1005e-04, -3.3029e-04, -4.5342e-06,\n              7.5946e-05,  2.9149e-04,  2.6588e-04,  1.7033e-04,  1.4197e-05,\n             -1.8267e-04, -2.2420e-04, -3.1851e-05, -4.8700e-05, -7.3895e-04,\n              3.4732e-04, -1.7247e-05, -1.7631e-04,  1.8565e-04,  1.3345e-05,\n              4.2587e-04, -7.0454e-04, -3.5270e-04,  1.4058e-04, -5.8894e-05,\n             -2.3286e-05, -6.1929e-04, -1.2829e-03, -1.4021e-04, -1.5317e-03,\n             -4.1425e-04, -9.8656e-05,  9.8094e-04, -2.6590e-04,  3.7982e-05,\n              5.8169e-04, -3.2093e-04, -1.7313e-04, -1.5767e-04, -2.7725e-05,\n              3.1490e-06,  3.7633e-04, -6.9790e-05,  8.3589e-04, -9.6214e-04,\n              1.5965e-04,  3.4856e-05,  0.0000e+00,  7.3819e-05, -3.6247e-04,\n             -9.8450e-04, -1.7818e-04,  7.4178e-05, -2.4050e-04,  4.7977e-04,\n             -2.7680e-05, -7.4973e-06,  2.6432e-04, -1.3532e-05,  9.6691e-04,\n              3.6930e-04, -4.5865e-05, -5.1339e-04,  2.7332e-04]),\n     'exp_avg_sq': tensor([5.2471e-07, 1.8483e-06, 1.3707e-06, 1.2311e-06, 5.0598e-10, 4.2660e-09,\n             3.9083e-07, 1.3063e-06, 8.5047e-07, 6.9414e-10, 5.8914e-07, 3.1966e-07,\n             1.6618e-09, 2.9353e-09, 1.4798e-06, 8.4609e-07, 2.6305e-09, 1.0550e-06,\n             1.1035e-06, 2.7469e-10, 8.1293e-07, 2.3543e-06, 8.2112e-07, 2.9877e-07,\n             1.5609e-06, 1.6911e-09, 9.7087e-07, 9.9330e-07, 2.8763e-07, 1.5196e-06,\n             8.0971e-07, 1.2592e-06, 1.4181e-06, 2.3575e-07, 1.1495e-06, 7.8143e-07,\n             1.0997e-06, 1.8701e-06, 1.2088e-06, 5.6608e-09, 1.2038e-08, 7.8037e-07,\n             8.8592e-09, 1.3525e-06, 1.6232e-06, 8.9693e-08, 6.8317e-07, 0.0000e+00,\n             1.4107e-06, 1.3167e-06, 1.6877e-06, 2.5652e-06, 6.0035e-07, 1.3580e-06,\n             5.0998e-07, 1.5041e-09, 2.2045e-10, 2.0946e-06, 3.7976e-09, 1.2441e-06,\n             4.0060e-08, 5.6856e-07, 9.2720e-07, 4.6660e-08])},\n    6: {'exp_avg': tensor([ 2.7855e-04, -1.8591e-03, -6.7377e-04, -1.3073e-03,  7.4866e-04,\n              4.0140e-04, -4.6747e-04,  5.4644e-04, -1.2403e-03, -3.5866e-04,\n              2.5047e-05, -4.3076e-04, -1.8479e-04, -7.1634e-04, -1.6231e-03,\n             -2.2534e-04,  9.2569e-04, -1.7823e-03,  1.5598e-03, -2.6886e-03,\n              3.2252e-04, -5.3905e-04, -1.1772e-03, -3.9423e-04,  5.7222e-04,\n             -3.7591e-05,  1.0668e-04, -9.5227e-04,  2.4798e-03,  2.4405e-03,\n              2.0059e-03, -1.0928e-03, -8.5719e-04, -7.2413e-05,  1.9629e-05,\n             -1.1706e-03, -1.6128e-03,  4.8226e-04,  5.3066e-04, -8.8695e-04,\n             -1.2986e-03, -1.3671e-04,  1.0014e-03, -3.3082e-04, -1.5676e-03,\n             -1.9995e-03, -9.8146e-04, -9.3031e-05,  1.6068e-03,  2.7253e-03,\n              5.9413e-04,  6.1515e-04,  3.4355e-04, -2.6046e-04, -8.0856e-04,\n              1.9710e-03, -1.6241e-03,  1.2347e-03, -9.2919e-04, -1.0380e-03,\n              5.9728e-04, -1.8564e-03,  2.9742e-04,  1.4697e-03, -2.9979e-04,\n             -9.8637e-05, -1.1823e-03,  4.6392e-04, -2.4104e-05, -8.7238e-04,\n             -6.2267e-04, -1.8707e-03, -6.5396e-04,  1.8090e-03,  7.3701e-04,\n              3.9993e-04,  9.4372e-04,  1.2202e-03, -1.2506e-05,  9.9437e-04,\n             -4.7895e-05, -1.2934e-03, -2.7523e-04, -6.0480e-04, -2.1504e-04,\n              1.8113e-03, -9.8907e-04, -3.9122e-04, -7.6421e-04,  5.3431e-04,\n             -1.6786e-03, -4.5802e-04, -7.9829e-04,  2.6135e-03, -3.3651e-04,\n             -1.0589e-04, -2.3639e-03,  1.3546e-03, -3.9833e-04,  1.5260e-03,\n             -1.1621e-03,  4.9553e-04, -1.1979e-04, -8.2631e-04, -2.8289e-04,\n             -3.5826e-04, -3.9303e-03,  8.1509e-04, -1.5809e-04,  2.2413e-05,\n             -1.0992e-03,  6.1483e-04,  1.8248e-03, -1.0697e-04,  8.1760e-04,\n              9.5979e-04,  7.8248e-04,  3.4442e-04,  5.4243e-04, -8.0566e-04,\n              3.1063e-03, -1.9151e-03, -5.4731e-04,  1.0213e-03, -9.7349e-04,\n             -5.8347e-04, -1.3396e-03, -4.8525e-04, -3.1296e-03,  1.6929e-03,\n              6.7814e-04,  1.2413e-03, -2.7120e-03,  9.1019e-05,  2.0472e-03,\n             -6.2043e-04, -2.8262e-04,  1.2744e-03, -1.2924e-04, -2.7280e-03,\n             -6.3247e-05, -3.5328e-04, -2.6821e-04,  3.2768e-04,  1.1439e-03,\n              1.2698e-03, -5.9078e-04,  4.4080e-03, -5.0073e-03, -2.5394e-03,\n              1.5073e-03, -1.1033e-04,  4.2849e-04, -6.4924e-04,  6.2549e-03,\n             -3.0119e-03,  2.4097e-04,  2.2818e-04,  4.0557e-04, -6.6068e-04,\n             -5.4487e-04,  5.0937e-04, -1.2616e-04, -1.4990e-03,  6.6767e-04,\n              1.1569e-03, -9.3811e-04,  9.7934e-04, -1.5731e-03,  4.5378e-04,\n              1.8044e-04, -1.2451e-03,  1.1026e-03,  2.5767e-03, -5.5048e-04,\n             -1.4386e-03,  1.5864e-03,  1.5125e-03,  2.8396e-04, -1.4172e-03,\n              1.1332e-03,  1.0228e-03, -2.3671e-03,  1.3498e-04,  1.2270e-03,\n              1.8777e-03, -6.2490e-04,  3.1177e-04, -5.9901e-04,  5.9684e-04,\n              1.6453e-03, -3.8351e-04,  1.3647e-03,  4.6291e-04, -4.5735e-04,\n             -3.3424e-03,  0.0000e+00, -1.2076e-03,  1.9455e-04, -9.7601e-04,\n              4.5972e-04, -1.5907e-03,  7.0057e-04, -7.2009e-04,  5.2352e-04,\n              1.6610e-03,  2.2388e-04, -3.1478e-03, -1.7687e-03,  6.1440e-04,\n              1.4826e-03, -1.2069e-03, -7.5136e-04, -3.3460e-04, -1.1263e-03,\n             -7.5980e-04,  6.8475e-05,  2.1712e-04, -2.9945e-04, -3.1242e-04,\n             -9.9744e-04,  1.4715e-03, -5.8244e-04,  8.0883e-04,  8.9094e-04,\n             -2.8449e-04,  4.0980e-04, -8.5653e-04, -1.8546e-03,  2.3330e-04,\n              1.1502e-03, -2.7206e-04, -3.7906e-04, -9.9097e-04,  1.3801e-04,\n              1.5874e-03,  2.8402e-03,  6.9545e-04,  1.9229e-04, -3.3352e-04,\n             -2.4500e-04,  3.2894e-04,  8.8271e-04, -4.6642e-04, -5.7399e-04,\n              1.8935e-04,  1.0547e-03,  2.6732e-04,  4.1292e-04,  4.1147e-04,\n             -1.3151e-03, -3.0173e-04, -1.7036e-03, -9.0014e-04,  4.3282e-04,\n              8.1508e-04]),\n     'exp_avg_sq': tensor([9.0461e-07, 8.9305e-06, 1.4796e-06, 4.4019e-06, 2.9879e-06, 1.1887e-06,\n             3.8751e-06, 1.3757e-05, 4.3122e-06, 1.3092e-06, 3.9866e-06, 6.3881e-06,\n             1.8883e-05, 4.3628e-06, 2.4802e-06, 7.9551e-06, 5.3860e-06, 1.2498e-05,\n             3.6425e-06, 1.3508e-05, 5.8450e-06, 2.4709e-06, 1.0383e-05, 1.4811e-05,\n             5.7622e-06, 3.9382e-06, 1.5602e-05, 1.7363e-06, 8.9892e-06, 5.6253e-06,\n             8.6029e-06, 8.0910e-06, 6.7825e-07, 2.2790e-07, 3.0319e-06, 2.1897e-05,\n             4.0674e-06, 2.2612e-06, 1.1151e-05, 3.7405e-06, 9.5792e-07, 9.7177e-07,\n             1.8366e-06, 2.6679e-06, 2.0597e-06, 5.1103e-06, 7.0034e-06, 2.5150e-06,\n             4.7278e-06, 1.1511e-05, 7.3525e-07, 1.0281e-05, 7.3634e-06, 1.3463e-05,\n             5.9570e-06, 4.1840e-06, 2.6567e-05, 4.1602e-06, 1.3500e-06, 1.1829e-06,\n             1.8640e-06, 5.0986e-06, 5.0684e-06, 6.2311e-06, 1.5997e-06, 3.7836e-06,\n             2.7830e-05, 2.3944e-06, 6.5432e-06, 4.8924e-06, 7.3722e-06, 7.6594e-06,\n             1.4349e-06, 2.6928e-06, 2.6364e-06, 4.6739e-06, 9.7196e-06, 2.9028e-06,\n             2.4110e-06, 1.2332e-06, 5.5487e-06, 3.7347e-06, 9.7587e-06, 5.0838e-06,\n             5.0904e-06, 3.7892e-06, 6.3141e-06, 7.7442e-06, 1.0863e-06, 1.2995e-06,\n             1.2229e-05, 5.8714e-05, 5.4762e-06, 1.2176e-05, 3.1059e-07, 1.4459e-06,\n             3.5104e-06, 6.9583e-06, 3.2685e-06, 6.0512e-06, 4.4424e-06, 1.5362e-06,\n             7.7756e-07, 1.2535e-06, 7.3627e-07, 3.7615e-06, 1.6838e-05, 7.8242e-06,\n             1.8358e-06, 9.8047e-06, 8.5091e-06, 7.4936e-06, 6.0488e-06, 4.6221e-06,\n             2.1670e-06, 1.3678e-06, 3.4023e-06, 9.5806e-07, 1.5836e-06, 1.7059e-06,\n             1.4237e-05, 6.6184e-06, 1.6538e-06, 5.6665e-06, 2.1647e-06, 5.9552e-07,\n             8.9445e-06, 1.0977e-05, 9.5411e-06, 5.7788e-06, 9.9564e-06, 1.1836e-05,\n             1.0643e-05, 2.3234e-06, 4.0630e-06, 1.9933e-05, 6.6431e-06, 1.0323e-05,\n             4.7932e-06, 6.9793e-06, 1.4721e-06, 7.1447e-06, 1.3599e-05, 4.3873e-06,\n             9.9807e-06, 5.2572e-06, 1.1719e-06, 1.1004e-05, 9.3167e-06, 1.0275e-05,\n             6.9024e-06, 6.0418e-07, 7.3214e-06, 2.7612e-06, 6.9462e-05, 1.0188e-05,\n             2.8453e-06, 5.0288e-07, 7.5931e-06, 5.9580e-06, 2.2768e-06, 8.7711e-06,\n             4.9825e-07, 7.5134e-06, 2.4387e-06, 1.4294e-05, 1.5747e-05, 3.1795e-06,\n             9.0934e-06, 1.1657e-05, 1.1263e-06, 1.1779e-05, 5.9014e-06, 3.1241e-05,\n             9.2356e-06, 2.5812e-06, 3.6293e-06, 5.3087e-06, 5.1377e-06, 4.5111e-06,\n             1.3573e-06, 1.0908e-05, 9.1263e-06, 2.8058e-06, 5.3189e-06, 5.7443e-06,\n             2.7904e-06, 1.7012e-06, 3.5628e-06, 2.0040e-06, 7.0431e-06, 1.7197e-06,\n             3.2480e-06, 2.8177e-06, 2.2690e-06, 1.2139e-05, 0.0000e+00, 7.1544e-06,\n             1.7336e-05, 4.4891e-06, 2.6126e-06, 4.6606e-06, 5.2815e-06, 2.1806e-06,\n             1.5740e-06, 4.4878e-06, 1.0577e-05, 1.3158e-05, 4.1478e-06, 5.5926e-06,\n             1.8071e-05, 1.4485e-06, 4.9948e-06, 1.9361e-06, 3.8175e-06, 2.8438e-06,\n             6.9134e-06, 1.1710e-06, 4.3047e-06, 1.5148e-05, 9.5378e-06, 6.2834e-06,\n             2.9965e-06, 2.3070e-06, 3.1438e-06, 7.0852e-06, 5.1530e-06, 3.0720e-06,\n             4.1440e-06, 6.5913e-06, 1.0352e-05, 7.6736e-06, 3.8336e-06, 5.5767e-06,\n             6.9608e-07, 4.6952e-06, 1.2804e-05, 7.0681e-06, 4.2586e-06, 8.1766e-07,\n             4.6616e-06, 5.1458e-06, 3.6161e-06, 1.5035e-05, 2.0452e-05, 3.9467e-06,\n             1.1800e-05, 3.3464e-06, 2.9643e-06, 2.0766e-06, 6.9900e-06, 1.9948e-06,\n             7.3552e-06, 8.0188e-06, 3.3703e-06, 5.5891e-06])},\n    7: {'exp_avg': tensor([-1.9534e-04,  7.5920e-04,  8.3988e-05,  6.2375e-04, -7.8138e-05,\n             -1.5721e-05, -1.5234e-04,  2.3591e-04, -5.6953e-04,  1.3802e-03,\n              6.4814e-05,  2.2746e-05,  2.7823e-04,  1.2994e-03, -6.7716e-04,\n              8.0102e-05,  6.2620e-04,  6.4121e-04, -2.1751e-05, -1.9617e-04,\n             -6.5639e-10, -3.8684e-04,  5.9424e-04,  2.4658e-11,  3.5824e-05,\n             -1.8182e-04,  3.9065e-04, -6.5042e-04, -9.2436e-04, -1.4758e-04,\n             -2.4638e-04, -3.0126e-04, -9.7996e-05, -3.2621e-04,  1.4599e-04,\n             -2.0306e-04,  6.8016e-04,  1.3541e-03,  1.9515e-03,  3.1905e-05,\n              5.7408e-04,  3.1897e-04,  5.0529e-04, -2.0789e-04, -1.2618e-03,\n             -3.5238e-10,  2.9371e-04,  1.0839e-03,  3.3858e-04,  8.6680e-05,\n              2.8265e-04, -4.7009e-06,  7.6488e-04, -6.8648e-05,  1.5795e-03,\n              3.6762e-04, -3.2931e-04,  3.0403e-04,  3.0866e-04,  7.3098e-04,\n             -6.5909e-04,  3.5049e-04, -6.5091e-05, -7.9966e-04, -3.0993e-04,\n              1.2806e-05, -4.5924e-11, -2.4864e-04,  9.4943e-04, -5.5302e-04,\n              2.1321e-04,  4.5075e-04,  8.3842e-04,  3.2539e-05,  9.4833e-05,\n              4.1913e-04, -6.6754e-04,  2.8321e-04,  3.0684e-04,  8.9428e-05,\n             -3.6875e-10, -1.2003e-03, -6.4512e-04, -1.6833e-04,  7.5185e-04,\n             -1.0380e-04, -3.1133e-04,  2.9520e-04, -2.7686e-04,  5.5376e-04,\n             -3.6603e-04,  2.7769e-04,  3.6149e-04,  1.6204e-03, -3.0491e-04,\n              4.5878e-04,  6.1542e-04,  1.6622e-03, -5.5026e-04, -4.9428e-04,\n              3.6292e-05,  1.0014e-03,  6.2301e-04,  1.9347e-04,  4.8284e-04,\n             -1.2978e-04, -5.4755e-04, -3.2263e-10, -1.6667e-04, -1.2803e-04,\n             -3.5464e-04,  3.2228e-10,  5.7766e-04, -6.2112e-04,  9.3282e-05,\n              3.2594e-04, -1.4153e-04,  1.5691e-04, -7.4571e-05, -7.3247e-05,\n             -1.6303e-03, -7.9448e-05, -1.6662e-04, -3.0106e-04, -5.2675e-04,\n             -4.8536e-04, -1.8707e-04, -9.3570e-05, -8.7737e-04, -5.6765e-04,\n             -2.0284e-04,  1.0104e-03, -9.9337e-04,  8.1714e-05, -1.0224e-04,\n             -9.0477e-04, -7.4055e-04, -3.6478e-04,  2.3704e-04,  3.3400e-04,\n             -4.6125e-04,  5.4409e-04,  5.2823e-04,  2.1976e-04, -3.4685e-04,\n              6.6887e-05, -8.5219e-05,  2.7463e-04, -1.2809e-04,  6.7287e-04,\n             -5.4786e-04, -5.3154e-04,  2.2841e-04,  8.4537e-05,  1.2317e-05,\n              1.4939e-03, -1.8374e-04,  1.6125e-04,  5.8660e-05, -2.1664e-04,\n              1.0898e-03,  2.4087e-04,  1.4403e-04,  1.9560e-04, -8.8420e-05,\n             -7.4238e-04, -2.6889e-04,  1.2463e-04, -1.6712e-08,  5.2333e-04,\n              3.0103e-06,  4.2328e-05, -3.0872e-05, -4.1796e-04, -7.3490e-04,\n             -1.0949e-05, -3.1576e-10,  2.0983e-03,  4.8515e-04, -7.3498e-04,\n             -5.3616e-04,  2.5693e-04,  9.7771e-04, -5.8530e-04, -4.9696e-04,\n              2.2359e-04, -1.7597e-04, -1.0532e-03,  4.2271e-04, -4.5491e-04,\n             -4.6798e-07, -5.8912e-04,  1.0786e-03, -2.7713e-04, -1.0336e-04,\n             -3.7343e-04,  0.0000e+00, -5.1477e-04,  2.0224e-04, -8.2457e-04,\n             -6.8551e-04,  3.2796e-04,  2.3172e-04, -4.2612e-04, -7.5203e-04,\n              2.1077e-04,  3.9947e-04,  1.2003e-03, -3.6095e-04, -9.3682e-08,\n             -1.0225e-04,  1.1317e-04,  2.6745e-04,  2.7997e-05, -1.0006e-03,\n             -8.7290e-04,  1.0859e-03,  1.3514e-05,  4.6399e-04, -1.6841e-05,\n              1.7427e-05, -9.9231e-05,  2.2613e-04, -7.4403e-04, -8.8442e-07,\n              1.4350e-04, -3.1050e-04,  8.5952e-06, -7.5939e-04, -1.0496e-03,\n              4.3614e-04,  4.2427e-04, -1.7554e-04,  1.2545e-07, -6.7490e-05,\n             -1.7656e-05,  5.6082e-04, -4.0078e-04, -6.4074e-04,  2.2121e-04,\n              1.2432e-04,  2.5503e-04, -8.4620e-05, -1.6472e-04,  1.3007e-03,\n             -6.9577e-04,  6.7060e-10,  1.2265e-04,  5.9370e-04, -7.8588e-04,\n             -1.0363e-04, -3.1701e-04,  1.4535e-10,  5.1817e-05, -1.9328e-06,\n             -6.9992e-04]),\n     'exp_avg_sq': tensor([3.3826e-07, 1.1100e-06, 8.8210e-07, 1.0413e-06, 1.0128e-06, 1.8321e-06,\n             5.7887e-07, 6.6113e-07, 1.1197e-06, 1.3510e-06, 1.6310e-08, 5.3457e-10,\n             7.3484e-07, 1.2100e-06, 5.2936e-07, 2.3136e-07, 1.0269e-06, 9.3597e-07,\n             6.1777e-10, 2.1408e-06, 9.3731e-16, 7.9532e-07, 4.0153e-06, 2.6759e-18,\n             1.3748e-06, 8.5188e-07, 1.3824e-06, 7.7787e-07, 2.8638e-06, 6.8270e-07,\n             6.6928e-07, 1.1486e-06, 5.2811e-07, 2.9700e-07, 1.1585e-06, 5.1726e-08,\n             1.2096e-06, 1.2990e-06, 2.2157e-06, 1.5712e-08, 4.7465e-07, 5.7311e-07,\n             3.6424e-07, 9.7974e-07, 9.8634e-07, 2.4749e-18, 2.1948e-06, 3.6403e-06,\n             7.6596e-07, 2.0637e-06, 5.3111e-07, 2.0408e-11, 9.0636e-07, 8.0369e-07,\n             5.5992e-06, 1.2638e-06, 2.5636e-07, 7.7776e-07, 5.9892e-07, 1.0935e-06,\n             4.1313e-07, 3.0057e-07, 8.9493e-07, 1.2337e-06, 6.7578e-07, 4.8929e-07,\n             6.1997e-18, 5.7415e-07, 1.0935e-06, 1.0186e-06, 7.9103e-07, 1.2447e-06,\n             6.3903e-07, 4.7148e-07, 6.9639e-07, 9.8369e-07, 1.6723e-06, 1.0538e-06,\n             7.3788e-07, 5.1262e-07, 1.6545e-18, 2.9387e-06, 1.6208e-06, 5.8742e-07,\n             1.1094e-06, 1.1919e-06, 8.1885e-07, 9.0334e-07, 4.9812e-07, 5.5449e-07,\n             8.9686e-07, 6.9570e-06, 6.3273e-07, 3.0830e-06, 3.1098e-07, 3.6102e-07,\n             6.2015e-07, 1.8787e-06, 1.3211e-06, 9.0616e-07, 8.9706e-07, 1.3578e-06,\n             4.6383e-07, 6.3383e-07, 4.2808e-07, 5.2695e-07, 2.6560e-06, 2.0173e-18,\n             5.9683e-07, 1.3704e-06, 3.2855e-06, 9.3477e-19, 7.2348e-07, 2.0269e-06,\n             6.5568e-07, 5.9700e-07, 7.3823e-07, 6.0263e-07, 6.1863e-07, 8.3260e-07,\n             3.0888e-06, 5.4506e-07, 1.1832e-06, 2.6672e-06, 1.1851e-06, 4.5027e-07,\n             1.7967e-06, 1.4642e-06, 2.2464e-06, 6.6483e-07, 7.6769e-07, 3.3222e-06,\n             1.2454e-06, 7.1690e-07, 8.3069e-08, 7.7814e-07, 2.6821e-06, 1.1050e-06,\n             3.9794e-07, 9.9471e-07, 4.8762e-07, 5.7681e-07, 1.1490e-06, 7.1285e-07,\n             5.9715e-07, 1.1714e-06, 5.9182e-07, 3.7361e-07, 1.0079e-06, 8.7288e-07,\n             9.1564e-07, 1.0124e-06, 1.3108e-06, 8.6960e-07, 2.0978e-10, 2.1190e-06,\n             7.6339e-07, 4.4226e-07, 2.8610e-06, 1.1595e-06, 8.7972e-07, 2.7006e-07,\n             3.3528e-07, 9.2651e-07, 9.0449e-07, 3.3594e-06, 1.3344e-06, 4.4132e-07,\n             3.2963e-14, 8.0967e-07, 9.3099e-10, 1.3309e-06, 4.1149e-07, 5.5114e-06,\n             1.8207e-06, 9.7111e-07, 1.2579e-18, 1.1097e-06, 8.5011e-07, 9.3567e-07,\n             5.6298e-07, 9.7218e-07, 8.1125e-07, 7.9787e-07, 6.3566e-07, 1.8539e-07,\n             4.6684e-07, 1.0674e-06, 6.0825e-07, 7.9666e-07, 2.1540e-06, 8.2164e-07,\n             1.1908e-06, 7.3591e-07, 1.0127e-06, 7.1292e-07, 0.0000e+00, 7.4897e-07,\n             5.0863e-06, 4.3015e-06, 8.4854e-07, 8.2463e-07, 3.0353e-07, 6.1148e-07,\n             4.9552e-07, 1.4686e-06, 1.3342e-06, 1.9301e-06, 7.4117e-07, 2.6695e-14,\n             1.5378e-06, 1.0431e-06, 6.3344e-07, 8.9150e-07, 3.2986e-06, 1.0858e-06,\n             1.9061e-06, 5.9071e-07, 7.9317e-07, 4.6964e-06, 3.5229e-08, 6.7443e-07,\n             5.4658e-07, 3.9906e-07, 5.7334e-12, 2.4205e-07, 1.1193e-06, 9.6882e-07,\n             1.0392e-06, 1.5058e-06, 5.4782e-07, 1.4377e-06, 5.1462e-07, 1.8676e-14,\n             1.3441e-07, 3.2904e-08, 6.7154e-07, 7.4787e-07, 1.1462e-06, 3.0392e-07,\n             9.4998e-07, 1.4988e-07, 1.1332e-06, 1.5919e-06, 3.9028e-06, 2.3971e-06,\n             1.7587e-18, 1.1390e-06, 8.7068e-07, 7.0672e-07, 1.0588e-06, 7.1702e-07,\n             1.3030e-18, 7.3757e-07, 7.4570e-07, 5.6240e-07])},\n    8: {'exp_avg': tensor([-1.4605e-05,  1.8266e-03,  7.7159e-04,  1.1613e-03, -7.1458e-04,\n              1.6701e-04,  4.7093e-04, -1.1255e-04, -1.2193e-03,  1.9912e-04,\n             -2.0682e-05,  2.2325e-04,  3.3068e-04,  1.0849e-03,  1.2148e-03,\n              4.6203e-04,  9.3791e-04,  1.7695e-03,  1.8162e-03,  2.4486e-03,\n             -1.3444e-04, -6.2305e-04, -1.6444e-03, -9.2702e-05,  4.3219e-04,\n              2.4489e-04,  7.1140e-05, -8.4758e-04, -2.3880e-03,  2.3910e-03,\n              2.4796e-03,  8.5215e-04,  7.3535e-04, -7.5999e-05,  3.1350e-04,\n             -6.6670e-04,  5.3276e-04,  9.9206e-04, -1.7974e-05, -1.2461e-03,\n             -1.4461e-03,  3.8430e-05, -5.2493e-04,  2.6227e-04,  6.1299e-04,\n              2.5664e-03, -7.0799e-04,  9.6539e-04,  1.4669e-03,  2.7344e-03,\n              7.3273e-04, -9.4659e-04,  9.7777e-05,  1.5921e-04,  1.3778e-03,\n             -1.6889e-03, -1.6203e-03, -1.1224e-03, -5.8506e-04,  1.3220e-03,\n             -3.1601e-05,  2.0849e-03, -4.3468e-05, -1.6349e-03,  1.4263e-04,\n             -2.6182e-04, -1.1719e-03,  3.1831e-04,  6.7021e-04,  8.3359e-04,\n             -6.3988e-04, -1.5844e-03,  7.5159e-04,  1.7280e-03,  7.7618e-04,\n              3.9816e-04, -1.0445e-03,  1.2286e-03,  1.7452e-05, -5.9594e-04,\n             -1.0577e-04, -1.7090e-03,  1.2907e-04, -5.1759e-04,  5.0637e-04,\n             -1.6621e-03, -9.7155e-04, -4.1793e-04, -7.7674e-04,  9.8261e-04,\n              9.9522e-04,  9.1383e-04, -3.4092e-04,  3.0166e-03, -3.5373e-04,\n              2.3998e-04, -1.9143e-03,  1.6431e-03, -5.0936e-04, -2.0510e-03,\n              1.2171e-03, -1.0889e-04,  5.7389e-04, -7.8634e-04,  8.0527e-04,\n              2.7466e-04,  3.4794e-03, -5.9658e-04, -7.5584e-05, -3.0529e-04,\n              8.9348e-04,  3.0499e-04, -1.4730e-03, -1.0329e-04,  8.5889e-04,\n             -7.9114e-04,  8.8969e-04, -4.4419e-04, -5.1691e-04,  6.5270e-04,\n             -2.8045e-03,  1.5112e-03, -4.6114e-04,  9.4596e-04,  6.0100e-04,\n             -8.4522e-04, -1.0960e-03, -2.7083e-04,  2.5215e-03, -1.6201e-03,\n              5.0748e-04, -6.2388e-04, -2.5401e-03,  1.9454e-04, -1.2388e-03,\n             -8.2404e-04, -2.1701e-04,  1.1919e-03,  3.9116e-04, -1.7176e-03,\n             -3.3948e-04, -9.5592e-05, -1.6678e-04, -2.9679e-04,  7.8497e-04,\n              1.2355e-03,  4.5494e-04,  4.2673e-03, -4.9528e-03,  2.3634e-03,\n              8.2974e-04, -3.5289e-04,  2.1572e-04,  7.7618e-04,  2.4466e-03,\n             -1.6729e-03, -6.4986e-04,  6.6402e-04,  5.6655e-04, -4.5438e-04,\n             -8.0114e-05, -1.0288e-03,  1.1454e-04,  1.4490e-03, -9.1111e-04,\n             -1.3245e-03,  6.6338e-04, -6.5744e-04,  1.4992e-03,  3.6471e-04,\n             -2.0939e-05,  1.1443e-03,  1.2947e-03,  1.8021e-03,  2.6981e-04,\n             -1.3590e-03, -1.0983e-03,  1.8976e-03,  4.8831e-04, -1.6213e-03,\n              1.0439e-03,  1.0793e-03,  1.9384e-03, -2.2639e-04,  9.9705e-04,\n             -2.0966e-03,  4.9102e-04, -5.5786e-04,  3.9225e-04,  1.4161e-04,\n             -1.4569e-03, -6.7669e-04, -1.2934e-03, -7.4485e-04,  6.6846e-04,\n             -2.9539e-03,  0.0000e+00,  8.0554e-04, -1.5792e-04, -6.0910e-04,\n             -3.5677e-04, -1.3325e-03, -2.9544e-04, -8.0551e-04, -8.9468e-04,\n             -1.9229e-03,  6.1556e-04, -2.4617e-03, -1.6127e-03,  5.9910e-04,\n             -1.5281e-03,  1.1879e-03,  3.7060e-04,  3.8229e-04,  9.3817e-04,\n              2.4585e-04,  6.9625e-04, -3.6337e-04,  2.6797e-04, -2.4415e-04,\n             -2.8613e-05, -1.3795e-03,  8.2335e-04,  6.0597e-04,  5.0661e-04,\n              2.6230e-04,  7.0290e-04,  7.1180e-04,  9.5470e-04, -1.5164e-05,\n              1.0276e-03, -1.6864e-05, -1.5433e-04,  2.2418e-03, -1.1427e-05,\n             -1.3286e-03, -2.3439e-03,  2.6228e-04, -4.9254e-04,  3.0085e-04,\n             -3.2184e-04,  5.0664e-04, -7.3862e-04,  2.5690e-04, -1.3659e-03,\n             -9.0429e-05, -4.8333e-04,  1.9782e-04, -4.2430e-04, -8.2932e-04,\n             -1.0370e-03,  1.8363e-04, -1.7589e-03,  9.1550e-04,  3.6915e-04,\n              1.0108e-03]),\n     'exp_avg_sq': tensor([1.1209e-06, 5.4658e-06, 1.4774e-06, 3.9101e-06, 2.4152e-06, 1.5185e-06,\n             3.8278e-06, 3.5801e-06, 3.0328e-06, 1.0336e-06, 4.1523e-06, 6.7996e-06,\n             1.7117e-05, 3.4901e-06, 2.0680e-06, 7.4668e-06, 4.4764e-06, 8.8480e-06,\n             3.4035e-06, 1.0617e-05, 5.2727e-06, 2.1175e-06, 7.2709e-06, 1.3551e-05,\n             5.0028e-06, 3.4006e-06, 1.3420e-05, 1.7174e-06, 8.1493e-06, 4.3491e-06,\n             7.8903e-06, 5.2455e-06, 7.8128e-07, 2.8625e-07, 2.6814e-06, 1.9741e-05,\n             1.5287e-06, 2.1654e-06, 8.2131e-06, 3.5127e-06, 1.2170e-06, 9.7497e-07,\n             1.3522e-06, 2.3120e-06, 2.0114e-06, 4.9402e-06, 6.9886e-06, 2.8108e-06,\n             4.2386e-06, 1.1191e-05, 7.4170e-07, 7.4951e-06, 5.1867e-06, 9.8185e-06,\n             8.9618e-06, 3.7121e-06, 2.3874e-05, 3.6559e-06, 1.4607e-06, 1.0393e-06,\n             1.5810e-06, 4.4672e-06, 5.1284e-06, 5.3969e-06, 1.5288e-06, 3.5923e-06,\n             2.1147e-05, 2.4731e-06, 3.9225e-06, 4.6102e-06, 5.8222e-06, 6.4825e-06,\n             1.3663e-06, 1.9184e-06, 2.3661e-06, 4.1099e-06, 7.3326e-06, 2.6492e-06,\n             1.8893e-06, 9.5525e-07, 5.3780e-06, 2.4962e-06, 8.0125e-06, 3.7516e-06,\n             4.0545e-06, 3.5201e-06, 4.4935e-06, 7.0486e-06, 9.7408e-07, 1.4528e-06,\n             8.2305e-06, 4.1193e-05, 3.7590e-06, 1.1470e-05, 4.1979e-07, 1.0186e-06,\n             3.1224e-06, 6.3151e-06, 3.0907e-06, 5.9918e-06, 4.3923e-06, 1.7958e-06,\n             1.3223e-06, 1.3611e-06, 9.3019e-07, 2.7363e-06, 1.4174e-05, 7.2646e-06,\n             1.6640e-06, 9.0670e-06, 6.9241e-06, 7.2325e-06, 5.0181e-06, 4.7195e-06,\n             2.0836e-06, 1.2252e-06, 2.8415e-06, 1.1896e-06, 1.4400e-06, 1.8388e-06,\n             1.0122e-05, 4.4348e-06, 2.6444e-06, 5.3911e-06, 2.0602e-06, 7.2292e-07,\n             7.4387e-06, 9.5981e-06, 8.5495e-06, 4.4384e-06, 7.3051e-06, 1.2055e-05,\n             7.1338e-06, 2.0419e-06, 3.7966e-06, 1.2138e-05, 7.2339e-06, 8.5249e-06,\n             4.4844e-06, 4.3154e-06, 1.5337e-06, 6.3863e-06, 8.6758e-06, 3.8391e-06,\n             7.4473e-06, 4.3982e-06, 1.3579e-06, 1.0305e-05, 8.1979e-06, 9.5858e-06,\n             4.9603e-06, 1.4001e-06, 5.9382e-06, 2.9977e-06, 5.1545e-05, 7.7036e-06,\n             2.2382e-06, 8.8463e-07, 6.6202e-06, 6.0735e-06, 2.5598e-06, 5.9729e-06,\n             3.1947e-07, 6.7724e-06, 2.5981e-06, 9.1918e-06, 9.2455e-06, 2.0308e-06,\n             8.1478e-06, 1.0505e-05, 1.1725e-06, 9.8472e-06, 5.3326e-06, 1.7747e-05,\n             7.5941e-06, 2.4806e-06, 3.8935e-06, 4.6147e-06, 4.0440e-06, 3.6074e-06,\n             1.3597e-06, 9.5069e-06, 8.4408e-06, 2.8570e-06, 4.3190e-06, 5.1837e-06,\n             2.7199e-06, 1.6643e-06, 3.9174e-06, 2.1355e-06, 6.1061e-06, 1.5296e-06,\n             3.3045e-06, 2.7146e-06, 2.7233e-06, 7.3388e-06, 0.0000e+00, 4.9386e-06,\n             1.4469e-05, 4.0606e-06, 2.5800e-06, 3.9424e-06, 5.0779e-06, 2.1615e-06,\n             1.8079e-06, 3.6697e-06, 7.2361e-06, 1.0359e-05, 3.7271e-06, 5.8233e-06,\n             1.5903e-05, 1.5248e-06, 4.5805e-06, 1.8634e-06, 3.7379e-06, 2.8515e-06,\n             5.6314e-06, 1.3037e-06, 3.4178e-06, 1.4077e-05, 8.9362e-06, 4.6249e-06,\n             2.6031e-06, 2.8533e-06, 3.0907e-06, 8.1845e-06, 7.3154e-06, 2.6597e-06,\n             3.1577e-06, 6.4186e-06, 8.9265e-06, 4.7696e-06, 4.2895e-06, 5.7012e-06,\n             3.6717e-07, 4.7009e-06, 1.2076e-05, 5.9555e-06, 3.5036e-06, 7.2922e-07,\n             5.7451e-06, 5.4478e-06, 2.9271e-06, 1.0117e-05, 1.2238e-05, 2.3672e-06,\n             1.0275e-05, 2.6107e-06, 2.6601e-06, 1.9600e-06, 6.3256e-06, 1.7288e-06,\n             7.0081e-06, 7.6463e-06, 2.7973e-06, 5.3232e-06])},\n    9: {'exp_avg': tensor([-1.9534e-04,  7.5920e-04,  8.3988e-05,  6.2375e-04, -7.8138e-05,\n             -1.5721e-05, -1.5234e-04,  2.3591e-04, -5.6953e-04,  1.3802e-03,\n              6.4814e-05,  2.2746e-05,  2.7823e-04,  1.2994e-03, -6.7716e-04,\n              8.0102e-05,  6.2620e-04,  6.4121e-04, -2.1751e-05, -1.9617e-04,\n             -6.5639e-10, -3.8684e-04,  5.9424e-04,  2.4658e-11,  3.5824e-05,\n             -1.8182e-04,  3.9065e-04, -6.5042e-04, -9.2436e-04, -1.4758e-04,\n             -2.4638e-04, -3.0126e-04, -9.7996e-05, -3.2621e-04,  1.4599e-04,\n             -2.0306e-04,  6.8016e-04,  1.3541e-03,  1.9515e-03,  3.1905e-05,\n              5.7408e-04,  3.1897e-04,  5.0529e-04, -2.0789e-04, -1.2618e-03,\n             -3.5238e-10,  2.9371e-04,  1.0839e-03,  3.3858e-04,  8.6680e-05,\n              2.8265e-04, -4.7009e-06,  7.6488e-04, -6.8648e-05,  1.5795e-03,\n              3.6762e-04, -3.2931e-04,  3.0403e-04,  3.0866e-04,  7.3098e-04,\n             -6.5909e-04,  3.5049e-04, -6.5091e-05, -7.9966e-04, -3.0993e-04,\n              1.2806e-05, -4.5924e-11, -2.4864e-04,  9.4943e-04, -5.5302e-04,\n              2.1321e-04,  4.5075e-04,  8.3842e-04,  3.2539e-05,  9.4833e-05,\n              4.1913e-04, -6.6754e-04,  2.8321e-04,  3.0684e-04,  8.9428e-05,\n             -3.6875e-10, -1.2003e-03, -6.4512e-04, -1.6833e-04,  7.5185e-04,\n             -1.0380e-04, -3.1133e-04,  2.9520e-04, -2.7686e-04,  5.5376e-04,\n             -3.6603e-04,  2.7769e-04,  3.6149e-04,  1.6204e-03, -3.0491e-04,\n              4.5878e-04,  6.1542e-04,  1.6622e-03, -5.5026e-04, -4.9428e-04,\n              3.6292e-05,  1.0014e-03,  6.2301e-04,  1.9347e-04,  4.8284e-04,\n             -1.2978e-04, -5.4755e-04, -3.2263e-10, -1.6667e-04, -1.2803e-04,\n             -3.5464e-04,  3.2228e-10,  5.7766e-04, -6.2112e-04,  9.3282e-05,\n              3.2594e-04, -1.4153e-04,  1.5691e-04, -7.4571e-05, -7.3247e-05,\n             -1.6303e-03, -7.9448e-05, -1.6662e-04, -3.0106e-04, -5.2675e-04,\n             -4.8536e-04, -1.8707e-04, -9.3570e-05, -8.7737e-04, -5.6765e-04,\n             -2.0284e-04,  1.0104e-03, -9.9337e-04,  8.1714e-05, -1.0224e-04,\n             -9.0477e-04, -7.4055e-04, -3.6478e-04,  2.3704e-04,  3.3400e-04,\n             -4.6125e-04,  5.4409e-04,  5.2823e-04,  2.1976e-04, -3.4685e-04,\n              6.6887e-05, -8.5219e-05,  2.7463e-04, -1.2809e-04,  6.7287e-04,\n             -5.4786e-04, -5.3154e-04,  2.2841e-04,  8.4537e-05,  1.2317e-05,\n              1.4939e-03, -1.8374e-04,  1.6125e-04,  5.8660e-05, -2.1664e-04,\n              1.0898e-03,  2.4087e-04,  1.4403e-04,  1.9560e-04, -8.8420e-05,\n             -7.4238e-04, -2.6889e-04,  1.2463e-04, -1.6712e-08,  5.2333e-04,\n              3.0103e-06,  4.2328e-05, -3.0872e-05, -4.1796e-04, -7.3490e-04,\n             -1.0949e-05, -3.1576e-10,  2.0983e-03,  4.8515e-04, -7.3498e-04,\n             -5.3616e-04,  2.5693e-04,  9.7771e-04, -5.8530e-04, -4.9696e-04,\n              2.2359e-04, -1.7597e-04, -1.0532e-03,  4.2271e-04, -4.5491e-04,\n             -4.6798e-07, -5.8912e-04,  1.0786e-03, -2.7713e-04, -1.0336e-04,\n             -3.7343e-04,  0.0000e+00, -5.1477e-04,  2.0224e-04, -8.2457e-04,\n             -6.8551e-04,  3.2796e-04,  2.3172e-04, -4.2612e-04, -7.5203e-04,\n              2.1077e-04,  3.9947e-04,  1.2003e-03, -3.6095e-04, -9.3682e-08,\n             -1.0225e-04,  1.1317e-04,  2.6745e-04,  2.7997e-05, -1.0006e-03,\n             -8.7290e-04,  1.0859e-03,  1.3514e-05,  4.6399e-04, -1.6841e-05,\n              1.7427e-05, -9.9231e-05,  2.2613e-04, -7.4403e-04, -8.8442e-07,\n              1.4350e-04, -3.1050e-04,  8.5952e-06, -7.5939e-04, -1.0496e-03,\n              4.3614e-04,  4.2427e-04, -1.7554e-04,  1.2545e-07, -6.7490e-05,\n             -1.7656e-05,  5.6082e-04, -4.0078e-04, -6.4074e-04,  2.2121e-04,\n              1.2432e-04,  2.5503e-04, -8.4620e-05, -1.6472e-04,  1.3007e-03,\n             -6.9577e-04,  6.7060e-10,  1.2265e-04,  5.9370e-04, -7.8588e-04,\n             -1.0363e-04, -3.1701e-04,  1.4535e-10,  5.1817e-05, -1.9328e-06,\n             -6.9992e-04]),\n     'exp_avg_sq': tensor([3.3826e-07, 1.1100e-06, 8.8210e-07, 1.0413e-06, 1.0128e-06, 1.8321e-06,\n             5.7887e-07, 6.6113e-07, 1.1197e-06, 1.3510e-06, 1.6310e-08, 5.3457e-10,\n             7.3484e-07, 1.2100e-06, 5.2936e-07, 2.3136e-07, 1.0269e-06, 9.3597e-07,\n             6.1777e-10, 2.1408e-06, 9.3731e-16, 7.9532e-07, 4.0153e-06, 2.6759e-18,\n             1.3748e-06, 8.5188e-07, 1.3824e-06, 7.7787e-07, 2.8638e-06, 6.8270e-07,\n             6.6928e-07, 1.1486e-06, 5.2811e-07, 2.9700e-07, 1.1585e-06, 5.1726e-08,\n             1.2096e-06, 1.2990e-06, 2.2157e-06, 1.5712e-08, 4.7465e-07, 5.7311e-07,\n             3.6424e-07, 9.7974e-07, 9.8634e-07, 2.4749e-18, 2.1948e-06, 3.6403e-06,\n             7.6596e-07, 2.0637e-06, 5.3111e-07, 2.0408e-11, 9.0636e-07, 8.0369e-07,\n             5.5992e-06, 1.2638e-06, 2.5636e-07, 7.7776e-07, 5.9892e-07, 1.0935e-06,\n             4.1313e-07, 3.0057e-07, 8.9493e-07, 1.2337e-06, 6.7578e-07, 4.8929e-07,\n             6.1997e-18, 5.7415e-07, 1.0935e-06, 1.0186e-06, 7.9103e-07, 1.2447e-06,\n             6.3903e-07, 4.7148e-07, 6.9639e-07, 9.8369e-07, 1.6723e-06, 1.0538e-06,\n             7.3788e-07, 5.1262e-07, 1.6545e-18, 2.9387e-06, 1.6208e-06, 5.8742e-07,\n             1.1094e-06, 1.1919e-06, 8.1885e-07, 9.0334e-07, 4.9812e-07, 5.5449e-07,\n             8.9686e-07, 6.9570e-06, 6.3273e-07, 3.0830e-06, 3.1098e-07, 3.6102e-07,\n             6.2015e-07, 1.8787e-06, 1.3211e-06, 9.0616e-07, 8.9706e-07, 1.3578e-06,\n             4.6383e-07, 6.3383e-07, 4.2808e-07, 5.2695e-07, 2.6560e-06, 2.0173e-18,\n             5.9683e-07, 1.3704e-06, 3.2855e-06, 9.3477e-19, 7.2348e-07, 2.0269e-06,\n             6.5568e-07, 5.9700e-07, 7.3823e-07, 6.0263e-07, 6.1863e-07, 8.3260e-07,\n             3.0888e-06, 5.4506e-07, 1.1832e-06, 2.6672e-06, 1.1851e-06, 4.5027e-07,\n             1.7967e-06, 1.4642e-06, 2.2464e-06, 6.6483e-07, 7.6769e-07, 3.3222e-06,\n             1.2454e-06, 7.1690e-07, 8.3069e-08, 7.7814e-07, 2.6821e-06, 1.1050e-06,\n             3.9794e-07, 9.9471e-07, 4.8762e-07, 5.7681e-07, 1.1490e-06, 7.1285e-07,\n             5.9715e-07, 1.1714e-06, 5.9182e-07, 3.7361e-07, 1.0079e-06, 8.7288e-07,\n             9.1564e-07, 1.0124e-06, 1.3108e-06, 8.6960e-07, 2.0978e-10, 2.1190e-06,\n             7.6339e-07, 4.4226e-07, 2.8610e-06, 1.1595e-06, 8.7972e-07, 2.7006e-07,\n             3.3528e-07, 9.2651e-07, 9.0449e-07, 3.3594e-06, 1.3344e-06, 4.4132e-07,\n             3.2963e-14, 8.0967e-07, 9.3099e-10, 1.3309e-06, 4.1149e-07, 5.5114e-06,\n             1.8207e-06, 9.7111e-07, 1.2579e-18, 1.1097e-06, 8.5011e-07, 9.3567e-07,\n             5.6298e-07, 9.7218e-07, 8.1125e-07, 7.9787e-07, 6.3566e-07, 1.8539e-07,\n             4.6684e-07, 1.0674e-06, 6.0825e-07, 7.9666e-07, 2.1540e-06, 8.2164e-07,\n             1.1908e-06, 7.3591e-07, 1.0127e-06, 7.1292e-07, 0.0000e+00, 7.4897e-07,\n             5.0863e-06, 4.3015e-06, 8.4854e-07, 8.2463e-07, 3.0353e-07, 6.1148e-07,\n             4.9552e-07, 1.4686e-06, 1.3342e-06, 1.9301e-06, 7.4117e-07, 2.6695e-14,\n             1.5378e-06, 1.0431e-06, 6.3344e-07, 8.9150e-07, 3.2986e-06, 1.0858e-06,\n             1.9061e-06, 5.9071e-07, 7.9317e-07, 4.6964e-06, 3.5229e-08, 6.7443e-07,\n             5.4658e-07, 3.9906e-07, 5.7334e-12, 2.4205e-07, 1.1193e-06, 9.6882e-07,\n             1.0392e-06, 1.5058e-06, 5.4782e-07, 1.4377e-06, 5.1462e-07, 1.8676e-14,\n             1.3441e-07, 3.2904e-08, 6.7154e-07, 7.4787e-07, 1.1462e-06, 3.0392e-07,\n             9.4998e-07, 1.4988e-07, 1.1332e-06, 1.5919e-06, 3.9028e-06, 2.3971e-06,\n             1.7587e-18, 1.1390e-06, 8.7068e-07, 7.0672e-07, 1.0588e-06, 7.1702e-07,\n             1.3030e-18, 7.3757e-07, 7.4570e-07, 5.6240e-07])},\n    10: {'exp_avg': tensor([-9.5000e-04,  4.6803e-04, -4.0894e-04, -3.5540e-04, -1.0548e-03,\n              5.2105e-04, -3.8500e-04,  5.5429e-04, -2.0905e-04,  4.9181e-04,\n             -1.7186e-03,  3.6680e-04,  6.6460e-04, -2.5934e-04,  5.0460e-04,\n              8.5866e-04,  1.1386e-03, -1.2654e-04,  3.0823e-04, -1.3229e-04,\n             -5.9671e-04, -7.2167e-04, -2.8666e-04,  4.2291e-03, -1.4911e-04,\n              3.6095e-04,  4.0660e-04,  1.9804e-04, -5.7077e-05, -4.1933e-04,\n              6.8809e-05, -6.1596e-04, -1.0659e-03,  1.1789e-03, -5.4887e-04,\n             -2.0788e-04, -2.0447e-04,  6.8054e-05,  2.1079e-05,  9.8675e-04,\n             -1.1423e-03,  6.3523e-04, -4.4475e-04, -9.3586e-04,  1.4844e-04,\n             -6.4351e-04,  6.2112e-04, -4.6449e-05,  8.0842e-04, -4.4552e-04,\n             -2.6841e-04,  3.1473e-04, -5.7447e-04,  1.8824e-04, -5.5202e-04,\n              1.3758e-04,  2.2697e-04,  1.1527e-06, -3.3947e-05, -3.0971e-04,\n              5.4171e-05,  1.2585e-03, -6.3879e-04,  2.5487e-04]),\n     'exp_avg_sq': tensor([7.5171e-07, 1.2927e-06, 7.5489e-07, 9.7876e-07, 4.4356e-06, 1.0155e-06,\n             9.4688e-07, 7.9984e-07, 8.5123e-07, 1.7292e-06, 1.0596e-06, 2.5544e-06,\n             3.2946e-06, 5.4530e-07, 3.1701e-06, 8.1647e-07, 2.1345e-06, 3.8867e-06,\n             1.1585e-06, 1.3171e-06, 2.6702e-06, 1.0048e-06, 5.3942e-07, 4.3435e-05,\n             1.0437e-04, 2.0770e-06, 2.5004e-06, 2.4487e-07, 2.1931e-06, 2.5207e-06,\n             1.3897e-06, 9.0390e-07, 4.3264e-06, 1.7607e-06, 5.7070e-07, 8.2999e-07,\n             2.2683e-06, 7.2088e-07, 6.6101e-07, 7.5000e-07, 1.6730e-06, 6.8506e-07,\n             9.6153e-07, 5.6965e-07, 1.5638e-06, 1.2654e-06, 1.2491e-06, 1.1012e-06,\n             1.0257e-06, 9.6150e-07, 1.5255e-06, 1.6860e-06, 2.0398e-06, 1.7816e-06,\n             1.1634e-06, 1.3312e-06, 5.1653e-06, 8.5737e-07, 9.2533e-07, 1.3616e-06,\n             1.0333e-06, 1.1814e-05, 3.3818e-06, 2.6167e-06])},\n    11: {'exp_avg': tensor([-6.5001e-04, -7.0739e-04, -5.5778e-04, -1.9406e-04, -7.2328e-04,\n              2.8533e-04, -2.7295e-04,  3.1312e-04, -5.5986e-04,  4.0060e-05,\n             -9.4336e-04, -6.8791e-04,  4.9731e-04,  9.8223e-06,  7.8861e-05,\n              4.7014e-04, -8.2453e-04, -1.2930e-04, -2.0807e-04, -1.6779e-04,\n             -7.9149e-04, -2.8289e-04, -2.5781e-04,  1.1883e-03,  7.4807e-05,\n             -5.6973e-04, -1.9502e-04,  7.6545e-05,  1.4162e-04, -2.6894e-04,\n              3.6259e-04, -1.8071e-04,  8.0871e-05, -7.3859e-04, -3.3625e-04,\n             -1.0376e-04, -6.6028e-05,  1.8942e-04,  4.4346e-05,  8.3329e-04,\n             -4.8210e-04,  2.6433e-04,  3.4557e-04, -5.7721e-04,  1.1852e-03,\n             -2.5385e-04,  3.8264e-04, -5.5469e-04,  6.5735e-04, -3.1178e-04,\n             -3.5155e-04,  2.8855e-04,  3.4670e-04,  1.1718e-04, -2.4077e-04,\n             -3.9454e-04,  2.0015e-04,  2.0771e-05,  6.3596e-05, -5.9051e-04,\n             -4.2977e-06,  2.7463e-04, -3.0659e-04, -9.5265e-04]),\n     'exp_avg_sq': tensor([4.1420e-07, 1.0734e-06, 8.2926e-07, 1.9904e-07, 1.4307e-06, 7.4297e-07,\n             1.2482e-06, 1.8695e-07, 6.8941e-07, 9.5557e-07, 3.1135e-07, 1.1991e-06,\n             3.6437e-07, 5.9561e-07, 8.6716e-07, 1.0435e-06, 1.0529e-06, 1.8786e-06,\n             7.0627e-07, 7.1351e-07, 1.1682e-06, 6.8252e-07, 4.5959e-07, 4.0632e-06,\n             1.5637e-05, 2.3498e-06, 4.1788e-07, 7.8064e-08, 1.1989e-06, 1.3139e-06,\n             1.5825e-06, 3.8472e-07, 4.1794e-07, 5.1108e-07, 3.9571e-07, 7.5249e-07,\n             1.3327e-06, 8.0269e-07, 2.5852e-07, 7.4903e-07, 5.8566e-07, 4.6513e-07,\n             1.1128e-06, 4.7996e-07, 6.4171e-07, 7.7271e-07, 5.9773e-07, 7.4014e-07,\n             4.3839e-07, 3.7786e-07, 5.2055e-07, 1.1572e-06, 1.1997e-06, 5.2195e-07,\n             6.9473e-07, 7.5619e-07, 3.1675e-06, 6.1976e-07, 3.8159e-07, 8.1790e-07,\n             5.2778e-07, 1.9464e-06, 1.1547e-06, 1.0636e-06])},\n    12: {'exp_avg': tensor([-5.9737e-04, -1.2040e-03, -6.7823e-04,  1.1580e-06, -1.6984e-04,\n             -5.6655e-04, -5.8693e-04,  2.5926e-04,  4.2798e-04,  1.5977e-04,\n             -5.2279e-04,  1.2997e-04, -7.2936e-04, -2.8736e-04, -6.4462e-06,\n             -6.1373e-04,  2.0311e-04,  5.0263e-04,  1.5757e-04, -3.5005e-04,\n              5.2319e-04,  1.9710e-04, -4.6271e-04,  1.3639e-03,  3.8928e-04,\n              1.2341e-04, -7.7005e-04,  4.8241e-04,  3.6031e-04,  4.2052e-04,\n             -2.0612e-04,  8.5925e-04,  3.7991e-04, -1.5933e-04,  1.9216e-04,\n             -4.9547e-04,  1.6578e-04, -8.3739e-04, -9.7045e-04,  3.6918e-04,\n             -6.6222e-04, -4.1234e-04,  6.0895e-04, -2.3307e-04, -8.0179e-04,\n              3.7157e-04, -1.5359e-04,  1.7002e-05, -7.3030e-04,  3.9642e-04,\n              2.6074e-04, -6.6464e-04, -2.3376e-04, -4.5365e-04,  7.8864e-04,\n              9.3996e-04,  5.0518e-05, -1.6382e-04,  9.8587e-04, -1.3062e-03,\n              6.7658e-06,  4.5638e-05,  3.4955e-04,  6.2698e-04]),\n     'exp_avg_sq': tensor([1.9979e-06, 8.1970e-07, 1.6693e-06, 9.2278e-07, 2.1389e-07, 1.3036e-06,\n             4.1925e-06, 1.1162e-06, 6.8905e-07, 4.1395e-07, 3.9367e-07, 1.3796e-06,\n             4.6689e-07, 1.2370e-06, 3.8634e-07, 5.8399e-07, 1.1426e-06, 4.5081e-07,\n             3.5069e-07, 2.8647e-06, 5.2223e-07, 6.3216e-07, 3.3219e-06, 4.4345e-05,\n             3.5381e-07, 8.6456e-07, 1.8631e-06, 1.1012e-06, 5.7375e-07, 3.3286e-07,\n             2.2485e-06, 2.2538e-06, 2.6483e-07, 4.1578e-07, 6.2533e-07, 4.9945e-07,\n             5.5270e-07, 2.6107e-06, 1.2889e-06, 2.0958e-06, 6.0366e-07, 1.1214e-06,\n             3.1504e-06, 8.7347e-07, 2.3341e-06, 4.9330e-07, 4.3000e-07, 4.0103e-07,\n             2.6687e-06, 6.8062e-07, 2.6079e-07, 1.7888e-06, 6.6424e-07, 3.0213e-07,\n             1.7485e-06, 1.4307e-06, 4.3129e-06, 2.0796e-06, 9.6496e-07, 4.6832e-06,\n             1.6444e-06, 4.9080e-07, 5.4431e-07, 5.1736e-07])},\n    13: {'exp_avg': tensor([ 4.0041e-06, -3.2591e-04, -1.5915e-05,  1.1254e-04, -1.3850e-06,\n             -2.9794e-04,  5.1367e-05,  3.1756e-04,  2.0066e-04,  2.5521e-04,\n             -2.1548e-04,  5.0531e-04,  1.0889e-05, -3.4214e-04,  1.0456e-05,\n             -4.5826e-04,  1.5279e-04,  7.0066e-04,  1.7555e-04, -1.9520e-04,\n              3.3093e-04,  5.9961e-04, -3.2138e-05,  2.0728e-04,  2.1354e-04,\n             -1.6103e-04,  1.3859e-05, -3.5408e-04,  2.3735e-04,  4.8610e-05,\n             -3.5704e-04,  3.1438e-06, -3.7678e-04,  1.5791e-04, -3.8656e-04,\n             -3.0592e-04,  1.3277e-04,  1.6541e-05, -1.4982e-05, -6.9039e-06,\n              1.3622e-05, -5.4382e-04, -4.3989e-05, -1.7239e-04,  6.9721e-04,\n              1.7964e-04,  1.0928e-04, -6.9200e-05, -7.1075e-06,  1.6054e-04,\n              2.0326e-04, -7.1888e-05, -1.4321e-04, -5.5705e-04,  3.4764e-05,\n              4.0160e-04,  7.8038e-05, -8.1814e-05,  5.3756e-04, -2.9794e-06,\n             -9.7576e-05, -3.1350e-04,  2.2188e-04,  4.5553e-04]),\n     'exp_avg_sq': tensor([2.0113e-10, 2.3951e-07, 4.0658e-09, 5.8706e-07, 1.4599e-07, 6.7785e-07,\n             6.7336e-09, 1.1662e-07, 3.6928e-07, 3.4660e-07, 3.7330e-07, 7.4636e-07,\n             2.7358e-07, 2.4209e-07, 4.5898e-07, 1.9701e-07, 5.1135e-07, 3.6655e-07,\n             2.1358e-07, 1.6406e-06, 4.0601e-07, 2.8029e-07, 3.6011e-09, 1.5160e-06,\n             1.7116e-07, 8.8772e-08, 8.6695e-10, 4.9945e-07, 1.8252e-07, 5.9386e-08,\n             5.6130e-07, 3.4701e-11, 1.6266e-07, 2.8308e-07, 4.5582e-07, 2.8758e-07,\n             3.5671e-07, 1.1416e-09, 3.6743e-10, 1.4484e-07, 3.4208e-07, 5.2098e-07,\n             2.1284e-08, 2.1151e-07, 4.2795e-07, 2.6996e-07, 3.6766e-07, 2.1066e-07,\n             1.5598e-09, 4.9066e-07, 1.7218e-07, 3.8703e-09, 2.7610e-07, 2.9841e-07,\n             2.7143e-09, 5.7185e-07, 3.4188e-07, 1.6183e-07, 2.5198e-07, 7.9868e-10,\n             3.3425e-08, 1.8991e-07, 1.3334e-07, 3.1537e-07])},\n    14: {'exp_avg': tensor([-4.2714e-05,  4.8530e-05, -3.4051e-04,  6.8198e-05,  4.9432e-04,\n              5.6608e-04,  3.7319e-04,  5.5995e-04,  4.3015e-04,  6.1434e-04,\n             -9.6582e-04,  1.1041e-04, -1.2446e-04, -5.5543e-05, -7.3680e-04,\n              2.6267e-04,  4.1603e-04, -1.6356e-04, -1.6041e-03,  3.2926e-04,\n              1.1817e-03,  6.3840e-04, -5.3182e-05, -4.2098e-04,  1.2093e-04,\n              5.0653e-04, -5.4871e-04, -1.2101e-04, -9.1794e-04,  2.0834e-04,\n             -1.6650e-03, -1.5257e-04,  2.6522e-04,  1.6981e-04, -5.3048e-04,\n              2.1023e-03,  1.8734e-04, -4.4977e-05,  8.0487e-04,  3.3503e-04,\n             -3.9490e-05,  7.9970e-04,  4.1707e-04, -5.0439e-05, -1.7905e-04,\n              3.2569e-04, -1.4209e-03, -6.9731e-04,  6.2670e-04, -1.7738e-03,\n             -4.9578e-04, -4.1955e-04,  2.1371e-04,  1.4622e-04,  6.2545e-04,\n              5.4908e-04,  6.0192e-04, -2.5259e-04,  2.2773e-04,  2.0406e-04,\n              4.3762e-04, -7.2402e-04,  3.3087e-04, -1.8038e-03,  2.9948e-04,\n             -3.7484e-04, -7.1650e-04, -1.2233e-04, -7.8366e-04,  6.9155e-05,\n              7.1110e-04,  8.5030e-05, -3.7574e-04, -8.5311e-05,  5.1943e-05,\n              5.0537e-04, -8.8208e-04, -2.1878e-04, -4.4405e-04,  1.1749e-04,\n              1.5957e-03,  3.2765e-04, -1.6655e-03, -6.2831e-04, -6.1458e-05,\n             -8.5031e-05, -6.7135e-04, -1.5029e-04,  9.9965e-05,  2.9703e-05,\n             -5.5871e-04,  5.3277e-04, -7.3862e-04, -9.3302e-04, -4.7611e-04,\n              2.7276e-04,  2.3822e-04, -8.3867e-04,  5.4957e-04,  1.1126e-04,\n              1.7330e-04, -1.2108e-03,  1.9959e-04, -1.0273e-04,  6.1694e-05,\n             -8.4748e-05, -3.0856e-04,  4.7516e-04,  9.5574e-05,  6.6343e-04,\n             -3.6742e-04, -3.2221e-04, -3.8182e-04,  9.6587e-04, -5.4247e-04,\n             -2.6756e-04, -2.5979e-04, -3.4668e-04,  5.6182e-04,  6.7325e-04,\n              4.9148e-04, -2.9036e-04,  3.1191e-04,  1.1897e-04,  1.1417e-05,\n              3.2419e-04, -1.0883e-03,  3.3334e-04, -6.6094e-04, -1.9657e-04,\n              5.0328e-05, -7.5682e-04,  1.4768e-04,  1.9024e-04, -8.6188e-04,\n              3.6132e-04,  6.4035e-04, -9.0772e-05, -2.7492e-04,  2.8313e-04,\n              6.8263e-04, -6.2152e-04, -2.0846e-04, -5.8523e-04, -1.0165e-04,\n             -4.8635e-04,  8.7234e-05, -1.8824e-04,  1.6913e-03, -2.1540e-04,\n             -5.0763e-04, -3.5756e-04, -2.3199e-04,  7.2745e-05,  3.2314e-03,\n             -2.9124e-04, -9.6957e-04,  1.6791e-04,  4.6346e-04, -6.6277e-05,\n              7.1322e-04, -2.1922e-04,  2.0477e-04, -5.7408e-04,  8.3047e-04,\n             -3.0210e-04,  1.2643e-04, -6.8989e-04,  1.3245e-03,  3.2141e-04,\n             -6.4924e-04, -7.5877e-04, -1.0450e-04,  3.1943e-04, -2.1903e-04,\n              1.8920e-04,  1.2332e-03, -9.2162e-04,  7.0612e-04,  1.0629e-04,\n              5.0232e-04,  1.0476e-04,  1.1489e-03, -8.4446e-04, -1.7193e-03,\n             -4.8079e-04,  3.6086e-05,  4.7812e-04, -1.1026e-03,  1.7868e-04,\n              9.5871e-05, -3.4780e-05,  5.1384e-04,  1.6980e-04, -3.2338e-04,\n             -3.3704e-04,  2.4700e-04, -1.8151e-04,  2.3319e-04, -4.8684e-05,\n              3.9319e-05, -4.6026e-04, -1.7723e-03, -2.0066e-04,  3.7949e-04,\n              1.6161e-04,  8.8762e-04,  2.4014e-03,  3.1508e-04, -8.7830e-04,\n              2.9132e-04,  6.0428e-05,  1.4015e-04, -2.1808e-04,  4.6268e-04,\n             -4.4473e-04,  3.3571e-04,  1.3534e-04, -1.4131e-05,  7.3128e-04,\n             -5.6022e-04, -3.4492e-04,  5.1667e-04,  9.8022e-04, -3.1613e-04,\n              5.7522e-04, -8.1242e-05,  5.7643e-05,  3.3251e-04, -1.5988e-03,\n              7.0429e-04,  1.7579e-04, -7.9247e-04,  1.4709e-04,  4.7667e-04,\n             -1.5205e-04,  2.2106e-04, -3.5471e-04,  1.9852e-03,  4.6053e-04,\n              6.4752e-04,  1.2071e-03, -5.8162e-04, -7.6450e-06, -5.5144e-04,\n              8.5384e-05, -7.5560e-05, -4.6573e-04, -2.4167e-04,  6.8613e-04,\n             -1.6740e-04,  2.5817e-04,  9.9764e-05,  3.7262e-05, -9.6809e-05,\n              1.0583e-03]),\n     'exp_avg_sq': tensor([8.2611e-07, 3.1557e-07, 7.1845e-07, 1.4001e-06, 8.1542e-07, 7.4033e-07,\n             4.8517e-07, 5.9568e-07, 4.7711e-07, 9.1015e-07, 2.2896e-06, 1.9555e-06,\n             3.4151e-06, 1.0709e-06, 2.8843e-07, 1.7681e-06, 1.8223e-06, 4.5160e-07,\n             1.5991e-06, 1.0356e-06, 1.3413e-06, 1.2720e-06, 1.3623e-06, 6.2540e-06,\n             1.1991e-06, 6.3244e-07, 2.6541e-06, 5.3808e-07, 1.6849e-06, 5.1189e-07,\n             2.1176e-06, 4.9589e-07, 2.2940e-07, 8.6290e-07, 5.5969e-07, 4.2905e-06,\n             2.1188e-06, 2.2045e-06, 1.1483e-06, 2.5387e-06, 2.0038e-07, 9.6870e-07,\n             3.3194e-07, 6.7170e-07, 6.6282e-07, 1.7366e-06, 1.4421e-06, 5.5153e-07,\n             1.1893e-06, 2.1364e-06, 3.5044e-07, 2.2149e-06, 5.3541e-07, 9.7559e-07,\n             7.3951e-07, 6.7293e-07, 9.3861e-07, 7.5142e-07, 7.6070e-07, 4.3122e-07,\n             1.3614e-06, 1.1484e-06, 5.4537e-07, 1.8177e-06, 3.8004e-07, 7.5647e-07,\n             8.7527e-06, 5.3078e-07, 9.1889e-07, 1.5634e-06, 6.5575e-07, 6.9832e-07,\n             5.6748e-07, 4.7392e-07, 2.6647e-07, 1.1555e-06, 1.5727e-06, 3.0501e-07,\n             1.3031e-06, 4.2575e-07, 1.9088e-06, 1.4933e-06, 2.6596e-06, 3.1860e-07,\n             5.9115e-07, 1.4618e-06, 3.0422e-07, 1.9031e-06, 5.3921e-07, 9.8834e-07,\n             2.9949e-07, 1.4060e-06, 1.2973e-06, 2.7711e-06, 1.0645e-06, 3.1261e-07,\n             1.1599e-06, 1.6751e-06, 2.6223e-06, 6.1214e-07, 4.9871e-07, 1.3975e-06,\n             3.0915e-07, 1.3991e-06, 1.0692e-06, 3.2437e-07, 6.9481e-06, 3.6543e-06,\n             1.2397e-06, 7.5130e-07, 2.0401e-06, 8.4299e-07, 6.5705e-07, 3.5223e-06,\n             1.2024e-06, 4.9451e-07, 6.0108e-07, 8.9449e-07, 3.7858e-07, 1.2531e-06,\n             7.0261e-07, 6.8123e-07, 6.4273e-07, 1.8092e-06, 2.2174e-07, 4.9462e-07,\n             1.4972e-06, 1.8927e-06, 2.8154e-06, 7.1242e-07, 4.2443e-07, 1.6499e-06,\n             4.4746e-07, 5.3832e-07, 3.1007e-06, 7.1112e-07, 2.0724e-06, 1.3673e-06,\n             4.4075e-07, 1.7480e-06, 1.4042e-06, 1.2712e-06, 1.3600e-06, 1.0739e-06,\n             3.6060e-07, 9.5339e-07, 4.4244e-07, 2.3528e-06, 2.8985e-06, 1.3977e-06,\n             1.2176e-06, 2.8385e-07, 2.2645e-06, 1.5505e-06, 1.7100e-05, 8.8657e-07,\n             1.7201e-06, 8.0441e-07, 2.0332e-06, 9.5776e-07, 1.2104e-06, 1.7023e-06,\n             3.1867e-07, 1.0484e-06, 1.8714e-06, 7.3371e-07, 5.5382e-07, 6.5963e-07,\n             2.0861e-06, 4.5075e-07, 1.1231e-06, 1.3094e-06, 6.8295e-07, 1.1971e-06,\n             1.1715e-06, 3.1638e-07, 1.6483e-06, 8.4114e-07, 5.0891e-07, 4.0513e-07,\n             1.0370e-06, 5.4629e-07, 1.5709e-06, 1.0212e-06, 2.3053e-06, 1.7512e-06,\n             3.6288e-07, 1.2011e-06, 8.7013e-07, 9.0470e-07, 4.4516e-07, 9.4394e-07,\n             5.9903e-07, 4.9279e-07, 6.3905e-07, 5.2902e-07, 4.0555e-07, 3.4870e-07,\n             2.9933e-06, 1.4122e-06, 7.6573e-07, 9.8653e-07, 3.6816e-06, 1.2400e-06,\n             3.2922e-07, 5.7975e-07, 1.6555e-06, 5.8655e-06, 8.9716e-07, 2.8691e-06,\n             5.1580e-07, 5.8856e-07, 3.6505e-07, 7.9445e-07, 5.6320e-07, 1.6017e-06,\n             1.3148e-06, 1.2285e-06, 5.3556e-07, 2.0409e-06, 5.4819e-07, 3.3933e-07,\n             4.8988e-07, 7.7134e-07, 1.4726e-06, 2.3526e-06, 1.7757e-06, 4.3785e-07,\n             3.0528e-07, 1.2601e-06, 2.9321e-06, 1.2720e-06, 2.1371e-06, 3.2434e-06,\n             4.6566e-07, 2.0685e-06, 1.4795e-06, 5.4371e-07, 2.6621e-06, 1.2464e-06,\n             1.7018e-06, 2.1751e-06, 1.5714e-06, 1.1267e-06, 4.1038e-06, 2.1023e-07,\n             2.4714e-06, 5.7569e-07, 4.1953e-07, 7.8296e-07, 1.0138e-06, 1.5959e-06,\n             1.6713e-06, 8.8871e-07, 1.4050e-06, 2.9795e-06])},\n    15: {'exp_avg': tensor([-5.1605e-05,  5.3799e-05, -6.2373e-05, -7.5761e-05,  2.7199e-04,\n             -3.4213e-04,  1.8403e-04,  2.1453e-04,  3.8423e-05,  1.6841e-04,\n             -1.8593e-05,  1.8453e-05, -2.0955e-04,  1.1298e-04, -5.2320e-04,\n              6.7282e-05, -4.3436e-04,  4.3920e-04, -2.1751e-05,  1.2423e-07,\n              2.5168e-10, -2.4108e-04, -1.2184e-04, -3.1981e-10,  6.6221e-04,\n             -1.2200e-04,  1.7499e-04, -6.3200e-04, -3.5944e-04, -1.0643e-05,\n             -6.5177e-05, -2.2638e-04,  2.6745e-04, -2.3389e-04,  8.3647e-05,\n             -1.3557e-05,  3.3828e-05,  1.0063e-03,  8.3823e-05,  1.7807e-05,\n             -8.2349e-05,  3.2328e-04,  3.8842e-04, -3.4796e-04, -9.6821e-04,\n             -7.2260e-10,  2.9926e-04, -4.0242e-04, -1.5791e-04, -1.0007e-05,\n             -3.8012e-04, -4.3132e-06,  1.1837e-04, -2.5558e-04,  5.8735e-04,\n              2.4225e-04,  3.2974e-10,  3.7657e-04, -1.8534e-04,  7.3302e-04,\n              4.6800e-05,  3.7742e-04,  1.0120e-05,  6.8832e-06, -8.3803e-05,\n             -4.6249e-05,  3.6766e-10, -2.9093e-04,  8.1421e-04, -1.1793e-05,\n              2.6389e-04,  4.4233e-04, -4.3599e-04, -2.1058e-04,  1.5667e-04,\n              2.5331e-04,  2.4028e-06,  3.5663e-05, -2.6626e-05, -1.0237e-04,\n             -4.4166e-10,  6.1697e-05, -1.0745e-04, -2.0700e-04, -2.3360e-04,\n             -3.3272e-05, -2.1272e-04,  2.7698e-04, -1.2708e-04, -2.0331e-04,\n             -2.2073e-04,  1.3432e-04,  4.8928e-05, -1.1452e-04,  3.7670e-04,\n              3.0704e-04,  4.1574e-04, -1.1851e-10,  2.2133e-04, -1.0745e-04,\n              1.3273e-04,  8.6375e-06,  9.0002e-05, -2.0828e-05,  1.1339e-04,\n              1.1519e-04, -1.2388e-05,  7.7466e-11,  4.5332e-05, -2.3276e-04,\n             -4.8315e-04,  8.1474e-11,  2.3332e-04,  6.3255e-04,  2.2776e-04,\n              3.9597e-04,  3.0229e-04, -3.7634e-04,  3.0689e-04, -1.9553e-05,\n              1.4582e-04,  7.6385e-04,  2.8662e-04,  2.9569e-04, -5.6172e-05,\n             -5.4657e-04, -1.4002e-04, -5.1156e-04, -1.5880e-04, -1.9632e-04,\n              7.6130e-06, -2.0451e-06, -2.8104e-04,  3.6044e-04,  2.3280e-05,\n             -1.5848e-04,  1.9061e-07, -7.1911e-05,  9.0166e-05, -3.6597e-04,\n             -1.3657e-05, -3.5553e-10,  1.3814e-04,  2.2322e-04, -2.4572e-04,\n              3.6512e-04, -1.3733e-04, -2.8910e-06,  2.4857e-05, -5.9902e-10,\n             -3.1167e-05,  1.0763e-04,  3.3564e-06, -7.6611e-06,  1.2316e-05,\n              2.9425e-04, -4.4158e-05, -1.1311e-04,  4.7133e-05, -5.1221e-04,\n             -1.1277e-05,  7.3233e-05,  4.5155e-06, -2.5244e-05, -9.3707e-05,\n             -1.0415e-04, -1.5494e-04, -4.5259e-04, -1.6139e-08, -4.2541e-05,\n              3.0105e-06,  7.6736e-06,  1.1106e-06,  3.0176e-07, -2.2356e-04,\n             -6.1908e-05, -2.7774e-10, -9.7980e-05,  7.4407e-05, -2.0168e-04,\n             -5.2607e-04,  6.0772e-05,  9.8870e-04,  1.2350e-05,  2.3947e-05,\n             -4.4106e-05,  4.0169e-05,  1.3151e-04, -7.6339e-05, -4.4123e-04,\n              1.6165e-04, -5.9561e-04,  2.0423e-04, -3.0146e-04, -8.0541e-04,\n              2.4924e-04,  3.7686e-04, -3.6700e-04, -1.0253e-04,  6.7808e-05,\n             -3.0596e-04,  3.1109e-04, -7.7303e-07,  2.6177e-06, -3.4004e-04,\n              3.2737e-04,  4.0010e-04, -1.6029e-05, -3.8897e-04, -8.2834e-08,\n              1.6829e-09,  2.2285e-04,  3.8669e-05, -1.6419e-04,  3.6083e-04,\n             -7.5401e-04, -1.4445e-05, -7.2388e-05,  5.8812e-04,  7.6333e-04,\n             -4.4836e-05,  1.0914e-04,  6.4655e-04,  7.4228e-06, -8.8440e-07,\n              6.1083e-05,  2.6371e-04,  1.4072e-04, -1.4548e-04, -1.5760e-03,\n             -1.7296e-05, -9.6172e-06,  1.2468e-04,  6.4728e-09,  1.5842e-04,\n              6.6051e-06,  4.6705e-04, -2.8774e-04,  9.2787e-05, -1.5667e-05,\n             -1.4219e-04,  9.9744e-06,  3.1096e-06,  4.7040e-04,  7.2127e-05,\n             -3.0814e-05,  4.6815e-10, -1.5340e-05,  6.9896e-05, -8.6714e-04,\n             -1.4235e-05, -7.4818e-05,  1.2056e-10,  6.3490e-10, -1.1980e-05,\n              1.9607e-05]),\n     'exp_avg_sq': tensor([1.4336e-07, 2.6964e-07, 5.5671e-07, 3.9306e-07, 9.4308e-07, 4.1551e-07,\n             2.4999e-07, 2.5367e-07, 3.7073e-07, 2.2521e-07, 1.2391e-09, 3.5337e-10,\n             2.5187e-07, 5.4465e-07, 1.6268e-07, 4.3307e-09, 4.1976e-07, 4.5111e-07,\n             6.1777e-10, 5.2498e-11, 9.3605e-16, 6.6443e-07, 2.4750e-08, 1.3717e-18,\n             8.5468e-07, 2.7555e-07, 8.7339e-07, 3.2539e-07, 1.9195e-06, 2.8153e-07,\n             3.1843e-09, 4.6085e-07, 1.5226e-07, 1.6868e-07, 4.6539e-07, 2.1332e-09,\n             1.3032e-08, 5.1729e-07, 2.0313e-08, 2.9980e-09, 1.1624e-07, 2.2504e-07,\n             2.3395e-07, 2.7450e-07, 6.3165e-07, 8.1172e-19, 2.1373e-06, 5.5800e-07,\n             5.6775e-07, 1.1498e-06, 1.8650e-07, 1.9028e-11, 3.4865e-07, 5.9444e-07,\n             7.3377e-07, 2.5042e-07, 1.5257e-18, 5.2306e-07, 4.9443e-07, 3.1251e-07,\n             6.1642e-07, 3.0083e-07, 6.2082e-07, 7.3364e-09, 3.8304e-07, 9.0885e-09,\n             6.5753e-18, 3.0658e-07, 6.9377e-07, 1.1312e-08, 4.2688e-07, 7.1441e-07,\n             4.2470e-07, 2.2465e-07, 2.0964e-07, 6.9450e-07, 1.0208e-09, 3.0568e-07,\n             1.9769e-09, 2.6830e-07, 8.9363e-19, 4.9615e-09, 9.2058e-08, 1.9357e-07,\n             4.8289e-07, 1.0391e-06, 2.2742e-07, 2.2481e-07, 1.8126e-07, 1.5026e-07,\n             1.6780e-07, 2.4196e-07, 2.0433e-08, 2.6113e-08, 5.2393e-07, 1.5901e-07,\n             5.8133e-07, 9.5681e-19, 1.3372e-07, 5.1442e-07, 3.3322e-07, 6.2930e-10,\n             1.8291e-07, 8.7261e-08, 3.0203e-07, 1.9576e-07, 5.0466e-09, 7.9131e-19,\n             1.3168e-08, 5.0913e-07, 2.5164e-06, 4.7736e-19, 4.5486e-07, 1.4580e-06,\n             5.4632e-07, 2.2824e-07, 3.6012e-07, 2.3082e-07, 2.3001e-07, 3.3458e-09,\n             4.9165e-07, 4.4540e-07, 4.1640e-07, 1.7324e-06, 3.3837e-07, 3.3404e-07,\n             7.9955e-07, 3.5848e-07, 2.9886e-08, 3.7104e-07, 2.5800e-07, 3.6161e-10,\n             1.5312e-07, 4.7883e-07, 3.1000e-09, 1.9022e-07, 6.2935e-10, 9.1935e-08,\n             2.5158e-07, 2.0102e-07, 2.5094e-09, 9.8649e-19, 3.5089e-07, 4.9467e-07,\n             2.2801e-07, 7.6498e-07, 3.0089e-07, 1.0505e-09, 1.0973e-08, 1.0209e-18,\n             5.4231e-09, 2.1971e-07, 2.5842e-09, 1.5459e-08, 2.0978e-10, 3.3799e-07,\n             1.6114e-08, 3.3107e-07, 2.4996e-06, 5.9927e-07, 1.3076e-09, 4.1592e-09,\n             1.7092e-07, 7.2384e-07, 1.6131e-08, 1.6727e-06, 5.6299e-07, 2.9674e-07,\n             7.3751e-15, 5.0483e-07, 9.3099e-10, 4.9675e-09, 3.5864e-07, 9.6874e-10,\n             1.0940e-07, 2.3491e-07, 6.6102e-19, 5.0719e-09, 3.1895e-07, 1.3361e-07,\n             4.8136e-07, 3.8845e-07, 5.0345e-07, 6.7701e-08, 2.7954e-08, 4.4986e-09,\n             2.8391e-07, 2.2437e-07, 4.5027e-09, 4.7614e-07, 3.6080e-07, 5.9796e-07,\n             5.1382e-07, 3.8817e-07, 4.6292e-07, 9.8772e-08, 3.7252e-07, 2.1070e-07,\n             2.3355e-07, 5.1649e-09, 5.9028e-07, 3.3205e-07, 5.1248e-09, 1.5188e-08,\n             1.0693e-07, 5.9921e-07, 7.3511e-07, 2.9612e-10, 5.7805e-07, 2.0347e-14,\n             1.0246e-14, 6.2831e-07, 4.0724e-07, 4.6273e-07, 7.7624e-07, 9.6396e-07,\n             1.5645e-09, 9.9414e-08, 3.1288e-07, 7.6818e-07, 1.6804e-08, 1.8166e-07,\n             3.1866e-07, 2.6972e-08, 5.7334e-12, 1.0731e-08, 8.7996e-07, 4.5485e-07,\n             1.4120e-07, 9.0225e-07, 4.4597e-09, 2.4599e-08, 2.3499e-08, 2.3708e-15,\n             1.3054e-07, 1.3175e-10, 5.3909e-07, 3.6133e-07, 1.4130e-08, 5.7477e-09,\n             5.7187e-07, 5.8921e-10, 5.9276e-09, 4.3488e-07, 1.1507e-08, 1.1974e-07,\n             9.0906e-19, 5.6783e-07, 2.9469e-07, 5.8573e-07, 4.9001e-08, 3.6462e-09,\n             5.9964e-19, 9.9445e-19, 9.4167e-09, 2.8234e-08])},\n    16: {'exp_avg': tensor([-1.5086e-04,  3.2803e-05,  6.0938e-05, -8.4172e-05, -4.2667e-05,\n              1.4085e-04, -1.1888e-05, -6.9428e-05,  5.9663e-05,  2.6718e-05,\n              4.5264e-04, -5.7867e-05, -1.4229e-04,  4.2179e-04, -1.3946e-04,\n              2.2984e-04, -4.1475e-04, -2.3086e-04,  3.2891e-04,  3.8890e-05,\n              1.6850e-05, -5.1594e-05,  1.8444e-04, -2.4364e-04, -1.3248e-04,\n             -1.5943e-04, -2.5209e-04, -2.5728e-04,  8.9992e-06, -2.3778e-04,\n              9.8046e-05,  3.1777e-04, -2.7819e-04, -3.5037e-04,  4.4756e-05,\n              2.0475e-04,  8.9080e-05, -4.3401e-04,  2.4800e-04,  6.4048e-04,\n             -3.5313e-05, -3.6276e-04,  4.2412e-04,  1.5367e-04, -1.7521e-04,\n             -6.3974e-05,  6.1384e-05, -4.2063e-04,  3.1931e-04, -2.9079e-04,\n              3.2188e-04, -1.1250e-04,  1.0747e-04, -4.8607e-04, -5.6781e-05,\n              1.0219e-04,  1.3973e-04,  1.0811e-04, -1.2581e-04, -1.7229e-05,\n              5.5808e-05,  2.0620e-04,  8.9864e-05,  1.0799e-04]),\n     'exp_avg_sq': tensor([2.1665e-07, 1.1215e-07, 3.1940e-07, 8.8941e-08, 2.4271e-07, 2.1922e-07,\n             4.0477e-07, 1.4747e-07, 1.5913e-07, 1.6528e-07, 1.5428e-07, 2.3768e-07,\n             2.4777e-07, 2.2089e-07, 1.0292e-07, 2.0070e-07, 1.0593e-07, 1.5083e-07,\n             1.5583e-07, 9.4202e-08, 1.7266e-07, 1.8069e-07, 2.4299e-07, 1.3139e-07,\n             1.7438e-07, 9.3995e-08, 1.1872e-07, 1.3565e-07, 1.3150e-07, 1.8675e-07,\n             2.8859e-07, 1.8253e-07, 3.1966e-07, 1.6775e-07, 2.1456e-07, 1.4645e-07,\n             1.2150e-07, 1.5289e-07, 1.5529e-07, 1.7775e-07, 3.4671e-07, 1.8863e-07,\n             1.6849e-07, 1.6721e-07, 1.5244e-07, 1.5869e-07, 1.0680e-07, 1.2629e-07,\n             2.4000e-07, 1.5985e-07, 1.7047e-07, 1.4476e-07, 1.7481e-07, 3.3488e-07,\n             1.1620e-07, 1.2804e-07, 2.1810e-07, 1.3554e-07, 1.3881e-07, 3.2020e-07,\n             1.8015e-07, 1.3794e-07, 1.1561e-07, 4.6408e-07])},\n    17: {'exp_avg': tensor([ 7.2936e-06,  5.2308e-04,  2.4626e-04, -8.8154e-05,  1.1893e-04,\n              5.6087e-05,  2.7277e-04, -5.8614e-05,  7.8674e-05, -1.4998e-04,\n              3.1896e-04, -2.1193e-04, -7.9776e-05,  1.7894e-04,  6.1000e-05,\n              2.5785e-04, -4.9259e-04, -2.4957e-04,  2.5370e-04,  1.7753e-05,\n             -1.9664e-05, -2.0081e-04,  2.6198e-05, -2.6086e-04, -1.2049e-04,\n             -2.3163e-04, -3.3391e-04, -1.7846e-04,  1.4452e-04, -1.4974e-04,\n              1.8044e-04,  4.4744e-04, -9.6256e-05, -1.9938e-04, -8.1398e-05,\n              1.7028e-04, -5.7256e-05, -6.5363e-05, -8.6704e-05,  4.3881e-04,\n              1.7424e-05,  6.1158e-05,  4.6778e-05, -1.1582e-04, -2.2668e-04,\n             -1.7637e-04,  1.6056e-04, -4.0391e-04,  1.2809e-04, -2.2837e-04,\n              3.0069e-04, -3.7180e-05,  2.0418e-06, -4.7202e-04, -3.8726e-05,\n              7.6510e-05,  6.8303e-05, -2.4061e-05,  1.1640e-04,  1.5205e-04,\n              1.3315e-05,  1.3682e-04, -5.9176e-05, -4.0224e-06]),\n     'exp_avg_sq': tensor([1.6525e-07, 1.7124e-07, 4.5441e-07, 7.8545e-08, 1.5644e-07, 1.5499e-07,\n             2.4167e-07, 1.8103e-07, 8.5151e-08, 1.5714e-07, 9.6027e-08, 1.5441e-07,\n             2.3022e-07, 1.9171e-07, 1.3668e-07, 1.6520e-07, 1.3730e-07, 1.3659e-07,\n             7.7440e-08, 7.3679e-08, 1.0914e-07, 1.1839e-07, 1.9813e-07, 1.1594e-07,\n             1.0029e-07, 1.2949e-07, 1.3983e-07, 7.3720e-08, 1.3365e-07, 1.4988e-07,\n             2.1459e-07, 1.0162e-07, 1.5461e-07, 1.9622e-07, 1.5350e-07, 1.3988e-07,\n             9.9153e-08, 9.5961e-08, 9.3910e-08, 1.6288e-07, 1.5598e-07, 9.7769e-08,\n             1.1890e-07, 1.1954e-07, 9.6780e-08, 1.2253e-07, 1.1812e-07, 1.6163e-07,\n             1.6858e-07, 1.2801e-07, 1.2017e-07, 1.1992e-07, 1.3806e-07, 1.3858e-07,\n             7.7276e-08, 1.5383e-07, 1.2029e-07, 1.4822e-07, 9.6785e-08, 1.6508e-07,\n             9.2318e-08, 1.1973e-07, 9.9793e-08, 8.7415e-08])},\n    18: {'exp_avg': tensor([ 2.1647e-04,  4.1065e-04,  1.6381e-04,  1.3651e-04, -2.9273e-04,\n              1.1776e-04, -2.1877e-04,  4.1234e-04,  2.6202e-04, -2.2974e-04,\n             -8.5784e-05, -8.5660e-05, -2.9068e-04, -1.0796e-03, -6.5451e-04,\n              5.7669e-04, -1.5986e-04,  3.5019e-04, -2.5779e-04,  2.8941e-04,\n             -3.2457e-05,  1.8539e-05,  2.3796e-04, -1.5042e-04, -7.3473e-05,\n             -2.3791e-04, -4.1500e-04,  3.8821e-04,  3.0227e-04, -8.4969e-04,\n              2.6519e-04, -1.3004e-04, -2.6643e-04,  9.0193e-05,  2.9573e-04,\n              4.2337e-04,  2.2943e-04, -4.4624e-04, -6.5572e-04,  2.8199e-04,\n             -1.7884e-04, -4.6195e-05,  2.0202e-04, -3.3540e-04, -1.2453e-04,\n             -9.3024e-05,  7.0022e-04, -5.5276e-04,  4.9978e-04, -7.9707e-05,\n              2.9674e-04,  1.7087e-04, -2.2501e-05, -3.6068e-05, -4.0413e-04,\n              4.9381e-06, -3.8475e-05,  3.0945e-04, -3.6095e-04, -5.2423e-05,\n              1.2977e-04,  4.6128e-05, -6.1099e-04, -1.0809e-04]),\n     'exp_avg_sq': tensor([3.9653e-07, 5.7878e-07, 2.4780e-07, 1.9254e-07, 8.2529e-07, 3.3526e-07,\n             1.4924e-07, 1.6925e-07, 2.2062e-07, 9.1533e-07, 3.5851e-07, 2.9985e-07,\n             5.9078e-07, 3.9020e-07, 4.9105e-07, 2.9345e-07, 2.5463e-07, 2.1960e-07,\n             1.9087e-07, 2.8380e-07, 6.2537e-07, 1.5989e-07, 1.7096e-07, 1.7424e-07,\n             2.4645e-07, 2.3134e-07, 3.1099e-07, 3.6653e-07, 1.9684e-07, 2.4984e-07,\n             1.2402e-07, 1.5425e-07, 1.7160e-07, 1.7854e-07, 3.9870e-07, 4.1395e-07,\n             1.8774e-07, 4.5545e-07, 5.6117e-07, 3.2743e-07, 1.9193e-07, 1.6522e-07,\n             2.6583e-07, 2.9146e-07, 1.1229e-07, 1.8451e-07, 6.8144e-07, 1.3384e-06,\n             3.4246e-07, 1.8211e-07, 3.5850e-07, 4.7694e-07, 2.8666e-07, 4.4700e-07,\n             9.5791e-07, 4.8792e-07, 5.0167e-07, 2.5456e-07, 5.0523e-07, 2.0398e-07,\n             2.3357e-07, 2.0503e-07, 7.3626e-07, 2.6019e-07])},\n    19: {'exp_avg': tensor([-6.5125e-05,  2.1362e-04,  1.4999e-04,  6.6812e-06,  3.7768e-06,\n              8.4916e-06, -3.2188e-04,  3.2369e-04, -3.3746e-05, -1.8697e-05,\n              4.8584e-05,  4.6797e-05, -5.0896e-04, -6.2990e-04, -1.6138e-04,\n              3.5285e-04, -1.5385e-04,  4.5731e-05,  4.7462e-05,  2.7193e-04,\n             -2.1967e-04,  8.2488e-05,  1.9444e-04, -1.9421e-04, -1.3185e-04,\n             -1.7956e-04, -3.4281e-04,  2.0150e-04, -1.4057e-04, -4.5081e-04,\n              6.7110e-05, -2.2434e-05, -1.3851e-04,  1.4891e-04,  2.1589e-04,\n              3.1608e-04,  3.5696e-04, -4.7557e-04, -5.3024e-05,  3.7788e-04,\n             -3.5402e-04, -2.3445e-05, -9.2748e-05, -3.5686e-04, -1.1932e-04,\n             -9.0632e-05,  2.4228e-06, -1.7680e-05,  1.0462e-04, -1.8604e-04,\n              1.2035e-04,  6.5949e-05,  1.3581e-04, -1.9421e-05,  4.2954e-05,\n             -1.6414e-04, -4.0940e-06,  5.4124e-04, -2.5977e-04, -5.4891e-05,\n              1.8415e-04,  5.4051e-05,  1.9278e-04, -1.9362e-04]),\n     'exp_avg_sq': tensor([5.0684e-09, 8.7699e-07, 2.2927e-07, 1.2465e-07, 6.1504e-09, 2.1533e-07,\n             1.1725e-07, 8.1875e-08, 1.1125e-07, 6.0616e-10, 2.2006e-07, 8.6091e-08,\n             2.5459e-07, 1.8517e-07, 2.0789e-07, 1.2513e-07, 1.1920e-07, 1.2335e-07,\n             8.8620e-08, 5.8107e-08, 1.7350e-07, 1.1223e-07, 1.0201e-07, 1.0176e-07,\n             1.5476e-07, 1.8931e-07, 1.7476e-07, 1.8118e-07, 1.0969e-07, 1.3131e-07,\n             4.8100e-08, 8.6513e-08, 1.4717e-07, 9.8852e-08, 1.8900e-07, 1.9665e-07,\n             1.0721e-07, 1.7918e-07, 1.9854e-07, 1.8404e-07, 9.5097e-08, 1.2371e-07,\n             1.3709e-07, 1.3682e-07, 9.8676e-08, 1.1874e-07, 2.2823e-10, 2.5477e-09,\n             1.4724e-07, 1.1620e-07, 1.4199e-07, 2.2116e-07, 1.4792e-07, 2.3842e-07,\n             5.0944e-09, 2.2493e-07, 1.9496e-07, 1.5335e-07, 1.6140e-07, 1.2899e-07,\n             1.4239e-07, 1.0505e-07, 4.6251e-08, 1.4363e-07])},\n    20: {'exp_avg': tensor([ 4.5983e-04, -4.0817e-04,  4.8385e-04, -2.0412e-04,  1.8157e-04,\n             -4.4203e-04,  1.5577e-04, -2.8927e-04, -2.9538e-04, -9.7760e-04,\n              1.2749e-04, -1.5688e-04, -4.7870e-05,  5.5130e-04,  2.4557e-04,\n              7.0977e-04, -3.4278e-05,  1.2713e-05,  3.5668e-04, -3.3181e-04,\n             -1.3355e-04, -1.7552e-04,  5.2408e-04, -1.3521e-03, -6.1860e-05,\n              7.3909e-05, -2.6067e-04, -4.5571e-04,  1.1828e-04,  1.8391e-04,\n              1.5647e-04,  8.4859e-05, -1.3653e-04, -1.6369e-04,  4.5241e-05,\n              1.5374e-04, -2.1563e-04, -1.5526e-04,  1.8839e-04,  6.2242e-04,\n             -9.8843e-04,  3.6731e-04, -1.1675e-04,  1.5069e-04, -3.8876e-04,\n              2.7118e-04,  5.0770e-04, -8.4829e-04,  3.6244e-05, -1.2446e-04,\n             -1.2262e-04,  1.8091e-04,  8.6434e-05,  1.9045e-04, -4.8626e-05,\n             -7.9658e-04, -8.1117e-06,  4.3009e-04,  4.0789e-04, -3.7469e-04,\n             -5.0839e-05,  7.1804e-04,  1.7734e-04, -7.7177e-04, -1.1592e-03,\n             -8.7164e-04, -1.4943e-04,  1.2864e-05,  2.8989e-04,  3.1914e-05,\n              2.2966e-05, -3.2020e-05, -3.3985e-04, -4.5024e-04, -9.3262e-05,\n              8.2892e-05,  2.8976e-04, -1.9511e-04, -1.0123e-04,  6.8088e-04,\n              3.4447e-04,  9.1592e-05, -4.4456e-04, -1.0150e-03, -3.8323e-04,\n              8.4120e-05, -9.7977e-05, -1.0498e-03,  1.9813e-04, -8.8867e-04,\n             -4.3647e-04, -4.3455e-04, -4.0827e-04,  5.1791e-04, -4.3484e-04,\n             -1.6483e-04, -1.7512e-04,  2.8192e-04, -4.1063e-04,  1.0126e-03,\n             -4.3185e-04,  8.2174e-04,  2.5416e-04,  1.1543e-04, -1.0990e-05,\n              8.0719e-05, -5.5980e-04,  3.4605e-04,  2.3333e-04,  2.8174e-04,\n             -2.6441e-04,  9.6758e-05, -9.7254e-05,  9.5581e-05, -1.4467e-04,\n              1.3820e-04,  3.4426e-04,  4.2501e-06,  1.1559e-04, -8.9225e-04,\n              1.9298e-04, -4.8852e-05, -8.8898e-05,  5.6207e-05,  1.4088e-04,\n              2.2800e-04,  3.5561e-04,  2.0502e-06,  5.0871e-04, -1.9416e-04,\n              1.5328e-04, -3.1628e-04,  2.4279e-04, -2.7064e-04, -7.1633e-05,\n             -6.7405e-04,  2.1465e-04, -4.4903e-04, -2.1895e-04,  1.2746e-04,\n              4.5567e-04, -3.2355e-04,  1.0269e-03,  4.7188e-04,  1.7516e-04,\n             -1.0956e-03, -3.4990e-04,  7.7411e-04,  7.8372e-04, -7.0623e-04,\n             -7.1520e-04, -3.5675e-07, -2.3219e-04, -4.5462e-04,  5.3978e-04,\n              3.8219e-05,  4.4600e-04, -2.4000e-04, -2.8062e-05,  9.0136e-05,\n              2.2973e-04, -3.7753e-04, -9.9110e-05, -7.9860e-05, -1.8213e-04,\n              1.7706e-04,  3.5605e-04, -2.2515e-04, -5.5795e-04,  4.7343e-05,\n              8.4128e-05, -5.6400e-04,  1.8647e-04, -3.6392e-04, -5.9472e-04,\n              6.6708e-05, -1.0658e-04,  7.6769e-05, -3.0032e-04,  1.1519e-05,\n              3.3239e-04,  9.1741e-05,  6.1851e-04, -1.7814e-05,  5.7549e-05,\n              2.5372e-04,  5.0229e-04, -6.0099e-05,  2.5553e-04, -4.1505e-05,\n             -1.8352e-04, -6.4631e-04,  3.3419e-04, -7.1882e-04,  2.0769e-04,\n             -1.0798e-04,  3.0988e-04,  7.4857e-04, -4.9346e-04,  2.6723e-04,\n             -2.2127e-04,  7.3021e-05,  5.0267e-04, -3.5311e-04,  1.7030e-04,\n              5.0815e-04,  6.1894e-05,  1.0295e-04,  4.0820e-06,  6.6536e-04,\n             -1.6128e-05, -2.2941e-04, -2.5339e-04, -5.2570e-04,  5.6885e-05,\n             -3.2498e-05, -2.4604e-04, -3.5750e-04,  8.2170e-06, -7.5934e-05,\n              1.0715e-03, -6.0006e-04,  2.4778e-04,  8.8754e-04,  1.1076e-03,\n             -9.1533e-04,  4.6489e-04, -3.1970e-04, -1.0048e-04, -5.8418e-04,\n             -1.6099e-04, -9.0332e-05,  3.4111e-05,  2.1427e-04,  7.8408e-05,\n             -1.0630e-03, -5.1692e-04, -3.7777e-04, -4.0077e-04, -2.1674e-04,\n             -6.3138e-05, -4.5373e-04,  8.2869e-04, -3.3305e-05,  3.6023e-04,\n             -1.4482e-04,  6.3972e-04, -1.4112e-04,  1.8929e-04, -1.9468e-04,\n              9.7256e-04,  4.7126e-04,  3.2176e-04, -1.2285e-06, -3.4692e-04,\n              3.1033e-04]),\n     'exp_avg_sq': tensor([2.9918e-07, 1.9024e-07, 4.3303e-07, 2.7970e-07, 1.7909e-07, 6.6099e-07,\n             6.0364e-07, 4.2997e-07, 2.6845e-07, 4.0228e-07, 6.1743e-07, 8.4102e-07,\n             9.5162e-07, 6.0455e-07, 1.5797e-07, 1.0314e-06, 2.1318e-07, 3.3022e-07,\n             1.3948e-06, 6.1454e-07, 8.6965e-07, 1.7477e-07, 1.1404e-06, 7.9041e-07,\n             3.7598e-07, 3.6322e-07, 1.0691e-06, 2.0093e-07, 1.0512e-06, 1.8180e-07,\n             4.9907e-07, 9.7636e-08, 3.8914e-07, 3.0745e-07, 2.3481e-07, 5.1814e-07,\n             5.3593e-07, 1.8149e-07, 2.7774e-07, 8.2223e-07, 3.7556e-07, 1.2039e-06,\n             2.6992e-07, 3.6559e-07, 6.9580e-07, 1.4527e-06, 1.9151e-07, 4.0192e-07,\n             7.1931e-07, 2.1971e-07, 2.2182e-07, 7.1321e-07, 2.8927e-07, 7.5145e-07,\n             1.0274e-06, 2.5041e-07, 7.8475e-07, 2.5414e-07, 7.0007e-07, 2.6393e-07,\n             3.0578e-07, 1.0122e-06, 2.4658e-07, 3.3790e-07, 4.2176e-07, 1.2828e-06,\n             2.3054e-06, 3.6160e-07, 3.1696e-07, 7.3226e-07, 3.1094e-07, 1.9684e-07,\n             4.3531e-07, 3.1387e-07, 1.2688e-07, 1.6560e-07, 3.2010e-07, 4.1319e-07,\n             8.2498e-07, 2.9468e-07, 8.4578e-07, 9.3879e-07, 5.8728e-07, 4.6505e-07,\n             8.6975e-07, 5.0221e-07, 8.9361e-08, 9.6106e-07, 3.1437e-07, 7.2945e-07,\n             1.4827e-07, 9.3918e-07, 6.0895e-07, 6.6863e-07, 1.3603e-06, 2.6646e-07,\n             2.8586e-07, 4.9411e-07, 3.4262e-07, 5.5015e-07, 6.4523e-07, 7.5547e-07,\n             2.9921e-07, 9.6407e-07, 3.2003e-07, 2.6921e-07, 6.1214e-07, 7.7576e-07,\n             8.4515e-07, 1.3258e-06, 1.1108e-06, 9.5503e-07, 1.1820e-07, 1.4460e-06,\n             9.9469e-07, 4.0235e-07, 3.8181e-07, 5.2561e-07, 1.7995e-07, 9.5409e-07,\n             6.8248e-07, 3.5071e-07, 2.0175e-07, 1.7525e-07, 1.3169e-07, 4.1506e-07,\n             7.0466e-07, 3.6953e-07, 4.4044e-07, 2.4074e-07, 2.9223e-07, 8.6556e-07,\n             2.4167e-07, 2.8282e-07, 5.6093e-07, 2.8367e-07, 7.7062e-07, 8.3818e-07,\n             1.9581e-07, 4.3627e-07, 5.1694e-07, 3.8445e-07, 7.8154e-07, 2.5830e-07,\n             2.2204e-07, 5.8444e-07, 2.9944e-07, 1.0036e-06, 9.3243e-07, 5.0764e-07,\n             1.1269e-06, 1.7442e-07, 5.6907e-07, 1.4224e-06, 5.0431e-06, 3.9811e-07,\n             7.8148e-07, 6.8007e-07, 5.3031e-07, 1.1207e-06, 9.7626e-07, 9.2745e-07,\n             1.5979e-07, 3.1734e-07, 1.1674e-06, 5.9318e-07, 5.0398e-07, 4.2674e-07,\n             1.4214e-06, 2.8958e-07, 9.4831e-07, 6.8667e-07, 2.1190e-07, 6.6393e-07,\n             5.8310e-07, 2.1058e-07, 1.2172e-06, 1.0807e-06, 2.2014e-07, 2.5800e-07,\n             1.1405e-06, 2.9708e-07, 6.8042e-07, 1.4788e-07, 2.9070e-07, 7.7271e-07,\n             4.7920e-07, 1.1924e-06, 7.4807e-07, 1.7449e-07, 3.3558e-07, 1.1724e-06,\n             6.7399e-07, 3.4880e-07, 5.4876e-07, 4.1655e-07, 2.6692e-07, 3.3361e-07,\n             7.9814e-07, 3.9936e-07, 3.8306e-07, 2.6087e-07, 5.6992e-07, 2.0143e-07,\n             2.7802e-07, 3.1260e-07, 8.1343e-07, 6.1519e-07, 3.5453e-07, 1.6043e-06,\n             3.1113e-07, 4.3054e-07, 3.1505e-07, 4.6166e-07, 1.7186e-07, 6.4897e-07,\n             8.4797e-07, 7.8997e-07, 2.2030e-07, 8.8002e-07, 1.1153e-06, 5.0266e-07,\n             2.0206e-07, 3.4872e-07, 1.1282e-06, 9.9103e-07, 1.1566e-06, 2.4398e-07,\n             2.7541e-07, 4.4684e-07, 1.2869e-06, 2.4980e-07, 5.2552e-07, 7.6256e-07,\n             4.0933e-07, 1.1415e-06, 3.1586e-07, 2.6196e-07, 8.8880e-07, 5.8364e-07,\n             9.1511e-07, 6.1160e-07, 9.3498e-07, 8.9413e-07, 2.3930e-06, 1.6683e-07,\n             4.4632e-07, 2.9222e-07, 2.0532e-07, 6.0219e-07, 9.4586e-07, 7.4744e-07,\n             9.3888e-07, 3.2375e-07, 4.9682e-07, 4.5794e-07])},\n    21: {'exp_avg': tensor([ 2.4739e-04, -1.2154e-04, -2.4827e-04,  2.8787e-04, -1.2839e-05,\n             -2.5930e-04,  2.1187e-04,  3.0479e-04, -3.5398e-04,  1.8457e-04,\n             -1.3891e-05,  1.5027e-05, -1.3767e-04,  1.3649e-04, -1.1340e-04,\n              6.7901e-05, -1.7077e-04, -3.5812e-05, -2.2932e-05,  5.0317e-10,\n              3.1281e-10, -7.1688e-05, -1.4360e-09, -1.0355e-10,  2.3117e-04,\n              8.0901e-06, -1.7458e-04, -5.4073e-05, -3.6995e-04, -5.8407e-05,\n             -1.5331e-06, -9.7368e-05,  2.8644e-04, -4.7893e-04,  1.0028e-04,\n             -1.0505e-05,  2.2764e-05,  9.8481e-04,  3.7914e-05,  5.4923e-10,\n             -5.6319e-04,  7.7711e-05,  1.1499e-05, -3.3068e-04, -1.4806e-04,\n              1.0784e-11,  1.1922e-05,  4.0182e-06,  5.7156e-05,  1.3452e-04,\n              9.0436e-06, -4.2585e-06,  1.2250e-04, -3.4395e-04,  6.7850e-05,\n              2.7433e-04, -5.6928e-10, -5.4462e-05, -5.8525e-05,  6.1051e-04,\n              1.8380e-04,  3.2002e-04,  6.8125e-06,  3.1084e-06, -7.3148e-04,\n             -4.7793e-05, -3.6021e-10, -1.3853e-04,  7.1574e-04, -5.2294e-05,\n              1.1145e-04,  4.9460e-05, -3.6441e-04,  9.1633e-05,  1.4956e-04,\n              5.1577e-05,  1.5980e-06, -1.6455e-04, -2.0729e-05, -1.0469e-04,\n             -9.0238e-10,  1.8586e-05, -1.0780e-04, -1.7727e-04, -5.4083e-05,\n              7.6118e-07,  1.3610e-05,  1.1050e-04, -4.7126e-04, -1.5480e-04,\n             -2.4064e-04,  1.3432e-04, -2.3787e-05, -8.5259e-05, -8.4855e-05,\n             -4.5303e-05,  1.6382e-04, -4.5576e-10,  1.4780e-04,  1.4133e-04,\n              3.0193e-04,  9.9259e-06, -1.8043e-05, -3.6818e-05, -6.9067e-05,\n             -8.4262e-05, -1.4481e-05,  2.7981e-11, -3.0987e-06,  1.1183e-05,\n              1.4343e-04,  1.6825e-10, -7.2952e-05, -1.1931e-10, -2.2089e-05,\n              4.1843e-04,  6.7458e-05, -1.7934e-04,  1.4992e-04, -1.9971e-05,\n             -8.4967e-05,  4.2102e-04,  4.3444e-04,  1.8314e-04, -6.1852e-05,\n             -9.8071e-04, -2.6219e-05, -5.0813e-04,  2.4968e-06, -3.5812e-04,\n              6.2215e-05, -1.0852e-09, -4.1637e-04,  9.2129e-05,  2.1013e-06,\n             -1.8178e-04, -1.2423e-06, -6.7929e-05,  7.8989e-05, -6.2356e-05,\n             -1.6071e-05,  4.1722e-10, -1.9184e-05, -2.6301e-04,  8.4149e-06,\n             -1.4204e-05, -3.0873e-04,  4.7854e-06,  2.4732e-05, -1.1486e-10,\n              8.8952e-06,  4.7556e-05, -9.0732e-10, -8.4961e-06,  1.0096e-05,\n              3.7274e-04, -2.0207e-05, -8.7875e-05, -4.4543e-06, -1.0350e-04,\n             -1.1277e-05,  2.4303e-05,  4.8375e-05, -1.3325e-04, -6.5280e-06,\n              2.0674e-07,  4.0917e-04,  6.8059e-05, -1.6043e-08,  6.6159e-05,\n              3.0106e-06,  1.2134e-05, -1.2095e-05,  4.0328e-10, -7.4451e-05,\n              2.5468e-06, -8.5973e-11, -9.0606e-05, -1.5504e-04, -1.5249e-04,\n             -2.6640e-04, -5.9599e-05, -6.0046e-07,  1.1350e-05,  7.4369e-06,\n             -4.4107e-05, -2.8446e-05, -9.1015e-06, -3.4778e-05, -4.6057e-04,\n              2.7181e-05, -3.8357e-05, -1.5808e-04, -4.4831e-04, -2.8465e-04,\n             -1.1225e-04,  2.5028e-04, -5.3893e-04,  7.7103e-07,  6.7805e-05,\n             -2.0396e-04, -2.1417e-05,  2.1127e-05,  7.1906e-06, -1.0490e-05,\n              1.2412e-05, -1.4189e-06, -1.5865e-05, -1.5932e-04, -5.3119e-09,\n              1.2710e-09,  9.6458e-05,  1.1036e-04, -5.3270e-04, -2.2773e-05,\n             -7.7871e-04, -1.2700e-05,  3.5385e-05,  7.9755e-05,  7.1714e-04,\n             -4.4836e-05, -2.5315e-05,  6.3814e-07, -1.6588e-05, -8.8438e-07,\n              2.7043e-05, -1.2567e-04, -1.3082e-04,  1.0179e-04, -1.6781e-03,\n              3.0674e-05, -1.0094e-05,  1.4293e-07,  7.4760e-09, -3.5674e-04,\n              3.2928e-10,  5.0313e-04, -3.6929e-04,  6.1143e-05, -1.3608e-05,\n             -1.2547e-04,  5.5300e-07,  7.8816e-06, -7.7160e-05,  7.2277e-06,\n             -1.4367e-04,  5.1308e-10, -1.4989e-04, -5.7401e-06, -3.1142e-04,\n             -1.2013e-07, -8.6191e-05,  2.2818e-10,  4.5820e-10, -5.2066e-05,\n             -1.7850e-10]),\n     'exp_avg_sq': tensor([2.1200e-07, 1.2726e-07, 5.3947e-07, 1.3667e-07, 2.3057e-07, 3.3833e-07,\n             1.4622e-07, 2.8134e-07, 2.0073e-07, 1.9683e-07, 3.0215e-10, 3.3767e-10,\n             9.7649e-08, 4.0716e-07, 9.6570e-08, 4.1006e-09, 1.0474e-07, 3.0034e-07,\n             6.2466e-10, 1.7219e-18, 9.4277e-16, 2.3937e-07, 3.7808e-16, 1.0496e-18,\n             4.0129e-07, 1.3768e-07, 2.9784e-07, 1.7715e-07, 1.7146e-06, 1.1944e-07,\n             3.8047e-11, 7.1826e-08, 1.4615e-07, 2.0030e-07, 4.5302e-07, 3.6412e-11,\n             6.5389e-09, 4.7587e-07, 9.4588e-09, 6.0528e-16, 1.2714e-07, 5.4312e-08,\n             1.5357e-07, 1.4009e-07, 8.4305e-08, 6.0849e-19, 1.2255e-09, 2.1206e-09,\n             1.1392e-07, 3.1847e-07, 7.0082e-08, 1.8940e-11, 2.1074e-07, 3.7025e-07,\n             5.9972e-07, 1.2426e-07, 1.5309e-18, 1.0816e-07, 1.6529e-07, 2.5554e-07,\n             2.5860e-07, 2.9822e-07, 8.5880e-10, 2.5768e-09, 2.2842e-07, 9.0983e-09,\n             7.0946e-18, 2.4459e-07, 4.9988e-07, 8.0140e-09, 2.0303e-07, 2.8898e-07,\n             2.5400e-07, 1.4479e-07, 1.0390e-07, 2.3838e-07, 8.9952e-10, 1.5600e-07,\n             7.6990e-10, 1.3464e-07, 5.6738e-19, 1.3192e-09, 9.2074e-08, 1.6011e-07,\n             2.6930e-08, 1.5806e-12, 4.0926e-08, 6.2699e-08, 2.1562e-07, 1.4683e-07,\n             8.6798e-08, 2.4196e-07, 5.5344e-09, 2.6079e-08, 2.0079e-08, 1.2247e-07,\n             1.8477e-07, 9.8399e-19, 1.3288e-07, 1.7067e-07, 1.6256e-07, 6.2384e-10,\n             9.3234e-08, 1.7798e-08, 2.8491e-07, 1.5839e-07, 1.7199e-09, 5.5463e-19,\n             1.8498e-10, 7.4914e-10, 2.1212e-06, 4.3618e-19, 1.8686e-07, 1.3083e-18,\n             5.6896e-10, 1.5696e-07, 1.9066e-07, 1.3182e-07, 1.2867e-07, 3.3818e-09,\n             3.6302e-08, 1.7689e-07, 4.2021e-07, 1.3497e-06, 1.5312e-07, 5.9737e-07,\n             6.2607e-08, 3.1224e-07, 2.1282e-11, 2.5193e-07, 1.4197e-07, 2.7245e-12,\n             1.6032e-07, 1.9631e-07, 5.1246e-10, 1.5791e-07, 3.7997e-11, 8.8058e-09,\n             9.7261e-08, 1.9061e-08, 2.5212e-09, 9.1841e-19, 6.5295e-08, 1.3651e-07,\n             1.2033e-07, 1.0939e-07, 1.8185e-07, 4.9670e-10, 1.0958e-08, 1.0616e-18,\n             6.3660e-10, 1.7657e-07, 7.2676e-19, 1.5447e-08, 1.6170e-10, 2.1584e-07,\n             9.1270e-10, 1.6301e-07, 2.3107e-06, 3.7550e-08, 1.3076e-09, 6.6974e-10,\n             1.1632e-07, 3.3381e-07, 1.6260e-09, 6.8119e-11, 4.3893e-07, 3.4018e-07,\n             7.3107e-15, 2.5544e-07, 9.3099e-10, 3.5582e-09, 3.4393e-07, 1.2821e-18,\n             5.7797e-08, 8.6797e-08, 3.8618e-19, 4.9070e-09, 1.7129e-07, 1.1840e-07,\n             4.4288e-07, 1.5645e-07, 8.4245e-10, 6.7715e-08, 1.0008e-10, 4.4986e-09,\n             2.9249e-07, 3.5226e-08, 1.1568e-09, 3.9431e-07, 1.7625e-08, 5.3911e-09,\n             1.1095e-07, 1.6248e-07, 1.9596e-07, 1.2841e-07, 2.5773e-07, 1.5179e-07,\n             1.3398e-09, 5.1649e-09, 2.5613e-07, 1.3704e-07, 3.0145e-09, 1.4902e-08,\n             1.0197e-07, 2.6301e-07, 6.8379e-12, 2.9549e-10, 2.6675e-07, 5.5090e-15,\n             1.0248e-14, 2.6496e-07, 2.6521e-07, 2.8200e-07, 1.7154e-07, 9.0864e-07,\n             1.3490e-09, 4.5877e-09, 1.7193e-07, 7.5974e-07, 1.6804e-08, 2.0171e-07,\n             1.5769e-07, 2.2848e-09, 5.7330e-12, 1.7159e-09, 4.8758e-07, 1.9945e-07,\n             7.7952e-08, 8.7407e-07, 3.4395e-09, 2.3345e-08, 7.5770e-14, 2.3631e-15,\n             1.3565e-07, 9.1972e-14, 3.7636e-07, 1.7345e-07, 9.4909e-09, 1.8918e-09,\n             2.6374e-07, 2.8809e-10, 2.2322e-09, 3.7810e-08, 2.3400e-10, 6.1304e-08,\n             7.2320e-19, 3.9092e-07, 1.0204e-07, 3.8917e-07, 6.1146e-12, 3.5689e-09,\n             5.1143e-19, 8.9296e-19, 5.0323e-09, 7.1456e-19])},\n    22: {'exp_avg': tensor([-3.4808e-04,  1.3909e-05, -4.9109e-04, -2.2031e-04, -1.2308e-04,\n              1.0513e-04, -2.7005e-04,  1.7886e-04,  2.2621e-04,  2.5273e-04,\n              3.7996e-04,  4.0970e-04, -9.1835e-05,  5.7254e-04,  2.6850e-04,\n             -1.3911e-04,  3.5128e-04, -1.3555e-05,  6.1083e-04, -1.8744e-04,\n             -4.7381e-04,  1.0615e-03, -5.9410e-06, -4.4452e-04, -1.8298e-04,\n             -4.0845e-04,  5.7239e-04, -1.5725e-04, -7.9958e-04, -3.8850e-05,\n              6.4907e-05,  1.1643e-04,  1.6747e-04, -2.4846e-04,  4.5378e-05,\n              1.5873e-04,  6.4817e-05,  3.5468e-04,  1.8279e-04, -4.5546e-04,\n              1.3592e-04, -7.1455e-06,  6.6105e-04,  1.1942e-03, -4.1355e-04,\n             -5.0228e-04,  6.4886e-04, -6.7221e-05, -2.6286e-04,  2.3480e-04,\n             -2.9007e-04,  1.6115e-04, -5.0162e-04,  2.0954e-04, -1.9093e-04,\n              2.7193e-04,  1.6010e-04, -1.6230e-04, -6.3967e-04,  2.2132e-04,\n             -3.7027e-04, -5.7686e-04,  1.6139e-04,  8.1056e-05,  1.1544e-04,\n             -3.6985e-04, -3.4214e-04, -2.8251e-04, -2.9475e-04,  3.6425e-04,\n             -3.7355e-04,  9.0760e-05,  4.4522e-04,  1.2386e-04, -1.9512e-04,\n             -1.4987e-04,  3.4534e-04, -1.2014e-04, -1.8696e-04,  3.3164e-04,\n             -2.2862e-04,  4.0372e-04,  3.3559e-04,  1.6872e-04, -1.7013e-05,\n             -2.0388e-04, -5.4010e-04,  9.7557e-04,  4.4552e-05,  7.1959e-04,\n              9.6613e-05,  2.6576e-04, -1.7351e-04, -4.4594e-04,  2.3845e-04,\n              9.8541e-04, -7.9041e-05,  9.9286e-05, -1.0091e-04,  2.5754e-04,\n              3.4453e-04, -1.1995e-03, -5.3577e-06,  8.0815e-04, -2.9647e-04,\n              6.0061e-04, -9.5443e-05,  4.5889e-04,  4.5089e-04, -9.3182e-04,\n             -9.6407e-04, -2.0586e-04, -6.9709e-05, -6.0620e-04,  2.3901e-04,\n             -4.0005e-04, -2.2504e-04, -3.1977e-04, -6.1608e-05, -5.0785e-04,\n              4.6638e-04, -3.8195e-04, -3.4745e-04, -1.6044e-04, -3.2354e-04,\n              4.1849e-04, -1.7460e-04,  9.9619e-05]),\n     'exp_avg_sq': tensor([2.4414e-07, 1.2788e-07, 3.0910e-07, 3.1042e-07, 2.7902e-07, 3.9569e-07,\n             4.4173e-07, 2.8466e-07, 3.7210e-07, 7.4862e-07, 4.4678e-07, 5.3390e-07,\n             3.5122e-07, 3.4628e-07, 4.3645e-07, 3.0321e-07, 5.1778e-07, 5.8244e-07,\n             3.2796e-07, 2.8192e-07, 8.0265e-07, 7.0443e-07, 3.6859e-07, 4.5292e-07,\n             2.1737e-07, 7.1659e-07, 3.9022e-07, 2.3103e-07, 4.3188e-07, 4.2975e-07,\n             4.3830e-07, 5.4413e-07, 2.6776e-07, 4.2654e-07, 3.4766e-07, 3.0846e-07,\n             6.1170e-07, 3.5333e-07, 5.0011e-07, 9.9673e-07, 4.0113e-07, 3.3852e-07,\n             3.3502e-07, 6.3194e-07, 1.0656e-06, 2.6781e-07, 4.5129e-07, 1.2799e-06,\n             3.5381e-07, 3.9656e-07, 5.1606e-07, 3.6709e-07, 3.6236e-07, 3.6450e-07,\n             4.2067e-07, 3.3950e-07, 7.2151e-07, 2.8274e-07, 4.2916e-07, 4.8611e-07,\n             5.4406e-07, 4.0074e-07, 2.4607e-07, 4.2254e-07, 4.0194e-07, 3.3126e-07,\n             3.8623e-07, 4.4490e-07, 2.4596e-07, 4.5506e-07, 3.1881e-07, 8.9956e-07,\n             4.0680e-07, 3.9186e-07, 3.1260e-07, 3.2310e-07, 2.6591e-07, 2.0032e-07,\n             5.4624e-07, 2.9011e-07, 2.5082e-07, 3.7298e-07, 3.2784e-07, 3.1941e-07,\n             4.6933e-07, 3.3863e-07, 2.8721e-07, 1.0761e-06, 3.2206e-07, 4.1710e-07,\n             4.4113e-07, 6.3483e-07, 7.5597e-07, 3.7638e-07, 3.6486e-07, 4.8731e-07,\n             2.8363e-07, 2.8316e-07, 3.5164e-07, 3.5369e-07, 6.1524e-07, 8.6605e-07,\n             4.9271e-07, 4.5251e-07, 4.2844e-07, 5.1213e-07, 1.1469e-06, 4.2690e-07,\n             2.7780e-07, 4.3256e-07, 5.6605e-07, 6.7090e-07, 4.2927e-07, 4.8006e-07,\n             5.0215e-07, 3.3323e-07, 7.8663e-07, 2.8069e-07, 8.6104e-07, 3.2938e-07,\n             5.4688e-07, 5.5046e-07, 1.0553e-06, 4.6709e-07, 4.0877e-07, 3.0116e-07,\n             1.1301e-06, 7.9883e-07])},\n    23: {'exp_avg': tensor([-2.8707e-04,  4.1298e-05,  3.6963e-05, -1.5843e-04, -1.2353e-04,\n              1.6532e-04,  3.0477e-04,  6.9793e-05,  1.4077e-04, -8.7666e-05,\n              2.2076e-04,  1.7629e-04,  6.9730e-05,  2.5229e-04,  1.4759e-04,\n             -5.1388e-05,  3.2863e-04, -1.5114e-04,  7.1360e-04, -7.0015e-05,\n             -2.9582e-04,  7.9794e-04,  7.1328e-05, -4.3257e-04, -3.9184e-05,\n             -1.3104e-04,  4.2509e-04, -3.3834e-04, -7.0560e-04, -2.2525e-06,\n              5.5259e-05, -1.4565e-04,  7.3829e-05,  9.4283e-05,  2.0198e-05,\n              8.3146e-05, -2.1461e-04,  2.9984e-04,  2.6899e-04,  1.4509e-04,\n             -2.0575e-05, -2.3308e-04,  3.8416e-04,  5.2755e-04, -2.7929e-04,\n             -3.1107e-04,  3.5920e-04, -6.0574e-04, -1.6647e-04, -7.4719e-05,\n             -1.4926e-04, -1.4386e-04, -3.7788e-04, -4.5829e-05, -3.3968e-04,\n              1.8495e-04, -3.0525e-05, -9.4474e-05, -4.1511e-04, -4.6045e-05,\n             -3.0158e-04, -4.5157e-04,  3.3430e-04,  4.2104e-05,  3.6424e-05,\n             -1.3972e-04, -1.4114e-04, -4.3114e-04, -1.3560e-04, -2.7261e-05,\n             -2.3992e-04,  3.5005e-04,  1.4816e-04,  2.9367e-05, -1.8393e-05,\n              1.0906e-04,  3.3046e-04,  2.4787e-04,  1.4959e-05,  1.8041e-04,\n             -1.0491e-04,  5.8128e-04,  3.1085e-04,  8.1232e-05, -9.9772e-05,\n             -2.8935e-04, -3.4288e-04,  3.4518e-04,  5.9421e-05,  7.7454e-04,\n              8.9650e-05,  6.9870e-04, -9.8411e-05, -4.3205e-04,  2.4603e-04,\n              8.5320e-04,  3.4059e-05, -1.4831e-04, -9.6523e-05,  1.0895e-04,\n              2.0740e-04, -7.0354e-04, -3.9718e-04,  5.7547e-04, -3.1781e-04,\n              2.0825e-04, -6.5229e-06,  2.9608e-04,  4.7590e-04, -8.0825e-04,\n             -7.1287e-04, -2.6165e-04, -1.4445e-04, -2.5755e-04,  1.0052e-04,\n             -3.3654e-04,  1.7765e-04, -1.8452e-04,  1.1853e-05, -2.3937e-04,\n              1.4776e-04, -2.2114e-04, -2.7290e-04, -1.0680e-04, -1.2302e-04,\n              2.1179e-04, -2.4639e-04,  2.0449e-04]),\n     'exp_avg_sq': tensor([9.9592e-08, 1.4741e-07, 2.1187e-07, 2.6468e-07, 1.1246e-07, 2.6237e-07,\n             3.0605e-07, 1.4802e-07, 3.4878e-07, 3.0037e-07, 3.0141e-07, 4.2206e-07,\n             2.7316e-07, 3.1799e-07, 1.2821e-07, 9.0924e-08, 1.8827e-07, 3.3218e-07,\n             2.1714e-07, 1.3825e-07, 3.3574e-07, 3.8581e-07, 2.2221e-07, 5.2683e-07,\n             1.1006e-07, 3.7924e-07, 1.6725e-07, 2.3192e-07, 2.9691e-07, 3.2274e-07,\n             2.7413e-07, 3.5877e-07, 1.4688e-07, 3.0192e-07, 2.5598e-07, 1.8094e-07,\n             2.2875e-07, 2.2196e-07, 3.0993e-07, 7.7426e-08, 1.9064e-07, 3.3234e-07,\n             1.7488e-07, 1.8934e-07, 2.9919e-07, 1.8651e-07, 2.6698e-07, 4.4944e-07,\n             2.7414e-07, 3.4205e-07, 1.6024e-07, 3.5737e-07, 2.2333e-07, 1.5774e-07,\n             2.6730e-07, 2.2273e-07, 3.5844e-07, 1.8905e-07, 2.4611e-07, 2.2403e-07,\n             2.6612e-07, 1.8615e-07, 1.9810e-07, 4.6438e-07, 2.0548e-07, 2.4829e-07,\n             2.0997e-07, 2.2569e-07, 1.1653e-07, 3.5015e-07, 2.5011e-07, 5.4346e-07,\n             2.2031e-07, 1.5828e-07, 1.5028e-07, 1.7722e-07, 1.2516e-07, 1.5220e-07,\n             1.9499e-07, 2.0383e-07, 1.2685e-07, 2.8261e-07, 1.9825e-07, 1.3214e-07,\n             1.5857e-07, 3.3897e-07, 1.9215e-07, 4.0034e-07, 1.9246e-07, 3.5080e-07,\n             2.7133e-07, 4.0922e-07, 2.8671e-07, 2.1619e-07, 2.8289e-07, 3.4517e-07,\n             1.5933e-07, 1.6383e-07, 1.5342e-07, 1.6917e-07, 3.3144e-07, 6.3944e-07,\n             2.8377e-07, 2.8136e-07, 1.9587e-07, 1.5877e-07, 2.6889e-07, 2.6892e-07,\n             1.5882e-07, 2.8105e-07, 3.7674e-07, 4.7932e-07, 2.5752e-07, 2.7795e-07,\n             3.1875e-07, 1.8556e-07, 2.6662e-07, 1.4360e-07, 3.8860e-07, 1.1373e-07,\n             2.9583e-07, 3.4175e-07, 2.6870e-07, 1.6368e-07, 2.4976e-07, 1.3244e-07,\n             4.3963e-07, 5.1297e-07])},\n    24: {'exp_avg': tensor([-1.0206e-04, -2.0356e-04,  4.6699e-04,  4.4935e-05,  8.4483e-05,\n              2.2941e-04, -1.7549e-04,  1.9401e-03,  2.4135e-04, -6.4377e-04,\n              6.8434e-04,  2.2739e-04,  4.8575e-04,  5.3647e-05, -2.1100e-04,\n             -1.0604e-04, -1.6318e-04,  6.0462e-04, -2.4711e-05,  2.3462e-05,\n             -8.2059e-04, -4.1758e-04,  9.3804e-05,  7.0540e-05,  3.2910e-04,\n              2.5530e-04,  6.5165e-05,  3.4482e-04,  1.7050e-04,  1.9709e-04,\n              6.5172e-05,  1.0994e-04,  1.7159e-04, -7.1935e-04,  5.7532e-05,\n             -1.4097e-04, -3.5417e-06, -3.6541e-05,  5.8420e-04,  5.7213e-04,\n             -2.2075e-04,  5.2429e-04, -6.6923e-04,  6.2839e-04, -5.2396e-04,\n             -4.9229e-04,  1.2300e-04, -1.3346e-03,  2.2201e-04,  1.6024e-04,\n             -2.7946e-05, -1.9694e-04,  9.6496e-04, -5.1346e-04, -2.2140e-04,\n              1.9327e-05,  1.6765e-04,  2.2010e-04,  2.2491e-05,  7.6798e-04,\n              5.9869e-04,  2.0168e-04, -5.0063e-06, -2.7533e-05,  2.7258e-04,\n             -6.8805e-04,  1.3483e-04, -2.8155e-04,  2.9622e-04,  1.8083e-04,\n             -5.0272e-04, -3.1537e-04,  1.4986e-06, -5.0409e-04,  2.1468e-04,\n             -5.2475e-05, -1.4137e-04,  1.6118e-04,  9.9386e-05, -9.9578e-04,\n             -1.6422e-04, -1.5451e-03,  1.5540e-04, -3.4208e-04, -7.6035e-04,\n             -2.9792e-04,  2.0858e-04,  3.9232e-04, -4.8113e-04,  3.3833e-04,\n             -2.2709e-04, -2.4885e-04, -6.8158e-05, -8.5284e-08, -7.1645e-05,\n              2.8396e-04,  2.8507e-04, -1.9077e-04, -3.7492e-05, -3.1549e-04,\n             -1.3761e-04,  9.3014e-05, -2.7831e-04,  6.3503e-04,  9.0318e-05,\n              4.6861e-04, -5.7083e-04, -1.6323e-04,  7.5568e-04,  7.4083e-05,\n              4.6025e-05,  2.6704e-04,  3.8720e-04,  8.7027e-04, -6.8005e-04,\n             -6.6026e-04,  2.5887e-04,  5.9508e-04,  5.9846e-05,  1.7529e-04,\n              1.3147e-04,  7.4141e-05, -1.0833e-03, -3.3995e-04, -6.4412e-05,\n              1.6396e-05, -4.0136e-04,  1.3125e-04]),\n     'exp_avg_sq': tensor([2.1176e-07, 1.0616e-06, 1.1449e-06, 1.2982e-07, 1.5157e-07, 7.8639e-07,\n             1.8256e-07, 1.4860e-06, 1.8574e-07, 1.1295e-06, 9.0461e-07, 1.7581e-07,\n             2.1703e-06, 1.4989e-07, 8.8918e-08, 6.8317e-07, 8.0744e-08, 1.0482e-06,\n             6.1938e-07, 5.7598e-07, 4.7447e-07, 3.3282e-07, 2.9464e-07, 1.0669e-07,\n             2.2531e-07, 1.2837e-07, 1.4869e-07, 1.7333e-07, 1.6857e-07, 1.5720e-07,\n             9.2793e-08, 5.8294e-07, 4.2785e-07, 1.3429e-06, 1.3036e-07, 1.1823e-07,\n             1.1698e-07, 8.6921e-08, 4.5621e-07, 1.0308e-06, 8.0161e-07, 1.6565e-06,\n             1.2167e-06, 5.6103e-07, 9.8829e-07, 4.4144e-07, 1.3247e-07, 9.5311e-07,\n             4.9201e-07, 4.9862e-07, 1.8818e-07, 8.7981e-08, 9.6639e-07, 7.6312e-07,\n             2.9481e-07, 1.5642e-07, 1.1698e-07, 9.1381e-07, 1.2099e-07, 1.0232e-06,\n             9.1027e-07, 3.2195e-07, 1.0901e-07, 1.2074e-07, 1.2251e-07, 2.0596e-07,\n             1.8281e-07, 1.4257e-06, 1.6109e-07, 1.2521e-07, 9.3301e-07, 1.1249e-06,\n             1.6889e-07, 1.8345e-06, 7.3454e-07, 5.6629e-07, 6.1913e-07, 7.3040e-07,\n             1.6720e-07, 1.2751e-06, 2.3135e-07, 9.2585e-07, 1.6159e-07, 2.1892e-06,\n             8.7267e-07, 3.7578e-07, 1.7924e-07, 1.6810e-07, 1.5425e-07, 9.3078e-07,\n             1.8413e-07, 2.2654e-07, 1.1900e-07, 2.5370e-07, 1.3774e-07, 2.8200e-07,\n             2.3889e-07, 1.4666e-07, 2.0614e-07, 2.2486e-07, 2.0361e-07, 1.7031e-07,\n             2.0781e-07, 7.0547e-07, 5.8015e-07, 8.1872e-07, 1.8762e-07, 5.4835e-07,\n             7.8341e-07, 7.8711e-08, 8.8686e-07, 9.6198e-08, 2.0886e-07, 1.1173e-06,\n             6.4275e-07, 7.5759e-07, 1.0657e-06, 9.4684e-07, 1.0425e-07, 2.8850e-07,\n             3.1155e-07, 2.0353e-07, 1.2728e-06, 6.7098e-07, 3.6612e-07, 1.0613e-07,\n             1.1819e-06, 5.5070e-07])},\n    25: {'exp_avg': tensor([ 2.2086e-05, -2.5294e-05, -1.1563e-05, -1.4600e-04,  1.3619e-04,\n              9.5617e-06,  3.6280e-05,  3.8297e-06,  1.3481e-04,  1.7247e-05,\n              1.7749e-05,  3.6155e-05,  1.4446e-04, -1.2903e-04, -2.0964e-05,\n             -3.8063e-05, -1.1593e-04,  9.6966e-06,  1.8842e-05, -7.1923e-05,\n              2.6948e-04, -2.6353e-04,  4.7662e-05, -8.5079e-05,  1.5145e-04,\n              2.5902e-04,  2.3050e-04, -3.9834e-06, -8.9913e-05, -1.6051e-05,\n              1.1459e-04, -3.7219e-05,  1.8453e-04, -2.2200e-06, -2.9952e-05,\n             -1.6517e-04, -1.0908e-05,  1.9722e-05, -9.2954e-05,  7.1406e-05,\n             -1.8320e-05, -3.3012e-05, -8.9350e-06,  3.7041e-05, -2.6231e-05,\n             -5.5777e-05,  3.3182e-04,  2.7628e-06, -6.2308e-05,  1.4174e-04,\n             -4.5993e-05, -3.3349e-04,  1.5179e-04, -1.2495e-05, -1.7634e-04,\n              9.5397e-05,  2.6709e-04, -2.0964e-05,  6.1455e-05, -2.4011e-05,\n              8.3136e-07,  1.0405e-04, -1.3197e-04, -2.6897e-04, -8.0767e-05,\n             -2.7627e-04,  1.9056e-04,  1.0682e-04, -1.3297e-04, -4.4305e-07,\n             -2.6653e-06,  1.1995e-04,  3.7301e-05, -5.6981e-06,  2.6941e-05,\n              4.7311e-06,  1.1461e-04, -1.6932e-05, -1.0509e-04, -1.6489e-05,\n             -1.4716e-04, -6.9948e-05, -5.8845e-05, -3.7775e-05, -3.6252e-04,\n             -7.0310e-05, -6.3162e-05,  8.8573e-05, -3.9059e-04,  2.9775e-06,\n             -3.3485e-04, -3.1407e-04,  5.1191e-05,  1.0256e-04, -2.6571e-05,\n              3.5844e-06, -1.2087e-04, -2.9517e-05, -5.7324e-05, -1.6673e-04,\n             -3.7791e-04, -1.3723e-04, -1.7538e-04, -1.1471e-05, -1.9461e-04,\n              1.3219e-05, -1.7612e-04, -1.8562e-05, -7.2763e-05,  6.3292e-06,\n             -5.0952e-06,  1.1679e-04,  2.4996e-04,  2.7122e-04, -4.5230e-05,\n              3.1064e-04,  6.4038e-05, -1.4998e-04,  8.4900e-05, -3.5222e-05,\n              7.5401e-05,  7.9452e-05,  3.4683e-05,  1.8279e-05,  2.5562e-05,\n              4.9023e-05, -2.4178e-05,  1.1789e-05]),\n     'exp_avg_sq': tensor([7.5141e-08, 2.0028e-09, 7.3786e-10, 4.9472e-08, 7.3376e-08, 1.3374e-09,\n             6.7062e-08, 1.0328e-09, 9.0020e-08, 2.2696e-09, 1.6424e-09, 5.8684e-08,\n             1.6245e-08, 1.9663e-07, 4.3371e-08, 8.2884e-09, 4.4756e-08, 7.9117e-10,\n             1.3956e-09, 5.6232e-08, 8.4972e-08, 1.2395e-07, 1.2363e-07, 5.4982e-08,\n             1.1629e-07, 6.3988e-08, 5.6969e-08, 6.3991e-08, 6.2077e-08, 5.1767e-08,\n             5.8608e-08, 4.0708e-08, 3.0080e-08, 3.4934e-09, 4.9401e-08, 6.4345e-08,\n             5.1733e-08, 3.7552e-08, 1.2100e-07, 7.8069e-09, 1.8541e-09, 1.3036e-09,\n             2.4774e-10, 1.6395e-09, 8.0382e-10, 5.1813e-09, 7.2801e-08, 1.3765e-09,\n             3.1018e-08, 1.3806e-07, 6.5476e-08, 5.6740e-08, 4.2013e-08, 1.1004e-09,\n             1.1702e-07, 4.8228e-08, 4.7433e-08, 1.4156e-09, 5.7138e-08, 1.9745e-09,\n             3.2169e-10, 2.0840e-08, 5.4796e-08, 5.4430e-08, 1.0138e-07, 7.6240e-08,\n             7.4179e-08, 2.4709e-08, 1.3741e-07, 6.6568e-08, 7.2007e-10, 5.7382e-08,\n             5.8199e-08, 3.9285e-10, 4.2717e-09, 5.3246e-09, 2.5891e-08, 1.3645e-09,\n             7.4669e-08, 1.0115e-08, 8.2578e-08, 2.0822e-09, 5.5845e-08, 1.1509e-09,\n             9.8871e-08, 1.0846e-07, 7.1821e-08, 7.2484e-08, 9.3601e-08, 1.7116e-09,\n             8.2343e-08, 7.2178e-08, 5.7864e-08, 1.8970e-07, 7.0232e-08, 1.2310e-07,\n             9.0495e-08, 6.2101e-08, 7.2337e-08, 8.1150e-08, 1.8656e-07, 9.3743e-08,\n             6.8146e-08, 5.8187e-10, 3.0220e-08, 1.1784e-09, 5.8338e-08, 3.0152e-09,\n             1.9174e-08, 4.3083e-08, 5.4663e-09, 3.9551e-08, 9.0281e-08, 5.6444e-08,\n             1.3857e-07, 6.0326e-08, 1.2938e-08, 1.2353e-08, 9.7475e-08, 8.2948e-08,\n             1.0443e-07, 6.9970e-08, 1.8137e-09, 8.1393e-10, 6.3390e-08, 5.0270e-08,\n             8.5243e-10, 1.6327e-09])},\n    26: {'exp_avg': tensor([ 1.4514e-05,  6.6667e-04,  2.2947e-04, -1.4474e-04,  2.0598e-05,\n             -5.1316e-05, -1.0519e-04, -1.1280e-04,  5.5286e-05,  5.8135e-05,\n             -1.9817e-04,  4.0011e-05, -7.4748e-05, -3.9004e-05, -2.7119e-04,\n             -2.2608e-04, -9.6190e-05,  2.3909e-04, -2.1854e-05, -8.5290e-05,\n              5.6503e-05, -1.0195e-04, -9.7541e-05,  5.1893e-05,  2.9642e-05,\n             -1.5953e-04,  6.9263e-05, -9.7624e-05, -4.1506e-05, -3.9626e-04,\n              2.8509e-04,  1.0279e-04,  7.6240e-05,  1.5125e-04, -1.3923e-04,\n             -2.6738e-04,  5.4655e-05, -3.7934e-05,  8.1902e-05, -3.1815e-05,\n             -1.0648e-05, -5.2158e-05, -1.3700e-04, -4.5194e-05, -2.2795e-05,\n              5.5846e-05,  3.1475e-04,  7.5084e-05, -1.9721e-04,  6.4220e-06,\n              1.7162e-04,  2.6765e-04, -2.4152e-05, -1.8900e-06, -4.2346e-05,\n              2.3002e-05, -4.2734e-05, -2.2318e-04, -3.5905e-05,  9.0445e-06,\n             -1.0282e-04,  7.1512e-05,  1.4686e-04,  5.4327e-05,  1.0668e-04,\n              8.4036e-05,  1.2141e-04, -7.5214e-05,  9.8641e-05,  1.0713e-05,\n              1.6919e-04, -1.9202e-04, -1.1128e-04, -1.0226e-04, -6.1528e-05,\n             -1.2987e-04,  2.1226e-04,  4.2880e-05,  1.0850e-05, -1.5176e-04,\n             -1.7212e-05, -3.1696e-05, -1.1879e-04,  1.1400e-04, -1.5642e-04,\n              3.5863e-05, -2.7967e-04, -1.3871e-04,  2.2671e-04,  1.6830e-04,\n             -8.5010e-07,  1.2577e-05, -2.8436e-04,  9.3159e-06, -7.0353e-05,\n              6.5691e-05,  1.3257e-04,  1.2643e-05,  8.1693e-05, -1.3313e-04,\n              1.0416e-05,  1.0668e-04, -5.1663e-05,  8.9126e-05, -5.9325e-06,\n              1.4987e-04, -3.4596e-04,  7.6971e-05, -1.0874e-04,  5.1127e-05,\n              3.3005e-05,  1.4459e-04,  4.2411e-05, -7.8242e-05,  4.4879e-05,\n              6.4417e-04, -5.7592e-06, -8.8785e-05,  1.3045e-05,  1.0006e-04,\n             -2.0581e-05,  2.2199e-05, -4.8837e-05, -5.8977e-05, -9.9461e-06,\n              2.1505e-04,  2.2153e-05, -6.4920e-05, -1.9785e-04,  8.6934e-05,\n              1.7281e-04, -2.5443e-04, -1.7743e-04, -4.4617e-04, -9.6495e-05,\n             -5.1852e-05,  1.3948e-05,  2.8089e-04, -1.4618e-04, -1.2085e-04,\n              2.4678e-05,  9.1854e-05,  1.5804e-04, -3.1851e-04,  4.7941e-05,\n             -1.9239e-05,  1.3030e-04, -5.1721e-04, -2.6744e-04,  9.3388e-07,\n             -7.9788e-05, -2.9389e-05,  1.8940e-04, -1.7987e-04, -8.5692e-05,\n             -4.5359e-04,  1.1634e-04,  8.5248e-05, -1.2601e-04, -9.3482e-05,\n              3.9858e-05,  1.6121e-04, -1.1279e-04,  3.8902e-04, -4.7910e-05,\n              9.4444e-05,  2.4199e-04,  1.4782e-04, -9.3090e-05,  1.1037e-04,\n              1.6944e-04,  1.3194e-04, -2.0194e-04, -8.8794e-05,  7.9502e-05,\n              3.9740e-05, -5.9807e-07,  2.0923e-04, -1.1942e-04, -1.8246e-06,\n              1.0918e-04, -1.6066e-05, -5.4133e-05, -4.7916e-06,  1.8735e-04,\n              5.1555e-05, -2.2069e-05, -1.5452e-05,  1.6783e-04, -4.9737e-05,\n              2.9125e-05,  6.2531e-05, -9.2508e-06, -9.1950e-05, -2.2285e-05,\n              1.4814e-04,  4.1344e-05, -1.4730e-04,  5.6282e-05, -1.0180e-04,\n              3.4742e-04,  1.5380e-05, -2.0552e-05, -4.7283e-04,  8.6370e-05,\n              1.3145e-04, -8.2245e-05, -1.4933e-04, -2.2472e-04, -5.8584e-06,\n              1.1989e-04,  4.3528e-05,  5.5595e-05,  7.5227e-05,  7.8833e-06,\n             -5.9457e-06, -2.3734e-04, -1.1337e-04, -9.7611e-05,  8.5196e-05,\n             -3.5413e-05,  5.4562e-05, -7.2009e-05,  3.5482e-04, -1.4350e-04,\n              6.4538e-05, -4.7139e-05,  1.3032e-04, -3.1724e-04,  1.6109e-04,\n              8.8966e-06, -1.0460e-04, -1.6650e-04, -6.7319e-05,  2.0277e-04,\n              7.9961e-05,  1.2516e-04,  7.5938e-05,  1.9459e-04, -2.9750e-05,\n              1.2846e-04,  2.4098e-04, -1.8455e-05, -1.1423e-04, -3.0320e-05,\n             -1.4618e-04, -5.8610e-05, -8.2606e-05, -3.5247e-05,  1.3268e-04,\n             -1.5269e-04,  9.5764e-05, -1.5001e-04,  1.1978e-04, -3.0164e-05,\n             -3.2407e-05, -1.3065e-04, -4.8785e-05,  1.2723e-04, -1.7725e-04,\n             -1.0888e-04, -1.5533e-04,  8.4208e-05,  5.9163e-05, -4.2444e-05,\n             -5.7544e-05,  9.5130e-05,  5.3208e-05, -2.4366e-05,  7.3362e-05,\n              1.3030e-04, -7.1360e-05, -6.8412e-05, -9.0407e-05,  3.5011e-04,\n             -3.4206e-04,  2.8296e-05, -2.3142e-05, -6.6988e-06, -2.0628e-04,\n             -7.9346e-05, -1.1367e-04,  1.9923e-05, -1.2665e-04,  1.7144e-04,\n              6.0430e-05, -4.9545e-05, -4.0583e-05,  5.4885e-06, -1.0044e-05,\n              7.0846e-05,  4.8497e-05,  1.0242e-04,  4.7170e-05,  2.5089e-04,\n             -7.0053e-05, -2.4251e-04, -7.2751e-05,  1.5595e-04,  8.0286e-05,\n             -5.6837e-05, -2.2904e-05, -1.1948e-04, -2.0642e-04, -3.2669e-06,\n             -2.7591e-06,  1.3293e-04,  2.4142e-05,  9.7258e-05,  2.8601e-04,\n              1.1752e-04,  1.0532e-03, -5.5728e-05, -3.3857e-05, -1.4608e-04,\n             -4.8125e-05, -8.2861e-05, -4.1015e-05, -1.4157e-05,  1.2605e-04,\n              8.9876e-06,  4.5364e-05,  6.9115e-05,  1.9179e-04, -2.5534e-04,\n             -1.8435e-04, -1.9907e-04, -4.3775e-05, -2.9603e-05,  3.6943e-05,\n              1.3022e-05,  1.1967e-05,  1.5464e-04,  3.1700e-05, -5.9201e-05,\n             -1.0167e-04, -1.5428e-04, -1.3214e-04,  1.3204e-04, -1.0622e-04,\n             -1.4021e-04,  2.2054e-04, -8.4261e-05, -3.1165e-05,  1.2275e-04,\n              1.6975e-04,  1.8575e-04,  5.6828e-05,  6.5991e-07,  6.0193e-05,\n             -3.2788e-05,  7.3160e-06, -1.1080e-04,  1.1352e-04,  9.0703e-06,\n             -8.6420e-05,  3.4373e-06,  1.9974e-04,  3.4014e-04, -6.7479e-05,\n             -2.3118e-04,  1.9641e-05, -1.6129e-05,  4.0078e-05, -3.2041e-05,\n             -4.0418e-05, -1.6613e-04,  8.2653e-05,  3.3326e-05, -3.1444e-04,\n              1.7104e-04,  1.7499e-04, -2.3613e-05, -6.1476e-05, -8.6302e-05,\n              1.0721e-04, -1.0040e-04,  7.3033e-05,  2.0191e-04, -2.9414e-06,\n              6.8273e-05, -1.2799e-05, -1.1871e-04,  1.3038e-04,  1.5784e-04,\n              2.0329e-05,  1.0274e-04, -6.2218e-05, -6.7928e-06, -1.0827e-04,\n             -2.7940e-04, -2.2172e-05,  8.8791e-05,  3.9211e-05,  3.2827e-04,\n              1.7629e-05,  1.1267e-04,  1.0143e-04, -4.5196e-05, -2.7877e-05,\n              5.7150e-05, -3.5720e-05,  3.4816e-05, -1.2403e-04, -9.6688e-05,\n              1.3260e-04,  4.6472e-04, -9.4194e-05, -3.5785e-05,  1.3643e-04,\n             -2.0949e-04, -1.4561e-04, -3.4640e-05,  7.1483e-05,  2.9848e-05,\n              4.4974e-05, -6.7445e-07, -2.3429e-04,  1.0679e-04,  8.2455e-05,\n              7.3079e-05, -2.1459e-04,  9.9756e-05,  4.8619e-05, -2.6293e-04,\n             -1.3026e-04,  5.1290e-05, -6.2278e-05,  7.6962e-05, -1.3186e-04,\n             -8.3926e-05, -5.4530e-05, -1.3873e-04,  1.3083e-04,  1.0970e-04,\n             -7.4895e-05,  2.4136e-04,  1.8743e-05, -8.6682e-05, -1.9558e-04,\n             -6.6715e-05,  6.2785e-05, -2.1911e-05,  1.2726e-04,  5.9070e-05,\n              1.3039e-04, -3.4866e-05, -4.5861e-05, -4.8785e-05,  7.8074e-05,\n              2.3127e-04, -1.7293e-04, -1.3943e-04, -1.7720e-04, -1.9582e-04,\n              8.7038e-05,  1.4999e-04,  1.6080e-04,  3.1006e-05,  1.8685e-04,\n              1.0535e-04,  1.7314e-04,  2.1703e-04,  1.5607e-04,  2.1438e-04,\n             -2.5288e-05, -3.1300e-05, -2.6801e-05,  8.1250e-05, -1.6184e-04,\n             -9.9011e-05, -1.1747e-04, -9.1947e-05,  1.1042e-04,  8.9953e-05,\n             -9.5244e-05, -6.1892e-06, -1.1057e-04, -4.7332e-05, -1.8597e-04,\n             -3.5727e-05, -1.9764e-04,  9.1182e-05, -8.1009e-05,  1.2050e-04,\n             -1.1398e-04,  1.9555e-04,  1.1135e-04,  1.3388e-04,  1.8313e-04,\n             -3.6096e-05,  5.8552e-05,  1.4135e-04, -2.0345e-04, -2.2237e-04,\n             -1.6233e-04,  1.6606e-04, -6.3695e-05, -3.9004e-05,  2.2143e-04,\n              5.6839e-06,  2.3713e-04,  8.5593e-05,  5.9476e-05, -2.5925e-04,\n             -2.9650e-05, -1.2476e-05,  2.0542e-04, -5.0925e-06,  1.4214e-04,\n              1.7462e-04,  1.6789e-04]),\n     'exp_avg_sq': tensor([2.1311e-08, 2.5449e-07, 1.2124e-07, 8.6383e-08, 3.1014e-08, 5.0199e-08,\n             3.0511e-08, 2.1028e-08, 3.2820e-08, 1.5755e-08, 9.8340e-08, 2.4701e-08,\n             4.8791e-08, 4.6553e-08, 4.2518e-08, 5.8222e-08, 3.7428e-08, 5.3144e-08,\n             4.3668e-08, 1.9033e-08, 1.1021e-07, 3.7925e-08, 3.6761e-08, 3.7629e-08,\n             5.3626e-08, 5.8951e-08, 5.8803e-08, 8.1224e-08, 3.5500e-08, 1.1106e-07,\n             6.7283e-08, 6.3600e-08, 1.5098e-07, 1.2483e-07, 8.8426e-08, 6.7017e-08,\n             3.0604e-08, 6.5876e-08, 7.7583e-08, 5.1994e-08, 1.0680e-07, 3.3415e-08,\n             3.4350e-08, 3.5789e-08, 2.0922e-07, 2.8950e-08, 3.9799e-08, 3.9060e-08,\n             7.8528e-08, 2.6939e-08, 4.8493e-08, 6.3169e-08, 6.3347e-08, 4.4680e-08,\n             5.0355e-08, 6.6994e-08, 8.4200e-08, 7.5475e-08, 2.2343e-08, 2.5549e-08,\n             4.8454e-08, 3.3642e-08, 9.1358e-08, 5.7932e-08, 4.4412e-08, 4.0343e-08,\n             3.8095e-08, 4.1870e-08, 7.7675e-08, 3.9806e-08, 7.2602e-08, 4.1238e-08,\n             3.5598e-08, 4.5279e-08, 9.7825e-08, 8.4165e-08, 3.7775e-08, 8.1039e-08,\n             4.3046e-08, 3.1240e-08, 2.6973e-08, 3.5142e-08, 8.7028e-08, 3.4866e-08,\n             4.3124e-08, 3.1714e-08, 7.7360e-08, 2.7015e-08, 4.2699e-08, 7.5757e-08,\n             3.4555e-08, 7.7760e-08, 6.9986e-08, 8.7892e-08, 3.7988e-08, 5.5281e-08,\n             6.8386e-08, 3.4394e-08, 2.9944e-08, 6.8248e-08, 1.7441e-08, 2.6053e-08,\n             3.1113e-08, 3.0852e-08, 3.3791e-08, 2.5504e-08, 4.8906e-08, 3.5181e-08,\n             2.5801e-08, 5.5523e-08, 2.9929e-08, 3.9909e-08, 3.9541e-08, 7.7758e-08,\n             3.0514e-08, 3.5367e-07, 8.2733e-08, 3.8137e-08, 1.8089e-08, 4.6144e-08,\n             3.3869e-08, 2.2998e-08, 6.3872e-08, 7.3332e-08, 3.3545e-08, 4.1090e-08,\n             2.6446e-08, 5.1942e-08, 7.9212e-08, 2.2217e-08, 6.8348e-08, 5.8207e-08,\n             5.3101e-08, 2.8385e-07, 4.1467e-08, 3.6626e-08, 3.5654e-08, 2.9057e-07,\n             2.9437e-08, 4.7255e-08, 3.5403e-08, 3.1031e-08, 4.3217e-08, 7.5054e-08,\n             2.7968e-08, 3.5743e-08, 1.1518e-07, 1.8352e-07, 2.9060e-07, 4.4334e-08,\n             1.2278e-07, 6.0034e-08, 2.5491e-08, 2.4960e-08, 8.6969e-08, 8.2847e-08,\n             7.8651e-08, 9.5414e-08, 3.0582e-08, 6.3848e-08, 3.1166e-08, 6.0213e-08,\n             4.0318e-08, 1.9984e-07, 3.4456e-08, 4.0125e-08, 3.8340e-08, 3.1848e-08,\n             6.2223e-08, 4.4625e-08, 3.3050e-08, 3.2982e-08, 3.6151e-08, 1.1067e-07,\n             3.5121e-08, 2.8189e-08, 8.6086e-08, 2.7728e-08, 2.7532e-08, 6.3382e-08,\n             4.0523e-08, 3.2074e-08, 4.2281e-08, 5.1113e-08, 7.1749e-08, 5.2898e-08,\n             3.4511e-08, 3.4874e-08, 1.2741e-07, 2.0766e-08, 5.7044e-08, 9.5381e-08,\n             4.9513e-08, 2.5093e-08, 3.8969e-08, 2.3480e-08, 3.6001e-08, 4.6125e-08,\n             5.7330e-08, 6.6516e-08, 9.1653e-08, 2.3447e-08, 3.1695e-08, 1.5989e-07,\n             5.2863e-08, 9.2119e-08, 3.5030e-08, 9.8040e-08, 3.9605e-08, 4.0870e-08,\n             4.3996e-08, 9.1273e-08, 3.0931e-08, 2.7037e-08, 3.7011e-08, 7.2983e-08,\n             3.9309e-08, 2.1027e-08, 4.7741e-08, 9.8754e-08, 3.6071e-08, 2.1608e-08,\n             3.9214e-08, 1.8660e-07, 5.8667e-08, 4.1725e-08, 7.3024e-08, 3.2368e-08,\n             6.0587e-08, 5.2016e-08, 4.9343e-08, 7.0603e-08, 2.6806e-08, 7.4162e-08,\n             1.0767e-07, 4.6180e-08, 3.0479e-08, 2.3707e-08, 8.1404e-08, 2.4266e-08,\n             3.7790e-08, 6.0250e-08, 8.5931e-08, 3.4600e-08, 3.8596e-08, 9.5410e-08,\n             3.9835e-08, 3.4791e-08, 1.0001e-07, 1.3096e-07, 2.6227e-08, 1.3314e-07,\n             9.8228e-08, 3.8168e-08, 3.6872e-08, 3.3791e-08, 3.9777e-08, 9.7862e-08,\n             5.1983e-08, 1.4433e-07, 7.7843e-08, 1.2412e-07, 7.5350e-08, 2.5588e-08,\n             7.5238e-08, 3.3062e-08, 1.6537e-07, 4.7477e-08, 5.1027e-08, 5.2788e-08,\n             1.1743e-07, 4.4396e-08, 2.3605e-08, 2.2844e-08, 1.8379e-07, 1.4342e-07,\n             3.4588e-08, 3.4969e-08, 7.0567e-08, 3.0417e-08, 3.2473e-08, 7.3169e-08,\n             5.8518e-08, 1.8251e-07, 8.7877e-08, 3.2956e-08, 3.5288e-08, 1.6397e-07,\n             1.0849e-07, 3.9489e-08, 7.5297e-08, 2.0725e-07, 1.1714e-07, 2.2629e-08,\n             6.2897e-08, 7.5720e-08, 2.0792e-07, 2.0109e-08, 1.2773e-07, 4.4346e-08,\n             2.4471e-08, 6.8886e-08, 5.2014e-08, 4.2481e-08, 2.6018e-08, 2.8982e-08,\n             4.0475e-08, 4.0969e-08, 2.5693e-08, 8.9694e-08, 4.1206e-08, 6.2550e-07,\n             2.5622e-08, 3.5949e-08, 3.6784e-08, 2.5560e-08, 4.7867e-08, 2.6659e-08,\n             5.4527e-08, 4.7705e-08, 5.6936e-08, 8.6398e-08, 4.3966e-08, 5.6434e-08,\n             3.6742e-08, 1.1632e-07, 3.3203e-08, 3.4902e-08, 6.9689e-08, 3.4972e-08,\n             1.5559e-07, 2.6457e-08, 4.0819e-08, 3.3340e-08, 5.4131e-08, 3.2749e-08,\n             8.1963e-08, 7.2126e-08, 1.7771e-08, 1.2565e-07, 1.0394e-07, 2.7894e-07,\n             5.5223e-08, 4.1417e-08, 4.9995e-08, 4.7508e-08, 4.2419e-08, 2.4797e-08,\n             2.8839e-08, 5.8156e-08, 1.5163e-08, 2.3545e-08, 5.2334e-08, 1.1948e-07,\n             2.8819e-08, 4.3519e-08, 3.1101e-08, 1.2012e-07, 1.5462e-07, 3.4982e-08,\n             1.0140e-07, 7.5274e-08, 6.2429e-08, 1.0238e-07, 4.6182e-08, 7.1105e-08,\n             5.9762e-08, 3.8611e-08, 3.9139e-08, 1.7472e-07, 2.0011e-07, 5.8462e-08,\n             8.2178e-08, 3.5376e-08, 3.1072e-08, 3.9863e-08, 2.6932e-08, 4.8300e-08,\n             5.2017e-08, 3.4620e-08, 2.9903e-08, 4.1240e-08, 4.4212e-08, 8.2806e-08,\n             5.2090e-08, 6.3389e-08, 1.7019e-08, 3.7106e-08, 2.5548e-08, 4.5342e-08,\n             4.8685e-07, 3.4446e-08, 4.6269e-08, 5.5875e-08, 1.3385e-07, 2.5248e-08,\n             4.2500e-08, 2.6291e-08, 3.4004e-08, 8.8505e-08, 4.7736e-08, 3.4996e-08,\n             8.9845e-08, 4.5668e-08, 6.0506e-08, 4.0998e-08, 1.5497e-07, 4.2907e-08,\n             6.2285e-08, 1.0276e-07, 4.7149e-08, 2.0930e-07, 4.7890e-08, 2.5930e-08,\n             3.6388e-08, 1.8545e-08, 4.7978e-08, 4.8742e-08, 3.3202e-08, 2.2819e-08,\n             4.5591e-08, 4.6813e-08, 8.9755e-08, 3.9263e-08, 6.9520e-08, 9.2832e-08,\n             4.1412e-08, 2.5310e-08, 3.9937e-08, 2.7423e-08, 4.2805e-08, 3.9889e-08,\n             4.1471e-08, 7.1596e-08, 5.8446e-08, 2.3379e-08, 1.1188e-07, 5.4081e-08,\n             3.3806e-08, 4.4419e-08, 6.3132e-08, 4.2858e-08, 8.7151e-08, 3.9776e-08,\n             3.0781e-08, 8.1731e-08, 5.4752e-08, 5.1245e-08, 3.7343e-08, 3.8932e-08,\n             2.7969e-08, 9.7824e-08, 1.1738e-07, 3.3479e-08, 6.1489e-08, 2.5521e-08,\n             5.1171e-08, 2.1715e-08, 6.1659e-09, 1.0956e-07, 6.8075e-08, 2.7072e-08,\n             2.4495e-08, 1.1832e-07, 6.2401e-08, 3.8024e-08, 1.2386e-07, 3.4379e-08,\n             3.0816e-08, 3.3301e-08, 3.1139e-08, 1.5025e-07, 4.8237e-08, 5.6986e-08,\n             3.6063e-08, 6.0081e-08, 5.8118e-08, 7.0990e-08, 5.8543e-08, 1.1573e-07,\n             1.2098e-07, 4.1712e-08, 7.8107e-08, 1.0463e-07, 3.6888e-08, 2.4989e-08,\n             4.1481e-08, 3.8588e-08, 1.9253e-08, 1.4964e-07, 4.9466e-08, 1.1982e-07,\n             3.6295e-08, 5.2719e-08, 8.4099e-08, 6.6949e-08, 3.8885e-08, 1.0293e-07,\n             5.8374e-08, 4.5659e-08, 2.9736e-08, 4.9277e-08, 5.7889e-08, 3.2623e-08,\n             9.9663e-08, 3.9115e-08, 1.1895e-07, 2.3060e-08, 8.4989e-08, 2.8452e-08,\n             5.7825e-08, 3.0091e-08])},\n    27: {'exp_avg': tensor([ 1.0177e-06,  1.8259e-04, -2.0357e-05, -6.2851e-05, -7.3499e-06,\n             -1.8379e-05,  1.9696e-05,  1.4981e-04, -4.0734e-05,  8.3602e-05,\n             -7.1195e-05,  3.9730e-05,  1.0347e-04, -1.3868e-04, -8.4434e-05,\n             -3.9666e-05,  1.6568e-04,  8.9263e-05,  2.5653e-05, -1.9943e-05,\n              5.0308e-05, -9.5967e-06,  1.0998e-04,  5.3429e-05, -6.7456e-06,\n              5.4132e-05, -7.7257e-05,  3.5393e-05,  2.8318e-05,  9.8548e-05,\n              2.4043e-04, -8.6016e-05, -7.7825e-05, -1.3723e-04, -4.5823e-05,\n             -6.5049e-05,  9.1885e-05, -7.7825e-05,  1.3531e-05,  2.5283e-05,\n              6.1940e-05, -3.4853e-05,  1.2083e-04,  3.1335e-05, -4.5068e-05,\n             -8.6214e-05,  2.6578e-04, -1.0145e-04,  1.5359e-04,  3.1326e-05,\n              3.4633e-05, -9.5468e-05,  4.5561e-05, -1.5090e-05, -6.9308e-05,\n              9.7642e-05,  7.3989e-05, -4.3738e-05,  3.0920e-05,  1.7006e-05,\n             -1.5750e-06,  3.5426e-05, -6.4742e-05, -7.4838e-05, -1.1244e-04,\n             -2.4452e-05,  1.1305e-04,  4.9311e-05,  7.0298e-05,  1.4028e-04,\n             -2.1703e-05,  4.6066e-05,  1.7204e-05,  7.0265e-05,  6.7375e-06,\n              9.5742e-06, -2.8045e-05,  1.4517e-04,  8.2431e-05,  6.3362e-05,\n             -1.5580e-04,  2.7209e-05,  1.0572e-04, -1.5516e-04, -1.1716e-04,\n              1.9050e-05,  2.6528e-04, -4.7666e-05, -1.4089e-04, -1.9386e-04,\n             -2.8449e-05, -2.0551e-04, -4.3960e-05, -1.9079e-04,  4.6354e-05,\n             -2.2318e-04,  4.6766e-05,  4.6010e-05, -9.6905e-05, -8.7865e-05,\n              1.7513e-04, -4.3028e-05, -1.7747e-05,  1.3732e-04,  6.9348e-05,\n              1.4661e-04,  3.2887e-04, -1.0052e-05,  1.6788e-04, -1.9407e-04,\n              5.1713e-05,  3.9286e-05,  1.1139e-05,  1.7299e-05, -7.2031e-06,\n              9.7136e-05, -2.7738e-06,  1.3213e-05, -1.9746e-05,  1.3803e-05,\n             -8.8042e-05,  6.2325e-05,  8.3563e-07, -4.0121e-05,  1.2665e-04,\n              1.3503e-04,  1.2182e-05, -1.9949e-05,  6.1072e-05,  8.3911e-05,\n              7.2554e-05,  7.2136e-06,  1.1176e-04,  7.8604e-05,  1.5414e-04,\n              2.7889e-05, -8.9275e-05,  1.6202e-04, -1.9301e-05, -8.0836e-05,\n              1.1219e-04,  1.3335e-05, -1.2608e-04, -2.9723e-04,  8.9684e-05,\n             -7.9413e-05, -1.1716e-04, -1.2986e-05,  6.2486e-05,  9.9636e-05,\n              6.4780e-05,  1.5528e-04, -7.9462e-05,  9.2565e-05,  5.9483e-05,\n             -9.4657e-05, -1.0379e-04, -6.0220e-06, -3.2318e-05,  1.5692e-04,\n              1.6548e-05,  6.1673e-06,  3.9460e-05,  2.0739e-04,  9.1227e-05,\n             -3.3892e-05,  1.1112e-05,  4.9076e-05,  1.1093e-04,  1.3191e-05,\n             -1.4423e-04, -1.2075e-04, -4.0726e-05,  1.2205e-04, -5.3863e-05,\n              3.4612e-05,  1.1466e-06, -1.7864e-04, -8.2477e-05,  1.9305e-05,\n             -3.2726e-05,  2.3171e-05,  5.1475e-05,  1.0438e-05,  1.0262e-04,\n             -7.0888e-05,  2.6231e-05,  6.8618e-06,  2.0145e-05, -1.3174e-04,\n              2.7744e-05, -4.8484e-05, -1.8328e-04,  2.8701e-05,  1.1045e-04,\n             -4.6894e-05,  3.3799e-05,  2.3627e-05,  8.3887e-05, -2.6430e-05,\n             -4.9257e-06,  4.9131e-05, -5.6256e-06,  1.9788e-04, -2.1782e-04,\n              2.4196e-05, -1.4049e-05,  7.2729e-05,  5.7088e-05,  2.3285e-05,\n              7.2912e-05,  7.1322e-05,  9.0290e-05,  7.8446e-05,  1.0074e-05,\n              3.0084e-05,  7.6475e-05, -4.3568e-05,  8.9964e-05,  1.2757e-05,\n              9.5730e-05,  2.4166e-05, -1.1923e-04, -7.8176e-05,  1.1763e-05,\n              6.8564e-05, -4.7849e-05, -5.5243e-05, -1.8312e-04, -1.9777e-05,\n             -7.2620e-05,  1.2721e-04, -3.5640e-05, -1.3342e-05,  2.8264e-05,\n              3.4556e-05, -1.4378e-04, -2.1633e-05,  8.4877e-06, -3.3251e-05,\n             -6.2147e-05, -4.9766e-05,  1.6859e-04, -6.7214e-05, -6.9089e-05,\n              1.0854e-04, -4.2247e-05,  6.1818e-05,  8.5836e-05, -3.5467e-06,\n             -1.5036e-04,  5.9292e-05,  2.2046e-06, -5.4718e-05, -1.5399e-05,\n              9.8850e-05, -1.8052e-04, -3.2410e-05, -8.6831e-05,  1.1244e-04,\n              9.6230e-05, -3.3920e-05, -2.3337e-05, -7.1143e-05,  1.7052e-04,\n              8.9526e-05, -2.4381e-05, -9.5574e-05,  1.1363e-05,  6.7428e-06,\n              3.1960e-05,  1.4266e-04,  1.9229e-04,  2.2161e-05,  4.2629e-06,\n             -2.5306e-05,  4.5896e-05,  1.3031e-04,  2.0444e-05, -9.5340e-05,\n             -7.3008e-05, -2.6479e-04, -6.3126e-06,  2.4872e-05, -3.3542e-05,\n             -2.0033e-04,  7.7496e-05,  2.0206e-05,  1.1086e-04, -1.0628e-04,\n              3.0660e-04,  2.0112e-05, -6.7422e-06,  1.6251e-04, -1.3022e-04,\n             -2.4125e-05,  9.9038e-05, -5.0539e-05,  2.1880e-04,  6.0397e-05,\n              4.0319e-06, -1.1348e-05,  5.7593e-05,  7.3738e-05,  4.7895e-05,\n             -1.4588e-04, -6.4136e-05, -7.8577e-05,  9.5399e-05,  7.0515e-05,\n              1.3327e-04, -5.8113e-05, -3.7772e-05, -6.0136e-06, -1.2015e-04,\n             -2.9709e-05,  3.2230e-05,  1.2049e-05,  8.8639e-05, -1.0413e-04,\n             -9.4743e-05,  1.0821e-04,  2.9842e-05, -6.2387e-05,  1.4294e-04,\n             -4.1833e-05,  5.0009e-05,  3.6111e-05,  3.1771e-05,  6.9690e-05,\n              1.5114e-04, -3.2206e-05, -1.4968e-04, -9.9695e-05,  3.5261e-05,\n             -6.7726e-05, -7.7700e-06, -2.4784e-05, -8.0207e-05,  2.6782e-05,\n             -8.7531e-05, -2.7565e-05,  1.1344e-04, -3.6238e-05,  5.4052e-05,\n              1.9720e-04, -5.4295e-07, -4.6761e-05,  4.7760e-05, -1.3582e-04,\n             -3.6436e-05,  9.1529e-05, -1.8160e-04, -2.3150e-06, -1.1784e-04,\n             -9.4982e-05, -1.5445e-04,  2.2630e-05,  4.0029e-06, -6.2602e-06,\n             -1.4191e-04, -1.4074e-04, -4.8336e-05, -7.2805e-07,  2.7154e-05,\n             -7.0824e-06,  2.5817e-05,  3.2532e-05, -1.2260e-05, -2.0039e-05,\n              1.5294e-04,  8.1043e-05, -1.2586e-04, -1.4421e-04, -2.1392e-05,\n              7.0591e-05, -1.3718e-06,  1.2827e-04,  9.0302e-05,  6.3432e-05,\n              5.6832e-05,  2.0813e-04,  6.4915e-05,  1.6372e-04,  1.0268e-04,\n              7.8702e-05, -5.4546e-05,  1.4281e-05, -8.3420e-06, -3.2685e-05,\n             -1.4048e-04, -1.0422e-04, -2.3279e-05, -4.5281e-05,  1.5986e-04,\n             -5.1875e-06, -8.0324e-05,  4.4935e-06, -3.9984e-05,  1.7481e-05,\n              6.0805e-05,  3.6320e-05, -6.4550e-06, -4.6372e-05,  1.9332e-05,\n             -8.0082e-08,  7.2030e-05,  3.3262e-05,  4.8217e-06,  6.4367e-05,\n              3.6134e-05,  6.4148e-05, -3.7853e-05,  2.5642e-05,  3.4706e-05,\n             -1.4769e-05,  2.1928e-05, -1.2909e-04,  7.2455e-05, -3.7150e-05,\n             -5.6118e-05,  1.8738e-04, -6.7653e-05,  4.0709e-05,  1.3265e-04,\n             -1.3265e-04,  1.1609e-04, -1.8842e-05,  1.1943e-04, -2.7274e-04,\n             -1.6518e-04,  2.0314e-05, -5.6431e-05,  6.8469e-05, -6.2118e-05,\n             -7.5351e-06, -1.3757e-05, -9.6174e-06, -5.8035e-05,  1.9351e-04,\n             -3.7857e-05, -3.1873e-06, -8.0965e-07,  4.2274e-05,  5.2036e-05,\n              1.9126e-04,  2.0070e-05, -1.0942e-04,  1.0372e-04,  8.7119e-05,\n             -1.7437e-04, -1.9716e-04, -2.6154e-04, -1.6946e-04,  1.1216e-04,\n             -1.2463e-04,  1.7541e-06,  1.4173e-04,  9.3488e-06, -1.2441e-04,\n              2.6792e-05, -1.1015e-04, -1.5252e-04,  3.9222e-06, -2.6458e-04,\n              1.0814e-05, -5.6316e-05,  8.3703e-05, -4.4784e-06, -9.5028e-05,\n             -3.3393e-05,  5.8863e-06, -4.7198e-06,  4.5615e-05, -5.2840e-05,\n              1.1950e-05,  7.9837e-05,  8.9475e-05, -5.7958e-05,  1.1347e-05,\n              3.7543e-05, -1.9582e-04, -5.0296e-06,  1.9967e-04,  1.5250e-04,\n              1.3483e-05,  8.8727e-05,  1.4156e-05,  8.1639e-05,  1.5736e-05,\n              2.5846e-05,  6.9917e-06, -4.2556e-06, -9.2864e-05,  3.8882e-05,\n              4.5728e-05,  1.7729e-04,  2.3461e-05,  1.3969e-04,  1.7623e-04,\n              2.6730e-05, -7.1167e-05, -3.5778e-05, -1.8918e-04, -7.5369e-05,\n             -6.1922e-05,  4.2606e-05,  9.9032e-05, -1.1091e-05,  4.8028e-05,\n             -1.2031e-04, -9.3815e-05]),\n     'exp_avg_sq': tensor([2.0513e-08, 3.0583e-08, 2.6602e-09, 5.2091e-08, 1.6939e-08, 1.9291e-08,\n             2.0157e-08, 1.6718e-08, 1.3195e-08, 1.1120e-08, 5.0925e-08, 1.7903e-08,\n             3.9042e-08, 2.0205e-08, 3.2300e-08, 7.1262e-08, 1.7692e-08, 2.8943e-08,\n             2.2159e-08, 2.9829e-08, 4.4454e-08, 2.6580e-08, 2.9066e-08, 1.5633e-08,\n             4.3238e-08, 2.4027e-08, 1.8223e-08, 4.0850e-10, 2.4074e-08, 2.0692e-08,\n             3.6165e-08, 3.7776e-08, 4.3246e-08, 4.6224e-08, 2.6628e-09, 3.7732e-08,\n             1.4792e-08, 6.4666e-08, 4.4234e-08, 3.0518e-08, 2.8318e-09, 1.7911e-08,\n             2.9595e-08, 1.9535e-08, 4.3918e-08, 1.5487e-08, 2.6861e-08, 2.4937e-08,\n             6.2659e-08, 1.9129e-08, 1.9246e-08, 2.6299e-08, 1.6939e-08, 1.8977e-08,\n             2.9847e-08, 7.2037e-09, 5.1041e-08, 2.4773e-08, 1.1692e-08, 2.1346e-08,\n             1.5035e-08, 4.7271e-08, 6.2327e-08, 2.0688e-08, 2.3903e-08, 2.6897e-08,\n             3.1623e-08, 1.3208e-08, 2.1968e-08, 3.7050e-08, 4.1398e-08, 2.2207e-08,\n             1.8063e-08, 1.5091e-08, 3.2797e-08, 2.1653e-08, 2.1157e-08, 4.0410e-08,\n             2.9998e-08, 2.2051e-08, 1.5879e-08, 1.1739e-08, 4.2649e-08, 1.7558e-08,\n             2.2011e-08, 1.2548e-08, 4.4121e-08, 1.7016e-08, 3.5761e-08, 2.9728e-08,\n             1.9738e-08, 5.7226e-08, 3.9624e-08, 4.2879e-08, 2.4559e-08, 2.7063e-08,\n             3.1626e-08, 1.9965e-08, 3.8735e-08, 2.9228e-08, 2.9669e-08, 2.0902e-08,\n             1.4284e-08, 2.7099e-08, 2.0966e-08, 1.7481e-08, 2.8477e-08, 1.9316e-08,\n             1.7808e-08, 6.0024e-08, 1.9154e-08, 2.5874e-08, 2.7343e-08, 6.8300e-09,\n             2.1040e-08, 6.3661e-08, 2.6867e-09, 3.3574e-08, 1.0161e-08, 2.0188e-08,\n             1.7978e-08, 1.0351e-08, 3.6225e-08, 2.0604e-08, 2.0704e-08, 1.6490e-08,\n             1.1629e-08, 1.1980e-08, 2.7783e-08, 1.6673e-08, 4.5930e-08, 2.5891e-08,\n             2.3191e-08, 4.7750e-09, 2.6173e-08, 2.4121e-08, 2.5107e-08, 7.4566e-08,\n             2.1121e-08, 1.9365e-08, 3.5681e-08, 4.8253e-08, 2.3679e-08, 4.1958e-08,\n             1.6728e-08, 2.2153e-08, 5.5180e-08, 1.3730e-09, 1.0352e-07, 1.2325e-08,\n             1.0319e-08, 4.4790e-08, 1.4975e-08, 1.5310e-08, 4.9735e-08, 3.7510e-08,\n             1.6392e-08, 1.5366e-10, 1.4539e-08, 3.9250e-08, 1.2514e-08, 2.6652e-08,\n             2.1138e-08, 4.2375e-08, 3.6680e-08, 1.5430e-08, 2.2086e-08, 1.6386e-08,\n             3.8643e-08, 2.7750e-08, 2.1024e-08, 1.7213e-08, 3.9473e-08, 4.0056e-08,\n             1.4421e-08, 2.0418e-08, 2.8178e-08, 2.7483e-08, 1.4735e-08, 4.5978e-08,\n             2.2364e-08, 1.5651e-08, 3.1211e-08, 2.5157e-08, 1.2579e-08, 8.7154e-09,\n             2.5460e-08, 2.9339e-08, 3.8709e-10, 1.0497e-07, 1.8702e-08, 6.5486e-09,\n             2.7041e-08, 1.7584e-08, 2.9612e-08, 8.7044e-09, 1.4416e-08, 5.3833e-09,\n             1.9671e-08, 2.4437e-08, 1.4776e-08, 2.2706e-08, 2.6152e-08, 6.5154e-08,\n             4.8597e-08, 5.4993e-09, 1.5608e-08, 4.1590e-08, 1.6941e-08, 2.4538e-08,\n             2.8658e-08, 2.2686e-08, 1.4585e-08, 2.4029e-08, 2.4307e-08, 4.4484e-08,\n             4.2064e-08, 1.1507e-08, 2.1235e-08, 3.4808e-08, 1.7408e-08, 1.0103e-08,\n             2.4812e-08, 3.1507e-08, 3.4954e-08, 1.4574e-08, 3.6438e-08, 1.4710e-08,\n             4.6384e-08, 2.4788e-08, 2.8417e-08, 4.7552e-08, 1.3925e-08, 1.3632e-08,\n             3.4925e-08, 2.0797e-08, 2.5483e-08, 1.6882e-08, 1.5847e-08, 9.9052e-09,\n             2.3919e-08, 7.5644e-08, 3.9089e-08, 3.0390e-08, 2.0346e-08, 4.4617e-08,\n             2.6977e-08, 2.5404e-08, 1.5036e-08, 1.4450e-09, 1.8555e-08, 2.9958e-08,\n             7.7591e-09, 3.8287e-08, 2.3886e-08, 2.2696e-08, 2.3879e-08, 5.4029e-08,\n             4.0525e-08, 6.0151e-08, 4.0564e-08, 5.1686e-09, 5.7965e-08, 1.9480e-08,\n             5.7084e-08, 2.9961e-08, 4.9510e-08, 5.2618e-08, 3.1315e-08, 3.9472e-08,\n             6.1709e-08, 2.4848e-08, 1.9884e-08, 2.4433e-08, 9.4607e-11, 2.3242e-09,\n             1.4715e-08, 2.8442e-08, 7.2029e-08, 1.8300e-08, 2.4345e-08, 2.5974e-08,\n             1.6200e-08, 2.0738e-09, 4.7254e-08, 1.5636e-08, 1.9290e-08, 3.4816e-09,\n             1.0395e-07, 2.3051e-08, 1.6023e-07, 3.2351e-10, 1.1261e-08, 1.2518e-08,\n             1.7834e-08, 4.1498e-08, 2.9583e-08, 2.9625e-08, 1.1555e-07, 1.7152e-08,\n             9.5534e-09, 4.0870e-09, 2.2522e-08, 1.1330e-08, 1.2945e-08, 2.0716e-08,\n             3.4793e-08, 4.3764e-08, 1.7869e-08, 5.4584e-08, 1.5406e-08, 1.2645e-08,\n             3.8990e-08, 1.3618e-08, 2.9124e-08, 2.3652e-08, 1.6288e-08, 1.4408e-08,\n             2.7396e-08, 1.9618e-08, 3.1930e-08, 2.8198e-08, 2.0594e-08, 3.2375e-08,\n             1.6548e-08, 4.1008e-08, 1.3679e-08, 1.3538e-08, 1.2340e-08, 2.1301e-08,\n             2.5521e-08, 2.6192e-08, 2.6309e-08, 2.3168e-08, 1.6442e-08, 2.5926e-08,\n             2.9090e-08, 4.8857e-08, 1.4735e-08, 4.9761e-08, 4.1064e-08, 5.9627e-08,\n             3.7854e-08, 2.0916e-08, 3.0772e-08, 2.9907e-08, 2.0994e-08, 1.1034e-08,\n             2.2788e-08, 5.6620e-08, 7.7368e-09, 2.2344e-08, 5.1637e-08, 1.9342e-11,\n             2.4657e-08, 2.0313e-08, 4.0865e-08, 3.3487e-08, 4.1686e-08, 2.5594e-08,\n             4.4091e-08, 4.9860e-08, 2.7275e-08, 3.6867e-11, 3.3940e-08, 4.1721e-08,\n             3.9901e-09, 2.2090e-08, 2.3596e-08, 7.3462e-08, 1.7730e-07, 2.2112e-08,\n             3.1314e-08, 9.5842e-08, 1.3342e-08, 2.8093e-08, 1.8447e-08, 1.7317e-08,\n             4.4832e-08, 2.1351e-08, 1.6532e-08, 8.0663e-08, 1.7267e-08, 5.0763e-08,\n             1.9461e-08, 3.4492e-08, 1.0753e-08, 2.7566e-08, 3.9728e-08, 1.5850e-08,\n             1.2914e-08, 3.0531e-08, 4.6436e-08, 2.7418e-08, 7.9706e-08, 1.5057e-08,\n             1.6780e-08, 1.7715e-08, 1.7646e-08, 2.0660e-08, 2.2732e-08, 1.7763e-08,\n             4.1821e-08, 4.0994e-08, 2.3269e-08, 2.2699e-08, 3.5617e-08, 1.4301e-08,\n             3.8300e-08, 6.4231e-09, 4.0096e-08, 2.3656e-08, 2.3613e-08, 1.2227e-08,\n             1.8940e-08, 1.7603e-08, 3.8401e-08, 3.4777e-08, 1.5894e-08, 2.1270e-08,\n             2.4454e-08, 2.9323e-08, 3.8571e-08, 1.6576e-08, 4.2099e-08, 5.5398e-08,\n             2.5606e-08, 3.3209e-08, 2.0264e-08, 2.7090e-08, 2.0766e-08, 2.2227e-08,\n             2.0228e-08, 2.4235e-08, 1.9464e-08, 1.6896e-08, 1.1696e-09, 2.3605e-08,\n             2.8115e-08, 3.7772e-08, 2.4775e-08, 2.8092e-08, 6.3337e-08, 2.9022e-08,\n             1.2866e-08, 7.2981e-08, 1.7061e-08, 2.4203e-08, 2.3620e-08, 1.4779e-08,\n             2.0845e-08, 5.3964e-08, 4.3207e-08, 2.8591e-08, 1.6274e-08, 1.0410e-08,\n             3.1333e-08, 1.8206e-08, 8.8317e-09, 4.2991e-08, 1.7235e-08, 2.4788e-08,\n             1.0337e-08, 9.9703e-09, 5.4782e-08, 2.0212e-08, 4.0751e-08, 1.6286e-08,\n             1.6984e-08, 2.4107e-08, 1.6514e-08, 3.4006e-10, 2.0011e-08, 9.2049e-08,\n             2.0658e-08, 2.9593e-08, 4.1223e-08, 3.4546e-08, 2.5339e-08, 1.2617e-10,\n             1.4903e-09, 4.7993e-08, 3.8239e-08, 4.7070e-08, 2.7161e-08, 1.1900e-08,\n             1.9136e-08, 2.6805e-08, 2.6383e-08, 5.1564e-09, 2.2877e-08, 1.8085e-08,\n             1.6047e-08, 3.0970e-08, 3.3153e-08, 2.2949e-08, 2.7264e-08, 6.8466e-10,\n             4.1719e-08, 2.7761e-08, 1.7210e-08, 3.2362e-08, 2.7844e-08, 3.1697e-08,\n             1.6321e-08, 1.1201e-08, 8.6922e-08, 1.1640e-08, 5.8970e-08, 1.1629e-08,\n             3.7318e-08, 2.0590e-08])},\n    28: {'exp_avg': tensor([ 8.2486e-05,  7.9132e-04, -4.6308e-04, -2.1619e-04,  1.0824e-04,\n             -1.7438e-05, -1.8017e-05,  7.0918e-05, -4.4971e-05,  1.6735e-04,\n             -9.6156e-05,  5.6675e-05,  8.1235e-05, -1.9747e-04, -4.1825e-05,\n             -2.6546e-05,  9.5630e-05,  1.7354e-04,  1.2046e-05,  7.5686e-05,\n              6.3347e-05,  6.9123e-05,  1.9138e-04,  8.0973e-05, -4.2559e-05,\n             -2.4302e-04, -2.0231e-04, -4.6137e-05,  3.9543e-05,  3.5234e-04,\n              3.4723e-05, -1.3917e-04, -4.4008e-05, -1.6369e-05,  4.3763e-05,\n              4.4203e-05,  1.3356e-04, -1.4006e-05,  4.8315e-05,  7.5539e-05,\n              2.1214e-04, -6.3413e-05, -3.5287e-05,  7.3485e-06, -8.0909e-07,\n             -1.3035e-04,  2.9183e-05, -1.3338e-04,  1.4016e-04,  1.6169e-04,\n              4.6799e-05, -9.9197e-05,  2.5301e-05, -2.0657e-05,  4.7199e-06,\n              3.4191e-04,  6.1391e-05, -2.8510e-05,  3.3708e-05, -2.9893e-05,\n              2.5959e-04, -3.9824e-05, -3.0299e-05, -4.7936e-05, -1.2264e-04,\n              3.1241e-05,  2.3187e-04,  2.5727e-05,  9.1587e-05,  2.4098e-04,\n              1.9168e-04,  8.8406e-05,  5.2707e-05,  6.9980e-05,  2.0176e-04,\n              9.4692e-05,  7.8822e-05,  1.7509e-04,  5.9519e-05, -3.1681e-05,\n             -2.7812e-04,  1.9549e-05,  3.9963e-05, -1.6919e-04,  3.2906e-05,\n              8.8390e-05,  1.3747e-04, -1.2446e-05, -8.9339e-05,  3.9015e-05,\n             -6.5704e-05, -1.2650e-04,  7.3508e-05, -8.9056e-05, -2.7148e-05,\n             -4.9275e-05,  6.1816e-05,  1.7136e-04, -2.1553e-04, -4.9312e-05,\n              3.2052e-04,  1.9090e-05,  3.7731e-05,  1.4366e-04, -7.4879e-05,\n              3.6966e-05,  3.1734e-04,  2.1205e-05,  7.0810e-05, -2.6793e-05,\n             -6.0613e-05,  4.2870e-05,  3.3403e-05, -7.3673e-05,  1.8072e-05,\n             -8.4535e-05, -9.4013e-05, -3.2848e-05, -2.1206e-05,  1.3527e-04,\n             -5.2021e-05,  1.7286e-05, -1.3145e-04, -1.7211e-04,  1.4621e-04,\n              9.7433e-05, -1.0264e-04, -1.8481e-04,  2.3283e-04,  8.0759e-05,\n              2.2826e-04, -3.3089e-04,  2.8520e-04,  2.0423e-04,  1.5853e-05,\n              1.8623e-05, -2.0477e-04,  3.8856e-05,  1.3724e-04, -8.3939e-05,\n              7.5760e-05,  1.0230e-04, -1.8683e-04, -3.1100e-04,  9.6039e-05,\n             -8.3031e-05, -1.7165e-05,  7.8483e-05,  2.0510e-04,  1.1882e-04,\n              3.2150e-04,  1.7023e-04, -8.3631e-05,  1.7088e-04,  2.7531e-04,\n             -3.6177e-04, -1.8791e-05,  1.3364e-04, -7.3651e-05,  1.3531e-04,\n             -7.7347e-06, -2.5670e-05, -1.0256e-05,  1.7329e-04,  2.0001e-04,\n             -5.2920e-05,  3.9175e-04,  5.6596e-05, -1.7436e-04, -8.4646e-06,\n             -1.1721e-04, -1.5609e-04, -8.6587e-05,  1.7923e-04,  5.7567e-05,\n              8.4254e-05, -2.2069e-04, -4.5723e-05, -1.2254e-04, -4.7881e-05,\n             -1.2133e-05,  2.0270e-05, -1.2627e-04,  1.6369e-05,  2.2013e-04,\n             -2.0372e-05, -5.6153e-05,  8.6287e-05,  2.0620e-04, -1.3256e-04,\n              5.1822e-05,  1.7174e-04, -3.0781e-04,  9.4214e-05,  1.0383e-04,\n             -1.3287e-07, -2.2869e-05,  2.0873e-04,  2.2979e-04,  1.4173e-04,\n              6.8505e-05, -9.1595e-05,  9.6186e-05,  3.2494e-04,  3.0255e-06,\n              7.7963e-05, -8.6694e-05, -1.5787e-04,  2.8270e-04,  8.1931e-05,\n             -8.1877e-06, -2.0764e-05, -2.4860e-05,  1.3509e-04,  2.5574e-05,\n              3.0812e-05,  3.2640e-05, -6.3540e-05,  1.6076e-04, -1.0354e-05,\n              1.6565e-05,  4.7398e-05,  2.9369e-05, -4.4078e-04,  1.4475e-05,\n              2.0105e-04,  1.9327e-05, -7.7165e-05, -2.7889e-04, -3.0977e-05,\n              6.9423e-05,  1.8020e-04, -1.5370e-05, -1.2087e-04, -7.1021e-05,\n              1.9898e-04, -1.9799e-04, -7.7669e-05,  7.9468e-05,  4.3871e-05,\n              1.5421e-04, -1.5073e-04,  2.1888e-04,  1.1147e-04,  7.0398e-05,\n             -1.2513e-04,  5.4066e-05,  1.2135e-04,  2.0222e-04, -8.6149e-05,\n             -6.1389e-05,  5.7817e-05,  6.4052e-05,  8.7300e-06, -4.9697e-05,\n              1.0658e-04, -2.5678e-04, -4.4418e-05,  2.9335e-05,  2.2972e-04,\n              1.1445e-04, -1.5252e-04, -6.3866e-05, -6.8495e-05,  6.7364e-05,\n              3.5943e-05,  1.3235e-04, -5.2194e-05,  2.6392e-06, -7.1867e-05,\n              2.3068e-06,  1.3234e-04,  2.0047e-04, -9.1449e-05, -1.6275e-05,\n             -9.7544e-05,  1.5786e-05,  1.3732e-04,  2.4144e-05,  1.3729e-04,\n             -1.6267e-04, -1.5975e-04,  3.5085e-05, -1.5797e-04,  3.0619e-04,\n             -7.7401e-05,  1.0876e-04, -9.4182e-05,  5.1752e-05,  8.0161e-05,\n              1.2791e-04,  1.5734e-04, -2.6977e-05,  9.1064e-05, -6.0187e-05,\n             -1.4507e-04,  7.2649e-05, -1.4569e-04,  2.7924e-04,  7.6298e-05,\n              2.0815e-06, -1.9407e-05,  3.0777e-05, -1.2433e-04,  4.1765e-05,\n             -2.5587e-04, -3.8262e-05, -7.3747e-05,  1.0431e-04,  1.4553e-05,\n              1.2887e-04, -7.9839e-04, -6.7503e-05,  3.0928e-05, -7.1924e-05,\n             -1.0163e-05,  1.5530e-05,  5.6932e-05,  5.7049e-05,  1.5233e-04,\n             -1.4756e-04,  2.9039e-04,  7.9846e-05, -9.3742e-05,  1.5710e-04,\n             -8.9780e-05,  1.1835e-04,  1.2549e-04, -7.3552e-05,  8.0943e-05,\n              5.7263e-04,  4.0269e-05, -5.1238e-05, -9.2888e-05, -2.3706e-04,\n              5.9824e-05, -7.1629e-05, -5.9968e-05, -1.9348e-05, -2.1358e-05,\n              2.2614e-04,  6.4598e-06,  7.3400e-05, -3.1973e-05, -8.3255e-06,\n              1.2364e-04, -2.1927e-05,  1.3049e-04,  1.0826e-04,  9.8778e-05,\n             -4.3345e-06,  1.1722e-04, -2.7888e-04,  1.7902e-04, -1.4434e-04,\n             -8.2008e-05, -2.6391e-04,  1.1495e-05,  1.4660e-04,  3.5075e-05,\n              8.8584e-05, -9.2380e-05,  2.2315e-04,  1.2679e-05,  2.7058e-05,\n             -1.1482e-05, -9.6691e-05, -1.6529e-05, -7.2803e-05, -2.0248e-04,\n             -1.5157e-05,  1.8867e-04, -7.9412e-05, -8.9534e-05,  1.0152e-04,\n              5.7560e-05, -1.2034e-04,  1.3807e-04,  5.4296e-05, -2.1313e-05,\n              2.1202e-04,  2.5114e-04,  7.2937e-05,  1.9653e-04,  9.3556e-05,\n              9.8883e-05, -5.6359e-05, -8.2546e-06, -2.7485e-05, -2.1528e-06,\n             -5.5227e-04, -7.8264e-05, -7.2654e-05, -8.3885e-05, -1.6473e-04,\n             -1.5187e-05, -1.4812e-04, -4.0828e-05, -3.2029e-05,  1.7966e-04,\n              1.8086e-04,  3.8910e-05, -1.5700e-04, -6.8180e-05,  4.8288e-05,\n              1.0266e-04,  2.7181e-04, -2.7586e-05,  6.1914e-05,  2.1780e-04,\n              2.9371e-04, -1.8537e-05,  1.7584e-05,  4.3993e-06, -9.1962e-05,\n             -1.0020e-04,  1.0925e-04, -1.2617e-04,  1.4616e-04, -2.5331e-05,\n             -1.4559e-05,  1.2182e-04, -1.0782e-04, -9.8865e-05, -2.3919e-04,\n              2.4138e-05,  1.5824e-04,  2.9692e-04,  1.1103e-05, -1.4435e-04,\n             -1.0492e-04, -6.0014e-06, -4.7450e-05,  5.6619e-05, -7.8835e-05,\n             -1.8778e-05, -7.7789e-05,  3.0540e-05,  5.8921e-05,  2.0630e-04,\n              1.1026e-04, -1.2909e-05,  1.1072e-04,  1.2072e-04,  2.0012e-05,\n              2.7694e-04,  1.4496e-04, -3.5570e-05, -7.8998e-06, -1.5892e-04,\n             -2.6155e-04, -2.1426e-04, -1.9150e-04, -6.3106e-05,  5.6561e-05,\n             -2.3034e-04,  6.7227e-05,  3.3759e-05,  4.2230e-06, -1.5279e-04,\n             -3.0191e-05, -6.1675e-05, -1.5163e-04,  2.6052e-05, -2.0614e-04,\n              2.7955e-05, -1.2463e-04,  1.1394e-04, -7.6289e-05, -9.2382e-05,\n             -1.0950e-04,  1.1300e-04,  1.5301e-04, -1.7145e-04, -5.5600e-05,\n              1.1529e-04, -5.8086e-05,  2.0059e-04, -1.0914e-04,  1.5689e-04,\n             -9.8826e-05, -9.7173e-05, -6.9603e-05,  2.5193e-04,  1.8826e-04,\n              3.2624e-05,  4.8055e-05,  7.6369e-05, -2.5560e-05, -2.1601e-04,\n              1.5523e-04, -3.6617e-04, -1.5112e-05,  2.0652e-05,  6.4139e-05,\n             -5.8176e-05,  1.8518e-04,  3.3981e-04, -7.8278e-05,  1.3433e-04,\n              1.4199e-05, -3.4151e-05,  8.8440e-06, -3.2879e-04,  1.5881e-04,\n             -6.4881e-05,  1.9311e-04,  8.6303e-05,  9.4806e-05, -6.9919e-05,\n             -2.8805e-05, -5.1659e-05]),\n     'exp_avg_sq': tensor([3.6076e-08, 2.9601e-07, 1.3015e-07, 1.8543e-07, 1.9649e-08, 2.2977e-08,\n             3.3354e-08, 2.2706e-08, 1.7026e-08, 2.5449e-08, 4.6196e-08, 4.3559e-08,\n             4.4189e-08, 2.6290e-08, 4.4509e-08, 6.4130e-08, 2.5728e-08, 6.3178e-08,\n             2.8707e-08, 4.3592e-08, 7.3872e-08, 4.1269e-08, 4.7574e-08, 2.2384e-08,\n             5.2879e-08, 6.1600e-08, 3.7896e-08, 8.7856e-08, 2.8351e-08, 7.7659e-08,\n             6.3218e-08, 3.9819e-08, 1.3323e-07, 7.7157e-08, 1.1974e-07, 4.8492e-08,\n             1.8751e-08, 8.8113e-08, 9.2460e-08, 2.9245e-08, 4.6032e-08, 2.1584e-08,\n             3.9100e-08, 3.4635e-08, 1.9533e-07, 2.1866e-08, 4.7864e-08, 4.5265e-08,\n             8.1377e-08, 5.3598e-08, 3.5467e-08, 5.1198e-08, 4.3723e-08, 2.3033e-08,\n             4.7063e-08, 9.4313e-08, 4.8499e-08, 5.6458e-08, 2.3546e-08, 2.7172e-08,\n             4.7663e-08, 4.6898e-08, 1.0120e-07, 3.5677e-08, 3.5139e-08, 3.7377e-08,\n             4.4475e-08, 4.9912e-08, 2.5938e-08, 5.1853e-08, 8.8773e-08, 3.9307e-08,\n             4.6067e-08, 2.5031e-08, 1.1087e-07, 9.1611e-08, 2.8017e-08, 8.2123e-08,\n             6.2163e-08, 3.7100e-08, 2.7945e-08, 2.7279e-08, 7.4041e-08, 2.5317e-08,\n             4.3800e-08, 2.7595e-08, 4.1471e-08, 3.2893e-08, 5.8904e-08, 4.2468e-08,\n             3.7916e-08, 6.1953e-08, 5.7667e-08, 1.2198e-07, 3.1905e-08, 2.4444e-08,\n             5.6396e-08, 3.0247e-08, 7.2569e-08, 4.6080e-08, 8.3854e-08, 6.6833e-08,\n             1.0054e-07, 4.2667e-08, 3.9471e-08, 3.2857e-08, 4.6233e-08, 2.1466e-08,\n             2.0825e-08, 7.5697e-08, 3.1575e-08, 5.3788e-08, 4.7351e-08, 6.4021e-08,\n             3.8399e-08, 9.8583e-08, 5.7842e-08, 3.1853e-08, 1.5523e-08, 2.4783e-08,\n             3.2778e-08, 2.1388e-08, 5.3946e-08, 3.7014e-08, 4.4029e-08, 2.8032e-08,\n             1.6593e-08, 7.3549e-08, 5.0893e-08, 2.6262e-08, 1.2897e-07, 7.8465e-08,\n             5.9611e-08, 4.9647e-07, 5.5340e-08, 3.5825e-08, 4.2467e-08, 2.4792e-07,\n             4.0160e-08, 2.4266e-08, 4.9216e-08, 6.9921e-08, 2.4636e-08, 6.1405e-08,\n             3.2718e-08, 5.3078e-08, 9.3018e-08, 1.2029e-07, 2.8048e-07, 1.6864e-08,\n             1.2534e-07, 5.2645e-08, 2.1836e-08, 2.7619e-08, 6.5962e-08, 1.7179e-07,\n             1.8950e-07, 8.8401e-08, 3.6278e-08, 5.5724e-08, 2.6098e-08, 4.6343e-08,\n             3.0366e-08, 1.5507e-07, 5.2668e-08, 3.5523e-08, 4.3609e-08, 3.3616e-08,\n             9.1934e-08, 5.3210e-08, 2.7509e-08, 2.3710e-08, 5.4676e-08, 4.4246e-08,\n             2.7422e-08, 2.6992e-08, 5.3645e-08, 3.2838e-08, 2.6805e-08, 5.4758e-08,\n             1.9426e-08, 3.4773e-08, 8.0305e-08, 3.3300e-08, 1.0316e-07, 5.6222e-08,\n             3.6311e-08, 1.9433e-08, 1.0441e-07, 1.8331e-08, 6.0260e-08, 1.0763e-07,\n             4.9655e-08, 2.8572e-08, 3.8700e-08, 1.4829e-08, 2.7679e-08, 4.2523e-08,\n             1.1116e-07, 4.2219e-08, 8.2589e-08, 2.3029e-08, 2.6768e-08, 1.6429e-07,\n             5.4287e-08, 1.0458e-07, 3.2120e-08, 1.0601e-07, 3.2348e-08, 4.2681e-08,\n             5.4473e-08, 5.6423e-08, 3.2599e-08, 2.5194e-08, 3.5785e-08, 5.1312e-08,\n             6.1500e-08, 1.7968e-08, 4.5262e-08, 5.2402e-08, 2.7441e-08, 1.3588e-08,\n             3.4406e-08, 1.5494e-07, 5.9093e-08, 3.2305e-08, 6.6982e-08, 2.4152e-08,\n             6.1814e-08, 6.1893e-08, 4.8877e-08, 1.3225e-07, 2.0180e-08, 9.5046e-08,\n             6.8325e-08, 3.2951e-08, 3.3611e-08, 3.0163e-08, 9.2440e-08, 1.9558e-08,\n             3.5960e-08, 9.6878e-08, 8.8062e-08, 3.2392e-08, 2.9730e-08, 9.1308e-08,\n             5.4726e-08, 5.8120e-08, 7.2032e-08, 6.5708e-08, 2.0853e-08, 1.4643e-07,\n             9.9841e-08, 3.5732e-08, 2.2446e-08, 3.9386e-08, 1.8977e-08, 7.2096e-08,\n             4.1024e-08, 9.4628e-08, 5.1150e-08, 1.0401e-07, 8.3563e-08, 3.0956e-08,\n             7.1020e-08, 3.8701e-08, 1.5406e-07, 1.2471e-07, 4.7773e-08, 1.0875e-07,\n             8.2296e-08, 3.0070e-08, 2.9616e-08, 3.7944e-08, 1.7979e-07, 1.0276e-07,\n             4.8391e-08, 3.8427e-08, 1.3007e-07, 2.9037e-08, 2.8720e-08, 6.3335e-08,\n             3.8443e-08, 1.8956e-07, 1.5456e-07, 2.5472e-08, 3.6447e-08, 1.2993e-07,\n             1.0657e-07, 2.7873e-08, 1.2981e-07, 2.7285e-07, 7.6583e-08, 1.7816e-08,\n             3.1689e-08, 8.2347e-08, 2.1173e-07, 7.1455e-08, 2.1373e-07, 3.2664e-08,\n             2.0976e-08, 7.3345e-08, 4.8536e-08, 2.0627e-08, 2.6429e-08, 2.6517e-08,\n             6.6841e-08, 5.4281e-08, 1.7298e-08, 6.6151e-08, 3.6606e-08, 4.5639e-07,\n             3.3229e-08, 3.0813e-08, 4.5864e-08, 5.4396e-08, 3.6711e-08, 3.3419e-08,\n             3.4358e-08, 2.7977e-08, 3.0041e-08, 9.7375e-08, 4.2061e-08, 2.9820e-08,\n             2.7993e-08, 5.5142e-08, 3.0025e-08, 3.2326e-08, 6.8208e-08, 3.4982e-08,\n             2.3721e-07, 3.9387e-08, 3.0415e-08, 3.0665e-08, 3.8915e-08, 3.4083e-08,\n             2.8276e-08, 6.0524e-08, 2.5904e-08, 6.0348e-08, 8.5695e-08, 2.4095e-07,\n             4.3628e-08, 2.7028e-08, 5.4115e-08, 4.6005e-08, 3.8368e-08, 1.7227e-08,\n             2.0360e-08, 1.2410e-07, 1.5090e-08, 2.6826e-08, 8.8841e-08, 1.0586e-07,\n             3.3838e-08, 3.2754e-08, 8.7295e-08, 7.1463e-08, 1.5223e-07, 4.9278e-08,\n             8.5766e-08, 9.6628e-08, 4.5030e-08, 1.0737e-07, 4.3988e-08, 6.1162e-08,\n             8.9032e-08, 4.1470e-08, 3.6907e-08, 1.7923e-07, 8.0768e-08, 9.3673e-08,\n             1.1570e-07, 1.0625e-07, 4.0911e-08, 3.9353e-08, 3.0971e-08, 2.8554e-08,\n             5.8367e-08, 2.9050e-08, 3.1576e-08, 6.4519e-08, 3.0374e-08, 6.1787e-08,\n             1.2731e-08, 4.6409e-08, 3.5744e-08, 5.0480e-08, 3.0521e-08, 2.0289e-08,\n             3.3503e-07, 4.9653e-08, 5.2681e-08, 3.8429e-08, 1.1694e-07, 5.3454e-08,\n             6.2025e-08, 3.5658e-08, 3.5137e-08, 9.7035e-08, 3.8709e-08, 2.3257e-08,\n             6.9976e-08, 4.7042e-08, 2.9059e-08, 3.0517e-08, 1.2221e-07, 3.9919e-08,\n             6.5796e-08, 3.8680e-08, 6.6119e-08, 2.3841e-07, 4.6652e-08, 1.6501e-08,\n             2.8877e-08, 2.0551e-08, 5.1645e-08, 9.2621e-08, 3.1793e-08, 3.4467e-08,\n             3.6864e-08, 4.6993e-08, 6.3080e-08, 3.0137e-08, 5.7814e-08, 1.2214e-07,\n             5.0500e-08, 5.6915e-08, 7.0304e-08, 3.3839e-08, 2.2355e-08, 6.7556e-08,\n             2.8415e-08, 3.7676e-08, 4.0105e-08, 2.7490e-08, 1.1036e-07, 4.1440e-08,\n             3.3855e-08, 5.6886e-08, 3.5644e-08, 4.0689e-08, 7.0289e-08, 4.3714e-08,\n             1.4841e-08, 1.2374e-07, 3.8848e-08, 5.3968e-08, 2.2086e-08, 5.5935e-08,\n             5.4367e-08, 1.0584e-07, 9.1825e-08, 3.4771e-08, 3.9164e-08, 3.0278e-08,\n             5.3561e-08, 2.9922e-08, 3.4461e-08, 4.7836e-08, 2.7338e-08, 3.1050e-08,\n             2.0663e-08, 1.2780e-07, 7.2483e-08, 2.6604e-08, 8.9145e-08, 1.7755e-08,\n             2.6665e-08, 3.4771e-08, 2.6397e-08, 1.5495e-07, 3.0180e-08, 1.3705e-07,\n             2.8417e-08, 3.6587e-08, 6.2790e-08, 7.3411e-08, 4.1960e-08, 1.2862e-07,\n             1.1796e-07, 5.3164e-08, 4.1430e-08, 7.7078e-08, 4.0961e-08, 1.3206e-08,\n             3.5936e-08, 2.8790e-08, 4.1498e-08, 1.6562e-07, 4.4513e-08, 1.5622e-07,\n             2.8824e-08, 5.6572e-08, 4.9006e-08, 7.5497e-08, 5.2373e-08, 1.1281e-07,\n             1.4048e-08, 3.7037e-08, 3.4834e-08, 4.5574e-08, 5.1499e-08, 5.1441e-08,\n             1.3075e-07, 2.3503e-08, 1.0312e-07, 2.2960e-08, 7.4653e-08, 2.1811e-08,\n             6.4870e-08, 3.7889e-08])},\n    29: {'exp_avg': tensor([ 1.0177e-06,  1.8259e-04, -2.0357e-05, -6.2851e-05, -7.3499e-06,\n             -1.8379e-05,  1.9696e-05,  1.4981e-04, -4.0734e-05,  8.3602e-05,\n             -7.1195e-05,  3.9730e-05,  1.0347e-04, -1.3868e-04, -8.4434e-05,\n             -3.9666e-05,  1.6568e-04,  8.9263e-05,  2.5653e-05, -1.9943e-05,\n              5.0308e-05, -9.5967e-06,  1.0998e-04,  5.3429e-05, -6.7456e-06,\n              5.4132e-05, -7.7257e-05,  3.5393e-05,  2.8318e-05,  9.8548e-05,\n              2.4043e-04, -8.6016e-05, -7.7825e-05, -1.3723e-04, -4.5823e-05,\n             -6.5049e-05,  9.1885e-05, -7.7825e-05,  1.3531e-05,  2.5283e-05,\n              6.1940e-05, -3.4853e-05,  1.2083e-04,  3.1335e-05, -4.5068e-05,\n             -8.6214e-05,  2.6578e-04, -1.0145e-04,  1.5359e-04,  3.1326e-05,\n              3.4633e-05, -9.5468e-05,  4.5561e-05, -1.5090e-05, -6.9308e-05,\n              9.7642e-05,  7.3989e-05, -4.3738e-05,  3.0920e-05,  1.7006e-05,\n             -1.5750e-06,  3.5426e-05, -6.4742e-05, -7.4838e-05, -1.1244e-04,\n             -2.4452e-05,  1.1305e-04,  4.9311e-05,  7.0298e-05,  1.4028e-04,\n             -2.1703e-05,  4.6066e-05,  1.7204e-05,  7.0265e-05,  6.7375e-06,\n              9.5742e-06, -2.8045e-05,  1.4517e-04,  8.2431e-05,  6.3362e-05,\n             -1.5580e-04,  2.7209e-05,  1.0572e-04, -1.5516e-04, -1.1716e-04,\n              1.9050e-05,  2.6528e-04, -4.7666e-05, -1.4089e-04, -1.9386e-04,\n             -2.8449e-05, -2.0551e-04, -4.3960e-05, -1.9079e-04,  4.6354e-05,\n             -2.2318e-04,  4.6766e-05,  4.6010e-05, -9.6905e-05, -8.7865e-05,\n              1.7513e-04, -4.3028e-05, -1.7747e-05,  1.3732e-04,  6.9348e-05,\n              1.4661e-04,  3.2887e-04, -1.0052e-05,  1.6788e-04, -1.9407e-04,\n              5.1713e-05,  3.9286e-05,  1.1139e-05,  1.7299e-05, -7.2031e-06,\n              9.7136e-05, -2.7738e-06,  1.3213e-05, -1.9746e-05,  1.3803e-05,\n             -8.8042e-05,  6.2325e-05,  8.3563e-07, -4.0121e-05,  1.2665e-04,\n              1.3503e-04,  1.2182e-05, -1.9949e-05,  6.1072e-05,  8.3911e-05,\n              7.2554e-05,  7.2136e-06,  1.1176e-04,  7.8604e-05,  1.5414e-04,\n              2.7889e-05, -8.9275e-05,  1.6202e-04, -1.9301e-05, -8.0836e-05,\n              1.1219e-04,  1.3335e-05, -1.2608e-04, -2.9723e-04,  8.9684e-05,\n             -7.9413e-05, -1.1716e-04, -1.2986e-05,  6.2486e-05,  9.9636e-05,\n              6.4780e-05,  1.5528e-04, -7.9462e-05,  9.2565e-05,  5.9483e-05,\n             -9.4657e-05, -1.0379e-04, -6.0220e-06, -3.2318e-05,  1.5692e-04,\n              1.6548e-05,  6.1673e-06,  3.9460e-05,  2.0739e-04,  9.1227e-05,\n             -3.3892e-05,  1.1112e-05,  4.9076e-05,  1.1093e-04,  1.3191e-05,\n             -1.4423e-04, -1.2075e-04, -4.0726e-05,  1.2205e-04, -5.3863e-05,\n              3.4612e-05,  1.1466e-06, -1.7864e-04, -8.2477e-05,  1.9305e-05,\n             -3.2726e-05,  2.3171e-05,  5.1475e-05,  1.0438e-05,  1.0262e-04,\n             -7.0888e-05,  2.6231e-05,  6.8618e-06,  2.0145e-05, -1.3174e-04,\n              2.7744e-05, -4.8484e-05, -1.8328e-04,  2.8701e-05,  1.1045e-04,\n             -4.6894e-05,  3.3799e-05,  2.3627e-05,  8.3887e-05, -2.6430e-05,\n             -4.9257e-06,  4.9131e-05, -5.6256e-06,  1.9788e-04, -2.1782e-04,\n              2.4196e-05, -1.4049e-05,  7.2729e-05,  5.7088e-05,  2.3285e-05,\n              7.2912e-05,  7.1322e-05,  9.0290e-05,  7.8446e-05,  1.0074e-05,\n              3.0084e-05,  7.6475e-05, -4.3568e-05,  8.9964e-05,  1.2757e-05,\n              9.5730e-05,  2.4166e-05, -1.1923e-04, -7.8176e-05,  1.1763e-05,\n              6.8564e-05, -4.7849e-05, -5.5243e-05, -1.8312e-04, -1.9777e-05,\n             -7.2620e-05,  1.2721e-04, -3.5640e-05, -1.3342e-05,  2.8264e-05,\n              3.4556e-05, -1.4378e-04, -2.1633e-05,  8.4877e-06, -3.3251e-05,\n             -6.2147e-05, -4.9766e-05,  1.6859e-04, -6.7214e-05, -6.9089e-05,\n              1.0854e-04, -4.2247e-05,  6.1818e-05,  8.5836e-05, -3.5467e-06,\n             -1.5036e-04,  5.9292e-05,  2.2046e-06, -5.4718e-05, -1.5399e-05,\n              9.8850e-05, -1.8052e-04, -3.2410e-05, -8.6831e-05,  1.1244e-04,\n              9.6230e-05, -3.3920e-05, -2.3337e-05, -7.1143e-05,  1.7052e-04,\n              8.9526e-05, -2.4381e-05, -9.5574e-05,  1.1363e-05,  6.7428e-06,\n              3.1960e-05,  1.4266e-04,  1.9229e-04,  2.2161e-05,  4.2629e-06,\n             -2.5306e-05,  4.5896e-05,  1.3031e-04,  2.0444e-05, -9.5340e-05,\n             -7.3008e-05, -2.6479e-04, -6.3126e-06,  2.4872e-05, -3.3542e-05,\n             -2.0033e-04,  7.7496e-05,  2.0206e-05,  1.1086e-04, -1.0628e-04,\n              3.0660e-04,  2.0112e-05, -6.7422e-06,  1.6251e-04, -1.3022e-04,\n             -2.4125e-05,  9.9038e-05, -5.0539e-05,  2.1880e-04,  6.0397e-05,\n              4.0319e-06, -1.1348e-05,  5.7593e-05,  7.3738e-05,  4.7895e-05,\n             -1.4588e-04, -6.4136e-05, -7.8577e-05,  9.5399e-05,  7.0515e-05,\n              1.3327e-04, -5.8113e-05, -3.7772e-05, -6.0136e-06, -1.2015e-04,\n             -2.9709e-05,  3.2230e-05,  1.2049e-05,  8.8639e-05, -1.0413e-04,\n             -9.4743e-05,  1.0821e-04,  2.9842e-05, -6.2387e-05,  1.4294e-04,\n             -4.1833e-05,  5.0009e-05,  3.6111e-05,  3.1771e-05,  6.9690e-05,\n              1.5114e-04, -3.2206e-05, -1.4968e-04, -9.9695e-05,  3.5261e-05,\n             -6.7726e-05, -7.7700e-06, -2.4784e-05, -8.0207e-05,  2.6782e-05,\n             -8.7531e-05, -2.7565e-05,  1.1344e-04, -3.6238e-05,  5.4052e-05,\n              1.9720e-04, -5.4295e-07, -4.6761e-05,  4.7760e-05, -1.3582e-04,\n             -3.6436e-05,  9.1529e-05, -1.8160e-04, -2.3150e-06, -1.1784e-04,\n             -9.4982e-05, -1.5445e-04,  2.2630e-05,  4.0029e-06, -6.2602e-06,\n             -1.4191e-04, -1.4074e-04, -4.8336e-05, -7.2805e-07,  2.7154e-05,\n             -7.0824e-06,  2.5817e-05,  3.2532e-05, -1.2260e-05, -2.0039e-05,\n              1.5294e-04,  8.1043e-05, -1.2586e-04, -1.4421e-04, -2.1392e-05,\n              7.0591e-05, -1.3718e-06,  1.2827e-04,  9.0302e-05,  6.3432e-05,\n              5.6832e-05,  2.0813e-04,  6.4915e-05,  1.6372e-04,  1.0268e-04,\n              7.8702e-05, -5.4546e-05,  1.4281e-05, -8.3420e-06, -3.2685e-05,\n             -1.4048e-04, -1.0422e-04, -2.3279e-05, -4.5281e-05,  1.5986e-04,\n             -5.1875e-06, -8.0324e-05,  4.4935e-06, -3.9984e-05,  1.7481e-05,\n              6.0805e-05,  3.6320e-05, -6.4550e-06, -4.6372e-05,  1.9332e-05,\n             -8.0082e-08,  7.2030e-05,  3.3262e-05,  4.8217e-06,  6.4367e-05,\n              3.6134e-05,  6.4148e-05, -3.7853e-05,  2.5642e-05,  3.4706e-05,\n             -1.4769e-05,  2.1928e-05, -1.2909e-04,  7.2455e-05, -3.7150e-05,\n             -5.6118e-05,  1.8738e-04, -6.7653e-05,  4.0709e-05,  1.3265e-04,\n             -1.3265e-04,  1.1609e-04, -1.8842e-05,  1.1943e-04, -2.7274e-04,\n             -1.6518e-04,  2.0314e-05, -5.6431e-05,  6.8469e-05, -6.2118e-05,\n             -7.5351e-06, -1.3757e-05, -9.6174e-06, -5.8035e-05,  1.9351e-04,\n             -3.7857e-05, -3.1873e-06, -8.0965e-07,  4.2274e-05,  5.2036e-05,\n              1.9126e-04,  2.0070e-05, -1.0942e-04,  1.0372e-04,  8.7119e-05,\n             -1.7437e-04, -1.9716e-04, -2.6154e-04, -1.6946e-04,  1.1216e-04,\n             -1.2463e-04,  1.7541e-06,  1.4173e-04,  9.3488e-06, -1.2441e-04,\n              2.6792e-05, -1.1015e-04, -1.5252e-04,  3.9222e-06, -2.6458e-04,\n              1.0814e-05, -5.6316e-05,  8.3703e-05, -4.4784e-06, -9.5028e-05,\n             -3.3393e-05,  5.8863e-06, -4.7198e-06,  4.5615e-05, -5.2840e-05,\n              1.1950e-05,  7.9837e-05,  8.9475e-05, -5.7958e-05,  1.1347e-05,\n              3.7543e-05, -1.9582e-04, -5.0296e-06,  1.9967e-04,  1.5250e-04,\n              1.3483e-05,  8.8727e-05,  1.4156e-05,  8.1639e-05,  1.5736e-05,\n              2.5846e-05,  6.9917e-06, -4.2556e-06, -9.2864e-05,  3.8882e-05,\n              4.5728e-05,  1.7729e-04,  2.3461e-05,  1.3969e-04,  1.7623e-04,\n              2.6730e-05, -7.1167e-05, -3.5778e-05, -1.8918e-04, -7.5369e-05,\n             -6.1922e-05,  4.2606e-05,  9.9032e-05, -1.1091e-05,  4.8028e-05,\n             -1.2031e-04, -9.3815e-05]),\n     'exp_avg_sq': tensor([2.0513e-08, 3.0583e-08, 2.6602e-09, 5.2091e-08, 1.6939e-08, 1.9291e-08,\n             2.0157e-08, 1.6718e-08, 1.3195e-08, 1.1120e-08, 5.0925e-08, 1.7903e-08,\n             3.9042e-08, 2.0205e-08, 3.2300e-08, 7.1262e-08, 1.7692e-08, 2.8943e-08,\n             2.2159e-08, 2.9829e-08, 4.4454e-08, 2.6580e-08, 2.9066e-08, 1.5633e-08,\n             4.3238e-08, 2.4027e-08, 1.8223e-08, 4.0850e-10, 2.4074e-08, 2.0692e-08,\n             3.6165e-08, 3.7776e-08, 4.3246e-08, 4.6224e-08, 2.6628e-09, 3.7732e-08,\n             1.4792e-08, 6.4666e-08, 4.4234e-08, 3.0518e-08, 2.8318e-09, 1.7911e-08,\n             2.9595e-08, 1.9535e-08, 4.3918e-08, 1.5487e-08, 2.6861e-08, 2.4937e-08,\n             6.2659e-08, 1.9129e-08, 1.9246e-08, 2.6299e-08, 1.6939e-08, 1.8977e-08,\n             2.9847e-08, 7.2037e-09, 5.1041e-08, 2.4773e-08, 1.1692e-08, 2.1346e-08,\n             1.5035e-08, 4.7271e-08, 6.2327e-08, 2.0688e-08, 2.3903e-08, 2.6897e-08,\n             3.1623e-08, 1.3208e-08, 2.1968e-08, 3.7050e-08, 4.1398e-08, 2.2207e-08,\n             1.8063e-08, 1.5091e-08, 3.2797e-08, 2.1653e-08, 2.1157e-08, 4.0410e-08,\n             2.9998e-08, 2.2051e-08, 1.5879e-08, 1.1739e-08, 4.2649e-08, 1.7558e-08,\n             2.2011e-08, 1.2548e-08, 4.4121e-08, 1.7016e-08, 3.5761e-08, 2.9728e-08,\n             1.9738e-08, 5.7226e-08, 3.9624e-08, 4.2879e-08, 2.4559e-08, 2.7063e-08,\n             3.1626e-08, 1.9965e-08, 3.8735e-08, 2.9228e-08, 2.9669e-08, 2.0902e-08,\n             1.4284e-08, 2.7099e-08, 2.0966e-08, 1.7481e-08, 2.8477e-08, 1.9316e-08,\n             1.7808e-08, 6.0024e-08, 1.9154e-08, 2.5874e-08, 2.7343e-08, 6.8300e-09,\n             2.1040e-08, 6.3661e-08, 2.6867e-09, 3.3574e-08, 1.0161e-08, 2.0188e-08,\n             1.7978e-08, 1.0351e-08, 3.6225e-08, 2.0604e-08, 2.0704e-08, 1.6490e-08,\n             1.1629e-08, 1.1980e-08, 2.7783e-08, 1.6673e-08, 4.5930e-08, 2.5891e-08,\n             2.3191e-08, 4.7750e-09, 2.6173e-08, 2.4121e-08, 2.5107e-08, 7.4566e-08,\n             2.1121e-08, 1.9365e-08, 3.5681e-08, 4.8253e-08, 2.3679e-08, 4.1958e-08,\n             1.6728e-08, 2.2153e-08, 5.5180e-08, 1.3730e-09, 1.0352e-07, 1.2325e-08,\n             1.0319e-08, 4.4790e-08, 1.4975e-08, 1.5310e-08, 4.9735e-08, 3.7510e-08,\n             1.6392e-08, 1.5366e-10, 1.4539e-08, 3.9250e-08, 1.2514e-08, 2.6652e-08,\n             2.1138e-08, 4.2375e-08, 3.6680e-08, 1.5430e-08, 2.2086e-08, 1.6386e-08,\n             3.8643e-08, 2.7750e-08, 2.1024e-08, 1.7213e-08, 3.9473e-08, 4.0056e-08,\n             1.4421e-08, 2.0418e-08, 2.8178e-08, 2.7483e-08, 1.4735e-08, 4.5978e-08,\n             2.2364e-08, 1.5651e-08, 3.1211e-08, 2.5157e-08, 1.2579e-08, 8.7154e-09,\n             2.5460e-08, 2.9339e-08, 3.8709e-10, 1.0497e-07, 1.8702e-08, 6.5486e-09,\n             2.7041e-08, 1.7584e-08, 2.9612e-08, 8.7044e-09, 1.4416e-08, 5.3833e-09,\n             1.9671e-08, 2.4437e-08, 1.4776e-08, 2.2706e-08, 2.6152e-08, 6.5154e-08,\n             4.8597e-08, 5.4993e-09, 1.5608e-08, 4.1590e-08, 1.6941e-08, 2.4538e-08,\n             2.8658e-08, 2.2686e-08, 1.4585e-08, 2.4029e-08, 2.4307e-08, 4.4484e-08,\n             4.2064e-08, 1.1507e-08, 2.1235e-08, 3.4808e-08, 1.7408e-08, 1.0103e-08,\n             2.4812e-08, 3.1507e-08, 3.4954e-08, 1.4574e-08, 3.6438e-08, 1.4710e-08,\n             4.6384e-08, 2.4788e-08, 2.8417e-08, 4.7552e-08, 1.3925e-08, 1.3632e-08,\n             3.4925e-08, 2.0797e-08, 2.5483e-08, 1.6882e-08, 1.5847e-08, 9.9052e-09,\n             2.3919e-08, 7.5644e-08, 3.9089e-08, 3.0390e-08, 2.0346e-08, 4.4617e-08,\n             2.6977e-08, 2.5404e-08, 1.5036e-08, 1.4450e-09, 1.8555e-08, 2.9958e-08,\n             7.7591e-09, 3.8287e-08, 2.3886e-08, 2.2696e-08, 2.3879e-08, 5.4029e-08,\n             4.0525e-08, 6.0151e-08, 4.0564e-08, 5.1686e-09, 5.7965e-08, 1.9480e-08,\n             5.7084e-08, 2.9961e-08, 4.9510e-08, 5.2618e-08, 3.1315e-08, 3.9472e-08,\n             6.1709e-08, 2.4848e-08, 1.9884e-08, 2.4433e-08, 9.4607e-11, 2.3242e-09,\n             1.4715e-08, 2.8442e-08, 7.2029e-08, 1.8300e-08, 2.4345e-08, 2.5974e-08,\n             1.6200e-08, 2.0738e-09, 4.7254e-08, 1.5636e-08, 1.9290e-08, 3.4816e-09,\n             1.0395e-07, 2.3051e-08, 1.6023e-07, 3.2351e-10, 1.1261e-08, 1.2518e-08,\n             1.7834e-08, 4.1498e-08, 2.9583e-08, 2.9625e-08, 1.1555e-07, 1.7152e-08,\n             9.5534e-09, 4.0870e-09, 2.2522e-08, 1.1330e-08, 1.2945e-08, 2.0716e-08,\n             3.4793e-08, 4.3764e-08, 1.7869e-08, 5.4584e-08, 1.5406e-08, 1.2645e-08,\n             3.8990e-08, 1.3618e-08, 2.9124e-08, 2.3652e-08, 1.6288e-08, 1.4408e-08,\n             2.7396e-08, 1.9618e-08, 3.1930e-08, 2.8198e-08, 2.0594e-08, 3.2375e-08,\n             1.6548e-08, 4.1008e-08, 1.3679e-08, 1.3538e-08, 1.2340e-08, 2.1301e-08,\n             2.5521e-08, 2.6192e-08, 2.6309e-08, 2.3168e-08, 1.6442e-08, 2.5926e-08,\n             2.9090e-08, 4.8857e-08, 1.4735e-08, 4.9761e-08, 4.1064e-08, 5.9627e-08,\n             3.7854e-08, 2.0916e-08, 3.0772e-08, 2.9907e-08, 2.0994e-08, 1.1034e-08,\n             2.2788e-08, 5.6620e-08, 7.7368e-09, 2.2344e-08, 5.1637e-08, 1.9342e-11,\n             2.4657e-08, 2.0313e-08, 4.0865e-08, 3.3487e-08, 4.1686e-08, 2.5594e-08,\n             4.4091e-08, 4.9860e-08, 2.7275e-08, 3.6867e-11, 3.3940e-08, 4.1721e-08,\n             3.9901e-09, 2.2090e-08, 2.3596e-08, 7.3462e-08, 1.7730e-07, 2.2112e-08,\n             3.1314e-08, 9.5842e-08, 1.3342e-08, 2.8093e-08, 1.8447e-08, 1.7317e-08,\n             4.4832e-08, 2.1351e-08, 1.6532e-08, 8.0663e-08, 1.7267e-08, 5.0763e-08,\n             1.9461e-08, 3.4492e-08, 1.0753e-08, 2.7566e-08, 3.9728e-08, 1.5850e-08,\n             1.2914e-08, 3.0531e-08, 4.6436e-08, 2.7418e-08, 7.9706e-08, 1.5057e-08,\n             1.6780e-08, 1.7715e-08, 1.7646e-08, 2.0660e-08, 2.2732e-08, 1.7763e-08,\n             4.1821e-08, 4.0994e-08, 2.3269e-08, 2.2699e-08, 3.5617e-08, 1.4301e-08,\n             3.8300e-08, 6.4231e-09, 4.0096e-08, 2.3656e-08, 2.3613e-08, 1.2227e-08,\n             1.8940e-08, 1.7603e-08, 3.8401e-08, 3.4777e-08, 1.5894e-08, 2.1270e-08,\n             2.4454e-08, 2.9323e-08, 3.8571e-08, 1.6576e-08, 4.2099e-08, 5.5398e-08,\n             2.5606e-08, 3.3209e-08, 2.0264e-08, 2.7090e-08, 2.0766e-08, 2.2227e-08,\n             2.0228e-08, 2.4235e-08, 1.9464e-08, 1.6896e-08, 1.1696e-09, 2.3605e-08,\n             2.8115e-08, 3.7772e-08, 2.4775e-08, 2.8092e-08, 6.3337e-08, 2.9022e-08,\n             1.2866e-08, 7.2981e-08, 1.7061e-08, 2.4203e-08, 2.3620e-08, 1.4779e-08,\n             2.0845e-08, 5.3964e-08, 4.3207e-08, 2.8591e-08, 1.6274e-08, 1.0410e-08,\n             3.1333e-08, 1.8206e-08, 8.8317e-09, 4.2991e-08, 1.7235e-08, 2.4788e-08,\n             1.0337e-08, 9.9703e-09, 5.4782e-08, 2.0212e-08, 4.0751e-08, 1.6286e-08,\n             1.6984e-08, 2.4107e-08, 1.6514e-08, 3.4006e-10, 2.0011e-08, 9.2049e-08,\n             2.0658e-08, 2.9593e-08, 4.1223e-08, 3.4546e-08, 2.5339e-08, 1.2617e-10,\n             1.4903e-09, 4.7993e-08, 3.8239e-08, 4.7070e-08, 2.7161e-08, 1.1900e-08,\n             1.9136e-08, 2.6805e-08, 2.6383e-08, 5.1564e-09, 2.2877e-08, 1.8085e-08,\n             1.6047e-08, 3.0970e-08, 3.3153e-08, 2.2949e-08, 2.7264e-08, 6.8466e-10,\n             4.1719e-08, 2.7761e-08, 1.7210e-08, 3.2362e-08, 2.7844e-08, 3.1697e-08,\n             1.6321e-08, 1.1201e-08, 8.6922e-08, 1.1640e-08, 5.8970e-08, 1.1629e-08,\n             3.7318e-08, 2.0590e-08])},\n    30: {'exp_avg': tensor([-2.4256e-04,  8.8438e-05, -1.0350e-04,  2.3180e-05, -5.2267e-05,\n             -4.6414e-04,  4.3442e-04,  1.9130e-04,  2.7097e-05, -3.4858e-04,\n              1.6859e-05, -1.0564e-05,  2.8059e-05,  1.4991e-04, -4.1431e-04,\n              1.7635e-05, -2.5756e-04, -2.0772e-04, -9.8823e-05, -1.9545e-04,\n              2.8099e-04, -5.6798e-04,  5.1026e-06,  3.8790e-04, -8.2411e-05,\n             -2.2931e-04,  2.0134e-04, -9.8497e-05, -1.4271e-04, -3.6467e-04,\n              1.3049e-04, -3.2431e-05,  1.9459e-04,  1.3913e-04, -1.9900e-04,\n             -2.0840e-04,  5.0812e-05,  2.1805e-04, -4.7906e-05, -1.4297e-04,\n             -1.6541e-04,  3.8770e-04,  2.7077e-06,  2.7208e-04, -8.7716e-05,\n              1.0857e-04,  1.6497e-04,  1.3602e-04,  2.1302e-04, -1.8603e-05,\n             -1.1366e-04,  3.4984e-05,  1.5071e-04, -7.2330e-06, -4.9682e-05,\n              1.3293e-04,  2.3454e-04, -2.8180e-04,  1.5404e-04, -3.3790e-04,\n             -1.2826e-04,  3.1511e-05, -1.2679e-04, -2.3315e-04,  7.6984e-05,\n             -5.9071e-05,  1.2951e-04, -1.0950e-04,  1.2048e-04,  1.1498e-04,\n             -4.9168e-05,  4.5638e-05,  6.1063e-05, -6.4642e-05, -2.2039e-04,\n              2.3599e-04, -1.3763e-05, -8.6921e-05, -2.0246e-04,  9.6597e-05,\n             -9.9234e-05,  7.7679e-05,  6.1130e-04,  1.9940e-04, -8.9875e-05,\n             -1.1776e-05, -9.1764e-05,  2.2346e-05, -1.3382e-04, -3.6650e-05,\n              5.0210e-05, -2.7796e-04,  1.1864e-04, -1.8147e-05, -7.8663e-05,\n             -5.6503e-04,  1.2761e-04, -1.1518e-04,  3.6544e-04,  2.7491e-06,\n             -2.4703e-04,  4.1817e-04,  2.5479e-04,  1.4018e-04, -2.7909e-05,\n             -2.5167e-04, -1.5046e-04, -1.2677e-04,  6.2787e-04,  7.8072e-05,\n              6.6859e-05, -1.0845e-04, -1.5387e-04,  2.9403e-05,  3.6627e-05,\n              1.2586e-04,  2.4789e-04, -2.7604e-05,  1.2745e-04,  1.9672e-04,\n             -5.4375e-04, -1.4933e-04,  7.7123e-06, -1.9665e-04, -1.4209e-04,\n             -1.9175e-04,  1.7302e-04, -2.3951e-05]),\n     'exp_avg_sq': tensor([1.5922e-07, 1.1595e-07, 1.5703e-07, 6.0072e-08, 8.4429e-08, 1.3065e-07,\n             1.8375e-07, 8.1924e-08, 9.0096e-08, 5.6515e-08, 5.9695e-08, 1.8884e-07,\n             1.0941e-07, 9.8911e-08, 1.4274e-07, 1.3817e-07, 8.2021e-08, 1.0032e-07,\n             1.6837e-07, 9.3262e-08, 9.3480e-08, 1.6964e-07, 1.4122e-07, 1.5970e-07,\n             7.8191e-08, 5.6320e-08, 3.4927e-07, 4.5845e-08, 7.2395e-08, 2.1380e-07,\n             8.2927e-08, 8.6783e-08, 2.4418e-07, 9.0238e-08, 2.4973e-08, 1.1968e-07,\n             7.8963e-08, 1.2973e-07, 1.2469e-07, 1.4985e-08, 9.2564e-08, 1.3089e-07,\n             6.1817e-08, 1.7197e-07, 5.2582e-08, 1.8080e-07, 1.0756e-07, 6.1783e-08,\n             1.4257e-07, 1.7770e-07, 5.3066e-08, 9.7965e-08, 1.9319e-07, 2.5793e-07,\n             5.5387e-08, 3.9625e-08, 8.4612e-08, 1.3495e-07, 3.2743e-07, 3.7838e-07,\n             1.1642e-07, 2.2957e-07, 3.0158e-07, 1.8999e-07, 1.7335e-07, 9.3844e-08,\n             2.3595e-07, 1.0689e-07, 1.6469e-07, 4.9431e-08, 1.0417e-07, 1.2449e-07,\n             1.1323e-07, 4.7669e-08, 6.1532e-08, 8.7032e-08, 1.5577e-07, 3.4584e-08,\n             6.2792e-08, 2.5724e-07, 1.9614e-07, 1.5208e-07, 1.4209e-07, 7.9013e-08,\n             3.6640e-08, 8.6933e-08, 1.9135e-07, 6.2474e-08, 5.6928e-08, 9.8125e-08,\n             1.0478e-07, 4.7623e-07, 1.1648e-07, 9.9435e-08, 8.7284e-08, 3.2999e-07,\n             7.5700e-08, 1.2462e-07, 6.4535e-08, 6.1314e-08, 7.5366e-08, 1.7586e-07,\n             5.9496e-08, 5.8251e-08, 5.9002e-08, 8.8809e-08, 1.0862e-07, 4.0142e-08,\n             8.0161e-07, 1.4633e-07, 1.1569e-07, 1.2457e-07, 1.4416e-07, 7.7999e-08,\n             9.7631e-08, 1.2083e-07, 6.5970e-08, 5.7496e-08, 4.4730e-08, 5.7886e-08,\n             1.2227e-07, 1.5878e-07, 5.1818e-08, 7.5876e-08, 8.7789e-08, 9.4370e-08,\n             1.7828e-07, 5.5483e-08])},\n    31: {'exp_avg': tensor([-1.2861e-04, -5.4877e-05, -2.2447e-04,  1.9819e-04,  1.5892e-04,\n             -2.1826e-04,  7.9440e-05,  1.9251e-04, -4.2028e-06, -2.9824e-04,\n              7.7015e-06, -1.3045e-04, -1.5892e-05, -1.5800e-04, -3.9817e-04,\n             -1.2820e-04, -1.7717e-04, -7.0325e-05, -2.6095e-04, -1.8022e-04,\n              1.9811e-04, -3.3362e-04, -1.2321e-04,  2.0820e-04, -1.5268e-05,\n             -3.7914e-04, -4.0099e-05, -3.5279e-05, -8.3435e-05, -5.4886e-05,\n              2.7029e-05,  2.3950e-05,  3.8239e-05,  1.8989e-04, -3.7163e-04,\n             -4.8527e-05,  1.3116e-04, -2.5951e-05,  2.8244e-05, -1.3609e-04,\n             -1.4906e-04,  2.6137e-04,  7.4673e-05,  1.7916e-04, -6.7998e-05,\n              5.5507e-05,  9.3946e-05,  1.1236e-04,  3.1735e-04, -7.2571e-05,\n             -4.0064e-05, -2.8273e-04,  1.2763e-04,  8.3000e-06, -2.1934e-05,\n             -7.0031e-05,  1.3865e-04,  5.7287e-05,  4.2260e-05, -1.5239e-04,\n              1.1792e-04,  3.4602e-04, -5.5574e-05, -1.6221e-04,  1.7149e-04,\n              2.9996e-05, -1.2819e-04, -5.1569e-05,  3.9521e-05,  2.3037e-04,\n              1.1707e-04,  1.2131e-04, -4.6255e-05, -1.9694e-04,  6.1684e-05,\n              6.4320e-05, -1.2651e-04, -1.8123e-04, -1.4614e-04,  1.6960e-04,\n              1.5296e-04, -1.5688e-04,  3.3042e-04,  1.7104e-04, -1.5832e-04,\n              2.1053e-06, -2.1186e-04,  1.3764e-04, -1.2294e-04,  2.1427e-05,\n             -6.7513e-05,  4.3698e-05,  4.7023e-04, -1.2921e-04, -1.0548e-04,\n             -2.9748e-05, -5.4813e-05, -3.5539e-05,  2.5911e-04,  2.0597e-04,\n             -1.6535e-04,  1.0140e-04,  2.1858e-04, -2.6056e-05,  1.1146e-04,\n             -2.2351e-04, -2.4888e-04, -1.8532e-05,  3.1930e-04,  1.4602e-04,\n             -3.7969e-04, -8.7695e-05, -2.6900e-04, -1.2192e-04, -9.7005e-05,\n              2.2987e-04,  1.7272e-04, -1.5426e-04,  1.9725e-04, -2.0102e-04,\n             -2.9841e-04, -7.2672e-05, -6.6373e-05,  5.9282e-05,  1.5776e-04,\n             -1.2598e-04, -1.3936e-05, -1.3133e-04]),\n     'exp_avg_sq': tensor([6.9600e-08, 4.4902e-08, 1.2756e-07, 2.8753e-08, 9.3894e-08, 4.4204e-08,\n             9.7031e-08, 6.0721e-08, 2.1200e-08, 7.6018e-08, 6.0551e-08, 1.3005e-07,\n             3.6834e-08, 1.0193e-07, 9.2039e-08, 6.4131e-08, 4.3786e-08, 1.0217e-07,\n             8.8197e-08, 6.5963e-08, 6.7961e-08, 6.6534e-08, 2.5389e-07, 1.0519e-07,\n             5.3441e-08, 6.6248e-08, 5.5838e-08, 5.1493e-08, 1.8753e-08, 9.7559e-08,\n             6.4570e-08, 4.4709e-08, 1.1422e-07, 7.8989e-08, 9.0813e-08, 7.5435e-08,\n             5.3137e-08, 7.4125e-08, 6.9836e-08, 1.8790e-08, 4.5079e-08, 6.5947e-08,\n             5.7190e-08, 6.2655e-08, 8.5283e-08, 1.5199e-07, 7.5144e-08, 5.3328e-08,\n             1.7634e-07, 8.8422e-08, 5.8477e-08, 1.0055e-07, 7.7029e-08, 1.3271e-07,\n             3.5502e-08, 7.1484e-08, 6.2670e-08, 7.0810e-08, 1.3070e-07, 5.6681e-08,\n             6.6716e-08, 8.4255e-08, 8.5884e-08, 9.7935e-08, 1.2968e-07, 7.0544e-08,\n             2.9768e-07, 4.3171e-08, 5.7974e-08, 7.5577e-08, 4.8229e-08, 8.6127e-08,\n             9.6303e-08, 5.5502e-08, 1.2504e-07, 9.5073e-08, 1.0141e-07, 7.0246e-08,\n             3.7160e-08, 1.5970e-07, 4.0645e-08, 2.4220e-07, 8.1970e-08, 5.8381e-08,\n             5.2531e-08, 8.9140e-08, 9.8705e-08, 7.0429e-08, 4.1341e-08, 3.1090e-08,\n             6.4922e-08, 6.1215e-08, 1.8317e-07, 2.6100e-08, 6.4101e-08, 3.2985e-08,\n             5.7853e-08, 1.5713e-07, 5.2685e-08, 1.1019e-07, 3.8327e-08, 1.4131e-08,\n             3.6377e-08, 7.9078e-08, 6.3396e-08, 7.1759e-08, 9.9766e-08, 5.3555e-08,\n             3.2383e-07, 1.0831e-07, 7.2437e-08, 1.0463e-07, 1.1658e-07, 4.7076e-08,\n             6.6821e-08, 1.1699e-07, 5.3814e-08, 6.3162e-08, 6.3935e-08, 4.9360e-08,\n             7.5960e-08, 3.8013e-08, 7.6986e-08, 5.9916e-08, 5.1925e-08, 2.7411e-08,\n             6.0732e-08, 3.7600e-08])},\n    32: {'exp_avg': tensor([-3.8901e-05, -1.6899e-04, -7.9936e-05,  1.5474e-04,  4.3353e-04,\n             -1.9412e-04,  6.9566e-04,  5.4054e-04, -3.5340e-04, -1.7498e-04,\n             -1.3144e-04, -5.4817e-04, -3.1247e-04, -3.4668e-04,  1.7776e-06,\n              2.1271e-04, -4.1473e-04, -2.9580e-04,  4.0853e-05,  4.0036e-04,\n             -7.4246e-05, -7.2069e-05,  1.1211e-04,  1.3915e-04,  6.6972e-05,\n              3.6117e-04,  1.9406e-04, -2.8764e-04, -7.9999e-04, -3.2007e-04,\n             -1.9918e-04,  3.1372e-04, -8.3563e-04,  9.4657e-05, -6.4978e-05,\n              2.8158e-04, -1.7321e-04, -1.3843e-05, -5.2446e-04,  1.0140e-04,\n              1.2279e-04, -6.4243e-04, -2.3264e-04,  1.2958e-04, -5.8844e-04,\n              2.6953e-04, -1.7376e-04,  2.3122e-06,  5.9851e-04, -1.1400e-04,\n             -7.2468e-04,  9.8803e-04,  2.9231e-04, -1.9851e-04, -1.9002e-04,\n             -2.9850e-04,  1.1977e-05,  2.1115e-04, -1.8011e-04,  3.2873e-04,\n              2.8110e-04,  2.7877e-04,  7.7994e-06,  6.2283e-06,  1.1404e-03,\n              6.2717e-05, -2.8951e-04,  6.1700e-05,  3.4190e-04, -2.1644e-04,\n             -5.0967e-04,  1.0465e-06,  8.8320e-05, -1.0336e-04,  3.5980e-04,\n             -4.2001e-04, -1.6559e-04, -1.1863e-04,  4.0088e-05,  8.4633e-04,\n             -2.1836e-04,  1.2126e-04,  9.1780e-04,  4.3717e-04, -1.0572e-04,\n              5.1229e-04,  3.8204e-05,  6.1306e-04,  5.6947e-05,  3.5712e-04,\n              4.0076e-04,  5.6764e-05, -5.8931e-05,  5.3583e-04,  2.2781e-04,\n             -1.6433e-04, -5.7348e-04, -1.3805e-04, -1.6216e-04,  3.2316e-04,\n             -1.9018e-04, -2.1718e-05, -4.1485e-06,  5.4170e-05, -2.7020e-05,\n              3.7635e-04, -8.4349e-05,  9.0943e-05, -1.1593e-04, -4.5322e-04,\n              5.0544e-04,  1.4968e-06,  4.3361e-05, -1.3839e-05, -7.1335e-04,\n             -1.9449e-04, -2.1047e-04,  1.0630e-04, -4.3596e-05,  3.0374e-05,\n             -5.2771e-04, -3.0672e-04, -1.0294e-04,  3.0748e-04, -2.1580e-04,\n             -4.4593e-04,  1.4272e-04,  1.7081e-04]),\n     'exp_avg_sq': tensor([1.1247e-07, 1.3584e-07, 2.1731e-07, 1.0454e-07, 7.6243e-07, 1.4321e-07,\n             1.5973e-06, 1.4507e-07, 1.1316e-07, 2.3815e-07, 1.0236e-07, 4.1855e-07,\n             1.3931e-07, 4.9380e-07, 1.0533e-07, 2.5767e-07, 1.3898e-07, 1.2041e-07,\n             1.5431e-07, 3.6456e-07, 1.2085e-07, 1.0531e-07, 1.2888e-07, 1.0569e-07,\n             3.1954e-07, 1.0057e-06, 2.1347e-07, 7.3955e-07, 1.5102e-07, 2.4955e-07,\n             1.6151e-07, 9.7795e-08, 3.3394e-07, 2.3681e-07, 1.0295e-07, 1.6825e-07,\n             9.0157e-08, 2.7524e-07, 2.9613e-07, 1.1580e-07, 1.2204e-07, 1.2483e-07,\n             1.0411e-07, 2.7218e-07, 2.9436e-07, 1.8047e-07, 1.6123e-07, 1.4794e-07,\n             3.2155e-07, 1.1923e-07, 6.9094e-07, 3.1352e-07, 2.5467e-07, 2.3314e-07,\n             1.9867e-07, 1.8376e-07, 3.1431e-07, 2.7351e-07, 2.6559e-07, 2.0283e-07,\n             7.9553e-08, 1.1190e-07, 1.4031e-07, 2.0032e-07, 5.0119e-07, 3.1533e-07,\n             1.4903e-07, 1.4453e-07, 1.4930e-07, 1.1899e-07, 7.7022e-07, 1.3313e-07,\n             1.4557e-07, 2.8411e-07, 1.1514e-07, 8.8356e-07, 1.0653e-07, 1.1927e-07,\n             1.6710e-07, 7.0505e-07, 1.8976e-07, 9.9980e-08, 4.6702e-07, 9.5086e-07,\n             4.1303e-07, 1.8366e-07, 2.8928e-07, 1.1928e-06, 2.0247e-07, 5.3589e-07,\n             1.1365e-07, 7.2159e-08, 2.2433e-07, 2.9252e-07, 2.6074e-07, 1.0103e-07,\n             4.4065e-07, 1.0371e-06, 1.3791e-07, 1.1167e-07, 1.2477e-07, 1.9741e-07,\n             1.1694e-07, 1.5185e-07, 1.8839e-07, 6.0450e-07, 9.6782e-08, 9.7272e-08,\n             3.1046e-07, 1.8994e-07, 1.2587e-07, 1.3233e-07, 2.4170e-07, 1.3991e-07,\n             9.6998e-07, 8.6239e-07, 1.3851e-07, 1.0783e-07, 2.0959e-07, 1.4241e-07,\n             1.6139e-07, 1.3178e-07, 1.4456e-07, 9.2726e-08, 1.3766e-07, 1.2385e-07,\n             4.1618e-07, 1.0985e-07])},\n    33: {'exp_avg': tensor([-1.1317e-04, -1.8058e-04,  1.0333e-04,  1.3209e-04, -2.3760e-05,\n             -1.0286e-04,  5.3223e-04,  5.0319e-04, -3.2509e-04, -8.4609e-05,\n             -1.2295e-04, -2.6965e-04, -2.8043e-04, -5.6920e-04,  2.2441e-05,\n              1.1121e-04,  3.1076e-04, -2.5766e-04, -8.6330e-06, -1.3247e-04,\n             -1.7997e-04, -6.6138e-05,  1.1062e-04,  2.8914e-04,  9.0939e-05,\n              2.3405e-05,  2.1079e-04, -5.2208e-06, -8.6786e-04, -5.7744e-05,\n              8.8662e-05, -1.4451e-05, -8.4315e-05,  1.3734e-04,  1.0894e-04,\n              2.5321e-04, -9.5811e-05, -2.0967e-04,  2.7525e-05,  1.3205e-04,\n              1.7707e-04, -4.4958e-04, -1.5523e-04, -5.0997e-05, -2.4840e-04,\n              1.5213e-04, -6.0705e-05,  7.6801e-05, -5.6466e-05, -4.5450e-04,\n              2.1419e-04,  3.9459e-04,  5.2129e-04,  1.6772e-05, -9.9213e-05,\n             -4.0538e-04, -2.3670e-04,  1.3227e-04, -6.9673e-05,  2.7346e-04,\n              1.9843e-04, -6.0253e-06,  1.6127e-05, -9.1552e-05,  3.1657e-04,\n              1.6849e-04, -1.6355e-04,  4.8051e-05,  2.6946e-04, -1.2612e-04,\n              4.4987e-06,  1.4101e-04,  1.8576e-04, -1.2305e-05,  1.2812e-04,\n              2.5056e-04,  7.7265e-05,  1.5739e-07, -1.2279e-04,  5.9854e-05,\n             -3.8901e-05, -1.2090e-05,  4.4948e-04, -1.6813e-05,  5.0114e-05,\n              2.7437e-04,  4.3511e-04,  1.2680e-05,  8.8423e-05, -1.2716e-04,\n              4.0638e-04,  6.6886e-04,  1.7962e-04,  4.6422e-04,  5.6440e-05,\n             -8.4809e-05, -2.8942e-05,  5.7470e-06, -9.3836e-05,  1.9728e-04,\n             -9.5296e-05, -7.0646e-05,  7.2984e-05, -2.5087e-05,  2.7083e-04,\n              1.0621e-04,  6.9159e-05,  5.1158e-06,  2.3218e-04,  1.4041e-05,\n              5.3487e-04, -1.5079e-05,  4.4374e-04,  1.5301e-04, -3.9320e-04,\n              2.3644e-05, -4.9884e-04,  8.1441e-05,  7.4245e-06, -8.0732e-05,\n              9.0158e-05, -8.7522e-05,  2.7360e-05,  2.0572e-04, -8.8555e-05,\n             -1.7708e-04, -1.2111e-04,  1.1489e-04]),\n     'exp_avg_sq': tensor([1.0851e-07, 5.9043e-08, 1.4371e-07, 7.4993e-08, 1.1850e-09, 1.2306e-07,\n             9.6070e-07, 1.4649e-07, 7.0080e-08, 1.5809e-07, 7.7163e-08, 1.4915e-07,\n             4.8772e-08, 2.5320e-07, 8.8102e-08, 1.5427e-07, 1.5392e-07, 9.1798e-08,\n             1.4459e-07, 1.8378e-07, 1.0263e-07, 7.4285e-08, 3.9754e-08, 1.0234e-07,\n             1.3103e-07, 9.2531e-10, 1.7295e-07, 2.3906e-09, 1.7094e-07, 7.5739e-08,\n             1.3985e-07, 1.4424e-07, 9.7890e-08, 1.6602e-07, 6.7641e-08, 9.6062e-08,\n             3.5790e-08, 1.3520e-07, 1.2930e-07, 7.4547e-08, 1.1750e-07, 8.1493e-08,\n             6.5497e-08, 9.7622e-08, 1.6008e-07, 5.6426e-08, 9.9243e-08, 8.2604e-08,\n             3.3067e-08, 1.2383e-07, 4.7863e-08, 1.2406e-07, 1.7534e-07, 1.5632e-07,\n             1.7617e-07, 3.0080e-07, 2.0326e-07, 1.4000e-07, 9.7044e-08, 1.3339e-07,\n             6.6316e-08, 1.5597e-07, 1.2390e-07, 1.0046e-07, 7.0699e-08, 9.7502e-08,\n             4.0605e-08, 4.2737e-08, 1.2815e-07, 3.6476e-08, 1.2681e-09, 7.7834e-08,\n             1.0044e-07, 1.2263e-07, 1.0360e-07, 1.8156e-07, 1.2243e-07, 6.4549e-08,\n             5.7526e-08, 6.5385e-08, 1.4483e-07, 6.0999e-08, 1.7814e-07, 1.5037e-09,\n             2.2185e-07, 7.9762e-08, 1.8869e-07, 6.7937e-10, 9.9768e-08, 7.9418e-08,\n             7.4670e-08, 3.5608e-07, 1.6161e-07, 1.6123e-07, 1.3365e-07, 1.3818e-07,\n             6.0373e-08, 1.8890e-09, 8.0400e-08, 1.1694e-07, 8.1102e-08, 1.6586e-07,\n             4.8893e-08, 9.8148e-08, 1.6286e-07, 4.5706e-08, 8.8784e-08, 7.8034e-08,\n             1.9015e-07, 8.0330e-08, 1.1870e-07, 6.5132e-08, 2.2378e-07, 1.0488e-07,\n             3.2695e-07, 1.2085e-09, 1.5429e-07, 4.6962e-08, 6.5785e-08, 1.1778e-07,\n             9.4985e-08, 7.1483e-08, 1.1298e-07, 1.1870e-07, 1.2213e-07, 1.0288e-07,\n             4.4296e-08, 2.9966e-08])},\n    34: {'exp_avg': tensor([-1.2704e-04,  2.2847e-04,  2.3040e-05,  2.5327e-05,  2.1937e-04,\n              4.7904e-06,  2.7585e-05,  4.5938e-05,  5.9658e-05, -9.1692e-06,\n             -1.4581e-04,  1.5005e-04, -2.2617e-04,  7.8467e-05, -7.6820e-05,\n             -1.8139e-04, -5.6064e-05,  1.0455e-04, -1.9344e-05,  4.1894e-05,\n              1.2933e-04,  9.0562e-05, -5.3240e-05, -9.2683e-05,  2.3348e-05,\n              3.9761e-04, -6.1548e-05, -9.4246e-05,  5.1675e-05, -3.3761e-05,\n             -1.4883e-04,  9.6148e-06, -1.8487e-04,  3.7281e-05, -5.0979e-05,\n              3.9878e-05,  6.5179e-05,  1.6606e-04, -7.2777e-05,  1.1937e-04,\n             -3.6134e-04, -6.3302e-05,  1.2057e-04,  4.5904e-05, -6.5160e-05,\n             -5.9804e-05, -1.0188e-05, -7.1827e-05, -7.1092e-05,  1.3436e-04,\n              1.7948e-04,  8.7445e-05, -2.2762e-05,  6.6313e-05, -1.3399e-05,\n              6.5979e-04, -1.4337e-05, -1.8100e-04,  5.8755e-05, -1.8894e-04,\n             -1.6853e-04, -6.6549e-05,  1.8084e-04,  1.0064e-05,  1.3228e-04,\n              1.5572e-05,  1.5482e-04,  2.9561e-05,  6.1093e-05,  1.8737e-05,\n              1.3218e-04, -1.4946e-04,  2.6843e-04,  4.7019e-05, -8.4195e-05,\n              7.8252e-05,  9.2065e-05,  7.0764e-05,  1.6529e-05,  4.6716e-05,\n             -1.4232e-04,  1.5250e-04, -1.7481e-04,  1.3793e-04,  5.5167e-05,\n             -2.3685e-04, -2.7963e-05,  1.0433e-04, -1.0430e-04, -1.1832e-05,\n             -2.3668e-04,  2.6458e-04,  1.5704e-04,  1.1643e-04, -2.6891e-04,\n             -1.3949e-05,  1.7396e-04, -1.8260e-04,  4.0424e-05, -1.1542e-04,\n             -6.5586e-05,  5.8045e-05,  8.2819e-05, -1.4856e-04, -1.5946e-04,\n             -3.9892e-05, -7.5867e-05, -2.0002e-04, -5.2251e-05,  1.1075e-04,\n              3.7036e-05,  1.5208e-04, -3.4982e-04,  2.9331e-04, -1.6062e-04,\n             -2.8773e-04, -2.6413e-04,  8.9427e-05, -1.0686e-04,  1.0500e-04,\n              1.8356e-06, -1.7706e-05,  1.0340e-04,  3.1520e-04, -5.4818e-05,\n              1.4161e-04,  1.5379e-04,  8.4553e-08, -2.4386e-04, -8.1525e-05,\n              8.6723e-05,  2.3654e-04,  4.5196e-05, -7.8887e-05, -1.8453e-04,\n              9.8568e-05,  1.5785e-05, -2.9488e-05, -3.1622e-05,  2.0624e-04,\n             -6.0493e-05, -7.4258e-05,  1.5110e-04, -1.3983e-04, -1.2008e-04,\n              5.4426e-05,  8.2418e-05, -9.2257e-05, -1.4196e-04,  6.8466e-05,\n              4.7706e-04,  2.8751e-04, -1.9206e-05, -8.1574e-05,  2.1042e-04,\n             -3.2982e-04, -1.9905e-04, -6.4003e-05, -5.0882e-05,  7.8019e-05,\n              6.1982e-05, -2.6941e-05, -1.3569e-04, -2.4932e-04,  5.8189e-05,\n              3.5040e-05,  1.2200e-05,  2.6078e-05, -1.0896e-04,  7.1120e-05,\n              1.7708e-05, -4.4521e-05, -1.5023e-04,  4.5318e-05,  5.8978e-05,\n             -5.5903e-05, -3.2513e-04,  2.0447e-05,  8.6426e-05,  2.9271e-04,\n              1.0570e-04,  8.2465e-05,  9.9217e-05,  7.0987e-06, -1.1555e-04,\n             -1.9930e-04,  8.2509e-05, -1.2737e-04, -2.6700e-04, -6.2680e-05,\n              2.0009e-05,  1.9389e-04, -2.6666e-04,  2.4493e-05, -1.2809e-04,\n              3.4162e-06,  1.5556e-05, -2.0894e-04,  6.1727e-05, -1.4693e-05,\n             -2.6554e-05,  1.9612e-04, -8.4504e-05,  2.4996e-04, -1.5358e-04,\n              3.9951e-04, -3.0231e-04, -1.0132e-04,  2.1802e-04,  8.9593e-06,\n              1.0995e-05, -9.6784e-05,  3.9826e-05,  6.6839e-05,  7.6943e-05,\n             -3.2616e-05,  3.5611e-04,  1.8739e-05, -4.5041e-05,  1.4582e-04,\n             -1.0924e-04, -6.9774e-05,  1.1715e-04,  4.3372e-04,  3.4471e-05,\n              3.4845e-05, -2.6399e-05,  1.5210e-04, -1.5311e-04, -3.2731e-04,\n             -6.0288e-05,  1.3582e-04, -6.0267e-05,  1.5260e-05, -3.0842e-04,\n              9.3956e-06, -4.5077e-05,  2.0163e-05,  1.8963e-04, -7.5271e-05,\n             -2.8052e-05, -3.7207e-05, -7.7642e-05,  1.4716e-04,  1.1471e-04,\n             -1.3757e-04,  3.3246e-04, -5.6860e-06, -1.3358e-04, -6.6630e-05,\n              6.3209e-06, -1.2814e-04, -1.3599e-04,  3.8666e-06,  1.3708e-05,\n             -1.1323e-04,  1.3390e-04, -1.7772e-04, -1.4729e-04, -2.1797e-04,\n              2.5711e-04, -5.0596e-05,  3.5998e-04,  2.0215e-06,  1.2782e-05,\n              5.0489e-05, -4.8823e-05, -4.3930e-04,  2.9971e-04,  1.3719e-04,\n              4.6000e-05,  7.8200e-06,  1.9883e-04, -1.6831e-04,  5.3242e-05,\n             -1.1480e-04,  5.7887e-07,  1.0740e-04,  1.2974e-04,  1.9255e-05,\n              1.0490e-04,  2.7568e-04,  5.8757e-06, -1.0099e-04,  2.5487e-05,\n              1.5964e-04, -1.7605e-04, -8.1872e-05, -7.4573e-06,  1.7259e-04,\n             -2.4292e-04, -6.5818e-05, -5.0474e-06,  5.3102e-05,  8.5061e-05,\n              3.2561e-04, -3.8049e-05, -3.9090e-05, -4.5416e-05, -6.2697e-05,\n             -1.3303e-04,  2.7614e-06, -8.1069e-05, -8.1923e-05,  3.6923e-05,\n              4.6188e-04,  3.8368e-05, -2.8649e-05,  1.1681e-04, -3.2188e-04,\n             -1.4490e-04,  4.1109e-04,  1.7365e-04,  1.2984e-04,  2.5498e-06,\n             -2.4976e-04,  1.1468e-04,  2.5098e-05,  2.0968e-04,  1.5230e-04,\n              6.5505e-05, -1.3818e-04,  2.1848e-04, -1.9792e-04, -6.4537e-05,\n              3.0110e-05, -1.4835e-04,  1.9463e-05,  1.6306e-04, -1.7157e-05,\n             -2.5834e-04, -1.1683e-04,  8.3300e-05, -9.8581e-05,  3.2128e-04,\n             -1.9385e-04, -3.3033e-05,  7.7601e-05, -1.3106e-05, -8.8406e-05,\n              2.8769e-04,  2.0751e-05, -8.3832e-05,  5.1071e-05,  8.2900e-05,\n              2.5969e-04, -8.9162e-05, -2.5368e-05, -1.1177e-04,  3.5715e-05,\n             -9.6459e-05,  1.5452e-04,  6.7366e-05, -3.5223e-05, -9.9836e-05,\n             -1.3004e-05,  1.5131e-04, -5.7699e-05,  1.3978e-05,  7.0584e-05,\n              1.6836e-05,  4.1955e-08,  3.8362e-04,  1.5703e-05, -2.1404e-04,\n             -1.4608e-04,  2.0972e-04,  4.9946e-05,  2.6170e-04, -4.6105e-05,\n              3.7450e-04, -1.3362e-04,  8.0322e-05, -3.0640e-05,  2.1034e-04,\n              5.0623e-05,  2.1790e-04, -4.1009e-05,  7.9134e-05,  1.6404e-04,\n             -2.3693e-04, -1.3541e-04,  1.1889e-05,  8.2275e-05, -7.5249e-05,\n             -1.7618e-04,  1.0963e-04, -1.5477e-04,  1.5002e-04, -1.4260e-05,\n              6.7252e-05,  8.6632e-05, -5.0535e-05, -1.6967e-04, -1.1530e-04,\n             -1.3048e-06, -1.4946e-04,  3.7192e-05,  4.8611e-05,  2.8414e-05,\n              1.3390e-04, -8.0234e-05,  2.0161e-04,  7.7418e-06,  2.1481e-05,\n              1.0275e-04, -9.2135e-05,  2.0445e-04,  6.1887e-05, -2.9199e-04,\n              1.3867e-04,  3.2370e-04, -9.9008e-05, -3.8880e-05,  7.8267e-05,\n              3.4422e-05,  4.3326e-05, -2.9880e-04, -3.7009e-04,  2.3442e-04,\n             -4.0475e-05,  2.2580e-05,  6.6201e-05,  7.2941e-05, -1.3323e-04,\n              4.7657e-05,  1.4107e-04,  2.8564e-05, -2.7253e-04, -1.8603e-05,\n              2.2787e-04,  3.4526e-05,  1.4577e-04,  1.4527e-04, -1.8058e-05,\n              1.4463e-04,  1.9978e-04,  9.9999e-05,  5.3395e-06,  7.6725e-05,\n              9.4634e-05,  1.9873e-04,  7.2749e-06, -8.2058e-05, -9.0600e-06,\n             -1.7844e-04,  3.7693e-05,  1.6663e-04, -1.1557e-04,  3.0011e-05,\n              1.8547e-04, -2.4105e-04,  6.9591e-05,  1.3391e-04, -1.3514e-04,\n             -4.3426e-05, -6.7080e-06,  9.9399e-05, -1.5427e-04,  4.8748e-05,\n             -2.3066e-05,  6.2663e-05,  4.1303e-06, -9.8321e-05,  2.3747e-05,\n              1.2250e-04, -5.7101e-05,  1.6224e-04, -6.1498e-05,  7.0280e-05,\n             -1.7099e-04, -4.6996e-05, -1.3967e-04, -1.7470e-04,  1.5661e-05,\n             -2.5969e-04,  4.6376e-05,  7.9399e-05, -1.1346e-04, -8.0234e-05,\n              4.2295e-05,  3.0346e-06,  3.0646e-04, -1.7263e-04,  1.6308e-04,\n              1.1966e-04, -1.0603e-04, -2.5198e-05, -2.8259e-04, -2.7782e-04,\n              1.4874e-04,  5.9110e-05, -6.8588e-06, -9.1437e-08, -2.7142e-04,\n              2.0522e-04, -1.4630e-04,  5.2084e-05, -2.8273e-04,  1.1408e-04,\n             -1.4874e-04,  4.1160e-05, -2.7222e-05, -2.6684e-04,  1.7713e-04,\n              3.8148e-05, -2.2626e-04,  1.1869e-04,  1.9311e-04, -2.2130e-04,\n              5.5281e-05, -1.7314e-04]),\n     'exp_avg_sq': tensor([6.0452e-08, 5.8431e-08, 2.0809e-08, 9.1768e-08, 6.7197e-08, 2.8947e-08,\n             5.9931e-08, 6.6172e-08, 2.3469e-08, 2.0815e-08, 1.5039e-07, 7.3466e-08,\n             8.6369e-08, 8.2878e-09, 5.2946e-08, 6.6853e-08, 3.9127e-08, 9.2570e-08,\n             2.8663e-08, 7.2481e-08, 7.4504e-08, 4.0663e-08, 9.8242e-09, 3.2047e-08,\n             2.7225e-08, 9.1683e-08, 2.5531e-08, 8.4744e-08, 9.6647e-08, 1.2222e-07,\n             6.1880e-08, 2.4020e-08, 1.0462e-07, 1.3203e-07, 8.6041e-08, 6.2400e-08,\n             6.9887e-08, 1.5620e-07, 7.3984e-08, 1.0657e-07, 1.2763e-07, 4.0258e-08,\n             1.1256e-07, 2.3998e-08, 3.8615e-08, 1.5947e-08, 9.0216e-08, 3.7332e-08,\n             7.4900e-08, 1.7759e-08, 3.6901e-08, 4.8532e-08, 4.3963e-08, 4.5285e-08,\n             1.6569e-08, 9.9246e-08, 9.6274e-08, 1.1279e-07, 1.8449e-08, 2.8127e-08,\n             3.3322e-08, 2.4336e-08, 7.2334e-08, 3.1102e-08, 7.4435e-08, 3.2300e-08,\n             3.7558e-08, 8.1409e-08, 3.2611e-08, 4.2049e-08, 6.7718e-08, 4.7861e-08,\n             6.9672e-08, 2.2313e-08, 1.0406e-07, 3.9005e-08, 8.7250e-08, 8.5778e-08,\n             9.7054e-08, 5.2875e-08, 2.7292e-08, 2.5775e-08, 1.2518e-07, 8.5895e-08,\n             8.7315e-08, 5.7004e-08, 9.5573e-08, 1.7453e-08, 1.0485e-07, 1.1935e-07,\n             4.6515e-08, 4.9902e-08, 1.0726e-07, 3.4415e-08, 3.4443e-08, 6.5425e-08,\n             5.4829e-08, 1.9910e-08, 7.7629e-08, 8.3969e-08, 2.3169e-08, 4.3865e-08,\n             7.6185e-08, 3.3797e-08, 5.7422e-08, 7.1598e-08, 1.2019e-07, 5.0264e-08,\n             2.3761e-08, 5.8713e-08, 3.5090e-08, 1.7429e-08, 6.6858e-08, 9.4047e-08,\n             3.4890e-08, 7.4440e-08, 7.7820e-08, 3.1664e-08, 1.1600e-08, 3.4070e-08,\n             3.7385e-08, 2.3618e-08, 3.6384e-08, 6.7669e-08, 2.6484e-08, 2.4928e-08,\n             3.6364e-08, 6.9132e-08, 2.6979e-08, 4.9390e-08, 6.1710e-08, 1.5146e-07,\n             7.8979e-08, 4.2880e-08, 1.0763e-07, 6.9903e-08, 3.7492e-08, 1.6811e-07,\n             4.3499e-08, 3.2445e-08, 8.5054e-08, 1.0491e-07, 4.6092e-08, 2.2042e-08,\n             2.5186e-08, 7.8846e-09, 9.4724e-08, 7.9896e-08, 7.8806e-08, 1.6572e-08,\n             1.6211e-07, 6.3870e-08, 5.8859e-08, 2.7761e-08, 1.5278e-07, 1.2686e-07,\n             8.0990e-08, 1.1768e-07, 2.4955e-08, 7.0676e-08, 2.5664e-08, 2.1592e-08,\n             5.1926e-08, 2.0934e-07, 3.8513e-08, 2.8456e-08, 2.6176e-08, 1.6377e-08,\n             2.1889e-08, 2.7060e-08, 3.7766e-08, 2.5263e-08, 3.9689e-08, 1.0407e-07,\n             2.4006e-08, 5.0951e-08, 1.0324e-07, 8.4623e-08, 2.4506e-08, 5.7142e-08,\n             4.4352e-08, 2.6566e-08, 7.5414e-08, 2.9717e-08, 7.7006e-08, 1.2169e-07,\n             6.4979e-08, 3.0148e-08, 1.2715e-07, 2.3430e-08, 4.9101e-08, 8.4892e-08,\n             4.7543e-08, 6.0377e-08, 2.5572e-08, 3.5854e-08, 3.6525e-08, 2.7817e-08,\n             5.3622e-08, 4.8902e-08, 1.1567e-07, 8.3247e-08, 2.6144e-08, 7.5987e-08,\n             7.6632e-08, 1.2737e-07, 2.4422e-08, 9.8337e-08, 4.0784e-08, 4.7620e-08,\n             4.1574e-08, 3.0437e-08, 2.2101e-08, 3.6210e-08, 2.4692e-08, 6.0186e-08,\n             1.4766e-07, 4.2292e-08, 3.6906e-08, 3.4409e-08, 2.0801e-08, 2.9264e-08,\n             3.8731e-08, 7.4955e-08, 3.0202e-08, 2.6794e-08, 4.9984e-08, 3.1931e-08,\n             2.4445e-08, 8.3430e-08, 6.5839e-08, 6.6999e-08, 3.8228e-08, 1.6131e-07,\n             2.5299e-07, 3.6894e-08, 3.2619e-08, 2.8822e-08, 1.0855e-07, 2.3858e-08,\n             5.2255e-08, 8.4254e-08, 8.9874e-08, 4.1396e-08, 7.8684e-08, 8.0079e-08,\n             7.5027e-08, 4.4837e-08, 1.7047e-07, 1.1216e-07, 3.1658e-08, 3.4269e-08,\n             7.5934e-08, 7.9451e-08, 2.3119e-08, 2.9174e-08, 9.8796e-08, 6.4151e-08,\n             8.4942e-08, 1.8899e-07, 7.7549e-08, 2.7903e-08, 7.1079e-08, 6.3292e-08,\n             1.1172e-07, 3.7115e-08, 4.8766e-08, 1.0011e-07, 9.4384e-08, 6.6958e-08,\n             7.4026e-08, 3.1433e-08, 2.1277e-08, 1.6055e-08, 1.5141e-07, 1.5406e-07,\n             2.2201e-08, 4.8019e-08, 1.1567e-07, 2.8481e-08, 7.9111e-08, 1.0378e-07,\n             2.2345e-08, 8.0873e-08, 3.0478e-08, 2.8666e-08, 3.9551e-08, 1.7571e-07,\n             1.0609e-07, 6.4306e-08, 1.1094e-07, 3.8221e-08, 1.0282e-07, 2.0711e-08,\n             1.9724e-08, 1.1438e-07, 5.1470e-08, 7.0340e-08, 1.3278e-08, 1.3511e-07,\n             2.5134e-08, 8.9766e-08, 4.8218e-08, 3.5411e-08, 2.7649e-08, 1.1407e-07,\n             3.7824e-08, 1.1995e-07, 5.5417e-08, 1.1387e-07, 7.4332e-08, 1.1982e-07,\n             1.1912e-07, 4.3430e-08, 3.2631e-08, 1.2250e-07, 1.7063e-08, 1.1342e-08,\n             1.1329e-07, 1.6016e-08, 2.0097e-08, 1.1503e-07, 7.2878e-08, 9.5933e-08,\n             4.5088e-08, 3.3135e-08, 3.1176e-08, 3.1919e-08, 1.2419e-07, 1.0471e-07,\n             2.1784e-07, 5.4789e-08, 2.6053e-08, 1.1011e-07, 3.8054e-08, 2.1832e-08,\n             3.8681e-08, 5.0630e-08, 2.2123e-08, 1.3155e-07, 7.1997e-08, 5.1347e-08,\n             6.1130e-08, 2.9844e-08, 3.4149e-08, 9.9945e-08, 2.7199e-08, 2.8052e-08,\n             7.7390e-08, 9.7215e-08, 2.8573e-08, 6.5696e-08, 1.1031e-07, 1.0695e-07,\n             2.1328e-08, 3.5060e-08, 3.4870e-08, 8.0097e-08, 4.0413e-08, 2.6510e-08,\n             3.5532e-08, 7.2887e-08, 4.6390e-08, 7.4470e-08, 5.8430e-08, 3.0016e-08,\n             1.2372e-07, 3.6080e-08, 9.1709e-08, 1.5184e-07, 1.2155e-07, 8.1271e-08,\n             2.0645e-08, 6.3956e-08, 5.0194e-08, 1.0436e-08, 5.0598e-08, 7.0017e-08,\n             3.3596e-08, 1.0284e-07, 4.2168e-08, 1.0727e-07, 2.9076e-08, 5.7399e-08,\n             1.9930e-08, 4.0753e-08, 3.0787e-08, 3.0706e-08, 5.9673e-08, 3.9768e-08,\n             1.4793e-07, 7.1962e-08, 2.6295e-08, 3.2433e-08, 3.2712e-08, 3.3992e-08,\n             6.6098e-08, 4.5336e-08, 3.0951e-08, 1.0557e-07, 3.4388e-08, 4.1603e-08,\n             4.6512e-08, 2.4996e-08, 4.6475e-08, 1.0338e-07, 3.5254e-08, 3.6937e-08,\n             3.1511e-08, 8.1431e-08, 2.4718e-08, 1.4802e-07, 3.4155e-08, 3.6902e-08,\n             4.1970e-08, 6.3752e-08, 2.4238e-08, 6.4318e-08, 9.4136e-08, 6.4786e-08,\n             1.5701e-08, 1.2153e-08, 3.3941e-08, 4.1024e-08, 4.2094e-08, 2.5982e-08,\n             2.1571e-08, 3.5144e-08, 9.3670e-08, 3.6974e-08, 5.1832e-08, 2.3593e-08,\n             4.3845e-08, 3.0825e-08, 3.3751e-08, 5.2721e-08, 1.1588e-07, 6.0027e-08,\n             9.7034e-08, 2.3215e-08, 3.5441e-08, 1.4886e-07, 6.1625e-08, 9.8637e-08,\n             2.7521e-08, 1.1675e-07, 2.6771e-08, 4.7742e-08, 7.5809e-08, 7.0085e-08,\n             4.4082e-08, 5.6699e-08, 3.0471e-08, 3.5179e-08, 4.1337e-08, 2.4972e-08,\n             1.0019e-07, 3.6206e-08, 1.5906e-08, 1.1059e-07, 4.8777e-08, 3.9600e-08,\n             2.0178e-08, 3.9619e-08, 2.2833e-08, 3.9132e-08, 8.2949e-08, 1.0222e-07,\n             1.9754e-08, 9.2926e-08, 3.8748e-08, 4.4617e-08, 4.9940e-08, 6.6342e-08,\n             2.6560e-08, 6.0464e-08, 5.3221e-08, 3.3553e-08, 8.6912e-08, 1.5745e-07,\n             1.2682e-07, 2.1301e-08, 7.9732e-08, 1.2638e-07, 1.6120e-08, 2.3792e-08,\n             3.2529e-08, 4.0141e-08, 6.0510e-08, 1.1258e-07, 4.5553e-08, 4.8046e-08,\n             4.5524e-08, 7.8379e-08, 1.1704e-07, 5.0972e-08, 8.9287e-08, 1.0809e-07,\n             5.4605e-08, 5.1424e-08, 3.0643e-08, 5.4540e-08, 2.8816e-08, 1.0527e-07,\n             1.1835e-07, 2.8592e-08, 6.2660e-08, 3.0924e-08, 5.7014e-08, 2.0024e-08,\n             2.6490e-08, 7.5515e-08])},\n    35: {'exp_avg': tensor([-1.3872e-06,  1.5595e-06, -2.2128e-06, -4.2248e-05, -7.1570e-06,\n             -2.4415e-05,  1.0710e-05,  5.6479e-05,  7.4748e-06,  7.3919e-05,\n             -5.1196e-06,  2.7497e-05, -2.2251e-05, -9.8490e-06, -1.3993e-04,\n             -7.8248e-05,  1.8078e-04,  1.7295e-05,  3.1432e-06, -3.7076e-05,\n              5.5103e-05, -5.8191e-05,  4.7810e-06, -7.3214e-06, -4.1069e-05,\n             -1.7776e-06, -1.3547e-07,  2.1577e-05, -1.5188e-05, -4.3220e-07,\n             -1.6641e-05, -2.2813e-05,  2.5775e-05, -1.6829e-04, -2.0024e-05,\n             -6.7063e-09,  3.1575e-06, -4.5958e-06, -2.5910e-05,  1.5190e-05,\n              7.8856e-06, -4.4223e-05, -2.1214e-05, -2.3509e-05, -4.3034e-11,\n             -7.3456e-05,  3.0169e-05, -3.3065e-05,  1.0862e-05,  1.5103e-05,\n              2.5953e-05,  1.6148e-05,  3.9907e-06, -9.4043e-05,  3.0604e-05,\n             -1.4440e-07,  3.5524e-05,  6.9986e-06,  2.6743e-05,  1.2397e-04,\n              6.4079e-05, -4.0289e-05,  2.4748e-05, -8.1785e-05,  7.9606e-06,\n             -5.0419e-06,  8.7498e-05, -1.6096e-05,  3.8986e-05,  5.6618e-11,\n             -5.4021e-05,  1.0245e-06, -1.5631e-05,  5.1204e-05, -4.4819e-05,\n              1.0936e-04, -7.1825e-05,  2.0932e-04,  1.8937e-06,  8.0248e-05,\n             -1.0232e-04,  4.7411e-05,  8.7334e-05, -8.2167e-05, -1.4097e-06,\n              4.8981e-05,  4.0945e-05,  2.3551e-05, -6.1027e-07, -9.5949e-05,\n             -2.9630e-05, -3.5038e-05, -7.2980e-06,  7.8171e-11, -1.7441e-05,\n             -1.1294e-04,  1.9527e-05, -1.7317e-07, -2.5361e-05, -3.7021e-05,\n              3.8992e-05, -1.8406e-05, -3.4340e-05,  2.8905e-04,  6.6781e-06,\n             -2.6156e-05,  5.4921e-06, -6.0911e-05,  7.1211e-05, -1.7967e-04,\n              3.8214e-05,  5.4463e-05,  1.5232e-05,  6.7821e-06, -5.9005e-05,\n             -2.3178e-05, -1.7414e-05,  6.0753e-05,  1.7383e-05,  1.5260e-05,\n             -5.9035e-05,  5.2043e-05, -7.7360e-07, -7.4722e-05,  1.0510e-06,\n              9.2854e-05,  5.1394e-05,  2.8900e-05,  1.5574e-08,  8.9776e-05,\n             -1.5382e-05, -2.8244e-05,  5.4193e-05, -3.8290e-11, -4.3381e-05,\n             -1.6138e-06, -3.9198e-05,  6.5096e-08, -5.8188e-05,  4.6188e-05,\n             -5.8096e-06,  2.4078e-05, -9.7884e-05, -2.5065e-04, -2.2276e-05,\n             -7.3908e-05, -1.7939e-04, -2.0983e-06, -1.9440e-05,  6.6434e-05,\n              1.3807e-05,  1.1781e-04, -2.6865e-05,  9.0183e-05,  3.3988e-06,\n             -3.1587e-06,  1.0047e-04, -5.3666e-06, -7.3046e-05,  8.9061e-05,\n              4.3099e-05, -3.5741e-05, -1.3079e-05, -2.6289e-08,  6.2294e-05,\n             -3.7142e-05,  1.5277e-05,  2.9292e-05, -2.3627e-07,  7.8724e-05,\n              4.3015e-06,  2.3441e-05,  9.4092e-05,  4.6175e-11,  4.3669e-06,\n              1.5278e-05, -1.9836e-05, -3.2115e-05, -7.0695e-06,  3.0566e-06,\n              2.0163e-05,  6.6147e-05,  4.2268e-05, -3.1880e-08,  1.6122e-07,\n              1.1305e-05,  1.6388e-05,  9.3900e-05,  6.3050e-06, -7.0449e-05,\n              2.8034e-05,  5.4330e-06, -2.7908e-05,  4.4344e-05,  1.1784e-06,\n             -2.0788e-05,  7.3725e-05,  8.9610e-05,  5.9896e-05, -4.9626e-05,\n             -1.7913e-05, -3.2208e-06,  1.3757e-05,  6.8895e-08, -1.7294e-04,\n             -6.9092e-06,  4.2721e-05, -8.5674e-06, -2.5314e-05,  2.0148e-06,\n              9.8893e-07,  1.2284e-05,  6.7293e-05,  8.7064e-05, -1.6340e-05,\n              1.5615e-05,  1.5305e-05, -2.4495e-05,  5.7923e-05, -4.5328e-05,\n              2.9733e-05, -5.1641e-05, -7.2006e-05, -7.4733e-05, -9.1542e-06,\n              1.0815e-04, -4.4872e-05, -1.5065e-05, -1.2186e-04,  1.2330e-05,\n             -6.2475e-05,  1.2246e-04, -4.4584e-05, -5.8704e-07, -7.3146e-05,\n             -3.5746e-05,  1.5728e-05, -9.6781e-05,  1.3300e-05, -4.8777e-05,\n              3.1787e-05, -2.3424e-04, -1.9615e-06, -1.2113e-04,  6.9276e-06,\n             -1.6500e-05,  8.5418e-06,  7.0102e-05, -2.3038e-06, -1.9955e-05,\n             -1.0127e-04,  6.4693e-06,  1.6646e-05, -1.4136e-05,  5.3529e-06,\n              2.2592e-05,  4.5980e-05,  2.6562e-06, -3.1171e-05,  1.4387e-06,\n             -1.0961e-04,  2.3282e-11, -6.2518e-05,  9.7832e-06,  3.9981e-05,\n              2.9001e-05, -1.0116e-09, -1.5518e-05, -9.0661e-06,  7.9940e-07,\n              1.4284e-05,  3.7877e-05,  2.2842e-04, -3.4634e-06,  4.1845e-06,\n             -4.4611e-06, -3.2681e-05,  8.0413e-06,  5.2242e-06, -6.7390e-05,\n             -7.6435e-06, -6.1527e-06,  3.2020e-05,  1.7714e-06, -3.8655e-06,\n             -1.5261e-04,  1.2802e-04,  2.4991e-05, -1.0234e-04,  9.0977e-07,\n              3.6369e-04,  9.6891e-11,  8.4332e-06,  4.2358e-05, -1.8846e-04,\n              5.9789e-06,  6.7567e-08, -5.9953e-05,  3.0768e-06, -1.7424e-05,\n             -1.0034e-04,  1.1119e-06,  3.6351e-05,  1.3431e-04, -7.9129e-07,\n              4.9400e-05,  2.1100e-05, -1.1803e-04,  3.0198e-06, -3.6235e-06,\n             -1.0948e-05,  8.3821e-05,  3.2571e-06,  1.5830e-04, -7.1971e-07,\n              4.0007e-11,  1.4393e-06,  8.7373e-05,  5.2556e-06, -1.3311e-04,\n              3.4896e-05,  1.2033e-05, -1.3253e-05, -3.9606e-06,  1.1005e-04,\n             -2.4814e-05,  3.1581e-05,  3.3683e-05, -2.9722e-06, -2.1222e-05,\n              2.5189e-11,  4.3108e-05, -1.3484e-04, -3.8658e-06,  1.0104e-04,\n              5.5041e-06,  6.4387e-05, -9.8762e-05,  2.3165e-05, -1.7900e-05,\n             -8.4734e-05,  2.2487e-06,  1.6951e-04, -7.3229e-05, -4.3293e-05,\n              1.4188e-05, -1.4482e-05, -9.8700e-05, -1.3494e-05, -1.7104e-04,\n             -4.4063e-05, -1.1605e-05, -1.1037e-04, -4.1745e-07, -1.2524e-04,\n             -2.9517e-05, -5.2368e-05,  1.0905e-04,  2.5131e-07, -4.9540e-05,\n              9.0729e-05, -1.6112e-05, -9.2012e-05,  5.8009e-08, -7.9365e-06,\n             -9.5068e-06,  3.9780e-07, -8.7364e-07,  1.1147e-04,  4.5551e-05,\n             -1.6795e-05, -1.0985e-05, -7.8725e-07,  2.7649e-05,  4.0049e-06,\n              3.3657e-05,  1.4617e-05,  9.4005e-05, -3.0493e-05,  6.2001e-06,\n              6.3207e-06,  6.5876e-06,  1.5906e-05,  2.0219e-04,  4.3603e-05,\n              3.9057e-05, -5.0817e-05, -1.9198e-07, -8.5503e-05, -5.8935e-05,\n             -2.3495e-10,  2.6268e-05,  3.5793e-05, -1.1466e-04,  2.2790e-04,\n              6.8789e-05, -2.4229e-05,  1.0500e-05, -3.8019e-05,  4.6389e-05,\n             -2.2451e-05,  1.0950e-05,  7.3160e-05,  6.0953e-05,  2.2702e-06,\n              4.5575e-05, -1.1405e-05,  8.8315e-05, -2.4415e-05, -3.9678e-08,\n              1.8299e-07,  2.1802e-06, -3.7653e-05,  5.0711e-05, -3.3312e-05,\n             -3.7657e-05, -2.0138e-05, -1.4627e-04, -2.5408e-05,  1.3550e-05,\n              2.8079e-06,  1.1121e-04,  1.8875e-06,  6.0033e-05,  7.6037e-07,\n             -1.6989e-07,  1.1843e-04,  4.4980e-05,  6.6490e-05, -2.3713e-04,\n             -1.4529e-04,  4.4020e-05, -8.8324e-05,  5.9692e-06,  2.7203e-05,\n             -2.8008e-07, -1.6429e-05, -1.3995e-05,  5.0539e-06,  1.5235e-04,\n              1.2337e-07,  1.1761e-07, -8.0082e-05, -1.0845e-05,  3.4036e-05,\n              3.3858e-04,  5.1131e-05,  9.3082e-06,  4.2645e-05, -1.8541e-05,\n             -6.3484e-05, -5.3331e-05,  2.8530e-06, -1.3366e-04,  7.8036e-05,\n             -1.1151e-04, -5.2988e-06,  1.9577e-05, -6.8804e-05, -1.0106e-04,\n              6.4329e-05, -9.2933e-05, -3.7942e-05, -2.1165e-06, -1.2138e-04,\n             -2.6573e-05, -4.0578e-05,  4.6730e-05,  1.6397e-04, -7.2613e-06,\n              3.2003e-06,  2.3600e-11,  6.7885e-06,  9.1835e-06,  2.0494e-05,\n              2.9865e-07,  7.5740e-11,  7.6189e-05, -2.2022e-06,  1.1347e-05,\n              7.8194e-07, -1.5023e-05,  2.0875e-05, -5.9228e-05,  3.7644e-05,\n             -2.5747e-05,  7.6022e-05, -1.2344e-05,  1.2834e-05, -2.3169e-06,\n              2.8430e-06,  7.0101e-07, -4.3272e-06, -2.8582e-06, -9.7882e-06,\n             -8.8565e-10, -3.1641e-06,  1.3562e-06,  1.7008e-04,  2.2663e-04,\n             -1.0534e-05, -5.8754e-05,  1.8303e-05,  3.5055e-05,  5.9767e-06,\n             -1.1891e-04, -7.9157e-05, -9.0504e-06,  3.6563e-05,  6.6507e-05,\n             -1.0999e-07,  1.5205e-06]),\n     'exp_avg_sq': tensor([5.6992e-10, 8.8925e-09, 3.5092e-11, 5.0022e-08, 2.3082e-11, 1.5616e-08,\n             1.4855e-08, 3.6077e-09, 1.1234e-08, 1.1337e-08, 1.5365e-09, 6.0940e-09,\n             1.4481e-09, 2.3131e-09, 3.6187e-08, 4.2254e-08, 1.7227e-08, 2.1760e-09,\n             2.1303e-08, 8.8811e-10, 3.6346e-08, 2.7654e-08, 2.6283e-10, 1.5637e-08,\n             2.9217e-08, 5.8762e-10, 6.0015e-12, 3.1362e-10, 2.4433e-09, 1.6533e-10,\n             3.4085e-10, 1.4315e-09, 4.6968e-08, 4.0627e-08, 2.6982e-10, 3.0082e-14,\n             6.2435e-10, 1.5420e-09, 4.1551e-08, 9.1405e-10, 2.2179e-10, 1.7872e-08,\n             3.8474e-10, 1.4749e-09, 4.1347e-20, 1.3339e-08, 5.0822e-09, 2.0153e-08,\n             5.0910e-10, 1.4529e-08, 1.6914e-08, 4.9793e-10, 5.7434e-11, 2.3861e-08,\n             1.5256e-09, 1.2656e-09, 3.1325e-08, 2.3693e-10, 1.1773e-08, 2.2943e-08,\n             1.3412e-08, 4.2502e-08, 5.7368e-08, 1.7209e-08, 3.6409e-10, 1.8408e-08,\n             2.3703e-08, 7.5651e-10, 1.9601e-08, 3.2503e-15, 3.6275e-08, 4.5212e-10,\n             1.3270e-08, 1.6811e-08, 1.8328e-08, 3.0466e-08, 2.0552e-08, 3.6932e-08,\n             3.0422e-10, 9.8559e-09, 1.5342e-08, 1.0886e-08, 3.8235e-09, 1.7796e-09,\n             9.9861e-10, 5.0796e-09, 2.0780e-08, 1.3551e-08, 2.3402e-10, 1.1072e-08,\n             1.6618e-08, 4.0862e-08, 2.0384e-10, 1.9734e-20, 1.9934e-08, 6.1395e-09,\n             3.1434e-08, 1.8397e-11, 9.8768e-09, 2.6218e-08, 1.8798e-08, 1.8994e-08,\n             1.7161e-08, 2.3443e-08, 8.4297e-10, 2.4983e-09, 1.0215e-09, 1.4725e-09,\n             1.5083e-08, 5.5383e-08, 1.6692e-08, 1.7831e-08, 2.3169e-08, 9.5062e-10,\n             1.5536e-08, 4.2196e-08, 5.0122e-10, 2.5194e-08, 5.8809e-09, 1.7771e-08,\n             1.7467e-08, 1.2613e-08, 1.9389e-10, 2.0960e-08, 1.0139e-10, 3.9617e-09,\n             1.2619e-08, 3.9889e-09, 1.2773e-14, 1.5178e-08, 3.2651e-08, 8.4739e-10,\n             2.8306e-09, 3.8429e-20, 1.0936e-09, 6.5099e-09, 1.7593e-08, 2.4280e-13,\n             1.4716e-08, 1.3341e-08, 4.5038e-10, 1.4906e-09, 2.1307e-08, 3.1754e-08,\n             2.3093e-08, 2.1521e-08, 4.7041e-08, 8.6242e-12, 3.9455e-09, 1.0527e-08,\n             2.6534e-10, 2.7926e-08, 3.2615e-09, 1.3661e-08, 1.5515e-09, 1.1858e-09,\n             1.2307e-08, 1.3230e-10, 1.6045e-08, 4.0223e-08, 1.1090e-08, 2.1651e-09,\n             5.4257e-09, 2.1963e-13, 3.0465e-08, 1.4594e-08, 1.9959e-08, 1.4217e-08,\n             3.3463e-12, 2.4956e-08, 1.4566e-10, 1.3260e-08, 3.7511e-08, 1.6573e-20,\n             1.1628e-08, 7.9687e-09, 4.5709e-10, 1.8895e-09, 1.3538e-08, 3.7648e-08,\n             1.9585e-08, 1.5492e-08, 2.8914e-08, 4.4117e-15, 1.0619e-11, 4.1872e-10,\n             2.7663e-09, 2.7046e-08, 2.7851e-10, 1.0546e-07, 1.8533e-08, 2.7292e-09,\n             1.2697e-08, 3.3144e-09, 9.8670e-12, 1.4473e-08, 1.4300e-08, 8.7575e-09,\n             1.4573e-08, 2.4797e-08, 7.3925e-10, 2.9385e-10, 2.4946e-08, 1.3484e-13,\n             4.6375e-08, 2.0441e-10, 1.2584e-08, 3.1829e-11, 1.6010e-08, 2.3176e-12,\n             2.3894e-08, 2.4697e-08, 1.3123e-08, 1.8353e-08, 1.7273e-08, 3.6526e-08,\n             1.6907e-08, 1.3925e-08, 1.7151e-08, 3.3606e-08, 1.7853e-08, 1.3144e-08,\n             1.1682e-08, 1.5364e-08, 3.0985e-09, 1.3561e-08, 2.7196e-08, 1.5867e-08,\n             2.6065e-08, 7.4094e-10, 2.3432e-08, 3.5724e-08, 1.5438e-08, 2.3822e-10,\n             6.5222e-09, 2.1448e-08, 1.2742e-08, 1.6493e-08, 3.3273e-10, 1.4788e-08,\n             2.3004e-08, 5.1754e-08, 7.5466e-12, 2.4155e-08, 2.4808e-10, 5.3095e-10,\n             3.7620e-10, 2.5006e-08, 1.3536e-10, 4.9900e-10, 1.6083e-08, 2.8156e-08,\n             5.3612e-10, 2.3472e-09, 2.1113e-08, 1.6741e-08, 7.6751e-09, 4.2631e-08,\n             3.0615e-08, 7.2013e-09, 1.0123e-08, 1.5699e-20, 3.6121e-08, 5.0738e-10,\n             1.9667e-08, 4.6270e-09, 3.6421e-13, 6.5097e-10, 1.4743e-10, 3.2328e-08,\n             4.9370e-08, 2.1217e-08, 1.6738e-08, 1.8306e-10, 9.3294e-11, 2.7610e-10,\n             1.5908e-08, 1.2958e-10, 5.3130e-08, 1.7112e-08, 9.1422e-10, 3.9880e-09,\n             1.2859e-08, 8.0751e-13, 1.9171e-10, 1.4921e-08, 1.9582e-08, 5.0396e-10,\n             6.3354e-08, 8.3202e-11, 1.4152e-07, 2.4808e-20, 6.0758e-10, 1.2427e-08,\n             1.6101e-08, 3.1895e-08, 2.6589e-14, 2.4667e-08, 4.9496e-10, 9.1667e-10,\n             1.4442e-08, 2.5970e-10, 2.0401e-08, 1.8411e-08, 1.4938e-08, 3.7899e-09,\n             3.4481e-08, 5.3784e-08, 7.3955e-09, 1.4352e-10, 2.2118e-10, 4.2713e-08,\n             7.2659e-10, 3.2651e-08, 3.3763e-11, 2.2845e-16, 1.4610e-08, 1.3265e-08,\n             6.2024e-10, 1.9716e-08, 3.0470e-08, 2.1120e-09, 4.7816e-10, 1.5436e-10,\n             1.7927e-08, 3.8596e-08, 1.4507e-08, 9.7394e-09, 4.8276e-09, 1.0064e-09,\n             3.4281e-20, 2.8545e-08, 2.4092e-08, 4.3883e-10, 1.5458e-08, 1.4074e-09,\n             2.7990e-08, 5.2353e-08, 1.5394e-08, 1.7836e-09, 3.9455e-08, 2.4958e-11,\n             3.6831e-08, 1.5502e-08, 1.7540e-08, 7.7893e-10, 1.7641e-08, 1.3423e-08,\n             1.1996e-09, 3.3517e-08, 1.5262e-08, 1.7647e-09, 4.5984e-08, 1.2917e-12,\n             2.2355e-08, 2.5162e-08, 3.7360e-08, 2.9590e-08, 2.7773e-12, 2.0289e-08,\n             2.9982e-08, 3.2853e-08, 2.1961e-08, 4.9434e-14, 2.9271e-08, 3.6246e-08,\n             1.9764e-12, 1.6501e-08, 2.1190e-08, 6.4544e-08, 1.0896e-09, 1.8445e-08,\n             7.1844e-13, 1.0787e-09, 1.1949e-09, 1.4909e-08, 2.7390e-09, 2.2638e-08,\n             3.2925e-08, 3.6623e-10, 1.4690e-08, 6.2573e-09, 1.5594e-08, 4.1182e-08,\n             1.2708e-08, 3.3492e-08, 1.3234e-08, 1.4585e-13, 4.3059e-08, 2.2925e-08,\n             2.4799e-13, 1.3890e-09, 2.0020e-09, 3.1027e-08, 6.0825e-08, 1.4666e-08,\n             5.1150e-09, 1.4445e-09, 1.2697e-08, 1.9025e-08, 1.9483e-08, 1.3783e-08,\n             3.9310e-08, 1.1250e-08, 2.1311e-08, 1.5505e-09, 1.4001e-10, 1.3668e-08,\n             3.2933e-08, 3.1285e-14, 7.0282e-13, 1.0419e-11, 2.0315e-08, 2.1307e-08,\n             1.8269e-08, 1.4148e-09, 2.0708e-08, 2.8421e-08, 9.7745e-10, 7.3982e-10,\n             1.5901e-08, 1.8866e-08, 2.0427e-11, 1.6231e-08, 1.0309e-09, 1.8574e-11,\n             1.6747e-08, 2.6635e-08, 1.4571e-08, 2.4201e-08, 1.7835e-08, 1.5863e-08,\n             2.2229e-08, 2.2297e-10, 2.2434e-08, 1.3113e-10, 1.7249e-10, 8.0909e-10,\n             5.2515e-10, 3.2693e-08, 2.0303e-08, 1.0428e-11, 3.8454e-08, 1.3991e-09,\n             1.8142e-08, 7.6168e-08, 1.7229e-08, 1.6948e-08, 2.7074e-09, 2.2026e-09,\n             2.2911e-08, 1.3643e-08, 9.2823e-11, 2.0115e-08, 1.4878e-08, 1.1046e-08,\n             1.3299e-09, 5.0783e-10, 3.5180e-09, 3.6332e-08, 3.8233e-09, 2.0892e-08,\n             1.1921e-08, 4.5080e-10, 3.8987e-08, 1.6104e-09, 3.3179e-08, 1.1060e-09,\n             1.4983e-08, 3.1958e-10, 2.0282e-08, 1.5363e-20, 1.9039e-08, 3.7216e-09,\n             2.1892e-08, 1.0118e-11, 1.6260e-16, 3.0325e-08, 6.3755e-10, 1.2617e-10,\n             1.2493e-10, 5.7288e-10, 3.0834e-08, 4.6082e-09, 3.1585e-08, 1.1789e-08,\n             1.7886e-08, 1.6988e-08, 1.0710e-09, 1.5266e-11, 2.2781e-08, 1.6408e-10,\n             1.5019e-08, 1.0836e-09, 8.7197e-11, 5.4406e-16, 1.2458e-09, 8.0173e-12,\n             3.2248e-08, 2.4110e-08, 1.6933e-08, 2.8911e-08, 1.7638e-08, 2.3936e-09,\n             2.2792e-10, 1.2523e-08, 4.3545e-08, 9.0827e-10, 5.2329e-08, 1.3641e-08,\n             4.3653e-11, 2.3904e-09])},\n    36: {'exp_avg': tensor([-1.6117e-04, -2.4917e-04, -1.2277e-04,  2.1007e-04,  2.3638e-05,\n              5.4576e-05,  1.0215e-05,  1.6691e-04, -9.8556e-04,  1.4394e-04,\n              7.5829e-04, -1.2251e-04, -5.8533e-04,  3.5547e-04,  2.7525e-04,\n              1.2666e-04, -7.0667e-05,  5.1960e-05,  7.0469e-05,  1.9799e-04,\n             -1.6125e-04,  6.3223e-05, -8.7286e-05, -7.3632e-05,  1.0851e-04,\n              5.0736e-04, -2.0981e-04, -4.3937e-06,  1.3925e-05,  4.2206e-05,\n              7.6618e-05,  3.3164e-05, -2.8295e-04, -1.0073e-05, -1.7145e-04,\n             -5.0340e-05, -9.6996e-05,  4.8471e-04, -9.0512e-05, -4.1380e-05,\n              3.4065e-05, -7.3172e-05, -5.1149e-04, -1.9719e-04,  1.6707e-04,\n             -1.1864e-05, -2.4626e-04, -3.7367e-05, -9.3716e-05, -5.7530e-04,\n              1.2516e-06,  2.0015e-04, -1.1640e-05, -1.7118e-05,  2.4872e-04,\n              1.9002e-04,  1.5779e-05, -2.0646e-04,  9.7336e-05,  2.2157e-05,\n              4.6284e-04, -3.9295e-05, -4.5504e-05,  1.0008e-04, -4.8962e-05,\n              5.2561e-05,  2.4266e-04,  2.5399e-04, -5.2643e-04, -1.7484e-04,\n             -2.5219e-05, -2.7394e-05, -1.3773e-04,  5.9962e-04,  1.4105e-04,\n             -3.7735e-05,  3.4024e-04, -2.9544e-04, -1.2929e-05, -2.8697e-05,\n             -2.0565e-04,  1.8738e-05,  1.3803e-03, -2.7419e-06, -9.7420e-05,\n              1.3889e-04,  4.3737e-04,  4.6199e-04,  1.1371e-04, -2.4395e-04,\n             -5.9903e-05, -2.7148e-04, -1.5323e-04, -1.3429e-04,  1.6166e-04,\n              1.2751e-05,  1.9734e-04, -2.1359e-04,  7.5457e-05,  8.6707e-05,\n             -8.8766e-05, -7.3356e-05, -4.2738e-05, -1.5237e-04,  4.5619e-05,\n             -2.9863e-04,  2.5128e-04,  4.2970e-05, -5.2524e-05, -1.8003e-04,\n             -4.3851e-05, -3.7846e-04, -2.2632e-05,  1.9543e-04, -1.8017e-04,\n             -8.5542e-06,  1.1516e-04,  1.2437e-04, -5.0639e-04, -7.0155e-04,\n             -8.5154e-08,  1.1410e-04,  3.8256e-05, -4.0022e-04, -3.7229e-05,\n             -8.8443e-05, -1.4701e-04,  6.0418e-04]),\n     'exp_avg_sq': tensor([1.2392e-07, 2.3592e-07, 1.2859e-07, 1.3713e-07, 2.4307e-07, 1.3014e-07,\n             1.1636e-07, 1.9281e-07, 9.1058e-07, 2.7830e-07, 9.0468e-07, 2.2537e-07,\n             1.5365e-07, 1.7884e-07, 1.3600e-07, 9.8175e-08, 1.9294e-07, 1.0935e-07,\n             1.9237e-06, 9.1859e-08, 3.9429e-08, 1.4238e-07, 1.6558e-07, 1.3157e-07,\n             2.1943e-07, 3.2758e-07, 3.9727e-07, 4.0926e-07, 1.0586e-07, 9.1717e-08,\n             7.3427e-07, 1.8085e-07, 1.5823e-07, 1.1532e-07, 1.2114e-07, 1.1841e-07,\n             1.1507e-07, 1.3038e-07, 1.8257e-07, 1.8251e-07, 1.3810e-07, 8.3321e-08,\n             1.1865e-07, 1.7065e-07, 1.9331e-07, 9.5301e-08, 1.3096e-07, 1.1526e-07,\n             1.7205e-07, 2.3973e-07, 1.6386e-07, 2.2400e-07, 1.6954e-07, 6.3049e-07,\n             1.5006e-07, 1.5976e-07, 1.1005e-07, 2.4017e-07, 1.4956e-07, 1.9481e-07,\n             1.1140e-07, 1.3933e-07, 8.4949e-08, 1.2637e-07, 1.3425e-07, 8.2310e-08,\n             1.8706e-07, 1.6336e-07, 8.9818e-08, 1.4786e-07, 9.4534e-08, 1.2464e-07,\n             1.3819e-07, 2.4935e-07, 1.9295e-07, 7.9727e-08, 1.2939e-07, 9.0186e-08,\n             7.7332e-09, 1.0642e-07, 1.0937e-08, 2.2001e-09, 1.2012e-06, 1.9008e-07,\n             9.7958e-08, 1.9402e-07, 6.9000e-07, 1.4705e-07, 1.2216e-07, 2.2953e-07,\n             1.3086e-07, 1.3414e-07, 8.9992e-08, 1.3944e-07, 1.4880e-07, 4.9313e-07,\n             2.3793e-07, 1.0136e-07, 1.6727e-07, 1.5354e-07, 1.1571e-07, 9.9014e-08,\n             1.1888e-07, 4.1398e-07, 2.3606e-07, 1.7828e-07, 1.2777e-07, 3.3353e-08,\n             1.8728e-07, 1.3258e-07, 1.9304e-07, 2.9124e-07, 1.5622e-07, 1.5858e-07,\n             1.6662e-07, 8.6257e-08, 1.5495e-07, 1.8130e-07, 2.7865e-07, 1.4380e-07,\n             1.2605e-07, 1.0105e-07, 8.9004e-08, 2.0893e-07, 5.8591e-08, 9.3949e-08,\n             1.7775e-07, 1.9556e-07])},\n    37: {'exp_avg': tensor([ 5.8418e-05, -1.7389e-04, -4.7812e-05,  1.0498e-04,  3.2604e-05,\n              8.1148e-06, -4.5266e-05,  1.4216e-04,  5.6502e-04,  8.8539e-05,\n              4.0894e-04, -5.2175e-05, -4.1472e-04,  1.6908e-04,  6.9982e-05,\n              9.9264e-05,  2.9254e-06, -2.4989e-04, -1.2812e-04,  3.2808e-04,\n             -2.2485e-04, -2.8454e-04, -1.0337e-04,  1.1169e-04,  4.9758e-05,\n              6.7924e-05, -1.1077e-04,  2.6108e-05,  1.0034e-04,  1.9434e-04,\n              1.0841e-04,  5.3640e-04, -3.5570e-05,  6.1482e-05, -1.6221e-04,\n             -7.3164e-05, -1.1511e-05,  2.7090e-04,  2.9124e-05,  8.4128e-06,\n              1.5637e-04, -5.7856e-05, -2.6287e-04, -5.3014e-05,  6.4721e-05,\n             -8.6181e-05, -3.2761e-04, -8.0382e-06, -1.2150e-04, -3.0899e-04,\n             -1.6937e-04,  2.5098e-04,  2.3706e-04,  2.6031e-05,  2.7714e-04,\n              2.4211e-05,  1.4773e-04, -7.5274e-05,  4.0489e-05, -1.4343e-04,\n              2.7263e-04, -8.7445e-05, -4.1811e-06,  5.8950e-05,  2.2564e-05,\n              1.8571e-04,  3.2970e-05, -1.2502e-04, -3.7801e-04, -2.5051e-05,\n              4.4952e-05, -6.8220e-05, -1.6727e-05,  1.4608e-04,  7.7004e-05,\n              4.2020e-05,  1.2805e-04, -2.2315e-04, -2.0420e-05, -1.3130e-04,\n             -2.5985e-04,  2.8712e-05,  9.5359e-04,  2.5808e-05, -2.4708e-04,\n              7.4438e-05, -8.9776e-04,  1.8877e-04,  4.1364e-05, -2.6131e-04,\n             -3.8390e-05, -1.9270e-04, -8.5608e-05, -1.2406e-04,  1.1972e-04,\n             -5.5193e-06, -7.8608e-05, -2.0485e-04,  2.6364e-05, -9.8102e-05,\n             -1.1225e-04, -8.6756e-05,  6.4049e-07, -2.9054e-04, -1.2652e-04,\n             -1.5275e-04,  1.3843e-04,  8.3471e-05, -2.4489e-04, -6.2253e-05,\n             -1.5043e-04, -1.8715e-04,  7.0597e-05, -4.5065e-05, -2.1453e-04,\n             -3.0311e-05,  9.3959e-05,  2.8912e-04, -2.5266e-04, -2.8520e-04,\n              1.7446e-05,  8.9912e-05,  1.1990e-04, -4.3014e-05, -3.9865e-05,\n             -1.1465e-04, -8.7492e-05,  3.8378e-04]),\n     'exp_avg_sq': tensor([1.3313e-07, 9.3139e-08, 3.4826e-08, 9.7691e-08, 1.0205e-07, 5.7500e-08,\n             7.4200e-08, 1.0195e-07, 2.4395e-07, 7.9234e-08, 1.8809e-07, 5.6755e-08,\n             5.3533e-08, 7.3425e-08, 9.1558e-08, 5.3733e-08, 7.8841e-08, 1.5035e-07,\n             6.8754e-07, 1.1601e-07, 1.0638e-07, 1.5040e-07, 6.6131e-08, 1.1250e-07,\n             1.7332e-07, 1.4089e-07, 1.3715e-07, 8.9084e-08, 1.1654e-07, 9.6908e-08,\n             9.5239e-08, 1.2591e-07, 7.4201e-08, 4.4567e-08, 1.3406e-07, 5.4993e-08,\n             9.4549e-08, 7.5172e-08, 6.7026e-08, 3.3834e-08, 9.1293e-08, 1.3879e-07,\n             5.4614e-08, 1.3709e-07, 1.1098e-07, 1.0415e-07, 1.2451e-07, 1.3831e-07,\n             7.6206e-08, 1.0622e-07, 1.8198e-07, 1.3469e-07, 1.0839e-07, 3.3562e-07,\n             8.8146e-08, 7.5628e-08, 1.0201e-07, 1.2649e-07, 4.0326e-08, 8.2478e-08,\n             1.1443e-07, 6.1014e-08, 9.1909e-08, 5.8936e-08, 5.5672e-08, 1.2275e-07,\n             9.2014e-08, 1.1831e-07, 1.1291e-07, 1.0101e-07, 1.1411e-07, 8.5938e-08,\n             9.7005e-08, 1.4108e-07, 9.0152e-08, 1.1712e-07, 7.2518e-08, 6.7678e-08,\n             1.3782e-08, 1.2345e-07, 1.7697e-08, 2.2808e-09, 6.0560e-07, 1.3730e-07,\n             8.4208e-08, 1.3423e-07, 9.6356e-07, 6.0447e-08, 6.2247e-08, 1.3881e-07,\n             4.9372e-08, 6.6576e-08, 2.9744e-08, 3.4413e-08, 8.1047e-08, 1.9179e-07,\n             2.1000e-07, 6.8948e-08, 1.7550e-07, 1.5023e-07, 9.8078e-08, 1.6596e-07,\n             1.0370e-07, 1.7722e-07, 1.4427e-07, 8.6768e-08, 6.3663e-08, 8.2887e-08,\n             8.3107e-08, 3.6249e-08, 1.6952e-07, 1.5731e-07, 1.3672e-07, 3.0963e-07,\n             1.2224e-07, 7.3750e-08, 9.2384e-08, 1.5956e-07, 7.6447e-08, 8.9936e-08,\n             4.7170e-08, 5.7628e-08, 1.4289e-07, 4.0932e-08, 4.8212e-08, 1.1337e-07,\n             8.4512e-08, 8.9939e-08])},\n    38: {'exp_avg': tensor([-4.3297e-04, -9.2444e-05, -3.1041e-05,  3.7945e-04, -1.7335e-04,\n              3.2406e-04,  1.8967e-04,  8.7528e-05,  5.8292e-05,  1.5730e-04,\n             -3.4648e-04,  3.0891e-04,  3.5919e-04,  1.0087e-04, -2.6102e-06,\n              4.9226e-04, -2.0064e-04, -2.4344e-04,  2.3388e-04,  1.4238e-04,\n             -3.5640e-05,  1.8708e-04, -3.6284e-05, -5.9588e-04, -4.3830e-05,\n             -5.1685e-04, -1.3846e-04, -5.3416e-05,  6.4907e-05,  6.4607e-04,\n             -3.8059e-04, -1.8098e-04,  1.6793e-04,  4.0948e-04, -2.6683e-04,\n             -6.5184e-05, -3.6638e-04,  8.7234e-05,  1.1830e-04, -2.1413e-04,\n             -8.7900e-05,  5.7820e-05, -2.8548e-04, -3.4304e-04,  6.5594e-04,\n              2.7705e-04,  4.2509e-05, -2.8967e-04, -9.0684e-05,  2.0780e-04,\n              1.2821e-05,  1.3979e-04, -1.4645e-04,  3.6288e-05, -3.3950e-04,\n             -2.7239e-05, -3.2794e-04, -3.7881e-04, -1.2399e-03,  7.1454e-05,\n              1.6218e-04,  2.9709e-04, -4.7283e-05,  2.6078e-04,  2.0339e-05,\n              1.4284e-03, -1.0639e-04, -2.3215e-04,  7.4215e-05,  6.8479e-04,\n             -4.3114e-05,  7.3599e-05,  2.2086e-04,  1.6233e-04, -3.0389e-04,\n              2.2552e-04, -1.2418e-04, -4.2910e-05, -2.6219e-04,  3.4642e-04,\n              5.2544e-04,  1.2221e-04, -2.4088e-04,  3.2722e-04, -2.0506e-04,\n             -2.0548e-04, -3.6461e-04,  9.7482e-06,  1.5635e-04, -1.6431e-04,\n             -1.0332e-04, -7.5062e-04,  2.9416e-05,  3.0720e-05, -7.0230e-05,\n             -4.3832e-04, -1.5295e-04,  3.2206e-04, -2.1305e-04,  3.5313e-04,\n              7.7331e-05, -9.3111e-05, -1.2977e-04,  1.6402e-04, -1.6821e-04,\n             -3.1957e-05, -6.2007e-05, -9.6613e-05,  1.4047e-04,  2.1752e-04,\n              5.5644e-06,  2.2428e-04,  4.4395e-04, -2.2983e-04,  1.3374e-04,\n              1.9002e-05,  2.8700e-04, -2.4026e-04,  8.4004e-05,  4.8542e-05,\n             -8.6660e-05,  5.9417e-05,  1.5988e-04, -1.1696e-04,  8.6139e-05,\n              8.4489e-05,  2.0463e-04,  2.3305e-04]),\n     'exp_avg_sq': tensor([2.6550e-07, 1.1187e-07, 1.2209e-07, 1.3811e-07, 1.0793e-07, 3.3326e-07,\n             9.1010e-08, 1.1526e-07, 9.6401e-08, 1.2031e-07, 1.5145e-07, 5.7551e-08,\n             2.3720e-07, 1.6290e-07, 1.4349e-07, 1.7525e-07, 9.8115e-08, 3.0698e-07,\n             6.4921e-08, 6.0473e-07, 2.8871e-07, 8.4143e-08, 1.2782e-07, 1.3295e-07,\n             1.5433e-07, 6.3507e-07, 1.3320e-07, 2.5734e-07, 5.7164e-08, 1.6298e-07,\n             9.4817e-08, 9.8556e-08, 1.0773e-07, 2.0797e-07, 5.4848e-07, 5.0229e-07,\n             9.6393e-08, 1.1750e-07, 9.4178e-08, 7.9268e-08, 1.0007e-07, 1.2119e-07,\n             2.3393e-07, 1.6112e-07, 5.8799e-07, 3.7719e-07, 1.2893e-07, 1.9904e-07,\n             1.0088e-07, 1.8474e-07, 1.5377e-07, 1.1810e-07, 1.0656e-07, 9.0981e-07,\n             2.0284e-07, 1.2154e-07, 1.0653e-07, 1.2760e-07, 7.0558e-07, 3.1886e-07,\n             1.5562e-07, 1.1248e-07, 5.2408e-08, 1.4379e-07, 2.0777e-07, 5.9200e-07,\n             3.5996e-07, 7.3690e-08, 4.3012e-07, 5.6933e-07, 8.8443e-08, 9.4751e-08,\n             1.3474e-07, 4.7069e-07, 1.3112e-07, 2.5649e-07, 1.6566e-07, 1.4945e-07,\n             2.6431e-07, 1.6148e-07, 2.5382e-07, 1.0459e-07, 2.5662e-07, 2.0433e-07,\n             9.9270e-08, 1.1396e-07, 1.9863e-07, 6.2431e-08, 9.3292e-08, 8.7313e-08,\n             7.7306e-08, 5.0754e-07, 1.3952e-07, 4.8100e-07, 1.9464e-07, 1.6014e-07,\n             8.5207e-08, 1.2561e-07, 1.0432e-07, 6.8868e-07, 6.3649e-07, 8.3509e-08,\n             1.3093e-07, 1.5988e-07, 1.1273e-07, 8.7351e-08, 1.2628e-07, 1.1246e-07,\n             1.9337e-07, 2.2970e-07, 3.5860e-07, 1.1008e-07, 1.9476e-07, 1.0525e-07,\n             1.3355e-07, 8.7957e-08, 1.2695e-07, 1.8342e-07, 9.9853e-08, 1.1594e-07,\n             1.7162e-07, 6.5763e-08, 3.8071e-07, 1.0016e-07, 1.0691e-07, 1.3156e-07,\n             1.1544e-07, 2.5273e-07])},\n    39: {'exp_avg': tensor([-3.5511e-04,  5.3776e-05, -1.6648e-04,  1.0607e-04, -2.3181e-06,\n              4.1370e-06,  8.5566e-05, -7.5504e-05, -1.1527e-05,  1.4890e-04,\n             -5.1867e-05,  1.4906e-04,  1.8312e-04, -1.5855e-04,  2.4531e-04,\n              2.0260e-04, -8.5036e-05, -2.3970e-04,  1.1153e-04,  1.5690e-05,\n              4.3453e-05,  2.9386e-05, -1.2299e-04, -2.9334e-04, -5.4366e-05,\n              2.0580e-05, -2.1795e-04,  1.0249e-04,  2.1828e-06,  5.0653e-04,\n             -1.4603e-04,  5.9611e-05,  1.5441e-04, -2.9163e-04, -1.8619e-05,\n             -5.8815e-05, -2.4035e-04,  8.2528e-05,  2.0994e-05, -6.9326e-05,\n             -3.8699e-05,  3.0412e-04,  2.7501e-04, -3.1084e-04, -5.1125e-05,\n              5.3952e-04,  9.3793e-05, -1.0846e-04, -8.9578e-05,  1.5941e-04,\n              4.6313e-05,  7.7477e-05, -4.2121e-05,  1.6737e-05, -1.0322e-04,\n              2.1244e-05, -2.2819e-04, -1.8374e-04, -5.8124e-04,  1.1162e-04,\n              2.1890e-04,  2.0451e-04, -3.3731e-05,  4.3146e-04,  3.2307e-05,\n             -3.2230e-05, -2.1217e-05, -1.3880e-04,  3.6540e-04,  5.8213e-04,\n              2.1176e-05, -9.4461e-05,  1.6394e-04,  5.1048e-05, -2.4697e-04,\n              4.9674e-05, -7.1289e-05, -4.6740e-05, -1.3760e-04,  2.8478e-04,\n              4.9955e-04,  7.6429e-05, -4.3947e-05,  2.5276e-04, -2.1045e-04,\n             -1.4069e-04, -3.6400e-05, -1.2871e-04,  6.4102e-05, -1.8590e-04,\n             -3.7300e-05, -4.3388e-04, -6.3871e-05, -5.5775e-06,  2.5293e-04,\n             -2.1683e-04, -4.3429e-05,  2.4791e-04, -1.7190e-04,  1.8770e-04,\n              4.7851e-05, -1.3624e-05, -2.8574e-05,  2.3548e-04, -7.0819e-05,\n             -6.1469e-05, -1.7992e-05,  3.1138e-06, -7.1808e-05,  1.5311e-05,\n             -1.8742e-05, -6.3851e-05,  5.2273e-04, -1.0783e-04,  9.2285e-05,\n              5.5615e-05,  1.4904e-04, -4.2052e-05,  2.1209e-04, -8.8785e-06,\n             -8.5566e-05,  4.7637e-05,  2.2159e-04, -9.5469e-05, -2.2901e-05,\n              9.9878e-05,  1.2074e-04,  1.9947e-04]),\n     'exp_avg_sq': tensor([1.3745e-07, 6.3131e-08, 8.5605e-08, 2.7960e-08, 7.1353e-08, 1.7033e-08,\n             3.4738e-08, 4.8086e-08, 6.6710e-08, 6.1898e-08, 8.0225e-08, 4.6918e-08,\n             6.3549e-08, 5.3058e-08, 8.3717e-08, 6.7768e-08, 3.9677e-08, 1.3285e-07,\n             2.0463e-07, 1.0846e-09, 9.4045e-08, 6.8568e-08, 9.7863e-08, 8.5530e-08,\n             5.3020e-08, 1.1124e-09, 1.1754e-07, 5.3493e-08, 4.3856e-08, 1.5159e-07,\n             5.7411e-08, 6.5326e-08, 9.5271e-08, 1.5021e-07, 3.0177e-09, 1.9473e-09,\n             3.6276e-08, 7.7612e-08, 4.2345e-08, 4.5204e-08, 5.0868e-08, 1.0490e-07,\n             8.5693e-08, 5.7279e-08, 6.0301e-09, 3.9100e-07, 1.3766e-07, 3.6127e-08,\n             4.2994e-08, 8.7145e-08, 5.5477e-08, 4.0623e-08, 2.4966e-08, 5.9757e-10,\n             6.8949e-08, 5.7236e-08, 7.5770e-08, 9.1682e-08, 2.4583e-07, 2.5995e-08,\n             6.2788e-08, 9.7086e-08, 3.1291e-08, 1.0866e-07, 4.0422e-08, 2.9864e-09,\n             1.5882e-07, 4.9162e-08, 1.3422e-07, 2.5453e-07, 3.9444e-08, 1.1938e-07,\n             9.7860e-08, 2.0380e-09, 1.3658e-07, 1.0060e-07, 6.3020e-08, 4.8450e-08,\n             1.3036e-07, 1.3580e-07, 1.6317e-07, 5.7375e-08, 1.4413e-07, 1.2756e-07,\n             5.0508e-08, 7.6243e-08, 7.9490e-08, 3.8428e-08, 1.5928e-08, 5.8377e-08,\n             4.0979e-08, 1.4508e-07, 1.1281e-07, 8.3077e-10, 7.6897e-08, 4.3705e-08,\n             9.0099e-08, 9.1510e-08, 6.3535e-08, 9.6306e-08, 2.1011e-07, 4.6524e-08,\n             3.6870e-08, 8.8703e-08, 3.1242e-08, 3.2438e-08, 3.8556e-08, 6.9138e-08,\n             1.7759e-07, 5.3157e-08, 3.5959e-09, 9.8212e-08, 1.3611e-07, 4.0236e-08,\n             5.8021e-08, 8.7012e-08, 3.6153e-08, 4.2151e-08, 6.1597e-08, 9.3073e-08,\n             1.1971e-07, 2.8611e-08, 1.6395e-07, 6.3898e-08, 5.2522e-08, 3.8446e-08,\n             5.8353e-08, 1.2812e-07])},\n    40: {'exp_avg': tensor([-4.5007e-05,  1.6780e-04, -1.2493e-05, -2.4619e-06,  2.9800e-04,\n             -2.3997e-05, -1.2697e-04,  1.6404e-04,  7.2506e-07, -1.1654e-04,\n             -1.6626e-04, -1.8113e-04, -3.5579e-05, -3.6018e-05, -8.3846e-05,\n             -1.7407e-04, -3.8229e-05, -1.6660e-05,  1.2508e-05, -2.6063e-04,\n             -1.2089e-04,  4.3272e-05, -1.4111e-04,  2.4521e-05,  5.4180e-05,\n             -2.0234e-04, -1.7616e-04, -1.9564e-04, -2.3692e-04, -2.5647e-04,\n             -1.2345e-04,  1.5842e-04,  1.5826e-04, -1.5742e-04, -8.0982e-05,\n              1.6076e-05, -8.6574e-05,  1.0770e-04,  7.3496e-05, -7.3657e-05,\n              2.1373e-04, -2.5349e-05,  7.4886e-05, -2.6772e-04,  1.3729e-04,\n             -2.3711e-05, -8.1935e-05,  8.9596e-05, -1.7292e-05, -8.9985e-05,\n              1.4723e-04, -4.4783e-05, -8.6707e-06,  1.2993e-04, -1.7555e-05,\n              3.1627e-04, -6.6345e-05,  3.7963e-05, -9.0331e-05, -4.0336e-05,\n             -5.6851e-05,  8.7151e-05,  3.2887e-04, -1.2994e-05, -2.1253e-04,\n             -1.3002e-04, -6.2624e-06, -3.3072e-05,  1.1125e-04, -1.1349e-04,\n             -5.1366e-05, -8.2869e-05, -6.1901e-05, -6.1960e-05, -2.4526e-05,\n             -4.1078e-05,  1.3964e-04, -6.0111e-05,  1.1393e-04, -2.3336e-04,\n              3.4562e-05,  1.4507e-04, -2.3870e-04, -1.4229e-04, -5.0269e-05,\n              7.7693e-05, -5.9561e-05,  9.2082e-05, -1.0012e-04,  1.5899e-04,\n             -1.1299e-04, -6.3311e-06,  4.4544e-04, -2.7990e-04, -1.4799e-04,\n              1.2628e-04, -5.1033e-05,  1.0798e-04,  2.4214e-04,  2.0851e-04,\n             -1.1798e-05,  8.5632e-05,  8.7588e-05,  3.6300e-05,  3.6922e-05,\n             -2.4720e-04, -1.9554e-05, -1.3122e-04, -2.7878e-05, -1.8127e-04,\n              6.2314e-06,  2.2638e-04, -1.8195e-04, -2.1032e-04, -6.7370e-05,\n             -2.0227e-04, -1.1092e-04, -8.5413e-05, -1.3751e-04, -1.7365e-04,\n              1.8266e-04, -1.1162e-05,  1.8721e-04, -4.7684e-05, -8.4099e-05,\n             -5.2216e-05,  5.9731e-05,  8.3164e-06, -2.2309e-04, -2.0960e-04,\n             -8.5988e-06,  3.0271e-05, -9.6865e-05,  1.7646e-05,  1.6234e-04,\n             -6.8582e-05, -8.7957e-06,  2.3570e-04, -1.0566e-04, -2.3365e-05,\n             -2.7274e-05, -1.1274e-04,  2.7276e-05, -7.4076e-05, -2.5875e-05,\n              6.9762e-06,  1.6600e-04, -1.9456e-04,  2.1567e-04,  1.6807e-04,\n             -4.0694e-04,  2.5662e-05, -2.2198e-04,  6.6228e-05,  1.4799e-04,\n             -3.4238e-06, -9.4310e-05,  1.2634e-04, -9.4885e-05,  2.5450e-04,\n             -3.4347e-05,  1.9980e-04,  7.6462e-05, -1.8909e-04, -5.6425e-05,\n             -4.8331e-05,  5.4239e-06,  4.3452e-05,  2.0478e-04,  9.8074e-05,\n             -1.5437e-04, -2.9291e-05, -7.5123e-05,  1.0054e-04, -3.5137e-05,\n             -4.2477e-05,  3.4765e-05,  7.9303e-05,  4.3842e-05, -2.6223e-05,\n             -7.6157e-05,  1.8423e-04, -2.2998e-05,  6.9553e-06, -1.3360e-04,\n              1.2289e-04,  7.1695e-05, -4.4737e-05,  5.5554e-05, -4.3365e-06,\n             -9.1065e-05,  3.2366e-05,  1.6085e-04,  8.3206e-05, -1.6396e-04,\n              2.0158e-04, -3.2153e-05, -1.4618e-05,  2.4053e-05, -2.0402e-04,\n              1.3653e-04,  2.5220e-05, -3.4212e-07, -2.1803e-04,  1.2473e-04,\n              1.4242e-04,  2.5597e-05,  2.0195e-05, -1.7592e-07,  1.8099e-05,\n             -4.7457e-05,  2.5438e-05, -4.7468e-05, -1.1215e-04, -3.0348e-05,\n              5.5276e-05,  1.2357e-04,  1.2673e-04,  1.1086e-04,  1.1762e-04,\n             -4.3007e-05,  2.3767e-05,  4.8130e-06, -2.1146e-04, -1.5056e-05,\n             -3.3402e-05, -4.6596e-05,  9.8642e-05,  1.1039e-04, -8.5776e-05,\n             -2.2650e-05, -1.4072e-04,  1.0933e-04,  1.4620e-04,  1.8373e-04,\n             -6.1625e-05,  6.2705e-05, -3.7334e-05, -1.1943e-06, -1.4270e-05,\n              7.4560e-05,  9.9444e-05,  2.9388e-04, -1.0271e-05, -5.0892e-04,\n             -1.4145e-04, -1.7069e-05,  1.0583e-04,  3.2106e-04, -1.6474e-04,\n             -1.3123e-04, -3.1008e-05,  8.9752e-05,  1.3012e-04,  1.6017e-05,\n              1.0521e-05, -4.7211e-05,  8.3648e-05,  1.5195e-05, -1.0129e-04,\n             -1.5959e-04,  5.2552e-05,  5.7674e-05,  6.2282e-05, -3.6905e-05,\n             -9.5842e-05, -1.4353e-04,  1.8313e-04,  1.7640e-04,  4.9697e-05,\n             -1.4607e-04, -1.1818e-04,  1.7849e-05,  3.5507e-05,  5.1314e-05,\n              1.6815e-04, -6.2613e-06,  3.2026e-05,  7.1684e-05, -6.6015e-05,\n              1.1919e-04, -1.0801e-04, -2.3627e-05, -4.4251e-05,  1.5088e-04,\n              6.7673e-05,  3.5523e-06,  1.5092e-04, -4.2464e-05, -7.3375e-05,\n              1.4339e-04,  1.8740e-04,  5.3219e-05, -3.3780e-05, -1.9923e-06,\n             -6.0031e-06,  1.8297e-04, -3.9666e-05, -8.4309e-06, -9.4323e-06,\n             -4.5457e-05,  1.3581e-05, -2.2136e-06, -1.1757e-04, -1.4456e-04,\n             -1.8601e-04,  5.9167e-06,  2.1516e-04, -8.4227e-05, -5.1489e-05,\n              2.2955e-04,  1.5142e-04, -9.7099e-05,  1.0851e-04, -3.6295e-05,\n              1.1260e-04, -6.5284e-05, -1.1857e-04, -7.1920e-05,  3.3382e-04,\n              1.7084e-06, -2.0312e-06,  2.9536e-04,  2.1957e-05,  5.4205e-05,\n             -1.7407e-04,  7.6250e-06,  1.3239e-04, -9.0705e-05, -2.2317e-06,\n             -1.7505e-05, -1.1821e-04,  8.6426e-05,  3.9738e-05, -8.6388e-05,\n              1.8440e-04,  1.2450e-05, -1.3468e-06,  5.9060e-05,  6.1185e-05,\n             -6.4151e-05, -2.0559e-06,  1.4007e-04,  6.7551e-05,  8.2583e-05,\n              1.6553e-04,  5.1285e-05,  4.9551e-05, -7.9166e-05, -8.2154e-05,\n             -1.5151e-04, -1.3115e-06, -1.2729e-04, -6.5632e-05,  4.5867e-05,\n              4.0256e-05,  1.0970e-05, -4.2453e-06,  2.6184e-04,  3.4321e-05,\n             -1.3165e-04,  1.1955e-04, -5.3305e-05, -2.0361e-05, -3.8845e-05,\n             -1.6234e-04, -1.4635e-04, -1.0656e-04, -1.6420e-05, -2.6857e-04,\n              2.9525e-04, -5.7815e-05,  1.6441e-04, -2.9589e-05, -1.3154e-04,\n              9.1138e-05, -1.2801e-04, -1.2420e-04, -6.3416e-05,  1.9518e-05,\n             -7.6035e-05, -8.8278e-05, -6.2795e-05,  3.6714e-06,  2.8374e-05,\n             -1.9069e-04,  4.9605e-05,  1.3909e-04, -2.3295e-04,  1.3828e-04,\n              3.2983e-05, -1.3651e-04, -1.1439e-04, -7.5742e-05, -3.5178e-06,\n              7.6617e-05,  4.1585e-05,  8.6477e-05, -1.4307e-04, -2.5949e-05,\n              9.8883e-05, -2.2212e-05, -2.2564e-04, -4.5404e-06, -1.0151e-04,\n             -3.5646e-04,  8.1243e-05, -5.3303e-05, -1.2367e-04,  2.1148e-04,\n             -7.1099e-05,  1.8259e-04,  5.1452e-05,  2.5833e-05,  7.1000e-05,\n             -9.6098e-05,  1.7965e-04,  1.1898e-04,  2.2062e-04,  5.0191e-05,\n              1.5154e-05, -6.2312e-05, -4.9743e-06,  5.1669e-05,  6.1242e-05,\n             -1.4652e-04,  3.3097e-05,  1.5997e-04, -2.2048e-04, -8.7342e-05,\n              1.6042e-05,  4.2518e-05, -4.2007e-05, -8.7648e-05,  1.4754e-04,\n             -4.6348e-05,  2.6637e-05, -2.1882e-04, -2.3572e-04,  1.2576e-04,\n              1.2846e-04, -2.3323e-04, -2.1941e-05, -2.9647e-04,  8.2353e-06,\n              5.0248e-05,  1.2456e-04, -2.2688e-04, -7.0583e-05,  9.8026e-05,\n             -7.0075e-05, -1.6689e-04,  1.3038e-04,  3.8901e-05,  4.5413e-05,\n             -1.2256e-04, -3.6730e-05, -2.1248e-05, -3.8129e-06,  6.2694e-05,\n              1.3076e-04, -1.0163e-04, -6.1556e-05,  1.2609e-04,  1.4794e-04,\n              1.1900e-05,  4.3597e-05,  1.2497e-04,  6.6454e-05, -2.6729e-04,\n              1.6917e-04,  4.4968e-06, -5.7626e-05,  2.3034e-04, -6.6906e-05,\n              1.6569e-04, -2.0213e-04,  5.2937e-05,  2.2404e-04,  2.3348e-04,\n              1.7195e-04, -3.6229e-05,  2.2769e-04,  2.0324e-04,  1.0334e-04,\n             -9.2914e-05,  9.0319e-05,  5.4086e-05, -6.2058e-05,  2.2075e-04,\n             -5.4086e-05, -1.3316e-04,  9.7691e-05,  2.8935e-05, -1.6293e-04,\n             -5.6379e-05, -2.6223e-04,  9.7583e-07, -1.4081e-04,  2.9033e-04,\n              9.8936e-05,  5.4578e-05,  7.9307e-05, -8.1554e-06,  1.0003e-04,\n             -4.5699e-05, -1.9357e-05,  3.5431e-04,  5.3899e-05,  1.2235e-04,\n             -1.3857e-04,  4.9761e-05]),\n     'exp_avg_sq': tensor([3.0720e-08, 4.6961e-08, 7.0891e-08, 6.0904e-08, 7.1204e-08, 1.4445e-08,\n             3.4076e-08, 4.0033e-08, 1.3672e-08, 9.0557e-09, 2.3630e-08, 5.5964e-08,\n             4.2145e-08, 4.0172e-08, 3.9739e-08, 2.9578e-08, 1.5873e-08, 7.2860e-08,\n             1.4637e-08, 6.4207e-08, 6.1833e-08, 2.1868e-08, 6.3864e-08, 2.7217e-08,\n             3.1490e-08, 6.9747e-08, 6.5469e-08, 5.8954e-08, 6.2051e-08, 1.1136e-07,\n             6.9160e-08, 5.4360e-08, 5.6885e-08, 2.2713e-08, 5.5472e-08, 1.1994e-08,\n             4.6908e-08, 4.0014e-08, 4.3359e-08, 7.1578e-08, 7.4096e-08, 1.6209e-08,\n             8.4672e-08, 5.4661e-08, 3.0598e-08, 2.1631e-08, 3.7584e-08, 1.4179e-08,\n             2.9331e-08, 2.2507e-08, 2.2041e-08, 4.4721e-08, 4.4644e-08, 3.1192e-08,\n             2.8719e-08, 1.1543e-07, 1.3688e-08, 1.1008e-07, 1.6487e-08, 1.9365e-08,\n             2.0800e-08, 3.7520e-08, 2.3711e-07, 2.1596e-08, 5.4916e-08, 1.4793e-08,\n             6.8019e-09, 3.9584e-08, 3.6301e-08, 2.5267e-08, 2.9109e-08, 5.4829e-08,\n             1.9162e-08, 1.7962e-08, 6.8796e-08, 1.8856e-08, 4.5440e-08, 4.4493e-08,\n             4.2104e-08, 5.1260e-08, 1.7724e-08, 1.9382e-08, 3.1792e-08, 4.7259e-08,\n             7.0079e-08, 1.5323e-08, 6.7949e-09, 2.8253e-08, 3.7389e-08, 1.0063e-07,\n             1.6945e-08, 2.0766e-08, 5.6924e-08, 4.7663e-08, 1.6839e-08, 5.7257e-08,\n             3.6387e-08, 4.1955e-08, 5.7138e-08, 2.7897e-08, 1.3135e-08, 2.8575e-08,\n             2.9058e-08, 1.4340e-08, 4.4213e-08, 5.1354e-08, 6.8472e-08, 5.9015e-08,\n             1.9529e-08, 3.9904e-08, 2.6352e-08, 2.6497e-08, 3.2262e-08, 6.2875e-08,\n             1.4541e-08, 3.7133e-08, 6.0935e-08, 3.8768e-08, 2.0887e-08, 2.3312e-08,\n             2.2889e-08, 1.8319e-08, 3.4822e-08, 5.0154e-08, 3.1899e-08, 4.0570e-08,\n             1.6501e-08, 4.9270e-08, 7.5221e-08, 2.1240e-08, 1.9368e-08, 4.7253e-08,\n             4.6365e-08, 2.3985e-08, 8.7382e-08, 6.3902e-08, 3.3075e-08, 4.1111e-08,\n             1.8051e-08, 1.9455e-08, 6.5048e-08, 6.0844e-08, 4.2185e-08, 2.1046e-08,\n             1.5520e-08, 1.5726e-08, 5.8705e-08, 8.9379e-08, 1.5798e-07, 2.6986e-08,\n             9.4203e-08, 1.8931e-08, 5.3272e-08, 2.5096e-08, 1.7120e-08, 3.3204e-08,\n             4.5036e-08, 6.1043e-08, 2.0590e-08, 4.5368e-08, 2.0739e-08, 4.0809e-08,\n             4.5078e-08, 6.7724e-08, 2.8006e-08, 1.7447e-08, 1.4118e-08, 1.2066e-08,\n             2.4875e-08, 9.5045e-08, 1.0527e-07, 2.0174e-08, 4.2525e-08, 1.6243e-08,\n             1.5019e-08, 4.5653e-08, 1.7460e-08, 4.1567e-08, 2.9736e-08, 1.6100e-08,\n             2.3867e-08, 2.0707e-08, 2.7920e-08, 5.9526e-08, 1.4582e-07, 4.6207e-08,\n             4.3605e-08, 3.2462e-08, 8.1494e-08, 4.8659e-08, 2.4213e-08, 5.5997e-08,\n             3.6597e-08, 3.3857e-08, 7.4036e-08, 3.8518e-08, 1.9187e-08, 3.6214e-08,\n             3.3492e-08, 2.1294e-08, 7.1363e-08, 4.7053e-08, 1.6014e-08, 3.5737e-08,\n             4.8395e-08, 1.0264e-07, 2.0019e-08, 1.0188e-07, 2.4477e-08, 4.7446e-08,\n             4.9308e-08, 4.0034e-08, 1.5863e-08, 3.3969e-08, 1.3079e-08, 2.2634e-08,\n             2.1168e-08, 2.4294e-08, 1.3461e-08, 3.6618e-08, 1.8957e-08, 2.1291e-08,\n             6.1705e-08, 5.6709e-08, 7.6496e-08, 2.9334e-08, 2.8187e-08, 2.6331e-08,\n             2.6200e-08, 4.8802e-08, 3.5386e-08, 2.1789e-08, 3.8663e-08, 6.7003e-08,\n             3.8220e-08, 2.1110e-08, 1.3469e-08, 2.1292e-08, 5.2987e-08, 1.6075e-08,\n             4.5961e-08, 2.1919e-08, 1.5602e-07, 2.3827e-08, 7.4823e-08, 5.3577e-08,\n             1.9311e-08, 4.5683e-08, 9.7590e-08, 7.1163e-08, 4.1145e-08, 3.1374e-08,\n             8.1441e-08, 1.4986e-08, 2.2947e-08, 8.4746e-09, 3.8088e-08, 3.7443e-08,\n             5.2133e-08, 1.8120e-08, 1.6339e-08, 3.0665e-08, 2.0109e-08, 2.9755e-08,\n             1.8005e-08, 3.1384e-08, 3.3433e-08, 4.0799e-08, 4.1430e-08, 2.2037e-08,\n             7.3649e-08, 1.3452e-08, 2.0579e-08, 3.8310e-08, 3.8538e-08, 1.2165e-07,\n             2.9060e-08, 6.3939e-08, 4.7530e-08, 1.5638e-08, 5.0562e-08, 4.0544e-08,\n             1.1158e-08, 2.6651e-08, 1.6956e-07, 8.8800e-09, 1.9370e-08, 9.2197e-08,\n             6.2588e-08, 3.8987e-08, 1.8965e-07, 5.6309e-08, 3.8504e-08, 2.0058e-08,\n             2.3403e-08, 2.5958e-08, 5.4058e-08, 4.5650e-08, 5.1042e-08, 5.4499e-08,\n             2.0612e-08, 3.9313e-08, 1.8258e-08, 5.5520e-08, 2.5388e-08, 3.3178e-08,\n             2.8119e-08, 7.5733e-08, 1.8574e-08, 2.3398e-08, 5.7988e-08, 9.8543e-08,\n             6.7193e-08, 2.8708e-08, 3.2856e-08, 1.9065e-08, 2.2208e-08, 2.7730e-08,\n             3.2486e-08, 2.5770e-08, 9.6842e-09, 1.0391e-08, 5.5701e-08, 6.0407e-08,\n             4.8249e-08, 1.1276e-07, 1.8635e-08, 2.6229e-08, 3.3338e-08, 4.3407e-08,\n             4.3877e-08, 2.1318e-08, 2.4755e-08, 5.8623e-08, 1.7082e-08, 3.2103e-08,\n             1.3055e-08, 2.5816e-08, 1.3796e-08, 2.2999e-08, 7.9594e-08, 2.9658e-08,\n             5.1030e-08, 3.1107e-08, 2.8360e-08, 9.9090e-08, 2.5019e-08, 1.8401e-08,\n             5.5102e-08, 3.6291e-08, 2.4998e-08, 4.2603e-08, 2.9028e-08, 4.4276e-08,\n             1.2741e-08, 2.8430e-08, 2.6649e-08, 6.1263e-08, 5.6267e-08, 3.5229e-08,\n             4.8754e-08, 3.1418e-08, 1.0421e-08, 1.0512e-07, 2.5285e-08, 3.3581e-08,\n             7.6917e-08, 2.9473e-08, 5.6784e-08, 9.8275e-08, 1.6024e-07, 3.0279e-08,\n             2.3588e-08, 2.5979e-08, 2.3142e-08, 2.4034e-08, 4.8915e-08, 3.4742e-08,\n             3.3886e-08, 6.3894e-08, 4.5864e-08, 5.3657e-08, 2.3241e-08, 2.6296e-08,\n             2.9381e-08, 3.9427e-08, 1.9477e-08, 1.1015e-07, 3.6459e-08, 1.9467e-08,\n             5.5915e-08, 5.2422e-08, 5.9834e-08, 2.2239e-08, 2.3035e-08, 1.4026e-08,\n             2.5708e-08, 3.7419e-08, 3.1255e-08, 1.4045e-08, 1.5547e-08, 4.1950e-08,\n             3.5612e-08, 5.5725e-08, 2.5803e-08, 5.4139e-08, 1.1190e-07, 2.0144e-08,\n             1.3426e-08, 1.3202e-07, 8.5743e-08, 3.6705e-08, 1.4966e-08, 2.9426e-08,\n             3.6454e-08, 3.0993e-08, 2.6740e-08, 3.9683e-08, 6.2374e-08, 5.7869e-08,\n             6.2237e-08, 1.1351e-08, 1.0200e-07, 2.5096e-08, 7.9809e-08, 3.0188e-08,\n             1.3534e-08, 2.3248e-08, 4.9555e-08, 1.1954e-08, 2.1931e-08, 2.0477e-08,\n             3.3897e-08, 5.9291e-08, 1.8999e-08, 5.0606e-08, 4.5846e-08, 4.7077e-08,\n             7.0926e-08, 3.9055e-08, 2.8472e-08, 5.7699e-08, 7.3771e-08, 6.5675e-08,\n             2.5125e-08, 8.2060e-08, 2.1246e-08, 5.2793e-08, 4.5434e-08, 3.7333e-08,\n             2.4827e-08, 3.0975e-08, 2.9543e-08, 2.9414e-08, 1.9914e-08, 1.8218e-08,\n             1.1214e-08, 4.1156e-08, 2.1920e-08, 4.4549e-08, 5.1627e-08, 3.6232e-08,\n             2.4162e-08, 1.4252e-07, 2.3895e-08, 4.0235e-08, 3.4226e-08, 5.0028e-08,\n             1.8953e-08, 8.0760e-08, 2.5058e-08, 1.5966e-07, 3.2102e-08, 1.4418e-07,\n             3.0251e-08, 2.9004e-08, 6.5873e-08, 4.3377e-08, 4.8275e-08, 1.0735e-07,\n             8.7614e-08, 2.6030e-08, 3.7291e-08, 1.2310e-07, 1.8586e-08, 2.9342e-08,\n             2.5587e-08, 3.6550e-08, 6.3582e-08, 1.3001e-07, 2.4676e-08, 9.4249e-08,\n             1.3545e-08, 4.8684e-08, 6.3684e-08, 1.1555e-07, 9.7206e-08, 2.9252e-08,\n             3.2957e-08, 2.4121e-08, 2.2930e-08, 2.7337e-08, 1.5889e-08, 1.2767e-08,\n             9.2296e-08, 3.1053e-08, 2.4153e-08, 8.1959e-08, 7.0973e-08, 3.5215e-08,\n             2.1852e-08, 2.8740e-08])},\n    41: {'exp_avg': tensor([-1.4668e-05,  3.2965e-05, -1.8000e-06,  1.5291e-05, -7.3602e-06,\n             -2.3900e-05,  1.6208e-05,  4.0972e-05,  1.2121e-05,  8.9376e-05,\n             -1.9642e-06, -2.4122e-05, -4.3285e-06, -1.1524e-05, -1.4737e-04,\n             -4.1489e-05,  1.1058e-04,  1.6945e-05, -2.3786e-05, -2.6335e-05,\n              3.7027e-05, -3.3912e-05,  1.8990e-06, -9.4315e-06,  4.1345e-05,\n             -5.8686e-06,  1.0915e-08,  1.2513e-05, -1.9990e-05, -2.4700e-06,\n             -1.6641e-05, -2.3299e-05, -1.3226e-05, -1.6308e-04, -1.4095e-05,\n             -6.3466e-09,  4.8446e-06,  1.4204e-07, -7.7039e-05,  9.5025e-06,\n              5.3783e-06, -3.5619e-05, -1.1584e-05, -1.3544e-05, -5.1325e-11,\n             -7.7137e-05, -1.5936e-05,  3.3063e-05, -3.6045e-09,  5.9747e-05,\n              2.2671e-05,  1.0481e-05,  1.9321e-07,  1.6960e-05,  3.0604e-05,\n              1.2870e-05, -6.7394e-06,  9.4240e-06, -1.9037e-05,  7.3825e-05,\n             -3.9838e-05,  4.8379e-05,  4.7003e-05, -4.9699e-06,  7.6166e-07,\n             -6.1465e-06,  7.3497e-05, -5.9833e-06,  1.5527e-05,  3.3554e-11,\n             -1.9791e-05, -1.6116e-06,  7.3657e-05,  4.3430e-05,  2.0631e-05,\n              1.1993e-04, -4.7604e-05,  1.4532e-04,  2.8235e-06,  1.2764e-05,\n             -3.3441e-05,  8.9565e-05,  6.2250e-06, -2.8944e-05,  9.5500e-06,\n              4.8981e-05, -7.3359e-05, -1.8095e-05,  4.2399e-06, -5.3975e-06,\n             -8.1440e-06,  4.6226e-06, -6.4778e-07,  2.7971e-11,  2.8807e-05,\n             -1.6605e-05, -4.3182e-06, -1.7316e-07, -1.5597e-05, -3.1021e-05,\n              5.3172e-05, -5.5732e-05, -1.1730e-04,  1.8292e-04, -4.8294e-06,\n             -2.4735e-05,  6.9702e-06, -3.5094e-05,  5.2816e-05, -1.2664e-04,\n             -4.6125e-05, -6.6251e-05,  1.7686e-05,  5.0447e-06, -5.7988e-05,\n             -5.5018e-05,  5.4456e-06, -1.2043e-06,  1.7383e-05, -3.4238e-05,\n             -5.5657e-05,  3.5783e-05, -7.7359e-07, -1.0770e-05, -1.5455e-06,\n              9.2854e-05,  2.7660e-05, -2.9205e-06,  1.5534e-08, -1.7459e-06,\n              2.5425e-06, -1.1335e-05,  1.3531e-05, -4.9401e-11, -1.2863e-05,\n              2.0828e-05, -3.9547e-05,  6.5156e-08, -5.4366e-05,  1.6594e-05,\n              7.7514e-06,  2.5077e-05, -1.3204e-04, -1.8565e-04,  2.1799e-05,\n             -9.2351e-05, -9.3368e-05, -1.7194e-06, -2.0384e-05,  7.7420e-05,\n             -4.0680e-07,  6.4293e-06,  1.6792e-05,  8.2926e-05,  2.1016e-06,\n              9.6638e-07,  1.0692e-04, -2.1300e-07, -9.2222e-05,  1.3231e-04,\n              2.6063e-05, -3.5742e-05,  1.4876e-06,  4.1004e-09,  1.3586e-04,\n             -6.2292e-05,  8.8272e-05,  7.0437e-05, -2.3634e-07, -1.2924e-05,\n              7.4443e-06, -2.3344e-05,  6.1133e-05,  1.0969e-11,  2.6233e-05,\n             -1.2489e-05, -9.4271e-06, -2.5463e-05,  1.3621e-05,  4.3178e-05,\n              4.8863e-05,  7.2296e-05,  9.9740e-05, -3.1908e-08,  1.6127e-07,\n              1.2937e-05,  9.7437e-06,  5.8243e-05,  2.4906e-06, -8.7100e-05,\n              6.1734e-05, -1.8813e-06, -3.6061e-05,  9.5879e-07,  1.1784e-06,\n             -7.7263e-05,  1.5274e-05, -1.3904e-06,  2.6751e-05, -1.5130e-04,\n             -7.5088e-06,  2.4276e-06,  3.9353e-05,  6.8857e-08, -1.8436e-04,\n             -3.8570e-06,  3.9658e-05, -5.7146e-07,  6.3146e-06,  2.0148e-06,\n             -3.4794e-05,  4.4825e-05,  6.3039e-05, -2.7360e-05, -2.5429e-05,\n              1.6610e-06,  5.3214e-05, -1.1495e-05,  6.0684e-05, -4.9088e-05,\n              2.4821e-05, -9.4608e-06, -3.1709e-05, -1.4809e-04, -1.0271e-06,\n              1.9828e-05, -4.9771e-05, -3.8253e-05, -9.5891e-05, -2.6551e-07,\n             -9.0666e-05,  1.3272e-04,  4.5634e-05, -2.5392e-06, -6.6095e-05,\n              2.5775e-05,  1.8250e-05, -6.4420e-05,  5.1738e-06, -3.1003e-05,\n              2.8594e-05, -2.4624e-04, -1.9642e-06,  5.6246e-05,  5.0623e-06,\n              2.2174e-06,  9.1544e-06,  8.3123e-05,  4.5336e-08,  5.2577e-06,\n              5.4798e-06,  6.8823e-05,  8.6967e-07, -1.9269e-05,  5.0372e-05,\n              4.4743e-05,  3.7876e-05, -2.4859e-05, -1.3154e-04, -2.2046e-06,\n             -1.6088e-07,  6.5071e-11, -1.2582e-04, -2.8128e-06,  4.8863e-06,\n              2.9660e-05, -8.9093e-10, -6.6196e-06,  4.3466e-07,  2.8397e-05,\n             -6.5563e-05,  7.0352e-05,  1.2052e-04, -3.4634e-06,  2.5686e-06,\n             -3.5715e-06,  3.3661e-05,  8.6409e-07, -1.1528e-04, -5.1099e-06,\n             -5.7688e-06,  3.8683e-06,  8.1426e-05, -1.9462e-10, -3.8655e-06,\n             -3.4555e-05,  3.1542e-05,  2.4205e-05, -2.0225e-05,  9.8459e-07,\n              8.5098e-06,  1.5935e-10,  1.4882e-05,  8.4539e-05, -5.9986e-05,\n             -1.2084e-05,  1.1705e-07, -2.7003e-05, -1.6511e-06,  9.3557e-06,\n             -3.9894e-06, -1.5738e-06, -2.0969e-05,  2.9712e-05, -1.1369e-05,\n              5.1019e-05,  2.1896e-05,  4.1902e-05,  1.4517e-05, -6.3170e-06,\n             -6.9411e-06,  1.9481e-04,  1.0136e-05,  1.4135e-04,  4.5873e-07,\n             -2.0003e-11, -1.3177e-06,  1.1164e-04,  5.2556e-06, -1.5308e-04,\n              7.4794e-05,  1.2676e-05, -1.2913e-05, -4.5694e-06,  1.0567e-04,\n             -5.8702e-05,  4.2680e-05,  2.5530e-05, -3.3020e-06, -2.1588e-05,\n              9.4088e-11,  5.9227e-05, -9.0623e-05,  1.5963e-08,  1.9956e-05,\n              3.8841e-06,  1.1183e-04, -6.3776e-05,  1.6697e-05, -1.7671e-07,\n             -2.2251e-05,  3.1938e-06,  1.7792e-04, -4.2773e-05,  1.5920e-05,\n             -1.3916e-05,  3.3191e-05, -4.8507e-05, -3.9903e-06, -1.4156e-04,\n              4.7013e-06, -1.0459e-05, -1.4078e-04, -4.2796e-07, -1.4329e-04,\n              2.2768e-05, -8.7098e-05,  1.0996e-04,  2.5135e-07, -1.9821e-05,\n              1.3023e-04, -2.5335e-05, -7.6975e-05,  5.7952e-08, -4.8151e-05,\n              2.9316e-06,  3.9802e-07,  5.1047e-05,  5.7721e-05,  6.1721e-05,\n             -1.6795e-05,  5.7773e-06,  4.7502e-11,  1.0230e-05,  2.2715e-06,\n              5.7596e-06,  5.0854e-06, -1.5865e-05, -4.0704e-05,  1.3708e-06,\n             -1.4282e-04,  1.6505e-05,  5.8175e-05,  1.4967e-04,  1.0117e-05,\n              2.4849e-05, -3.6237e-05, -1.8145e-07, -6.8926e-05, -1.1276e-04,\n             -2.8958e-10,  1.3887e-05,  3.6373e-05, -6.8909e-05,  1.5253e-04,\n              7.7884e-06, -1.7337e-05,  6.7357e-06, -6.7709e-05,  9.5723e-06,\n             -5.1626e-06, -1.5785e-05,  4.4132e-05,  5.7735e-05,  2.1356e-05,\n              3.2095e-05,  2.4584e-11,  3.9980e-05, -4.8875e-05, -3.2738e-08,\n              1.8296e-07,  7.0685e-11,  1.9460e-05,  2.3828e-05,  1.0799e-05,\n             -2.5259e-05, -1.7260e-05,  5.0504e-05, -1.6110e-05, -4.6624e-06,\n              2.8078e-06,  1.1136e-04,  1.8875e-06, -1.3479e-05,  7.0982e-06,\n              2.1907e-10,  1.4017e-04, -5.6397e-06,  4.2202e-05, -2.1356e-04,\n             -1.5066e-04,  5.6570e-05, -7.1465e-06,  5.9693e-06,  8.8361e-05,\n              9.3535e-07, -5.9833e-06, -1.3913e-05,  6.5714e-06,  1.5409e-04,\n             -3.9177e-05,  2.0573e-07, -9.6907e-05, -1.7662e-05,  6.1332e-06,\n              1.9583e-04,  6.2325e-05,  3.2725e-06, -1.3906e-06, -9.2719e-06,\n             -9.8132e-05, -5.3335e-05,  1.7484e-06, -9.8072e-05,  4.1984e-05,\n             -2.5966e-05, -5.2228e-06,  1.8726e-05,  6.1336e-06, -9.2781e-05,\n              2.0545e-06, -9.3748e-05, -1.3526e-05, -2.1165e-06, -1.0640e-04,\n             -1.9118e-05,  1.3954e-05, -1.9503e-06,  2.0271e-04, -7.2613e-06,\n             -7.2735e-05,  2.4452e-11,  9.7130e-05,  9.1836e-06, -2.4596e-05,\n              2.9863e-07,  4.3240e-11,  1.3349e-06, -2.0033e-05,  7.2912e-06,\n              3.0811e-06, -1.3442e-05,  1.1146e-05, -5.6366e-05,  6.9133e-05,\n             -4.3735e-05,  1.4080e-04, -1.4448e-05, -8.4807e-06, -1.1656e-06,\n             -8.5416e-06,  7.0105e-07,  4.3690e-05,  5.6478e-06, -1.2654e-07,\n             -8.7718e-10, -1.5534e-06,  9.8022e-07,  1.6675e-04,  2.6897e-04,\n              1.7414e-05,  2.1880e-05,  4.3451e-05,  6.5853e-06,  4.7355e-06,\n             -4.2890e-05, -1.2657e-05, -8.2487e-06,  7.0123e-05, -6.0973e-06,\n             -1.1007e-07, -2.9867e-06]),\n     'exp_avg_sq': tensor([2.6977e-10, 1.2627e-08, 2.1146e-11, 4.0824e-08, 2.2305e-11, 1.1271e-08,\n             9.8387e-09, 1.1292e-09, 9.9957e-09, 7.8295e-09, 1.4471e-09, 1.1632e-09,\n             2.6789e-11, 2.2842e-09, 3.3034e-08, 8.5137e-09, 1.6153e-08, 2.1808e-09,\n             1.2811e-08, 5.7486e-10, 4.1117e-08, 1.7290e-08, 2.4294e-10, 1.1711e-08,\n             2.4033e-08, 2.7883e-10, 1.1780e-13, 2.3343e-10, 2.3392e-09, 1.5368e-10,\n             3.4085e-10, 1.4310e-09, 3.9060e-08, 4.0410e-08, 1.1963e-10, 1.7679e-14,\n             5.4393e-10, 2.2331e-10, 3.8241e-08, 1.4314e-10, 1.9156e-10, 1.0202e-08,\n             1.4887e-10, 1.4581e-09, 4.2413e-20, 1.3015e-08, 4.0369e-09, 7.9966e-09,\n             8.8979e-13, 1.4793e-08, 1.4274e-08, 4.8278e-10, 2.9622e-11, 2.0151e-08,\n             1.5256e-09, 1.2868e-10, 1.0147e-08, 2.0620e-10, 9.0256e-09, 1.6905e-08,\n             8.8644e-09, 3.6866e-08, 3.4646e-08, 1.0956e-08, 2.6291e-10, 1.6640e-08,\n             1.6117e-08, 4.7930e-10, 1.3545e-08, 1.7749e-20, 3.2944e-08, 4.4533e-10,\n             1.1771e-08, 1.3915e-08, 7.5771e-09, 2.0652e-08, 1.6542e-08, 3.0346e-08,\n             1.0031e-10, 6.4963e-10, 1.1178e-08, 8.3134e-09, 1.8123e-11, 1.0372e-09,\n             2.8832e-10, 5.0796e-09, 7.6476e-09, 8.2544e-09, 1.6706e-10, 1.7829e-10,\n             7.9164e-09, 1.6249e-08, 1.2476e-10, 1.7334e-20, 1.5528e-08, 1.9002e-09,\n             2.9356e-08, 1.8397e-11, 1.3765e-09, 2.4718e-08, 9.6238e-09, 1.7475e-08,\n             1.4853e-08, 1.4587e-08, 7.7451e-10, 2.4112e-09, 9.9378e-10, 1.0080e-09,\n             1.3086e-08, 3.3460e-08, 2.0589e-08, 1.8869e-08, 1.7867e-09, 3.1987e-10,\n             1.4999e-08, 4.3590e-09, 9.8658e-11, 2.0530e-08, 5.8809e-09, 1.8117e-08,\n             1.2222e-08, 9.4756e-09, 1.9389e-10, 9.6387e-09, 6.4147e-11, 3.9617e-09,\n             1.0635e-08, 2.2742e-09, 1.2776e-14, 1.1313e-08, 2.2629e-08, 7.3226e-11,\n             6.9586e-10, 3.4985e-20, 2.2284e-10, 5.2419e-10, 1.8179e-08, 2.4280e-13,\n             1.3300e-08, 1.9468e-09, 2.9629e-10, 6.3825e-10, 1.8111e-08, 3.0175e-08,\n             1.7109e-08, 1.5472e-08, 3.7493e-08, 1.3272e-12, 3.9128e-09, 1.2740e-08,\n             1.1471e-11, 1.6649e-09, 6.2227e-10, 1.0954e-08, 2.8172e-11, 6.2629e-12,\n             1.2517e-08, 2.4846e-11, 1.1129e-08, 3.0194e-08, 1.0929e-08, 2.1650e-09,\n             1.4631e-09, 1.7761e-13, 1.5608e-08, 1.4046e-08, 1.2336e-08, 1.0343e-08,\n             3.3659e-12, 5.9567e-10, 1.3206e-10, 9.0724e-09, 3.2012e-08, 1.4568e-20,\n             9.0682e-09, 5.1539e-09, 7.4964e-11, 1.0124e-09, 4.3534e-09, 3.3886e-08,\n             1.7390e-08, 1.4779e-08, 2.1759e-08, 1.5525e-14, 1.0616e-11, 4.0841e-10,\n             4.4574e-10, 1.9628e-08, 3.1523e-11, 7.8595e-08, 1.0450e-08, 2.8270e-11,\n             2.6084e-09, 2.8690e-10, 9.8669e-12, 2.2703e-08, 1.4063e-08, 1.2831e-08,\n             1.5490e-08, 1.3487e-08, 5.7057e-10, 1.6807e-10, 1.7155e-08, 1.3483e-13,\n             4.5304e-08, 1.9312e-10, 7.9277e-09, 2.3412e-12, 1.4508e-08, 2.3176e-12,\n             1.6895e-08, 1.9366e-08, 1.1494e-08, 1.5975e-08, 1.4621e-08, 9.8255e-10,\n             9.7732e-09, 1.1774e-08, 6.5578e-09, 3.0213e-08, 1.6468e-08, 6.2660e-09,\n             6.6658e-10, 2.3354e-08, 2.2211e-11, 1.1425e-08, 2.1889e-08, 1.4222e-08,\n             1.7894e-08, 5.3070e-12, 1.5744e-08, 1.7382e-08, 5.5431e-09, 7.1342e-11,\n             5.3733e-09, 4.8696e-10, 1.2196e-08, 9.6968e-09, 1.5902e-10, 1.0102e-08,\n             2.1760e-08, 4.9218e-08, 6.1587e-12, 8.5599e-09, 1.4678e-10, 2.8586e-11,\n             3.2783e-10, 2.6730e-08, 1.8778e-11, 2.0555e-10, 1.0607e-08, 2.6541e-08,\n             7.3194e-11, 2.3710e-09, 1.5421e-08, 8.8846e-09, 7.0621e-09, 3.0700e-08,\n             2.7628e-08, 1.5539e-10, 5.4060e-11, 1.5974e-20, 1.5347e-08, 1.6597e-10,\n             2.6227e-09, 4.5555e-09, 3.6422e-13, 3.4743e-10, 1.7984e-11, 2.8547e-08,\n             4.2089e-08, 9.7522e-09, 1.4169e-08, 1.8306e-10, 1.8891e-11, 2.4716e-11,\n             1.4384e-08, 7.0238e-11, 3.6960e-08, 1.2318e-08, 8.7014e-10, 3.1832e-09,\n             1.2119e-08, 7.8257e-14, 1.9171e-10, 8.3405e-09, 8.7271e-09, 4.9312e-10,\n             2.8120e-08, 8.0719e-12, 1.2185e-08, 2.4675e-20, 3.3568e-10, 1.0957e-08,\n             1.2530e-08, 2.0727e-08, 1.6827e-15, 2.7760e-08, 8.3579e-11, 4.4427e-10,\n             1.0992e-08, 2.4121e-10, 1.3848e-08, 5.8139e-09, 9.6442e-09, 3.7981e-09,\n             3.3655e-08, 2.9534e-08, 6.7121e-09, 5.4665e-11, 4.9269e-11, 3.8843e-08,\n             3.4310e-10, 1.6635e-08, 1.8638e-12, 1.0415e-20, 1.1052e-08, 1.1492e-08,\n             6.2132e-10, 1.5291e-08, 1.4708e-08, 2.1144e-09, 4.7671e-10, 1.4461e-10,\n             2.1055e-08, 4.1797e-08, 1.0783e-08, 5.5769e-09, 8.0618e-10, 1.0083e-09,\n             2.9724e-20, 2.3354e-08, 1.5338e-08, 2.1256e-10, 8.5313e-09, 1.3679e-09,\n             2.5972e-08, 3.2796e-08, 1.0848e-08, 1.5046e-13, 3.7336e-08, 2.0621e-11,\n             3.2936e-08, 1.2122e-08, 1.7294e-08, 4.4347e-10, 1.2562e-08, 9.5487e-09,\n             6.1708e-10, 1.8497e-08, 9.2901e-09, 1.7010e-09, 3.1553e-08, 1.2703e-12,\n             1.9164e-08, 1.4789e-08, 1.6570e-08, 2.9500e-08, 2.7773e-12, 1.9822e-08,\n             2.6364e-08, 1.8961e-08, 1.8811e-08, 4.9433e-14, 2.2932e-08, 2.7205e-08,\n             1.9631e-12, 1.2784e-08, 8.3911e-09, 5.7290e-08, 1.0896e-09, 1.3262e-08,\n             6.1727e-16, 8.1752e-11, 1.0275e-09, 5.7285e-10, 9.7443e-10, 1.3965e-08,\n             2.2355e-08, 3.2060e-11, 1.1677e-08, 2.9598e-09, 1.0421e-08, 2.8162e-08,\n             1.3403e-08, 6.5575e-09, 1.7551e-09, 1.4399e-13, 3.9973e-08, 2.7127e-08,\n             6.9151e-20, 8.0078e-10, 1.8867e-09, 2.4832e-08, 4.9410e-08, 1.3413e-08,\n             3.2062e-09, 1.4684e-09, 1.6154e-08, 1.3070e-08, 4.8851e-10, 8.1394e-09,\n             2.4278e-08, 1.1290e-08, 1.8312e-08, 1.1430e-09, 3.6316e-20, 6.3482e-09,\n             2.5120e-08, 3.0232e-14, 7.0283e-13, 2.6103e-20, 1.6939e-08, 1.8288e-08,\n             4.2375e-09, 1.1951e-09, 9.7875e-09, 1.4496e-08, 5.1523e-10, 1.9710e-10,\n             1.5901e-08, 1.2669e-08, 2.0427e-11, 9.7703e-09, 1.0130e-09, 2.6985e-20,\n             1.4264e-08, 1.8794e-08, 5.3552e-09, 1.4557e-08, 1.8099e-08, 1.3588e-08,\n             1.9027e-08, 2.2297e-10, 1.7756e-08, 1.0545e-10, 4.2298e-11, 8.0884e-10,\n             6.0046e-11, 3.4107e-08, 9.8133e-09, 1.0487e-11, 2.5128e-08, 8.3619e-10,\n             1.2289e-08, 3.8851e-08, 1.2311e-08, 9.4777e-09, 1.3544e-10, 1.1017e-09,\n             2.1925e-08, 1.3641e-08, 6.8917e-11, 1.6908e-08, 8.4417e-09, 1.0489e-08,\n             1.3051e-09, 5.0910e-10, 1.5737e-08, 3.4467e-08, 2.6759e-09, 1.6597e-08,\n             9.1319e-09, 4.5080e-10, 2.3329e-08, 1.5670e-09, 1.3192e-08, 6.0599e-11,\n             1.2726e-08, 3.1958e-10, 1.6627e-08, 1.6349e-20, 1.3145e-08, 3.7216e-09,\n             2.0283e-08, 1.0118e-11, 1.6271e-16, 2.2100e-08, 3.3563e-10, 1.0740e-10,\n             2.1806e-11, 3.6418e-10, 2.6052e-08, 4.6120e-09, 1.0037e-08, 1.0216e-08,\n             1.6784e-08, 1.4753e-08, 4.7950e-11, 1.0375e-11, 1.0424e-08, 1.6408e-10,\n             1.3070e-08, 7.9235e-10, 2.8072e-13, 5.4412e-16, 1.3578e-10, 4.2760e-12,\n             2.6525e-08, 1.8163e-08, 1.5336e-08, 2.3679e-08, 9.8915e-09, 1.4926e-09,\n             1.5674e-10, 1.0992e-08, 2.2474e-08, 8.8497e-10, 4.8887e-08, 1.2815e-08,\n             4.3653e-11, 2.0320e-09])},\n    42: {'exp_avg': tensor([ 2.4960e-04,  5.8119e-04,  4.4536e-04,  5.7734e-05,  3.5010e-05,\n             -9.2673e-05, -7.7261e-05,  2.4179e-04, -9.0557e-05, -3.3411e-04,\n             -5.2364e-05, -2.4411e-04, -7.4390e-05, -5.2060e-04,  2.9708e-05,\n              2.2821e-04, -4.1514e-04, -1.5878e-04,  3.3999e-05,  6.9419e-05,\n              2.3052e-04,  9.6544e-05, -1.8423e-04,  1.7266e-04, -2.6070e-05,\n             -5.6018e-04,  1.7949e-04, -3.7024e-04, -3.3340e-04, -9.6692e-05,\n              1.8650e-04,  6.0603e-05, -1.1653e-04,  2.6865e-04,  8.0237e-05,\n              2.1233e-04,  2.5985e-04,  4.0484e-04,  2.6886e-04, -6.6721e-05,\n              1.7782e-04,  3.0740e-04, -1.3521e-04,  6.2666e-04,  7.2842e-05,\n              5.5964e-04, -2.7373e-04,  1.4448e-04,  4.4859e-05, -1.6207e-04,\n             -1.0633e-04,  8.4158e-06, -2.6408e-04, -2.2430e-04, -3.5386e-04,\n             -1.2163e-04,  5.9757e-04,  1.2352e-04,  1.1486e-04, -7.5198e-05,\n              4.1880e-05,  2.0594e-04, -9.7819e-06, -7.1194e-05, -2.0919e-04,\n              2.3791e-04, -1.2761e-05, -3.2129e-04,  4.4816e-04, -2.8752e-04,\n             -2.0332e-04, -2.8284e-04,  5.6805e-05,  1.1836e-04,  2.1822e-04,\n              1.4778e-05, -2.4497e-04, -2.1194e-04,  9.7423e-05, -1.5524e-04,\n              1.3140e-05,  2.9620e-05, -2.4781e-05, -6.1270e-05, -5.5844e-05,\n             -1.0303e-04,  4.9631e-05,  8.5509e-05,  1.5008e-04, -3.2801e-05,\n              3.7420e-04, -5.1015e-05, -1.7432e-04, -3.5435e-04, -1.4746e-04,\n             -2.9060e-04,  6.2366e-05,  2.3061e-04, -1.6122e-04,  1.8658e-04,\n              5.6556e-05, -1.5929e-04,  9.2290e-05,  1.6399e-04,  7.6435e-05,\n              1.6551e-04, -1.9991e-04, -9.2314e-06,  1.4593e-04,  2.4581e-04,\n              1.9982e-04,  6.6492e-05,  1.5493e-04,  2.6985e-04,  1.2997e-04,\n             -4.8436e-04, -2.2754e-04, -1.3305e-05, -2.1134e-04,  1.1243e-04,\n             -9.0706e-05, -1.8397e-04, -1.3591e-05, -3.9842e-05, -9.0247e-07,\n              1.0106e-04,  5.0372e-05, -3.1774e-04]),\n     'exp_avg_sq': tensor([2.3392e-07, 3.4857e-07, 2.5319e-07, 1.0251e-07, 1.8462e-07, 1.5246e-07,\n             1.6877e-07, 1.2053e-07, 1.2886e-07, 2.1249e-07, 1.0786e-07, 1.2930e-07,\n             4.7007e-07, 1.7061e-07, 7.0270e-08, 1.6787e-07, 1.7868e-07, 1.1375e-07,\n             1.0564e-07, 1.6302e-07, 1.6830e-07, 9.3089e-08, 1.3013e-07, 1.1308e-07,\n             9.6823e-09, 9.5727e-08, 1.5916e-07, 3.5007e-07, 1.5683e-07, 2.5977e-07,\n             1.2847e-07, 1.3712e-07, 1.1296e-07, 1.3683e-07, 9.8293e-08, 1.4025e-07,\n             2.3734e-07, 1.6584e-07, 1.5303e-07, 9.7889e-08, 1.3529e-07, 2.1206e-07,\n             8.1127e-08, 1.4532e-07, 9.6142e-08, 1.0587e-07, 1.4340e-07, 1.5453e-07,\n             1.5028e-07, 2.0458e-07, 1.4173e-07, 1.8807e-07, 1.9339e-07, 1.9415e-07,\n             1.3877e-07, 1.2542e-07, 2.2842e-07, 1.9994e-07, 1.1570e-07, 1.4508e-07,\n             1.5697e-07, 1.1471e-07, 1.4892e-07, 7.9642e-08, 8.0766e-08, 1.7777e-07,\n             3.6417e-07, 1.1396e-07, 1.4661e-07, 3.3866e-07, 1.4176e-07, 1.6155e-07,\n             1.0559e-07, 1.3359e-07, 1.5116e-07, 1.4930e-07, 1.7088e-07, 1.5410e-07,\n             1.4735e-07, 1.9118e-07, 2.4537e-07, 1.3345e-07, 1.0877e-07, 1.5774e-07,\n             9.0875e-08, 1.7665e-07, 1.6519e-07, 8.2389e-08, 1.2305e-07, 1.8578e-07,\n             1.0046e-07, 1.6057e-07, 2.1892e-07, 1.6316e-07, 1.5388e-07, 1.2200e-07,\n             1.5521e-07, 3.5903e-07, 1.2327e-07, 1.3076e-07, 6.1815e-08, 1.5827e-07,\n             2.5946e-07, 2.0505e-07, 2.4810e-07, 9.8213e-07, 7.7449e-08, 1.2337e-07,\n             1.3972e-07, 1.4542e-07, 2.2707e-07, 1.6243e-07, 3.9967e-07, 1.5906e-07,\n             2.3416e-07, 2.1040e-07, 1.3437e-07, 1.1863e-07, 5.4331e-08, 4.4184e-07,\n             2.3000e-07, 1.6947e-07, 1.4552e-07, 9.1901e-08, 1.0059e-07, 8.2214e-08,\n             6.3307e-08, 1.1189e-07])},\n    43: {'exp_avg': tensor([ 1.8911e-04,  2.2145e-04,  2.5083e-04,  2.5029e-05,  8.8235e-05,\n             -1.6789e-04, -2.1420e-05,  3.3480e-04, -4.3763e-05, -3.8787e-04,\n             -1.8577e-05,  6.0484e-05, -7.7568e-05, -4.2236e-04,  1.6442e-05,\n              2.5289e-04, -2.8076e-04, -1.0658e-04,  1.0775e-04,  5.1706e-05,\n              4.0504e-05,  2.4210e-04, -1.1410e-04,  5.8465e-05, -1.4053e-05,\n             -3.9334e-04,  2.2466e-04, -5.6958e-04, -1.7073e-04, -5.0372e-05,\n              1.3860e-04,  6.6357e-05, -1.5629e-04,  1.7215e-05, -1.4917e-04,\n              7.6051e-05,  2.0682e-04,  2.3190e-04,  1.4988e-04, -3.3912e-04,\n              1.7207e-04,  1.7699e-04, -7.0447e-05,  3.3088e-04, -1.3092e-04,\n              2.4251e-04, -2.0569e-04,  1.0039e-04, -3.1393e-05,  1.4698e-05,\n              1.1566e-04, -1.2017e-04, -1.3581e-04, -1.3416e-04, -1.5375e-04,\n             -3.3619e-05,  2.5511e-04,  7.0141e-05,  1.3159e-04,  4.8438e-05,\n              3.1986e-05,  5.7153e-06,  1.3452e-04, -1.3602e-04, -1.1247e-04,\n              2.6899e-04, -7.7208e-06, -1.6520e-04,  3.8037e-04, -1.3270e-04,\n             -2.9587e-05, -1.1767e-04,  6.2112e-05, -1.1177e-05,  7.7628e-05,\n              1.8749e-05, -1.3734e-04, -2.3548e-04,  8.9708e-05, -7.5152e-05,\n              1.3116e-04, -9.0557e-05,  6.4751e-06, -1.0376e-04, -3.0108e-05,\n             -3.1873e-05, -7.3746e-05,  1.8596e-04,  1.6673e-04, -1.2077e-04,\n              3.5298e-04,  6.7120e-06, -6.4497e-05, -1.4597e-04, -6.0081e-05,\n             -2.4166e-04,  1.5262e-04,  7.3433e-05, -2.0986e-04,  3.8300e-05,\n              3.0030e-05, -5.3030e-05,  1.3674e-04,  1.0884e-04,  9.2521e-05,\n              3.2436e-04, -3.4925e-04, -9.3912e-05,  7.3374e-05,  1.8095e-04,\n              9.0663e-05,  7.8294e-05,  1.9400e-04,  1.4299e-04,  1.3220e-04,\n             -2.3060e-04, -2.8117e-04, -5.6984e-06, -2.5791e-04,  1.9692e-04,\n             -2.4133e-05,  9.0482e-05,  7.3214e-05, -2.3306e-05, -6.7515e-05,\n              7.0049e-05, -8.5351e-06, -2.0779e-04]),\n     'exp_avg_sq': tensor([8.3140e-08, 8.4992e-08, 8.0617e-08, 7.8744e-08, 1.3930e-07, 6.0025e-08,\n             1.4187e-07, 1.2366e-07, 1.4589e-07, 1.8892e-07, 4.7606e-08, 1.4755e-07,\n             1.6006e-07, 9.6790e-08, 6.4528e-08, 8.1548e-08, 1.1783e-07, 3.7825e-08,\n             6.3560e-08, 1.3460e-07, 1.0364e-07, 2.4808e-07, 8.6228e-08, 2.2746e-08,\n             2.3567e-08, 6.8511e-08, 9.7988e-08, 2.1261e-07, 9.0114e-08, 1.1878e-07,\n             1.0655e-07, 9.9558e-08, 5.1805e-08, 6.8765e-08, 1.4334e-07, 7.9164e-08,\n             1.2451e-07, 5.4620e-08, 1.2631e-07, 1.2104e-07, 6.1440e-08, 8.7784e-08,\n             8.7683e-08, 5.5525e-08, 1.0647e-07, 2.4503e-08, 8.3013e-08, 9.2862e-08,\n             7.4728e-08, 7.8043e-08, 1.6488e-07, 1.5882e-07, 7.6326e-08, 6.5752e-08,\n             1.3921e-07, 7.3824e-08, 1.5727e-07, 1.0132e-07, 7.5201e-08, 8.0820e-08,\n             8.6875e-08, 2.1516e-08, 1.1497e-07, 9.4590e-08, 4.9086e-08, 1.0751e-07,\n             1.9955e-07, 6.2169e-08, 9.6959e-08, 1.2697e-07, 6.1245e-08, 6.3818e-08,\n             9.9340e-08, 4.9305e-08, 9.4211e-08, 6.9507e-08, 9.1034e-08, 1.0904e-07,\n             5.4063e-08, 7.5183e-08, 1.7384e-07, 1.4254e-07, 1.9124e-08, 6.8146e-08,\n             7.1719e-08, 6.2965e-08, 9.4195e-08, 9.2927e-08, 9.9914e-08, 1.5895e-07,\n             1.0552e-07, 1.1753e-07, 8.5262e-08, 1.1306e-07, 1.4401e-07, 1.2908e-07,\n             9.2924e-08, 1.0178e-07, 8.2852e-08, 6.1847e-08, 4.4328e-08, 4.0565e-08,\n             1.1796e-07, 1.5280e-07, 1.4272e-07, 8.9275e-07, 8.8459e-08, 6.2539e-08,\n             4.4642e-08, 8.1381e-08, 9.4903e-08, 7.5179e-08, 1.8093e-07, 3.1160e-08,\n             1.3956e-07, 1.5290e-07, 7.3920e-08, 7.4275e-08, 5.6362e-08, 1.7815e-07,\n             1.2554e-07, 1.5481e-07, 7.3667e-08, 9.6873e-08, 3.6753e-08, 7.1731e-08,\n             2.3715e-07, 7.6319e-08])},\n    44: {'exp_avg': tensor([-2.8418e-04, -1.1931e-04,  1.9208e-04,  6.2766e-05,  3.5005e-06,\n             -1.5586e-04, -1.9127e-04,  7.3661e-05, -2.6025e-06,  2.2692e-04,\n              5.0466e-05,  1.1320e-04,  5.1231e-04,  3.5789e-04,  1.1315e-05,\n              8.2834e-05, -1.1972e-04, -9.3681e-05, -6.4533e-05, -1.5655e-04,\n             -2.3000e-04,  5.7244e-05, -8.2079e-05, -1.3567e-04, -4.7075e-04,\n             -7.2773e-05,  1.7944e-05, -6.7373e-05, -2.5991e-04, -7.4891e-06,\n             -1.4051e-04,  2.5362e-04,  1.0116e-04, -2.6889e-05, -2.3528e-04,\n             -3.5775e-04,  7.4678e-05, -6.9855e-05, -3.8968e-05, -5.1538e-05,\n              3.8374e-05,  5.5340e-05,  1.3842e-04,  5.6069e-05, -2.6334e-04,\n              4.0641e-04,  1.3607e-04, -6.7750e-05, -3.7039e-05, -4.5860e-06,\n              9.4146e-05,  1.2233e-05, -1.5848e-07, -5.6471e-05, -1.2630e-04,\n              2.3619e-04,  9.4548e-05,  1.0746e-05, -3.5548e-04,  1.7762e-04,\n              1.7160e-05,  2.8896e-05, -2.1134e-04,  4.6882e-04,  1.7391e-04,\n             -5.4749e-05,  4.6490e-05, -1.1805e-04,  7.5168e-05,  2.7420e-04,\n             -2.4202e-04, -3.3324e-04, -2.3084e-04, -2.0582e-04, -3.0573e-04,\n              2.9675e-05, -1.0871e-04, -3.4227e-04, -8.7052e-05,  1.3936e-04,\n              2.4478e-04, -2.1872e-04,  3.0752e-04, -2.1602e-04, -1.5675e-05,\n              2.3799e-04,  3.5483e-06, -1.7634e-04,  2.4990e-04, -5.3910e-05,\n             -3.1750e-05, -1.6759e-04,  1.9178e-04, -8.9740e-05, -1.2403e-04,\n             -1.4825e-04,  1.7706e-04, -1.2229e-04,  3.1874e-04, -8.9639e-05,\n             -1.4231e-04,  8.1477e-05,  3.3832e-04, -6.1078e-05, -1.9855e-04,\n              8.2852e-05,  1.7113e-04,  2.5841e-05, -5.2481e-04,  1.0725e-04,\n              2.9182e-05,  2.3481e-04,  1.7956e-04, -1.2546e-04, -3.0986e-04,\n              2.2723e-04, -1.3523e-04, -1.3869e-04,  2.5069e-04,  2.8858e-04,\n              1.3298e-05, -1.9129e-05,  2.8324e-04,  2.4151e-04,  7.0639e-05,\n              2.2033e-04, -3.1559e-05, -9.2213e-06]),\n     'exp_avg_sq': tensor([6.3583e-08, 1.7696e-07, 2.1471e-07, 6.4202e-08, 1.3346e-07, 8.1878e-08,\n             1.3053e-07, 5.3100e-08, 5.2123e-08, 4.6193e-08, 1.6987e-07, 1.1192e-07,\n             2.8432e-07, 2.6672e-07, 3.1165e-07, 6.0446e-08, 5.8146e-08, 3.8692e-08,\n             1.6321e-07, 4.5977e-08, 1.4561e-07, 1.2803e-07, 5.4237e-08, 2.0965e-08,\n             3.0108e-07, 9.7908e-08, 5.6501e-08, 7.0405e-08, 8.4823e-08, 7.0778e-08,\n             1.9778e-07, 1.3116e-07, 8.5390e-08, 7.7233e-08, 1.5564e-07, 4.2783e-08,\n             4.2771e-08, 4.4287e-08, 4.9616e-08, 4.8932e-08, 3.5035e-08, 4.9465e-08,\n             1.5115e-07, 5.4713e-08, 7.8412e-08, 3.2820e-07, 4.5289e-08, 4.9294e-08,\n             1.2353e-07, 6.1574e-08, 4.0215e-08, 8.2237e-08, 8.8599e-08, 4.0167e-08,\n             1.0512e-07, 9.9513e-08, 2.0694e-07, 3.6354e-08, 9.9755e-08, 2.6941e-07,\n             2.9259e-08, 4.8334e-08, 9.3557e-08, 1.3192e-07, 1.2559e-07, 8.2628e-08,\n             3.4064e-08, 4.3549e-08, 2.7572e-08, 9.0964e-08, 6.1233e-08, 3.2442e-07,\n             1.2338e-07, 8.4655e-08, 2.7477e-07, 1.1826e-07, 8.3165e-08, 1.1490e-07,\n             2.4355e-07, 2.1204e-07, 1.1198e-07, 5.3775e-08, 9.4641e-08, 5.0273e-08,\n             4.6034e-08, 4.5361e-08, 6.4065e-08, 5.7952e-08, 4.2365e-08, 1.3819e-07,\n             4.9752e-08, 8.8275e-08, 4.5033e-08, 7.6001e-08, 2.9618e-07, 8.3682e-08,\n             5.9718e-08, 5.9548e-08, 3.4976e-07, 3.8746e-08, 1.2867e-07, 3.8047e-08,\n             4.5794e-07, 4.0563e-08, 1.3326e-07, 4.4705e-08, 6.2431e-08, 4.5258e-07,\n             3.1123e-07, 3.1069e-08, 8.0291e-08, 1.1467e-07, 4.6506e-08, 1.9102e-07,\n             2.6882e-07, 1.5263e-07, 4.5477e-08, 4.7017e-08, 1.5670e-07, 7.5671e-08,\n             8.3977e-08, 8.3018e-08, 1.1022e-07, 7.3069e-08, 7.3444e-08, 6.0982e-08,\n             5.5996e-08, 3.2392e-08])},\n    45: {'exp_avg': tensor([-8.1298e-05, -7.2790e-06,  2.4518e-04,  4.1370e-06, -1.4206e-04,\n             -6.5410e-05, -1.3154e-04,  5.4485e-06,  7.7869e-05,  1.2148e-04,\n              8.8899e-05,  1.3011e-04,  3.4956e-04,  1.3750e-06,  2.3486e-05,\n              6.8908e-05, -9.4320e-05,  9.1078e-05, -2.4096e-04, -1.2863e-04,\n              4.3438e-07,  1.4325e-04,  3.5180e-05, -9.7822e-05, -2.2893e-05,\n             -2.1679e-05,  1.0579e-05, -6.7768e-05, -7.6827e-05,  7.5013e-05,\n             -4.1337e-05, -1.5193e-05,  6.2943e-05, -8.4220e-05, -1.9398e-05,\n             -2.1814e-04, -3.6295e-05, -3.8122e-05, -1.3680e-05,  1.2562e-04,\n              2.8772e-05, -9.0311e-05,  1.0402e-04,  4.3917e-05, -6.3417e-05,\n              2.3724e-04,  8.5092e-05, -3.3582e-05, -2.1484e-04, -6.0062e-05,\n              6.4099e-05, -5.1678e-05, -3.9500e-05, -1.0134e-04, -1.6539e-04,\n             -1.3891e-04,  3.1381e-05,  1.0706e-04,  1.8199e-04, -1.3274e-05,\n             -5.0286e-05,  7.6527e-05, -9.9853e-05,  6.9151e-05,  1.1796e-04,\n             -1.1044e-04,  7.9096e-05, -3.8364e-05,  3.9881e-05,  1.6531e-04,\n             -8.0742e-05, -4.8849e-05, -4.3002e-05, -8.5746e-05, -8.4228e-05,\n              8.8623e-05,  2.7084e-05,  8.3538e-06,  1.4474e-05, -3.8128e-05,\n              7.2237e-05, -1.1374e-04,  1.2197e-04, -1.8011e-04,  7.9198e-06,\n              2.0746e-04, -1.3388e-04, -1.5590e-04,  1.7151e-04, -1.6665e-04,\n             -1.9346e-05, -2.7210e-04,  1.8589e-04, -2.0438e-05,  1.1750e-05,\n             -2.3205e-04,  1.1856e-04, -1.9104e-04,  6.7430e-05, -1.5474e-04,\n             -6.0541e-05,  2.5522e-05,  2.7806e-04,  4.2079e-05, -8.7104e-05,\n              4.7906e-06, -1.4734e-05,  2.2192e-05, -1.9208e-05,  1.5592e-04,\n             -7.4798e-05,  1.9413e-04,  1.5738e-04, -1.3889e-04, -3.2967e-05,\n             -2.3932e-04, -1.7705e-05, -1.5742e-04,  2.1972e-04,  2.1114e-04,\n              4.1548e-05, -1.2842e-05, -1.4526e-04,  1.2691e-04,  1.6877e-04,\n              1.1788e-04, -2.5821e-05,  1.9236e-05]),\n     'exp_avg_sq': tensor([1.2900e-08, 1.9353e-08, 9.4439e-08, 1.4800e-08, 4.3726e-08, 3.5836e-08,\n             6.9556e-08, 2.9403e-08, 4.1358e-08, 1.6443e-08, 2.5122e-08, 5.6434e-08,\n             1.0485e-07, 1.0412e-07, 6.2610e-09, 2.3244e-08, 4.6065e-08, 3.3421e-08,\n             7.1638e-08, 2.8510e-08, 1.0825e-08, 9.1453e-08, 4.1395e-08, 1.1524e-08,\n             8.1238e-09, 5.5938e-08, 3.2853e-08, 2.2932e-08, 7.3885e-08, 3.5947e-08,\n             2.9457e-08, 7.6883e-08, 3.7198e-08, 1.9469e-08, 6.0791e-08, 2.7682e-08,\n             2.8333e-08, 1.4328e-08, 2.8770e-08, 1.5088e-08, 2.5832e-08, 2.3462e-08,\n             5.6332e-08, 4.1376e-08, 4.2703e-08, 9.3798e-08, 3.3210e-08, 2.1884e-08,\n             3.2745e-08, 4.4037e-08, 3.2800e-08, 4.6385e-08, 3.2181e-08, 2.6771e-08,\n             3.1959e-08, 6.7853e-08, 1.2047e-08, 3.9078e-08, 4.6218e-08, 1.5125e-09,\n             1.9933e-08, 2.7176e-08, 5.9962e-08, 6.4316e-08, 3.6048e-08, 4.8516e-08,\n             2.1982e-08, 2.4551e-08, 1.5665e-08, 3.7496e-08, 3.0334e-08, 9.8261e-09,\n             8.1420e-08, 7.8884e-08, 7.1945e-09, 5.9254e-08, 3.4244e-08, 4.2260e-08,\n             4.5219e-10, 1.1098e-08, 4.0255e-08, 2.6357e-08, 7.1877e-08, 2.6613e-08,\n             2.1590e-08, 3.1316e-08, 3.9714e-08, 3.2992e-08, 2.3810e-08, 2.4539e-08,\n             1.9293e-08, 4.8103e-08, 2.6234e-08, 2.2844e-08, 1.1614e-08, 5.8886e-08,\n             5.5323e-08, 5.3352e-08, 1.1507e-07, 6.5621e-08, 9.3045e-08, 1.8393e-08,\n             1.3090e-07, 3.5282e-08, 1.5861e-08, 2.8349e-08, 2.5861e-08, 5.5638e-09,\n             8.4110e-09, 2.7752e-08, 3.2187e-08, 5.0852e-08, 3.8959e-08, 1.4200e-08,\n             2.2963e-08, 5.9018e-08, 2.4600e-08, 4.4409e-08, 7.7856e-08, 4.1088e-08,\n             4.4157e-08, 5.6910e-08, 6.2917e-08, 4.5440e-08, 5.8575e-08, 2.8594e-08,\n             2.4064e-08, 2.4415e-08])},\n    46: {'exp_avg': tensor([ 1.6898e-04,  2.5253e-04, -1.9761e-06, -2.2845e-05, -1.3488e-04,\n              7.2473e-05,  8.4897e-05,  3.7256e-05,  1.3465e-05, -1.1296e-04,\n             -1.0001e-04, -1.3725e-05,  1.8288e-04,  1.6561e-04, -1.8807e-05,\n              1.6400e-04,  2.2672e-05,  4.1001e-04,  1.2100e-04, -3.3660e-05,\n              3.6494e-05, -1.5571e-04,  1.5151e-04,  4.6233e-05, -1.4242e-04,\n              1.8392e-04,  1.8198e-05,  1.9654e-05,  1.9764e-04, -1.1315e-05,\n             -1.1854e-04,  8.2208e-05, -1.2861e-04, -2.6563e-04,  3.4551e-05,\n             -3.7338e-05,  5.7404e-05, -9.7789e-05, -2.6571e-05,  1.6487e-04,\n              6.9577e-05,  5.0457e-05,  1.1447e-04,  1.9502e-04,  2.2185e-04,\n             -1.4156e-04, -1.3282e-04,  7.0344e-05,  1.3581e-04,  3.0734e-05,\n              9.9480e-05,  5.0341e-05, -1.1063e-05, -4.3561e-05,  8.8136e-06,\n              2.9972e-05,  1.9857e-05,  1.9512e-04,  7.3720e-05, -1.0785e-04,\n             -1.9729e-04,  6.8102e-06,  1.1798e-05, -4.1964e-05,  2.2775e-04,\n              8.8796e-06, -2.3832e-06, -1.4011e-04,  1.3231e-04, -1.2380e-04,\n             -1.8131e-04,  2.0075e-05,  4.2975e-05, -7.1999e-05,  6.2632e-05,\n              5.3936e-06, -8.9152e-05,  1.2231e-06, -1.4425e-04,  2.9707e-05,\n              1.3872e-05,  3.4700e-05, -1.6641e-04,  7.5351e-05,  1.5451e-04,\n              2.1742e-04, -1.3125e-04,  3.4452e-05,  4.9507e-05, -3.6657e-05,\n              6.9628e-05,  1.1591e-05, -9.5961e-05,  3.9368e-04,  6.5176e-05,\n              1.7197e-04, -9.2358e-05, -5.4929e-05, -1.2163e-04,  4.7998e-05,\n             -6.2841e-05, -7.1882e-05,  1.9299e-05, -5.2887e-05, -7.8720e-05,\n             -1.2043e-05, -5.7430e-05, -2.7880e-05, -8.3261e-05,  5.5478e-04,\n             -1.3999e-04,  1.8593e-05,  2.2137e-05,  1.5591e-05,  2.0642e-04,\n             -7.8260e-05, -1.9476e-04, -7.8160e-05,  3.0732e-06, -9.6872e-05,\n              5.7279e-05, -6.8718e-05,  1.5875e-04,  8.2218e-05, -1.1388e-04,\n              3.2860e-05, -1.3154e-04,  2.2638e-05, -3.1612e-05,  2.6179e-05,\n             -4.8796e-05,  9.9360e-05,  2.7141e-05, -1.5048e-04, -1.7423e-04,\n              3.4195e-05,  1.2298e-04,  5.2948e-06,  7.9688e-05,  1.0702e-05,\n              5.9090e-05,  8.6073e-05, -4.4563e-05, -1.2576e-04,  1.3547e-05,\n              1.9234e-05, -3.1770e-05,  3.4141e-04, -7.6603e-05, -4.0939e-05,\n              1.2208e-04,  4.1380e-04,  2.9219e-04,  5.3772e-05, -1.4103e-04,\n              3.5116e-04, -2.1948e-04, -1.0263e-04,  1.2873e-04, -7.6089e-05,\n              1.6376e-04,  4.7144e-05,  7.4564e-06,  2.1587e-05,  1.2313e-04,\n             -2.9578e-05,  8.4336e-05,  2.8105e-06,  1.7956e-04, -9.3462e-05,\n              1.0873e-04,  1.3135e-04,  4.7630e-05,  4.0507e-05,  2.5264e-05,\n              1.1701e-05,  2.6053e-04, -1.2156e-04, -1.4992e-04,  7.1969e-05,\n             -1.3487e-04, -5.4041e-05,  9.1371e-05, -1.2628e-04,  4.4728e-04,\n             -1.0752e-04,  2.2931e-04,  6.6155e-05,  1.6772e-05,  1.0031e-04,\n              1.6985e-04,  3.4635e-05, -8.7576e-05, -1.0951e-04, -6.2275e-05,\n             -2.1716e-05, -1.2807e-05, -2.2829e-04, -1.2765e-04,  3.0123e-05,\n             -1.5056e-04,  1.3972e-04,  1.9694e-05, -6.2472e-05, -5.5239e-05,\n              2.5767e-04, -2.7200e-05, -2.1903e-04, -3.0457e-05,  2.7272e-04,\n             -2.0562e-05, -1.0970e-05,  1.0435e-04,  1.0993e-04,  1.2044e-04,\n              1.3418e-04, -1.4804e-04, -3.8361e-05, -6.1272e-05,  2.9649e-05,\n             -1.7989e-04,  4.6843e-05, -1.2922e-04, -2.5759e-04,  3.7080e-04,\n             -1.1613e-04,  1.4707e-04, -5.2790e-05,  1.1759e-04, -1.0219e-04,\n             -5.4322e-05,  4.8298e-05, -9.7946e-05, -3.1398e-05,  1.5543e-04,\n              1.3105e-04, -7.5291e-05, -1.0689e-05, -4.7926e-06,  7.2994e-05,\n              5.6080e-05,  1.6677e-04,  3.5883e-04,  2.6915e-05,  2.5591e-04,\n             -1.7196e-04, -1.7487e-04, -9.9590e-05, -2.4910e-04,  1.7024e-04,\n             -1.1443e-04, -2.5476e-04,  1.4841e-04, -1.4428e-04, -1.3787e-04,\n              4.5820e-05, -3.5971e-05, -9.1029e-06, -2.4142e-04,  2.3445e-04,\n              1.8270e-04,  3.0290e-04, -1.6139e-04,  1.6377e-04,  8.1320e-05,\n              3.7886e-05,  2.6253e-04,  1.3642e-04, -7.6254e-05,  6.7517e-05,\n              1.7972e-04, -5.1433e-05,  3.8737e-05, -6.2813e-05,  3.8607e-05,\n             -5.9658e-05,  7.6762e-05,  9.7070e-05, -8.1284e-06,  1.3547e-05,\n             -1.1060e-05, -1.2859e-05,  5.0389e-05,  2.7115e-05,  2.3893e-04,\n             -7.7038e-05, -6.8188e-06,  7.3967e-05,  1.6022e-04,  1.4244e-04,\n             -8.0880e-05, -3.6055e-05,  9.2611e-05,  6.8333e-05,  3.0201e-05,\n              1.2548e-05,  1.2345e-04,  1.3036e-04,  4.5226e-05,  9.1754e-05,\n             -2.1461e-04, -1.5025e-04,  2.2225e-05, -9.3265e-05,  2.1198e-05,\n             -7.3758e-05,  1.4197e-04,  1.5220e-04,  9.6043e-05, -1.8363e-04,\n              1.4573e-04, -2.0663e-04,  1.7008e-05, -4.1048e-05,  1.2980e-04,\n             -1.1967e-05,  4.4294e-05,  1.4848e-04,  1.3727e-04,  3.1786e-05,\n             -6.0872e-05,  1.3809e-04, -1.7532e-04, -1.5756e-04, -4.1256e-05,\n              5.8870e-05,  1.4201e-04, -7.5197e-05, -1.0859e-04, -1.4721e-04,\n             -2.0530e-05,  7.2033e-05,  9.8118e-05, -6.5725e-06,  7.9758e-05,\n             -8.1520e-06, -8.6227e-05,  2.7119e-05,  1.5217e-05, -1.0054e-05,\n              3.0720e-04,  2.2783e-05, -1.2621e-04,  2.6672e-05,  6.7248e-05,\n              1.7375e-04, -3.3346e-05, -9.1981e-05, -1.9352e-04,  1.9506e-04,\n             -9.4252e-05,  8.0080e-05,  7.3577e-05,  1.0793e-04,  2.0553e-05,\n             -2.4101e-06,  5.8041e-05,  2.0035e-05, -4.1018e-04,  9.3303e-05,\n              8.5586e-05, -2.2456e-04, -2.8224e-05,  8.4247e-05, -1.7990e-06,\n             -1.9410e-06, -2.2174e-04, -1.4924e-05, -1.8395e-06, -7.6927e-05,\n             -4.1010e-05,  3.8665e-05,  5.0585e-04, -7.6971e-05,  6.4201e-05,\n             -4.0424e-05,  3.8337e-04, -1.3465e-04, -4.6207e-05,  2.1404e-04,\n             -1.6456e-04, -1.6055e-04,  1.6550e-05, -6.0597e-05,  6.5382e-05,\n              2.0541e-05, -1.7000e-04,  9.7464e-05, -1.6775e-04, -1.5144e-04,\n              2.4492e-04, -3.4672e-05,  2.0448e-04,  2.2729e-04, -1.3757e-04,\n              5.2961e-05, -4.8654e-05, -1.4242e-04,  1.0418e-05, -3.6470e-05,\n             -2.0716e-04,  8.0655e-05,  1.5267e-04, -1.2708e-04,  2.6527e-05,\n             -1.6903e-04,  2.7228e-04,  2.6354e-05, -9.1449e-06, -3.4815e-05,\n              4.1764e-05,  5.9781e-05, -1.5420e-04,  1.0549e-04,  1.8472e-04,\n              8.2830e-05, -4.1926e-05, -1.3044e-04,  6.9666e-05,  6.5380e-05,\n             -1.3379e-04,  1.7698e-04,  2.2929e-04, -1.7356e-04, -2.5039e-05,\n             -4.8245e-05, -6.1105e-05, -4.0511e-05, -1.2655e-04,  5.8683e-05,\n             -5.9699e-05,  6.7001e-05, -5.8481e-05,  7.7154e-05,  1.6538e-04,\n              1.0613e-06, -8.3396e-05,  1.2174e-04,  1.4667e-04, -2.8810e-05,\n             -6.0879e-06,  1.5292e-05, -2.9056e-04, -2.6369e-04, -5.6648e-05,\n             -2.3098e-04,  1.8347e-04, -7.6612e-05,  1.3671e-04,  1.3281e-04,\n             -2.0702e-05,  2.1376e-05,  1.3354e-04,  1.7614e-04,  3.5913e-06,\n             -1.0574e-05, -1.3618e-05,  7.7877e-05, -1.0914e-04,  8.3555e-05,\n             -8.5802e-05, -5.0704e-05,  9.7989e-05, -2.1087e-05,  9.2607e-05,\n              7.9696e-06,  1.4188e-06, -8.6531e-05, -2.1336e-05, -1.8997e-04,\n             -1.4932e-05, -1.4489e-05, -3.6972e-05,  6.4412e-05,  6.4593e-05,\n              4.0796e-05,  1.1298e-04, -8.8157e-05, -1.6038e-05,  8.4520e-05,\n              7.0921e-05,  1.2292e-04,  9.3068e-05,  1.1347e-04,  5.0137e-05,\n              2.7794e-05, -2.7255e-04, -4.2044e-05,  4.4455e-05,  2.9582e-05,\n              1.1302e-04,  1.1318e-04, -1.0265e-04,  1.1077e-04,  1.4854e-04,\n             -2.8822e-04, -1.9011e-04, -4.0524e-04, -7.5151e-05,  1.3651e-05,\n              1.2205e-04, -1.4400e-04,  9.1145e-05,  1.1680e-04, -2.2805e-05,\n             -2.6972e-04, -3.4383e-05, -2.2318e-04,  2.4687e-04, -1.0120e-04,\n             -8.7882e-05, -1.8098e-04]),\n     'exp_avg_sq': tensor([7.4729e-08, 4.7530e-08, 4.6551e-08, 9.5411e-08, 5.7714e-08, 9.7904e-09,\n             3.4118e-08, 4.1019e-08, 1.1379e-08, 1.5969e-08, 1.0139e-07, 3.9015e-08,\n             5.9858e-08, 1.7570e-08, 2.5131e-08, 5.4062e-08, 1.8471e-08, 4.6466e-08,\n             1.1273e-08, 5.8839e-08, 3.7480e-08, 2.8460e-08, 5.6373e-08, 5.0277e-08,\n             1.9222e-08, 5.2955e-08, 6.4033e-08, 4.9763e-08, 5.6171e-08, 1.2650e-07,\n             8.0609e-08, 2.9864e-08, 3.7571e-08, 5.7249e-08, 4.2972e-08, 8.8277e-08,\n             5.3104e-08, 1.0412e-07, 3.9436e-08, 4.9416e-08, 1.0914e-07, 1.1383e-08,\n             4.9902e-08, 4.7891e-08, 2.4615e-07, 2.2632e-08, 1.8244e-08, 2.3340e-08,\n             1.1068e-07, 1.7508e-08, 2.3150e-08, 3.0567e-08, 5.3489e-08, 2.3435e-08,\n             8.0647e-08, 6.3274e-08, 7.3532e-08, 8.1192e-08, 1.5451e-08, 1.3277e-08,\n             2.1183e-08, 6.9293e-08, 5.1012e-08, 1.6003e-08, 5.1929e-08, 1.5534e-08,\n             1.2353e-08, 4.3976e-08, 2.3006e-08, 7.5052e-08, 4.7924e-08, 7.4214e-08,\n             2.1970e-08, 3.5363e-08, 3.1667e-08, 1.5644e-08, 3.4783e-08, 5.0628e-08,\n             4.6497e-08, 4.5899e-08, 8.6140e-09, 1.4285e-08, 8.6114e-08, 5.5338e-08,\n             7.8687e-08, 2.8143e-08, 6.1345e-08, 3.2008e-08, 4.6570e-08, 6.5839e-08,\n             1.7590e-08, 5.9526e-08, 4.9244e-08, 1.6460e-07, 2.2060e-08, 4.8916e-08,\n             1.3801e-08, 2.5410e-08, 5.0509e-08, 3.5848e-08, 1.2912e-08, 3.5444e-08,\n             2.4080e-08, 2.0031e-08, 4.9176e-08, 2.4988e-08, 7.5534e-08, 3.1072e-08,\n             1.6454e-08, 4.2126e-07, 3.5644e-08, 2.2045e-08, 4.7402e-08, 6.4442e-08,\n             1.7608e-08, 1.6706e-07, 5.3595e-08, 2.5941e-08, 2.8672e-08, 2.7187e-08,\n             1.4757e-08, 2.9695e-08, 9.2802e-08, 4.7797e-08, 4.8194e-08, 3.1516e-08,\n             3.4187e-08, 7.4672e-08, 7.6970e-08, 2.5533e-08, 3.3842e-08, 7.1767e-08,\n             6.5702e-08, 7.4948e-08, 9.4958e-08, 6.4798e-08, 3.0507e-08, 1.1712e-07,\n             2.1605e-08, 1.3936e-08, 4.6277e-08, 6.9806e-08, 2.9252e-08, 2.4616e-08,\n             1.0437e-08, 1.7055e-08, 2.8328e-08, 2.2612e-07, 4.5746e-08, 3.5555e-08,\n             7.4320e-08, 8.0945e-08, 6.1789e-08, 1.9765e-08, 3.9231e-08, 3.4223e-07,\n             1.2501e-07, 4.7976e-08, 2.0744e-08, 3.7524e-08, 1.7412e-08, 4.5390e-08,\n             3.8015e-08, 9.2253e-08, 1.8250e-08, 1.9080e-08, 1.0418e-08, 2.4979e-08,\n             5.6800e-08, 3.7204e-08, 6.3432e-08, 2.9056e-08, 2.3462e-08, 6.2056e-08,\n             1.8095e-08, 6.1005e-08, 7.3913e-08, 3.8787e-08, 4.1793e-08, 3.9854e-08,\n             2.8739e-08, 1.8134e-08, 5.1279e-08, 9.8165e-08, 8.2104e-08, 5.1796e-08,\n             5.3668e-08, 3.2236e-08, 1.0981e-07, 1.0496e-07, 1.4809e-08, 3.5446e-08,\n             4.5929e-08, 4.8261e-08, 6.5568e-08, 1.6128e-08, 1.6387e-08, 2.3520e-08,\n             2.6169e-08, 2.9630e-08, 5.4615e-08, 4.1131e-08, 1.5039e-08, 1.9547e-07,\n             3.9934e-08, 1.3934e-07, 1.3811e-08, 1.0730e-07, 1.7196e-08, 6.7483e-08,\n             7.6475e-08, 3.2464e-08, 1.1564e-08, 2.1741e-08, 2.0743e-08, 7.4103e-08,\n             4.3151e-08, 2.2066e-08, 1.3327e-08, 4.1510e-08, 2.6887e-08, 3.5047e-08,\n             3.8552e-08, 3.7488e-08, 7.2324e-08, 2.2301e-08, 6.0946e-08, 2.6927e-08,\n             1.5607e-08, 6.8687e-08, 2.6257e-08, 2.0311e-08, 3.3653e-08, 7.5054e-08,\n             3.2312e-08, 5.4418e-08, 1.0077e-08, 1.4304e-08, 6.8297e-08, 1.7896e-08,\n             1.9264e-08, 7.5446e-08, 1.0417e-07, 2.1299e-08, 4.4791e-08, 4.4105e-08,\n             8.7231e-08, 3.5819e-08, 1.6138e-07, 6.8274e-08, 3.3086e-08, 6.4437e-08,\n             6.2353e-08, 6.4092e-08, 2.8942e-08, 1.2548e-08, 3.0168e-08, 5.2845e-08,\n             4.3170e-08, 1.2980e-07, 6.5349e-08, 1.3219e-07, 3.9949e-08, 2.2541e-08,\n             8.2105e-08, 4.6463e-08, 1.7229e-07, 1.0144e-07, 9.3133e-08, 1.6139e-08,\n             5.2137e-08, 7.2235e-09, 1.9334e-08, 6.4873e-08, 8.0583e-08, 7.0805e-08,\n             1.0203e-08, 3.8125e-08, 3.1886e-08, 9.8692e-09, 4.5282e-08, 6.8072e-08,\n             2.9846e-08, 1.2992e-07, 1.4618e-07, 8.7191e-09, 1.7089e-08, 9.2830e-08,\n             5.2812e-08, 4.3538e-08, 4.5449e-08, 1.5324e-07, 4.2773e-08, 1.6846e-08,\n             1.6131e-08, 2.8750e-08, 9.4050e-08, 2.8926e-08, 5.2079e-08, 4.8823e-08,\n             2.2773e-08, 3.6180e-08, 1.7000e-08, 5.2674e-08, 1.4252e-08, 4.8765e-08,\n             7.1472e-08, 4.6229e-08, 1.1714e-08, 9.7600e-08, 6.5869e-08, 2.7292e-08,\n             6.0203e-08, 1.5312e-08, 4.0650e-08, 7.6476e-08, 2.5264e-08, 2.3356e-08,\n             7.6953e-08, 3.8637e-08, 2.5113e-08, 8.1730e-08, 7.3096e-08, 4.2538e-08,\n             3.0444e-08, 5.5745e-08, 1.9807e-08, 1.1238e-08, 9.8557e-08, 5.3518e-08,\n             1.5543e-07, 2.1268e-08, 1.6647e-08, 4.6675e-08, 1.0400e-08, 5.3792e-08,\n             3.0107e-08, 2.2289e-08, 1.8881e-08, 1.0088e-07, 4.8624e-08, 9.8163e-08,\n             6.5295e-08, 1.9803e-08, 5.9184e-09, 6.5321e-08, 1.7533e-08, 1.7598e-08,\n             5.7005e-08, 3.9495e-08, 1.3097e-08, 2.9348e-08, 3.2366e-08, 6.1970e-08,\n             2.3519e-08, 2.9244e-08, 1.6378e-08, 4.8630e-08, 1.2980e-07, 3.3257e-08,\n             9.4794e-08, 4.9258e-08, 9.2569e-09, 1.8229e-07, 5.2834e-08, 3.2809e-08,\n             7.9703e-08, 4.8546e-08, 2.8549e-08, 7.9546e-08, 1.0752e-07, 2.8332e-08,\n             1.1793e-07, 8.6974e-08, 3.7604e-08, 3.2257e-08, 4.4037e-08, 4.0722e-08,\n             2.4138e-08, 4.8925e-08, 2.2306e-08, 4.1707e-08, 1.6853e-08, 4.8494e-08,\n             2.6664e-08, 4.5825e-08, 3.8646e-08, 1.6248e-07, 3.2545e-08, 2.5045e-08,\n             1.1711e-07, 3.2918e-08, 3.8177e-08, 4.8385e-08, 5.8613e-08, 1.2012e-08,\n             4.2178e-08, 3.5499e-08, 2.6423e-08, 1.6189e-08, 3.3935e-08, 1.8100e-08,\n             4.5195e-08, 5.8487e-08, 2.0583e-08, 7.5607e-08, 5.8573e-08, 1.0572e-08,\n             3.4811e-08, 8.9486e-08, 7.7706e-08, 2.6309e-07, 1.8332e-08, 1.3820e-08,\n             5.9844e-08, 4.5240e-08, 2.6741e-08, 3.0547e-08, 5.3475e-08, 5.3673e-08,\n             3.1996e-08, 2.8293e-08, 2.8269e-08, 5.0368e-08, 7.5082e-08, 9.0424e-08,\n             2.9457e-08, 1.9171e-08, 6.8817e-08, 9.3798e-09, 3.3143e-08, 3.4123e-08,\n             1.8747e-08, 4.1676e-08, 5.8913e-08, 4.1728e-08, 7.2656e-08, 3.1594e-08,\n             6.6357e-08, 1.2097e-08, 1.5568e-08, 5.4102e-08, 5.5120e-08, 4.8997e-08,\n             2.1368e-08, 5.0440e-08, 2.3585e-08, 2.5619e-08, 6.0829e-08, 4.7478e-08,\n             1.7752e-08, 5.3033e-08, 5.5878e-08, 2.1562e-08, 1.2488e-08, 1.4441e-08,\n             4.5760e-08, 5.0755e-08, 1.3067e-08, 3.3389e-08, 4.0629e-08, 1.6130e-08,\n             1.9206e-08, 8.7054e-08, 2.2140e-08, 6.0671e-08, 5.7556e-09, 3.9543e-08,\n             5.8355e-08, 4.1448e-08, 3.9001e-08, 1.1208e-07, 2.3577e-08, 1.0909e-07,\n             1.5724e-08, 7.0712e-08, 1.0689e-07, 1.9206e-08, 4.6939e-08, 8.7825e-08,\n             9.7386e-08, 6.1555e-08, 3.1167e-08, 1.0124e-07, 2.5391e-08, 1.8885e-08,\n             3.9974e-08, 6.7533e-08, 3.2177e-08, 8.7808e-08, 1.9389e-08, 5.1268e-08,\n             2.4947e-08, 4.1214e-08, 8.4465e-08, 8.7418e-08, 5.5108e-08, 6.2840e-08,\n             4.9654e-08, 2.0424e-08, 2.5731e-08, 1.8101e-08, 1.4801e-08, 5.4937e-08,\n             5.3772e-08, 4.2348e-08, 4.0450e-08, 6.0872e-08, 5.0656e-08, 2.2923e-08,\n             1.5327e-07, 3.1392e-08])},\n    47: {'exp_avg': tensor([-1.4705e-05,  1.5594e-04,  3.5102e-10,  4.2593e-05,  1.1504e-06,\n             -6.7040e-05,  2.2868e-05,  1.6324e-05, -1.3903e-05, -3.1680e-05,\n             -1.9642e-06, -1.0336e-05, -4.3284e-06, -1.0698e-05, -1.2159e-04,\n             -5.0172e-05,  3.0184e-05,  1.9201e-05, -1.2023e-05, -2.3750e-05,\n              2.1914e-06,  2.5993e-05,  1.7326e-06, -1.7036e-11,  1.1921e-04,\n              2.9656e-06, -3.1081e-08,  5.5022e-06,  1.4698e-06,  1.3083e-07,\n             -1.6641e-05, -9.1709e-06,  1.1925e-04, -3.8343e-05, -3.8681e-06,\n             -6.2899e-09, -3.0981e-06,  2.9791e-07, -6.7799e-05,  7.4329e-06,\n              1.2540e-05, -8.1195e-06, -7.1962e-06, -1.5733e-05, -6.0451e-11,\n             -7.7559e-05, -1.5975e-05,  3.3058e-05, -3.6176e-09,  1.7573e-05,\n             -1.0640e-05,  9.9634e-06,  1.0342e-07, -1.7607e-05,  3.0604e-05,\n              7.3606e-06, -6.7393e-06,  5.8274e-06, -2.0904e-05,  3.9777e-05,\n             -6.2594e-05, -2.7557e-09,  4.6788e-05,  2.1637e-05,  4.5016e-07,\n             -2.1691e-05,  4.3390e-05, -2.7195e-06,  3.6727e-05,  1.6682e-11,\n             -1.3103e-04,  1.4700e-06,  6.1772e-05,  1.2574e-04,  9.3854e-11,\n              1.0429e-04, -2.0152e-06,  5.0573e-05,  2.3017e-06, -1.4384e-06,\n              1.1976e-05,  5.5341e-05,  2.8876e-06, -8.4098e-06,  4.9375e-06,\n              5.8256e-05, -7.6574e-05, -1.8095e-05,  3.3118e-06, -5.4152e-06,\n             -2.3387e-05,  4.6227e-06, -6.4772e-07,  1.0235e-10,  4.1683e-05,\n             -1.6653e-05, -1.6156e-05,  6.4908e-11, -1.4100e-05, -5.4258e-05,\n             -1.6148e-05, -6.1857e-05, -6.5614e-06,  9.8595e-05, -1.0060e-05,\n             -2.4447e-05,  1.6539e-05, -1.9240e-06,  4.3997e-05,  1.9976e-05,\n             -5.7246e-05, -2.5757e-05,  1.1511e-05,  6.1516e-06, -1.2948e-04,\n             -5.5018e-05, -2.8359e-07,  2.8338e-05,  1.2069e-05,  6.8272e-05,\n             -5.9678e-05,  7.9761e-06, -7.7360e-07, -4.8885e-11, -2.2824e-06,\n              6.0169e-05,  4.7903e-05, -2.0701e-06, -2.0303e-09, -1.8841e-06,\n              1.0989e-05, -1.1335e-05,  1.9132e-05, -5.9556e-11, -1.1325e-05,\n              1.7938e-05,  1.0666e-04,  6.5189e-08,  7.2695e-05,  3.2836e-05,\n              7.7513e-06,  1.4231e-05, -1.5124e-04, -1.4997e-05, -2.7888e-05,\n             -8.5846e-05, -5.2802e-05,  1.5388e-10,  7.4979e-06,  1.3460e-04,\n             -8.1251e-07,  6.4292e-06,  1.6936e-05,  1.1480e-04,  1.6790e-06,\n              9.6635e-07,  1.1944e-04, -3.7895e-06, -2.8292e-05,  4.1303e-05,\n             -8.7714e-05, -1.2782e-05,  1.3569e-05, -4.7067e-11,  1.0534e-04,\n             -4.5114e-05,  9.9616e-05,  6.6457e-05, -2.3634e-07,  5.3759e-11,\n              7.5692e-06, -1.5816e-05, -5.2612e-06,  3.4567e-11,  6.0933e-06,\n             -1.7191e-05, -9.4272e-06, -1.6100e-05,  8.5938e-11, -2.7828e-06,\n              5.9299e-05, -2.5144e-05,  6.7871e-05, -3.1871e-08,  2.4618e-07,\n              6.9816e-06,  2.1297e-05,  2.9010e-05,  2.4906e-06,  2.8098e-06,\n              1.2077e-04, -2.0246e-06, -3.5196e-05, -2.0322e-06,  1.0806e-06,\n             -4.6843e-05, -1.7575e-05, -1.0420e-05,  5.0678e-05, -1.5144e-04,\n             -3.0785e-06, -4.6899e-06, -1.9662e-05,  6.8886e-08, -3.9095e-05,\n              2.0272e-06,  1.7036e-05,  1.1106e-10,  6.6952e-05,  2.0148e-06,\n              4.2025e-11, -3.3869e-11,  2.2269e-05, -3.2514e-05, -1.1009e-04,\n              3.3767e-06,  5.3214e-05,  3.5006e-05,  4.0674e-05, -1.0864e-04,\n             -2.1611e-06, -9.9232e-06,  6.7110e-07,  6.1774e-05,  2.9012e-08,\n              2.5528e-05, -9.3160e-05,  1.1512e-05,  1.1981e-05, -2.6551e-07,\n             -5.0162e-05,  7.6887e-05,  4.8866e-05, -2.8995e-06, -5.1055e-12,\n              2.8368e-05, -2.0621e-05, -3.7226e-05,  4.7611e-06, -7.1577e-05,\n             -4.4473e-06, -1.7494e-05, -1.9694e-06,  3.0989e-05,  1.5298e-06,\n             -1.1595e-06,  9.1544e-06, -2.8407e-05, -1.3640e-06,  4.6697e-06,\n             -5.7076e-05,  1.2038e-04, -2.4897e-07, -1.9808e-05,  9.7844e-05,\n              2.9875e-05,  3.7798e-05,  4.6834e-05, -9.2751e-05, -2.4087e-06,\n             -1.6087e-07,  8.1441e-11, -1.2410e-04, -2.6793e-06,  4.8862e-06,\n             -1.5803e-05, -1.0439e-09, -6.6196e-06,  5.7701e-07,  3.5076e-05,\n              1.6568e-05,  3.1829e-05,  6.5334e-05, -3.8890e-06,  2.5979e-06,\n             -3.5716e-06, -2.1855e-05, -7.8740e-07, -4.7615e-05, -3.5538e-05,\n             -3.2972e-06,  8.8897e-06,  1.0222e-04, -1.3309e-09,  1.3385e-06,\n             -9.7430e-06,  3.4553e-05, -2.2619e-06, -1.9781e-05,  1.0003e-06,\n             -1.3131e-05,  1.0958e-10,  2.0263e-05,  2.8321e-05, -5.9334e-05,\n             -4.7599e-05,  1.8663e-10, -1.9048e-06,  1.3807e-06,  9.4000e-06,\n              2.7579e-05, -2.0793e-06, -3.0375e-05,  3.2011e-05,  4.3483e-05,\n              5.1019e-05,  8.4278e-05,  2.8051e-05,  2.0705e-05, -6.3008e-06,\n             -7.1798e-06,  1.0463e-04,  1.0095e-05,  7.4521e-05,  4.5877e-07,\n              2.9800e-11,  2.6729e-05,  1.1144e-04,  5.2556e-06, -5.7665e-05,\n              7.4935e-05,  1.1829e-05, -5.1803e-06, -4.5608e-06,  7.4642e-05,\n             -2.4244e-05,  1.9568e-05, -9.1255e-06, -3.3019e-06, -1.7223e-05,\n              8.2545e-11,  1.1838e-04, -1.6708e-04,  5.6230e-06, -3.1368e-05,\n              6.6589e-06,  7.8388e-05,  2.4968e-05,  4.2666e-05, -1.7527e-07,\n              5.3467e-05,  3.1939e-06,  1.1012e-04, -5.0276e-05,  4.0087e-05,\n             -1.5237e-05, -3.3922e-05, -2.9982e-05, -5.9161e-06, -1.4142e-04,\n              9.0567e-05, -1.0458e-05,  3.1888e-05, -2.3844e-07,  3.3814e-05,\n             -2.0827e-05,  5.6246e-05, -4.1896e-06,  1.4454e-10,  3.9984e-05,\n              1.0313e-04, -8.4106e-06, -9.9755e-07,  4.2849e-08, -1.8813e-05,\n              2.4580e-05,  6.7748e-09,  3.1585e-05,  5.6834e-05, -1.0615e-10,\n             -1.6795e-05,  6.6007e-06, -1.7267e-11,  1.4938e-07,  1.0100e-05,\n              5.7595e-06, -2.7428e-06, -1.5865e-05, -8.3102e-05,  6.6338e-07,\n             -1.5690e-04,  1.6505e-05,  2.7094e-05,  9.1728e-05, -4.2121e-05,\n              1.3106e-06, -2.4939e-05, -1.8144e-07, -5.1144e-05, -1.1975e-04,\n             -2.1065e-10,  7.4748e-06,  3.6657e-05, -6.5009e-05,  1.6786e-04,\n             -6.2943e-05, -3.1311e-05,  7.8019e-06, -2.0105e-05, -3.9055e-05,\n             -5.1626e-06, -1.7565e-05, -3.0843e-05,  3.9063e-05, -5.3308e-06,\n             -1.0734e-06,  5.9007e-11,  4.8188e-05, -7.2331e-05, -4.9875e-11,\n              1.8299e-07,  7.9346e-11,  9.5597e-05, -8.3952e-05, -2.3502e-05,\n             -1.5219e-05, -1.8572e-05,  5.0504e-05,  1.9829e-06, -2.7894e-06,\n              2.8079e-06, -9.8212e-07,  1.9436e-06, -2.4646e-06,  2.1660e-05,\n              2.5569e-10,  4.7259e-05, -5.8958e-05,  5.7701e-06, -1.6644e-04,\n             -4.1901e-05,  5.4743e-05, -7.3877e-07,  3.0247e-08, -2.6302e-05,\n             -2.6731e-07, -5.2072e-06,  4.5074e-06,  6.4589e-06,  2.0933e-05,\n              8.3123e-06, -2.8846e-07, -9.4002e-05,  2.7971e-06, -4.5550e-05,\n              1.4704e-04, -1.3748e-05,  7.3089e-06,  1.4671e-06, -9.0217e-06,\n              6.0087e-07, -5.3335e-05, -4.2819e-07, -9.3994e-06,  2.4522e-06,\n              3.2272e-06, -5.2229e-06,  1.9171e-05,  6.4882e-05, -2.2883e-07,\n              2.9027e-07, -3.7848e-05, -1.2734e-05, -7.9845e-07, -5.7103e-05,\n             -1.1946e-05,  7.2604e-06, -3.1119e-06,  6.9026e-07, -7.2481e-06,\n             -1.5070e-05,  2.5452e-11, -1.0903e-10,  8.7298e-06, -2.2148e-05,\n              2.9870e-07,  4.0199e-11,  3.6961e-05, -7.5335e-06,  8.0214e-06,\n             -1.3154e-06, -1.3443e-05, -5.8047e-05,  1.6213e-05,  6.9557e-05,\n             -4.8366e-05,  1.5925e-05,  7.5387e-06, -1.0054e-05, -1.1360e-06,\n             -5.2411e-05, -3.8624e-11, -8.0084e-05, -1.0578e-06, -1.2650e-07,\n             -8.6532e-10,  9.0970e-07,  9.8025e-07,  6.9355e-05,  1.3572e-04,\n              7.4140e-05,  4.4594e-05,  2.9788e-05,  6.5853e-06,  5.9617e-06,\n              9.4131e-05,  1.1727e-06, -8.1195e-06,  1.3070e-04,  2.1513e-05,\n             -1.1004e-07,  3.3739e-06]),\n     'exp_avg_sq': tensor([2.6740e-10, 2.2642e-08, 1.1745e-19, 3.6885e-08, 2.6746e-12, 9.0487e-09,\n             7.3197e-09, 2.6739e-10, 9.9211e-09, 5.7929e-09, 1.4471e-09, 6.7712e-10,\n             2.6789e-11, 2.1645e-09, 1.6950e-08, 5.3053e-09, 9.5095e-09, 2.1453e-09,\n             7.1423e-09, 5.8247e-10, 2.1711e-08, 4.2369e-09, 1.8206e-10, 8.8717e-21,\n             1.8904e-08, 1.1221e-10, 2.3786e-14, 7.4961e-11, 1.2380e-09, 1.4463e-12,\n             3.4085e-10, 1.0864e-10, 2.8368e-08, 1.6978e-08, 4.3687e-11, 1.7677e-14,\n             1.6574e-10, 2.2205e-10, 1.7655e-08, 1.4173e-10, 1.1795e-10, 5.7906e-09,\n             8.7590e-11, 1.0128e-09, 3.7740e-20, 1.0808e-08, 4.0292e-09, 8.0001e-09,\n             8.8980e-13, 9.3092e-09, 1.3812e-08, 2.4642e-10, 2.9399e-11, 1.1555e-08,\n             1.5256e-09, 9.8008e-11, 1.0147e-08, 2.5317e-11, 8.4302e-09, 1.1523e-08,\n             7.8354e-09, 1.7986e-12, 3.4732e-08, 1.1704e-08, 2.3018e-10, 9.2348e-09,\n             1.0632e-08, 1.1430e-10, 1.1138e-08, 1.3331e-20, 2.2102e-08, 4.0863e-10,\n             7.3081e-09, 1.4003e-08, 1.5532e-20, 1.3154e-08, 1.2469e-08, 2.0785e-08,\n             6.3901e-11, 3.3792e-10, 7.4237e-09, 8.1560e-09, 3.1115e-12, 8.2626e-10,\n             2.0502e-10, 4.0975e-09, 7.6769e-09, 8.2544e-09, 1.0710e-11, 1.7795e-10,\n             6.1658e-09, 1.6248e-08, 1.2476e-10, 1.7179e-20, 1.0854e-08, 1.9006e-09,\n             1.3276e-08, 7.1113e-21, 1.3756e-09, 2.0878e-08, 7.8522e-09, 1.3762e-08,\n             1.4969e-08, 1.1596e-08, 5.7826e-10, 2.4138e-09, 6.2625e-10, 5.2938e-11,\n             9.6141e-09, 2.3093e-08, 1.3011e-08, 1.3351e-08, 1.2583e-09, 3.1919e-10,\n             9.7640e-09, 4.3590e-09, 2.9551e-11, 1.1088e-08, 5.1405e-09, 1.3994e-08,\n             1.2509e-08, 8.1438e-09, 1.9389e-10, 1.4222e-13, 2.7886e-11, 2.8421e-09,\n             7.9491e-09, 2.5292e-10, 2.6349e-16, 1.0041e-08, 1.5310e-08, 7.3227e-11,\n             6.2433e-10, 3.2612e-20, 2.1239e-10, 2.2170e-10, 2.0730e-08, 2.4281e-13,\n             9.0558e-09, 1.5412e-09, 2.9629e-10, 3.7946e-10, 1.0998e-08, 1.3380e-08,\n             1.2598e-08, 1.5908e-08, 1.6748e-08, 3.2780e-15, 3.0212e-09, 1.2255e-08,\n             7.1410e-13, 1.6649e-09, 6.3588e-10, 7.3060e-09, 2.7035e-11, 6.2630e-12,\n             7.9519e-09, 2.1664e-11, 9.5447e-09, 2.0719e-08, 9.4843e-09, 8.5812e-10,\n             5.0813e-10, 3.0020e-20, 1.2153e-08, 8.8511e-09, 8.6024e-09, 9.4689e-09,\n             3.2057e-12, 1.0433e-20, 1.3259e-10, 1.6865e-09, 2.3806e-08, 1.2890e-20,\n             7.5299e-09, 3.9410e-09, 7.4964e-11, 8.6407e-10, 6.6131e-18, 1.9978e-08,\n             1.2882e-08, 1.1584e-08, 1.4775e-08, 1.5524e-14, 1.0723e-11, 1.4356e-10,\n             3.8221e-10, 1.6145e-08, 3.1523e-11, 3.7412e-08, 8.3523e-09, 2.8527e-11,\n             1.2334e-09, 2.0297e-10, 7.4847e-12, 2.0208e-08, 1.1159e-08, 4.7448e-09,\n             1.8925e-08, 1.0951e-08, 4.8348e-10, 1.2154e-10, 1.0727e-08, 1.3484e-13,\n             2.0286e-08, 1.1521e-10, 6.1148e-09, 4.8756e-17, 9.0557e-09, 2.3176e-12,\n             1.3945e-20, 1.2939e-20, 7.4244e-09, 7.7120e-09, 9.8697e-09, 9.8456e-10,\n             9.7732e-09, 9.9425e-09, 4.3963e-09, 2.4591e-08, 1.5144e-08, 5.0599e-09,\n             2.2416e-10, 1.6527e-08, 2.1010e-11, 9.1654e-09, 1.6894e-08, 1.4336e-08,\n             9.5324e-09, 5.3071e-12, 1.2057e-08, 8.3111e-09, 5.5508e-09, 4.2337e-11,\n             8.9529e-21, 4.8521e-10, 9.0266e-09, 5.9599e-09, 1.5463e-10, 8.6686e-09,\n             1.4320e-08, 2.8673e-08, 6.1601e-12, 4.2649e-09, 4.2561e-11, 1.5482e-11,\n             3.2782e-10, 1.7435e-08, 8.2645e-12, 1.2732e-10, 5.7351e-09, 2.4167e-08,\n             7.0695e-11, 2.3703e-09, 1.1093e-08, 7.7699e-09, 7.0524e-09, 1.7979e-08,\n             1.8103e-08, 1.5540e-10, 5.4060e-11, 1.6026e-20, 1.5334e-08, 1.6541e-10,\n             2.6227e-09, 3.1163e-10, 3.6423e-13, 3.4743e-10, 1.7043e-11, 1.4184e-08,\n             2.4933e-08, 3.1879e-09, 1.0437e-08, 1.7321e-10, 1.1008e-11, 2.4716e-11,\n             9.8526e-09, 4.7653e-11, 2.0158e-08, 7.7544e-09, 3.3462e-10, 2.9494e-09,\n             1.5407e-08, 4.0081e-14, 1.4204e-10, 3.7153e-09, 8.2847e-09, 1.0473e-11,\n             2.8053e-08, 8.0075e-12, 4.3667e-10, 2.1853e-20, 1.9529e-10, 9.3983e-09,\n             1.1399e-08, 2.0378e-08, 6.0476e-20, 1.9465e-08, 4.9516e-11, 1.0690e-10,\n             1.2597e-08, 1.5323e-10, 1.0941e-08, 3.2838e-09, 7.3229e-09, 3.7981e-09,\n             4.2429e-08, 2.2721e-08, 6.7166e-09, 5.1198e-11, 4.9335e-11, 1.5949e-08,\n             3.4956e-10, 8.4015e-09, 1.6877e-12, 9.3883e-21, 9.8798e-09, 8.5851e-09,\n             6.2132e-10, 1.8864e-08, 1.4709e-08, 2.1163e-09, 1.0617e-10, 1.4390e-10,\n             1.3379e-08, 3.6941e-08, 8.5550e-09, 2.5051e-09, 8.0619e-10, 7.9724e-10,\n             2.8256e-20, 1.7390e-08, 1.4210e-08, 1.9835e-11, 4.6628e-09, 9.1086e-11,\n             1.7770e-08, 1.7693e-08, 8.2616e-09, 1.5054e-13, 2.6708e-08, 2.0621e-11,\n             3.1894e-08, 8.6871e-09, 3.7677e-09, 3.6161e-10, 9.6525e-09, 9.0702e-09,\n             6.3563e-11, 1.8501e-08, 6.1176e-09, 1.7009e-09, 1.6314e-08, 2.0515e-13,\n             9.9471e-09, 7.5170e-09, 1.1534e-08, 2.6638e-08, 3.6155e-20, 1.4167e-08,\n             1.9580e-08, 1.5709e-08, 1.0462e-08, 1.6688e-14, 1.9010e-08, 1.5089e-08,\n             1.6130e-13, 3.6941e-09, 8.3487e-09, 3.0565e-20, 1.0896e-09, 1.2988e-08,\n             1.4953e-20, 1.1800e-13, 3.8669e-10, 5.7285e-10, 5.9126e-10, 1.3965e-08,\n             1.5894e-08, 3.0813e-11, 1.0484e-08, 2.9595e-09, 7.2833e-09, 1.6431e-08,\n             1.1315e-08, 2.2951e-10, 1.0225e-09, 1.3983e-13, 1.5801e-08, 1.7986e-08,\n             6.0977e-20, 3.6529e-10, 1.8905e-09, 1.3467e-08, 2.9546e-08, 8.3313e-09,\n             1.0694e-09, 1.3539e-09, 8.2838e-09, 1.0456e-08, 4.8851e-10, 8.2148e-09,\n             1.6964e-08, 4.8815e-09, 1.3947e-08, 6.0400e-12, 3.6289e-20, 6.0961e-09,\n             1.5652e-08, 1.0515e-20, 7.0281e-13, 2.6479e-20, 1.1930e-08, 1.0000e-08,\n             2.2113e-09, 5.2606e-10, 9.8072e-09, 1.4496e-08, 1.8960e-10, 1.8195e-10,\n             1.5901e-08, 1.7037e-11, 1.9783e-11, 6.9638e-12, 6.4402e-10, 2.4729e-20,\n             1.4813e-08, 1.5473e-08, 1.8602e-09, 1.0668e-08, 9.5529e-09, 1.2515e-08,\n             1.1561e-08, 1.3549e-15, 6.5870e-09, 9.8249e-11, 2.8414e-11, 2.2068e-11,\n             6.0156e-11, 1.2881e-08, 6.4716e-09, 6.9076e-12, 1.8318e-08, 1.3203e-11,\n             9.4341e-09, 3.3720e-08, 9.0867e-09, 9.1182e-09, 1.1789e-10, 1.0896e-09,\n             9.4450e-09, 1.3641e-08, 5.6849e-11, 9.4872e-09, 6.3799e-09, 9.5816e-09,\n             1.3051e-09, 5.1428e-10, 1.3111e-08, 2.2981e-08, 1.9771e-09, 8.6223e-09,\n             8.1269e-09, 1.1533e-11, 1.8973e-08, 1.3681e-09, 5.7140e-09, 5.1272e-11,\n             4.4912e-12, 3.2030e-10, 1.3399e-08, 1.3121e-20, 1.7961e-14, 3.6903e-09,\n             1.0275e-08, 1.0118e-11, 1.7014e-20, 2.0002e-08, 9.0491e-11, 5.0764e-11,\n             8.8998e-13, 3.6372e-10, 1.0486e-08, 1.0277e-09, 1.0049e-08, 6.9795e-09,\n             1.4006e-08, 1.6128e-08, 4.1635e-11, 1.0244e-11, 7.5657e-09, 2.7347e-20,\n             1.3633e-08, 4.9303e-10, 2.8072e-13, 5.3672e-16, 1.0796e-10, 4.2759e-12,\n             2.0678e-08, 1.3441e-08, 1.1555e-08, 1.2822e-08, 1.1082e-08, 1.4926e-09,\n             1.5507e-10, 1.3699e-08, 2.4422e-08, 8.8383e-10, 2.8089e-08, 8.1531e-09,\n             4.3653e-11, 1.7042e-10])},\n    48: {'exp_avg': tensor([-1.7442e-04,  1.9690e-04,  1.7381e-04, -1.1573e-04,  6.7530e-04,\n             -3.4393e-04, -1.0221e-04, -6.7967e-05, -5.8109e-04, -5.3019e-05,\n              1.1748e-04, -6.2661e-04, -5.3147e-04, -7.7305e-05,  2.4179e-04,\n             -1.9395e-04,  6.1209e-05, -4.2294e-04, -1.6881e-04,  1.1732e-04,\n              2.5734e-04,  7.2811e-04, -1.2353e-04, -8.3141e-06, -2.2893e-04,\n              1.7975e-04,  2.8215e-04,  1.3038e-04,  4.2638e-04,  3.0902e-04,\n              8.5813e-05,  6.0364e-05, -4.4417e-04, -1.0901e-04, -2.9395e-04,\n              3.7081e-05,  1.1019e-04,  1.8522e-04, -1.7787e-04, -4.3317e-05,\n              2.3109e-04, -2.4143e-05, -2.1202e-04,  1.9961e-04,  2.7075e-04,\n              1.6435e-04, -1.8842e-04, -2.5377e-04, -3.2382e-04,  6.1397e-04,\n             -2.6804e-04, -1.0404e-04,  5.3539e-06, -2.6715e-04, -1.2911e-04,\n              4.5961e-04,  8.0081e-06, -8.9007e-05,  2.7764e-04,  1.8882e-04,\n              4.1742e-04,  4.3877e-04, -1.2839e-04,  2.1686e-05, -2.4367e-04,\n              1.3996e-04,  1.1734e-05, -3.6256e-04, -4.3943e-04, -2.6546e-04,\n              4.5442e-04,  1.4750e-04,  3.2816e-04,  1.6297e-04,  2.6401e-04,\n             -2.6053e-04,  7.6315e-05, -6.6429e-04,  2.6815e-04,  2.3918e-04,\n              2.6768e-05,  1.4198e-04, -1.1548e-04,  6.3182e-04, -8.3967e-05,\n             -3.1934e-04,  1.1126e-04,  6.6866e-04,  3.1643e-04, -1.6638e-05,\n              1.5860e-04,  2.0511e-04,  3.8410e-04,  4.1193e-05,  3.2332e-04,\n             -1.2320e-04, -3.1301e-04, -1.6109e-04, -1.2995e-04, -1.3340e-04,\n             -2.8736e-04, -3.2371e-04, -1.4734e-04,  7.1878e-05,  4.9190e-04,\n             -3.0834e-04, -2.7226e-05, -9.0474e-04, -1.5169e-04, -2.5276e-04,\n             -2.6310e-04, -1.2341e-04, -7.7636e-05, -3.4405e-04, -7.5338e-05,\n             -1.0173e-04,  4.9194e-05,  7.7697e-04, -3.9005e-04,  8.7832e-05,\n              5.9077e-05, -1.0216e-04, -3.8132e-05, -2.4749e-04,  3.9955e-05,\n              3.1957e-05, -3.6072e-04,  6.9994e-04, -8.1282e-05, -1.5807e-04,\n             -1.8930e-06,  8.3766e-04,  8.3774e-05, -3.1502e-04,  1.2140e-04,\n              2.8841e-04, -2.1470e-04,  8.3141e-05, -3.8402e-04,  7.2590e-04,\n              7.9319e-05,  1.9545e-05, -6.2091e-04, -1.8362e-04,  3.3898e-04,\n             -1.8471e-05,  1.8732e-04, -3.1330e-04, -5.1838e-04,  1.7820e-04,\n             -1.2900e-04,  7.8002e-05, -2.7973e-04, -5.9676e-05,  5.5705e-05,\n             -3.8259e-04, -1.4320e-04,  4.4993e-04, -4.9125e-04, -9.2809e-05,\n             -1.6977e-04,  1.1176e-04, -3.8923e-05,  3.5691e-04, -2.8147e-07,\n              4.0403e-06,  2.1289e-04, -1.9925e-04,  4.8973e-04,  2.6674e-04,\n             -1.4758e-04,  9.3870e-05, -1.3137e-04, -1.8621e-04, -2.1015e-04,\n             -1.4321e-04, -2.1669e-05, -2.0771e-04, -4.9790e-05, -2.8806e-04,\n              2.6743e-04,  1.8078e-04, -5.3356e-05, -1.6712e-04,  1.8691e-04,\n              1.8076e-04, -1.9765e-04, -9.5865e-05, -1.0690e-04,  1.0038e-05,\n             -3.4256e-05,  7.1785e-05, -1.2676e-04, -2.4125e-04,  1.7831e-04,\n              9.9275e-05, -6.0800e-04,  7.9959e-05, -3.5603e-05,  2.1251e-04,\n              5.9437e-04,  1.5329e-04, -2.4420e-04,  1.4295e-04,  5.5323e-05,\n              7.5248e-04,  4.8419e-04,  1.9562e-04, -1.3586e-05, -4.8113e-05,\n             -1.1326e-04, -2.4864e-04, -2.8136e-04, -3.9479e-04,  4.8345e-04,\n             -4.5037e-05, -4.7353e-05, -4.9699e-04, -4.2497e-05,  8.7118e-05,\n              2.2291e-05, -1.7961e-04, -2.1905e-04, -2.7903e-05,  1.6216e-04,\n             -2.6768e-04,  7.4791e-05, -3.1511e-04, -1.5718e-04, -9.2773e-05,\n             -1.4849e-04,  3.6163e-04,  7.9003e-04, -1.9893e-04, -2.9336e-04,\n              9.2194e-05,  3.0625e-04, -2.8831e-04, -2.7351e-04, -1.9103e-04,\n             -2.6453e-05, -8.2224e-04,  2.0821e-04,  5.4389e-04,  1.4832e-04,\n             -7.7471e-04,  5.6467e-05,  1.8674e-04, -1.5025e-05, -2.6044e-04,\n              1.0446e-04,  2.4984e-04,  1.6398e-04,  3.2417e-04, -1.6199e-05,\n              7.3364e-04]),\n     'exp_avg_sq': tensor([1.5227e-07, 2.7636e-07, 2.4474e-07, 3.1763e-07, 2.5597e-07, 1.4618e-07,\n             1.5172e-07, 2.8430e-07, 2.4851e-07, 2.1323e-07, 1.8991e-07, 2.1740e-07,\n             1.5535e-07, 2.0552e-07, 2.2088e-07, 3.0288e-07, 2.1595e-07, 1.4924e-07,\n             2.0947e-07, 1.4006e-07, 2.2752e-07, 3.4957e-07, 2.7876e-07, 1.4490e-07,\n             1.9034e-07, 1.4960e-07, 1.5951e-07, 2.2921e-07, 3.4874e-07, 1.5442e-07,\n             1.2845e-07, 1.9050e-07, 2.0831e-07, 2.9980e-07, 3.7154e-07, 2.7042e-07,\n             2.5292e-07, 1.7696e-07, 3.0046e-07, 3.1488e-07, 4.1203e-07, 2.4579e-07,\n             1.9093e-07, 1.9642e-07, 2.7793e-07, 1.0530e-07, 1.8222e-07, 1.4376e-07,\n             1.2309e-07, 1.7002e-07, 4.9405e-07, 2.3725e-07, 1.3930e-07, 4.1446e-07,\n             1.9189e-07, 1.7693e-07, 2.2802e-07, 3.6373e-07, 1.9787e-07, 3.6065e-07,\n             1.3486e-07, 3.4748e-07, 2.8961e-07, 1.7669e-07, 1.8206e-07, 2.8613e-07,\n             1.7220e-07, 2.3951e-07, 2.4714e-07, 3.2462e-07, 1.9501e-07, 2.6406e-07,\n             1.8469e-07, 4.1647e-07, 1.1501e-07, 2.7659e-07, 2.6046e-07, 2.7155e-07,\n             2.4060e-07, 1.7260e-07, 2.4129e-07, 1.6572e-07, 1.8233e-07, 2.0661e-07,\n             3.3472e-07, 2.0371e-07, 1.5840e-07, 2.0905e-07, 2.0529e-07, 1.6856e-07,\n             2.0421e-07, 2.9027e-07, 2.2777e-07, 4.3285e-07, 2.3166e-07, 2.6128e-07,\n             2.6506e-07, 2.9545e-07, 2.1722e-07, 2.7938e-07, 1.4450e-07, 2.8156e-07,\n             1.8890e-07, 2.9417e-07, 1.9923e-07, 3.2577e-07, 2.7214e-07, 2.6001e-07,\n             1.5505e-07, 1.8894e-07, 2.4865e-07, 2.5725e-07, 1.9045e-07, 2.2691e-07,\n             1.7054e-07, 2.0120e-07, 2.6143e-07, 2.5761e-07, 1.6228e-07, 2.3892e-07,\n             1.3979e-07, 1.7108e-07, 1.9669e-07, 3.5241e-07, 2.8667e-07, 1.7249e-07,\n             2.8741e-07, 3.6728e-07, 1.4955e-07, 1.6558e-07, 2.2171e-07, 5.1868e-07,\n             1.7239e-07, 2.3545e-07, 2.1871e-07, 2.7011e-07, 2.9740e-07, 2.7721e-07,\n             1.7556e-07, 2.1453e-07, 2.2243e-07, 2.8192e-07, 2.3346e-07, 1.6753e-07,\n             2.0314e-07, 3.5449e-07, 1.6441e-07, 2.7253e-07, 3.3353e-07, 1.3937e-06,\n             2.3172e-07, 2.1885e-07, 2.9499e-07, 2.9424e-07, 1.7984e-07, 1.9707e-07,\n             3.5735e-07, 2.4961e-07, 1.4155e-07, 1.5658e-07, 1.6869e-07, 1.6842e-07,\n             2.4593e-07, 2.7344e-07, 2.7342e-07, 3.9102e-07, 2.2028e-07, 2.1633e-07,\n             3.8015e-07, 3.9387e-07, 1.8975e-07, 2.9480e-07, 1.9988e-07, 7.3010e-08,\n             2.2467e-07, 1.9714e-07, 2.7238e-07, 2.8916e-07, 1.7623e-07, 1.9499e-07,\n             2.7119e-07, 2.0333e-07, 3.1818e-07, 1.1925e-07, 3.4021e-07, 1.7160e-07,\n             2.7851e-07, 1.5533e-07, 2.6130e-07, 2.6755e-07, 1.6092e-07, 1.8190e-07,\n             2.6286e-07, 1.8833e-07, 3.2664e-07, 2.5562e-07, 4.7913e-07, 1.8677e-07,\n             1.5633e-07, 2.6980e-07, 2.2390e-07, 1.8108e-07, 2.1006e-07, 1.8693e-07,\n             1.8455e-07, 2.0298e-07, 2.6101e-07, 2.3381e-07, 2.3901e-07, 2.3125e-07,\n             1.7624e-07, 1.5975e-07, 1.6716e-07, 2.2316e-07, 2.4037e-07, 1.8127e-07,\n             2.5171e-07, 1.5021e-07, 2.1154e-07, 2.2340e-07, 2.7850e-07, 2.1871e-07,\n             1.7421e-07, 3.1257e-07, 2.3388e-07, 2.0406e-07, 2.1767e-07, 2.6966e-07,\n             2.1908e-07, 1.1018e-07, 3.6798e-07, 2.3502e-07, 2.5714e-07, 2.7731e-07,\n             1.8769e-07, 2.3287e-07, 2.3674e-07, 4.3131e-07, 2.2073e-07, 1.4896e-07,\n             2.6414e-07, 3.4495e-07, 2.8409e-07, 2.1302e-07, 2.5733e-07, 3.9281e-07,\n             2.8169e-07, 2.1324e-07, 2.4698e-07, 1.4597e-07, 1.4676e-07, 2.3346e-07,\n             1.1823e-07, 2.6356e-07, 2.3856e-07, 2.0768e-07])},\n    49: {'exp_avg': tensor([-9.2455e-05,  1.0878e-04,  3.5929e-05, -8.2867e-05,  3.8678e-04,\n             -1.4137e-04, -7.3967e-05, -7.5452e-05, -5.4379e-04, -3.6210e-05,\n              6.0814e-05, -3.2987e-04, -2.3814e-04,  1.0865e-04,  2.3657e-04,\n             -2.2963e-04,  6.4743e-05, -4.1249e-04, -1.7601e-04,  1.9506e-04,\n              1.1430e-04,  3.5513e-04,  2.7304e-05, -4.6070e-05, -8.6633e-05,\n              1.6984e-04,  1.7667e-04,  1.3197e-04,  3.0457e-04,  4.3212e-04,\n              8.7100e-05,  1.2342e-05, -5.1514e-04, -4.8831e-04, -7.8822e-05,\n             -8.0855e-07, -1.8934e-05,  5.0429e-05,  7.2732e-05, -2.9259e-05,\n              1.8651e-04, -1.8272e-05, -4.1676e-05,  1.9127e-04,  1.0544e-04,\n              1.1754e-04, -1.6190e-04, -1.0060e-04, -2.1809e-04,  2.8919e-04,\n              8.8221e-05, -6.7573e-05,  8.0048e-05, -3.1107e-04, -2.1962e-05,\n              2.6384e-04, -2.5615e-04, -1.1548e-04,  4.2676e-05,  1.6148e-04,\n              3.8017e-04,  2.5152e-04, -2.0968e-04,  2.5938e-06, -9.8575e-05,\n              1.6724e-04, -9.1223e-05, -2.0005e-04, -2.0846e-04, -1.9768e-04,\n              2.4693e-04,  9.3842e-05,  2.3716e-04,  1.7038e-04,  1.7001e-04,\n             -1.0523e-04, -5.1270e-05, -1.9106e-04,  2.3253e-04,  2.0381e-04,\n             -4.6728e-05,  2.3681e-05, -1.7942e-04,  3.3883e-04, -1.5122e-04,\n             -1.2680e-04,  6.1761e-05,  3.0563e-04,  1.8526e-04, -5.4188e-05,\n              8.2915e-05,  3.7755e-04,  2.6559e-04, -1.5217e-04,  3.1529e-04,\n             -2.1282e-05, -3.2019e-04, -1.8938e-04, -2.2168e-04, -1.9303e-04,\n             -2.0691e-04, -1.2358e-05, -5.0665e-05, -3.7493e-06,  2.0353e-04,\n             -4.3645e-04, -1.1555e-04, -5.5150e-04, -1.3338e-04, -1.3888e-04,\n             -1.4591e-04, -7.0105e-05, -1.4164e-04, -1.7396e-04, -1.3371e-05,\n             -9.8913e-05,  2.1853e-05,  3.5932e-04, -2.1373e-04,  1.0502e-04,\n             -4.4958e-05, -6.1424e-05,  1.4377e-05, -2.3246e-04, -1.4269e-05,\n              9.8472e-05, -1.8951e-04,  7.7842e-04, -3.7429e-05, -4.0449e-05,\n              7.2347e-05,  3.6100e-05,  1.1058e-04, -2.2531e-04,  1.8853e-04,\n              1.2084e-04, -8.1842e-05, -1.2607e-05, -2.8919e-04,  2.9878e-04,\n              9.1832e-05,  1.3629e-04, -4.1234e-04, -1.4162e-04,  1.6677e-04,\n              8.8684e-05,  1.4556e-04, -1.4044e-04, -2.6850e-04,  1.0418e-04,\n             -1.1923e-04,  1.0730e-04, -1.3101e-04,  1.4218e-05,  2.2304e-05,\n             -1.0283e-04, -7.9100e-05,  3.0072e-04, -3.0729e-04, -4.1433e-05,\n             -6.1689e-05,  6.9292e-05, -2.5543e-05,  1.3664e-04, -1.5677e-04,\n             -2.9658e-05,  7.5307e-05, -1.1060e-04,  5.1025e-04,  1.4496e-04,\n             -2.0357e-04, -9.1734e-06, -1.8098e-04, -1.6245e-04, -2.8069e-05,\n             -8.3783e-05,  6.8885e-06, -6.6691e-05, -3.3037e-05, -1.9246e-04,\n              1.6309e-04,  6.8663e-05,  1.6121e-04,  3.8329e-05,  2.8379e-04,\n              2.0900e-05, -1.9142e-05, -9.4529e-05, -1.8315e-04, -3.5096e-05,\n             -1.9330e-07,  7.9413e-05, -1.8596e-04, -1.2787e-04,  7.9155e-06,\n             -5.6800e-05, -2.3986e-04,  5.7331e-07, -2.0851e-05,  6.9082e-05,\n              4.3105e-04,  1.5256e-04, -1.3235e-04,  9.0571e-05, -1.5629e-05,\n              4.0998e-04,  3.4450e-04,  1.0776e-04, -2.9304e-05, -7.1543e-05,\n             -1.2927e-04, -1.1027e-04, -1.1501e-04, -2.1048e-04,  2.6393e-04,\n             -3.6545e-05, -4.7052e-05, -2.5672e-04, -1.4781e-06,  9.0580e-05,\n             -1.2546e-04, -3.5291e-05, -1.7339e-04, -8.1361e-05,  7.7670e-05,\n             -1.8024e-04,  4.0129e-05, -1.8221e-04, -7.2365e-05, -6.0783e-05,\n             -3.2302e-05,  1.9142e-04,  4.6649e-04, -1.5165e-04, -2.9174e-04,\n             -7.4330e-05,  1.3852e-04, -2.1425e-04, -2.4851e-04, -1.5470e-04,\n              1.6295e-04, -5.4567e-04,  1.4152e-04,  3.1534e-04,  1.1799e-04,\n             -4.8450e-04,  1.6288e-04,  2.3052e-04,  4.8154e-05, -3.9992e-04,\n              1.1335e-04,  2.4992e-04,  2.4977e-04,  9.2988e-05,  6.8455e-05,\n              5.4250e-04]),\n     'exp_avg_sq': tensor([5.5229e-08, 1.0977e-07, 1.3313e-07, 6.0445e-08, 9.1298e-08, 4.0439e-08,\n             3.2842e-08, 9.0842e-08, 1.5275e-07, 8.4389e-08, 5.9805e-08, 7.4791e-08,\n             3.8482e-08, 5.9867e-08, 9.1567e-08, 1.4768e-07, 6.2840e-08, 9.2583e-08,\n             1.1282e-07, 5.9424e-08, 3.8336e-08, 8.9513e-08, 7.5860e-08, 8.4742e-08,\n             6.1969e-08, 7.8279e-08, 7.7246e-08, 6.2545e-08, 1.5818e-07, 1.7043e-07,\n             9.0881e-08, 8.0175e-08, 1.1348e-07, 2.2421e-07, 9.0842e-08, 1.2524e-07,\n             1.2328e-07, 4.9349e-08, 1.1000e-07, 8.5921e-08, 1.5193e-07, 5.4783e-08,\n             8.3653e-08, 9.8297e-08, 9.9451e-08, 3.9699e-08, 1.2649e-07, 5.9037e-08,\n             7.1250e-08, 1.0211e-07, 4.9221e-07, 1.3716e-07, 5.5000e-08, 1.8013e-07,\n             4.9477e-08, 1.0838e-07, 1.9327e-07, 1.1895e-07, 8.8115e-08, 1.6452e-07,\n             1.1805e-07, 1.1485e-07, 3.7357e-07, 4.7088e-08, 8.4912e-08, 2.0440e-07,\n             1.2768e-07, 8.2101e-08, 8.9489e-08, 1.1268e-07, 5.8632e-08, 5.3298e-08,\n             7.8455e-08, 2.0176e-07, 3.6114e-08, 6.4966e-08, 1.1346e-07, 3.4345e-08,\n             1.3549e-07, 9.2397e-08, 1.1329e-07, 8.2780e-08, 1.0651e-07, 9.4662e-08,\n             1.6871e-07, 6.2318e-08, 6.8550e-08, 5.8942e-08, 4.7034e-08, 4.1916e-08,\n             1.0564e-07, 1.2083e-07, 8.6198e-08, 2.5343e-07, 9.8067e-08, 1.3637e-07,\n             1.6680e-07, 1.8091e-07, 1.1529e-07, 1.1073e-07, 4.5551e-08, 8.0833e-08,\n             9.7539e-08, 9.9417e-08, 5.0479e-08, 2.4427e-07, 7.0410e-08, 1.4967e-07,\n             5.7765e-08, 4.0884e-08, 9.8962e-08, 6.3165e-08, 8.9084e-08, 1.1479e-07,\n             5.9843e-08, 8.1061e-08, 1.5233e-07, 6.3586e-08, 6.8776e-08, 7.6393e-08,\n             2.2967e-08, 5.6763e-08, 1.3171e-07, 1.5337e-07, 8.4777e-08, 9.4741e-08,\n             7.7052e-08, 2.7743e-07, 1.5943e-08, 1.0474e-07, 1.1541e-07, 4.2468e-07,\n             7.5012e-08, 8.3764e-08, 2.3823e-07, 9.9644e-08, 1.4107e-07, 1.3228e-07,\n             1.0016e-07, 6.5836e-08, 9.0513e-08, 1.5437e-07, 9.9326e-08, 6.8831e-08,\n             5.7962e-08, 1.2136e-07, 5.0591e-08, 9.7380e-08, 1.6128e-07, 6.5157e-07,\n             7.3759e-08, 5.3793e-08, 1.3425e-07, 8.8136e-08, 5.1887e-08, 8.8526e-08,\n             2.8553e-07, 8.5835e-08, 8.5891e-08, 1.0711e-07, 5.2115e-08, 2.6878e-08,\n             1.5224e-07, 1.3314e-07, 1.1536e-07, 1.6595e-07, 2.1404e-07, 5.8694e-08,\n             2.4373e-07, 1.8493e-07, 9.1347e-08, 1.0218e-07, 5.1872e-08, 9.2234e-08,\n             1.1904e-07, 5.9580e-08, 1.5280e-07, 8.8662e-08, 8.6640e-08, 7.2577e-08,\n             7.7278e-08, 8.7807e-08, 1.3446e-07, 5.5875e-08, 1.9647e-07, 9.2998e-08,\n             1.4221e-07, 9.0322e-08, 1.1269e-07, 6.2399e-08, 8.3613e-08, 5.4975e-08,\n             1.0316e-07, 7.4042e-08, 9.9557e-08, 1.3353e-07, 2.6997e-07, 4.8820e-08,\n             6.0990e-08, 7.9182e-08, 9.9896e-08, 8.1344e-08, 6.2379e-08, 6.4865e-08,\n             4.0317e-08, 7.0673e-08, 1.0982e-07, 8.4484e-08, 8.3987e-08, 1.2639e-07,\n             1.2018e-07, 3.5816e-08, 7.0578e-08, 8.8565e-08, 9.1718e-08, 6.4633e-08,\n             8.6183e-08, 3.8032e-08, 6.2858e-08, 5.9372e-08, 7.3037e-08, 8.0827e-08,\n             5.3013e-08, 7.3646e-08, 5.3912e-08, 4.2702e-08, 3.4909e-08, 1.0744e-07,\n             4.4215e-08, 4.1327e-08, 1.0668e-07, 8.6845e-08, 8.5870e-08, 9.9777e-08,\n             8.1733e-08, 1.2371e-07, 1.3133e-07, 1.2776e-07, 1.0847e-07, 8.8661e-08,\n             1.2586e-07, 1.2682e-07, 1.5080e-07, 8.5041e-08, 8.8982e-08, 1.8726e-07,\n             9.0794e-08, 7.2317e-08, 9.9640e-08, 9.1515e-08, 4.3806e-08, 1.6164e-07,\n             7.7944e-08, 8.7565e-08, 9.0227e-08, 1.1390e-07])},\n    50: {'exp_avg': tensor([ 1.0941e-04,  4.2273e-04,  3.2301e-05,  2.0208e-04, -2.8294e-04,\n              7.3420e-06, -3.3470e-04,  1.4993e-04, -1.1107e-04,  4.6715e-05,\n             -1.6846e-04,  1.6787e-04, -1.7013e-04,  2.4308e-04, -1.9302e-04,\n             -1.1611e-04,  2.9826e-04, -1.4402e-04, -2.3096e-04, -7.7246e-05,\n              3.5362e-05, -5.7875e-05, -1.7758e-04, -3.4415e-04, -1.6626e-04,\n              1.3761e-04,  1.7070e-05, -3.7136e-05, -3.1652e-05, -2.8576e-04,\n             -1.1389e-04, -7.1281e-05,  9.0615e-05, -1.7344e-06,  2.4863e-04,\n             -6.9373e-05,  8.1680e-05, -2.6171e-04,  2.2200e-04,  1.4294e-04,\n              1.1806e-05, -6.8137e-05,  2.2384e-04, -2.5618e-04,  5.2101e-05,\n             -2.8643e-05,  1.3766e-04,  8.1480e-05, -4.1438e-05,  7.5474e-05,\n             -2.5241e-04, -1.1786e-04,  6.8163e-05, -3.8752e-05, -1.0817e-04,\n             -7.5942e-05,  1.9505e-04,  3.7068e-05, -3.8037e-04,  1.6471e-05,\n              4.3132e-05,  2.0898e-04,  2.4096e-04, -3.6568e-05, -1.6584e-04,\n             -1.1435e-04, -3.3289e-05, -6.2304e-05, -2.9092e-04, -1.0401e-04,\n              3.7824e-04, -3.6643e-04, -3.4375e-04,  3.2527e-05,  1.6297e-05,\n              1.1089e-04,  3.7931e-05, -1.5639e-04, -4.6635e-04, -1.2078e-05,\n              2.7745e-04,  9.0089e-05,  3.8933e-04,  1.3796e-04,  1.0476e-04,\n             -2.5628e-05, -1.2926e-04, -5.7573e-05,  4.4795e-04,  5.4079e-05,\n              1.1387e-04,  8.0120e-05,  1.1104e-04,  1.3043e-04,  1.2964e-04,\n              3.5598e-04, -5.7949e-04, -1.6956e-04,  8.1680e-05, -3.2861e-04,\n             -7.2209e-06, -9.1997e-05, -2.4297e-04,  4.8404e-07, -7.2853e-05,\n             -2.1506e-04, -2.8049e-05,  1.8264e-04,  1.3231e-04, -2.3664e-05,\n             -3.4877e-05,  2.0330e-06,  5.4865e-05, -2.0656e-04,  2.7194e-04,\n             -1.3732e-04, -1.8775e-04, -2.5396e-04,  4.7947e-05, -1.1110e-04,\n              3.4894e-05,  2.2734e-05, -3.1654e-05, -3.8840e-05,  1.7941e-05,\n             -9.5282e-05,  9.1005e-05, -1.2925e-04, -5.9224e-05,  2.6666e-04,\n             -3.4493e-04, -1.1095e-04, -6.8457e-05,  1.4994e-04,  1.9714e-04,\n             -9.5850e-05, -1.4816e-04, -1.5893e-04,  1.1600e-04, -1.0110e-04,\n             -2.0065e-05, -1.8298e-05, -1.0808e-04,  5.0342e-05, -1.4091e-04,\n              1.9928e-04, -1.8166e-04, -1.5867e-04, -6.3369e-05, -1.5826e-04,\n              1.4976e-04, -1.1675e-04,  2.0712e-06,  2.5855e-04,  2.6277e-04,\n             -7.0525e-05, -4.0568e-04,  6.5095e-06,  1.3018e-04, -2.8276e-04,\n              1.2595e-04, -1.8275e-05,  1.1374e-04, -4.3491e-05, -4.2214e-05,\n              3.2899e-04, -1.2606e-04, -3.7006e-05,  5.2985e-05,  1.2538e-04,\n              4.8511e-05,  3.5927e-04, -1.6233e-04, -1.7393e-04, -4.8782e-05,\n             -9.8587e-05, -2.5401e-04,  8.1850e-06,  4.2053e-05, -1.4047e-05,\n              3.7900e-05,  1.7083e-04,  4.2224e-04, -2.0732e-04, -1.7278e-04,\n             -1.8027e-04, -1.8544e-04,  7.8729e-05, -2.0161e-04,  9.0815e-06,\n              1.9805e-04,  8.5471e-05, -2.5462e-04,  9.7442e-05,  5.2334e-05,\n              8.0963e-05, -1.3889e-05,  1.2268e-04, -7.7779e-06, -8.2371e-05,\n              1.2893e-04,  2.0221e-04,  1.0333e-04,  3.9403e-04,  7.8872e-05,\n              3.0084e-04, -1.3098e-04,  2.7455e-04, -2.4694e-04, -1.5840e-04,\n             -1.8447e-04, -1.9788e-04,  3.2507e-04,  1.6789e-04,  1.5747e-04,\n             -2.0670e-04, -5.0725e-05,  6.8892e-05, -3.8705e-04,  5.8169e-04,\n             -1.8192e-04,  5.8225e-05,  6.0536e-04, -2.6027e-04, -9.3775e-06,\n             -2.5258e-04, -2.9361e-05, -4.7992e-05,  5.1032e-04, -9.5292e-05,\n              1.4456e-04, -4.2769e-04,  1.3693e-04, -3.4161e-05, -6.9535e-05,\n             -1.3425e-04,  3.3071e-05, -6.6906e-05,  3.4628e-04, -1.3651e-04,\n             -5.3206e-05, -1.9001e-04,  8.3500e-05,  1.3870e-04,  5.6074e-05,\n             -1.4113e-05,  9.0235e-05,  1.8363e-04, -9.6484e-05,  5.6507e-04,\n              9.3340e-05, -1.4472e-04,  5.9193e-05, -5.4486e-07, -2.7070e-04,\n              9.9329e-05]),\n     'exp_avg_sq': tensor([1.3090e-07, 2.3118e-07, 2.9434e-08, 2.7932e-07, 2.6371e-07, 7.9318e-08,\n             4.9891e-08, 2.1127e-07, 2.2844e-07, 6.2906e-08, 5.7484e-08, 6.6284e-08,\n             1.8528e-07, 5.6998e-08, 2.0775e-07, 1.6826e-07, 1.6357e-07, 2.5940e-07,\n             1.0668e-07, 2.4363e-08, 2.8361e-08, 9.2457e-08, 2.1498e-07, 1.9669e-07,\n             2.9164e-07, 1.9855e-07, 2.7088e-08, 5.0799e-08, 6.4069e-08, 4.0821e-07,\n             4.1768e-08, 4.0137e-08, 3.3868e-08, 4.7737e-08, 4.3705e-08, 9.3405e-08,\n             2.9972e-08, 2.1759e-07, 2.9205e-07, 5.3060e-07, 2.0270e-07, 4.1556e-08,\n             1.4153e-07, 9.4038e-08, 1.2014e-07, 4.3631e-08, 3.5180e-08, 1.8060e-07,\n             8.0238e-08, 5.9257e-08, 2.2961e-07, 1.4326e-07, 5.2488e-08, 1.9543e-07,\n             3.6194e-08, 5.5925e-08, 1.1798e-07, 1.4838e-07, 2.6013e-07, 2.0701e-08,\n             7.5040e-08, 2.2535e-07, 3.1718e-07, 3.8091e-08, 2.5328e-08, 1.0928e-07,\n             3.7772e-08, 3.4068e-07, 1.9277e-07, 3.9169e-08, 2.1417e-07, 1.6347e-07,\n             1.2894e-07, 3.5014e-08, 3.3895e-08, 1.5036e-07, 2.3466e-08, 3.2365e-08,\n             1.9356e-07, 2.6413e-08, 3.2466e-07, 3.7382e-08, 1.2867e-07, 7.2344e-08,\n             4.2900e-08, 6.8336e-08, 3.6895e-08, 2.1452e-08, 2.9043e-07, 8.0748e-08,\n             4.6210e-08, 1.0900e-07, 3.2814e-08, 4.1931e-08, 1.9670e-07, 1.7550e-07,\n             2.1847e-07, 6.8138e-08, 3.0455e-08, 3.1047e-07, 8.0480e-08, 1.9626e-08,\n             5.1732e-08, 9.3586e-08, 3.0416e-08, 2.7866e-08, 1.3999e-07, 2.4485e-07,\n             1.5517e-07, 3.9469e-08, 8.5631e-08, 2.2188e-07, 2.4439e-08, 8.2025e-08,\n             2.7296e-07, 8.1362e-08, 8.3877e-08, 2.9236e-08, 5.3283e-08, 1.9275e-08,\n             2.1960e-08, 3.4092e-08, 4.7237e-08, 7.6322e-08, 2.4673e-07, 3.2304e-08,\n             2.9409e-08, 3.1877e-08, 1.3179e-07, 1.5658e-07, 1.2323e-07, 3.5076e-08,\n             7.0272e-08, 5.4930e-08, 4.5580e-08, 1.7885e-07, 2.6497e-07, 4.0611e-08,\n             3.8226e-08, 2.2211e-08, 1.9283e-08, 3.6690e-08, 1.7002e-07, 6.0088e-08,\n             1.8806e-07, 9.0751e-08, 3.1618e-08, 1.9504e-07, 3.4465e-08, 7.6023e-08,\n             1.5323e-07, 3.1289e-07, 4.3293e-08, 1.7075e-07, 2.2275e-07, 3.9055e-08,\n             9.5789e-08, 2.3307e-08, 2.4775e-08, 6.8494e-08, 3.2656e-08, 8.4803e-08,\n             2.8796e-08, 6.4333e-08, 4.8110e-08, 1.5435e-07, 3.5426e-08, 4.4866e-08,\n             1.1601e-07, 3.1030e-08, 2.6306e-08, 1.4872e-07, 1.5048e-07, 3.7124e-08,\n             1.2617e-07, 2.1128e-07, 7.9606e-08, 4.6123e-08, 5.7662e-08, 3.5060e-08,\n             4.9354e-08, 9.9505e-08, 2.2114e-07, 9.4266e-08, 1.3966e-07, 1.1675e-07,\n             1.3305e-07, 1.7451e-08, 3.0872e-07, 1.6720e-07, 1.7508e-07, 2.8733e-08,\n             3.3963e-08, 3.1057e-08, 9.5710e-08, 6.8424e-08, 2.9766e-08, 3.7078e-08,\n             2.4443e-08, 1.5656e-07, 2.4917e-07, 3.3553e-08, 3.8276e-08, 1.9592e-07,\n             3.4937e-08, 3.0440e-07, 3.4506e-08, 9.8787e-08, 2.3022e-07, 1.5150e-07,\n             2.9103e-07, 2.1986e-07, 2.6661e-07, 2.5462e-08, 2.6363e-08, 2.8408e-07,\n             7.4453e-08, 1.8734e-07, 1.8330e-07, 1.8094e-07, 2.4404e-08, 2.7136e-08,\n             2.6372e-07, 3.0980e-07, 4.8816e-08, 5.1351e-08, 2.2337e-08, 3.2599e-08,\n             2.1963e-07, 5.7335e-08, 8.1475e-08, 2.2182e-07, 2.7879e-08, 3.5906e-08,\n             1.0704e-07, 4.7993e-08, 4.7446e-08, 2.0813e-07, 1.7115e-07, 4.3360e-08,\n             3.8324e-08, 1.0939e-07, 7.4218e-08, 2.5758e-08, 1.7140e-07, 4.5063e-08,\n             3.3493e-08, 7.7886e-08, 2.5260e-08, 2.5161e-07, 1.7192e-08, 3.4332e-08,\n             2.3494e-08, 5.1298e-08, 1.6831e-07, 3.8325e-08])},\n    51: {'exp_avg': tensor([ 6.7149e-05,  1.1939e-05, -4.5069e-05, -6.4611e-06, -8.8158e-06,\n              1.4030e-04, -1.1814e-05,  5.5405e-05,  6.6615e-05,  7.5723e-05,\n             -6.9893e-05, -4.8398e-05, -9.8451e-05,  1.2685e-04, -2.3394e-07,\n              6.4329e-05,  2.1963e-05, -8.2206e-06,  1.9592e-05, -1.2289e-05,\n             -5.9426e-06,  4.0598e-05, -1.1985e-05,  6.4945e-05,  4.6165e-05,\n             -3.2477e-05,  5.4395e-05, -4.6027e-05, -4.4231e-05,  4.4373e-06,\n             -1.8654e-05,  6.7472e-06,  1.3918e-04, -3.7486e-05,  1.1037e-04,\n              3.5975e-05, -5.8076e-06,  9.6899e-06, -8.7282e-05,  9.1290e-05,\n              1.4743e-05, -6.4821e-05,  6.4196e-05,  4.9800e-05, -1.0772e-05,\n             -1.0675e-04,  1.2540e-04,  6.6747e-05,  1.1005e-04,  6.1153e-05,\n              3.9939e-05, -1.5490e-04,  1.5758e-04,  9.7494e-06,  1.8944e-05,\n              1.4268e-04,  1.2736e-04,  7.9464e-05, -7.4216e-05,  1.3660e-04,\n              8.6867e-05, -1.7823e-05, -1.7072e-05, -4.6194e-05, -1.0131e-04,\n              5.5700e-05, -6.1486e-05, -4.0324e-06, -8.3978e-06, -1.1578e-04,\n              3.0186e-05, -2.6559e-05,  3.3935e-05,  3.5536e-05,  6.2261e-05,\n              7.0555e-05, -3.6616e-05,  7.2918e-06,  1.0832e-04, -3.8695e-05,\n              2.9405e-05, -2.8741e-05, -2.5459e-05,  3.5108e-05,  7.6411e-05,\n              6.1485e-05, -4.2381e-05,  1.0641e-05, -1.2489e-06, -2.6676e-05,\n              5.8424e-05, -4.0122e-05,  5.8059e-05,  1.0837e-05,  3.4124e-05,\n             -2.7664e-05, -2.4405e-05,  4.1955e-05,  1.0671e-04, -9.7685e-06,\n              9.2480e-05, -4.7483e-05, -1.4736e-04,  1.9982e-05,  1.0412e-04,\n             -2.1382e-04,  8.9057e-05,  2.8681e-06, -4.1674e-06, -1.8985e-05,\n              5.3336e-05, -1.6889e-05, -1.4187e-05,  1.3487e-04, -1.5156e-05,\n             -5.5751e-05, -7.9532e-05, -5.1524e-05,  7.3307e-05, -5.6901e-05,\n             -1.6740e-06,  7.7390e-05, -6.5653e-05,  3.4265e-06, -1.0983e-05,\n              4.3673e-05,  5.8843e-05, -2.3151e-04,  3.5828e-05,  1.5355e-04,\n             -8.2386e-06,  2.3598e-05,  1.6757e-04,  4.2837e-06,  1.5574e-04,\n             -3.9755e-05,  2.5392e-05, -4.3789e-05,  7.4287e-06, -8.2013e-05,\n             -7.1918e-05, -3.7854e-05, -9.0287e-05, -4.1098e-05, -3.7255e-05,\n              2.6485e-04, -5.0846e-06,  2.8788e-05, -1.3277e-04, -7.2391e-05,\n              9.6769e-05,  1.2200e-04, -1.6188e-05, -1.6628e-05,  3.3604e-05,\n              2.4955e-05,  6.4686e-05,  4.5695e-05, -1.3938e-05, -1.1265e-04,\n              8.9383e-05,  4.1949e-05,  5.6256e-05, -1.6413e-04,  3.8708e-05,\n              1.9743e-05, -3.2450e-05, -4.0142e-05,  1.2830e-06,  1.0901e-05,\n              4.9658e-05, -4.4662e-06, -1.1400e-04, -1.6411e-04, -6.4172e-05,\n             -4.5589e-05, -1.7070e-04, -3.0056e-05, -5.1053e-05, -9.0678e-06,\n              9.4912e-05,  2.4609e-05,  2.2508e-06,  6.1435e-05, -5.8247e-05,\n              4.6159e-06, -2.3000e-05,  1.0094e-05, -7.7253e-05,  8.9636e-05,\n             -2.2728e-05, -4.9177e-06, -2.4869e-04,  9.5116e-05, -1.4036e-05,\n             -2.2479e-05, -5.8857e-05,  1.2104e-04,  4.1428e-05,  4.0090e-05,\n             -6.8102e-06, -1.7342e-05,  9.7070e-05,  2.7715e-05,  6.6031e-05,\n              4.9461e-05, -6.1841e-05,  2.4993e-05, -5.3672e-06, -5.8975e-05,\n             -3.8051e-05,  2.5854e-05, -2.5815e-05,  1.9064e-04, -4.1466e-05,\n              1.3734e-05, -7.2901e-05, -5.6682e-06, -2.3763e-05,  4.1547e-05,\n             -1.1425e-04, -6.8718e-05,  3.6227e-06,  2.0372e-05, -8.3757e-05,\n             -7.5993e-05, -2.4616e-05, -9.8462e-05,  1.1587e-05,  8.3302e-05,\n             -5.3420e-05,  5.8327e-05,  7.8610e-05,  6.4301e-05, -2.3313e-04,\n             -1.8641e-04, -1.6768e-05, -1.0293e-05,  8.1719e-05,  1.3711e-05,\n              7.8706e-05,  3.9143e-05,  4.3595e-06,  7.8283e-05, -2.0594e-05,\n              5.0790e-05,  1.1057e-04,  1.1414e-04, -7.5300e-05, -3.0702e-05,\n              6.4973e-05, -2.3676e-04, -4.8485e-05, -6.6742e-05, -6.5214e-05,\n              1.7502e-04]),\n     'exp_avg_sq': tensor([2.1861e-08, 2.4221e-09, 9.8870e-09, 3.3490e-09, 1.0366e-09, 3.4826e-08,\n             1.9411e-08, 5.4119e-09, 1.4545e-08, 1.9799e-08, 1.2750e-08, 3.3646e-08,\n             2.4296e-09, 2.3430e-08, 3.1364e-09, 1.2137e-08, 1.9966e-08, 1.7584e-09,\n             9.3559e-09, 1.0779e-08, 8.5503e-09, 1.8749e-08, 3.3966e-09, 2.0510e-08,\n             1.3215e-09, 1.5695e-08, 1.6544e-08, 1.3566e-08, 1.5688e-08, 1.1250e-09,\n             1.6606e-08, 1.6929e-08, 1.7300e-08, 2.4662e-08, 3.8809e-08, 2.6467e-08,\n             1.7811e-08, 1.6005e-09, 9.9076e-09, 1.4669e-07, 3.0978e-09, 2.2406e-08,\n             5.4212e-09, 3.0640e-08, 1.6655e-08, 1.6721e-08, 1.9686e-08, 5.9739e-09,\n             3.0558e-08, 3.7280e-08, 1.1090e-09, 2.9872e-08, 3.3102e-08, 3.4277e-09,\n             1.0350e-08, 2.9390e-08, 1.8581e-08, 1.9492e-08, 8.8093e-09, 1.5562e-08,\n             1.9638e-08, 2.5763e-09, 8.6747e-10, 1.8054e-08, 1.1360e-08, 1.4027e-08,\n             1.6380e-08, 1.6663e-09, 2.1112e-09, 1.7298e-08, 5.5183e-09, 6.4259e-09,\n             1.6611e-08, 1.1490e-08, 1.6792e-08, 3.0688e-08, 1.0939e-08, 1.3389e-08,\n             2.8008e-09, 1.1349e-08, 7.2819e-10, 2.3885e-08, 7.9690e-09, 1.8928e-08,\n             1.5288e-08, 2.2867e-08, 1.3759e-08, 1.0808e-08, 1.0377e-09, 1.1408e-08,\n             2.3002e-08, 3.2492e-08, 1.3115e-08, 1.4312e-08, 3.3707e-09, 3.1027e-09,\n             2.5037e-09, 2.1607e-08, 1.5721e-08, 1.2848e-09, 1.2793e-08, 1.2025e-08,\n             1.6905e-08, 1.2141e-08, 1.2209e-08, 1.9092e-08, 5.3024e-09, 1.1698e-09,\n             6.4497e-09, 1.2245e-08, 3.0536e-08, 4.2370e-09, 9.3734e-09, 1.5365e-08,\n             1.1974e-09, 1.1822e-08, 1.4671e-08, 1.1841e-08, 2.5038e-08, 6.9561e-09,\n             1.2539e-08, 2.0709e-08, 2.4848e-08, 1.1951e-08, 1.7627e-09, 1.3167e-08,\n             1.6844e-08, 3.6773e-08, 9.5681e-09, 2.5509e-08, 9.7600e-09, 1.0114e-08,\n             2.0656e-08, 2.2116e-08, 1.8049e-08, 6.7077e-09, 1.6769e-09, 1.2451e-08,\n             1.3123e-08, 1.0206e-08, 1.0018e-08, 1.3576e-08, 1.7739e-08, 1.7438e-08,\n             9.3344e-09, 4.5083e-08, 1.3388e-08, 1.8051e-09, 2.7273e-08, 2.2479e-08,\n             5.4831e-08, 4.1551e-08, 1.8403e-08, 2.2708e-08, 5.3900e-09, 1.1860e-08,\n             2.5267e-08, 1.3035e-08, 9.9547e-09, 1.7136e-08, 1.6166e-08, 1.9748e-08,\n             1.3041e-08, 1.2882e-08, 1.9359e-08, 6.0934e-09, 2.0933e-08, 1.7445e-08,\n             1.9630e-08, 1.3160e-08, 1.5531e-08, 1.8881e-09, 1.1384e-08, 1.9628e-08,\n             1.8754e-08, 4.4655e-09, 1.7993e-08, 1.7952e-08, 1.9089e-08, 1.2178e-08,\n             2.0769e-08, 8.9806e-09, 1.1213e-09, 3.0803e-08, 7.0222e-09, 1.7039e-08,\n             2.2314e-08, 9.0736e-09, 5.2419e-09, 3.0004e-08, 8.9489e-09, 1.3921e-08,\n             2.4556e-08, 1.6866e-08, 1.7897e-08, 1.5199e-08, 1.2047e-08, 1.5100e-08,\n             8.7727e-09, 1.0438e-08, 2.7959e-09, 1.3302e-08, 2.2218e-08, 2.3584e-09,\n             1.3281e-08, 1.9442e-09, 1.0421e-08, 1.8381e-08, 3.4058e-09, 9.7040e-09,\n             1.5395e-09, 3.6533e-09, 2.9306e-09, 2.0775e-08, 2.2334e-08, 2.0402e-09,\n             3.0159e-08, 2.6912e-09, 5.4557e-10, 6.1084e-09, 1.5274e-08, 1.5674e-08,\n             2.4400e-09, 8.5071e-10, 2.1491e-08, 1.2396e-08, 8.3962e-09, 1.2638e-08,\n             3.1272e-09, 1.7018e-08, 3.0316e-08, 1.8392e-08, 1.2559e-08, 1.3503e-08,\n             2.8882e-08, 1.7766e-08, 3.6744e-08, 7.1559e-10, 8.2458e-09, 3.2382e-08,\n             1.5269e-08, 1.4386e-08, 2.0791e-08, 1.2425e-08, 2.5114e-09, 1.8039e-08,\n             3.2342e-08, 2.0138e-08, 1.8455e-08, 4.5269e-09, 9.2366e-09, 1.7556e-08,\n             1.0614e-08, 1.7255e-08, 1.7756e-08, 3.3434e-08])},\n    52: {'exp_avg': tensor([-1.7425e-05, -3.1541e-05, -6.6619e-05,  ..., -6.6811e-05,\n             -9.0847e-05, -3.4345e-05]),\n     'exp_avg_sq': tensor([4.4750e-08, 2.2646e-08, 2.8786e-08,  ..., 3.2752e-08, 2.8248e-08,\n             2.5768e-08])},\n    53: {'exp_avg': tensor([-2.7977e-05,  4.1508e-05,  1.2660e-05,  ...,  3.3110e-05,\n             -7.1506e-06, -4.2250e-05]),\n     'exp_avg_sq': tensor([1.4909e-08, 9.9832e-09, 1.5622e-08,  ..., 2.0470e-08, 1.7685e-08,\n             1.5093e-08])},\n    54: {'exp_avg': tensor([ 1.2814e-05,  1.8406e-04,  9.7979e-05,  ...,  6.0403e-06,\n             -1.2264e-04, -1.2892e-04]),\n     'exp_avg_sq': tensor([4.9436e-08, 1.8417e-08, 3.6051e-08,  ..., 3.3392e-08, 3.9997e-08,\n             2.3314e-08])},\n    55: {'exp_avg': tensor([-2.7977e-05,  4.1508e-05,  1.2660e-05,  ...,  3.3110e-05,\n             -7.1506e-06, -4.2250e-05]),\n     'exp_avg_sq': tensor([1.4909e-08, 9.9832e-09, 1.5622e-08,  ..., 2.0470e-08, 1.7685e-08,\n             1.5093e-08])},\n    56: {'exp_avg': tensor([ 4.6307e-05,  2.9773e-04, -6.9585e-05, -2.5576e-05,  5.6377e-04,\n             -2.0198e-04,  1.2480e-04,  3.4869e-05, -5.6336e-05,  1.9245e-05,\n             -1.0014e-04,  1.8401e-04, -7.3088e-05,  8.4336e-05, -3.0371e-05,\n              1.1103e-04,  3.8754e-05, -3.0361e-05, -6.4776e-05, -9.6930e-05,\n             -4.6817e-05, -2.9148e-04,  1.9061e-04, -2.2739e-04,  5.2751e-05,\n              1.8141e-04, -2.7722e-04, -2.4978e-05, -2.5390e-04,  8.5197e-05,\n             -1.0030e-04,  2.8628e-05, -2.3906e-04,  2.6297e-04, -2.3368e-04,\n             -6.9807e-05, -2.0889e-04, -1.0513e-04,  1.6936e-04, -2.3794e-05,\n              5.1421e-05, -1.2763e-04,  1.7529e-04, -1.0449e-04, -1.0491e-04,\n              1.5405e-04,  1.9727e-04, -1.8758e-05,  4.9422e-05, -8.9670e-05,\n              4.0789e-05,  1.3952e-04,  8.3346e-05, -2.7802e-04, -2.4804e-04,\n             -4.4776e-05, -4.6043e-05,  6.5267e-05,  3.8509e-05,  3.5099e-05,\n              1.0771e-05, -3.5834e-04, -1.0972e-04,  1.2508e-04, -3.9241e-05,\n             -1.5424e-04, -1.5210e-04, -3.5730e-04, -1.9362e-04,  5.3180e-05,\n             -1.5389e-04, -3.3846e-05,  1.6560e-04, -1.6853e-05, -2.4313e-05,\n             -2.7826e-04,  4.7935e-05, -4.0220e-05,  1.7117e-04,  2.5704e-04,\n              5.8822e-05, -6.0819e-05,  2.6758e-05,  6.3186e-05,  1.7463e-04,\n             -2.5796e-04, -1.7768e-04, -4.7654e-05,  4.0074e-04, -1.8109e-04,\n             -1.8361e-05,  1.2014e-04, -2.3761e-04,  4.2318e-04, -2.4392e-04,\n              2.0450e-04,  2.0260e-05, -2.9406e-04, -5.8863e-05,  1.1521e-04,\n             -7.9547e-05,  1.9740e-04, -2.8460e-05, -1.5374e-04,  1.4038e-04,\n              1.2429e-04, -2.3871e-04,  2.2456e-05,  5.7777e-05,  9.4583e-05,\n             -5.2897e-05, -3.8213e-04, -1.4996e-04,  8.3624e-05,  1.1648e-04,\n              2.5933e-05,  2.5994e-04, -1.5685e-04,  1.2220e-04,  2.8524e-05,\n             -2.9148e-04,  2.0854e-04, -9.5699e-06, -6.6697e-05, -9.3768e-05,\n             -8.6692e-07,  1.0431e-05, -3.3407e-05,  1.7341e-04, -1.1127e-04,\n              3.1177e-05,  5.6213e-05, -4.3218e-05, -3.9666e-05, -1.4993e-04,\n              7.5731e-05, -1.2770e-04,  2.9429e-04,  1.5584e-04, -3.2087e-04,\n              5.0302e-05,  3.0373e-04, -1.2154e-04, -3.0395e-04, -3.8078e-04,\n             -1.1964e-04,  3.5308e-06, -1.2164e-04,  9.0226e-05, -8.0041e-05,\n             -1.1294e-04, -7.5439e-05, -3.0331e-05, -3.2705e-04,  1.2660e-04,\n              6.7048e-05,  1.4723e-04,  1.3554e-04,  2.7178e-04, -3.3800e-05,\n             -4.4550e-05, -2.4290e-04, -1.1468e-04,  3.9515e-04,  9.2670e-05,\n              4.5557e-05,  1.5710e-05, -1.8540e-04, -1.3506e-04, -2.5981e-04,\n              6.5657e-05, -1.0573e-04,  1.1378e-04,  8.6161e-06, -4.9417e-06,\n              1.4052e-04, -1.0788e-04,  3.1681e-06, -1.8869e-04,  9.0016e-06,\n             -5.6899e-05, -4.8241e-05,  1.4119e-06,  2.0753e-05, -1.7549e-05,\n              7.4732e-05, -1.4709e-06,  5.6761e-05,  2.1052e-04,  7.0248e-05,\n             -2.1055e-04, -6.0746e-05,  1.7060e-04, -1.8681e-04,  1.2192e-04,\n              1.0657e-05, -1.4021e-04, -1.3997e-04, -1.1054e-04,  1.0020e-04,\n              3.0421e-04, -2.8503e-04,  3.9880e-05,  1.6754e-04, -2.1348e-04,\n              6.9271e-05, -8.7912e-05, -2.9727e-04,  7.7062e-05,  6.4653e-05,\n              8.7458e-05, -2.2145e-05,  2.3775e-04,  4.1798e-04, -5.3289e-05,\n              4.5617e-06,  1.7215e-04,  1.9259e-04,  1.6016e-04,  1.7401e-05,\n             -6.4475e-05, -1.1934e-04, -1.3588e-04, -1.6482e-04, -1.8469e-04,\n             -9.7456e-06,  2.7096e-04,  4.7625e-05,  8.8933e-05,  3.4495e-04,\n              2.7074e-04,  7.6508e-05, -1.2167e-05,  6.1700e-05, -2.2143e-05,\n              4.7185e-05,  8.2948e-05,  1.2110e-04,  1.2855e-04, -2.6085e-04,\n              1.0275e-05,  2.4505e-04, -5.4481e-05, -9.1148e-05, -4.3912e-06,\n             -2.5234e-04, -2.0613e-04,  8.0092e-05, -5.7495e-05,  8.3269e-05,\n              1.6180e-04,  2.5510e-04,  6.6815e-05,  1.6710e-04,  7.6018e-05,\n              2.3243e-04]),\n     'exp_avg_sq': tensor([3.3910e-08, 6.5596e-08, 2.7322e-08, 6.2438e-08, 1.1922e-07, 7.1480e-08,\n             2.6384e-07, 5.8366e-08, 7.1812e-08, 4.8514e-08, 7.1402e-08, 5.9149e-08,\n             8.0526e-08, 2.3849e-08, 4.6575e-08, 4.7320e-08, 5.1284e-08, 4.2757e-08,\n             6.1143e-08, 9.0708e-08, 4.6572e-08, 9.8064e-08, 9.6206e-08, 3.0856e-07,\n             6.6652e-08, 9.2371e-08, 6.9205e-08, 5.3666e-08, 6.3577e-08, 5.4815e-08,\n             4.8453e-08, 8.2921e-08, 9.3696e-08, 5.3744e-08, 7.6729e-08, 4.6550e-08,\n             4.5086e-08, 3.4214e-08, 3.4703e-08, 5.0665e-08, 6.3095e-08, 3.9015e-08,\n             5.5843e-08, 1.5643e-07, 1.0329e-07, 1.3603e-07, 7.2006e-08, 8.2184e-08,\n             6.9543e-08, 5.8257e-08, 5.8701e-08, 1.9568e-08, 6.8991e-08, 8.8350e-08,\n             5.1393e-08, 7.6360e-08, 5.3797e-08, 2.0856e-08, 6.3044e-08, 5.9545e-08,\n             4.5916e-08, 5.9244e-08, 5.8173e-08, 4.1991e-08, 1.3382e-07, 4.5706e-08,\n             7.7242e-08, 5.5639e-08, 5.7641e-08, 7.4546e-08, 6.4849e-08, 6.2230e-08,\n             6.6002e-08, 6.8876e-08, 6.0809e-08, 7.9447e-08, 5.8293e-08, 5.0690e-08,\n             5.3239e-08, 7.1032e-08, 7.7344e-08, 4.6068e-08, 4.3997e-08, 6.7079e-08,\n             1.3834e-07, 8.8510e-08, 3.5822e-08, 6.1824e-08, 6.0246e-08, 4.3198e-08,\n             3.0522e-08, 2.7569e-08, 8.2747e-08, 6.3217e-08, 1.4014e-07, 8.6840e-08,\n             1.2370e-08, 4.5891e-08, 6.1324e-08, 4.5369e-07, 7.1491e-08, 6.5629e-08,\n             2.7206e-08, 1.0200e-07, 6.0178e-08, 4.5699e-08, 8.7390e-08, 4.2847e-08,\n             1.0984e-08, 3.1906e-07, 7.4525e-08, 8.8354e-08, 2.5122e-08, 1.1471e-07,\n             6.2873e-08, 3.8856e-08, 5.5372e-08, 4.6759e-08, 4.4958e-08, 4.6015e-08,\n             3.1618e-08, 6.1414e-08, 5.6613e-08, 3.7982e-08, 7.4912e-08, 7.1595e-08,\n             2.4049e-08, 1.2250e-07, 2.4258e-08, 4.9422e-08, 4.3293e-08, 3.9186e-08,\n             6.5711e-08, 3.8780e-08, 2.6932e-08, 2.1095e-07, 5.8662e-08, 7.2085e-08,\n             7.3509e-08, 2.0498e-07, 4.9487e-08, 6.4447e-08, 4.8917e-08, 6.0154e-08,\n             8.9497e-08, 1.4225e-08, 4.1370e-08, 5.2545e-08, 4.9544e-08, 6.2457e-08,\n             4.1588e-08, 4.9496e-08, 1.1208e-07, 1.0576e-07, 4.8348e-08, 9.4276e-08,\n             4.0038e-08, 6.8412e-08, 8.1516e-08, 1.0484e-07, 9.6573e-08, 1.7827e-07,\n             6.0887e-08, 5.6299e-08, 7.1168e-08, 1.7374e-07, 6.8397e-08, 1.6485e-07,\n             5.5630e-08, 5.5197e-08, 4.3740e-08, 3.7176e-08, 3.5336e-08, 5.3756e-08,\n             5.0682e-08, 1.0057e-07, 7.5420e-08, 9.3448e-08, 1.0905e-07, 3.4081e-07,\n             5.0265e-08, 7.2520e-08, 4.3626e-08, 2.5175e-08, 8.2223e-08, 1.9613e-08,\n             5.7949e-08, 7.2346e-08, 4.7670e-08, 4.8943e-08, 2.6424e-07, 1.5888e-08,\n             1.5662e-07, 3.9138e-08, 6.1605e-08, 9.2828e-08, 4.5272e-08, 9.3383e-08,\n             8.8834e-08, 4.8699e-08, 1.0432e-07, 8.3383e-08, 5.3755e-08, 4.7858e-08,\n             6.0368e-08, 1.3798e-07, 3.0930e-08, 7.2592e-08, 5.7150e-08, 5.0632e-08,\n             4.6479e-08, 6.7170e-08, 6.9528e-08, 1.1371e-07, 1.0362e-08, 5.2482e-08,\n             7.7413e-08, 1.5134e-07, 8.5060e-08, 1.0221e-07, 5.5804e-08, 8.2011e-08,\n             2.1409e-07, 7.1552e-08, 8.6154e-08, 6.6507e-08, 7.6538e-08, 7.6368e-08,\n             1.4523e-07, 1.2800e-07, 7.4917e-08, 6.8103e-08, 4.0014e-08, 7.1563e-08,\n             8.8504e-08, 4.4005e-08, 8.0851e-08, 5.2400e-08, 4.8447e-08, 1.3299e-07,\n             1.1766e-07, 4.5237e-08, 7.1516e-08, 1.9441e-07, 3.9134e-08, 6.5174e-08,\n             6.8124e-08, 9.7443e-08, 5.6861e-08, 6.6352e-08, 7.1224e-08, 4.5297e-08,\n             8.1306e-08, 8.1575e-08, 7.7051e-09, 5.6674e-08])},\n    57: {'exp_avg': tensor([-6.5145e-07,  1.8775e-04, -2.2032e-04, -4.3789e-05,  2.2014e-04,\n             -1.3438e-04, -8.9428e-08,  4.2414e-05,  3.0620e-05, -1.2504e-05,\n              1.0948e-05,  6.3798e-05, -3.8334e-05,  6.3086e-06, -9.6979e-05,\n              2.1585e-05,  2.6627e-05, -2.4290e-05,  2.3056e-05, -4.5420e-05,\n             -2.9044e-05, -2.5302e-04,  1.9232e-05, -1.4244e-04, -1.7424e-05,\n              1.8708e-04, -9.8496e-05,  1.0688e-04, -1.4435e-04,  1.6042e-04,\n             -1.0668e-04,  3.6357e-05, -1.8054e-04, -2.6270e-05, -1.7706e-04,\n             -4.5613e-05, -1.2972e-04, -1.0008e-04,  1.1045e-04,  4.2888e-05,\n              1.1800e-04, -1.0489e-04,  1.4298e-04, -1.1301e-04, -5.1803e-05,\n              1.9529e-04,  1.3311e-05,  5.3089e-05,  2.0348e-05, -2.1183e-05,\n             -2.6551e-05,  2.6537e-05, -6.5338e-06, -1.2964e-04, -2.1299e-04,\n              6.1649e-05,  2.8349e-05,  1.2113e-04,  7.2353e-05,  1.5485e-04,\n              6.1596e-05, -2.2420e-04, -4.9198e-05,  1.2438e-04,  2.8026e-06,\n             -4.1393e-05, -3.5229e-05, -2.6900e-04, -1.6935e-04,  1.0457e-04,\n             -5.7333e-05,  2.0763e-05,  1.0932e-04, -1.4102e-04, -5.6117e-05,\n             -1.9880e-04, -8.8543e-08, -1.9221e-05,  2.1769e-04,  1.6295e-04,\n              1.2499e-05,  4.5396e-05, -3.5887e-05, -2.1158e-05,  7.4418e-05,\n             -8.6056e-05, -4.7329e-05,  3.7028e-06,  2.1152e-04, -2.0022e-04,\n             -3.6500e-05,  1.9232e-04, -3.0220e-05,  2.2755e-04, -1.2864e-04,\n              1.6115e-04,  6.2162e-05, -2.5085e-04, -7.1678e-05,  3.5284e-05,\n             -5.7559e-05,  1.1369e-04, -4.9058e-05, -9.1996e-05,  1.5426e-05,\n              6.6383e-05, -1.2164e-04, -5.2109e-05,  3.5648e-05,  5.0118e-06,\n             -1.4429e-05, -3.4042e-04, -2.0454e-04,  9.3962e-05,  8.5006e-05,\n              7.3957e-06,  7.6230e-05, -9.5311e-05, -2.1848e-05, -1.2924e-04,\n             -1.4058e-04,  2.2796e-04, -7.1870e-05,  4.0329e-05, -5.1329e-05,\n              3.0721e-05,  2.5071e-05, -1.9347e-05,  7.1148e-05, -1.3683e-04,\n              7.4689e-05,  2.2625e-05,  1.7346e-05,  8.6775e-05, -4.5192e-05,\n             -1.6928e-06, -2.0234e-04,  7.2925e-05,  8.7757e-05, -2.0305e-04,\n              7.1356e-05,  2.5568e-04, -1.1945e-04, -2.0113e-04, -1.3351e-04,\n             -1.7979e-04,  8.9269e-05, -1.4620e-04,  9.0511e-05, -3.0869e-05,\n             -3.2208e-05, -9.4591e-06,  5.8448e-05, -1.4362e-04,  1.3616e-04,\n             -2.6617e-06,  6.6082e-05,  1.6605e-04, -4.2422e-05,  5.6518e-05,\n             -1.0762e-04, -7.5486e-05, -5.9946e-05,  3.4374e-04,  2.4923e-05,\n              3.8896e-04,  1.3775e-04, -7.8241e-05, -7.1030e-05, -1.3658e-04,\n              3.4623e-05, -1.1096e-05,  4.9705e-05,  1.0495e-04,  1.1031e-04,\n              5.5803e-05, -7.4491e-05,  3.1746e-05, -7.6542e-05,  2.4158e-05,\n             -1.0049e-04, -7.4646e-05,  1.0656e-05,  1.8226e-04,  6.7412e-05,\n              1.2941e-04,  1.4201e-04,  2.1086e-05,  6.1618e-05,  1.1377e-04,\n              1.3707e-04,  1.7248e-05,  2.1272e-04, -1.5180e-04,  2.4211e-04,\n              1.0606e-05, -1.2279e-04, -2.2416e-04, -2.1631e-05,  8.5435e-05,\n              1.2080e-04, -4.0200e-04, -9.3820e-05,  8.2019e-05, -1.4994e-04,\n              8.0847e-05, -1.6792e-04, -1.9129e-04,  5.3218e-05, -2.5179e-05,\n              1.3128e-06,  2.4016e-05,  1.4165e-04,  1.2525e-04, -1.0184e-04,\n              1.1767e-04,  1.3569e-05,  1.1957e-04,  1.0093e-04, -1.6396e-06,\n              4.0060e-05, -2.0009e-04, -8.2286e-05, -1.5397e-05, -1.4831e-04,\n             -5.6588e-05,  1.6646e-04,  6.0919e-05,  7.4491e-05,  2.2627e-04,\n              1.2452e-04, -2.0467e-05, -1.9241e-05,  1.2091e-04,  2.4314e-05,\n              3.2582e-05,  5.8730e-05,  7.9790e-05, -5.0347e-05, -9.7051e-05,\n             -4.9222e-05,  1.7713e-04, -1.1916e-04,  3.7198e-05, -1.0802e-05,\n             -1.0083e-04, -1.7665e-04, -8.5391e-05, -4.9872e-05,  7.6160e-05,\n             -5.9603e-06,  2.5612e-04,  3.2870e-07,  1.8077e-04,  1.3847e-04,\n              1.7351e-04]),\n     'exp_avg_sq': tensor([2.1885e-08, 2.7670e-08, 3.1120e-08, 4.4380e-08, 6.8175e-08, 3.2717e-08,\n             4.2349e-08, 1.9939e-08, 4.1146e-08, 1.5717e-08, 4.0751e-08, 2.6029e-08,\n             3.3866e-08, 3.0138e-08, 3.3294e-08, 1.2708e-08, 2.4356e-08, 1.7310e-08,\n             3.1695e-08, 8.1223e-08, 1.8340e-08, 4.4247e-08, 6.3343e-08, 9.0563e-08,\n             4.8684e-08, 4.7257e-08, 3.2312e-08, 3.5836e-08, 1.3562e-08, 3.9928e-08,\n             3.3621e-08, 4.3853e-08, 4.5072e-08, 3.3472e-08, 6.6209e-08, 1.9163e-08,\n             3.6952e-08, 2.8940e-08, 3.2204e-08, 1.9411e-08, 3.9410e-08, 1.9176e-08,\n             5.0072e-08, 5.0935e-08, 4.5512e-08, 6.3569e-08, 5.6238e-08, 2.7208e-08,\n             6.5786e-08, 4.4658e-08, 5.4084e-08, 3.6218e-08, 4.7899e-08, 3.9401e-08,\n             2.8291e-08, 4.5250e-08, 2.4398e-08, 4.1018e-08, 3.2026e-08, 4.8251e-08,\n             2.5302e-08, 3.1402e-08, 2.3921e-08, 4.0307e-08, 9.1478e-08, 1.3242e-08,\n             1.1818e-08, 3.1649e-08, 2.7668e-08, 4.0620e-08, 1.0457e-08, 4.5769e-08,\n             4.5235e-08, 4.2351e-08, 3.5715e-08, 4.7624e-08, 3.8301e-08, 3.5994e-08,\n             4.9879e-08, 3.8627e-08, 4.2002e-08, 3.4795e-08, 4.3050e-08, 2.0513e-08,\n             9.3457e-08, 9.5335e-08, 1.6537e-08, 2.0720e-08, 2.9055e-08, 2.6610e-08,\n             3.0183e-08, 4.1371e-08, 4.4596e-08, 4.1112e-08, 3.0676e-08, 4.3924e-08,\n             4.7009e-08, 3.0118e-08, 3.5447e-08, 1.2408e-07, 2.5694e-08, 4.1503e-08,\n             2.1883e-08, 4.9844e-08, 3.2467e-08, 2.7236e-08, 5.1489e-08, 1.5663e-08,\n             1.4126e-08, 8.2965e-08, 1.7604e-08, 4.9785e-08, 3.6273e-08, 3.0394e-08,\n             2.7186e-08, 2.1442e-08, 2.0658e-08, 2.0570e-08, 3.6439e-08, 3.2853e-08,\n             4.1996e-08, 4.3073e-08, 4.1126e-08, 3.4827e-08, 2.0890e-08, 4.6219e-08,\n             1.9019e-08, 7.0229e-08, 3.0494e-08, 3.1924e-08, 3.6717e-08, 2.0331e-08,\n             4.5610e-08, 3.4108e-08, 3.7662e-08, 3.2685e-08, 5.7228e-08, 2.0980e-08,\n             1.3524e-08, 7.2061e-08, 2.4112e-08, 4.9672e-08, 2.7548e-08, 2.3812e-08,\n             1.7369e-08, 2.8374e-08, 3.3992e-08, 3.2770e-08, 3.0831e-08, 3.9807e-08,\n             1.8268e-08, 1.9690e-08, 6.3765e-08, 4.2827e-08, 3.7897e-08, 1.3801e-08,\n             3.4520e-08, 5.6062e-08, 6.5872e-08, 4.6709e-08, 7.5218e-08, 5.0453e-08,\n             2.8922e-08, 5.1478e-08, 4.9336e-08, 5.9548e-08, 3.0514e-08, 5.3285e-08,\n             4.1914e-08, 2.2395e-08, 2.4556e-08, 1.7324e-08, 3.4689e-08, 2.9653e-08,\n             4.8039e-08, 2.0884e-08, 3.5008e-08, 5.1114e-08, 5.9784e-08, 6.1066e-08,\n             3.7313e-08, 5.0097e-08, 2.9559e-08, 3.4976e-08, 7.2863e-08, 1.7642e-08,\n             5.2731e-08, 3.5663e-08, 4.2507e-08, 3.0289e-08, 4.8369e-08, 4.2219e-08,\n             1.6971e-07, 4.1523e-08, 5.5575e-08, 3.0894e-08, 1.9914e-08, 6.6843e-08,\n             2.9240e-08, 1.5310e-08, 2.9011e-08, 6.9906e-08, 1.7975e-08, 3.9201e-08,\n             3.5049e-08, 5.9310e-08, 3.8420e-08, 4.3719e-08, 3.3967e-08, 4.3256e-08,\n             1.8130e-08, 4.6854e-08, 2.8117e-08, 5.6779e-08, 2.1799e-08, 4.9929e-08,\n             1.3828e-08, 7.3272e-08, 3.7058e-08, 4.5095e-08, 3.5748e-08, 4.4407e-08,\n             6.3556e-08, 3.5617e-08, 3.0455e-08, 5.8094e-08, 3.7040e-08, 3.9167e-08,\n             4.8991e-08, 6.9202e-08, 3.9129e-08, 1.5474e-08, 3.6650e-08, 6.5123e-08,\n             4.9672e-08, 2.0452e-08, 4.3902e-08, 3.5641e-08, 3.2027e-08, 1.0130e-07,\n             5.7264e-08, 2.8120e-08, 5.0705e-08, 8.7397e-08, 3.1323e-08, 2.4748e-08,\n             3.1040e-08, 5.4939e-08, 2.9665e-08, 3.0009e-08, 5.6751e-08, 3.9374e-08,\n             7.2529e-08, 4.1543e-08, 2.9014e-08, 3.3828e-08])},\n    58: {'exp_avg': tensor([-9.2664e-05,  8.6548e-05,  2.5047e-04, -3.1480e-05,  5.8490e-05,\n              2.6382e-04, -4.8261e-05, -1.0065e-04, -2.1553e-04, -4.0123e-04,\n              1.2316e-04,  9.3624e-05,  4.6796e-04, -2.0721e-04,  1.6588e-04,\n              4.2551e-05,  5.4055e-05, -1.9174e-04,  2.9762e-05,  3.1329e-04,\n              1.7088e-04, -2.0556e-04,  1.1696e-04, -3.4604e-04, -8.3390e-05,\n              8.2202e-05,  2.4650e-04, -2.2736e-04, -2.4122e-04, -1.9375e-04,\n             -2.6591e-04,  5.6796e-06,  5.2726e-04,  2.8069e-04,  3.3164e-04,\n             -8.6533e-05, -1.1224e-05,  2.3181e-05, -1.9894e-04,  2.0055e-04,\n              2.0605e-04, -4.9441e-05,  2.8683e-05, -1.3365e-04,  1.9716e-06,\n             -1.9934e-04, -1.3763e-04,  5.0862e-05,  8.7212e-05,  9.6802e-05,\n             -2.3423e-04, -1.7390e-04,  3.3852e-05,  1.3720e-04, -4.6855e-04,\n              8.4245e-05,  7.0063e-05,  7.4329e-05, -5.6204e-05,  1.8100e-04,\n             -2.6532e-05,  4.1861e-05,  1.4584e-04,  1.4245e-04,  1.2032e-04,\n              1.4109e-04, -3.1511e-04, -8.1165e-05,  1.6246e-04, -5.8907e-05,\n              7.2622e-05, -2.4265e-04, -2.3062e-05, -7.6817e-04, -1.1026e-04,\n              8.0283e-05, -8.1993e-05,  9.3592e-06,  1.1324e-04, -2.4205e-05,\n             -4.4135e-04,  2.1598e-04,  1.9819e-04,  5.8026e-05, -6.2659e-04,\n             -3.2772e-04, -6.4243e-04,  1.9861e-04,  1.1698e-04, -1.2686e-04,\n              6.0325e-05,  3.9538e-04, -8.5637e-06,  2.5492e-04,  1.2831e-04,\n             -2.2730e-04, -1.1332e-04,  1.8176e-04, -1.1379e-04, -3.6757e-04,\n             -1.5629e-06, -1.8803e-07,  3.4738e-05,  6.6491e-05, -2.6863e-04,\n             -1.8853e-04,  3.4050e-04, -3.5033e-04,  5.6188e-05, -1.3964e-04,\n              5.1307e-05, -6.2687e-04,  1.2887e-04, -1.5548e-04,  3.2461e-04,\n             -1.5279e-04,  1.6552e-04,  9.9836e-05, -2.9853e-04,  2.5347e-04,\n             -6.2159e-05,  1.1338e-04, -1.0198e-04, -4.1878e-04, -2.0775e-04,\n              1.9834e-04,  2.0065e-04, -1.2615e-05,  2.9836e-04,  1.6037e-04,\n              1.5592e-06, -2.1948e-04,  1.9522e-04, -1.4045e-04, -3.3156e-04,\n              1.5944e-04, -1.5764e-04,  1.0476e-04,  1.7152e-04,  3.8689e-04,\n              8.3938e-05,  8.7042e-06,  9.0139e-05,  1.9968e-04, -4.2419e-04,\n              1.1976e-05,  1.1814e-04, -1.1242e-04, -4.4995e-04, -1.0435e-04,\n              1.0850e-04, -6.7980e-05, -3.0497e-04, -6.5038e-06,  6.8277e-04,\n             -3.9687e-04, -1.9354e-04, -1.2595e-04,  2.2513e-04,  1.9140e-05,\n              1.6431e-04, -3.5080e-04, -2.2560e-05, -8.2648e-05,  5.7446e-06,\n              1.4546e-04,  1.1738e-06, -3.3432e-04,  2.7302e-04, -1.9878e-04,\n             -8.1027e-05, -2.6089e-04,  3.4044e-05,  2.1619e-05, -2.2710e-05,\n              2.9244e-05, -1.6787e-04, -7.1971e-05, -1.1724e-04,  5.5368e-05,\n             -1.8417e-04,  1.3602e-04, -2.9693e-04,  6.3112e-05, -3.7048e-04,\n              1.5557e-04, -4.3168e-06,  1.3277e-04,  4.8714e-04,  3.5895e-05,\n             -1.9221e-05, -1.4492e-04, -1.2409e-05,  1.5882e-04,  1.8817e-05,\n             -4.4268e-04, -3.8006e-05,  1.5713e-04, -8.9815e-05, -6.7855e-06,\n              1.8227e-04, -5.3814e-05,  6.3391e-05, -1.8787e-04,  2.8984e-05,\n              2.8588e-03,  4.0293e-05,  1.3832e-03,  6.4589e-04, -2.8743e-04,\n             -1.0259e-04, -1.5290e-05,  1.4076e-04,  2.7701e-05,  9.8056e-05,\n              1.0933e-04, -2.1559e-05, -2.0440e-05, -1.5180e-04,  2.4326e-04,\n             -4.0498e-05,  1.0744e-04, -1.5402e-04,  5.5190e-05, -2.8928e-04,\n              2.0127e-04,  4.2172e-04,  1.3293e-04,  2.2936e-04, -8.8903e-05,\n             -2.6577e-04, -2.7268e-04, -1.7680e-04,  1.6396e-04, -6.2484e-05,\n             -4.5747e-05,  9.5813e-05, -2.5264e-04, -1.7300e-04, -2.5378e-04,\n             -2.7405e-05,  8.7902e-05,  8.5980e-05, -4.1989e-05, -1.6173e-04,\n              5.4901e-06, -1.3143e-04, -1.7266e-04,  2.5697e-05,  7.7022e-05,\n             -3.3339e-04, -6.2658e-05, -2.0818e-04,  1.2417e-04,  2.1126e-04,\n             -9.3990e-05]),\n     'exp_avg_sq': tensor([7.1830e-08, 8.8898e-08, 5.8777e-08, 3.2283e-08, 1.4911e-07, 1.2858e-07,\n             2.3860e-07, 4.1645e-08, 9.4709e-08, 9.6138e-08, 1.2511e-07, 6.9483e-08,\n             2.1939e-07, 7.4552e-08, 1.3540e-07, 8.1379e-08, 1.0911e-07, 8.5737e-08,\n             8.6052e-08, 9.2174e-08, 6.5023e-08, 2.3474e-07, 1.6234e-07, 2.0878e-07,\n             8.4659e-08, 1.1225e-07, 5.6942e-08, 2.1732e-07, 8.2133e-08, 8.8597e-08,\n             1.5975e-07, 1.0628e-07, 3.2718e-07, 7.4763e-08, 2.5315e-07, 1.4169e-07,\n             9.0930e-08, 1.8275e-07, 1.6063e-07, 4.6003e-08, 3.6361e-07, 7.6501e-08,\n             5.8565e-08, 1.1993e-07, 9.1452e-08, 1.1095e-07, 6.6046e-08, 9.8858e-08,\n             1.0009e-07, 6.5028e-08, 6.6519e-08, 1.1537e-07, 7.4631e-08, 1.3719e-07,\n             1.2430e-07, 7.5203e-08, 7.6681e-08, 9.0893e-08, 7.5230e-08, 2.7148e-07,\n             6.7185e-08, 7.6591e-08, 7.2733e-08, 7.4557e-08, 9.3543e-08, 4.4589e-08,\n             7.7179e-08, 5.9880e-08, 1.0154e-07, 1.3748e-07, 5.5005e-08, 7.0607e-08,\n             1.5554e-07, 4.8013e-07, 7.7982e-08, 8.0559e-08, 8.0151e-08, 9.8210e-08,\n             9.8391e-08, 9.1844e-08, 8.4913e-08, 1.3004e-07, 9.4529e-08, 8.3208e-08,\n             2.1559e-07, 1.3520e-07, 3.4194e-07, 9.7538e-08, 1.8634e-07, 7.1966e-08,\n             1.6358e-07, 2.0161e-07, 7.4983e-08, 1.3115e-07, 1.2341e-07, 6.2320e-08,\n             5.6083e-08, 8.2011e-08, 1.4437e-07, 1.7588e-07, 8.9224e-08, 5.8614e-08,\n             5.7819e-08, 6.3269e-08, 5.4496e-08, 1.6412e-07, 9.9768e-08, 1.6922e-07,\n             1.7915e-07, 6.3355e-08, 1.8043e-07, 1.3527e-07, 1.5232e-07, 5.8574e-08,\n             8.5136e-07, 7.4286e-08, 1.2147e-07, 1.1637e-07, 1.1022e-07, 6.6110e-08,\n             7.7767e-08, 1.6238e-07, 1.0097e-07, 1.6218e-07, 6.0752e-08, 4.6871e-08,\n             8.9238e-08, 8.0721e-08, 6.0663e-08, 2.1326e-07, 1.0013e-07, 6.1106e-08,\n             5.3283e-08, 1.5385e-07, 1.2647e-07, 1.0100e-07, 6.2660e-08, 6.1907e-08,\n             1.3417e-07, 1.3180e-07, 6.9140e-08, 8.8902e-08, 8.6635e-08, 3.5339e-07,\n             2.9338e-07, 8.4884e-08, 2.7685e-07, 6.3204e-08, 4.3877e-07, 1.3097e-07,\n             9.4115e-08, 5.9713e-07, 8.6436e-08, 9.7033e-08, 4.1680e-07, 1.1288e-07,\n             1.0424e-07, 5.7669e-07, 9.2581e-08, 1.2487e-07, 1.0161e-07, 6.6488e-08,\n             1.1352e-07, 6.9962e-08, 5.8559e-08, 7.0996e-08, 1.4224e-07, 7.3543e-08,\n             6.5027e-08, 9.1972e-08, 8.7029e-08, 6.4383e-08, 1.2824e-07, 1.1274e-07,\n             1.4000e-07, 9.4049e-08, 1.0345e-07, 6.7417e-08, 8.1550e-08, 1.7630e-07,\n             3.1741e-07, 4.9621e-08, 1.1877e-07, 5.7348e-08, 1.7031e-07, 7.9595e-08,\n             1.1525e-07, 1.9359e-07, 9.7065e-08, 1.8346e-07, 1.0394e-07, 1.4689e-07,\n             1.4073e-07, 9.8846e-08, 6.0791e-08, 3.1422e-07, 1.6139e-07, 1.0394e-07,\n             7.0095e-08, 7.1134e-08, 2.9947e-07, 6.8642e-08, 3.4968e-08, 9.5653e-08,\n             6.3424e-08, 3.1954e-06, 8.3842e-08, 7.8429e-07, 2.4380e-07, 2.0517e-07,\n             1.2415e-07, 8.1448e-08, 1.7614e-07, 8.5981e-08, 4.4070e-08, 9.6660e-08,\n             1.4591e-07, 5.5885e-08, 1.4811e-07, 9.5651e-08, 1.8023e-07, 7.1979e-08,\n             1.2332e-07, 8.9943e-08, 1.3393e-07, 2.8313e-07, 6.0839e-07, 1.2340e-07,\n             7.4435e-08, 8.2430e-08, 8.1831e-08, 9.9634e-08, 1.1492e-07, 1.3246e-07,\n             6.3014e-08, 3.2039e-07, 5.2461e-08, 1.2744e-07, 8.2150e-08, 1.1628e-07,\n             7.4590e-08, 1.0637e-07, 6.2978e-08, 5.6118e-08, 1.6598e-07, 2.9651e-07,\n             9.9850e-08, 5.9049e-08, 8.5770e-08, 1.1788e-07, 1.7963e-07, 6.6324e-08,\n             7.5071e-08, 1.0590e-07, 4.8918e-08, 9.7236e-08])},\n    59: {'exp_avg': tensor([-7.0296e-05, -5.2854e-05,  1.2647e-04, -4.1771e-05,  2.4777e-05,\n              2.2763e-04,  8.1696e-05, -2.8418e-05, -1.4124e-04, -1.3529e-04,\n              1.7435e-04,  1.5141e-04,  2.8128e-04, -1.9570e-04,  3.5612e-05,\n              5.6377e-05,  3.9252e-05, -1.4838e-04,  5.3825e-05,  2.4893e-04,\n              1.6038e-04, -8.9512e-05,  2.3346e-04, -2.0367e-04, -1.3310e-04,\n             -6.7097e-05,  1.3633e-04, -3.0708e-04, -1.1568e-04, -1.6243e-05,\n             -1.4767e-04,  3.8156e-06,  3.7970e-04,  3.3480e-04,  2.3694e-04,\n             -5.7084e-05,  5.1089e-05,  1.1957e-04, -9.8992e-05,  1.4881e-04,\n              7.8028e-05, -4.6228e-05,  5.9937e-06,  1.6906e-05, -9.7530e-05,\n             -1.7064e-04, -8.9806e-05,  9.4266e-06, -1.1667e-05,  5.3274e-05,\n             -1.2268e-04, -2.1733e-04,  6.5981e-05,  1.4457e-04, -3.0601e-04,\n              2.0333e-06,  8.6718e-05, -4.6289e-05,  7.0208e-05,  9.7880e-05,\n             -3.5367e-05,  1.5228e-04,  5.7258e-05,  3.4854e-05,  1.4308e-04,\n              2.5962e-05, -2.0781e-04, -9.3626e-05,  2.3920e-04,  5.3482e-05,\n              1.7980e-04, -1.2425e-04, -9.2105e-05, -3.1145e-04, -1.8528e-04,\n              4.3687e-05, -1.5075e-04,  8.8060e-05,  1.3560e-04, -2.0156e-05,\n             -4.6671e-04,  1.2479e-04,  2.6174e-04,  1.3004e-05, -3.2627e-04,\n             -1.3814e-04, -2.9292e-04,  7.7064e-05,  2.6147e-05, -1.0142e-04,\n             -2.7301e-04,  2.0259e-04, -5.4344e-05, -4.0434e-06,  1.1877e-04,\n             -1.3015e-04, -1.0023e-05,  1.3967e-04, -9.8526e-05, -2.7404e-04,\n              4.5728e-05,  8.8349e-05,  6.9920e-05, -2.3285e-05, -3.3416e-04,\n             -1.3380e-04,  3.3330e-04, -1.3307e-04, -1.5720e-05, -8.8805e-05,\n              1.2622e-04, -1.1740e-04,  3.0168e-05, -1.2728e-04,  2.0616e-04,\n             -1.7050e-04,  6.2729e-05, -8.8004e-06, -2.1324e-04,  1.1939e-04,\n             -2.2076e-05,  5.6530e-05,  1.6859e-04, -2.3328e-04, -1.4894e-04,\n              1.9214e-04,  1.9818e-04,  1.4069e-04,  3.8897e-04,  2.8651e-04,\n             -1.6703e-05, -1.2007e-04, -1.1114e-04, -6.9133e-06, -9.9984e-05,\n              2.3759e-04, -4.0535e-05,  1.7104e-04,  7.9116e-05,  2.6481e-04,\n             -1.8879e-05, -3.9624e-05,  1.8416e-04,  6.9042e-05, -1.2554e-04,\n             -1.1484e-06,  3.0026e-06, -1.0575e-04, -2.8442e-04, -1.2446e-05,\n              1.9013e-04, -9.6564e-07, -2.2633e-04, -1.7944e-04,  1.8146e-04,\n             -1.5351e-04, -1.7126e-04, -5.2132e-05,  8.2768e-05, -1.5997e-05,\n              7.8588e-05, -2.2637e-04, -2.2944e-04, -4.1026e-05,  1.5468e-05,\n              1.1100e-04,  3.1030e-06, -2.4149e-04,  9.3442e-05, -1.1922e-04,\n             -7.4129e-05, -1.0596e-04, -1.8356e-04,  7.9224e-06, -1.1182e-05,\n             -3.6075e-05, -1.5248e-04,  1.0766e-04, -1.9393e-04, -6.9168e-05,\n             -6.6847e-05,  1.1514e-04, -1.5155e-04,  9.4981e-05, -1.5058e-04,\n              7.4600e-05,  1.5287e-04,  5.5161e-05,  3.0719e-04,  2.7291e-05,\n              8.5169e-05, -2.0335e-04, -1.2757e-05,  7.6078e-05,  9.3226e-06,\n             -2.1545e-04,  1.2066e-04,  1.6823e-04,  6.5327e-05,  6.3261e-05,\n              1.6003e-05, -6.0478e-05,  4.7673e-05, -8.3367e-05,  1.0844e-04,\n              8.2155e-04, -2.3647e-05,  3.5530e-04,  3.2422e-04, -1.1800e-04,\n             -1.7781e-04, -1.4452e-05,  6.0743e-05, -3.8050e-06, -6.2686e-05,\n              1.6231e-04, -8.0953e-05, -5.4338e-05, -1.0738e-04,  1.8673e-04,\n              7.6248e-05,  7.3460e-05, -2.5318e-04,  4.9644e-05,  1.4063e-04,\n              7.6403e-05,  2.3858e-04,  7.4380e-06,  1.2327e-04,  4.1782e-05,\n             -1.4792e-04, -2.1259e-04, -6.8331e-05,  1.4635e-04, -4.9002e-05,\n              6.7255e-05,  1.5932e-04, -1.1157e-04, -2.2985e-05, -1.5651e-04,\n             -1.5128e-05,  8.0665e-05,  4.3150e-05, -7.7846e-05, -2.7816e-04,\n              1.8260e-05, -5.2510e-05, -1.0244e-04, -1.0176e-04, -1.0567e-04,\n             -1.7129e-04, -1.3638e-04, -1.0542e-04,  1.0708e-04,  1.9053e-04,\n             -1.3942e-05]),\n     'exp_avg_sq': tensor([2.8261e-08, 6.5137e-08, 2.5355e-08, 2.0628e-08, 4.7251e-08, 7.6905e-08,\n             1.0545e-08, 2.0750e-08, 3.7632e-08, 6.6378e-08, 4.5416e-08, 4.4227e-08,\n             6.3336e-08, 5.3995e-08, 7.8264e-08, 2.9718e-08, 6.9172e-08, 4.6708e-08,\n             3.2048e-08, 4.4274e-08, 4.2545e-08, 7.8019e-08, 8.7692e-08, 6.4266e-08,\n             5.6195e-08, 5.4593e-08, 1.1771e-08, 1.2965e-07, 3.0765e-08, 4.6241e-08,\n             3.9458e-08, 3.1327e-08, 7.3465e-08, 5.4762e-08, 7.9306e-08, 4.6535e-08,\n             5.0589e-08, 1.0039e-07, 3.9936e-08, 1.9109e-08, 6.5754e-08, 4.7657e-08,\n             2.5432e-08, 5.5841e-08, 3.9789e-08, 5.4358e-08, 4.8622e-08, 5.5806e-08,\n             5.2473e-08, 2.7644e-08, 3.1546e-08, 5.0794e-08, 1.9700e-08, 5.9874e-08,\n             7.9964e-08, 4.8054e-08, 4.6231e-08, 4.6634e-08, 4.0364e-08, 5.6696e-08,\n             2.2800e-08, 4.3961e-08, 2.0792e-08, 2.5277e-08, 4.3484e-08, 2.8339e-08,\n             3.5576e-08, 4.1170e-08, 6.7281e-08, 2.2557e-08, 5.1905e-08, 3.9366e-08,\n             5.2845e-08, 7.7032e-08, 6.3833e-08, 3.3513e-08, 3.2155e-08, 5.2792e-08,\n             3.5613e-08, 6.2714e-08, 6.4025e-08, 4.6865e-08, 4.9331e-08, 4.9536e-08,\n             8.8789e-08, 5.9636e-08, 9.4820e-08, 4.2743e-08, 2.7740e-08, 6.4990e-08,\n             5.5821e-08, 9.3276e-08, 6.9559e-08, 3.5111e-08, 9.0428e-08, 3.6782e-08,\n             5.5447e-08, 5.8580e-08, 5.0555e-08, 4.7906e-08, 3.6628e-08, 2.4787e-08,\n             3.9100e-08, 6.8740e-08, 3.9211e-08, 7.6483e-08, 5.7367e-08, 5.2953e-08,\n             8.0300e-08, 4.1490e-08, 7.5527e-08, 4.1966e-08, 7.9057e-08, 2.4295e-08,\n             1.7187e-07, 4.2987e-08, 4.8195e-08, 6.8290e-08, 1.1870e-07, 1.9383e-08,\n             2.8923e-08, 5.3714e-08, 3.6528e-08, 7.0578e-08, 2.8745e-08, 4.2208e-08,\n             7.2869e-08, 6.7155e-08, 6.4243e-08, 1.2542e-07, 5.6364e-08, 2.5275e-08,\n             4.7098e-08, 5.6924e-08, 7.2996e-08, 4.4453e-08, 2.9747e-08, 3.9940e-08,\n             6.6318e-08, 6.9785e-08, 6.5100e-08, 4.3427e-08, 5.8703e-08, 9.8654e-08,\n             6.8644e-08, 3.7876e-08, 2.5709e-08, 3.3855e-08, 1.0192e-07, 4.8806e-08,\n             3.9527e-08, 1.6628e-07, 8.0206e-08, 3.5672e-08, 7.9329e-08, 2.5862e-08,\n             5.5118e-08, 1.0042e-07, 2.9686e-08, 6.3871e-08, 5.9009e-08, 3.7376e-08,\n             6.3953e-08, 2.5738e-08, 5.4910e-08, 2.8723e-08, 7.1800e-08, 3.4554e-08,\n             7.3367e-08, 5.5819e-08, 6.7517e-08, 1.9461e-08, 6.1403e-08, 4.3671e-08,\n             9.4611e-08, 2.5235e-08, 3.9012e-08, 3.0756e-08, 7.2591e-08, 7.6648e-08,\n             3.7480e-08, 3.4018e-08, 4.8505e-08, 3.5219e-08, 9.5762e-08, 2.7257e-08,\n             7.0863e-08, 7.8260e-08, 6.7985e-08, 4.9784e-08, 7.9425e-08, 8.3270e-08,\n             6.9668e-08, 3.9105e-08, 3.1043e-08, 9.6242e-08, 4.7459e-08, 6.0836e-08,\n             5.8682e-08, 3.5005e-08, 6.5655e-09, 5.0365e-08, 1.9804e-08, 5.6747e-08,\n             4.0029e-08, 1.9906e-07, 4.2143e-08, 1.2644e-07, 1.3308e-07, 4.5475e-08,\n             7.7695e-08, 3.4367e-08, 5.9679e-08, 3.0598e-08, 4.8181e-08, 6.3454e-08,\n             9.1174e-08, 3.0999e-08, 7.5733e-08, 5.5688e-08, 8.0086e-08, 4.2404e-08,\n             1.0406e-07, 4.6598e-08, 2.5826e-08, 6.9400e-08, 1.5097e-07, 5.6416e-08,\n             2.3174e-08, 5.4890e-08, 3.8136e-08, 3.5898e-08, 4.3053e-08, 1.1463e-07,\n             3.2214e-08, 8.9034e-08, 3.4309e-08, 3.3153e-08, 5.7481e-08, 2.3611e-08,\n             4.8404e-08, 5.0600e-08, 3.9343e-08, 3.4110e-08, 8.6329e-08, 1.1346e-07,\n             4.1565e-08, 3.7351e-08, 3.1030e-08, 5.1419e-08, 6.2664e-08, 4.0729e-08,\n             3.8678e-08, 7.0455e-08, 3.6686e-08, 6.4111e-08])},\n    60: {'exp_avg': tensor([-1.4085e-04, -1.1736e-04, -2.5163e-04,  ...,  4.3417e-05,\n             -1.4331e-05,  4.7924e-05]),\n     'exp_avg_sq': tensor([2.5670e-08, 2.3479e-08, 5.9167e-08,  ..., 7.2847e-08, 2.4340e-08,\n             2.2519e-08])},\n    61: {'exp_avg': tensor([-2.6825e-06,  4.2136e-05,  6.3323e-05,  ..., -1.8454e-05,\n              3.9091e-05, -8.3467e-05]),\n     'exp_avg_sq': tensor([1.2242e-08, 9.7038e-09, 3.0574e-09,  ..., 3.1351e-09, 1.7883e-08,\n             1.2105e-08])},\n    62: {'exp_avg': tensor([-7.1536e-05, -6.0729e-06, -1.7867e-05,  1.5539e-04, -8.8264e-05,\n              7.8979e-05, -6.5939e-07,  1.5511e-04,  4.1728e-05, -3.0870e-04,\n             -3.3881e-04, -2.7151e-04,  7.2673e-05, -1.7378e-04,  8.3080e-05,\n              1.8799e-06, -8.8131e-05,  3.2456e-04,  1.8793e-05,  9.5921e-05,\n             -7.4407e-05,  5.0339e-05,  1.0562e-04,  2.9279e-05, -2.1630e-05,\n             -8.7756e-05,  1.2762e-04,  4.2094e-05,  1.0543e-04, -5.8554e-05,\n              1.3775e-04,  6.8797e-04, -1.1691e-04, -3.7706e-05,  1.4348e-05,\n             -2.1070e-04, -1.8217e-04, -2.6565e-04, -2.0146e-04,  9.2480e-05,\n             -2.0253e-04, -4.4376e-05,  3.0318e-04,  3.0452e-04,  1.0935e-04,\n             -1.6589e-04, -4.3167e-05, -4.3555e-05,  3.8743e-04,  2.6646e-04,\n             -3.6586e-05, -8.7586e-05, -1.5996e-04, -1.0755e-04, -5.5694e-05,\n             -4.3136e-05, -6.2558e-05, -2.1127e-04, -2.3787e-05, -6.1394e-05,\n              1.9946e-04,  1.7818e-04,  3.3172e-04,  1.3695e-04,  1.3229e-04,\n              1.8778e-04,  2.1719e-04,  1.4087e-04, -1.3675e-04,  6.1621e-05,\n             -2.4784e-05, -7.5311e-05,  2.4263e-04,  2.5456e-04,  5.7446e-05,\n              9.5426e-05,  9.1503e-05,  1.3734e-04, -5.5366e-06,  4.5167e-04,\n             -2.5976e-04, -2.7639e-04, -9.2361e-06, -1.2365e-04, -1.4179e-04,\n             -1.1374e-04, -3.9648e-04,  7.2569e-05,  2.2568e-04,  2.5335e-04,\n             -4.3602e-05,  1.3054e-04, -2.6038e-04,  4.9884e-04,  1.0431e-04,\n              1.8225e-04, -2.1778e-04, -3.0618e-04, -3.0247e-05, -1.3303e-05,\n             -1.5551e-04,  1.6540e-04, -2.1026e-04, -1.0745e-04,  1.9060e-05,\n              1.1575e-04,  2.4816e-04,  3.6936e-04, -7.4804e-05, -3.0366e-04,\n             -1.9840e-05,  1.6301e-04,  1.0735e-05,  1.1319e-04, -3.1165e-04,\n              1.3246e-05,  1.4452e-04,  2.5477e-05,  3.7198e-05, -1.1638e-04,\n              8.3699e-05,  1.2422e-04, -2.0486e-04, -1.2204e-05, -1.8954e-04,\n             -3.2682e-04,  2.0356e-04,  1.3362e-04,  1.8136e-04, -1.8333e-04,\n             -3.3894e-04, -1.3659e-04, -1.7879e-04, -1.8023e-04,  3.2929e-05,\n              1.4659e-04, -7.9545e-05,  7.8719e-05,  3.6131e-04,  2.5315e-04,\n             -7.2403e-05,  1.8706e-04, -2.8364e-04,  6.2541e-05, -1.6611e-04,\n              1.2195e-04,  4.5387e-05, -4.4137e-04, -1.3743e-04,  8.4456e-05,\n              3.3097e-04, -8.6899e-05, -1.4055e-04,  1.9981e-04,  1.1501e-04,\n             -1.5037e-04,  2.8396e-05,  1.1089e-04,  8.5436e-05, -2.1721e-04,\n              4.9095e-05, -3.9229e-05,  8.6676e-05,  8.3346e-05,  1.7008e-04,\n             -7.3919e-05,  2.4669e-05,  9.0307e-05, -1.4154e-04, -3.0049e-04,\n              1.7925e-04, -1.4803e-04, -1.9295e-04, -1.8610e-04,  1.7908e-04,\n             -1.3829e-04, -2.1649e-04,  2.6442e-04,  3.0873e-04,  1.2873e-04,\n              1.3894e-04,  1.5528e-04,  6.5483e-05,  1.0527e-04, -1.7455e-04,\n             -1.8017e-04,  9.5654e-05,  1.9524e-06,  6.1688e-05, -3.0704e-04,\n              1.5796e-04, -3.5453e-04, -1.9937e-04,  2.3795e-04,  2.1763e-04,\n             -2.1011e-04,  4.8023e-05, -2.4169e-04, -4.0983e-05,  1.0634e-04,\n              5.2262e-05,  4.8732e-05,  6.8524e-05,  5.6975e-05,  2.3122e-04,\n             -5.8975e-05, -3.1100e-04,  1.0487e-04, -1.2105e-04,  2.6568e-04,\n              2.4381e-04, -2.3476e-04,  6.5106e-06,  4.4962e-04, -6.5078e-06,\n             -1.7148e-04, -1.0218e-04,  1.3458e-04, -2.0298e-04,  2.1932e-04,\n              2.9142e-05,  3.8775e-06, -1.6892e-04, -1.4064e-04,  1.5784e-04,\n             -1.2699e-04, -5.1622e-05, -6.9702e-06,  6.6547e-05,  2.2723e-04,\n              2.2926e-05, -2.2808e-04, -2.4477e-04, -2.0003e-04,  2.9039e-04,\n              1.3291e-04, -2.2508e-04,  2.7124e-04,  1.1197e-04, -8.0815e-05,\n             -9.2956e-05,  1.3984e-04, -1.1258e-07, -2.7550e-05, -9.3198e-05,\n             -9.2881e-06,  3.3738e-05,  5.2121e-05, -1.0131e-04,  1.2208e-04,\n             -1.1594e-04,  1.8357e-05, -2.3172e-05, -2.0751e-04,  8.8156e-05,\n             -2.4210e-04]),\n     'exp_avg_sq': tensor([8.8655e-08, 6.5803e-08, 7.5050e-08, 9.5292e-08, 6.2602e-08, 1.0430e-07,\n             4.9594e-08, 2.5120e-07, 7.6558e-08, 1.3163e-07, 9.9059e-08, 2.3735e-07,\n             5.9057e-08, 8.3237e-08, 7.1193e-08, 5.8433e-08, 4.8394e-08, 1.1866e-07,\n             8.9135e-08, 9.8518e-08, 2.4218e-07, 1.5729e-07, 6.6347e-08, 5.5872e-08,\n             4.3488e-08, 7.7373e-08, 9.2938e-08, 9.7614e-08, 1.3240e-07, 6.4503e-08,\n             8.9950e-08, 1.4098e-07, 8.4852e-08, 1.1420e-08, 7.2212e-08, 9.1718e-08,\n             1.2338e-07, 6.2043e-08, 1.4726e-07, 7.4195e-08, 1.2207e-07, 7.4361e-08,\n             6.4158e-08, 1.0090e-07, 8.5800e-08, 1.7702e-07, 6.7377e-08, 1.5544e-08,\n             9.7168e-08, 8.4695e-08, 8.2789e-08, 7.9233e-08, 8.6129e-08, 7.2493e-08,\n             7.0153e-08, 2.0327e-07, 9.5376e-08, 8.7588e-08, 7.6046e-08, 9.4173e-08,\n             7.3895e-08, 1.0186e-07, 1.5146e-07, 7.3567e-08, 9.8500e-08, 6.4311e-08,\n             1.0689e-07, 9.7074e-08, 2.0818e-07, 1.2290e-07, 7.6263e-08, 7.1373e-08,\n             1.1280e-07, 8.6126e-08, 1.2775e-07, 9.8085e-08, 8.1403e-08, 1.3636e-07,\n             8.2915e-07, 7.2040e-08, 1.1413e-07, 4.9100e-08, 1.1768e-07, 1.1181e-07,\n             1.0420e-07, 1.0357e-07, 1.4938e-07, 1.1106e-07, 1.1320e-07, 2.8568e-07,\n             2.4040e-07, 9.0032e-08, 1.7999e-07, 1.2417e-07, 7.7896e-08, 1.5771e-07,\n             8.7891e-08, 1.1511e-07, 8.5481e-08, 1.1205e-07, 9.4743e-08, 8.4045e-08,\n             1.6203e-07, 1.2789e-07, 7.9973e-08, 7.9798e-08, 1.0831e-07, 6.9629e-08,\n             1.0181e-07, 7.2874e-08, 7.2030e-08, 1.2168e-07, 4.4153e-08, 1.9769e-07,\n             7.8901e-08, 1.0817e-07, 7.5757e-08, 1.1306e-07, 9.6004e-08, 7.6888e-08,\n             4.7854e-08, 7.1936e-08, 8.2034e-08, 5.3518e-08, 5.7957e-08, 1.0124e-07,\n             1.1045e-07, 8.8537e-08, 7.8623e-08, 9.6506e-08, 1.0007e-07, 1.2646e-07,\n             5.9889e-08, 1.1383e-07, 2.0141e-07, 5.1485e-08, 8.4325e-08, 1.2807e-07,\n             1.9979e-07, 5.3647e-08, 1.4937e-07, 1.2384e-06, 1.3943e-07, 8.0082e-08,\n             8.6532e-08, 7.7328e-08, 2.3506e-07, 2.9237e-07, 7.4447e-08, 1.3327e-07,\n             1.0078e-07, 5.6207e-08, 1.1550e-07, 8.1978e-08, 1.1504e-07, 4.7624e-08,\n             9.7396e-08, 8.9712e-08, 1.5036e-07, 1.4307e-07, 1.7781e-07, 9.7379e-08,\n             1.6706e-07, 6.2970e-08, 6.1598e-08, 1.2393e-07, 1.9806e-07, 9.7234e-08,\n             9.3966e-08, 8.2320e-08, 7.4487e-08, 1.0065e-07, 8.0269e-08, 1.6193e-07,\n             8.6164e-08, 8.1970e-08, 1.3097e-07, 1.0403e-07, 5.9390e-08, 1.0039e-07,\n             1.0818e-07, 5.4919e-08, 5.7170e-08, 1.6745e-07, 7.9864e-08, 8.8612e-08,\n             7.0954e-08, 6.8071e-08, 5.4419e-08, 7.2308e-08, 1.1875e-07, 1.1216e-07,\n             7.4267e-08, 6.2400e-08, 3.6426e-08, 1.0705e-07, 1.2102e-07, 1.1151e-07,\n             5.4088e-08, 8.0694e-08, 1.5731e-07, 8.4857e-08, 6.6488e-08, 1.0491e-07,\n             1.4030e-07, 7.6596e-08, 5.7094e-08, 1.2646e-07, 8.4744e-08, 1.1157e-07,\n             1.7646e-07, 9.0732e-08, 6.5172e-08, 2.2256e-07, 7.0661e-08, 9.7504e-08,\n             7.7148e-08, 1.8203e-07, 1.2492e-07, 4.3904e-08, 7.4187e-08, 7.9885e-08,\n             1.3589e-07, 4.5972e-08, 1.9515e-07, 5.2879e-08, 1.4101e-07, 5.3387e-08,\n             5.1168e-08, 2.2448e-07, 1.3762e-07, 1.0622e-07, 1.1069e-07, 1.5636e-07,\n             8.1425e-08, 5.8593e-08, 7.6104e-08, 1.2794e-07, 1.0590e-07, 7.4892e-08,\n             1.0086e-07, 4.1854e-08, 3.4007e-08, 4.8291e-08, 1.5793e-07, 4.8052e-08,\n             9.8177e-08, 2.3412e-07, 8.8971e-08, 1.1289e-07, 7.4054e-08, 1.7792e-08,\n             6.8603e-08, 8.0648e-08, 7.4934e-08, 3.8196e-08])},\n    63: {'exp_avg': tensor([-1.0302e-04, -4.7186e-05, -2.4786e-05,  1.0145e-04, -7.0164e-05,\n              1.6187e-05, -1.6741e-05,  7.6045e-05, -8.1019e-06, -1.6877e-04,\n             -1.3494e-04, -9.3096e-05,  2.7446e-06, -7.0856e-05, -8.8137e-06,\n             -2.5795e-06,  4.6154e-05,  3.0402e-04, -1.8069e-05,  1.3224e-04,\n             -4.8877e-05,  4.0922e-05,  8.4625e-05,  3.4474e-05,  2.4800e-06,\n             -2.0220e-05,  6.7058e-05,  6.4980e-05, -7.1891e-06, -4.1556e-05,\n              1.1401e-04,  4.6307e-04, -1.0026e-04, -3.9987e-05,  1.9975e-05,\n             -1.2234e-04, -1.0233e-04, -2.4191e-04, -8.8340e-05,  4.4610e-05,\n             -1.7211e-04, -5.8054e-05,  1.6552e-04,  1.6351e-04,  1.0853e-04,\n             -5.5460e-05, -6.8923e-06, -6.5701e-05,  2.0321e-04,  3.1991e-04,\n             -6.5851e-05, -1.0586e-04, -1.2814e-04, -7.9594e-06, -2.1568e-06,\n             -5.8029e-05, -5.4450e-05, -1.2533e-04,  5.2535e-06, -7.2344e-05,\n              8.0019e-05,  1.1691e-04,  1.7522e-04,  5.2116e-05,  9.8174e-05,\n              1.5332e-04,  1.3739e-04,  7.8913e-05, -1.1164e-04,  1.3323e-05,\n             -5.4203e-05, -4.0160e-07,  6.7367e-05,  1.4726e-04,  1.6060e-04,\n              1.3410e-04,  4.4194e-05,  4.0610e-05, -8.7850e-06,  4.4520e-04,\n             -1.8368e-04, -1.4642e-04, -4.1087e-07, -9.1701e-05,  1.7689e-06,\n             -6.0103e-05, -1.4888e-04,  1.1221e-04,  2.5336e-04,  4.8729e-05,\n              2.3970e-04,  1.6981e-04, -1.9743e-04,  4.0287e-04,  7.4482e-05,\n              4.7935e-05, -2.0721e-04, -7.3144e-05, -1.5036e-05, -3.6493e-05,\n              4.9478e-05,  1.1303e-04, -7.1804e-05, -4.5921e-05,  6.1551e-05,\n              5.5570e-05,  1.4240e-04,  2.3192e-04, -7.2911e-05, -1.3650e-04,\n             -1.9493e-05,  8.7406e-05, -1.1157e-05,  3.8995e-05, -2.4477e-05,\n             -5.1874e-07,  5.6514e-05, -7.7092e-07,  3.3272e-05, -3.0228e-06,\n              9.4270e-05,  8.0615e-05, -8.7936e-05,  1.4911e-04, -1.2064e-04,\n             -1.2777e-04,  9.6190e-05,  1.2792e-05,  9.5791e-05, -1.3889e-04,\n             -1.9986e-04, -7.3282e-05, -1.0857e-04, -3.2139e-05,  4.1668e-06,\n              7.3354e-05, -5.9394e-05, -3.7192e-05,  3.1369e-04,  2.1203e-04,\n             -4.2858e-05,  7.4233e-05, -1.0985e-04,  6.8057e-05, -9.7236e-05,\n              7.7232e-05,  1.6434e-05, -2.6464e-04, -1.0785e-04, -5.5633e-05,\n              1.7847e-04, -4.7415e-05,  3.1116e-05,  1.0065e-04,  7.1245e-05,\n             -9.8948e-05,  4.0488e-06,  9.2677e-05,  2.3851e-05, -9.0561e-05,\n             -2.6624e-05, -1.0749e-05,  3.9466e-06,  1.2783e-05,  8.4638e-05,\n             -2.7329e-04,  3.4900e-05,  4.0408e-05, -3.7987e-05, -9.3356e-05,\n              4.4909e-05, -9.4766e-05, -1.6087e-04, -1.0865e-04,  9.9191e-05,\n             -1.6532e-04, -2.0084e-04,  1.5045e-04,  2.7720e-04, -3.0823e-05,\n              1.6785e-04,  9.7966e-05,  5.3004e-05,  1.7584e-04, -1.3143e-04,\n             -7.9928e-05,  4.2674e-05,  3.2221e-05,  7.1390e-05, -1.0662e-04,\n              7.5602e-05, -1.6508e-04, -5.5848e-05,  1.2098e-04,  2.4520e-04,\n             -1.8495e-04, -1.4870e-05, -1.0187e-04,  2.2876e-05,  1.0252e-04,\n              5.6639e-05,  2.7629e-05,  3.4497e-05, -4.6336e-05,  4.1367e-05,\n             -4.0506e-05, -1.9017e-04,  1.6695e-04,  9.5172e-05,  2.0131e-04,\n              1.3736e-04, -3.2973e-07, -1.1659e-04,  2.0458e-04, -7.1111e-05,\n             -1.4462e-04, -7.3144e-05,  6.9084e-05, -4.8147e-05,  1.5823e-04,\n              9.8670e-06, -4.1348e-05, -6.0774e-05, -7.6796e-05, -1.2274e-04,\n             -6.9837e-05,  1.1174e-05,  3.2577e-05,  2.2389e-05,  1.1829e-04,\n              5.0020e-05, -2.3441e-04, -1.1574e-04, -1.5572e-04,  2.4604e-04,\n              5.5349e-05, -1.2185e-04,  1.8327e-04, -2.8279e-06, -7.2525e-05,\n             -1.8940e-05,  7.3397e-05,  2.5747e-06, -8.5536e-06, -7.6741e-05,\n             -1.7623e-05,  7.3623e-05,  5.9192e-05,  4.3720e-05,  9.6675e-05,\n             -1.0015e-04,  1.1311e-04, -1.0942e-04, -1.2921e-04,  7.5216e-05,\n             -8.4296e-05]),\n     'exp_avg_sq': tensor([7.1997e-08, 3.3678e-08, 5.3988e-08, 5.1466e-08, 3.5143e-08, 5.1757e-08,\n             3.0921e-08, 3.8385e-08, 2.6782e-08, 7.7555e-08, 3.1673e-08, 3.8465e-08,\n             2.6917e-08, 2.0753e-08, 3.9610e-08, 2.0445e-08, 3.7954e-08, 7.8386e-08,\n             2.4046e-08, 4.4449e-08, 8.0262e-08, 3.3319e-08, 3.2938e-08, 1.7903e-08,\n             2.3532e-08, 1.6225e-08, 5.2243e-08, 2.9698e-08, 3.1493e-08, 1.8706e-08,\n             4.2372e-08, 7.8742e-08, 4.1167e-08, 1.0300e-08, 1.9392e-08, 5.5191e-08,\n             3.5494e-08, 3.4661e-08, 3.4525e-08, 2.6856e-08, 3.0005e-08, 3.0184e-08,\n             2.2604e-08, 3.9676e-08, 2.7725e-08, 3.6539e-08, 3.0307e-08, 1.2392e-08,\n             4.5439e-08, 6.1496e-08, 2.4103e-08, 3.0669e-08, 4.3612e-08, 3.6515e-08,\n             2.5809e-08, 5.5050e-08, 4.9340e-08, 2.8503e-08, 3.6962e-08, 2.8857e-08,\n             3.8516e-08, 4.0016e-08, 4.6489e-08, 3.5743e-08, 3.4737e-08, 2.6260e-08,\n             4.5280e-08, 4.0111e-08, 7.7080e-08, 4.7444e-08, 3.8927e-08, 4.2286e-08,\n             2.2050e-08, 4.9725e-08, 5.6403e-08, 3.2889e-08, 2.5054e-08, 2.7334e-08,\n             1.4888e-07, 5.2474e-08, 3.2416e-08, 2.2193e-08, 3.2609e-08, 4.3679e-08,\n             3.1486e-08, 3.0208e-08, 3.0250e-08, 3.9758e-08, 8.5853e-08, 6.2610e-08,\n             3.8079e-08, 5.0868e-08, 5.6973e-08, 6.9181e-08, 2.2902e-08, 5.5791e-08,\n             3.9429e-08, 3.7172e-08, 2.5585e-08, 5.3625e-08, 3.7304e-08, 3.0013e-08,\n             3.6598e-08, 4.7359e-08, 5.0230e-08, 3.0129e-08, 3.5805e-08, 2.8731e-08,\n             8.0528e-08, 3.3312e-08, 2.8457e-08, 5.8702e-08, 2.1808e-08, 7.1813e-08,\n             5.4005e-08, 5.0433e-08, 3.8306e-08, 2.0735e-08, 5.2552e-08, 3.0428e-08,\n             4.7950e-08, 3.2264e-08, 2.6077e-08, 4.5781e-08, 2.9464e-08, 3.2241e-08,\n             2.5833e-08, 3.1580e-08, 3.2899e-08, 4.6934e-08, 3.5458e-08, 5.2624e-08,\n             2.2207e-08, 5.6588e-08, 4.8125e-08, 2.4471e-08, 3.6761e-08, 4.2413e-08,\n             8.3665e-08, 2.0262e-08, 5.1744e-08, 2.3519e-07, 6.8752e-08, 3.4762e-08,\n             4.6266e-08, 2.2835e-08, 6.7125e-08, 9.5410e-08, 3.7250e-08, 5.2579e-08,\n             2.5262e-08, 2.4462e-08, 2.9659e-08, 2.7111e-08, 4.8185e-08, 2.9463e-08,\n             5.4384e-08, 2.4837e-08, 7.5781e-08, 3.4337e-08, 3.6802e-08, 1.8206e-08,\n             9.0783e-08, 2.5882e-08, 1.4731e-08, 9.2684e-08, 5.2233e-08, 6.6212e-08,\n             3.2852e-08, 2.3019e-08, 3.8120e-08, 2.9537e-08, 2.9227e-08, 1.2845e-07,\n             6.6144e-08, 6.4301e-08, 6.9759e-08, 4.2783e-08, 3.5859e-08, 4.7567e-08,\n             6.0959e-08, 3.4735e-08, 3.3919e-08, 7.2528e-08, 2.7513e-08, 4.4938e-08,\n             3.2911e-08, 3.2094e-08, 3.4466e-08, 2.3955e-08, 2.7601e-08, 7.9385e-08,\n             3.5599e-08, 2.2108e-08, 2.3146e-08, 5.7281e-08, 3.6306e-08, 3.1328e-08,\n             2.7107e-08, 3.5131e-08, 3.2963e-08, 4.8860e-08, 2.7388e-08, 3.9484e-08,\n             4.0618e-08, 1.2966e-08, 3.1072e-08, 6.5633e-08, 6.2217e-08, 6.1304e-08,\n             5.6506e-08, 6.0605e-08, 3.6914e-08, 4.8266e-08, 3.6578e-08, 7.0931e-08,\n             5.0357e-08, 6.9152e-08, 7.3425e-08, 2.4593e-08, 4.2742e-08, 3.5366e-08,\n             6.2702e-08, 2.3804e-08, 7.4728e-08, 2.5650e-08, 7.9073e-08, 2.7504e-08,\n             2.2399e-08, 3.1138e-08, 3.3664e-08, 6.5846e-08, 4.6931e-08, 7.5481e-08,\n             4.7195e-08, 4.3408e-08, 2.3480e-08, 4.9286e-08, 8.4477e-08, 3.8815e-08,\n             2.6687e-08, 2.4075e-08, 1.6529e-08, 4.8803e-08, 3.3578e-08, 2.3225e-08,\n             4.3272e-08, 3.9623e-08, 6.3400e-08, 7.7641e-08, 3.2766e-08, 2.7465e-08,\n             3.4822e-08, 5.2838e-08, 3.0762e-08, 2.3373e-08])},\n    64: {'exp_avg': tensor([-6.8268e-05,  1.8002e-04,  8.6569e-05,  3.3432e-04, -5.6655e-04,\n              4.0630e-05, -4.0717e-04, -6.5471e-05,  2.0719e-04, -1.5182e-04,\n              5.4918e-05, -1.5288e-04,  4.3818e-04,  3.5738e-05, -3.0111e-06,\n             -2.3142e-04,  1.5133e-04, -2.5875e-05, -1.1713e-04,  1.5749e-04,\n              1.2249e-04, -2.5338e-04, -1.2930e-06,  4.4525e-05,  9.1118e-05,\n             -4.0661e-05,  2.7095e-04,  1.6687e-04, -1.1652e-04, -1.8218e-04,\n              4.4189e-05, -3.8086e-04, -7.0733e-05, -1.5136e-04, -2.3846e-05,\n             -1.8916e-04, -1.7823e-04, -1.8931e-04,  2.3624e-04,  4.9752e-05,\n             -3.0667e-05, -1.0751e-04,  9.1262e-05, -2.2684e-04, -2.8090e-06,\n             -5.7397e-05, -3.5341e-04,  1.6517e-04, -2.7852e-04,  3.1896e-05,\n             -7.6764e-05, -1.7198e-05,  8.9228e-05,  2.7412e-04,  1.2729e-04,\n             -3.5783e-04, -2.0512e-05,  9.7870e-05, -4.1453e-05,  8.5942e-05,\n             -1.5004e-04,  4.3958e-04, -3.4066e-04, -2.2248e-05, -1.7079e-04,\n              5.4706e-04, -1.4158e-04, -9.3709e-06,  2.7776e-05, -9.8394e-05,\n              1.3047e-04,  9.9219e-05,  3.4120e-04, -4.7662e-05, -1.2922e-04,\n             -3.3557e-05,  9.9102e-05,  1.7248e-06, -3.4150e-04, -3.7272e-05,\n             -5.2921e-05, -1.9228e-04, -3.5081e-04, -2.6610e-04,  1.9152e-04,\n             -3.1004e-05,  8.5132e-05, -5.7539e-05,  2.4871e-05, -2.9765e-04,\n             -8.5999e-05, -7.5990e-05,  7.8554e-05, -8.0362e-05, -8.7206e-06,\n             -8.9774e-05,  1.9995e-04,  3.4855e-04,  2.0357e-05, -6.6315e-05,\n             -3.1304e-04,  2.0474e-05,  1.1569e-04,  1.4393e-04, -9.3526e-05,\n             -1.1647e-04, -3.6189e-05,  8.1456e-05, -2.5501e-05, -2.1916e-04,\n             -6.2115e-05,  2.0303e-04,  2.3146e-04, -1.6176e-04,  3.9828e-05,\n             -4.6181e-05,  1.3121e-04, -3.2027e-04,  2.3751e-05,  1.0593e-04,\n              1.6391e-04,  5.1286e-06, -1.2330e-04,  2.3225e-04,  3.2315e-05,\n              2.2841e-05, -2.0322e-04,  1.3671e-04, -9.0518e-05, -2.2304e-04,\n             -8.4951e-05,  6.8331e-05,  5.9918e-05,  2.5909e-04, -7.3330e-05,\n              1.3335e-04,  9.5664e-06, -2.4555e-05, -1.4508e-06,  2.2048e-04,\n              3.0795e-05,  1.1453e-05,  1.5814e-05,  1.0595e-04, -2.7666e-05,\n             -3.7793e-04, -3.4525e-05,  1.4025e-04,  1.7511e-04,  3.2689e-04,\n             -7.6843e-05, -1.7773e-04,  1.0425e-04,  8.4139e-05,  6.5888e-05,\n             -6.7596e-05,  3.4922e-04,  5.1601e-05, -5.9442e-04,  8.6760e-05,\n              2.9696e-05,  8.7910e-05,  1.0318e-04, -2.7821e-04,  3.1272e-05,\n             -1.0697e-04, -3.1422e-04, -1.0707e-04,  2.3937e-05,  3.0364e-04,\n              6.9465e-05,  1.4692e-04, -1.6479e-04,  8.4517e-06,  4.7626e-05,\n             -1.5728e-04,  1.0261e-04, -4.2993e-05,  1.5871e-04, -5.3837e-05,\n             -6.4744e-05,  4.5501e-06,  2.2773e-04, -1.2056e-04, -1.0193e-04,\n             -2.7009e-04,  3.9004e-04,  2.4263e-05,  1.7024e-04, -7.3052e-05,\n             -1.5963e-05,  6.2088e-05, -2.2082e-04,  2.2052e-04,  5.2604e-05,\n              8.1228e-05, -6.9239e-05, -6.4230e-05, -2.9939e-04,  2.8491e-05,\n              1.7765e-04,  1.3339e-04, -2.5258e-05,  4.1285e-04,  9.0575e-05,\n             -2.7939e-04, -5.5323e-05,  2.2152e-04, -1.9256e-04,  4.8289e-04,\n              1.1943e-04,  1.0123e-05, -1.1878e-04, -1.2739e-04, -5.7908e-05,\n              1.3653e-04,  7.0002e-05, -4.1896e-05, -1.2102e-04,  1.8534e-04,\n             -1.9719e-05, -2.8780e-05,  3.9067e-04,  4.5098e-05,  1.3714e-04,\n              6.6180e-05, -2.5456e-04,  9.4247e-05, -3.4019e-04,  8.2255e-05,\n              1.4732e-04,  3.0107e-04, -1.7952e-04,  3.7076e-04,  1.7537e-04,\n              2.1757e-05, -1.8198e-05, -7.0840e-05, -9.9726e-05,  6.6600e-05,\n             -1.1958e-04,  1.6946e-04, -1.7543e-04,  5.2813e-05, -7.6433e-05,\n             -4.9570e-05, -4.5290e-05, -2.8755e-04,  2.1944e-04,  6.9364e-06,\n             -2.4033e-04,  2.8970e-04,  4.9065e-05,  2.4819e-04,  2.0094e-05,\n              2.9029e-04]),\n     'exp_avg_sq': tensor([5.1020e-08, 8.9910e-08, 5.3064e-08, 1.3119e-07, 1.5555e-07, 6.4028e-08,\n             9.2942e-08, 6.2078e-08, 7.3218e-08, 7.9090e-08, 1.2168e-07, 1.5343e-07,\n             8.3637e-08, 6.4342e-08, 5.5650e-08, 7.4420e-08, 6.3932e-08, 4.6602e-08,\n             3.2559e-08, 9.2954e-08, 9.9375e-08, 6.5723e-08, 5.2728e-08, 4.1859e-08,\n             3.2316e-08, 1.0390e-07, 8.0747e-08, 1.3293e-07, 7.6459e-08, 6.3609e-08,\n             1.0720e-07, 1.4871e-07, 9.2976e-08, 8.5893e-08, 6.3163e-08, 5.0987e-08,\n             4.3191e-08, 2.8422e-08, 5.9319e-08, 6.2665e-08, 1.0000e-07, 2.3209e-07,\n             6.5533e-08, 4.5595e-08, 4.4701e-08, 6.6719e-08, 9.6482e-08, 1.1661e-07,\n             1.6696e-07, 5.7798e-08, 1.3451e-07, 1.0162e-07, 1.0355e-07, 7.5208e-08,\n             7.6255e-08, 5.5936e-08, 5.0867e-08, 1.0250e-07, 8.8236e-08, 5.2980e-08,\n             1.6502e-07, 1.5750e-07, 1.1808e-07, 6.8763e-08, 3.2573e-08, 1.2909e-07,\n             8.3515e-08, 4.7338e-08, 8.1985e-08, 4.6700e-08, 5.3182e-08, 1.7347e-07,\n             9.9325e-08, 5.6249e-08, 1.7506e-07, 6.4687e-08, 5.9333e-08, 1.6499e-07,\n             5.9209e-08, 4.5269e-08, 1.6285e-07, 9.8041e-08, 7.6018e-08, 7.8078e-08,\n             1.1496e-07, 1.0102e-07, 6.0065e-08, 3.7501e-08, 3.8470e-08, 8.4121e-08,\n             3.4957e-08, 8.3557e-08, 5.7692e-08, 8.9693e-08, 2.0163e-08, 4.1915e-08,\n             5.3128e-08, 1.1194e-07, 1.0640e-07, 4.9682e-08, 1.8576e-07, 2.9162e-07,\n             1.5682e-07, 7.1075e-08, 7.1084e-08, 7.0015e-08, 3.9670e-08, 1.2125e-07,\n             1.2556e-07, 7.8452e-08, 1.5682e-07, 7.5577e-08, 9.1414e-08, 1.3671e-07,\n             6.9766e-08, 8.5472e-08, 3.2409e-08, 1.7825e-07, 9.6898e-08, 3.9034e-08,\n             5.0154e-08, 1.9242e-07, 7.4066e-08, 8.0105e-08, 7.7856e-08, 7.2450e-08,\n             1.3328e-07, 1.0814e-07, 7.0382e-08, 6.1515e-08, 1.0308e-07, 1.0342e-07,\n             7.2814e-08, 5.2113e-08, 9.0434e-08, 7.4495e-08, 6.0192e-08, 1.2508e-07,\n             3.9868e-08, 1.0819e-07, 1.9865e-07, 4.4902e-08, 9.7321e-08, 7.3206e-08,\n             1.7717e-07, 7.6042e-08, 1.7403e-07, 1.2537e-07, 1.7406e-07, 4.1887e-07,\n             4.5098e-08, 1.8126e-07, 2.2423e-07, 1.0953e-07, 8.7946e-08, 5.9013e-08,\n             6.3607e-08, 9.3777e-08, 2.9678e-07, 1.2459e-07, 7.5772e-08, 1.1714e-07,\n             9.2785e-08, 3.4929e-07, 1.1159e-07, 8.3054e-08, 1.2765e-07, 6.3641e-08,\n             1.0894e-07, 1.5261e-07, 6.7360e-08, 7.2349e-08, 4.5661e-08, 1.5097e-07,\n             6.0896e-08, 5.7860e-08, 6.7846e-08, 1.0257e-07, 9.5443e-08, 5.7621e-08,\n             1.0181e-07, 9.7513e-08, 8.9084e-08, 9.4581e-08, 8.6208e-08, 1.0451e-07,\n             9.0638e-08, 6.6485e-08, 3.4736e-08, 5.2484e-08, 7.7465e-08, 3.8078e-08,\n             8.6842e-08, 1.1670e-07, 7.1393e-08, 9.3545e-08, 7.9678e-08, 8.1900e-08,\n             1.0863e-07, 7.0972e-08, 8.4239e-08, 7.1643e-08, 2.4309e-07, 9.4140e-08,\n             1.0129e-07, 6.6177e-08, 3.0868e-08, 8.7484e-08, 1.2535e-07, 1.3252e-07,\n             7.1227e-08, 3.9302e-08, 6.8620e-08, 8.3310e-08, 6.5118e-08, 4.1784e-08,\n             5.4070e-08, 5.3332e-08, 4.4410e-08, 6.4885e-08, 4.7032e-08, 5.3569e-08,\n             7.9028e-08, 5.7508e-08, 1.9055e-07, 1.0140e-07, 5.0969e-08, 1.2778e-07,\n             1.2151e-07, 9.2830e-08, 9.9880e-08, 1.1321e-07, 6.8371e-08, 1.0695e-07,\n             8.8049e-08, 7.6186e-08, 1.0583e-07, 6.5342e-08, 1.0788e-07, 8.0894e-08,\n             8.1859e-08, 9.2737e-08, 1.2780e-07, 6.2489e-08, 6.7248e-08, 4.9859e-08,\n             6.4701e-08, 1.4466e-07, 1.1915e-07, 4.8456e-08, 8.7325e-08, 1.1310e-07,\n             4.1337e-08, 8.5169e-08, 4.5466e-08, 2.3980e-07])},\n    65: {'exp_avg': tensor([ 1.4959e-06,  7.3454e-05,  8.0757e-05,  1.0299e-04, -2.2125e-04,\n              1.3209e-05, -2.3854e-04, -5.8917e-05,  1.0373e-04,  6.8098e-06,\n              2.3114e-05, -9.5428e-05,  3.4859e-04,  4.5884e-05,  1.3960e-04,\n             -1.1587e-04,  2.0676e-04,  3.6266e-05, -1.0171e-04,  8.6457e-05,\n              1.6262e-04, -1.1642e-04,  2.4396e-05, -3.9733e-05,  8.8181e-05,\n              1.0672e-04,  1.6267e-04,  1.4671e-04, -1.1623e-04, -1.3592e-04,\n             -9.1469e-05, -1.6766e-04, -6.8897e-06, -9.3762e-05, -4.7596e-05,\n             -1.5731e-04, -9.1689e-05, -1.3624e-04,  1.3202e-04,  9.6565e-05,\n             -1.6488e-05, -8.3399e-06,  7.2051e-05, -1.6970e-04,  3.5851e-05,\n             -3.8497e-06, -1.8281e-04,  5.5869e-05, -1.4062e-04, -4.5067e-05,\n             -6.7184e-05, -2.4184e-05,  1.3394e-04,  1.3993e-04,  1.1193e-04,\n             -2.2880e-04, -2.6013e-05,  2.2147e-05,  3.2669e-05,  9.9700e-05,\n             -8.8889e-06,  2.3346e-04, -1.7387e-04, -1.0527e-04, -1.2128e-04,\n              3.2130e-04, -1.4472e-04, -8.2898e-05,  3.1450e-05, -5.0897e-05,\n              1.0025e-04,  5.1386e-05,  1.7803e-04, -7.7493e-05,  3.3756e-05,\n             -1.2577e-04,  2.1944e-05,  5.5554e-05, -1.7925e-04, -7.2514e-06,\n              4.0464e-05, -1.9182e-04, -1.3415e-04, -1.6169e-04,  4.5583e-05,\n             -3.3027e-05,  6.6496e-05, -3.9321e-05,  2.8850e-05, -1.2460e-04,\n             -4.1855e-05, -1.7657e-05,  6.6084e-05,  2.4445e-05, -3.0535e-05,\n             -5.3553e-05,  7.0316e-05,  1.3718e-04, -3.4750e-05, -5.4926e-05,\n             -1.2920e-04, -1.8159e-05,  7.3320e-06,  1.0645e-04, -1.7603e-04,\n             -1.5772e-04,  2.0788e-05,  6.5066e-05,  3.9017e-05, -1.8394e-04,\n              1.1579e-04,  1.8139e-04,  7.9366e-05,  2.2382e-06,  8.1648e-05,\n             -6.9414e-06, -3.8255e-05, -1.2081e-04, -1.6626e-05,  2.5645e-04,\n              2.3933e-04,  3.3360e-05, -5.7987e-05,  1.0937e-04,  1.2891e-05,\n             -7.5716e-05, -9.1018e-05,  9.2533e-05, -9.2383e-05, -1.0982e-04,\n              1.1316e-05,  8.0503e-05,  9.6790e-05,  2.1365e-04, -2.7335e-05,\n              4.9290e-05,  4.6719e-05, -5.4245e-05, -2.0116e-05,  1.9818e-04,\n              6.5318e-05, -4.0139e-05, -4.6830e-05,  6.7315e-05,  5.3548e-06,\n             -2.4477e-04, -4.5174e-05,  3.5275e-05,  7.2978e-05,  1.1850e-04,\n             -6.9478e-05, -4.1953e-05,  1.4437e-05,  4.2538e-05, -1.2612e-05,\n             -3.5714e-05,  2.5323e-04, -1.3336e-06, -1.9399e-04, -5.4107e-06,\n              1.2522e-05,  7.7436e-05,  2.8687e-05,  3.1544e-05, -7.3329e-05,\n             -1.1004e-05, -1.1671e-04, -5.5442e-05, -8.3144e-05,  1.6269e-04,\n              7.1796e-06,  1.7920e-04, -8.3775e-07,  9.3033e-05,  5.1139e-05,\n             -6.2461e-05, -2.0948e-07,  4.5869e-05,  3.5487e-05, -3.2626e-05,\n              3.4541e-07, -1.5451e-05,  1.0536e-04, -7.2188e-05, -7.0524e-06,\n             -1.1780e-04,  2.5612e-04,  5.4892e-06,  1.0101e-04, -4.5619e-05,\n              1.3851e-05,  1.9669e-05, -1.2740e-04,  8.1387e-05,  1.7816e-05,\n              2.5136e-04, -1.8616e-05,  2.2087e-05, -1.0360e-04,  3.3166e-05,\n              1.2843e-04,  2.6938e-05, -2.1938e-06,  1.7298e-04,  6.1088e-05,\n             -1.0474e-04, -2.6840e-05,  1.4900e-04, -1.5326e-04,  2.1854e-04,\n              2.9839e-05, -1.3116e-05, -6.4487e-05, -8.0319e-05, -3.2415e-05,\n              8.9926e-05,  3.4055e-05, -3.7027e-05, -1.2776e-04,  1.3764e-04,\n             -5.8294e-05, -1.3423e-05,  2.3114e-04,  2.7648e-05,  4.5435e-05,\n              7.7309e-05, -8.3964e-05,  6.5178e-05, -1.4721e-04,  1.0141e-04,\n              9.5076e-05,  1.2686e-04, -1.4739e-05,  1.7750e-04,  4.1324e-05,\n              1.4623e-04,  7.4337e-05, -6.6416e-05, -8.0219e-05,  1.2085e-04,\n             -2.7195e-05,  1.1711e-04, -1.3080e-04,  1.6381e-04, -8.4338e-05,\n             -9.7957e-05, -1.6074e-06, -3.5018e-04,  1.8874e-04, -5.2061e-05,\n             -1.7620e-04,  7.9804e-05,  5.0449e-05,  2.4623e-04,  3.3447e-05,\n              1.4121e-04]),\n     'exp_avg_sq': tensor([2.5497e-08, 4.1664e-08, 1.2534e-08, 3.1673e-08, 4.9255e-08, 3.1524e-08,\n             3.3434e-08, 2.8746e-08, 2.9533e-08, 3.5949e-08, 3.1315e-08, 3.7057e-08,\n             4.6008e-08, 2.2482e-08, 2.6312e-08, 2.7137e-08, 1.8100e-08, 2.0923e-08,\n             1.1848e-08, 3.3178e-08, 3.6327e-08, 2.3416e-08, 2.0791e-08, 2.2378e-08,\n             1.5612e-08, 3.3004e-08, 3.4045e-08, 5.0081e-08, 3.6657e-08, 2.8076e-08,\n             3.3971e-08, 2.2320e-08, 2.2387e-08, 3.0619e-08, 2.5198e-08, 2.7449e-08,\n             1.6178e-08, 1.1669e-08, 1.9106e-08, 2.2855e-08, 4.5686e-08, 3.9279e-08,\n             2.8850e-08, 2.1092e-08, 3.2626e-08, 2.4072e-08, 3.7985e-08, 4.9763e-08,\n             6.4412e-08, 2.4010e-08, 2.8097e-08, 3.6849e-08, 3.2878e-08, 2.8986e-08,\n             4.2303e-08, 2.1211e-08, 2.3592e-08, 3.4833e-08, 1.9342e-08, 2.8379e-08,\n             3.5185e-08, 5.1964e-08, 3.3583e-08, 3.3656e-08, 1.4451e-08, 4.4820e-08,\n             2.7125e-08, 1.9463e-08, 3.4045e-08, 2.0065e-08, 2.6718e-08, 4.9086e-08,\n             3.6956e-08, 2.5522e-08, 5.0025e-08, 4.2212e-08, 1.5876e-08, 4.9623e-08,\n             2.5216e-08, 1.3037e-08, 4.3641e-08, 4.9486e-08, 3.4740e-08, 3.1783e-08,\n             3.8270e-08, 2.3882e-08, 2.0658e-08, 2.1986e-08, 1.6961e-08, 3.3497e-08,\n             1.4430e-08, 3.2432e-08, 2.3311e-08, 4.3512e-08, 1.5301e-08, 1.3786e-08,\n             1.8771e-08, 3.1220e-08, 3.7217e-08, 1.7709e-08, 3.3364e-08, 4.0903e-08,\n             5.3512e-08, 2.6376e-08, 4.4699e-08, 3.5352e-08, 1.4481e-08, 2.8136e-08,\n             3.7369e-08, 4.2544e-08, 4.0351e-08, 3.3789e-08, 3.1225e-08, 3.5234e-08,\n             3.3276e-08, 2.6081e-08, 1.6891e-08, 3.5402e-08, 2.6635e-08, 3.6355e-08,\n             2.9499e-08, 2.8819e-08, 2.3458e-08, 2.7453e-08, 2.8825e-08, 4.5060e-08,\n             4.9078e-08, 3.8530e-08, 4.6326e-08, 1.7842e-08, 3.5858e-08, 3.4118e-08,\n             3.0963e-08, 3.1216e-08, 3.8641e-08, 3.3600e-08, 2.3016e-08, 2.2613e-08,\n             2.1520e-08, 3.9420e-08, 3.2613e-08, 1.6698e-08, 4.0394e-08, 2.4285e-08,\n             2.7469e-08, 4.4189e-08, 4.6798e-08, 4.4229e-08, 2.7828e-08, 6.1601e-08,\n             1.4916e-08, 3.5203e-08, 4.3808e-08, 3.5735e-08, 3.4781e-08, 2.6980e-08,\n             3.3688e-08, 2.7203e-08, 3.2383e-08, 3.8722e-08, 3.8978e-08, 2.9751e-08,\n             4.5056e-08, 1.0633e-09, 5.2061e-08, 2.7616e-08, 4.5705e-08, 2.9400e-08,\n             4.3836e-08, 3.4101e-08, 2.5762e-08, 4.6680e-08, 2.6172e-08, 3.6513e-08,\n             3.8517e-08, 2.0927e-08, 2.5806e-08, 3.8495e-08, 4.2565e-08, 1.9985e-08,\n             2.7614e-08, 3.8736e-08, 5.2703e-08, 3.2146e-08, 2.5016e-08, 3.0868e-08,\n             4.5834e-08, 2.5478e-08, 1.5918e-08, 3.4579e-08, 1.7040e-08, 1.2934e-08,\n             4.0456e-08, 1.4840e-08, 2.9642e-08, 4.7553e-08, 3.5442e-08, 3.9215e-08,\n             1.8465e-08, 3.9597e-08, 3.0301e-08, 2.8979e-08, 4.1874e-08, 2.5634e-08,\n             2.0578e-08, 2.8643e-08, 8.7450e-09, 3.5703e-08, 2.0848e-08, 4.9583e-08,\n             2.4033e-08, 1.1743e-08, 3.3081e-08, 8.1091e-08, 2.6486e-08, 2.0712e-08,\n             2.1589e-08, 2.1446e-08, 1.6815e-08, 2.5214e-08, 2.1750e-08, 2.6114e-08,\n             3.1277e-08, 2.2974e-08, 4.1702e-08, 3.6353e-08, 1.4589e-08, 3.0387e-08,\n             4.3934e-08, 2.4071e-08, 2.4825e-08, 4.0864e-08, 4.7519e-08, 3.8006e-08,\n             3.1269e-08, 4.8612e-08, 3.1385e-08, 2.1660e-08, 2.8269e-08, 3.0297e-08,\n             2.6836e-08, 3.6307e-08, 4.3331e-08, 3.6865e-08, 2.0523e-08, 2.7692e-08,\n             2.8130e-08, 5.7298e-08, 3.7746e-08, 1.8705e-08, 2.9091e-08, 3.4257e-08,\n             1.9904e-08, 3.4090e-08, 2.9310e-08, 3.5122e-08])},\n    66: {'exp_avg': tensor([-1.5403e-04,  1.1748e-04,  4.9372e-05,  ...,  9.1006e-05,\n              4.4826e-05, -2.9255e-04]),\n     'exp_avg_sq': tensor([3.3572e-08, 2.8511e-08, 5.3808e-08,  ..., 8.5418e-08, 3.7832e-08,\n             4.7636e-08])},\n    67: {'exp_avg': tensor([ 1.6315e-05,  2.5480e-06,  1.0175e-05,  ..., -2.6334e-05,\n              1.7912e-05, -1.0026e-04]),\n     'exp_avg_sq': tensor([1.0541e-08, 1.0060e-08, 6.2136e-10,  ..., 6.7531e-10, 1.4530e-08,\n             9.0786e-09])},\n    68: {'exp_avg': tensor([-2.0421e-04, -2.2961e-05,  2.1073e-04,  1.2199e-04, -1.7379e-04,\n              3.5500e-05, -2.2919e-04, -4.0370e-04, -4.2979e-05,  6.7748e-05,\n             -1.8979e-04,  3.5166e-04,  1.7360e-04,  4.5747e-06,  8.1519e-05,\n              5.9904e-07,  8.6894e-05, -2.8923e-05, -2.6767e-05, -2.7248e-04,\n             -2.9059e-06,  2.1485e-04,  8.5727e-05,  7.2993e-05, -1.6527e-04,\n              1.4429e-05, -3.2657e-04, -1.1778e-04, -6.4197e-05,  2.4541e-04,\n             -3.3473e-04,  8.9676e-05,  2.9359e-05, -8.4938e-05,  6.4967e-05,\n             -2.3006e-05,  2.1294e-04, -7.3719e-05,  1.6284e-04, -7.8917e-05,\n             -1.2904e-04,  2.1850e-04, -8.9213e-05,  3.0879e-04,  3.1028e-04,\n             -2.8527e-04,  4.7759e-07, -1.1642e-05, -1.7218e-04, -9.7374e-05,\n              1.6747e-04, -1.3655e-04,  2.0845e-05, -2.3067e-04, -1.8777e-04,\n              1.2638e-04,  6.5475e-05,  7.6326e-05, -1.6777e-04,  2.2390e-04,\n             -1.4086e-04,  1.5266e-04,  3.2445e-04, -3.4046e-05,  2.2463e-04,\n             -9.9969e-06,  2.1235e-04,  7.3306e-05,  2.6421e-04,  1.7202e-04,\n             -6.0310e-06, -3.3884e-05, -8.0686e-05,  6.0632e-05,  5.5440e-05,\n              1.6033e-04,  1.7375e-04, -1.2690e-04,  7.8192e-05,  6.2077e-05,\n             -1.1467e-04, -1.6322e-05,  1.1568e-04, -1.2228e-05,  5.0616e-06,\n             -5.8001e-05, -2.2797e-04,  3.6776e-05, -1.5726e-04,  1.4904e-04,\n              3.0514e-04, -2.3998e-04, -3.6886e-06, -3.1751e-05, -2.6130e-04,\n              7.5673e-05,  3.2947e-04,  1.3646e-04,  7.5517e-05,  8.3746e-05,\n              6.7068e-05, -1.0835e-04, -1.7555e-05, -1.8427e-04,  1.1882e-04,\n             -1.0608e-04, -1.4312e-04,  1.1110e-04, -7.6797e-05, -8.2964e-05,\n              5.1921e-05,  1.3739e-04,  4.1506e-05, -1.8794e-04,  8.1633e-05,\n              5.4851e-05, -7.7624e-05, -1.6559e-05,  1.2675e-04,  1.0950e-05,\n              2.0899e-04, -1.1833e-04,  5.9461e-06,  2.0387e-04, -1.0399e-04,\n              8.4035e-05, -6.6715e-05,  5.5399e-05, -3.8698e-04,  4.8840e-05,\n             -1.3539e-04,  7.1277e-05, -1.3525e-04, -5.9343e-05, -1.0728e-04,\n              5.4965e-05,  2.3834e-04, -1.8148e-04,  2.7674e-05, -1.6457e-04,\n             -2.7174e-04,  6.9670e-05,  9.4594e-05,  2.2660e-05, -9.8648e-05,\n             -1.2956e-04,  1.0896e-06, -1.5106e-04,  7.2005e-05,  2.2362e-05,\n             -2.0674e-04, -4.9651e-04,  5.3202e-05,  9.4678e-05,  8.8774e-05,\n              1.6691e-04,  3.6264e-05, -7.2187e-05,  3.5960e-05,  2.7257e-05,\n             -7.7818e-05,  4.4171e-05,  2.9711e-04, -4.6345e-05,  7.0794e-05,\n             -1.0955e-06, -1.8739e-04, -2.2309e-04,  4.9830e-05, -9.7850e-05,\n              1.8708e-04, -3.5769e-05,  8.2648e-05,  6.1790e-05,  4.6611e-04,\n              6.5354e-05,  3.9533e-05,  1.6962e-04, -2.6274e-04, -1.6708e-04,\n              5.2606e-05, -1.4633e-04, -1.5296e-04,  2.4862e-04,  1.4985e-04,\n              1.2135e-04,  1.6842e-04,  2.9557e-04,  7.8542e-06,  6.5101e-05,\n              4.5683e-05, -3.2669e-05,  2.3257e-05,  5.8881e-05, -1.2876e-04,\n              2.7713e-04,  7.8937e-06, -2.6678e-04, -1.7500e-04, -1.3122e-04,\n              1.1026e-04,  4.4683e-05,  2.1665e-04,  9.4950e-05, -2.4922e-04,\n             -1.3781e-04, -8.6533e-06, -2.7257e-04,  2.9586e-05, -2.8121e-06,\n             -1.7652e-04,  1.5218e-05, -1.5499e-04,  1.0194e-04,  1.1900e-04,\n             -1.6199e-04, -8.0537e-06,  1.6935e-05,  1.6989e-05, -1.3477e-04,\n             -1.6884e-04, -1.2885e-04,  5.3114e-05, -5.5725e-06,  1.0263e-06,\n              2.1508e-04,  2.1004e-04,  3.4301e-05, -1.3985e-04, -7.8281e-05,\n             -2.1535e-04, -9.3777e-05, -2.5278e-04, -1.0704e-04,  1.4186e-04,\n              7.3216e-05,  1.6984e-05, -2.4069e-04,  2.8325e-04, -3.0739e-05,\n              1.1766e-04, -2.1273e-05, -1.5453e-04,  3.0633e-04, -1.7389e-04,\n              1.8697e-04, -8.3416e-05,  3.4052e-04, -9.3366e-05,  5.8819e-05,\n              2.5138e-04, -1.2079e-04, -1.6505e-04,  3.3638e-05, -9.5412e-05,\n             -3.7730e-04]),\n     'exp_avg_sq': tensor([8.7377e-08, 7.9164e-08, 3.8845e-08, 4.4190e-08, 9.8495e-08, 7.2371e-08,\n             7.7568e-08, 1.7294e-07, 8.5135e-08, 2.4192e-08, 7.1675e-08, 7.7309e-08,\n             7.7488e-08, 7.9904e-08, 1.1354e-07, 6.6574e-08, 1.7034e-07, 9.5810e-08,\n             7.7022e-08, 9.3189e-08, 1.0082e-07, 1.0563e-07, 6.5647e-08, 7.6910e-08,\n             5.3017e-08, 7.7191e-08, 9.6437e-08, 4.3882e-08, 6.6914e-08, 8.1706e-08,\n             1.7628e-07, 6.4057e-08, 6.5214e-08, 8.4983e-08, 6.1875e-08, 7.2769e-08,\n             8.1350e-08, 1.0178e-07, 8.3101e-08, 1.1886e-07, 4.5391e-08, 1.0979e-07,\n             8.1787e-08, 8.3815e-08, 1.0817e-07, 6.3723e-08, 1.2484e-07, 6.0473e-08,\n             1.1440e-07, 7.2792e-08, 5.7597e-08, 2.7292e-08, 1.4230e-07, 1.2543e-07,\n             1.1440e-07, 7.9186e-08, 6.7216e-08, 1.1562e-07, 5.9382e-08, 7.2504e-08,\n             7.8674e-08, 7.5793e-08, 1.4167e-07, 5.9713e-08, 6.9830e-08, 5.9627e-08,\n             2.1098e-07, 5.7598e-08, 7.0346e-08, 9.7923e-08, 1.3173e-08, 7.3975e-08,\n             9.5611e-08, 8.7789e-08, 7.5721e-08, 9.1737e-08, 8.5648e-08, 9.4483e-08,\n             6.2157e-08, 5.3550e-08, 7.2611e-08, 6.0578e-08, 6.5048e-08, 5.3268e-08,\n             6.5872e-08, 1.3886e-07, 1.3957e-07, 1.0165e-07, 1.5311e-07, 2.2927e-07,\n             9.8512e-08, 8.0826e-08, 8.1801e-08, 1.0536e-07, 6.1635e-08, 5.7737e-08,\n             8.1378e-08, 9.9165e-08, 7.9274e-08, 7.1352e-08, 1.3029e-07, 6.8353e-08,\n             1.0425e-07, 1.4499e-07, 4.7629e-08, 9.8411e-08, 4.5860e-08, 7.6568e-08,\n             9.4313e-08, 7.9671e-08, 3.5359e-08, 6.4289e-08, 5.8850e-08, 7.4674e-08,\n             6.5928e-08, 3.8494e-08, 4.5435e-08, 8.6272e-08, 7.2979e-08, 1.1022e-07,\n             8.0142e-08, 5.8475e-08, 8.8769e-08, 1.3343e-07, 8.9487e-08, 7.9309e-08,\n             5.3856e-08, 7.5457e-08, 7.9419e-08, 8.5840e-08, 5.3314e-08, 1.1914e-07,\n             4.4211e-08, 6.2203e-08, 1.0492e-07, 3.2643e-08, 8.3471e-08, 1.0116e-07,\n             6.7841e-08, 8.2637e-08, 7.1660e-08, 1.0754e-07, 7.9071e-08, 6.4919e-08,\n             6.8120e-08, 7.9296e-08, 1.0760e-07, 5.7412e-08, 6.5910e-08, 6.0687e-08,\n             7.4223e-08, 1.2453e-07, 5.1458e-08, 7.6577e-08, 4.9772e-08, 1.0010e-07,\n             9.6069e-08, 1.0729e-07, 5.1789e-08, 5.8176e-08, 9.1932e-08, 7.9080e-08,\n             5.8369e-08, 4.1204e-08, 3.6997e-08, 4.6516e-08, 7.1652e-08, 8.8619e-08,\n             5.6092e-08, 7.8521e-08, 9.0515e-08, 9.4045e-08, 8.6644e-08, 8.5300e-08,\n             2.8230e-07, 5.4943e-08, 6.5854e-08, 9.6718e-08, 6.6219e-08, 5.7175e-08,\n             7.6663e-08, 6.9982e-08, 1.1215e-07, 1.0899e-07, 6.9293e-08, 7.5168e-08,\n             1.0472e-07, 8.4831e-08, 5.1720e-08, 8.7806e-08, 8.4041e-08, 9.3034e-08,\n             8.9001e-08, 6.6956e-08, 1.0173e-07, 6.9167e-08, 5.6586e-08, 1.1770e-07,\n             8.3913e-08, 9.0183e-08, 6.6625e-08, 8.3379e-08, 7.9979e-08, 8.2890e-08,\n             1.0396e-07, 1.3633e-07, 1.4779e-07, 1.0119e-07, 8.4593e-08, 8.3845e-08,\n             1.2571e-07, 1.1244e-07, 8.7378e-08, 7.5222e-08, 1.6442e-07, 6.1773e-08,\n             1.0284e-07, 1.1102e-07, 8.3634e-08, 8.3961e-08, 9.0888e-08, 9.0585e-08,\n             8.7648e-08, 1.7780e-07, 1.1142e-07, 7.2891e-08, 5.2281e-08, 4.9769e-08,\n             1.0058e-07, 3.1533e-08, 8.8334e-08, 9.3527e-08, 9.0804e-08, 8.5764e-08,\n             1.8509e-07, 5.2382e-08, 5.7034e-08, 1.0658e-07, 3.9657e-08, 1.0358e-07,\n             5.4630e-08, 8.8203e-08, 9.7571e-08, 9.1247e-08, 1.1053e-07, 1.0037e-07,\n             7.1158e-08, 1.1529e-07, 7.4619e-08, 5.0959e-08, 1.1053e-07, 9.7446e-08,\n             8.7464e-08, 9.2316e-08, 1.7453e-07, 9.3261e-08])},\n    69: {'exp_avg': tensor([-2.0517e-04,  7.6137e-06,  1.6873e-04, -3.4345e-05, -8.9496e-05,\n             -2.4600e-05, -1.7015e-04, -6.6659e-05, -3.8786e-05,  6.1605e-05,\n             -1.1201e-04,  1.1357e-04,  1.5763e-04,  9.8124e-05,  1.0803e-05,\n              1.8602e-05, -1.2059e-04,  1.1357e-05, -2.9083e-05, -2.1085e-04,\n             -2.7003e-05,  1.7466e-06,  2.0599e-04, -1.0563e-05, -6.8620e-05,\n              6.0191e-06, -1.5173e-04, -6.3406e-05, -7.0852e-05,  1.3661e-04,\n             -1.1539e-04,  4.6699e-05, -1.8260e-05,  9.8426e-05,  1.3522e-04,\n             -5.4967e-05,  1.5368e-04, -2.3929e-05,  8.3400e-05, -9.0760e-05,\n             -1.9769e-04,  1.1782e-04, -9.0529e-05,  1.4747e-04,  1.8926e-04,\n             -1.5980e-04,  1.0555e-05, -2.6358e-06, -8.7902e-05, -1.0946e-06,\n              7.5980e-05, -9.0650e-05,  1.8663e-05, -7.9832e-05, -8.9904e-05,\n              5.9470e-05,  1.1420e-04,  2.1672e-04, -1.1282e-04,  1.3204e-04,\n             -1.9313e-04,  8.0900e-05,  1.4324e-04, -1.1943e-04,  1.1580e-04,\n             -1.7629e-06,  7.7402e-05,  8.3167e-05,  1.6878e-04,  7.5397e-05,\n             -1.3530e-05, -1.2487e-04, -9.7062e-05,  5.8128e-06,  9.1535e-05,\n              2.7833e-05,  1.1981e-04, -5.3434e-05,  1.3671e-05, -8.7616e-06,\n             -8.5550e-05, -1.2318e-05,  1.0551e-04, -5.4165e-06, -9.2351e-06,\n             -1.3954e-04, -1.0702e-04,  8.8182e-06, -8.6154e-05,  7.7201e-06,\n              2.1018e-04, -4.2764e-05, -1.2445e-05,  1.7499e-04, -7.5932e-05,\n              1.1404e-04,  1.3528e-04,  6.8904e-05,  7.8255e-05,  2.5495e-05,\n              4.6402e-05, -7.8257e-05,  7.4572e-07, -7.3528e-05,  5.6937e-05,\n             -1.0820e-04, -6.6267e-05,  2.4330e-05, -2.8608e-05, -7.5779e-05,\n              3.5108e-05,  1.8536e-04,  2.9454e-05, -1.6874e-04,  8.1569e-05,\n              1.9552e-05, -4.2962e-05,  2.2605e-04,  5.3423e-05,  3.5825e-06,\n              1.8023e-04, -6.1891e-05,  6.8657e-05, -1.9855e-05, -1.4840e-04,\n              3.6108e-05,  6.6503e-05, -1.2514e-06, -2.0790e-04,  2.7874e-06,\n             -1.2697e-04,  6.4242e-05, -1.1449e-04,  1.1131e-05, -9.7007e-05,\n              5.0292e-06,  1.1854e-04, -7.1242e-05,  1.3613e-04, -4.5867e-05,\n             -1.1608e-04,  3.1896e-05,  6.8647e-05, -5.0826e-05, -1.1689e-04,\n             -1.0748e-04,  2.2538e-05, -7.3441e-05,  4.9211e-05,  2.8572e-05,\n             -1.0111e-04, -2.2861e-04,  3.3934e-05,  1.1838e-04,  7.4563e-05,\n              7.9224e-05, -1.5120e-05, -4.9782e-06,  7.7314e-05,  3.2497e-05,\n             -6.4343e-05,  1.0173e-04,  1.9000e-04, -4.7473e-05,  9.7732e-05,\n             -4.0853e-05, -9.0587e-05, -1.0366e-04,  8.8217e-06, -1.3913e-05,\n              6.7527e-05,  4.3737e-05,  1.5755e-04,  3.8293e-05,  1.9146e-04,\n              4.6661e-05, -1.3216e-05,  1.3336e-04, -3.3241e-04, -4.4283e-05,\n              3.3572e-05, -1.6314e-04, -9.2376e-05,  9.2253e-05,  8.2259e-05,\n              6.0807e-05, -3.5621e-05,  2.0462e-04, -1.6454e-05,  1.3656e-04,\n              6.8450e-05,  2.5042e-05,  3.5674e-05,  4.7648e-05, -5.1835e-05,\n              1.5630e-04,  6.4200e-05, -1.1887e-04, -7.3954e-05, -1.0981e-04,\n              9.1272e-05,  5.6988e-05,  7.6331e-05,  1.2720e-04, -8.1007e-05,\n             -9.6869e-05,  9.6373e-06, -9.1771e-05,  5.8671e-05,  8.5986e-06,\n             -1.1479e-04,  4.1498e-06, -8.1741e-05,  8.5969e-05,  5.4899e-05,\n             -6.0211e-05,  1.9847e-04, -1.1962e-05,  3.0516e-05, -1.2099e-04,\n             -7.0499e-05, -1.5026e-04,  2.4237e-05, -1.2634e-05,  7.6391e-05,\n              8.8993e-05,  1.7873e-04, -1.2535e-06, -4.7160e-05,  8.8459e-06,\n             -1.2105e-04, -1.0702e-04, -2.0826e-04, -5.5227e-05,  1.6225e-05,\n             -1.0781e-06,  6.6084e-05, -1.4285e-04,  2.2220e-04, -1.8851e-05,\n              1.2567e-04,  3.8249e-05, -1.2061e-04,  1.7495e-04, -9.4034e-05,\n              1.0173e-04, -1.6718e-05,  1.1882e-04, -4.3926e-06,  2.5130e-05,\n              2.8359e-04, -9.9355e-05, -5.9585e-05,  2.4532e-04, -2.2784e-05,\n             -1.7979e-04]),\n     'exp_avg_sq': tensor([4.5143e-08, 3.7298e-08, 2.7084e-08, 2.6256e-08, 2.8420e-08, 3.6871e-08,\n             2.3185e-08, 2.6811e-08, 4.1126e-08, 2.3121e-08, 3.0438e-08, 1.8118e-08,\n             4.7491e-08, 2.5209e-08, 3.8124e-08, 3.2676e-08, 5.8938e-08, 5.0618e-08,\n             3.3689e-08, 3.0521e-08, 4.7599e-08, 5.8883e-08, 4.5453e-08, 3.7561e-08,\n             1.1298e-08, 2.0116e-08, 3.3658e-08, 3.1350e-08, 3.2448e-08, 2.6891e-08,\n             3.4550e-08, 1.8614e-08, 4.7997e-08, 4.1730e-08, 3.4463e-08, 2.6187e-08,\n             2.8095e-08, 5.3373e-08, 3.8206e-08, 4.2582e-08, 4.0520e-08, 3.8572e-08,\n             3.3537e-08, 5.6593e-08, 3.8248e-08, 3.4478e-08, 4.0692e-08, 1.8006e-08,\n             3.7047e-08, 3.4173e-08, 2.9592e-08, 1.6955e-08, 1.8897e-08, 2.8056e-08,\n             4.0695e-08, 3.5423e-08, 3.3505e-08, 3.4213e-08, 2.7999e-08, 4.6790e-08,\n             4.1257e-08, 1.8917e-08, 6.0036e-08, 4.6685e-08, 4.2870e-08, 3.1086e-08,\n             3.6958e-08, 3.8461e-08, 3.8901e-08, 3.1077e-08, 1.4654e-08, 3.3197e-08,\n             3.2772e-08, 4.1692e-08, 4.2596e-08, 4.3224e-08, 2.7144e-08, 3.1776e-08,\n             2.3254e-08, 1.1407e-08, 2.5487e-08, 2.5696e-08, 3.6939e-08, 2.6283e-08,\n             4.1412e-08, 5.6905e-08, 3.8335e-08, 2.9766e-08, 3.9896e-08, 1.3602e-07,\n             7.4143e-08, 3.5131e-08, 1.6058e-08, 5.5912e-08, 2.1815e-08, 3.4789e-08,\n             3.3442e-08, 4.6853e-08, 5.7596e-08, 2.0306e-08, 4.4998e-08, 2.5529e-08,\n             3.1549e-08, 6.4218e-08, 4.9896e-08, 3.4246e-08, 2.3961e-08, 2.3119e-08,\n             2.7251e-08, 2.8482e-08, 3.4113e-08, 4.7738e-08, 2.9506e-08, 4.6971e-08,\n             3.2387e-08, 1.7922e-08, 3.8418e-08, 5.5593e-08, 3.0560e-08, 1.6323e-08,\n             5.0043e-08, 2.6351e-08, 1.6634e-08, 4.4492e-08, 4.9110e-08, 3.4692e-08,\n             3.4840e-08, 2.8269e-08, 2.0167e-08, 4.4179e-08, 3.0460e-08, 3.1462e-08,\n             2.8281e-08, 2.4034e-08, 3.0423e-08, 3.0965e-08, 3.9497e-08, 2.3771e-08,\n             4.7422e-08, 3.2444e-08, 2.1174e-08, 4.7386e-08, 1.2687e-08, 2.8781e-08,\n             2.1441e-08, 2.3843e-08, 3.6611e-08, 2.7605e-08, 2.6048e-08, 2.1238e-08,\n             3.2577e-08, 5.4564e-08, 1.9719e-08, 3.5144e-08, 3.0444e-08, 4.4260e-08,\n             5.1944e-08, 7.7785e-08, 2.9659e-08, 2.6500e-08, 2.9706e-08, 5.6444e-08,\n             2.8893e-08, 2.3482e-08, 2.6463e-08, 2.7775e-08, 2.9757e-08, 2.8715e-08,\n             2.8005e-08, 2.4693e-08, 3.0561e-08, 3.5277e-08, 2.7513e-08, 3.2938e-08,\n             4.0265e-08, 3.2070e-08, 3.3519e-08, 3.9009e-08, 3.2964e-08, 3.9655e-08,\n             2.4009e-08, 3.8491e-08, 3.9706e-08, 1.6803e-08, 2.6763e-08, 4.2794e-08,\n             5.0981e-08, 3.7317e-08, 2.0318e-08, 4.8685e-08, 4.3861e-08, 2.9373e-08,\n             3.3494e-08, 2.7872e-08, 4.5514e-08, 5.1386e-08, 3.7523e-08, 2.4988e-08,\n             1.8965e-08, 4.2187e-08, 2.2662e-08, 3.8482e-08, 2.2449e-08, 4.6519e-08,\n             3.4890e-08, 4.6352e-08, 7.6529e-08, 2.4300e-08, 3.2129e-08, 3.3653e-08,\n             6.6861e-08, 3.7901e-08, 3.0201e-08, 3.6034e-08, 5.8888e-08, 3.4039e-08,\n             6.8454e-08, 2.6175e-08, 4.3800e-08, 3.4552e-08, 4.6435e-08, 4.6053e-08,\n             3.0686e-08, 3.3901e-08, 4.2189e-08, 3.6901e-08, 3.2053e-08, 3.9166e-08,\n             3.2146e-08, 7.5463e-08, 2.8402e-08, 3.5329e-08, 4.4484e-08, 2.6816e-08,\n             3.0378e-08, 2.1032e-08, 3.1852e-08, 4.3259e-08, 2.9744e-08, 4.0166e-08,\n             3.6857e-08, 4.1329e-08, 5.2521e-08, 2.5422e-08, 4.9697e-08, 5.8468e-08,\n             2.0615e-08, 3.5772e-08, 6.4042e-08, 3.1103e-08, 5.3010e-08, 3.8379e-08,\n             3.6144e-08, 4.9982e-08, 2.5352e-08, 4.3000e-08])},\n    70: {'exp_avg': tensor([ 1.0759e-04,  7.8386e-05, -4.1583e-05,  7.9578e-05, -2.3385e-05,\n             -1.1751e-04,  2.1201e-04, -1.3172e-04,  3.1926e-04,  1.2833e-04,\n             -5.7644e-06, -1.1488e-04, -1.1147e-04, -5.7501e-05, -7.8492e-05,\n              8.8218e-05,  1.8201e-04,  5.8926e-05,  1.4087e-04,  5.2160e-06,\n             -6.3603e-05, -9.1764e-05, -4.3517e-05, -8.0512e-05,  1.0205e-04,\n              1.1063e-04,  9.9537e-07, -1.7294e-04, -2.0156e-04, -1.6268e-05,\n             -5.3005e-05,  5.6431e-05,  8.5512e-05, -1.1921e-04, -9.3427e-05,\n             -7.4090e-05, -8.8643e-05,  7.0854e-05, -2.1003e-05,  1.6765e-04,\n              8.6915e-05, -8.4200e-05, -2.1011e-04, -1.0081e-04, -7.6291e-05,\n              1.0385e-04,  6.6017e-05, -3.2507e-05,  2.4701e-04, -1.1490e-04,\n             -2.5585e-05, -2.5621e-05,  6.0117e-05, -2.1590e-04,  6.2348e-05,\n             -3.5871e-05, -1.5176e-04, -5.7017e-05, -2.2945e-04, -3.9301e-05,\n              2.5968e-05,  1.4403e-04,  8.3028e-05,  1.1304e-04, -4.5787e-06,\n              1.0807e-04, -2.3375e-04, -2.5534e-04,  1.6574e-04, -2.6202e-04,\n              9.3543e-06,  2.6033e-04, -7.8698e-05, -4.8250e-04,  1.3562e-05,\n              6.1353e-05,  1.9876e-06,  1.0075e-04, -9.9586e-05,  1.4269e-04,\n             -2.1639e-05,  5.4002e-05,  1.2656e-04, -1.5773e-04,  1.8724e-04,\n             -1.5035e-04, -3.6358e-04, -1.4998e-04,  2.0181e-05,  1.7309e-04,\n              1.3035e-04, -1.1948e-04,  2.1219e-04, -4.9692e-05,  1.8257e-05,\n             -1.1158e-04, -1.8041e-04,  1.8263e-04,  1.6043e-04,  3.3140e-04,\n             -9.0425e-05, -1.0574e-04, -2.1997e-04, -9.9870e-05,  2.5673e-04,\n              1.4547e-05, -2.2999e-05, -1.1837e-04, -2.5445e-04,  1.5670e-04,\n              7.8208e-05,  3.8068e-05,  7.9117e-05, -3.1074e-05, -7.8821e-05,\n              1.3524e-04, -5.6043e-05, -5.8111e-05, -1.1839e-04,  1.4816e-04,\n             -2.5750e-05, -2.4024e-04, -1.0551e-05, -2.5834e-05,  1.0727e-04,\n             -2.4768e-05,  4.3732e-04, -4.7423e-05,  1.0613e-04, -3.7219e-05,\n              1.6493e-04, -7.3516e-06,  1.3157e-04,  9.8649e-05,  2.0385e-04,\n              1.0821e-05,  9.5582e-05,  9.6230e-05, -4.4304e-05, -2.3854e-04,\n              1.5134e-04, -2.2259e-04,  3.8438e-05,  4.9798e-05, -1.4640e-04,\n              5.4187e-06,  6.2285e-05,  5.9132e-06,  1.9572e-04,  2.4085e-04,\n              3.8469e-05, -2.2429e-05, -1.9527e-04,  1.0901e-04,  1.1587e-04,\n             -9.9874e-05,  1.0964e-05,  1.0711e-04, -1.8375e-04,  2.7829e-04,\n             -5.8751e-05, -1.2631e-04,  4.0731e-05,  5.2005e-04,  5.3429e-05,\n             -3.1850e-04,  3.6575e-05, -9.2141e-06,  2.8281e-04, -1.0476e-04,\n             -3.0528e-04,  2.0859e-04, -4.5994e-05, -9.0770e-05,  3.7925e-04,\n             -4.1133e-05,  2.6744e-05, -1.4529e-04,  1.6515e-04,  1.4279e-05,\n             -2.5649e-04, -2.1179e-04,  2.1617e-05, -1.7335e-04, -8.8539e-05,\n              6.2370e-05,  4.5504e-05, -2.4262e-04,  2.5573e-04,  2.9424e-04,\n              4.9461e-05, -9.8426e-05,  3.4383e-05, -8.6919e-05,  2.3613e-04,\n              5.0781e-05,  2.1808e-04, -4.3266e-04,  1.3859e-05,  3.6647e-05,\n              2.6655e-04, -5.9179e-05, -8.1676e-06, -1.1363e-04,  2.3316e-05,\n             -7.7118e-05,  1.4940e-04, -2.3770e-04, -5.2140e-05,  3.1111e-04,\n              1.1056e-04,  3.8982e-04, -3.9093e-04, -7.6953e-05, -1.1784e-04,\n             -7.6641e-05,  1.4675e-04,  2.9951e-05,  2.1035e-04, -2.9856e-05,\n             -7.1651e-05, -1.4885e-04, -1.2193e-04,  2.9338e-04, -6.7860e-05,\n             -9.7905e-05,  8.2223e-05, -2.7071e-04,  1.2857e-04,  2.0434e-04,\n              2.5935e-05,  7.5170e-05,  8.3049e-05,  1.0955e-04, -6.0488e-05,\n              8.0606e-05, -1.3323e-04,  7.5584e-05,  4.4795e-05, -9.4937e-06,\n              8.7480e-05, -7.9779e-05,  1.6864e-04, -2.8822e-04,  1.0052e-04,\n              8.0733e-05, -1.1331e-05, -2.0271e-04, -2.0741e-04,  8.8336e-05,\n              1.0279e-04, -9.3708e-05, -2.0492e-05, -2.2106e-04,  9.1760e-05,\n             -1.0517e-04]),\n     'exp_avg_sq': tensor([3.5960e-08, 6.7994e-08, 2.8071e-08, 4.6578e-08, 3.4123e-08, 8.2094e-08,\n             5.5860e-08, 3.8731e-08, 1.1649e-07, 3.6388e-08, 2.2384e-08, 1.0150e-07,\n             6.1608e-08, 3.1297e-08, 2.5693e-08, 7.7325e-08, 5.5363e-08, 3.8723e-08,\n             2.5074e-08, 5.6303e-08, 2.0175e-08, 5.9446e-08, 7.1020e-08, 7.4346e-08,\n             3.9863e-08, 3.8435e-08, 4.0989e-08, 4.7181e-08, 2.1699e-08, 7.9180e-08,\n             4.8269e-08, 3.3185e-08, 3.6502e-08, 5.6313e-08, 5.3297e-08, 4.8914e-08,\n             8.7526e-08, 3.0726e-08, 5.3427e-08, 2.3997e-08, 3.5116e-08, 2.5009e-08,\n             7.2738e-08, 3.1920e-08, 7.3985e-08, 3.0907e-08, 2.0502e-08, 7.3445e-08,\n             3.6128e-08, 5.4355e-08, 4.3772e-08, 7.2451e-08, 4.1567e-08, 7.1730e-08,\n             6.6800e-08, 3.1344e-08, 2.7419e-08, 4.7457e-08, 4.8905e-08, 5.3485e-08,\n             3.6530e-08, 3.8338e-08, 3.1532e-08, 9.9567e-08, 2.3552e-08, 2.9684e-08,\n             9.5007e-08, 6.6783e-08, 6.4583e-08, 8.3187e-08, 3.0474e-08, 9.9883e-08,\n             8.8705e-08, 5.6341e-08, 2.6915e-08, 5.2506e-08, 4.5196e-08, 5.9256e-08,\n             3.1909e-08, 2.8284e-08, 3.1888e-08, 5.1524e-08, 5.7045e-08, 5.2442e-08,\n             3.7009e-08, 3.3693e-08, 1.0282e-07, 6.7231e-08, 5.2448e-08, 2.9121e-08,\n             6.5612e-08, 2.5097e-08, 3.3205e-08, 6.0363e-08, 7.8475e-08, 4.8326e-08,\n             5.7390e-08, 2.3645e-08, 2.5599e-08, 5.5770e-08, 6.0037e-08, 2.1671e-08,\n             8.8316e-08, 5.0908e-08, 1.2210e-07, 4.6801e-08, 3.3588e-08, 5.7277e-08,\n             7.3562e-08, 5.2544e-08, 3.6456e-08, 2.8807e-08, 3.5101e-08, 2.0441e-08,\n             4.1852e-08, 5.4930e-08, 7.0207e-08, 4.6514e-08, 9.3728e-08, 2.4118e-08,\n             2.5876e-08, 7.4415e-08, 2.8169e-08, 3.1403e-08, 5.0577e-08, 5.8125e-08,\n             6.8246e-08, 2.3698e-08, 3.6639e-08, 3.5279e-08, 4.1312e-08, 2.2895e-08,\n             6.9307e-08, 5.1875e-08, 4.0465e-08, 9.8547e-08, 2.9496e-08, 3.1935e-08,\n             2.8926e-08, 7.0365e-08, 3.0697e-08, 4.3464e-08, 3.0072e-08, 7.0282e-08,\n             2.9357e-08, 1.2937e-07, 5.2699e-08, 7.1200e-08, 3.2963e-08, 3.8726e-08,\n             4.9587e-08, 7.1214e-08, 8.0768e-08, 5.0007e-08, 2.9071e-08, 5.9933e-08,\n             2.1166e-08, 3.7003e-08, 3.5102e-08, 3.0516e-08, 4.7612e-08, 7.1999e-08,\n             5.0672e-08, 8.6417e-08, 2.4142e-08, 7.8219e-08, 3.0911e-08, 4.8788e-08,\n             5.9509e-08, 3.4821e-08, 8.7026e-08, 9.4169e-08, 6.1466e-08, 4.1943e-08,\n             5.9576e-08, 2.2854e-08, 7.0665e-08, 7.9606e-08, 5.1690e-08, 3.1881e-08,\n             1.7873e-08, 6.4257e-08, 7.4625e-08, 5.7048e-08, 4.3987e-08, 3.1467e-08,\n             2.6302e-08, 5.8592e-08, 4.0498e-08, 8.1441e-08, 4.0883e-08, 3.4556e-08,\n             3.3784e-08, 5.7759e-08, 5.9991e-08, 6.2956e-08, 4.8591e-08, 6.2631e-08,\n             6.3081e-08, 3.1692e-08, 5.6645e-08, 5.2591e-08, 4.3583e-08, 8.4708e-08,\n             4.8987e-08, 4.5815e-08, 6.2400e-08, 3.0728e-08, 2.8636e-08, 4.7449e-08,\n             2.5109e-08, 8.5701e-08, 7.8486e-08, 3.3796e-08, 4.1440e-08, 7.2191e-08,\n             3.5670e-08, 3.9530e-08, 6.6872e-08, 3.5121e-08, 5.2762e-08, 4.6945e-08,\n             2.1497e-08, 6.4262e-08, 4.7327e-08, 4.2813e-08, 2.1194e-08, 4.0800e-08,\n             2.9369e-08, 4.1641e-08, 2.8078e-08, 8.4783e-08, 4.5427e-08, 3.5917e-08,\n             5.3444e-08, 4.9584e-08, 6.0762e-08, 4.1803e-08, 1.8714e-08, 7.0050e-08,\n             5.6391e-08, 5.3267e-08, 6.6017e-08, 5.3733e-08, 2.4979e-08, 4.9068e-08,\n             1.6577e-08, 7.4523e-08, 3.2521e-08, 6.7188e-08, 4.9695e-08, 2.9214e-08,\n             2.7891e-08, 2.6769e-08, 5.8387e-08, 4.4179e-08])},\n    71: {'exp_avg': tensor([-1.0053e-06,  1.7837e-04, -5.8307e-05, -9.0998e-05, -2.1214e-06,\n              3.6298e-06,  6.8706e-05, -4.8743e-05,  5.0689e-05,  1.4881e-04,\n             -1.0331e-04, -7.4907e-05, -6.3605e-05, -1.1575e-04, -3.1176e-05,\n              4.2949e-05,  3.0481e-05,  5.0684e-05,  5.1970e-05, -4.7788e-05,\n             -2.9318e-05,  1.0956e-05, -2.0836e-05, -7.5520e-05,  3.0519e-05,\n              1.0923e-04,  1.7998e-05, -1.3755e-05, -7.2892e-05,  5.8923e-05,\n              1.2560e-04,  3.9652e-06,  5.0308e-05, -7.7099e-05, -6.9853e-06,\n             -6.2038e-05, -5.8661e-05, -9.0992e-06,  2.1296e-05,  6.5083e-05,\n              9.9840e-05, -4.0443e-05,  1.5333e-05, -5.7583e-05,  2.7537e-05,\n              1.0245e-04,  5.4543e-05,  2.3604e-05,  3.4214e-05, -3.2196e-05,\n              8.6344e-06, -3.4194e-05,  6.1237e-05, -9.9487e-05,  2.6934e-05,\n             -4.9619e-05, -3.5518e-05,  6.0409e-05, -1.3377e-04, -3.7731e-05,\n             -2.5204e-06,  1.0517e-04,  7.1796e-05,  1.3810e-04, -4.5345e-05,\n              3.1763e-05, -1.9002e-04, -1.1812e-04,  9.0110e-06, -1.2150e-04,\n              1.8420e-05,  9.6858e-05, -4.1556e-05, -2.6656e-04,  4.3122e-05,\n              7.7627e-05, -8.9526e-05,  7.7332e-05, -5.5104e-05,  7.7550e-05,\n              2.9210e-05,  1.2035e-04,  8.0659e-05, -4.9274e-05,  3.2707e-05,\n             -1.4930e-04, -1.3461e-04, -1.2619e-04, -5.3414e-05,  7.4231e-05,\n              4.3422e-05, -6.8728e-05,  1.8210e-04,  2.7078e-05,  6.3028e-05,\n             -6.6563e-05, -1.7918e-04,  1.2337e-04,  7.1847e-05,  3.3036e-04,\n             -3.5318e-05, -5.8538e-05, -1.4874e-04,  1.6864e-05,  1.2532e-04,\n              2.6976e-05,  3.7856e-05,  5.4100e-05, -9.5078e-05,  1.0023e-04,\n              1.1372e-05,  5.0277e-05,  5.0802e-05, -2.3971e-05, -5.0083e-05,\n              1.3822e-04, -2.4895e-05, -2.9446e-05, -2.0606e-07,  6.4702e-05,\n              3.6080e-06, -1.5042e-04, -7.1848e-05, -1.8885e-05,  5.2040e-05,\n             -1.5455e-04,  2.3546e-04, -1.9127e-05,  7.5515e-05, -2.9027e-05,\n              1.6602e-04,  1.4577e-05,  9.8065e-05,  1.3131e-04,  8.9351e-05,\n              3.4804e-05,  4.8730e-05,  9.0187e-05, -3.7718e-06, -9.5769e-05,\n              8.7670e-05, -4.2268e-05,  4.5319e-05, -4.6714e-05, -5.7599e-05,\n              6.8143e-05,  8.0116e-05,  3.1789e-05,  5.8566e-05,  1.4350e-04,\n              5.0099e-05,  5.6082e-07, -1.3846e-04,  1.1115e-04,  4.9786e-05,\n             -8.6806e-06, -2.9337e-05,  2.7238e-05, -3.8761e-05,  2.7806e-04,\n             -1.1027e-05, -1.6827e-04,  1.3524e-04,  1.4237e-04,  6.6576e-05,\n             -1.7410e-04,  2.5550e-05, -5.5571e-05,  1.0315e-04, -1.6699e-04,\n             -8.8241e-05,  1.4907e-04, -1.1121e-04, -6.6098e-05,  2.4217e-04,\n             -2.5248e-05,  5.4267e-05, -3.8789e-05,  1.2224e-04,  2.2898e-05,\n             -2.1150e-04, -3.1890e-05, -6.8528e-05, -9.8108e-05, -5.8591e-05,\n              4.1212e-05,  6.1994e-06,  3.9325e-05,  7.7757e-05,  2.2723e-04,\n             -7.8359e-06, -7.9924e-05,  4.5726e-05, -4.4288e-05,  1.9726e-04,\n             -6.0143e-05,  1.3886e-04, -1.0363e-04, -3.2055e-05,  2.3238e-05,\n              1.1979e-04, -8.1363e-05,  1.8668e-05, -2.4530e-05,  1.0095e-04,\n              6.3934e-05,  1.1243e-05, -1.3257e-04,  5.0717e-05,  2.0177e-04,\n              9.6139e-05,  4.4383e-05, -8.2112e-05, -7.3869e-05,  6.4775e-06,\n             -1.1139e-04,  1.6181e-04,  9.9257e-05,  1.7245e-04, -6.3319e-06,\n             -8.2727e-05, -4.3094e-05, -5.8078e-05,  9.4421e-05,  3.1834e-05,\n             -1.3170e-04,  7.7431e-05, -1.6078e-04,  5.7287e-05,  6.2243e-05,\n              1.1554e-05,  5.4905e-05, -1.6153e-05,  6.9649e-05, -2.9444e-05,\n              1.8043e-04, -2.8202e-05, -2.0275e-05,  2.7128e-05,  8.2576e-05,\n              9.5855e-05,  1.6841e-05,  5.6703e-05, -6.1914e-05,  7.5731e-05,\n              6.0360e-05,  3.7879e-07, -1.0228e-04, -1.3904e-04,  4.3914e-05,\n              5.1488e-05, -5.6086e-05,  2.7954e-05, -1.7288e-04,  1.5503e-05,\n             -3.5013e-05]),\n     'exp_avg_sq': tensor([1.5463e-08, 2.9449e-08, 1.0621e-08, 2.3073e-08, 1.3903e-08, 2.6036e-08,\n             2.6962e-08, 1.7404e-08, 2.2974e-08, 1.6775e-08, 1.4768e-08, 2.4281e-08,\n             9.6319e-09, 1.5937e-08, 1.7396e-08, 2.5610e-08, 1.6512e-08, 1.6175e-08,\n             9.7154e-09, 2.2937e-08, 7.2520e-09, 2.1156e-08, 2.6761e-08, 2.4299e-08,\n             1.4787e-08, 1.8466e-08, 2.1635e-08, 1.9781e-08, 1.4685e-08, 3.9628e-08,\n             1.7946e-08, 1.5901e-08, 1.8554e-08, 1.8484e-08, 1.9748e-08, 2.4757e-08,\n             2.7311e-08, 1.2592e-08, 2.2544e-08, 1.2052e-08, 1.2752e-08, 1.4420e-08,\n             2.7037e-08, 1.5851e-08, 4.3944e-08, 1.6783e-08, 1.4352e-08, 2.0884e-08,\n             1.4501e-08, 2.1873e-08, 1.2989e-08, 1.9588e-08, 2.1673e-08, 2.4182e-08,\n             2.1590e-08, 2.3997e-08, 1.6729e-08, 2.1750e-08, 2.1101e-08, 3.1651e-08,\n             1.5986e-08, 2.3691e-08, 1.6327e-08, 6.2339e-08, 1.4457e-08, 1.6613e-08,\n             3.1729e-08, 2.8630e-08, 2.6472e-08, 1.7367e-08, 1.1925e-08, 1.3243e-08,\n             1.3769e-08, 2.1545e-08, 1.0218e-08, 1.9606e-08, 2.6321e-08, 2.7648e-08,\n             1.6880e-08, 1.5890e-08, 1.5528e-08, 2.2780e-08, 1.7976e-08, 1.8101e-08,\n             2.2545e-08, 2.1728e-08, 1.5770e-08, 3.0957e-08, 1.9000e-08, 1.4166e-08,\n             1.6047e-08, 1.0186e-08, 1.5634e-08, 2.1013e-08, 2.2425e-08, 1.6379e-08,\n             2.9221e-08, 1.0219e-08, 1.5233e-08, 2.8894e-08, 1.3216e-08, 1.1455e-08,\n             2.7518e-08, 1.7990e-08, 2.2246e-08, 2.2441e-08, 1.1488e-08, 2.6792e-08,\n             1.7118e-08, 1.7988e-08, 2.2221e-08, 1.4660e-08, 1.4518e-08, 1.1134e-08,\n             1.9737e-08, 2.4389e-08, 2.0884e-08, 1.8854e-08, 2.7640e-08, 1.2877e-08,\n             1.2231e-08, 2.1255e-08, 1.0639e-08, 1.1717e-08, 2.1612e-08, 2.2426e-08,\n             2.7408e-08, 8.9857e-09, 1.6680e-08, 2.0927e-08, 3.0237e-08, 1.3745e-08,\n             2.0210e-08, 2.1814e-08, 1.6016e-08, 1.0902e-08, 7.9907e-09, 1.4708e-08,\n             1.4478e-08, 2.1259e-08, 1.5450e-08, 1.1793e-08, 1.4721e-08, 1.1209e-08,\n             1.3968e-08, 2.1584e-08, 2.1413e-08, 2.0072e-08, 1.8509e-08, 1.4083e-08,\n             2.3739e-08, 1.8752e-08, 3.6363e-08, 1.9255e-08, 8.5366e-09, 1.1234e-08,\n             1.4587e-08, 2.1327e-08, 1.8600e-08, 2.6625e-08, 1.7823e-08, 2.7303e-08,\n             3.0207e-08, 1.4889e-08, 9.7406e-09, 2.4871e-08, 1.2991e-08, 2.0058e-08,\n             1.6484e-08, 1.9987e-08, 1.6007e-08, 3.2829e-08, 7.0951e-09, 2.3240e-08,\n             2.7264e-08, 1.3236e-08, 1.9181e-08, 1.9508e-08, 2.3619e-08, 1.3928e-08,\n             1.1171e-08, 2.2034e-08, 1.8769e-08, 2.5608e-08, 1.1671e-08, 1.4259e-08,\n             1.1807e-08, 2.0615e-08, 2.0248e-08, 3.1136e-08, 2.5013e-08, 2.0968e-08,\n             1.4128e-08, 1.0956e-08, 2.7322e-08, 2.5286e-08, 1.8495e-08, 2.5066e-08,\n             2.1270e-08, 1.7195e-08, 2.6230e-08, 2.5684e-08, 1.4108e-08, 2.8430e-08,\n             1.8766e-08, 1.4948e-08, 3.2096e-08, 9.9897e-09, 1.5825e-08, 2.0637e-08,\n             1.2234e-08, 2.8181e-08, 2.2392e-08, 1.4481e-08, 1.7277e-08, 2.9454e-08,\n             1.8671e-08, 1.9402e-08, 2.5023e-08, 1.5469e-08, 2.4645e-08, 1.3392e-08,\n             1.1150e-08, 2.0704e-08, 2.0193e-08, 2.0604e-08, 1.2108e-08, 1.9413e-08,\n             1.3934e-08, 2.0727e-08, 1.3138e-08, 3.2442e-08, 1.8450e-08, 1.8220e-08,\n             2.7730e-08, 2.9674e-08, 1.6429e-08, 1.5137e-08, 1.1970e-08, 2.7873e-08,\n             2.1521e-08, 1.7323e-08, 3.1595e-08, 2.0116e-08, 1.6648e-08, 2.4556e-08,\n             1.8661e-08, 2.3648e-08, 2.8651e-08, 3.6195e-08, 2.6689e-08, 1.1064e-08,\n             1.4489e-08, 1.1914e-08, 2.1717e-08, 1.8003e-08])},\n    72: {'exp_avg': tensor([ 4.7528e-05, -7.0593e-05,  2.9262e-04,  ..., -9.6495e-05,\n             -9.0890e-05, -7.3394e-05]),\n     'exp_avg_sq': tensor([4.2345e-08, 2.3671e-08, 6.3715e-08,  ..., 7.2040e-08, 4.3260e-08,\n             4.5968e-08])},\n    73: {'exp_avg': tensor([ 4.3686e-05, -9.9057e-06,  1.0285e-05,  ..., -1.9792e-05,\n              8.1325e-05, -6.4734e-05]),\n     'exp_avg_sq': tensor([1.3894e-08, 8.4823e-09, 6.2112e-10,  ..., 6.2533e-10, 1.3420e-08,\n             3.8820e-09])},\n    74: {'exp_avg': tensor([-2.0302e-04, -4.1374e-05, -7.3032e-05, -9.0171e-05, -1.3274e-04,\n              7.6171e-05,  2.0148e-04,  1.3660e-04, -1.9667e-04, -3.3970e-05,\n              8.1018e-05, -1.9134e-04, -2.8964e-04,  7.4807e-05, -9.2812e-05,\n              3.0616e-05, -1.4863e-04,  7.6930e-05, -1.6267e-04, -4.7429e-05,\n              1.9406e-04,  1.3905e-04,  2.6092e-05, -2.5298e-04,  1.4088e-04,\n              4.8396e-05,  2.4031e-04, -3.3780e-05, -1.7488e-04, -1.4692e-04,\n              1.4376e-04, -5.5840e-05,  1.0371e-04,  7.6342e-05,  3.2480e-04,\n             -1.0021e-04, -1.4795e-04,  6.6354e-05, -8.0077e-05, -1.6739e-04,\n             -7.5188e-05, -6.9065e-06, -2.0960e-04, -3.7959e-05,  2.0056e-04,\n             -9.5585e-05,  2.1219e-04,  1.9959e-04,  1.3319e-04,  3.2986e-04,\n              2.9762e-05, -3.6945e-05, -6.3519e-05,  2.8160e-05,  4.6831e-05,\n              3.8790e-05, -1.4668e-04,  2.1807e-05, -5.3511e-05, -4.3030e-05,\n             -9.5412e-05, -9.5964e-05, -8.3894e-05, -8.6095e-05,  8.5334e-05,\n              1.7617e-06,  4.1501e-04,  1.2986e-04, -2.1488e-04,  1.2676e-04,\n             -1.8703e-04, -1.7527e-04, -9.5450e-05, -3.0210e-05,  8.1026e-05,\n             -7.9610e-05,  1.7787e-04,  1.3584e-04,  1.1639e-04,  1.2228e-04,\n              2.4136e-04,  1.6192e-04, -2.5890e-04,  4.7706e-05,  1.4767e-04,\n             -5.1800e-05, -1.2258e-04,  1.6958e-06,  7.7191e-06,  7.2356e-05,\n              3.1075e-04, -2.8371e-04,  2.1316e-05,  1.1548e-04,  3.9078e-06,\n             -2.3102e-04, -1.9568e-04, -6.9829e-06,  5.4591e-04, -4.4383e-04,\n             -4.3740e-06,  2.9845e-04, -5.9889e-05,  6.8866e-05, -1.9298e-04,\n              2.0356e-04, -2.3867e-06,  2.4155e-06,  1.9983e-04,  1.7615e-04,\n              2.8584e-04, -2.4525e-06, -1.8982e-04, -2.5214e-05, -1.4230e-04,\n              6.0913e-05, -2.3654e-04,  2.5864e-04,  2.3450e-04,  9.1924e-06,\n             -1.8479e-04,  1.2754e-04,  2.0694e-04,  2.1694e-04, -3.4793e-04,\n             -2.2980e-05, -8.2498e-05,  3.9026e-04, -2.4272e-04, -1.2178e-04,\n             -3.0191e-04, -1.5786e-04,  2.1045e-04, -1.0895e-04, -7.8292e-05,\n              1.6480e-04, -2.4165e-04, -3.9960e-05, -6.6456e-05, -1.3017e-04,\n              7.5836e-05, -1.5148e-04, -1.2935e-04,  2.3139e-04, -1.7649e-06,\n              1.7956e-04,  9.3616e-05,  6.7766e-05, -5.9923e-05,  1.5546e-04,\n             -7.4621e-05,  2.3785e-04,  1.5097e-04, -1.6318e-04, -2.9530e-05,\n             -4.8174e-05, -3.4358e-05, -8.9041e-05, -1.5073e-04, -1.3732e-04,\n              3.9122e-05, -9.3528e-05, -1.7730e-04, -2.6819e-04, -9.6997e-05,\n             -7.8639e-05, -7.7137e-05, -2.5846e-04, -1.1863e-04,  1.8732e-04,\n              1.3287e-04, -6.6829e-07,  1.8159e-05, -1.1836e-04,  1.0572e-04,\n              1.6047e-05,  1.8035e-04,  2.3926e-04, -3.3677e-04, -1.9318e-04,\n              1.8431e-04, -8.3009e-05,  1.5531e-04, -2.6305e-04,  5.5813e-05,\n             -1.7687e-04,  3.4784e-05, -7.9732e-05, -4.9982e-04, -1.2298e-04,\n              1.8172e-04,  1.5621e-04,  9.1382e-05,  6.2909e-05, -2.9587e-04,\n              3.2532e-05,  3.9630e-05, -3.1136e-05, -2.1877e-04, -5.5473e-05,\n              2.3160e-04, -1.8978e-04, -1.5169e-04, -1.3609e-04, -8.2070e-05,\n             -2.1714e-04,  1.5559e-04,  1.8780e-04,  9.7924e-05,  9.8161e-05,\n             -6.2952e-05,  8.4779e-05, -1.1403e-04, -1.0266e-04,  5.8699e-05,\n              6.7723e-05, -1.2762e-04,  3.6152e-06,  3.5953e-05,  3.6414e-04,\n              8.4304e-06,  1.4916e-04,  3.8511e-05,  5.6741e-05, -2.1839e-04,\n              2.5038e-04,  4.0775e-04,  9.7701e-05, -2.8716e-04,  3.1886e-06,\n             -7.1634e-05, -2.9593e-06, -2.0673e-05,  4.7874e-04, -1.0280e-04,\n              5.8817e-05, -2.2830e-04,  4.2126e-04, -4.8186e-05,  7.5684e-05,\n             -2.5678e-04, -2.5058e-04,  1.1838e-04,  1.9567e-04, -2.2688e-04,\n              1.0373e-04,  2.8361e-04, -1.8974e-04,  1.8361e-04,  9.3895e-05,\n             -1.9094e-04,  2.6058e-04,  2.1614e-04, -1.4624e-04,  1.7598e-04,\n              1.3997e-04]),\n     'exp_avg_sq': tensor([8.5311e-08, 1.5593e-07, 1.0315e-07, 9.7289e-08, 2.9576e-07, 5.7785e-08,\n             1.4334e-07, 9.6009e-08, 1.4828e-07, 6.1304e-08, 7.7100e-08, 4.0609e-08,\n             6.4901e-08, 1.2441e-07, 9.7625e-08, 9.5374e-08, 6.9894e-08, 5.1709e-08,\n             3.4575e-08, 1.0737e-07, 5.3736e-08, 7.5824e-08, 2.8331e-08, 9.5796e-08,\n             5.2125e-08, 4.6236e-08, 1.2975e-07, 1.0350e-07, 9.3148e-08, 8.3993e-08,\n             5.8772e-08, 7.6453e-08, 8.4781e-08, 6.9957e-08, 7.7777e-08, 2.0014e-07,\n             1.2532e-07, 9.4510e-08, 6.8131e-08, 5.7356e-08, 6.2894e-08, 4.7706e-08,\n             1.1971e-07, 6.0980e-08, 7.9229e-08, 9.2157e-08, 8.3576e-08, 9.8347e-08,\n             6.2064e-08, 2.2098e-07, 6.6346e-08, 6.8600e-08, 9.3570e-08, 4.9164e-08,\n             8.4631e-08, 3.1342e-08, 3.5890e-08, 7.6965e-08, 4.7231e-08, 9.7022e-08,\n             4.1467e-08, 4.4631e-08, 1.4671e-07, 1.0456e-07, 9.6099e-08, 7.5868e-08,\n             6.2837e-08, 1.0366e-07, 7.5440e-08, 1.1280e-07, 9.0107e-08, 3.3883e-08,\n             6.6327e-08, 9.2878e-08, 5.5886e-08, 8.6696e-08, 6.0347e-08, 6.6447e-08,\n             9.1074e-08, 7.0072e-08, 5.3728e-08, 9.5961e-08, 7.1607e-08, 7.4574e-08,\n             6.3387e-08, 6.4434e-08, 4.2258e-08, 1.1344e-07, 2.3578e-07, 1.3383e-07,\n             1.6138e-07, 7.1459e-08, 4.3464e-08, 6.5662e-08, 4.7451e-08, 1.0612e-07,\n             6.9304e-08, 5.6028e-08, 1.1343e-07, 1.6143e-07, 8.0317e-08, 6.9416e-08,\n             6.1577e-08, 4.8775e-08, 6.8934e-08, 8.0403e-08, 1.0522e-07, 9.3950e-08,\n             7.8790e-08, 6.2946e-08, 9.9774e-08, 9.9716e-08, 5.8404e-08, 8.7193e-08,\n             4.8095e-08, 7.2800e-08, 8.4315e-08, 1.4288e-07, 5.2334e-08, 6.2737e-08,\n             6.4605e-08, 9.5641e-08, 1.0927e-07, 4.1410e-08, 6.7540e-08, 5.8744e-08,\n             9.1319e-08, 1.1902e-07, 6.3889e-08, 6.7523e-08, 1.2770e-07, 7.1923e-08,\n             7.9802e-08, 9.5497e-08, 6.3492e-08, 1.1984e-07, 7.3034e-08, 6.6947e-08,\n             1.0366e-08, 9.7918e-08, 4.9458e-08, 5.9085e-08, 6.8891e-08, 1.2414e-07,\n             5.8200e-08, 8.5140e-08, 7.5156e-08, 1.0937e-07, 5.0124e-08, 7.9753e-08,\n             7.4031e-08, 7.2515e-08, 1.0562e-07, 1.0204e-07, 6.9639e-08, 7.0582e-08,\n             6.4316e-08, 5.6841e-08, 9.5395e-08, 8.9583e-08, 2.8450e-08, 6.4675e-08,\n             7.6310e-08, 7.2877e-08, 5.0936e-08, 7.4825e-08, 1.1807e-07, 6.0929e-08,\n             1.2117e-07, 9.0824e-08, 7.2169e-08, 4.6184e-08, 8.0116e-08, 7.6471e-08,\n             1.3561e-07, 6.9280e-08, 6.6011e-08, 5.3251e-08, 9.8122e-08, 7.8709e-08,\n             1.1864e-07, 4.9774e-08, 5.3990e-08, 7.7791e-08, 3.4192e-08, 7.6722e-08,\n             6.7637e-08, 5.3659e-08, 9.7159e-08, 6.6255e-08, 1.1798e-07, 6.1039e-08,\n             4.1001e-08, 4.2845e-08, 1.0708e-07, 5.0841e-08, 9.0238e-08, 9.0330e-08,\n             5.9620e-08, 7.3628e-08, 7.2899e-08, 9.0121e-08, 1.6217e-07, 6.1686e-08,\n             8.7353e-08, 6.2331e-08, 1.6710e-07, 9.8588e-08, 9.5826e-08, 9.7401e-08,\n             7.5346e-08, 5.8472e-08, 8.9047e-08, 6.4303e-08, 8.4579e-08, 8.4106e-08,\n             1.3390e-07, 1.1115e-07, 5.5678e-08, 8.7569e-08, 6.1270e-08, 3.5468e-08,\n             4.6024e-08, 1.3927e-07, 7.9186e-08, 8.0316e-08, 1.0658e-07, 8.6874e-08,\n             1.0121e-07, 4.7776e-08, 1.7897e-07, 1.8139e-07, 6.6885e-08, 1.4269e-07,\n             5.5890e-08, 2.7807e-08, 1.3491e-07, 8.4184e-08, 3.4196e-08, 7.4772e-08,\n             8.0434e-08, 1.1211e-07, 1.0525e-07, 6.4728e-08, 5.8468e-08, 8.3564e-08,\n             7.7659e-08, 7.2272e-08, 8.0754e-08, 9.2191e-08, 1.0952e-07, 8.4890e-08,\n             6.8348e-08, 3.8215e-08, 6.5479e-08, 4.6212e-08])},\n    75: {'exp_avg': tensor([-1.1142e-04,  5.1223e-05, -9.8150e-05,  1.8127e-05, -7.9841e-05,\n              2.3487e-05,  1.0577e-04,  9.3302e-05, -8.7744e-05, -1.9112e-05,\n              4.9191e-05, -1.1946e-04, -1.2729e-04,  2.5060e-05, -1.2215e-04,\n              2.1449e-05, -1.8145e-04,  4.7969e-05, -6.0536e-05, -7.9900e-05,\n              8.2630e-05,  5.0048e-05,  7.3462e-05, -2.0695e-04,  6.0496e-05,\n              4.0182e-05,  7.9047e-05,  2.7468e-05, -1.0995e-04, -2.7447e-05,\n              2.9796e-06, -6.5721e-06,  1.6525e-04,  7.8863e-05,  2.4932e-04,\n              1.1760e-04, -1.1228e-04,  1.0850e-04,  8.0681e-05, -1.2446e-04,\n              2.5145e-06,  1.2173e-05, -1.3196e-04, -1.0608e-04,  1.7855e-04,\n              7.1050e-08,  6.2808e-05,  5.9909e-05,  4.8568e-05,  1.6745e-04,\n             -1.1123e-06, -7.6616e-05,  5.6149e-05, -5.2809e-06,  5.8290e-05,\n              2.3993e-06, -9.6446e-05,  1.2009e-05,  5.1349e-05,  1.0724e-05,\n             -1.4704e-04, -1.8254e-05, -2.6212e-05,  1.6290e-04,  3.4860e-05,\n              2.6452e-05,  2.8688e-04,  1.8105e-04, -1.6669e-04,  8.1886e-05,\n             -1.1182e-04, -2.1759e-04, -2.9755e-04, -6.1598e-05,  5.5090e-05,\n             -7.3076e-06,  1.9024e-04,  1.2533e-04,  4.4268e-05,  1.5831e-04,\n              2.0458e-04,  3.5475e-07, -1.7321e-04,  7.4986e-05,  8.3978e-05,\n              3.9636e-05, -5.7191e-05, -4.5152e-05, -2.3176e-05,  9.4063e-05,\n             -1.1292e-05, -1.6730e-04,  5.6771e-06,  9.2278e-05, -9.1738e-06,\n             -5.6165e-05, -1.6679e-04,  1.5141e-05,  3.1990e-04, -3.1819e-04,\n              1.8725e-05,  1.7018e-04, -6.6850e-05,  1.1254e-05, -1.2741e-04,\n              1.8076e-04,  1.1604e-05, -1.1574e-05,  7.6648e-05,  1.0190e-04,\n              2.3100e-04, -7.0980e-05, -8.5191e-05,  7.4476e-07, -1.1512e-04,\n              2.2103e-07, -1.7024e-04,  2.0974e-04,  2.5032e-04,  8.9486e-06,\n             -9.4550e-05,  3.0514e-05,  3.2599e-05,  1.4084e-04,  6.8311e-06,\n              1.3743e-06,  5.5953e-05,  1.8042e-04, -2.1374e-04, -1.0978e-04,\n             -2.1741e-04, -3.1990e-05,  1.9535e-04,  1.0829e-05, -1.1459e-04,\n             -1.5653e-05, -1.6203e-04,  1.3650e-05, -6.3142e-05, -1.6675e-04,\n              9.8200e-06, -8.2865e-05, -9.1879e-05,  2.8303e-04, -2.2192e-05,\n              6.8311e-05,  5.3628e-05,  1.4873e-05, -4.5086e-05,  9.5766e-05,\n             -2.7976e-05,  7.7372e-05, -7.8130e-05, -1.3609e-04,  4.1104e-05,\n              6.3632e-05,  6.8902e-05,  3.1717e-05, -1.1727e-04, -4.1133e-05,\n              3.7561e-05, -4.7860e-05, -7.2110e-05, -1.3866e-04, -4.3899e-05,\n             -5.4727e-05,  9.8657e-06, -1.3914e-04, -1.7755e-05,  1.5285e-04,\n              7.4639e-06, -4.1047e-06,  4.1780e-05, -1.2536e-04,  4.1121e-05,\n             -3.3383e-05,  1.1877e-04,  7.0597e-05, -2.0484e-04, -2.2158e-04,\n              2.0836e-04, -9.9464e-05,  1.7553e-04, -1.5527e-04,  1.6041e-04,\n             -4.5946e-05, -3.0968e-06, -7.4433e-05, -3.2142e-04, -1.0692e-04,\n              2.4236e-04,  1.0189e-04,  7.5838e-05,  3.7226e-05, -1.7412e-04,\n              2.9869e-05,  4.2018e-05, -2.1348e-05, -1.7832e-04, -8.3319e-05,\n              1.4016e-04, -1.2037e-04, -1.0857e-04, -1.7059e-04, -8.1018e-05,\n             -6.6697e-05,  9.8274e-05,  1.3772e-04,  1.1646e-05,  1.2982e-05,\n              7.4576e-06, -3.3033e-05, -4.1316e-05, -4.3651e-05,  2.2928e-04,\n              4.8392e-05, -3.2622e-05,  3.9220e-06,  4.5935e-05,  1.3072e-04,\n              1.3289e-05,  1.0832e-04,  4.7323e-05, -2.3064e-05, -1.1142e-04,\n              1.9621e-04,  1.9526e-04,  4.8335e-05, -2.1780e-04, -3.9213e-05,\n              1.0445e-05, -1.6673e-05, -9.4379e-05,  2.3468e-04, -5.2301e-05,\n             -9.3905e-06, -7.4096e-05,  1.8766e-04, -1.0343e-05,  2.1230e-05,\n             -1.5948e-04, -1.1727e-04, -1.3689e-05,  1.5988e-04, -7.1639e-05,\n              1.4168e-04,  1.4455e-04, -1.0422e-04,  9.7337e-05,  1.1012e-04,\n             -1.0990e-04,  1.3431e-04,  1.3212e-04, -1.0363e-04,  1.0474e-04,\n              1.4590e-04]),\n     'exp_avg_sq': tensor([2.6758e-08, 6.7001e-08, 4.7693e-08, 3.3478e-08, 4.2474e-08, 1.0698e-08,\n             2.5368e-08, 3.0366e-08, 4.3217e-08, 1.6723e-08, 3.3633e-08, 1.8968e-08,\n             3.2783e-08, 3.3513e-08, 4.6986e-08, 1.9840e-08, 3.8156e-08, 3.3857e-08,\n             7.7578e-09, 4.2481e-08, 1.2277e-08, 4.0854e-08, 2.5027e-08, 3.3043e-08,\n             1.4702e-08, 8.4575e-09, 7.3484e-08, 2.2175e-08, 5.3086e-08, 3.2638e-08,\n             1.5148e-08, 1.4682e-08, 3.4808e-08, 4.4438e-08, 4.3134e-08, 5.4151e-08,\n             5.9844e-08, 6.6315e-08, 2.6752e-08, 3.8304e-08, 1.7965e-08, 2.0762e-08,\n             3.0727e-08, 3.4128e-08, 2.5240e-08, 2.9695e-08, 2.5089e-08, 5.1310e-08,\n             2.4118e-08, 1.0278e-07, 2.7805e-08, 3.4855e-08, 4.7203e-08, 1.2469e-08,\n             3.2163e-08, 2.4654e-08, 3.0715e-08, 3.2431e-08, 3.3642e-08, 3.6960e-08,\n             1.9021e-08, 4.1138e-08, 2.3362e-08, 5.7688e-08, 2.7921e-08, 3.9404e-08,\n             3.0911e-08, 6.4186e-08, 4.6134e-08, 2.8614e-08, 3.3893e-08, 4.0068e-08,\n             4.9422e-08, 3.2469e-08, 2.8507e-08, 1.4882e-08, 3.6193e-08, 1.8178e-08,\n             3.3020e-08, 4.6794e-08, 3.4794e-08, 3.8170e-08, 2.5336e-08, 3.4055e-08,\n             1.2038e-08, 2.6611e-08, 3.3439e-08, 1.2894e-07, 8.5805e-08, 3.9851e-08,\n             2.3667e-08, 1.9594e-08, 2.0321e-08, 4.8307e-08, 8.8975e-09, 1.1360e-08,\n             5.0792e-08, 1.5239e-08, 3.0591e-08, 5.2562e-08, 3.7007e-08, 8.3418e-08,\n             1.6653e-08, 2.3715e-08, 1.6673e-08, 2.9780e-08, 2.9281e-08, 2.6156e-08,\n             2.5384e-08, 1.1721e-08, 3.6152e-08, 5.1177e-08, 1.1480e-08, 3.6267e-08,\n             3.1894e-08, 2.5051e-08, 3.3220e-08, 5.6028e-08, 3.7186e-08, 2.1961e-08,\n             2.0299e-08, 3.2851e-08, 1.3179e-08, 2.9405e-08, 5.9150e-08, 3.4655e-08,\n             3.3193e-08, 2.7627e-08, 2.9172e-08, 3.5350e-08, 4.4572e-08, 1.9473e-08,\n             4.2265e-08, 2.5591e-08, 4.3312e-08, 5.7417e-08, 2.9090e-08, 3.4784e-08,\n             8.3809e-09, 4.6597e-08, 2.3072e-08, 2.0761e-08, 3.0995e-08, 5.4498e-08,\n             1.9043e-08, 1.4020e-08, 1.5634e-08, 2.6457e-08, 2.2302e-08, 2.9251e-08,\n             3.7009e-08, 4.0010e-08, 5.9292e-08, 4.6185e-08, 2.0767e-08, 2.4865e-08,\n             4.3085e-08, 1.9347e-08, 2.9025e-08, 2.0672e-08, 1.1239e-08, 2.2364e-08,\n             3.1684e-08, 1.8012e-08, 4.3153e-08, 1.5989e-08, 4.3232e-08, 1.6400e-08,\n             3.4665e-08, 4.0202e-08, 2.8554e-08, 1.3572e-08, 1.8212e-08, 3.6234e-08,\n             5.1359e-08, 2.4383e-08, 3.6674e-08, 3.0720e-08, 3.2463e-08, 4.0009e-08,\n             7.1113e-08, 2.6304e-08, 4.5908e-08, 2.5435e-08, 2.7356e-08, 1.9414e-08,\n             1.2964e-08, 3.5325e-08, 4.7756e-08, 3.0954e-08, 4.8446e-08, 1.0833e-08,\n             2.8823e-08, 3.3251e-08, 4.0478e-08, 1.9094e-08, 6.4557e-08, 2.6281e-08,\n             3.1141e-08, 1.7210e-08, 2.2685e-08, 2.2549e-08, 5.2346e-08, 3.0837e-08,\n             4.2183e-08, 2.1058e-08, 6.9295e-08, 2.1387e-08, 2.0213e-08, 4.6761e-08,\n             1.8947e-08, 3.1620e-08, 3.7523e-08, 1.4013e-08, 5.3914e-08, 2.7040e-08,\n             6.9409e-08, 9.7172e-08, 2.0363e-08, 1.6721e-08, 1.6642e-08, 2.4761e-08,\n             2.4512e-08, 6.2955e-08, 2.5775e-08, 4.2462e-08, 7.6924e-08, 4.1542e-08,\n             3.7981e-08, 1.5748e-08, 2.5583e-08, 7.4760e-08, 4.1834e-08, 4.8001e-08,\n             1.2665e-08, 1.5655e-08, 4.2473e-08, 2.1423e-08, 7.8178e-09, 2.9123e-08,\n             3.3366e-08, 3.0529e-08, 3.8807e-08, 2.4018e-08, 1.3107e-08, 3.8623e-08,\n             2.1367e-08, 1.6347e-08, 2.9541e-08, 2.6568e-08, 1.9840e-08, 3.2920e-08,\n             2.6361e-08, 2.4081e-08, 2.5543e-08, 6.9495e-08])},\n    76: {'exp_avg': tensor([-2.2219e-04,  1.0597e-04,  5.2935e-05, -8.8329e-05, -4.9679e-05,\n              2.1471e-04, -1.2945e-04,  1.3644e-04, -1.8213e-06,  1.6076e-04,\n             -6.2205e-05,  9.8307e-05, -1.1277e-04,  6.1992e-05,  1.3892e-04,\n              1.4321e-04, -6.7811e-05,  5.2910e-05, -2.0749e-04, -2.3338e-04,\n              6.1264e-05,  1.4210e-04, -2.0181e-05,  2.2308e-05, -1.2616e-04,\n              4.9189e-05, -3.1790e-04,  5.0015e-04,  5.6319e-05, -1.5125e-04,\n              1.4519e-04,  1.5586e-04, -7.9360e-05,  3.0802e-04,  4.8577e-05,\n             -1.0498e-04,  3.3369e-05, -1.2662e-04,  1.8761e-04, -4.0997e-05,\n             -1.3778e-04,  1.1322e-04, -2.6672e-04,  7.2940e-05,  3.0207e-04,\n              9.6750e-05, -1.6395e-05,  2.2809e-04,  7.5255e-05,  1.9726e-04,\n              1.5998e-05,  8.4118e-05, -1.6983e-04, -1.2061e-04, -3.4025e-05,\n              2.4925e-05, -1.2419e-04,  2.6264e-04,  1.2193e-04,  3.0178e-05,\n             -1.3779e-04, -1.4760e-05, -2.9403e-04, -2.5770e-04,  5.6174e-06,\n              8.4753e-05,  2.4123e-04,  1.8463e-04,  1.4998e-05, -1.6268e-04,\n             -1.3677e-04, -1.6242e-04, -2.7482e-04,  3.3044e-04,  3.0367e-06,\n              1.2402e-05, -3.8069e-06,  2.6745e-04,  1.7172e-05,  1.0002e-04,\n              2.9713e-04, -9.1084e-05, -4.7670e-05, -1.0276e-04, -3.8155e-04,\n              1.3404e-04,  1.3239e-05,  1.1231e-04, -7.3470e-06,  8.7796e-05,\n             -5.7875e-05,  3.3653e-05,  1.2323e-04, -4.2623e-05, -1.0508e-05,\n              2.5029e-04,  2.0845e-04,  8.8155e-05, -1.5838e-04, -8.3972e-05,\n              1.5779e-04, -2.2037e-04, -7.7974e-06,  2.7903e-04, -1.5275e-04,\n             -2.3103e-04, -1.0802e-04,  9.5461e-05,  1.5217e-04, -3.0099e-05,\n              1.8063e-04,  5.1831e-05,  3.4479e-05,  1.5208e-04,  2.7459e-05,\n             -1.4516e-04,  9.8589e-05, -6.5233e-05,  2.5631e-04, -2.4154e-04,\n             -8.5786e-05, -2.5315e-04, -5.1989e-04,  1.8525e-04,  1.1200e-04,\n              1.4219e-04,  7.9174e-05, -1.7939e-04, -6.1069e-05,  1.3324e-04,\n              1.4789e-05,  1.7926e-04,  5.6822e-05, -1.5455e-05, -3.9949e-04,\n             -1.4949e-04, -5.2760e-05,  2.2072e-04, -1.8432e-04, -2.1065e-04,\n             -1.0673e-04,  5.5081e-05,  7.4857e-05, -3.4998e-05, -1.7307e-04,\n              1.2522e-04,  2.0844e-04,  8.8221e-06,  1.7916e-04, -6.6701e-06,\n              1.1478e-04, -6.5791e-05,  3.7735e-05, -1.6919e-04, -2.7055e-04,\n              8.3095e-05,  2.5664e-05, -3.3593e-05,  1.0540e-04,  1.5703e-04,\n             -8.5083e-05,  4.1154e-04,  2.7859e-05, -1.2687e-04, -1.2099e-04,\n             -1.0285e-04, -2.0739e-04,  6.2447e-05,  2.5505e-04, -1.4270e-04,\n              1.6622e-04,  2.7071e-04, -5.8263e-05,  2.3820e-05,  4.7737e-05,\n             -2.8859e-04, -7.0283e-05, -1.0151e-04,  5.4325e-05, -1.8956e-04,\n              2.8517e-04,  1.0718e-04, -2.9641e-05,  7.9662e-05,  9.7555e-05,\n              1.2850e-04, -2.1585e-04,  1.1302e-04, -8.0710e-05, -1.4346e-04,\n              2.8440e-05,  1.6728e-04,  1.7854e-04,  1.8323e-04, -2.7670e-05,\n              1.1548e-04, -2.8980e-05,  1.3504e-04, -5.6896e-05, -2.0795e-04,\n             -1.4152e-04, -3.1266e-05, -1.1318e-04, -3.2116e-04,  2.7096e-04,\n             -4.8866e-04, -3.3711e-04, -2.6003e-04,  3.9629e-05, -1.5025e-04,\n             -2.4245e-04, -6.0785e-05,  1.6262e-04, -3.7888e-05, -6.5903e-05,\n              1.1233e-05,  7.3188e-05, -1.1277e-04, -2.8967e-04, -1.6809e-05,\n              1.0057e-04,  5.9524e-05, -5.8586e-05,  6.0544e-05, -3.0008e-05,\n              6.5779e-05,  1.3349e-04, -1.6308e-04, -2.6506e-04,  7.8348e-05,\n              2.0411e-04,  1.8185e-05, -1.3485e-04,  2.5800e-05, -1.7581e-04,\n             -1.0990e-04, -2.0996e-05,  2.2226e-04, -5.4182e-05,  2.4186e-04,\n              4.3023e-04,  5.3270e-05,  4.1398e-05,  1.7326e-04,  3.1415e-05,\n              6.5743e-05,  1.0617e-05,  8.7284e-05, -6.9823e-05, -3.3666e-05,\n              6.3455e-06, -3.4490e-05, -1.5573e-04,  1.1463e-04, -2.6135e-04,\n             -1.8572e-04]),\n     'exp_avg_sq': tensor([3.9432e-08, 3.2810e-08, 5.1290e-08, 1.3084e-07, 5.9856e-08, 1.0019e-07,\n             5.6726e-08, 7.1749e-08, 6.6926e-08, 4.9234e-08, 4.3383e-08, 2.4750e-08,\n             4.5361e-08, 6.7538e-08, 1.3954e-07, 5.6156e-08, 3.3123e-08, 3.7679e-08,\n             4.2829e-08, 7.7491e-08, 1.0171e-07, 7.7355e-08, 5.6788e-08, 3.3289e-08,\n             4.0901e-08, 6.4436e-08, 4.2245e-08, 7.4773e-08, 2.8529e-08, 9.9725e-08,\n             6.3863e-08, 8.3575e-08, 4.4810e-08, 1.1059e-07, 3.7029e-08, 7.0995e-08,\n             6.5402e-08, 4.7162e-08, 7.1298e-08, 4.7912e-08, 5.9745e-08, 4.9705e-08,\n             7.8655e-08, 4.1085e-08, 7.8027e-08, 6.1051e-08, 8.8182e-08, 1.3644e-07,\n             4.5907e-08, 5.2693e-08, 7.6727e-08, 7.7291e-08, 2.5692e-07, 5.8743e-08,\n             3.9573e-08, 9.5470e-08, 4.0291e-08, 1.1772e-07, 7.6009e-08, 5.9153e-08,\n             6.8294e-08, 9.1394e-08, 8.0732e-08, 7.1239e-08, 5.1643e-08, 7.3356e-08,\n             4.3746e-08, 1.4266e-07, 5.7905e-08, 3.2298e-08, 5.0775e-08, 4.7287e-08,\n             7.0789e-08, 1.2413e-07, 6.9750e-08, 6.2673e-08, 4.2943e-08, 6.2763e-08,\n             4.2720e-08, 5.3675e-08, 5.7527e-08, 4.3640e-08, 4.0897e-08, 5.1963e-08,\n             1.1575e-07, 5.4119e-08, 7.2134e-08, 1.6778e-07, 3.7259e-08, 5.1726e-08,\n             4.6982e-08, 1.0581e-07, 4.0794e-08, 1.3403e-07, 4.1690e-08, 6.1931e-08,\n             3.6609e-08, 4.3553e-08, 6.1423e-08, 5.3308e-08, 5.2287e-08, 4.7171e-08,\n             3.8765e-08, 4.8907e-08, 3.1983e-08, 9.4062e-08, 6.4500e-08, 5.3088e-08,\n             4.6833e-08, 8.5014e-08, 4.0515e-08, 8.6989e-08, 8.1158e-08, 5.6470e-08,\n             4.0498e-08, 4.4959e-08, 1.1844e-07, 6.7783e-08, 3.8029e-08, 6.2056e-08,\n             6.5676e-08, 1.1922e-07, 1.4841e-07, 3.5727e-08, 8.2191e-08, 7.8789e-08,\n             3.8879e-08, 1.6025e-07, 7.4091e-08, 4.0072e-08, 3.9022e-08, 5.3768e-08,\n             7.0813e-08, 4.4399e-08, 1.0895e-07, 3.4968e-08, 4.1050e-08, 5.3376e-08,\n             4.5615e-08, 9.2772e-08, 4.5886e-08, 9.7725e-08, 5.5481e-08, 5.0492e-08,\n             3.3444e-08, 7.3816e-08, 1.4824e-07, 3.7258e-08, 6.1642e-08, 5.0662e-08,\n             9.9064e-08, 3.0926e-08, 4.1010e-08, 6.5825e-08, 6.5761e-08, 4.3951e-08,\n             1.2157e-07, 4.2024e-08, 6.1452e-08, 5.4881e-08, 9.1632e-08, 2.5590e-07,\n             5.0431e-08, 4.5993e-08, 5.3470e-08, 4.0884e-08, 8.3150e-08, 4.2901e-08,\n             4.1880e-08, 4.8644e-08, 4.8565e-08, 7.1322e-08, 1.5853e-07, 3.7226e-08,\n             7.1362e-08, 1.8609e-07, 4.3559e-08, 5.8027e-08, 1.0512e-07, 3.9373e-08,\n             5.4181e-08, 5.4430e-08, 4.4201e-08, 5.1354e-08, 6.0592e-08, 1.1858e-07,\n             5.5551e-08, 4.3573e-08, 8.6686e-08, 1.2248e-07, 4.1659e-08, 6.0980e-08,\n             7.0089e-08, 3.8270e-08, 3.8487e-08, 7.5176e-08, 1.0185e-07, 5.8671e-08,\n             3.8934e-08, 5.6129e-08, 6.3166e-08, 3.3388e-08, 2.3131e-07, 1.0153e-07,\n             9.8284e-08, 2.3336e-07, 5.5090e-08, 6.5770e-08, 5.5960e-08, 4.1286e-08,\n             6.4422e-08, 6.5938e-08, 4.6650e-08, 4.4184e-08, 4.4556e-08, 4.9162e-08,\n             5.9034e-08, 3.3050e-08, 3.1270e-08, 4.7299e-08, 4.1168e-08, 6.2492e-08,\n             3.2388e-08, 5.1619e-08, 4.8427e-08, 3.1770e-08, 4.9747e-08, 6.2953e-08,\n             1.0234e-07, 4.9122e-08, 9.2814e-08, 7.9185e-08, 9.2378e-08, 9.5011e-08,\n             4.8312e-08, 4.9437e-08, 6.5012e-08, 7.5959e-08, 6.3872e-08, 3.7304e-08,\n             1.1853e-07, 5.2450e-08, 7.2208e-08, 5.2710e-08, 1.0066e-07, 6.4726e-08,\n             6.1505e-08, 7.2129e-08, 5.7897e-08, 8.7138e-08, 4.2212e-08, 4.6860e-08,\n             6.4825e-08, 8.1999e-08, 5.5349e-08, 7.9194e-08])},\n    77: {'exp_avg': tensor([-1.5092e-04,  1.7065e-05,  5.5624e-06, -3.0444e-05, -1.8008e-04,\n              5.9918e-05, -7.1515e-05,  7.8193e-05,  9.7941e-05,  9.3179e-05,\n              8.9653e-05,  9.3267e-05, -1.7006e-05, -3.0914e-05,  1.3192e-05,\n              8.1764e-05, -2.0815e-05,  5.0551e-05, -8.8663e-05, -6.3150e-05,\n              1.9038e-04,  4.2077e-06, -1.7901e-05,  7.5829e-05, -9.0382e-05,\n              7.9047e-05, -1.3417e-04,  2.6000e-04,  2.7875e-05,  3.4001e-04,\n              1.3992e-04,  2.4940e-05, -1.0202e-04,  1.1697e-04, -2.2073e-05,\n             -1.1029e-04, -9.5105e-05,  1.6439e-07,  1.2414e-04,  4.7159e-06,\n             -6.5842e-05,  1.1269e-04, -1.4836e-04, -9.1924e-06,  4.6753e-05,\n              1.2123e-04,  1.3423e-05,  5.7605e-05,  1.3069e-04,  7.4770e-05,\n              3.4143e-05, -1.5503e-06, -1.6869e-04, -1.1393e-04, -8.9899e-05,\n              3.8869e-05, -1.0944e-04,  1.4930e-04,  2.2275e-04,  2.4152e-05,\n             -3.5586e-05, -2.9544e-05, -6.4639e-05, -1.7438e-04, -3.0665e-05,\n             -4.3353e-05,  2.2086e-04,  1.6025e-04,  5.2845e-05, -7.0452e-05,\n             -6.5610e-05, -8.7472e-05, -1.4719e-04,  2.2113e-04,  6.7393e-06,\n             -3.1371e-05, -5.2167e-05,  1.4128e-04, -4.7962e-06,  2.2126e-06,\n              9.6825e-05, -4.8561e-06, -5.4232e-06, -7.4838e-05, -1.6020e-04,\n              4.1844e-05, -4.0373e-06,  7.9763e-05,  3.4025e-05,  8.5851e-05,\n             -3.6174e-05, -3.0364e-06,  5.6846e-05, -1.4884e-05, -1.3822e-05,\n              1.1889e-04,  4.9641e-05,  3.0715e-05, -1.1182e-04, -3.9904e-05,\n              1.0177e-04, -1.5041e-04, -2.3579e-05,  1.0454e-04, -1.3693e-04,\n             -9.4526e-05, -7.0651e-05,  7.0960e-05,  1.4265e-04, -5.7982e-05,\n              9.5514e-05,  7.7008e-05,  1.0230e-04,  7.3023e-05,  3.9774e-05,\n             -7.1490e-05,  4.2252e-05, -1.7124e-04,  1.3051e-04, -6.2693e-05,\n              3.0144e-05, -1.5228e-04, -3.0649e-04,  7.8059e-05,  1.2775e-04,\n              8.7357e-05,  1.1816e-04, -7.5317e-05,  7.8583e-05,  1.1292e-04,\n             -1.2950e-05,  2.3969e-05,  4.9349e-05,  2.9882e-05, -1.9907e-04,\n             -1.0227e-04, -6.4422e-05,  9.3182e-05, -2.3288e-05, -1.8750e-04,\n              1.8688e-05, -5.9390e-05,  8.5196e-05, -3.2000e-06, -1.0526e-04,\n              3.5817e-06,  9.4597e-05,  2.1700e-05,  1.7815e-04, -3.4350e-05,\n              1.2555e-04, -5.4320e-05,  2.3708e-05, -4.7958e-05, -9.9854e-05,\n              1.1328e-04,  2.7795e-05, -2.8458e-06,  6.2174e-05,  4.9455e-05,\n             -8.5327e-05,  1.1885e-04,  1.7908e-05, -3.5532e-05,  3.3221e-04,\n             -1.5035e-05, -9.3287e-05,  1.3985e-05,  1.2952e-04, -7.7526e-05,\n              1.9009e-04,  2.1369e-05, -2.6332e-05,  1.2430e-05, -6.6676e-05,\n             -4.1149e-05,  1.4934e-05, -3.4627e-05,  4.9944e-05, -2.6419e-05,\n              1.7732e-04,  1.2069e-04,  3.6612e-05,  1.6375e-05,  9.8987e-05,\n              1.7553e-04, -1.3354e-04,  5.5621e-05, -2.9557e-05, -8.4481e-05,\n              3.6445e-05,  1.5615e-04,  1.0892e-04,  1.4207e-04, -4.8475e-05,\n              4.3209e-05,  9.9416e-05,  5.6253e-05, -8.2757e-05, -2.2909e-04,\n             -1.1701e-04, -8.8253e-05,  1.1196e-04, -1.6237e-04,  2.3697e-04,\n             -3.2780e-04, -1.6808e-04, -1.1756e-04,  8.1736e-05, -8.6854e-05,\n             -1.8985e-04, -8.6360e-06,  1.2827e-04,  2.4573e-05,  8.0973e-05,\n              3.4222e-05, -3.1091e-05, -9.1488e-05, -1.2724e-04,  1.2309e-05,\n              5.0248e-05,  7.0126e-06, -1.6736e-05,  2.2785e-05,  7.6350e-05,\n              5.6948e-05,  1.0301e-04, -7.4557e-05, -1.7363e-04,  6.9593e-05,\n              9.7415e-05,  6.6198e-05,  7.2727e-05,  5.4614e-05, -8.0196e-05,\n             -1.8708e-05,  5.6486e-05,  1.2300e-04, -4.4613e-07,  1.5720e-04,\n              2.6426e-04,  4.0019e-05,  5.1101e-06,  3.6023e-05,  9.7002e-05,\n              5.5016e-05,  2.8539e-06,  7.3399e-05, -4.3470e-05, -4.7926e-05,\n              4.6902e-05, -1.2978e-05, -7.6862e-05,  3.7290e-05, -1.0359e-04,\n             -1.0923e-04]),\n     'exp_avg_sq': tensor([1.4447e-08, 1.0658e-08, 2.3412e-08, 3.7954e-08, 4.5606e-08, 2.3667e-08,\n             3.5146e-08, 3.3235e-08, 1.7638e-08, 2.6200e-08, 2.5788e-08, 1.0215e-08,\n             1.7052e-08, 3.4175e-08, 4.2827e-08, 1.0955e-08, 1.8012e-08, 1.6151e-08,\n             1.5035e-08, 2.5500e-08, 3.1189e-08, 4.6635e-08, 2.3790e-08, 2.5325e-08,\n             1.4925e-08, 2.2229e-08, 7.9213e-09, 3.4219e-08, 1.1165e-08, 3.2619e-08,\n             2.1363e-08, 1.7283e-08, 1.2759e-08, 1.7353e-08, 2.2371e-08, 2.3568e-08,\n             3.0207e-08, 2.2315e-08, 2.3971e-08, 1.7294e-08, 1.8394e-08, 3.5821e-08,\n             3.9499e-08, 1.2599e-08, 2.0617e-08, 1.4773e-08, 1.0183e-08, 8.1920e-08,\n             2.5727e-08, 2.3563e-08, 2.8146e-08, 3.2039e-08, 6.5663e-08, 2.2442e-08,\n             2.0056e-08, 2.3700e-08, 3.2846e-08, 2.6994e-08, 2.7906e-08, 1.2372e-08,\n             2.7487e-08, 2.3615e-08, 2.3913e-08, 3.3095e-08, 1.8370e-08, 1.5201e-08,\n             2.1468e-08, 3.8574e-08, 1.7425e-08, 1.7811e-08, 2.4882e-08, 1.9990e-08,\n             2.1216e-08, 6.8615e-08, 3.9977e-08, 1.7975e-08, 2.0094e-08, 1.4687e-08,\n             1.6625e-08, 2.1081e-08, 2.3352e-08, 3.7820e-09, 1.6974e-08, 2.3981e-08,\n             2.4689e-08, 2.9548e-08, 3.8268e-08, 6.4503e-08, 1.5478e-08, 1.6110e-08,\n             2.4071e-08, 3.3631e-08, 1.5864e-08, 1.9317e-08, 1.9124e-08, 3.1005e-08,\n             4.0512e-09, 1.0133e-08, 1.5721e-08, 1.5533e-08, 2.0744e-08, 1.9295e-08,\n             2.5105e-08, 2.1767e-08, 1.8883e-08, 3.1881e-08, 2.5439e-08, 2.7815e-08,\n             2.1197e-08, 2.7580e-08, 1.1987e-08, 1.5738e-08, 3.4402e-08, 2.8262e-08,\n             1.8090e-08, 8.7214e-09, 3.5699e-08, 3.8348e-08, 1.3407e-08, 3.0294e-08,\n             1.1903e-08, 3.9249e-08, 3.7123e-08, 9.1416e-09, 2.9097e-08, 2.3345e-08,\n             1.4559e-08, 3.2427e-08, 3.0744e-08, 2.3821e-08, 3.0683e-08, 7.4508e-09,\n             2.3070e-08, 1.9867e-08, 2.1131e-08, 2.4241e-08, 1.8797e-08, 2.3653e-08,\n             1.4699e-08, 2.3944e-08, 1.5857e-08, 1.5128e-08, 2.1913e-08, 1.6391e-08,\n             2.1651e-08, 2.4808e-08, 3.2102e-08, 1.3881e-08, 5.4546e-08, 2.8762e-08,\n             1.9335e-08, 2.1255e-08, 1.2855e-08, 3.1659e-08, 1.9727e-08, 2.8974e-08,\n             1.5233e-08, 2.4241e-08, 1.9230e-08, 1.3618e-08, 2.3334e-08, 3.3867e-08,\n             2.3935e-08, 1.8601e-08, 5.9412e-08, 2.1191e-08, 4.4513e-08, 2.6383e-08,\n             1.9350e-08, 3.1391e-08, 2.4857e-08, 3.4641e-08, 2.6281e-08, 8.1812e-09,\n             2.6229e-08, 5.9502e-08, 1.5626e-08, 2.7223e-08, 3.8920e-08, 2.1476e-08,\n             2.7581e-08, 2.5581e-08, 1.9700e-08, 2.8246e-08, 2.7721e-08, 4.4581e-08,\n             2.2331e-08, 1.8996e-08, 1.5627e-08, 1.0296e-08, 2.5057e-08, 2.0465e-08,\n             2.5792e-08, 2.1806e-08, 3.0127e-08, 1.6173e-08, 4.2331e-08, 1.7284e-08,\n             3.2940e-08, 2.4340e-08, 2.8767e-08, 2.6319e-08, 3.3745e-08, 4.2677e-08,\n             4.6335e-08, 7.6960e-08, 1.3238e-08, 2.5317e-08, 1.7545e-08, 1.5250e-08,\n             3.3634e-08, 1.0406e-08, 1.8814e-08, 2.0196e-08, 2.0087e-08, 9.0942e-09,\n             1.5252e-08, 6.8907e-09, 1.1857e-08, 1.7277e-08, 7.9953e-09, 2.9776e-08,\n             1.4542e-08, 2.0991e-08, 3.5102e-08, 1.5458e-08, 2.4098e-08, 2.0239e-08,\n             3.4474e-08, 2.7110e-08, 2.5130e-08, 2.4444e-08, 3.0471e-08, 3.0221e-08,\n             1.3848e-08, 2.1559e-08, 3.1486e-08, 2.6135e-08, 2.9036e-08, 1.6802e-08,\n             3.6599e-08, 2.6292e-08, 4.2757e-08, 2.1780e-08, 3.0443e-08, 2.8299e-08,\n             2.1969e-08, 4.8172e-08, 1.9288e-08, 2.5499e-08, 1.7936e-08, 2.6682e-08,\n             2.3506e-08, 2.6225e-08, 2.1301e-08, 2.0322e-08])},\n    78: {'exp_avg': tensor([-1.3975e-04, -5.9954e-06,  1.3591e-04,  ..., -1.3195e-04,\n              9.1965e-06,  4.8832e-05]),\n     'exp_avg_sq': tensor([2.6317e-08, 1.5455e-08, 4.0720e-08,  ..., 5.4354e-08, 2.7154e-08,\n             3.0020e-08])},\n    79: {'exp_avg': tensor([ 5.0555e-05, -2.6863e-05,  4.6794e-06,  ..., -8.4238e-06,\n              1.0041e-07,  7.1595e-06]),\n     'exp_avg_sq': tensor([1.1286e-08, 7.9821e-09, 4.5500e-10,  ..., 4.6007e-10, 1.0687e-08,\n             7.0194e-10])},\n    80: {'exp_avg': tensor([-4.3307e-04, -2.0928e-04,  1.3640e-04,  4.5075e-04, -1.0029e-04,\n             -1.7931e-04, -2.4199e-04,  1.0012e-04,  1.9981e-04,  9.7142e-04,\n              1.5677e-04,  2.0891e-04,  2.5646e-04, -3.3392e-04,  1.4838e-04,\n             -2.7216e-04,  3.8638e-04, -2.5764e-04, -1.7337e-04, -1.6737e-04,\n              7.9285e-05, -1.8228e-04, -3.4538e-04,  1.3224e-04, -9.7178e-06,\n             -4.4499e-06, -1.7937e-04,  2.2972e-04,  1.2058e-04, -6.4406e-05,\n              5.2801e-06, -2.1471e-04,  3.8589e-05, -1.0526e-04,  6.5599e-05,\n             -1.2761e-05, -4.7662e-05,  4.6126e-05, -2.6707e-04, -3.5983e-04,\n              7.0586e-05, -1.2129e-04,  1.2738e-04,  5.1613e-04, -3.2214e-04,\n             -1.6322e-05,  3.0071e-04, -4.2428e-05, -6.8374e-04,  1.5694e-04,\n             -2.8143e-04, -2.7481e-04, -1.1805e-04, -4.5829e-05,  2.9827e-05,\n             -3.0629e-04, -2.8623e-04,  5.4131e-06, -1.2577e-04,  4.5224e-04,\n              2.1000e-04,  1.2225e-05,  1.8971e-04, -3.2065e-04, -1.8945e-04,\n              2.1147e-04, -2.0289e-04,  2.0140e-04,  3.6797e-05,  5.9590e-05,\n              1.0936e-04,  2.6950e-05, -2.7031e-04,  1.9274e-05,  1.8436e-04,\n             -6.8404e-05,  3.5164e-05, -4.2958e-04, -2.9449e-04, -4.1430e-04,\n             -6.7352e-05,  1.9693e-04, -2.1077e-04, -2.0872e-04, -3.5047e-05,\n              4.3968e-05, -1.5857e-04, -2.4482e-04,  3.5787e-04, -3.1683e-05,\n             -1.1038e-04, -3.1276e-04, -8.6067e-05,  1.1293e-04,  5.2060e-05,\n             -1.0456e-04, -1.4270e-04, -3.5301e-04,  2.3153e-04,  5.8547e-05,\n             -2.6008e-04,  2.5402e-04, -2.3274e-04, -4.1900e-05, -3.4979e-04,\n              1.1497e-05, -3.6691e-04, -3.4361e-05, -1.4173e-04, -9.9494e-05,\n              4.3031e-04, -2.0928e-04,  4.1948e-04,  6.0207e-05,  2.9595e-04,\n              1.4094e-04, -9.5657e-05,  1.0240e-04,  1.9075e-04, -2.1728e-05,\n             -2.3092e-04, -1.6025e-06, -7.2717e-05,  3.7517e-04,  1.1847e-04,\n             -1.9585e-05,  1.1187e-04, -5.5921e-05,  4.8162e-05,  5.8281e-07,\n             -2.5407e-04, -1.2152e-04, -6.8034e-06,  5.6607e-05, -6.9239e-06,\n             -1.7306e-04,  1.5501e-04, -3.6640e-04, -1.1753e-04,  2.3144e-04,\n             -2.5123e-04, -2.4035e-04, -1.0183e-04, -1.4033e-05,  4.9206e-05,\n             -5.0014e-05, -1.2932e-04,  5.6297e-05,  2.0183e-04, -1.7667e-04,\n             -6.5514e-06,  1.3675e-05, -3.9205e-05,  5.6714e-05,  7.5834e-05,\n              1.5010e-04,  9.9033e-05,  7.0048e-05, -1.8291e-04,  3.0514e-04,\n             -2.9923e-05, -2.5226e-04,  4.2167e-05, -3.0252e-04, -2.0569e-04,\n              1.2428e-04, -2.5665e-04,  1.3853e-04,  2.5757e-04,  2.7477e-04,\n              5.6641e-06,  1.1409e-04, -6.2271e-05,  9.6356e-05,  1.9883e-04,\n              1.7835e-04,  1.1908e-04, -3.5082e-05, -3.0797e-05, -4.1835e-05,\n              8.6968e-05,  1.5769e-04,  8.9343e-05,  2.3600e-04,  1.5294e-03,\n              6.0725e-05, -4.5541e-04, -1.5616e-04, -1.9324e-04,  6.1230e-05,\n             -2.6723e-04,  2.1773e-04,  2.0922e-04,  8.1826e-05, -3.3445e-04,\n              2.1650e-04, -2.1938e-04, -8.2032e-05, -2.3118e-04, -2.2383e-05,\n             -1.2240e-04, -8.1168e-05, -4.0327e-04,  4.2899e-04,  6.2168e-05,\n              4.4361e-05,  2.0238e-04, -2.5526e-04,  9.7995e-05, -1.8962e-04,\n              4.4789e-04, -7.2635e-05,  1.1671e-05,  1.3195e-05,  1.8832e-04,\n             -2.9884e-04,  2.7001e-04,  1.0653e-05,  1.3487e-04, -4.5574e-04,\n             -9.2622e-05,  3.0226e-04, -1.5996e-04,  2.7106e-04, -3.3859e-04,\n              2.4229e-04, -2.7464e-05, -5.6699e-05, -2.0313e-04,  1.3286e-04,\n              1.8369e-04,  1.7903e-04,  4.0451e-04, -3.6665e-05, -8.9161e-05,\n              6.7531e-05,  2.0909e-04,  4.0118e-04,  2.2408e-04,  1.8201e-04,\n             -1.1656e-04,  3.1559e-04, -9.3272e-05,  1.0794e-05, -1.4843e-04,\n             -1.1659e-04,  1.5614e-04, -1.6037e-04,  3.0106e-04,  7.1594e-05,\n              7.1777e-05,  6.0394e-06, -1.2998e-04,  1.6600e-04, -2.4127e-04,\n             -3.9355e-04]),\n     'exp_avg_sq': tensor([1.3157e-07, 1.1425e-07, 9.2290e-08, 1.2930e-07, 1.3187e-07, 5.6301e-08,\n             1.3218e-07, 8.5044e-08, 1.0456e-07, 3.3979e-07, 1.1434e-07, 1.0062e-07,\n             1.0817e-07, 1.0978e-07, 6.3450e-08, 1.2767e-07, 2.8945e-07, 1.6841e-07,\n             1.3687e-07, 7.9458e-08, 1.0261e-07, 1.4199e-07, 1.4278e-07, 1.0265e-07,\n             1.4426e-07, 1.2575e-07, 1.1123e-07, 1.2707e-07, 1.1511e-07, 1.5543e-07,\n             1.1088e-07, 1.4043e-07, 8.9568e-08, 1.9844e-07, 1.2868e-07, 1.4274e-07,\n             1.5901e-07, 9.5053e-08, 7.3783e-08, 1.4935e-07, 1.0120e-07, 3.0763e-07,\n             1.2304e-07, 1.3953e-07, 1.0839e-07, 8.1373e-08, 9.2450e-08, 1.5470e-07,\n             1.6554e-07, 1.1550e-07, 1.3345e-07, 8.6333e-08, 1.2436e-07, 1.2403e-07,\n             1.1377e-07, 1.4388e-07, 2.3707e-07, 7.5751e-08, 5.5952e-08, 1.3231e-07,\n             1.5752e-07, 1.3088e-07, 1.2207e-07, 1.2709e-07, 1.0796e-07, 1.8121e-07,\n             1.7695e-07, 2.0015e-07, 1.4720e-07, 1.2329e-07, 8.5644e-08, 1.5298e-07,\n             1.4389e-07, 7.2573e-08, 9.8577e-08, 1.0339e-07, 8.3859e-08, 2.0486e-07,\n             1.2968e-07, 8.6625e-08, 1.3117e-07, 9.1363e-08, 2.3704e-07, 1.9319e-07,\n             9.4540e-08, 1.3207e-07, 1.1454e-07, 1.7504e-07, 1.2220e-07, 1.2489e-07,\n             1.0827e-07, 1.7926e-07, 1.1473e-07, 1.5641e-07, 7.5187e-08, 2.5201e-07,\n             1.3563e-07, 1.3764e-07, 1.4411e-07, 9.0730e-08, 1.0116e-07, 1.0440e-07,\n             2.6242e-07, 7.1842e-08, 1.1066e-07, 1.1668e-07, 1.0866e-07, 9.5046e-08,\n             1.2103e-07, 1.1258e-07, 2.1754e-07, 9.9518e-08, 9.7060e-08, 7.0519e-08,\n             1.1883e-07, 1.0965e-07, 1.0174e-07, 9.0000e-08, 8.1085e-08, 1.7933e-07,\n             1.1989e-07, 5.6640e-08, 9.7934e-08, 1.0484e-07, 7.2270e-08, 1.3447e-07,\n             1.0710e-07, 1.2671e-07, 1.1785e-07, 1.3001e-07, 1.6446e-07, 1.2056e-07,\n             1.7388e-07, 1.1893e-07, 8.6406e-08, 1.2483e-07, 1.4232e-07, 1.8471e-07,\n             1.4616e-07, 1.1575e-07, 1.2831e-07, 9.9682e-08, 1.1866e-07, 1.0398e-07,\n             1.2377e-07, 1.2843e-07, 9.8898e-08, 1.2075e-07, 1.6063e-07, 1.0843e-07,\n             1.2830e-07, 8.2853e-08, 1.0886e-07, 1.2948e-07, 9.3419e-08, 9.2162e-08,\n             1.4001e-07, 6.2247e-08, 1.2013e-07, 3.2303e-07, 1.0542e-07, 1.1570e-07,\n             9.5432e-08, 1.1135e-07, 2.0125e-07, 1.3991e-07, 4.6556e-07, 6.7439e-08,\n             9.3186e-08, 1.3308e-07, 7.1781e-08, 1.2582e-07, 1.4583e-07, 1.3255e-07,\n             1.3514e-07, 8.4702e-08, 4.5391e-08, 1.2384e-07, 1.2572e-07, 5.2788e-08,\n             1.3253e-07, 1.2832e-07, 1.2285e-07, 9.0148e-08, 2.7696e-06, 1.0369e-07,\n             1.4043e-07, 1.3075e-07, 1.0793e-07, 1.9401e-07, 1.1722e-07, 1.8598e-07,\n             9.5514e-08, 7.3437e-08, 1.5613e-07, 9.4341e-08, 1.5809e-07, 4.7979e-08,\n             1.0574e-07, 2.2207e-07, 1.2008e-07, 1.0559e-07, 2.1219e-07, 1.2041e-07,\n             1.1755e-07, 1.0129e-07, 1.4502e-07, 1.2100e-07, 1.6066e-07, 1.0993e-07,\n             1.2943e-07, 1.0948e-07, 9.1201e-08, 1.1799e-07, 1.4454e-07, 9.9694e-08,\n             1.4059e-07, 1.1036e-07, 9.0377e-08, 2.0395e-07, 3.4485e-07, 1.6714e-07,\n             8.7433e-08, 6.0942e-08, 1.5492e-07, 8.8877e-08, 9.2117e-08, 1.3986e-07,\n             1.6097e-07, 1.0226e-07, 1.5706e-07, 5.8200e-08, 2.4924e-07, 1.3874e-07,\n             6.7318e-08, 9.5046e-08, 1.3245e-07, 9.2027e-08, 1.4493e-07, 5.7939e-08,\n             1.7863e-07, 1.0824e-07, 9.4788e-08, 8.4997e-08, 1.5266e-07, 9.8738e-08,\n             6.7190e-08, 1.2525e-07, 1.1480e-07, 1.7880e-07, 1.2798e-07, 1.5080e-07,\n             9.0415e-08, 1.4729e-07, 1.2032e-07, 1.1344e-07])},\n    81: {'exp_avg': tensor([-1.9876e-04, -9.0367e-05,  1.5356e-04,  1.8597e-04, -6.0937e-05,\n             -1.7457e-04, -4.6178e-05,  2.8294e-05,  6.6213e-05,  1.0550e-03,\n              3.7548e-05,  1.7354e-04,  1.4334e-04, -1.1459e-04,  6.3687e-05,\n             -1.5623e-04,  1.5062e-04, -1.2691e-04, -8.6747e-05, -1.4814e-05,\n              8.2591e-05, -8.0273e-05, -1.5813e-04,  8.6686e-05,  5.3700e-05,\n              3.8264e-05, -6.6875e-05,  3.7284e-05,  7.1482e-05, -3.8251e-05,\n              7.3569e-05, -2.0457e-04, -3.3690e-05, -2.2121e-05,  9.1585e-06,\n             -2.1556e-05, -1.6371e-05,  7.4985e-05, -1.0680e-04, -1.0065e-04,\n              2.0771e-04, -1.2004e-04,  9.5982e-05,  2.8870e-04, -8.4661e-05,\n              3.2820e-05,  1.0772e-04, -8.2271e-05, -3.5434e-04,  1.6063e-04,\n             -1.5540e-04, -1.5631e-04, -1.9300e-04, -3.5201e-06, -3.2500e-05,\n             -1.9431e-04, -1.1529e-04,  9.1216e-06, -4.3909e-05,  3.2055e-04,\n              2.4265e-04,  1.1296e-05,  1.9239e-04, -1.3986e-04, -1.0056e-04,\n              1.2068e-04, -2.1032e-04,  2.9263e-04,  9.6128e-05,  4.8788e-05,\n             -2.2286e-05,  1.2774e-04, -1.3858e-04,  3.6438e-06,  1.4923e-04,\n             -6.1924e-05,  8.9215e-05, -2.7092e-04, -1.0074e-04, -2.3276e-04,\n             -3.6331e-05,  1.7697e-04, -9.1338e-05, -7.4612e-05,  5.6121e-05,\n              3.5274e-05, -7.1121e-05, -1.1210e-04,  2.7081e-04, -3.8899e-05,\n             -5.2841e-05, -2.3245e-04,  2.2885e-05,  8.5028e-05,  1.7370e-04,\n             -1.1897e-05, -4.4968e-05, -1.7359e-04,  6.7451e-05, -1.5378e-05,\n             -1.9417e-04,  1.5024e-04, -6.2437e-05, -7.4934e-05, -1.1547e-04,\n             -4.2294e-06, -2.4825e-04, -5.3739e-05, -1.1105e-04,  1.4463e-06,\n              2.9214e-04, -1.2735e-04,  2.3702e-04,  4.5106e-05,  1.2947e-04,\n              1.0123e-04,  5.8564e-05,  1.1337e-04,  1.2140e-04, -4.0888e-05,\n             -1.1079e-04,  1.3404e-05, -3.2490e-05,  2.0973e-04,  3.5435e-05,\n              1.9414e-05,  5.2218e-05, -2.5101e-05,  1.6314e-04, -2.8722e-05,\n             -9.4598e-05, -4.0909e-05,  5.3572e-05, -3.6874e-05,  2.2532e-05,\n             -9.0443e-05,  3.6188e-05, -1.4803e-04, -1.1707e-04,  1.4669e-04,\n             -1.1763e-04, -1.0324e-04, -1.0636e-04, -5.5479e-05,  5.7474e-05,\n             -4.3665e-06, -1.1481e-04, -3.0137e-05,  1.6379e-04, -1.7318e-04,\n             -9.3052e-05,  1.5147e-06,  1.0320e-05,  1.2916e-05, -2.2541e-05,\n              1.6273e-04,  1.3630e-04,  1.6156e-05, -3.6179e-05,  1.0194e-04,\n             -7.3127e-05, -1.0960e-04, -6.9028e-07, -3.2207e-04, -1.1103e-04,\n              1.0615e-04, -8.9547e-05,  1.2196e-04,  2.4324e-04,  2.1395e-04,\n             -6.3537e-06,  1.1865e-04, -1.6129e-04,  6.5452e-05,  7.5998e-05,\n              6.6587e-05,  1.2365e-04,  2.4534e-05, -2.0593e-05, -3.9894e-05,\n              9.4031e-05,  7.9861e-05,  5.8675e-05,  1.4673e-04,  3.7822e-04,\n              3.9277e-05, -2.4235e-04, -1.1240e-05, -1.1946e-04,  1.1093e-04,\n             -1.1511e-04,  1.7687e-04,  7.4277e-05,  9.0341e-05, -1.3299e-04,\n              1.4661e-04, -1.2350e-04, -4.4650e-05, -6.3261e-05, -1.2211e-05,\n             -3.1587e-07, -6.3810e-05,  5.2056e-04,  1.7383e-04, -3.7124e-05,\n              6.1465e-05,  1.1960e-04, -1.8724e-04,  6.5382e-06, -8.7971e-05,\n              4.0075e-04, -7.1684e-05,  1.7619e-05, -4.3520e-06,  4.3043e-05,\n             -9.6322e-05,  1.2163e-04, -8.6771e-07,  2.8337e-05, -1.6597e-04,\n              3.2399e-05,  1.0447e-04, -2.9645e-05,  1.2184e-04, -1.8012e-04,\n              1.1577e-04, -1.1628e-04, -2.4881e-05, -1.6734e-04,  2.2452e-05,\n              4.9074e-05,  9.9253e-05,  2.9331e-04, -2.1178e-05, -1.8981e-05,\n              9.7526e-06,  2.1460e-04,  2.1311e-04,  7.5212e-05,  5.6899e-05,\n              1.1826e-05,  1.6782e-04, -8.6716e-05, -2.2161e-05, -5.8816e-05,\n             -6.0606e-05,  1.3560e-04, -6.0860e-05,  2.0578e-04,  4.8400e-05,\n              2.5399e-06, -3.0593e-05, -5.6279e-06,  1.0910e-04, -7.9602e-05,\n             -1.5601e-04]),\n     'exp_avg_sq': tensor([3.9012e-08, 3.5840e-08, 4.0497e-08, 3.8719e-08, 3.4159e-08, 3.5047e-08,\n             6.4852e-08, 2.5273e-08, 2.2505e-08, 3.8892e-07, 3.2351e-08, 4.5612e-08,\n             3.9719e-08, 4.7881e-08, 2.8322e-08, 4.4161e-08, 4.3466e-08, 3.1666e-08,\n             2.8533e-08, 3.1509e-08, 2.1851e-08, 5.3152e-08, 3.8909e-08, 4.1089e-08,\n             4.5377e-08, 4.5281e-08, 2.0498e-08, 3.0408e-08, 3.8182e-08, 3.5159e-08,\n             4.0784e-08, 5.0640e-08, 3.3393e-08, 7.6315e-08, 7.3469e-08, 3.3465e-08,\n             5.3779e-08, 2.8526e-08, 2.6434e-08, 4.3785e-08, 3.5862e-08, 7.9777e-08,\n             4.0941e-08, 4.4426e-08, 2.9920e-08, 2.1558e-08, 1.7640e-08, 7.2066e-08,\n             4.4966e-08, 3.6849e-08, 4.4390e-08, 3.3262e-08, 6.3947e-08, 2.9925e-08,\n             2.3974e-08, 3.4325e-08, 6.2149e-08, 2.3945e-08, 3.2203e-08, 4.2043e-08,\n             7.4830e-08, 6.4869e-08, 6.7367e-08, 3.2089e-08, 3.5866e-08, 3.5526e-08,\n             5.7286e-08, 7.9965e-08, 5.9535e-08, 2.9751e-08, 1.3755e-08, 5.6917e-08,\n             3.2897e-08, 3.7580e-08, 3.2393e-08, 3.3065e-08, 2.1147e-08, 6.8653e-08,\n             4.2397e-08, 3.0867e-08, 3.2583e-08, 5.2222e-08, 4.1194e-08, 7.6011e-08,\n             5.9584e-08, 3.6047e-08, 4.0111e-08, 5.7408e-08, 4.6162e-08, 4.8900e-08,\n             3.1940e-08, 6.4562e-08, 3.2392e-08, 8.5619e-08, 4.3631e-08, 4.2152e-08,\n             4.3701e-08, 3.4615e-08, 4.3587e-08, 3.3510e-08, 5.0521e-08, 2.4557e-08,\n             5.4533e-08, 3.8307e-08, 3.0654e-08, 3.2395e-08, 4.6531e-08, 3.9069e-08,\n             5.5368e-08, 3.8592e-08, 1.0445e-07, 3.2910e-08, 4.1832e-08, 1.4350e-08,\n             3.1399e-08, 2.9347e-08, 5.5202e-08, 3.2758e-08, 3.4186e-08, 5.5007e-08,\n             2.9636e-08, 2.4236e-08, 2.3460e-08, 2.8741e-08, 3.8117e-08, 4.0220e-08,\n             3.7569e-08, 5.5181e-08, 6.2856e-08, 4.9084e-08, 2.9640e-08, 3.2856e-08,\n             3.9689e-08, 3.6468e-08, 1.7455e-08, 2.8227e-08, 2.3582e-08, 5.6960e-08,\n             4.5685e-08, 6.9908e-08, 5.3273e-08, 3.1536e-08, 4.3381e-08, 3.7252e-08,\n             3.5503e-08, 2.7558e-08, 4.0657e-08, 3.7378e-08, 6.2392e-08, 3.2285e-08,\n             4.6186e-08, 2.5021e-08, 4.4426e-08, 3.0299e-08, 2.2608e-08, 3.7737e-08,\n             5.5602e-08, 5.6436e-08, 2.0599e-08, 3.0410e-08, 4.6255e-08, 2.6611e-08,\n             3.0269e-08, 4.8963e-08, 7.3346e-08, 3.2178e-08, 8.6826e-08, 4.1548e-08,\n             4.0260e-08, 3.3130e-08, 1.8997e-08, 3.3818e-08, 5.8088e-08, 4.1914e-08,\n             4.6058e-08, 3.0879e-08, 3.1439e-08, 4.3338e-08, 5.3643e-08, 2.5249e-08,\n             3.0636e-08, 3.8821e-08, 2.6156e-08, 2.6482e-08, 1.2444e-07, 3.8451e-08,\n             3.0340e-08, 6.2754e-08, 2.9052e-08, 1.1361e-07, 4.5773e-08, 7.0159e-08,\n             2.0011e-08, 2.7546e-08, 4.6025e-08, 3.3090e-08, 4.1164e-08, 1.0707e-07,\n             2.9268e-08, 5.0469e-08, 3.6168e-08, 2.8307e-08, 1.6681e-07, 2.2692e-08,\n             4.2832e-08, 2.1509e-08, 5.3439e-08, 5.3658e-08, 3.4907e-08, 3.7183e-08,\n             7.3543e-08, 3.9582e-08, 2.8626e-08, 2.4587e-08, 4.0060e-08, 2.1015e-08,\n             4.8059e-08, 5.2939e-08, 3.1402e-08, 6.3411e-08, 6.5545e-08, 3.2571e-08,\n             3.8938e-08, 1.8067e-08, 5.3842e-08, 3.8212e-08, 4.2679e-08, 3.1766e-08,\n             4.9194e-08, 2.3377e-08, 1.9053e-08, 3.2074e-08, 1.0422e-07, 3.8685e-08,\n             3.3985e-08, 2.8462e-08, 6.1129e-08, 3.7625e-08, 2.1244e-08, 2.6779e-08,\n             7.4144e-08, 3.9372e-08, 2.9912e-08, 2.7387e-08, 4.8359e-08, 4.0493e-08,\n             3.4269e-08, 3.1029e-08, 4.1772e-08, 3.3032e-08, 5.6099e-08, 5.3659e-08,\n             3.1573e-08, 4.8349e-08, 3.2708e-08, 3.7201e-08])},\n    82: {'exp_avg': tensor([-1.8748e-04, -7.5850e-05,  4.5270e-06, -1.4135e-04, -1.2020e-04,\n              1.6027e-04, -1.0982e-05, -2.0418e-04, -2.4849e-04,  1.2150e-04,\n              1.3740e-05,  1.4507e-04,  8.3938e-05,  3.8335e-04,  6.8790e-05,\n              1.7778e-04, -1.5029e-04,  1.2378e-04,  6.1796e-05,  1.4525e-04,\n              6.1627e-05,  5.4447e-05,  2.0666e-04,  1.0455e-04, -1.9931e-04,\n              6.7519e-05,  9.9703e-06,  2.1073e-04, -1.1152e-06,  2.3509e-04,\n              2.3093e-04, -3.6531e-04,  2.4422e-04, -5.3567e-05, -2.3414e-05,\n             -1.3000e-04, -2.3439e-04, -2.6952e-04,  2.3775e-04, -1.2625e-04,\n              2.3551e-05, -2.3103e-05, -1.4996e-04,  2.8816e-05, -1.4146e-04,\n             -1.7713e-04, -2.6002e-04,  6.8120e-05, -5.0299e-05,  9.8030e-05,\n              3.7709e-05, -5.6743e-05, -5.7668e-05, -3.6562e-05, -1.7788e-04,\n              1.2869e-04, -2.1047e-04,  1.9742e-04,  6.7698e-05, -7.1347e-05,\n              4.4169e-04,  1.6069e-04,  1.4259e-04,  5.2691e-05, -9.9794e-05,\n              2.5197e-05, -7.2468e-05, -7.8475e-07,  1.3447e-04,  1.1058e-05,\n              8.3410e-05,  2.5240e-05, -2.0609e-04,  3.0860e-05,  7.1553e-05,\n             -3.1310e-05,  1.5383e-04, -4.2828e-05, -4.1796e-05,  6.9794e-05,\n              4.3395e-05,  1.9520e-04, -1.2733e-04, -2.1988e-04,  4.1362e-04,\n             -2.6574e-05,  3.3439e-05, -2.0847e-04,  1.3148e-05,  1.3818e-04,\n             -2.6747e-04,  6.0411e-05,  5.8760e-05,  5.3655e-06, -2.0316e-04,\n              1.3869e-04, -4.4914e-05, -2.9462e-04, -8.8221e-05,  2.3267e-04,\n             -2.1858e-04,  6.8847e-05, -4.8958e-05,  1.6083e-04,  2.9760e-04,\n              1.7240e-04,  1.0805e-04, -1.9947e-05, -1.3825e-04, -4.0058e-04,\n              3.4843e-06,  1.4600e-05, -4.0363e-05,  2.3367e-05,  1.5116e-04,\n              4.3866e-05, -1.4900e-04,  2.5902e-04, -1.6767e-06,  1.3570e-04,\n              4.9241e-05,  3.4848e-04, -8.4310e-05, -1.6087e-04, -4.9583e-05,\n             -1.4211e-04,  4.0968e-05,  1.3875e-04, -9.2668e-05,  9.5225e-06,\n             -2.8516e-04, -1.3116e-04, -9.1831e-05, -9.8308e-06,  7.0696e-05,\n             -1.6514e-04, -3.9772e-05,  9.2926e-05,  9.9982e-05, -5.9349e-05,\n             -1.6002e-04,  8.3506e-05, -1.1514e-05, -1.0973e-04,  7.3117e-06,\n             -1.9497e-04, -1.5188e-05,  1.6158e-05, -3.4768e-05, -1.6333e-04,\n              3.3403e-05,  2.6497e-04, -2.4336e-04, -2.5936e-04, -1.0007e-05,\n              5.8321e-05,  5.8702e-05, -7.4587e-05, -8.3225e-05, -4.4031e-05,\n              7.9019e-05,  1.0260e-04, -1.6276e-04,  2.6590e-04,  9.2984e-05,\n              2.9025e-04,  2.8429e-04, -9.6017e-05,  2.8583e-05,  8.3206e-05,\n              1.3129e-04, -6.7587e-05,  2.0310e-05, -1.2390e-05,  1.7841e-04,\n              1.5373e-04,  5.0153e-04,  2.2627e-04,  2.4249e-04, -2.8226e-05,\n              3.0153e-06,  4.4523e-05,  2.3048e-05, -2.0688e-04, -2.2561e-05,\n             -7.2864e-05, -1.0265e-04, -4.8345e-05,  1.3953e-04,  6.2024e-05,\n              1.8416e-04, -4.4235e-05,  4.4286e-05, -3.1818e-04, -8.2363e-05,\n             -2.4039e-04, -3.7959e-05,  2.3682e-04,  1.8831e-04,  1.2196e-04,\n             -1.8502e-04,  7.0123e-05, -6.4737e-05, -1.0508e-04, -1.0190e-04,\n              1.9878e-04, -2.0099e-04,  1.3315e-04, -3.0926e-04,  1.3961e-05,\n             -9.6945e-05,  7.7636e-06, -1.7228e-04, -1.2528e-04,  2.3573e-04,\n              1.5819e-04, -1.2405e-04, -9.6764e-05,  1.0243e-04,  5.4544e-05,\n              1.1800e-04, -1.1500e-04,  2.0174e-04, -9.4816e-05,  2.2181e-04,\n             -1.1093e-04, -8.0685e-05,  2.0434e-04, -5.3075e-05,  2.5849e-05,\n             -2.3542e-04, -2.5020e-05,  3.8230e-05,  1.4514e-04, -1.4446e-04,\n             -1.4944e-04,  2.9672e-05,  2.5624e-05, -2.7124e-05,  2.2376e-04,\n              3.0590e-06, -2.4215e-04, -2.7604e-05,  6.5701e-05, -1.1556e-04,\n              4.1688e-05,  9.7712e-05, -3.0950e-04, -1.2510e-04,  9.9522e-05,\n              2.0668e-04, -1.1581e-05,  8.9045e-05, -5.8808e-04,  1.5067e-04,\n             -2.3822e-05]),\n     'exp_avg_sq': tensor([8.0585e-08, 2.0868e-08, 4.9560e-08, 6.0385e-08, 6.8844e-08, 1.0264e-07,\n             3.9219e-08, 7.0751e-08, 7.6118e-08, 6.4950e-08, 2.5648e-08, 6.8459e-08,\n             2.0546e-08, 7.5484e-08, 2.8839e-08, 4.1168e-08, 2.3246e-08, 5.0094e-08,\n             8.0817e-08, 3.2672e-08, 3.8785e-08, 3.1479e-08, 2.5993e-08, 4.9558e-08,\n             6.6107e-08, 3.6304e-08, 4.7897e-08, 7.3971e-08, 6.0627e-08, 4.8463e-08,\n             4.1820e-08, 6.1837e-08, 4.7931e-08, 3.3353e-08, 5.5412e-08, 5.1540e-08,\n             3.8397e-08, 4.0486e-08, 5.1180e-08, 5.8715e-08, 5.6934e-08, 7.3767e-08,\n             3.1783e-08, 5.2195e-08, 6.2420e-08, 9.4394e-08, 7.4975e-08, 6.2460e-08,\n             8.8841e-08, 5.3848e-08, 5.6890e-08, 2.3136e-08, 3.0492e-08, 6.4685e-08,\n             5.3175e-08, 4.8089e-08, 3.0895e-08, 4.5296e-08, 3.6311e-08, 3.7496e-08,\n             4.3828e-07, 6.2622e-08, 2.9118e-08, 2.5910e-08, 1.8099e-08, 7.4042e-08,\n             3.5230e-08, 5.5364e-08, 5.2147e-08, 5.2273e-08, 5.9616e-08, 4.1403e-08,\n             4.3510e-08, 5.7512e-08, 4.3454e-08, 2.4241e-08, 3.8356e-08, 3.3667e-08,\n             2.9020e-08, 2.3510e-08, 4.2738e-08, 6.9370e-08, 5.3075e-08, 5.3825e-08,\n             5.7903e-08, 2.8548e-08, 3.9033e-08, 7.2944e-08, 5.5704e-08, 4.0034e-08,\n             5.1404e-08, 2.4966e-08, 8.0958e-08, 6.6690e-08, 5.4316e-08, 6.8331e-08,\n             4.8682e-08, 3.7478e-08, 6.3997e-08, 6.2984e-08, 4.4739e-08, 5.6968e-08,\n             2.2183e-08, 6.0910e-08, 6.7841e-08, 5.8751e-08, 3.5033e-08, 3.0432e-08,\n             5.3547e-08, 6.5233e-08, 1.9687e-08, 3.6583e-08, 4.1489e-08, 2.7188e-08,\n             6.8274e-08, 6.0097e-08, 7.5106e-08, 5.2218e-08, 5.5128e-08, 8.7013e-08,\n             4.3197e-08, 6.9903e-08, 1.9459e-08, 4.8313e-08, 4.0152e-08, 3.8398e-08,\n             1.6131e-08, 3.4803e-08, 2.5750e-08, 2.5518e-08, 5.0403e-08, 2.7107e-08,\n             4.3626e-08, 7.5512e-08, 4.2153e-08, 5.6409e-08, 3.1892e-08, 4.6410e-08,\n             6.6211e-08, 4.0932e-08, 3.6847e-08, 3.7445e-08, 5.3602e-08, 2.1538e-08,\n             3.7147e-08, 3.0264e-08, 6.1403e-08, 9.1277e-08, 4.5642e-08, 4.4098e-08,\n             4.9436e-08, 3.5684e-08, 6.1927e-08, 3.3268e-08, 7.7492e-08, 3.4463e-08,\n             4.3053e-08, 5.4839e-08, 4.9350e-08, 4.4937e-08, 5.5032e-08, 5.2758e-08,\n             6.1649e-08, 4.4122e-08, 5.4829e-08, 5.5931e-08, 5.0277e-08, 6.1521e-08,\n             5.0755e-08, 5.3738e-08, 4.2798e-08, 4.9112e-08, 4.1361e-08, 5.9875e-08,\n             6.3179e-08, 4.3594e-08, 1.1979e-07, 5.2345e-08, 5.2206e-08, 2.5292e-08,\n             8.1938e-08, 4.8986e-08, 2.9426e-08, 3.9056e-08, 4.5621e-08, 6.9998e-08,\n             8.6665e-08, 5.6130e-08, 8.8317e-08, 3.4430e-08, 6.5135e-08, 6.8774e-08,\n             3.5822e-08, 1.0799e-07, 5.0014e-08, 7.8794e-08, 3.8174e-08, 5.3442e-08,\n             4.5789e-08, 6.7388e-08, 6.0077e-08, 3.7512e-08, 7.7746e-08, 3.4768e-08,\n             2.9541e-08, 4.2861e-08, 6.0599e-08, 2.1098e-08, 3.6839e-08, 1.1791e-07,\n             7.2148e-08, 7.3302e-08, 5.1924e-08, 3.9716e-08, 7.1716e-08, 4.1976e-08,\n             3.0193e-08, 4.5607e-08, 3.2549e-08, 4.0372e-08, 7.0085e-08, 5.5102e-08,\n             3.7183e-08, 6.1727e-08, 1.3009e-07, 1.9469e-08, 5.4696e-08, 4.6263e-08,\n             3.8632e-08, 6.5837e-08, 8.3888e-08, 1.4587e-08, 4.3482e-08, 3.0919e-08,\n             5.4390e-08, 1.1663e-07, 3.5873e-08, 2.3128e-08, 4.0480e-08, 3.1374e-08,\n             2.0474e-08, 4.4055e-08, 2.5264e-08, 3.0843e-08, 4.2401e-08, 4.2033e-08,\n             2.5249e-08, 4.0287e-08, 2.7391e-08, 2.6620e-08, 4.5531e-08, 8.2965e-08,\n             3.2617e-08, 1.1954e-07, 7.0382e-08, 2.0087e-08])},\n    83: {'exp_avg': tensor([-1.9869e-04, -3.5036e-05, -3.4864e-05,  5.2619e-05, -6.5516e-05,\n              7.3705e-05, -9.0710e-05, -2.2888e-05, -1.3709e-04,  9.7860e-05,\n              9.8508e-06,  7.9119e-05,  8.1139e-05,  2.9108e-04,  8.0208e-05,\n              8.1152e-05, -8.2065e-05,  3.7562e-05,  3.5912e-05,  7.4744e-05,\n              1.0420e-05,  2.9498e-05,  1.3439e-04,  3.0676e-05,  6.9003e-06,\n             -1.7784e-05, -2.3598e-05,  6.0629e-06, -3.1819e-05,  1.4412e-04,\n              1.3342e-04, -7.7195e-05,  8.6778e-05, -1.6478e-05,  6.7899e-05,\n              1.8962e-05, -1.0342e-04, -1.7532e-04,  6.3165e-05, -4.1523e-05,\n             -2.0661e-04, -6.6806e-05, -1.1708e-04,  6.1000e-05, -3.9590e-05,\n             -6.2436e-05,  1.7099e-05,  1.9074e-05, -3.2806e-05,  9.9927e-05,\n             -9.4253e-05,  2.1742e-05, -7.2864e-05,  2.9670e-05, -1.0385e-04,\n              4.3630e-06, -1.4270e-04,  2.3361e-04,  8.9665e-05, -7.0714e-05,\n              1.3909e-04,  2.7844e-04,  2.3239e-05,  5.0208e-05, -3.6316e-05,\n             -1.8082e-05, -1.9588e-05,  1.4170e-04,  7.2036e-05,  8.2714e-05,\n              1.0740e-04,  4.4278e-05, -8.3700e-05,  9.2709e-05,  6.3874e-05,\n             -4.1901e-05,  6.4426e-05,  6.0145e-05,  2.0052e-05,  7.4919e-05,\n              8.9148e-05,  1.1412e-04, -2.9219e-05, -2.0815e-04,  2.5394e-04,\n             -5.9518e-05,  3.0738e-05, -8.6496e-05,  1.0506e-04,  5.5298e-05,\n             -1.9203e-04, -7.7450e-06,  5.4125e-05, -7.3788e-05, -8.9574e-05,\n              1.0366e-04, -2.0789e-06, -1.6630e-04, -7.0932e-05,  1.7982e-04,\n             -1.7516e-04,  6.9363e-05, -2.7668e-05,  1.0912e-04,  1.6575e-04,\n              1.9397e-04,  9.3745e-05, -6.8502e-05, -1.2155e-04, -2.2051e-04,\n              1.0740e-05,  1.2129e-05, -1.2517e-05,  1.6899e-05,  6.4637e-05,\n              1.0938e-04, -6.0996e-05,  4.9151e-05,  7.0839e-05,  1.4158e-04,\n             -4.6584e-05,  2.4699e-04, -2.0704e-05, -1.4308e-04, -5.2323e-05,\n             -9.4553e-05,  7.9055e-05,  5.4322e-05, -5.5989e-05, -8.0063e-06,\n             -1.7326e-04, -1.6107e-04,  2.3127e-05,  3.5356e-05,  1.0455e-04,\n             -9.7665e-05, -3.0461e-05, -1.2353e-05,  3.0118e-05,  4.7513e-06,\n             -7.2220e-05,  4.9985e-05,  6.7359e-05, -6.4812e-05,  1.7269e-05,\n             -1.1306e-04,  4.7832e-05, -1.1034e-05, -3.7754e-05, -6.1961e-05,\n              1.1186e-04,  1.6183e-04, -3.0172e-05, -9.4623e-05,  2.0280e-05,\n             -4.0897e-05,  5.6625e-05, -5.6882e-05, -1.1520e-04, -2.2800e-05,\n              8.7560e-05,  4.6096e-05, -9.1255e-05,  1.4341e-04,  9.0036e-05,\n              6.2571e-05,  1.7380e-04, -8.4202e-05,  7.8770e-05,  5.6770e-05,\n              1.0418e-04, -1.4310e-04, -9.3057e-05, -1.5658e-06,  1.3590e-04,\n              1.7209e-04,  3.3659e-04, -1.8365e-05,  1.9206e-04,  5.6068e-08,\n             -5.0140e-05,  1.8570e-06,  1.0166e-04, -9.6323e-05,  6.9676e-05,\n              5.5408e-05,  9.1469e-06, -4.2434e-05,  4.8974e-05,  2.1957e-05,\n             -6.7333e-05, -6.8022e-05,  5.1881e-05, -1.3079e-04, -6.2918e-05,\n             -1.0702e-04,  4.8675e-05,  1.7775e-04,  1.3564e-04,  8.3723e-05,\n             -1.2369e-04,  2.4322e-05, -6.1286e-06, -4.3758e-05, -3.9224e-05,\n              8.8336e-05, -1.0418e-04,  7.6997e-05, -1.7922e-04,  2.1426e-06,\n             -3.6854e-05,  1.0188e-04, -3.6808e-05, -5.3244e-05,  1.6082e-04,\n              4.9365e-05, -8.0235e-05, -2.1653e-05,  3.4205e-06,  8.4417e-05,\n              3.2289e-05, -1.0755e-04,  5.3343e-05, -3.3309e-05,  2.6482e-04,\n             -6.3158e-05, -5.9276e-05,  1.0122e-04,  2.6016e-05,  7.7884e-05,\n              5.2825e-05, -3.7718e-05,  1.6166e-04,  6.9991e-05,  4.0052e-05,\n              1.9258e-05, -7.2443e-06, -1.1500e-05,  2.0577e-05,  1.9198e-04,\n             -2.2366e-05, -3.4970e-05, -7.1434e-05,  6.6500e-05, -1.2866e-04,\n              5.4931e-05,  6.4871e-05, -2.0261e-04, -6.2665e-05,  3.8497e-05,\n              9.2494e-05,  1.7009e-04,  6.8394e-05, -2.7471e-04,  3.7195e-05,\n             -2.2914e-05]),\n     'exp_avg_sq': tensor([2.5326e-08, 7.9086e-09, 2.1184e-08, 1.7518e-08, 2.2852e-08, 3.1164e-08,\n             2.1206e-08, 2.5053e-08, 3.1525e-08, 2.3898e-08, 1.0010e-08, 1.9134e-08,\n             9.0559e-09, 2.9552e-08, 1.1487e-08, 1.9924e-08, 1.0503e-08, 2.5063e-08,\n             1.2457e-08, 1.2030e-08, 1.4714e-08, 1.0011e-08, 1.9716e-08, 2.0493e-08,\n             2.1821e-08, 1.5808e-08, 1.8747e-08, 2.7131e-08, 1.6239e-08, 2.1216e-08,\n             2.1566e-08, 1.8234e-08, 2.0802e-08, 1.3742e-08, 1.8049e-08, 2.1555e-08,\n             1.1289e-08, 1.7729e-08, 1.9190e-08, 1.1411e-08, 1.8142e-08, 2.5619e-08,\n             1.3423e-08, 1.2325e-08, 1.9659e-08, 4.1377e-08, 3.3858e-08, 2.0483e-08,\n             3.1271e-08, 1.6172e-08, 1.4287e-08, 1.8126e-08, 1.1858e-08, 2.1764e-08,\n             1.7003e-08, 1.1424e-08, 1.3718e-08, 2.5358e-08, 1.6041e-08, 1.5329e-08,\n             3.1623e-08, 3.7252e-08, 1.1256e-08, 1.0516e-08, 8.8842e-09, 2.1783e-08,\n             1.2086e-08, 2.0664e-08, 9.3091e-09, 2.0541e-08, 1.6636e-08, 1.2809e-08,\n             1.8971e-08, 2.3951e-08, 1.6614e-08, 8.2180e-09, 1.5031e-08, 1.4180e-08,\n             1.7781e-08, 9.3798e-09, 1.6642e-08, 2.4301e-08, 1.7143e-08, 2.1991e-08,\n             2.2724e-08, 1.2250e-08, 1.7078e-08, 1.4637e-08, 2.5363e-08, 1.5513e-08,\n             2.4818e-08, 1.0528e-08, 3.5673e-08, 2.1462e-08, 1.6633e-08, 3.7457e-08,\n             1.2662e-08, 1.5298e-08, 1.1239e-08, 2.2840e-08, 1.5447e-08, 1.8396e-08,\n             1.1605e-08, 1.4367e-08, 2.1295e-08, 1.5301e-08, 1.3315e-08, 1.5813e-08,\n             2.4533e-08, 2.0673e-08, 9.7509e-09, 1.4859e-08, 1.9500e-08, 1.2413e-08,\n             2.6796e-08, 2.4392e-08, 2.2832e-08, 1.3981e-08, 2.1527e-08, 3.2994e-08,\n             1.8534e-08, 3.8570e-08, 1.0598e-08, 2.1205e-08, 1.7995e-08, 1.6711e-08,\n             8.1949e-09, 1.2905e-08, 8.9588e-09, 9.9977e-09, 1.6321e-08, 9.9421e-09,\n             1.8306e-08, 2.7533e-08, 1.0836e-08, 3.4560e-08, 1.2668e-08, 1.7890e-08,\n             1.6205e-08, 1.6268e-08, 1.5214e-08, 1.3247e-08, 2.9750e-08, 9.1829e-09,\n             1.5310e-08, 1.1923e-08, 1.9109e-08, 5.7555e-08, 1.5139e-08, 1.9849e-08,\n             1.4488e-08, 1.4525e-08, 2.1501e-08, 1.2899e-08, 2.5587e-08, 1.6925e-08,\n             1.8311e-08, 1.4146e-08, 1.7620e-08, 1.8130e-08, 3.2057e-08, 1.7794e-08,\n             2.2510e-08, 1.2186e-08, 1.9097e-08, 2.2138e-08, 1.8036e-08, 1.9724e-08,\n             1.6943e-08, 2.2622e-08, 2.4152e-08, 1.5893e-08, 1.2148e-08, 1.5297e-08,\n             2.5792e-08, 1.5495e-08, 4.8116e-08, 2.1192e-08, 1.8058e-08, 1.2775e-08,\n             2.6166e-08, 1.4572e-08, 1.9999e-08, 1.4952e-08, 1.7631e-08, 2.2969e-08,\n             1.8650e-08, 2.1197e-08, 3.0515e-08, 1.7036e-08, 1.5612e-08, 2.2507e-08,\n             1.8672e-08, 1.9376e-08, 1.9769e-08, 1.4830e-08, 1.8878e-08, 3.1887e-08,\n             2.0587e-08, 2.3345e-08, 2.3797e-08, 1.5451e-08, 2.8008e-08, 1.2732e-08,\n             1.5092e-08, 1.4652e-08, 1.4963e-08, 1.0452e-08, 1.6196e-08, 3.5443e-08,\n             1.7850e-08, 2.3438e-08, 1.4901e-08, 1.5797e-08, 2.2788e-08, 1.7933e-08,\n             1.3430e-08, 1.5938e-08, 1.4192e-08, 1.5222e-08, 1.6483e-08, 1.9912e-08,\n             1.3949e-08, 2.0221e-08, 7.4608e-08, 1.0182e-08, 2.3136e-08, 1.7022e-08,\n             2.6841e-08, 2.3296e-08, 3.6453e-08, 8.0962e-09, 2.5492e-08, 1.4974e-08,\n             7.6920e-09, 2.5448e-08, 1.2657e-08, 1.1763e-08, 1.1514e-08, 1.6318e-08,\n             8.8034e-09, 1.3511e-08, 1.4976e-08, 1.6534e-08, 1.6672e-08, 1.9579e-08,\n             1.0679e-08, 2.2704e-08, 7.4113e-09, 9.7415e-09, 1.9162e-08, 1.9491e-08,\n             1.4151e-08, 4.7047e-08, 2.2871e-08, 8.8682e-09])},\n    84: {'exp_avg': tensor([ 4.7648e-05,  1.6087e-05,  2.0361e-04,  ...,  2.5646e-04,\n             -5.0507e-05,  3.4738e-05]),\n     'exp_avg_sq': tensor([5.0726e-08, 2.1106e-08, 3.4926e-08,  ..., 5.2356e-08, 1.3284e-08,\n             4.5223e-08])},\n    85: {'exp_avg': tensor([ 7.3293e-05, -4.0639e-06,  1.4910e-05,  ..., -7.9918e-06,\n             -3.9478e-05,  9.9410e-06]),\n     'exp_avg_sq': tensor([1.0270e-08, 7.1560e-09, 3.0777e-10,  ..., 1.3537e-10, 9.0907e-09,\n             4.5148e-10])},\n    86: {'exp_avg': tensor([-6.1237e-05,  4.0499e-04,  9.6438e-05,  6.5750e-04,  1.1005e-04,\n             -2.5146e-04, -3.8946e-04, -7.8582e-05, -2.7536e-05, -3.5947e-04,\n             -4.4244e-06, -1.1051e-04, -1.7353e-04,  2.9479e-04, -2.5580e-04,\n              1.1813e-04,  9.9657e-06, -1.3908e-04, -1.3354e-04, -2.6215e-04,\n              2.8477e-04,  2.0739e-04, -2.1233e-04, -1.8274e-04,  2.4954e-04,\n              7.8855e-05,  3.6744e-04, -2.2375e-04, -4.5349e-05,  3.4935e-04,\n             -3.5851e-04,  3.5664e-04,  1.1405e-04, -3.1051e-04, -1.6226e-04,\n             -1.1514e-04,  1.3581e-04,  3.7814e-04,  3.2799e-04, -2.9284e-04,\n             -3.5858e-04,  2.7666e-04, -5.9618e-04,  3.1227e-04, -4.6150e-04,\n              8.0787e-04, -1.5175e-04, -1.3277e-04,  1.4522e-04, -3.7063e-04,\n              6.6818e-04,  7.4724e-05,  3.0079e-04, -3.6541e-04,  1.4604e-04,\n              5.1460e-04, -5.8364e-05,  1.8753e-06, -5.7871e-04,  4.3570e-04,\n              1.5434e-04,  6.7336e-05, -2.5803e-04, -5.2625e-04, -1.8511e-04,\n              2.6183e-04, -2.7854e-04,  4.0603e-05, -9.2314e-04, -4.9570e-04,\n              2.2784e-04, -1.3354e-04, -3.6522e-04,  4.3991e-04,  7.7474e-05,\n              1.2794e-04, -3.4879e-05, -3.6494e-04, -2.0722e-04, -2.1630e-04,\n             -4.4770e-04, -3.6026e-04,  6.0904e-05, -9.1278e-05,  8.4694e-04,\n              1.3636e-04, -2.4702e-04,  2.6931e-04,  3.2731e-04, -1.1253e-04,\n             -5.8924e-04,  9.6502e-05, -3.7139e-05,  3.5453e-04,  3.0295e-05,\n             -3.7705e-04,  1.3445e-04, -1.7422e-04, -1.4008e-04,  9.6322e-05,\n              1.9359e-04, -4.1522e-05, -1.6560e-04, -4.3436e-04,  2.5926e-04,\n              3.6409e-04,  5.5131e-04,  2.8517e-05, -1.6786e-04,  4.1509e-04,\n             -3.2374e-04,  1.6557e-04,  5.9248e-05,  4.9654e-04,  1.8327e-04,\n              3.3970e-05, -3.5585e-04,  5.8299e-04, -8.8488e-05,  2.6673e-05,\n             -5.5443e-04, -5.4715e-04,  2.6493e-05, -4.3990e-04,  7.6763e-05,\n             -9.1954e-05, -2.5136e-04,  1.2363e-04,  7.6125e-05, -1.0604e-03,\n              1.6548e-04, -2.0597e-04, -1.3353e-04,  4.2295e-04, -2.4840e-04,\n             -2.5090e-04,  2.3725e-04, -3.7365e-04,  1.4404e-04, -2.3725e-04,\n             -1.2763e-04,  2.4171e-04,  4.5848e-04, -5.8460e-05, -5.8133e-04,\n              2.6892e-04,  3.2234e-04, -3.0943e-04,  3.9791e-04, -7.6913e-05,\n             -2.1418e-04, -2.2137e-04,  3.5836e-04,  3.2419e-04,  2.3850e-04,\n             -3.2790e-04,  7.6988e-04, -9.0905e-05,  4.6619e-04, -5.1645e-05,\n              4.1921e-04, -2.4757e-04, -6.3430e-05, -2.4095e-04, -3.9309e-06,\n             -4.1244e-04, -5.5910e-05,  3.8521e-04,  1.8398e-04, -1.8151e-04,\n              3.4975e-04,  3.4537e-04,  3.3555e-04, -3.0125e-04,  2.6014e-05,\n              1.7868e-05, -1.6443e-04,  8.2149e-05,  4.4890e-04,  4.8899e-04,\n             -1.0591e-04, -1.3740e-04, -2.4143e-05, -2.8981e-04, -8.4915e-05,\n              6.1135e-04,  5.0272e-05,  3.6405e-04, -6.9613e-05, -2.3349e-04,\n             -2.2109e-04, -4.8494e-04, -7.4295e-05, -8.4407e-05,  1.2095e-04,\n              1.9273e-04, -1.1068e-04, -6.4567e-05,  5.5862e-04,  1.9523e-06,\n              4.0194e-04, -1.5473e-04, -5.5521e-04, -2.8543e-04, -2.9056e-04,\n             -8.2061e-05, -4.2737e-04,  1.5775e-04,  1.3786e-04, -1.5078e-04,\n             -1.0672e-05,  7.6825e-04, -2.5202e-04, -1.1894e-04,  6.6943e-04,\n             -9.7453e-06,  6.0650e-05, -8.0181e-05,  1.7095e-04,  3.5704e-04,\n              3.4671e-04,  1.5557e-04, -2.1366e-04, -9.8845e-05,  3.8496e-05,\n             -4.3537e-04,  3.9653e-04,  6.7555e-05, -1.7546e-04,  1.3996e-04,\n              7.0346e-04,  1.3286e-04, -1.4223e-04, -6.9717e-05,  2.7520e-05,\n              3.3999e-04,  1.2516e-04, -2.1544e-04, -6.0561e-05, -2.5406e-04,\n              2.6800e-04,  2.3125e-04,  2.1824e-04, -1.5752e-04, -1.7832e-04,\n              1.1365e-04, -1.1184e-04,  3.5636e-04,  2.0446e-04,  2.2670e-04,\n              2.6285e-04, -2.3800e-04, -1.8440e-04, -1.2932e-04, -1.1772e-04,\n              1.5585e-04,  3.5210e-05, -4.6436e-04, -6.7904e-04,  5.0006e-04,\n              2.2093e-04,  1.3042e-04, -4.4409e-04, -8.8400e-05,  2.3830e-04,\n             -2.7098e-05,  4.2807e-05, -1.9512e-04, -1.8056e-04, -1.6543e-04,\n              3.2982e-04,  3.1664e-04, -3.5132e-04,  1.2109e-04, -2.0803e-04,\n             -1.2241e-05, -4.9206e-04,  2.5815e-04, -2.4710e-04, -7.5773e-05,\n             -2.1155e-05, -3.5985e-04, -5.2888e-05,  9.0953e-05, -1.5273e-04,\n              5.1104e-04,  1.3693e-04, -5.7530e-06, -4.7066e-04, -8.9545e-07,\n              1.0342e-05, -2.6342e-04,  3.0444e-04, -7.9681e-05,  4.4729e-04,\n              1.4789e-04,  2.8549e-05, -3.9110e-04, -4.5930e-04,  1.0716e-04,\n             -9.8309e-05, -1.3811e-04,  3.7054e-04, -6.5080e-05,  1.7584e-04,\n             -7.9247e-04,  1.0488e-04,  4.1494e-04,  4.3309e-04, -8.5871e-05,\n              2.0474e-05,  2.3373e-04,  2.0145e-04, -1.9881e-04, -5.1320e-04,\n              1.4685e-04,  1.1548e-05,  2.8960e-06, -5.9053e-05,  1.5667e-04,\n              4.3538e-04, -2.5930e-04, -2.0555e-04,  3.0192e-04,  1.6194e-04,\n             -1.6202e-04, -2.7584e-04,  6.6287e-04,  1.2796e-05,  3.9921e-04,\n              1.8023e-04,  4.8046e-04,  1.5896e-04, -7.4815e-05,  1.2485e-04,\n              2.5675e-04, -3.5474e-04, -1.4191e-05,  5.4496e-04, -3.2641e-04,\n             -4.4867e-04,  5.3024e-05, -3.1310e-05, -1.4405e-05, -3.3318e-05,\n             -5.5100e-05,  3.9929e-05, -2.7764e-04,  2.7524e-04, -1.2384e-04,\n             -6.8379e-04,  1.3410e-05, -1.5091e-04,  6.1347e-04,  3.2441e-04,\n              4.1163e-04, -8.6263e-05,  6.8382e-05,  1.5348e-05,  2.4128e-05,\n             -1.8301e-04, -1.1415e-04, -2.0356e-04,  2.5688e-04,  8.8371e-05,\n             -6.2397e-04, -2.3819e-04, -2.7876e-04, -7.0227e-04,  2.6593e-04,\n             -4.9046e-04,  4.1678e-04, -1.3510e-04, -2.9311e-05,  1.8380e-05,\n              3.9519e-04,  2.2983e-04, -2.9208e-05,  3.8460e-05,  6.8495e-05,\n              2.2471e-04, -3.8417e-04, -9.9923e-05,  3.9195e-04,  3.9894e-04,\n              5.3339e-04,  3.5384e-04, -1.4311e-04,  1.2768e-04,  2.3652e-04,\n             -3.5643e-05, -1.6369e-04, -2.0795e-04,  1.3502e-04, -6.7762e-05,\n              2.8196e-04,  4.0250e-05, -1.6764e-04, -4.8542e-04, -2.3492e-04,\n              9.0359e-05, -7.0646e-04, -2.2013e-05,  1.9912e-04, -1.3113e-04,\n             -2.3234e-04,  3.0484e-05, -4.4361e-04, -6.6601e-05, -5.1659e-05,\n             -2.4096e-04, -4.0543e-04, -2.4678e-04,  1.0789e-04, -6.9881e-05,\n              1.2118e-04, -7.1419e-04,  3.0967e-04,  7.2105e-04, -1.0504e-04,\n             -1.0181e-04, -3.0205e-05, -1.7546e-04, -3.5039e-04, -2.9935e-04,\n              2.9120e-04,  2.4862e-05, -3.0150e-04, -1.7272e-05,  3.2479e-04,\n             -3.4492e-05,  7.0738e-05,  5.4436e-04, -2.7642e-04, -1.0954e-04,\n              3.1578e-04, -6.4778e-06, -1.8827e-04,  2.3562e-05,  1.6893e-04,\n              1.3976e-04,  6.7367e-05, -6.0133e-04, -1.1046e-04, -4.5405e-04,\n             -1.7928e-04,  1.1995e-04, -2.0657e-04,  1.7652e-04, -5.8156e-04,\n              2.8356e-04,  2.2673e-03,  2.4922e-04,  4.8826e-05,  3.0735e-04,\n             -2.4235e-04,  1.2620e-04,  1.2690e-04, -1.9939e-04, -4.0221e-04,\n             -7.4879e-05, -3.2533e-04,  5.5934e-04, -1.9866e-04,  4.4066e-04,\n              1.4377e-04,  3.3814e-04,  6.8394e-04, -4.4751e-04,  2.6201e-04,\n             -3.0905e-04, -1.9509e-04,  2.7852e-04, -3.5491e-04, -4.1634e-04,\n             -2.0695e-04, -4.2255e-04,  6.6683e-04, -3.5289e-04, -2.2345e-05,\n             -1.5920e-04,  4.9143e-04,  6.0436e-04,  2.6705e-04,  2.6832e-04,\n             -8.7336e-05,  1.2223e-05,  1.7562e-04, -2.6872e-04,  5.1160e-04,\n              4.3235e-04, -2.8717e-04,  5.2662e-06,  2.3274e-04,  1.5325e-04,\n              4.3864e-04,  1.5737e-05,  2.0418e-04, -7.8736e-05, -3.0054e-05,\n              1.7962e-04,  4.7988e-05, -4.0947e-04, -4.2197e-05, -2.6415e-04,\n              3.5250e-04,  2.2386e-04, -2.7602e-05, -3.6394e-04, -5.3955e-04,\n              3.3529e-04, -1.7192e-04]),\n     'exp_avg_sq': tensor([2.1900e-07, 2.2652e-07, 1.9959e-07, 2.3541e-07, 1.9220e-07, 3.2641e-07,\n             1.7704e-07, 1.9634e-07, 1.1341e-07, 2.2491e-07, 1.3547e-07, 1.9366e-07,\n             1.5344e-07, 2.4929e-07, 2.1967e-07, 2.2848e-07, 2.8581e-07, 2.9797e-07,\n             1.9255e-07, 2.8898e-07, 1.7241e-07, 3.7682e-07, 2.0793e-07, 2.6749e-07,\n             3.3944e-07, 4.2568e-07, 1.9965e-07, 2.0229e-07, 1.2036e-07, 3.0265e-07,\n             2.6560e-07, 3.7676e-07, 2.4047e-07, 3.1699e-07, 1.5020e-07, 1.4837e-07,\n             3.2145e-07, 2.0370e-07, 1.9048e-07, 1.8015e-07, 2.1949e-07, 2.4589e-07,\n             2.1469e-07, 1.8467e-07, 2.7733e-07, 3.0391e-07, 2.8387e-07, 2.0036e-07,\n             1.4986e-07, 2.2437e-07, 1.7974e-07, 2.4116e-07, 3.1369e-07, 2.2706e-07,\n             2.6687e-07, 2.5551e-07, 3.2284e-07, 1.7521e-07, 2.3590e-07, 2.1648e-07,\n             2.1604e-07, 1.4929e-07, 2.1125e-07, 2.9993e-07, 2.0668e-07, 1.6643e-07,\n             1.6479e-07, 2.2582e-07, 1.4595e-07, 3.4211e-07, 3.6990e-07, 2.2424e-07,\n             3.5366e-07, 2.0085e-07, 4.2001e-07, 2.4784e-07, 1.9247e-07, 2.3245e-07,\n             2.0131e-07, 2.6882e-07, 2.2774e-07, 2.3357e-07, 1.7407e-07, 2.6224e-07,\n             2.5323e-07, 2.4436e-07, 1.4425e-07, 3.6456e-07, 1.3819e-07, 2.1802e-07,\n             1.9020e-07, 2.8093e-07, 3.0790e-07, 3.8995e-07, 2.4652e-07, 1.6091e-07,\n             1.8597e-07, 2.4097e-07, 2.3030e-07, 2.7221e-07, 4.3582e-07, 3.3175e-07,\n             1.9471e-07, 2.3965e-07, 2.0173e-07, 2.9806e-07, 2.4078e-07, 2.6414e-07,\n             1.9451e-07, 2.8614e-07, 1.8294e-07, 2.0974e-07, 2.2480e-07, 2.8248e-07,\n             1.2640e-07, 2.9536e-07, 1.8267e-07, 2.2327e-07, 3.0486e-07, 1.7944e-07,\n             2.9811e-07, 5.5979e-07, 2.3564e-07, 2.3106e-07, 3.2485e-07, 2.9783e-07,\n             2.5126e-07, 3.9980e-07, 1.7940e-07, 3.3650e-07, 2.1812e-07, 1.6865e-07,\n             1.8695e-07, 2.9021e-07, 3.0256e-07, 2.9230e-07, 2.4087e-07, 2.3261e-07,\n             2.2879e-07, 1.7330e-07, 1.5283e-07, 2.8998e-07, 3.6515e-07, 1.7241e-07,\n             1.9533e-07, 2.9935e-07, 1.5203e-07, 5.0011e-07, 2.3338e-07, 1.3556e-07,\n             3.1170e-07, 2.5024e-07, 2.1534e-07, 2.8319e-07, 2.0209e-07, 1.2190e-07,\n             2.7753e-07, 2.2603e-07, 1.7886e-07, 3.6998e-07, 2.9708e-07, 2.8631e-07,\n             2.0367e-07, 2.1890e-07, 1.5321e-07, 2.4757e-07, 1.7272e-07, 3.3654e-07,\n             2.2445e-07, 2.4541e-07, 2.7918e-07, 1.6574e-07, 4.0382e-07, 1.8492e-07,\n             3.6427e-07, 4.2025e-07, 1.9736e-07, 2.5090e-07, 2.6412e-07, 1.7586e-07,\n             2.2458e-07, 2.2929e-07, 3.2201e-07, 2.4171e-07, 2.5123e-07, 2.4937e-07,\n             1.7894e-07, 1.7313e-07, 1.8524e-07, 2.2572e-07, 3.0117e-07, 3.1530e-07,\n             2.7931e-07, 2.9988e-07, 4.4099e-07, 2.6282e-07, 2.4777e-07, 2.0355e-07,\n             1.8559e-07, 2.8654e-07, 2.4336e-07, 2.4198e-07, 2.7835e-07, 2.6536e-07,\n             1.7152e-07, 2.0981e-07, 1.0844e-07, 1.6057e-07, 2.7018e-07, 2.4395e-07,\n             1.3048e-07, 2.7164e-07, 2.4018e-07, 2.9641e-07, 3.1720e-07, 3.4322e-07,\n             2.0039e-07, 1.8818e-07, 4.2211e-07, 1.9819e-07, 2.4049e-07, 1.1433e-07,\n             2.5143e-07, 2.0246e-07, 1.7089e-07, 2.2124e-07, 2.6920e-07, 1.7577e-07,\n             3.2851e-07, 3.6979e-07, 1.9908e-07, 1.7710e-07, 1.3621e-07, 2.3827e-07,\n             1.9906e-07, 1.8830e-07, 2.5845e-07, 1.9505e-07, 1.6647e-07, 3.6666e-07,\n             1.9200e-07, 1.8088e-07, 2.1342e-07, 1.7190e-07, 2.3902e-07, 2.9444e-07,\n             2.0881e-07, 3.2597e-07, 2.5873e-07, 1.5704e-07, 2.4779e-07, 2.3538e-07,\n             1.8440e-07, 3.7564e-07, 2.9179e-07, 2.4515e-07, 1.0793e-07, 1.7890e-07,\n             2.1618e-07, 3.0587e-07, 1.9772e-07, 2.8537e-07, 2.8979e-07, 3.4961e-07,\n             2.0929e-07, 3.5999e-07, 1.2652e-07, 1.5857e-07, 2.0441e-07, 3.4754e-07,\n             1.6505e-07, 2.3087e-07, 1.7017e-07, 3.0464e-07, 1.8311e-07, 3.4512e-07,\n             1.6263e-07, 1.8193e-07, 2.1843e-07, 1.5877e-07, 2.5635e-07, 4.0366e-07,\n             2.6581e-07, 1.6103e-07, 2.4945e-07, 3.1878e-07, 2.0210e-07, 1.9404e-07,\n             1.7822e-07, 2.3053e-07, 1.9106e-07, 1.8175e-07, 2.5392e-07, 2.0586e-07,\n             1.7346e-07, 2.6130e-07, 2.2671e-07, 1.8402e-07, 2.1385e-07, 2.2241e-07,\n             1.9292e-07, 2.9875e-07, 1.9987e-07, 1.8245e-07, 2.9093e-07, 3.1051e-07,\n             2.2126e-07, 3.9107e-07, 4.0871e-07, 2.7028e-07, 2.4370e-07, 1.0059e-06,\n             5.8993e-07, 2.1191e-07, 2.5863e-07, 3.8262e-07, 2.4649e-07, 2.8952e-07,\n             4.5754e-07, 2.9884e-07, 1.3680e-07, 1.6694e-07, 3.4578e-07, 2.8773e-07,\n             2.8260e-07, 2.1041e-07, 1.9907e-07, 2.9486e-07, 2.3595e-07, 2.8021e-07,\n             1.9765e-07, 3.1373e-07, 1.1511e-07, 3.0203e-07, 5.2956e-07, 1.9109e-07,\n             2.0591e-07, 1.3443e-07, 2.8883e-07, 3.6300e-07, 2.5444e-07, 2.1321e-07,\n             2.9255e-07, 4.6969e-07, 1.6380e-07, 3.3072e-07, 2.8733e-07, 1.8853e-07,\n             2.0487e-07, 1.6077e-07, 2.1405e-07, 1.8659e-07, 1.9984e-07, 2.3732e-07,\n             2.7943e-07, 2.1743e-07, 4.0017e-07, 2.3640e-07, 1.7250e-07, 2.3350e-07,\n             2.9660e-07, 4.3003e-07, 1.7451e-07, 2.3974e-07, 2.2465e-07, 5.1965e-07,\n             1.7857e-07, 2.1075e-07, 2.4820e-07, 1.9713e-07, 4.4844e-07, 1.8953e-07,\n             2.2644e-07, 1.5842e-07, 1.7548e-07, 2.8956e-07, 2.0426e-07, 2.3552e-07,\n             3.7400e-07, 2.7888e-07, 2.3321e-07, 2.1536e-07, 2.4088e-07, 2.5537e-07,\n             1.9920e-07, 3.3617e-07, 1.8634e-07, 2.7678e-07, 1.9001e-07, 2.2904e-07,\n             1.7754e-07, 1.6971e-07, 2.0350e-07, 7.8789e-08, 2.1539e-07, 1.9891e-07,\n             2.7548e-07, 2.2638e-07, 2.3513e-07, 2.5190e-07, 2.4688e-07, 2.7622e-07,\n             1.7159e-07, 1.9733e-07, 2.1977e-07, 2.0842e-07, 2.4821e-07, 3.8008e-07,\n             2.6938e-07, 2.4635e-07, 3.5974e-07, 2.5241e-07, 2.0335e-07, 1.6724e-07,\n             1.7667e-07, 2.1859e-07, 1.4627e-07, 2.2344e-07, 3.4583e-07, 1.3437e-07,\n             2.9156e-07, 1.7339e-07, 1.5036e-07, 2.0589e-07, 3.3649e-07, 2.4097e-07,\n             1.8330e-07, 2.9621e-07, 4.5452e-07, 2.1812e-07, 2.8739e-07, 1.2976e-07,\n             3.0068e-07, 2.9353e-07, 3.3019e-07, 2.6908e-07, 1.8626e-07, 1.7120e-07,\n             2.4827e-07, 2.2534e-07, 1.8099e-07, 2.2319e-07, 3.1458e-07, 1.6785e-07,\n             2.9115e-07, 2.1426e-07, 1.6276e-07, 2.1314e-07, 1.8557e-07, 3.2936e-07,\n             2.1189e-07, 4.4750e-06, 2.0592e-07, 1.5836e-07, 2.0316e-07, 1.8836e-07,\n             1.6558e-07, 2.9116e-07, 1.7255e-07, 2.7647e-07, 1.5612e-07, 1.5156e-07,\n             3.9743e-07, 1.9916e-07, 2.2476e-07, 1.7026e-07, 4.1416e-07, 3.3677e-07,\n             1.8663e-07, 1.4434e-07, 2.4990e-07, 3.2259e-07, 2.0993e-07, 3.4042e-07,\n             4.9232e-07, 2.5558e-07, 2.8254e-07, 2.9850e-07, 2.8210e-07, 2.0189e-07,\n             1.9917e-07, 3.1157e-07, 3.0034e-07, 2.6848e-07, 2.5933e-07, 2.4454e-07,\n             2.5665e-07, 2.6400e-07, 1.9386e-07, 2.0551e-07, 4.8518e-07, 1.6347e-07,\n             1.6364e-07, 1.7334e-07, 2.8903e-07, 3.2897e-07, 1.8794e-07, 2.3107e-07,\n             1.9453e-07, 4.2618e-07, 1.9254e-07, 1.7634e-07, 8.7326e-08, 2.0420e-07,\n             1.4720e-07, 2.3309e-07, 1.5200e-07, 1.6499e-07, 3.1077e-07, 3.4867e-07,\n             1.4193e-07, 2.4715e-07])},\n    87: {'exp_avg': tensor([-1.1664e-05,  1.6305e-04,  3.9606e-05,  2.6679e-04,  8.3155e-05,\n             -1.7726e-04, -2.0260e-04, -4.0301e-05,  7.6458e-06, -2.3742e-04,\n              2.1474e-05, -1.2142e-04, -1.4189e-04,  1.5041e-04, -1.2752e-04,\n              1.0045e-04,  5.2474e-05, -8.0601e-05, -1.3454e-04, -4.3658e-05,\n              1.2979e-04,  1.1220e-04, -6.9578e-05, -7.6974e-05,  2.3853e-04,\n              8.6036e-05,  2.7419e-04, -8.3009e-05, -6.3566e-05,  2.6348e-04,\n             -2.0788e-04,  2.5541e-04,  1.1466e-04, -1.9602e-04, -8.0232e-05,\n             -5.5501e-05,  5.2613e-05,  2.6158e-04,  1.1739e-04, -1.2865e-04,\n             -2.0126e-04,  1.7771e-04, -3.0648e-04,  1.6686e-04, -2.5707e-04,\n              3.8912e-04, -7.0188e-05, -3.5149e-05,  6.8055e-05, -2.0997e-04,\n              2.9058e-04, -1.7338e-06,  1.1315e-04, -1.6488e-04,  7.5391e-05,\n              2.8734e-04, -8.0421e-05, -1.3778e-05, -2.4415e-04,  2.2079e-04,\n              1.9147e-04,  7.6063e-05, -8.1034e-05, -2.0977e-04, -8.9844e-05,\n              1.5029e-04, -1.3005e-04,  1.1221e-05, -3.2999e-04, -2.4503e-04,\n              1.0009e-04, -7.5747e-05, -1.8601e-04,  2.6333e-04, -2.5187e-05,\n              1.7198e-05,  5.0675e-05, -1.2072e-04, -1.4851e-04, -8.8873e-05,\n             -2.6708e-04, -3.4773e-04,  3.1276e-05, -3.0809e-05,  4.7406e-04,\n              3.8926e-05, -7.4300e-05,  8.8590e-05,  1.0486e-04, -4.3003e-05,\n             -2.6165e-04,  3.6514e-05, -2.3427e-05,  1.9204e-04, -1.2301e-06,\n             -1.6213e-04,  4.4715e-05, -2.2086e-04, -2.9432e-05,  6.8388e-05,\n              1.0827e-04,  2.4078e-05, -1.3121e-04, -2.6195e-04,  9.3309e-05,\n              3.4364e-04,  2.7209e-04,  8.6579e-05, -1.3092e-04,  2.0707e-04,\n             -1.9964e-04,  3.7577e-05,  4.2447e-05,  3.4411e-04,  4.4333e-05,\n              8.8561e-05, -1.7251e-04,  3.2523e-04, -1.1676e-04,  7.7894e-05,\n             -2.3971e-04, -2.3989e-04, -2.5963e-05, -3.2586e-04, -2.8598e-05,\n             -2.9719e-05, -1.8186e-04,  1.7588e-04,  5.8218e-05, -4.3068e-04,\n              2.1983e-04, -1.0574e-04, -1.2251e-04,  9.6169e-05, -1.3406e-04,\n             -1.4675e-04,  7.7136e-05, -1.6852e-04,  9.0727e-05, -1.1129e-04,\n             -2.5629e-05,  7.9212e-05,  3.6043e-04, -2.3371e-05, -3.6077e-04,\n              1.3820e-04,  1.6092e-04,  2.8065e-05,  1.5765e-04, -2.2369e-05,\n             -1.8256e-04, -8.7188e-06,  2.2394e-04,  1.4665e-04,  1.0413e-04,\n             -1.5592e-04,  3.4675e-04, -5.8833e-05,  2.4756e-04,  2.7989e-05,\n              2.7957e-04, -2.4735e-04, -4.9281e-05, -9.0602e-05,  2.4112e-05,\n             -2.6769e-04, -1.0575e-04,  2.6733e-04,  1.1977e-04, -1.0183e-04,\n              2.7822e-04,  2.4952e-04,  1.1725e-04, -2.5632e-04,  7.9119e-05,\n              3.2791e-05, -2.1001e-04,  1.2678e-04,  2.9505e-04,  2.8052e-04,\n             -1.0983e-04, -1.2181e-04,  3.4960e-05, -2.2044e-04, -4.1869e-05,\n              2.1905e-04, -2.4788e-05,  1.8382e-04, -1.0684e-04, -1.1862e-04,\n             -1.5986e-04, -3.3296e-04, -1.6570e-05, -9.5423e-05,  7.9930e-05,\n              2.3067e-04, -7.1951e-05, -4.8081e-05,  2.3815e-04,  1.2774e-05,\n              3.1633e-04, -8.7768e-05, -2.6763e-04, -1.7459e-04, -6.6681e-05,\n             -1.5273e-06, -1.6614e-04,  8.6494e-05,  4.0981e-05, -4.8204e-05,\n             -4.9249e-05,  4.3366e-04, -1.4049e-04, -1.1734e-04,  4.8809e-04,\n             -1.3251e-04,  1.9984e-05, -4.6797e-05,  1.0765e-05,  1.4427e-04,\n              2.3436e-04,  7.1019e-05, -1.1224e-04, -6.6381e-05,  1.1213e-05,\n             -2.1474e-04,  1.8830e-04,  3.3085e-05, -7.6492e-05,  9.4788e-05,\n              3.1205e-04,  1.4069e-04, -6.4718e-05, -5.1550e-05,  6.4131e-06,\n              1.7047e-04,  5.7083e-05, -1.8095e-04, -1.6031e-05, -7.8419e-06,\n              6.1365e-05,  1.6141e-04,  2.2577e-04, -5.5987e-05, -4.3959e-05,\n              1.1849e-04, -1.5876e-05,  2.5952e-04,  1.6684e-04,  1.2825e-04,\n              1.3043e-04, -9.7251e-05, -7.0140e-05, -1.3593e-04, -2.8590e-05,\n              4.0065e-05,  3.8696e-05, -2.8141e-04, -4.7494e-04,  3.0869e-04,\n              1.2878e-04,  2.1560e-05, -1.8134e-04, -2.9121e-05,  2.0819e-04,\n             -2.1787e-04, -3.2963e-05, -1.1450e-04, -7.6448e-05, -1.9623e-04,\n              1.8631e-04,  1.5195e-04, -1.6352e-04, -3.3044e-05, -1.1916e-04,\n             -3.9143e-05, -2.6199e-04,  1.0486e-04, -1.1434e-04, -2.6931e-05,\n              2.9398e-05, -8.1430e-05, -1.6423e-05,  1.2230e-04, -8.9336e-05,\n              2.3977e-04,  9.1372e-05,  3.7970e-05, -2.2794e-04,  2.0823e-05,\n              6.8068e-06, -6.8944e-05,  9.1722e-05, -5.2448e-05,  3.7481e-04,\n              1.0074e-04,  4.4300e-05, -1.7384e-04, -1.5771e-04,  9.6485e-05,\n             -5.4906e-05, -1.0400e-04,  2.3008e-04, -2.2967e-05,  2.3420e-04,\n             -3.7116e-04,  5.6349e-05,  1.6004e-04, -8.1459e-04, -9.9145e-05,\n              4.8736e-05,  7.1047e-05,  7.3402e-05, -1.3271e-04, -2.9190e-04,\n              6.7197e-05,  4.2987e-05, -1.6520e-05,  2.4053e-05,  2.8697e-04,\n              1.7195e-04, -1.5280e-04, -1.3471e-04,  1.2839e-04,  1.8146e-04,\n             -9.9812e-05, -1.7091e-04,  3.6233e-04,  7.3197e-05,  1.4071e-04,\n              4.1742e-05,  3.0255e-04,  1.3034e-04, -3.6792e-05,  9.4650e-05,\n              1.1140e-04, -1.1869e-04,  7.4371e-07,  3.4363e-04, -2.9427e-04,\n             -2.1661e-04,  3.6140e-05,  6.8202e-05, -2.6209e-05,  2.5584e-05,\n             -2.7196e-05,  5.4572e-05, -5.3438e-05,  1.5377e-04, -1.6854e-04,\n             -2.9234e-04, -2.2246e-05, -1.3534e-04,  3.3633e-04,  2.2449e-04,\n              4.3010e-05,  2.8754e-05,  3.9682e-06,  6.0743e-05,  9.4282e-07,\n             -1.4350e-05, -7.0879e-05, -1.1334e-04,  1.4585e-04,  7.9010e-05,\n             -3.3666e-04, -1.1822e-04, -1.7569e-04, -6.9020e-04,  2.3212e-04,\n             -2.0851e-04,  2.1758e-04, -1.5716e-04,  7.0440e-06,  6.2608e-06,\n              3.2484e-04,  1.2173e-04,  3.2133e-05,  2.6504e-05,  2.0253e-05,\n              2.2444e-04, -2.7056e-04, -4.4880e-05,  1.4687e-04,  2.3951e-04,\n              1.5577e-04,  9.9651e-05, -1.3535e-05,  4.4508e-05,  1.0482e-04,\n             -4.9562e-05, -3.5383e-05, -1.6084e-04,  4.4246e-06, -5.3445e-05,\n             -1.3537e-05,  1.0759e-05, -6.7080e-05, -2.0526e-04, -1.1589e-04,\n              3.6311e-05, -3.6623e-04,  5.9121e-05,  1.1870e-04, -1.9399e-04,\n             -1.3658e-04,  1.0151e-04, -2.6284e-04, -5.3015e-05, -4.3785e-05,\n             -1.3794e-04, -2.0008e-04, -1.1521e-04,  5.4731e-05, -8.9205e-06,\n              7.2209e-05, -5.7819e-04,  1.5757e-04,  2.6339e-04, -1.1324e-04,\n             -1.1002e-04,  7.1836e-06, -1.6039e-04, -1.8034e-04, -1.6444e-04,\n              8.2949e-05, -6.5667e-05, -1.9695e-04,  1.9482e-06,  1.5417e-04,\n             -6.2232e-05, -6.8805e-06,  3.9911e-04, -2.1456e-04,  5.8446e-05,\n             -6.5106e-05, -2.3494e-06, -1.4148e-04, -7.8520e-05,  4.6117e-05,\n              8.7312e-05,  3.6250e-05, -2.4916e-04, -9.4908e-05, -2.1955e-04,\n             -1.1669e-04,  4.7818e-05, -7.6447e-05,  6.9097e-05, -1.7584e-04,\n              1.2585e-04,  5.1469e-04,  1.6438e-04,  2.6913e-05,  1.7891e-04,\n             -1.4186e-04,  8.4821e-05,  4.5652e-05, -4.8619e-05, -2.6479e-04,\n             -7.3008e-05, -1.6157e-04,  4.0084e-04, -6.3283e-05,  1.4964e-04,\n              6.5069e-05,  2.0093e-04,  2.6877e-04, -2.5643e-04,  1.2052e-04,\n             -1.8301e-04, -1.2274e-04,  1.5651e-04, -2.2093e-04, -2.2916e-04,\n             -2.6849e-04, -2.1692e-04,  2.1714e-04, -1.8732e-04, -4.6606e-05,\n              2.3889e-05,  3.2057e-04,  2.8901e-04,  1.7912e-04,  2.2288e-04,\n             -1.0305e-04,  4.1046e-05,  1.8157e-04, -9.0828e-05,  2.6632e-04,\n              2.3342e-04, -1.6711e-04, -1.5383e-06,  1.0994e-04,  1.0062e-04,\n              2.2231e-04,  1.1382e-05,  1.4405e-04, -8.4427e-05, -2.0296e-05,\n              1.2918e-04,  6.9512e-06, -2.2134e-04,  6.0642e-05, -2.1398e-04,\n              2.1616e-04,  8.3075e-05, -9.8825e-06, -2.3905e-04, -3.1528e-04,\n              1.8350e-04, -1.4520e-04]),\n     'exp_avg_sq': tensor([7.7693e-08, 5.4214e-08, 5.8219e-08, 6.7278e-08, 4.9146e-08, 1.6100e-07,\n             4.9278e-08, 5.0886e-08, 2.6825e-08, 3.8803e-08, 3.3928e-08, 6.9886e-08,\n             3.2781e-08, 7.2481e-08, 5.7069e-08, 7.0253e-08, 1.2396e-07, 7.4802e-08,\n             6.4058e-08, 1.0106e-07, 5.8907e-08, 1.2177e-07, 3.7948e-08, 1.0347e-07,\n             8.4257e-08, 2.2102e-07, 8.2464e-08, 4.9759e-08, 3.0047e-08, 8.2651e-08,\n             8.0318e-08, 9.8831e-08, 6.8496e-08, 4.7577e-08, 3.2170e-08, 4.1109e-08,\n             1.2661e-07, 5.5610e-08, 4.0109e-08, 4.6126e-08, 7.4870e-08, 8.7674e-08,\n             7.0480e-08, 4.8225e-08, 7.7762e-08, 9.7097e-08, 7.9550e-08, 4.0085e-08,\n             3.5405e-08, 6.5254e-08, 4.3306e-08, 7.7052e-08, 8.1753e-08, 6.3662e-08,\n             1.2677e-07, 7.1732e-08, 9.5353e-08, 4.3242e-08, 6.6645e-08, 6.0827e-08,\n             7.6742e-08, 2.8113e-08, 6.0204e-08, 7.1430e-08, 4.5183e-08, 2.7375e-08,\n             3.9935e-08, 6.3831e-08, 2.9566e-08, 7.7902e-08, 7.9978e-08, 7.1134e-08,\n             9.6594e-08, 6.0889e-08, 1.3691e-07, 8.5367e-08, 4.5306e-08, 7.2989e-08,\n             5.2704e-08, 6.2881e-08, 9.8640e-08, 8.3910e-08, 3.1206e-08, 6.5031e-08,\n             8.2578e-08, 4.5373e-08, 3.0568e-08, 1.1473e-07, 3.2696e-08, 6.8815e-08,\n             4.7082e-08, 1.3308e-07, 1.0101e-07, 1.3855e-07, 7.3805e-08, 4.1149e-08,\n             5.2278e-08, 7.7306e-08, 5.1822e-08, 8.9210e-08, 1.2116e-07, 8.6002e-08,\n             4.8932e-08, 6.1548e-08, 3.9378e-08, 1.3595e-07, 1.0046e-07, 7.1206e-08,\n             5.7770e-08, 9.0594e-08, 7.6542e-08, 6.1556e-08, 1.0545e-07, 7.1830e-08,\n             2.3285e-08, 9.4308e-08, 4.6399e-08, 7.3129e-08, 1.0182e-07, 4.8039e-08,\n             8.5111e-08, 1.1988e-07, 5.9514e-08, 9.9993e-08, 6.1300e-08, 1.0360e-07,\n             6.4180e-08, 1.7429e-07, 6.1135e-08, 6.5016e-08, 8.7752e-08, 4.0934e-08,\n             5.0376e-08, 9.0935e-08, 1.1977e-07, 1.4358e-07, 5.1978e-08, 6.5613e-08,\n             8.4806e-08, 3.8770e-08, 3.2140e-08, 7.6303e-08, 1.0910e-07, 4.9245e-08,\n             7.4491e-08, 6.4307e-08, 4.4591e-08, 1.1591e-07, 6.4861e-08, 3.6802e-08,\n             1.1230e-07, 7.5664e-08, 7.9951e-08, 8.6200e-08, 4.0494e-08, 5.3844e-08,\n             7.2813e-08, 7.8266e-08, 3.9504e-08, 1.0676e-07, 1.0306e-07, 1.3000e-07,\n             5.1679e-08, 4.7082e-08, 4.6026e-08, 9.6544e-08, 6.2441e-08, 8.1606e-08,\n             8.0373e-08, 8.9025e-08, 1.0890e-07, 4.4840e-08, 1.5168e-07, 7.2067e-08,\n             1.0488e-07, 1.2165e-07, 9.6747e-08, 8.9777e-08, 7.8993e-08, 4.0616e-08,\n             1.0046e-07, 8.6313e-08, 9.2866e-08, 8.1685e-08, 7.1179e-08, 4.1343e-08,\n             5.6976e-08, 4.3676e-08, 6.7132e-08, 6.2959e-08, 6.0232e-08, 1.4902e-07,\n             6.5435e-08, 9.6335e-08, 1.0188e-07, 1.1315e-07, 6.1132e-08, 7.0738e-08,\n             5.3025e-08, 9.1945e-08, 8.2938e-08, 7.9270e-08, 7.2666e-08, 9.1151e-08,\n             4.2323e-08, 6.2415e-08, 3.1402e-08, 2.9244e-08, 7.0515e-08, 4.0341e-08,\n             3.5468e-08, 8.3191e-08, 5.9898e-08, 6.3347e-08, 9.4353e-08, 1.0298e-07,\n             7.3245e-08, 4.2110e-08, 1.2130e-07, 6.9663e-08, 7.2663e-08, 2.5317e-08,\n             7.7758e-08, 4.5895e-08, 4.9498e-08, 9.8785e-08, 6.4257e-08, 5.6031e-08,\n             8.8135e-08, 8.6209e-08, 4.7125e-08, 6.4266e-08, 5.0910e-08, 5.3218e-08,\n             8.9986e-08, 4.1331e-08, 7.8035e-08, 5.8623e-08, 4.2823e-08, 1.5332e-07,\n             4.9159e-08, 5.1277e-08, 1.1196e-07, 4.7542e-08, 7.2348e-08, 7.6166e-08,\n             6.9485e-08, 1.3616e-07, 5.2255e-08, 4.4574e-08, 7.2977e-08, 7.6473e-08,\n             4.1481e-08, 1.0033e-07, 7.7609e-08, 9.7444e-08, 3.1878e-08, 4.7350e-08,\n             9.1298e-08, 1.0497e-07, 5.1694e-08, 7.9258e-08, 6.5146e-08, 1.0139e-07,\n             8.1655e-08, 1.7221e-07, 2.4555e-08, 4.6285e-08, 5.0887e-08, 9.3239e-08,\n             4.6398e-08, 5.8853e-08, 4.6944e-08, 4.4022e-08, 9.1134e-08, 1.0276e-07,\n             5.4041e-08, 5.4463e-08, 6.5584e-08, 3.4890e-08, 9.5990e-08, 9.8735e-08,\n             6.3774e-08, 6.8615e-08, 5.8224e-08, 1.2140e-07, 4.7864e-08, 4.8148e-08,\n             4.5222e-08, 6.3161e-08, 7.4512e-08, 3.8777e-08, 6.5106e-08, 4.5586e-08,\n             9.4273e-08, 7.2728e-08, 6.2331e-08, 4.7045e-08, 4.8720e-08, 4.7759e-08,\n             5.7613e-08, 1.2174e-07, 6.9478e-08, 8.3227e-08, 9.4598e-08, 8.3964e-08,\n             6.9684e-08, 8.3831e-08, 2.0341e-07, 9.4529e-08, 9.6617e-08, 2.0368e-07,\n             1.4867e-07, 6.0287e-08, 1.0218e-07, 9.5721e-08, 9.7299e-08, 5.9751e-08,\n             1.1155e-07, 1.2416e-07, 3.0978e-08, 4.3862e-08, 8.9003e-08, 1.0542e-07,\n             8.1481e-08, 6.0918e-08, 6.0382e-08, 9.6555e-08, 5.3080e-08, 6.5041e-08,\n             5.8635e-08, 8.1731e-08, 2.9555e-08, 4.9876e-08, 1.1842e-07, 7.3130e-08,\n             5.7443e-08, 3.3450e-08, 1.1326e-07, 1.0051e-07, 8.2640e-08, 6.3550e-08,\n             1.0804e-07, 1.3436e-07, 4.4850e-08, 7.8247e-08, 6.7303e-08, 4.7798e-08,\n             6.2993e-08, 7.0690e-08, 8.5906e-08, 3.7836e-08, 5.3190e-08, 6.7075e-08,\n             6.3716e-08, 1.1487e-07, 1.0210e-07, 6.2302e-08, 3.1006e-08, 9.3076e-08,\n             7.5070e-08, 1.0132e-07, 5.8656e-08, 5.1212e-08, 8.2201e-08, 1.6758e-07,\n             3.8809e-08, 6.3224e-08, 2.9127e-07, 7.9047e-08, 1.8356e-07, 5.1683e-08,\n             6.9634e-08, 5.0431e-08, 5.7264e-08, 1.5323e-07, 4.9638e-08, 8.0399e-08,\n             9.6168e-08, 8.0330e-08, 9.6957e-08, 6.3124e-08, 4.4846e-08, 8.4686e-08,\n             5.3326e-08, 7.6149e-08, 4.4364e-08, 7.7743e-08, 5.6323e-08, 5.7071e-08,\n             3.9977e-08, 4.1472e-08, 6.2535e-08, 8.4379e-08, 4.2318e-08, 6.1470e-08,\n             7.2985e-08, 5.1733e-08, 8.8336e-08, 9.2229e-08, 7.2984e-08, 8.9795e-08,\n             5.8216e-08, 6.2727e-08, 1.0266e-07, 6.3457e-08, 8.6365e-08, 1.1717e-07,\n             8.7876e-08, 8.2876e-08, 9.8495e-08, 5.6128e-08, 4.5931e-08, 3.3538e-08,\n             4.5517e-08, 8.4635e-08, 5.9500e-08, 3.2148e-08, 9.9424e-08, 4.0737e-08,\n             1.0835e-07, 4.0614e-08, 5.1371e-08, 5.3741e-08, 1.4811e-07, 7.9942e-08,\n             3.7194e-08, 9.8717e-08, 1.1585e-07, 5.5368e-08, 1.2303e-07, 1.9634e-08,\n             1.1164e-07, 1.3099e-07, 6.4679e-08, 7.1046e-08, 4.0797e-08, 4.1350e-08,\n             6.6061e-08, 4.6128e-08, 3.9098e-08, 9.3788e-08, 1.0590e-07, 4.1290e-08,\n             9.4479e-08, 4.6394e-08, 3.7670e-08, 7.3285e-08, 5.1987e-08, 1.3472e-07,\n             5.9468e-08, 2.2255e-07, 5.1704e-08, 3.3941e-08, 5.2909e-08, 5.0873e-08,\n             6.1756e-08, 6.9989e-08, 4.1160e-08, 1.0811e-07, 4.8640e-08, 3.4074e-08,\n             1.7919e-07, 6.2915e-08, 8.5630e-08, 5.6887e-08, 1.1431e-07, 9.8477e-08,\n             6.0622e-08, 2.8710e-08, 6.8929e-08, 1.1561e-07, 7.5628e-08, 7.3344e-08,\n             1.4003e-07, 1.1489e-07, 7.7806e-08, 5.7202e-08, 7.3525e-08, 9.4294e-08,\n             3.7957e-08, 8.9786e-08, 7.6559e-08, 8.4711e-08, 1.0159e-07, 4.3429e-08,\n             8.1416e-08, 1.1344e-07, 3.1795e-08, 4.5668e-08, 1.1057e-07, 3.8297e-08,\n             3.4054e-08, 4.8792e-08, 7.9051e-08, 6.1848e-08, 5.6473e-08, 7.3453e-08,\n             6.8226e-08, 9.0281e-08, 9.1865e-08, 2.6650e-08, 2.2280e-08, 5.9497e-08,\n             7.4920e-08, 5.4958e-08, 3.2418e-08, 2.8269e-08, 9.0432e-08, 8.1942e-08,\n             3.4416e-08, 6.7286e-08])},\n    88: {'exp_avg': tensor([ 4.6336e-05, -4.8317e-05, -5.1086e-04,  1.3208e-04, -3.3119e-05,\n              3.2627e-05, -2.3952e-05,  9.6162e-05, -1.2503e-05, -2.6425e-04,\n             -3.0730e-05, -3.2037e-05, -1.2536e-04,  6.9459e-05, -1.2116e-04,\n              1.5478e-04,  1.7605e-04, -1.8401e-04, -1.0398e-04, -2.1800e-04,\n             -8.5504e-05,  4.6414e-05, -2.2563e-05, -1.1753e-04, -1.1057e-04,\n             -2.6967e-04, -6.4927e-05, -8.0335e-05, -8.9930e-05,  7.3872e-05,\n              1.1542e-04,  2.0110e-04, -4.2660e-05,  8.6286e-05,  9.8365e-05,\n             -5.9202e-07, -1.9723e-04,  2.6752e-05, -1.8782e-04, -3.7610e-05,\n              1.0288e-04,  4.6636e-05,  1.7436e-04, -3.3352e-04, -1.6216e-04,\n              1.0594e-05,  9.2212e-05,  2.8643e-04,  1.1101e-04, -1.4143e-04,\n              1.2395e-04,  2.4407e-04,  7.9471e-05, -6.7347e-05,  1.3464e-04,\n              3.8677e-05, -8.6721e-05,  6.7586e-05, -1.0646e-05,  2.4714e-06,\n              3.2071e-05, -7.9639e-05,  9.8022e-05,  3.6202e-05, -2.2060e-04,\n              1.1784e-04, -9.6199e-05,  1.4719e-05,  9.8046e-05,  7.0418e-05,\n              2.1988e-05, -1.8115e-04, -7.4452e-05,  2.2184e-05, -7.3154e-05,\n              3.2556e-05,  1.6020e-04, -4.4732e-05, -4.3531e-05, -2.1369e-04,\n              1.0106e-04,  2.7297e-06,  6.5212e-05, -5.1438e-05,  1.9791e-04,\n              2.5888e-05, -4.7522e-05,  1.9795e-04, -4.7533e-05,  7.6028e-07,\n             -1.4279e-04, -3.0966e-05, -9.6384e-05, -4.4661e-05, -4.9555e-05,\n              8.1032e-05,  7.7720e-04, -1.0853e-04, -2.7866e-05,  8.1421e-05,\n             -1.4592e-04, -7.6937e-05,  1.8187e-04, -1.7582e-04,  7.8069e-05,\n              1.3377e-05, -3.5926e-04,  8.0840e-05,  9.0285e-05,  2.2065e-04,\n             -1.3714e-04, -3.9089e-05, -3.7752e-05,  4.4499e-05, -3.4941e-05,\n             -4.4933e-05,  1.1549e-04,  1.1226e-05,  8.6736e-05, -6.7443e-05,\n              2.4928e-04,  2.1623e-04,  1.5236e-05, -1.6876e-04, -1.4996e-04,\n             -5.7293e-05, -8.5554e-06,  8.6957e-05,  1.1618e-04,  1.0196e-04,\n             -8.7537e-05, -1.1500e-04, -3.4535e-05, -2.0980e-05, -2.3861e-04,\n             -2.3753e-04,  2.0002e-04,  9.8251e-05,  4.7336e-05,  1.5531e-04,\n             -8.7358e-05,  4.9707e-05, -1.5404e-04,  1.6742e-04,  5.8394e-05,\n             -2.0650e-05,  4.0077e-05, -1.5599e-04, -6.5914e-05,  8.8493e-05,\n              7.8650e-05, -1.6771e-04,  2.3437e-04,  1.7219e-04, -1.7391e-04,\n             -5.0868e-05,  1.1575e-04, -7.6457e-05,  2.1022e-05,  6.7547e-05,\n              3.7915e-05,  8.6335e-05, -7.4312e-05, -1.1413e-04, -4.7311e-05,\n             -1.1883e-04, -7.8256e-05,  2.6516e-05,  3.0417e-05,  1.5129e-04,\n              9.4274e-05,  4.6455e-06, -1.0749e-04,  3.7892e-05,  2.1074e-04,\n              1.2713e-04,  3.0114e-05, -9.2199e-05, -3.9435e-04, -1.1632e-05,\n              4.2062e-05, -8.0935e-05,  5.7105e-06,  7.2078e-05,  3.5661e-05,\n              1.1514e-04, -5.2931e-05, -5.1444e-05, -1.1968e-04, -7.6256e-05,\n             -1.9207e-04, -1.2876e-04, -5.7686e-05,  1.2146e-05,  1.6098e-04,\n             -5.5424e-05, -9.0602e-05, -1.3275e-05,  1.9337e-06, -6.3933e-05,\n             -1.3462e-04,  3.8139e-05,  8.8452e-04, -9.3862e-05,  5.0258e-05,\n             -2.8082e-04,  1.3826e-04, -1.6557e-04,  1.1302e-04, -3.3227e-04,\n             -7.6708e-05,  1.3113e-04, -5.6086e-05,  1.1560e-04, -6.5209e-05,\n              3.9074e-04,  4.7833e-06,  1.8352e-04,  3.3014e-05,  7.4115e-05,\n             -7.0073e-05,  1.9065e-04,  9.5837e-05,  2.0138e-05,  1.8227e-04,\n              6.7740e-07,  2.5511e-04, -3.9233e-06,  2.1985e-05,  5.8880e-05,\n              2.9810e-06, -1.5694e-06, -2.7023e-06,  2.1850e-05,  3.5572e-05,\n             -7.1385e-05,  3.2711e-05,  2.8696e-04,  5.3196e-05,  8.0462e-05,\n              1.0506e-04, -1.0108e-05,  2.0073e-04, -2.2268e-04, -3.4882e-05,\n              2.8950e-05, -6.2110e-05,  1.0667e-05, -9.1769e-05, -1.4437e-04,\n              1.4111e-04,  8.4508e-05,  1.2969e-05,  2.8088e-05, -2.2074e-04,\n             -1.2046e-04, -4.0401e-05,  2.4451e-05, -9.8882e-05,  5.6826e-05,\n             -1.9326e-05,  9.7278e-05,  2.2020e-05, -1.8586e-04,  1.6604e-04,\n             -1.5646e-04,  1.4836e-04, -3.6542e-05, -1.6058e-04,  6.3070e-05,\n              1.3068e-04,  8.8432e-05, -8.1612e-05,  1.2516e-04, -2.5263e-05,\n              6.6610e-05,  3.2792e-05,  8.1927e-05,  2.3030e-04,  7.4951e-05,\n              1.5501e-04, -2.9731e-05,  1.3157e-04, -1.0148e-04, -1.2673e-05,\n             -8.3384e-05,  7.1000e-05, -2.3925e-04, -5.9986e-05, -1.5350e-04,\n             -6.5114e-05,  5.9842e-05, -9.8957e-05,  2.8502e-05, -1.7029e-04,\n              1.0217e-04, -1.6533e-04, -2.3724e-05,  1.8678e-04,  2.9772e-05,\n              1.1285e-04, -1.5087e-04,  1.4612e-04, -2.5023e-04, -3.4387e-05,\n             -2.3260e-04, -2.1606e-04, -1.1981e-05, -1.5827e-04,  3.6314e-06,\n              4.3493e-05,  7.7863e-06,  9.3115e-05, -4.2981e-05,  8.9395e-05,\n              1.7090e-05, -4.6024e-05, -1.5887e-04, -7.4082e-05, -1.1535e-04,\n             -6.2058e-05, -6.1966e-05,  1.7761e-05, -7.7471e-05,  5.2410e-05,\n              1.0169e-04,  4.7589e-05, -1.5968e-04, -2.5708e-04,  1.8868e-05,\n             -5.6283e-05, -2.4542e-05,  4.0750e-06, -1.4945e-06, -5.3089e-05,\n             -9.6163e-05,  1.3194e-04,  1.8686e-05, -9.8240e-06,  3.3055e-04,\n              4.9036e-05, -6.8464e-05, -3.9151e-05,  1.2488e-04, -1.1540e-04,\n             -1.5369e-05,  6.3560e-05, -2.1014e-05, -1.1257e-04,  1.9793e-04,\n              1.4760e-04,  2.3957e-05,  1.1117e-04,  1.5999e-04, -1.5641e-04,\n             -4.5242e-05, -3.3102e-04,  2.5646e-04, -1.4086e-04,  3.6455e-05,\n             -1.7920e-04,  1.0429e-04, -1.9499e-04,  1.9017e-04, -6.0824e-06,\n              2.7770e-05, -1.1474e-04,  1.6825e-04, -5.0378e-05, -7.1804e-05,\n              7.7673e-05,  1.0363e-04, -5.1026e-05,  7.5145e-05, -1.1338e-04,\n             -1.8075e-05,  2.3496e-04, -1.1760e-04,  5.5338e-05,  9.5287e-05,\n             -1.8296e-04,  2.3826e-05,  1.6775e-04, -1.0267e-04,  8.5379e-05,\n             -1.9154e-04,  1.3075e-04,  5.3249e-05,  9.0462e-05, -1.7019e-04,\n              2.4992e-04,  1.0170e-04, -3.9237e-05,  2.0234e-05,  2.0285e-05,\n              1.2543e-04, -2.8017e-05, -1.1016e-04, -2.3407e-04,  1.0712e-04,\n              8.5618e-05, -1.1024e-04, -1.9349e-04,  3.5621e-05, -1.3158e-04,\n             -1.0641e-04,  4.2295e-05,  1.6732e-04, -8.4709e-05,  1.7373e-04,\n             -1.1516e-04,  1.1657e-04,  8.5732e-05,  3.9986e-05,  2.1620e-05,\n              4.4787e-06,  8.9689e-05, -7.9131e-06, -4.9370e-06, -2.0634e-04,\n              1.1758e-05, -1.9146e-05, -2.2663e-05,  1.0380e-06, -1.1798e-04,\n              2.9069e-04, -9.3422e-05,  1.3020e-05,  2.7293e-04,  2.6625e-04,\n              6.1972e-05,  2.8689e-05, -1.2974e-04, -1.3306e-05, -2.4050e-05,\n             -9.0962e-05, -2.4638e-05, -1.6209e-04, -5.8231e-05,  1.0542e-05,\n             -6.8548e-05,  6.7807e-06,  1.0465e-05,  2.8745e-05,  3.3500e-05,\n             -9.7935e-05,  8.2570e-05, -7.4698e-05,  1.8018e-05, -3.3748e-05,\n              8.1158e-06, -2.3901e-04, -6.8012e-06, -2.4331e-04, -7.0657e-05,\n              1.2278e-04,  2.8268e-04, -9.5068e-05, -7.9709e-06, -3.5928e-05,\n              2.5984e-05,  1.3791e-04, -7.2578e-05,  4.1661e-06,  6.2641e-05,\n              1.9791e-04, -4.4215e-05,  1.9968e-04, -1.8560e-05,  7.5443e-05,\n              1.1405e-04, -1.6621e-04, -1.7763e-04, -1.6374e-04, -1.2688e-05,\n             -4.2972e-05,  1.1042e-04,  6.2748e-05,  9.6616e-05,  1.2927e-04,\n              1.2031e-05,  7.3017e-05, -4.0984e-05, -2.7818e-04, -2.2813e-04,\n              1.3548e-04,  1.7992e-04,  1.4715e-04,  7.4033e-05, -2.8866e-04,\n              6.9734e-05,  1.6413e-04,  1.2783e-05, -2.2395e-04,  3.3506e-06,\n              1.0991e-04, -9.9510e-05,  5.6968e-06,  1.1488e-04, -1.0385e-04,\n              2.7431e-05,  3.6052e-05, -1.5019e-04, -1.3028e-04, -1.1027e-04,\n             -7.7087e-05, -2.3823e-05, -1.3584e-04,  1.6542e-04,  2.0867e-04,\n              3.7670e-05,  8.7601e-05]),\n     'exp_avg_sq': tensor([4.4101e-08, 4.3262e-08, 9.1128e-08, 3.8731e-08, 3.5891e-08, 2.9965e-08,\n             3.7752e-08, 3.7482e-08, 3.1966e-08, 4.6784e-08, 4.0712e-08, 3.2957e-08,\n             3.3059e-08, 3.2608e-08, 2.9940e-08, 4.9532e-08, 3.4354e-08, 3.4668e-08,\n             3.5567e-08, 4.3696e-08, 4.8874e-08, 3.3135e-08, 5.0289e-08, 2.3806e-08,\n             3.9245e-08, 6.1191e-08, 3.6556e-08, 4.0739e-08, 5.1183e-08, 2.1139e-08,\n             5.8271e-08, 4.0710e-08, 4.3895e-08, 5.3443e-08, 4.3043e-08, 3.8513e-08,\n             3.8093e-08, 2.9743e-08, 3.6176e-08, 4.4099e-08, 4.4345e-08, 3.4854e-08,\n             2.9101e-08, 8.8102e-08, 3.7089e-08, 3.5324e-08, 3.1343e-08, 6.5290e-08,\n             2.9232e-08, 4.4710e-08, 3.3974e-08, 3.6475e-08, 4.0902e-08, 3.2706e-08,\n             4.6806e-08, 5.6573e-08, 6.4248e-08, 2.9586e-08, 2.8032e-08, 2.5796e-08,\n             3.4733e-08, 3.5124e-08, 6.8717e-08, 3.0879e-08, 4.4239e-08, 3.2618e-08,\n             4.5199e-08, 3.0446e-08, 3.9587e-08, 4.7613e-08, 4.4670e-08, 3.1700e-08,\n             2.6412e-08, 5.1280e-08, 4.5797e-08, 4.6628e-08, 2.9088e-08, 4.9293e-08,\n             5.3112e-08, 4.3208e-08, 5.1338e-08, 2.7057e-08, 3.6400e-08, 2.5469e-08,\n             2.1050e-08, 2.7941e-08, 5.1958e-08, 3.5999e-08, 4.3579e-08, 3.9431e-08,\n             4.7051e-08, 3.8985e-08, 4.6501e-08, 3.2595e-08, 3.2806e-08, 3.6081e-08,\n             2.8067e-07, 3.9686e-08, 3.9325e-08, 4.3848e-08, 3.7529e-08, 4.6292e-08,\n             3.3384e-08, 4.6419e-08, 4.3611e-08, 3.8158e-08, 4.0168e-08, 5.1557e-08,\n             3.7067e-08, 3.0354e-08, 3.6104e-08, 2.8833e-08, 4.2552e-08, 3.4040e-08,\n             3.4118e-08, 2.7038e-08, 6.3012e-08, 2.8095e-08, 4.7753e-08, 3.6608e-08,\n             5.6304e-08, 3.8793e-08, 4.0416e-08, 3.8611e-08, 4.3082e-08, 4.6213e-08,\n             3.3779e-08, 4.1039e-08, 3.2244e-08, 4.2209e-08, 3.6744e-08, 2.9842e-08,\n             5.3081e-08, 3.4761e-08, 4.3615e-08, 3.1259e-08, 3.3883e-08, 5.1340e-08,\n             3.4180e-08, 3.9113e-08, 5.1893e-08, 4.9003e-08, 3.2395e-08, 3.6063e-08,\n             3.0646e-08, 2.5215e-08, 3.0365e-08, 2.9217e-08, 3.3667e-08, 3.2294e-08,\n             4.4170e-08, 3.6483e-08, 4.1756e-08, 3.5835e-08, 6.1643e-08, 4.2106e-08,\n             2.8746e-08, 3.1147e-08, 3.4939e-08, 4.2825e-08, 3.2739e-08, 4.2655e-08,\n             2.3330e-08, 3.5322e-08, 3.7094e-08, 3.5433e-08, 3.6149e-08, 3.1909e-08,\n             2.1125e-08, 4.3073e-08, 4.2205e-08, 3.0035e-08, 6.6280e-08, 4.5730e-08,\n             3.6755e-08, 3.2827e-08, 8.2024e-08, 3.9283e-08, 4.8621e-08, 3.0621e-08,\n             3.5976e-08, 2.7975e-08, 6.0928e-08, 3.3419e-08, 4.0073e-08, 6.6696e-08,\n             3.5612e-08, 4.2986e-08, 3.8680e-08, 4.1171e-08, 4.9720e-08, 4.0779e-08,\n             3.8862e-08, 4.1436e-08, 5.4526e-08, 4.2552e-08, 3.5283e-08, 3.9877e-08,\n             3.3979e-08, 2.5327e-08, 4.3294e-08, 3.2225e-08, 4.3942e-07, 3.4243e-08,\n             3.6306e-08, 2.8638e-08, 3.1822e-08, 4.2722e-08, 4.2246e-08, 6.1295e-08,\n             5.1491e-08, 4.3717e-08, 3.3761e-08, 3.9423e-08, 4.6080e-08, 3.5900e-07,\n             4.4572e-08, 4.0256e-08, 3.3858e-08, 3.3254e-08, 4.0699e-08, 5.3439e-08,\n             5.0602e-08, 3.1030e-08, 2.3706e-08, 4.7044e-08, 2.8075e-08, 4.6378e-08,\n             3.4849e-08, 4.6299e-08, 3.3862e-08, 4.0116e-08, 3.1372e-08, 2.7848e-08,\n             4.3091e-08, 3.9314e-08, 4.0017e-08, 7.3662e-08, 3.4606e-08, 4.0152e-08,\n             2.7352e-08, 4.6359e-08, 3.8564e-08, 4.6436e-08, 3.7647e-08, 3.5853e-08,\n             3.9232e-08, 4.3146e-08, 5.0051e-08, 3.3179e-08, 4.2268e-08, 4.2445e-08,\n             3.9902e-08, 3.4944e-08, 3.7049e-08, 3.3050e-08, 5.6775e-08, 3.1898e-08,\n             4.1016e-08, 2.9596e-08, 4.1033e-08, 2.4702e-08, 3.7352e-08, 3.4360e-08,\n             4.0778e-08, 4.8067e-08, 4.6621e-08, 5.2836e-08, 4.1389e-08, 4.1634e-08,\n             4.1748e-08, 3.9758e-08, 4.2749e-08, 5.1135e-08, 2.9174e-08, 2.9891e-08,\n             4.1250e-08, 3.4215e-08, 4.3108e-08, 3.7955e-08, 3.3209e-08, 4.9282e-08,\n             3.7460e-08, 4.1149e-08, 3.7092e-08, 3.6861e-08, 3.4636e-08, 5.2457e-08,\n             3.2978e-08, 4.3738e-08, 4.4295e-08, 4.4240e-08, 3.5610e-08, 6.1569e-08,\n             3.5971e-08, 2.5701e-08, 6.2562e-08, 3.6541e-08, 5.5153e-08, 4.3486e-08,\n             4.3505e-08, 3.5000e-08, 3.8452e-08, 4.0744e-08, 3.7640e-08, 4.1884e-08,\n             4.5266e-08, 2.6116e-08, 2.7901e-08, 4.7004e-08, 2.7605e-08, 4.2327e-08,\n             3.4678e-08, 2.8026e-08, 5.6559e-08, 3.0322e-08, 3.7869e-08, 3.8040e-08,\n             3.0324e-08, 4.9029e-08, 3.9105e-08, 5.1743e-08, 3.9942e-08, 3.3466e-08,\n             2.9264e-08, 2.7931e-08, 3.9821e-08, 3.4938e-08, 6.7453e-08, 4.3483e-08,\n             3.0397e-08, 3.9469e-08, 3.4620e-08, 3.1658e-08, 6.0047e-08, 5.0503e-08,\n             3.7121e-08, 4.3511e-08, 4.9708e-08, 2.9203e-08, 3.9979e-08, 2.9013e-08,\n             4.1632e-08, 3.8699e-08, 2.9135e-08, 3.2059e-08, 3.7084e-08, 3.2099e-08,\n             3.7370e-08, 4.5567e-08, 4.2481e-08, 3.0263e-08, 3.7663e-08, 5.1728e-08,\n             3.7200e-08, 4.0320e-08, 4.8364e-08, 1.4028e-07, 7.1123e-08, 1.6979e-07,\n             2.7168e-08, 4.7658e-08, 3.7290e-08, 4.6262e-08, 3.3926e-08, 4.3091e-08,\n             2.8218e-08, 4.4492e-08, 5.5259e-08, 2.8861e-08, 3.4134e-08, 5.6723e-08,\n             2.8700e-08, 4.4273e-08, 3.4371e-08, 3.8385e-08, 4.0644e-08, 3.3942e-08,\n             3.7065e-08, 4.1643e-08, 4.0948e-08, 4.5156e-08, 3.7210e-08, 6.1579e-08,\n             5.4806e-08, 4.1793e-08, 9.5409e-08, 4.7163e-08, 3.0498e-08, 3.8099e-08,\n             5.2453e-08, 3.8710e-08, 4.6654e-08, 1.1039e-07, 4.6795e-08, 3.4137e-08,\n             5.4303e-08, 4.2593e-08, 3.6420e-08, 4.1566e-08, 3.1746e-08, 5.4153e-08,\n             5.3052e-08, 3.3915e-08, 3.0389e-08, 5.9116e-08, 3.5404e-08, 3.1437e-08,\n             4.0332e-08, 3.8531e-08, 4.6799e-08, 2.1662e-08, 4.3117e-08, 3.8704e-08,\n             4.3599e-08, 1.6270e-07, 4.9147e-08, 2.3221e-08, 3.8780e-08, 5.6492e-08,\n             3.2964e-08, 2.7916e-08, 5.9359e-08, 3.1835e-08, 3.8423e-08, 6.5242e-08,\n             3.6525e-08, 6.2684e-08, 3.3825e-08, 4.2744e-08, 4.0754e-08, 5.6568e-08,\n             3.6411e-08, 4.0754e-08, 4.1602e-08, 2.7288e-08, 4.8636e-08, 3.8352e-08,\n             3.8076e-08, 7.0690e-08, 2.9542e-08, 4.3448e-08, 3.7499e-08, 4.6542e-08,\n             6.0119e-08, 4.0804e-08, 8.0280e-08, 3.9446e-08, 3.3405e-08, 3.1147e-08,\n             4.8462e-08, 4.2373e-08, 2.9185e-08, 3.4427e-08, 3.6243e-08, 2.5742e-08,\n             3.5350e-08, 4.0020e-08, 2.4549e-08, 4.6878e-08, 4.1242e-08, 1.1402e-07,\n             2.4679e-08, 3.3684e-08, 3.7912e-08, 3.7255e-08, 4.0790e-08, 5.6556e-08,\n             2.7021e-08, 4.1672e-08, 4.0045e-08, 3.8151e-08, 4.0384e-08, 4.8498e-08,\n             2.8369e-08, 3.8797e-08, 3.4915e-08, 2.7050e-08, 3.5368e-08, 3.1382e-08,\n             3.5650e-08, 4.0531e-08, 3.9964e-08, 3.5022e-08, 3.9420e-08, 3.5310e-08,\n             3.9567e-08, 4.6725e-08, 4.0504e-08, 3.7710e-08, 5.0500e-08, 3.4659e-08,\n             2.9833e-08, 5.5092e-08, 3.0629e-08, 4.1066e-08, 4.8699e-08, 2.6952e-08,\n             4.1398e-08, 3.0295e-08, 4.0809e-08, 4.2509e-08, 3.0806e-08, 4.1214e-08,\n             5.4233e-08, 3.2474e-08, 3.7778e-08, 2.9372e-08, 3.2464e-08, 4.0929e-08,\n             2.7083e-08, 2.6204e-08])},\n    89: {'exp_avg': tensor([ 4.4334e-05,  4.9771e-05, -2.1036e-04,  1.6230e-04, -5.8876e-06,\n              1.0074e-04, -9.1179e-05,  9.5458e-05,  2.1236e-05, -1.4246e-04,\n             -3.0637e-05,  3.8555e-05, -5.1422e-05,  4.3227e-05, -3.7903e-05,\n              1.2403e-04,  1.3003e-04, -1.8532e-04, -1.5182e-05, -2.0279e-04,\n             -1.1743e-04, -4.8429e-05,  2.8751e-05, -1.0437e-04, -1.2301e-04,\n             -1.7038e-04, -6.7050e-05, -2.8714e-05, -1.4842e-04,  1.0075e-04,\n              2.2254e-04,  1.9102e-04,  4.7821e-05,  4.8560e-06,  4.7536e-05,\n             -6.9985e-05, -1.5447e-04, -9.8989e-06, -1.0867e-04, -8.3887e-05,\n              1.3061e-04,  8.1546e-06,  1.5416e-04, -1.9691e-04, -7.7717e-05,\n              2.9917e-05,  8.9611e-05,  2.1207e-04,  3.8460e-05, -2.0133e-04,\n              5.8162e-06,  1.0570e-04,  6.6064e-05, -2.2561e-05, -2.3650e-05,\n             -3.5616e-05, -1.2162e-04,  9.3068e-05, -7.9566e-06, -2.4193e-05,\n              2.0828e-05,  1.8115e-05,  4.2842e-05, -4.7250e-05, -1.0258e-04,\n              1.0431e-04, -5.1184e-06, -1.2758e-05,  6.8515e-05, -3.6553e-05,\n              2.8037e-05, -8.5105e-05, -6.7073e-05,  2.4849e-05, -2.7059e-05,\n             -9.0443e-07,  6.1837e-05, -4.0374e-05, -7.8891e-05, -1.3415e-04,\n              1.1281e-04,  5.0962e-05, -2.0393e-05,  1.9436e-05,  9.4107e-05,\n             -1.6593e-05, -5.5387e-06,  7.8912e-05, -7.2441e-05, -2.6357e-05,\n             -4.4866e-06, -1.0148e-04, -3.5232e-05, -4.2274e-05, -7.8063e-06,\n             -1.0844e-05,  1.3703e-04, -3.0536e-05, -1.4981e-04,  2.0676e-04,\n             -3.2487e-05, -3.3640e-05,  7.8960e-05, -3.3853e-05,  9.3318e-06,\n              3.2239e-05, -4.8526e-05, -8.2941e-06,  5.6758e-05,  1.1288e-04,\n             -6.4269e-05, -2.4979e-06, -9.7945e-05,  1.2194e-04,  2.7741e-06,\n              6.4478e-05,  1.4527e-04, -2.1029e-05,  2.7463e-05, -8.7370e-05,\n              5.8233e-05,  3.3002e-05,  1.2530e-06, -1.0798e-04, -5.2504e-05,\n             -1.0922e-04,  5.6157e-05,  8.6744e-05, -1.9570e-05,  4.5026e-05,\n              1.0937e-05, -1.0549e-04,  2.5530e-06, -2.8893e-05, -1.0219e-04,\n             -1.4962e-04,  1.7746e-04, -3.5411e-05, -2.2294e-05,  6.3837e-05,\n             -1.1990e-04, -5.2358e-05, -5.6908e-05,  1.1224e-04, -4.1001e-05,\n             -5.8488e-06,  2.4880e-05, -7.6618e-05,  9.9894e-06,  1.4951e-04,\n              5.4424e-05, -1.2639e-04,  1.7478e-04,  1.2645e-04, -2.3228e-04,\n              1.2506e-04,  7.9397e-05,  4.5748e-05,  2.4752e-05, -3.6076e-07,\n              5.2712e-05,  1.0212e-04, -5.4447e-05, -4.3104e-05,  6.3522e-05,\n             -7.2442e-05, -1.7947e-05, -1.3864e-04,  3.8137e-05,  7.3794e-05,\n              7.9239e-05,  1.0405e-04, -4.6877e-05,  7.0573e-05,  1.4955e-05,\n              5.4212e-05,  3.0478e-05, -1.5580e-04, -2.2213e-04,  5.2691e-05,\n             -1.1024e-05, -1.1232e-04, -2.8726e-05,  1.1688e-04,  8.0565e-05,\n              1.4204e-04, -1.6985e-05,  3.7719e-05, -5.5537e-05, -1.0122e-04,\n             -9.3125e-05,  1.2291e-05,  4.1489e-05, -4.2614e-05,  3.8270e-05,\n             -4.7030e-05, -2.1801e-04,  2.5618e-05,  2.6451e-05, -8.2752e-05,\n             -4.3863e-05,  8.4700e-05,  1.6706e-04, -6.9533e-05,  8.0885e-05,\n             -1.1262e-04,  9.1358e-05, -9.7227e-05,  7.9473e-05, -2.1215e-04,\n             -5.6694e-05, -2.1304e-05, -1.4571e-05,  4.2166e-05, -1.2105e-05,\n             -2.3002e-04,  8.8159e-05,  9.7424e-05,  4.3180e-05,  1.9117e-05,\n              2.8149e-05,  9.1155e-05,  1.6421e-04, -5.8137e-05,  1.8583e-04,\n             -2.0136e-05,  1.5215e-04,  4.8244e-05,  6.8090e-06,  5.2161e-06,\n             -4.5764e-05,  1.0163e-04, -2.6876e-05, -1.0147e-04,  6.1731e-05,\n             -1.0336e-04,  4.9552e-05,  2.6681e-04,  4.0370e-05,  4.8123e-05,\n              4.0631e-05, -5.6975e-05,  1.6909e-04, -1.8348e-04, -3.6170e-06,\n              1.2132e-04, -9.8321e-05, -1.4621e-05, -7.4903e-06, -1.2436e-04,\n              1.4585e-04,  1.5562e-04,  1.9510e-05, -5.4883e-05, -1.6122e-04,\n             -2.2560e-04, -1.9635e-05, -1.4109e-06, -1.1315e-04,  3.8288e-05,\n              2.5578e-05,  3.0997e-05, -4.9682e-05, -1.9961e-04,  7.2511e-05,\n             -3.1294e-05,  1.8827e-04, -6.7763e-05, -1.1177e-04,  2.4005e-05,\n              4.3631e-05,  3.7276e-05, -1.3601e-04,  1.0530e-05,  6.2434e-06,\n              1.7808e-05,  3.6248e-05,  1.1642e-04,  1.0947e-04,  9.1344e-05,\n             -4.7023e-05, -4.5799e-05,  5.1826e-05, -3.8494e-05, -3.6842e-05,\n             -2.9065e-06,  5.1600e-05, -1.4046e-04, -2.8920e-05,  4.4013e-05,\n             -3.9100e-05,  5.6338e-05, -1.2396e-04,  8.7842e-05, -1.5210e-04,\n              2.1409e-05, -7.8413e-05,  1.8663e-05,  1.2689e-04,  1.0121e-05,\n              2.0756e-05, -5.8683e-05,  6.8195e-07, -4.0913e-05, -1.2478e-04,\n             -1.1803e-04, -1.6518e-04,  2.1930e-05, -2.2529e-05, -6.3811e-05,\n              4.0021e-05, -3.4778e-05, -4.8971e-05, -1.8506e-05,  6.9853e-05,\n             -8.3312e-06,  3.3010e-05, -4.5741e-05, -1.1650e-05, -2.6353e-05,\n             -1.5667e-04,  2.0240e-05,  3.6550e-05, -6.0284e-05,  3.4977e-05,\n             -1.2622e-04, -6.3853e-06, -6.1653e-05, -1.3217e-04, -1.1270e-04,\n             -7.5743e-05, -2.7529e-05, -7.2456e-05, -8.9285e-05, -5.0213e-05,\n             -1.4779e-04,  9.9428e-05,  1.3436e-05,  2.5734e-05,  2.5534e-04,\n              8.2118e-05, -1.5191e-04, -4.4309e-05,  9.5461e-05, -1.1944e-04,\n              2.9925e-05,  9.7500e-06,  1.7475e-05, -1.1787e-04,  2.2435e-05,\n              8.1708e-05,  6.1639e-05,  5.8039e-05,  1.1284e-04, -1.8276e-04,\n             -1.1956e-04, -1.5777e-04,  9.8659e-05, -1.0570e-04,  1.0102e-05,\n             -1.4027e-04,  5.3459e-05, -1.0376e-04,  3.1044e-04, -9.7329e-05,\n              1.7154e-04, -2.9310e-05,  1.6688e-04, -1.2433e-06, -1.4854e-05,\n              9.5452e-05,  1.2320e-04, -6.4074e-05,  5.1859e-06, -7.3706e-05,\n              2.0745e-06,  9.7987e-05, -1.2287e-04,  6.7398e-05, -7.3632e-05,\n             -5.1699e-05, -4.8581e-05, -6.3709e-05, -1.3344e-04, -2.1301e-05,\n             -8.1263e-06, -6.5759e-05, -5.9772e-05,  8.4403e-05, -2.1295e-04,\n              8.1775e-05, -4.3455e-05, -2.4513e-05,  1.1413e-04,  5.2395e-05,\n              1.3909e-04,  5.4433e-05,  2.2605e-05, -1.1722e-04,  2.0524e-04,\n             -4.9449e-06, -9.2322e-06, -1.0522e-04,  4.4459e-06, -7.5741e-05,\n             -1.3653e-04,  6.1704e-05,  8.5391e-05, -2.8601e-05,  2.1456e-04,\n             -2.6021e-06,  7.9203e-05,  1.5715e-05,  4.4754e-05,  2.6060e-05,\n             -7.3599e-05, -3.7635e-06, -1.3200e-05, -1.5390e-05, -9.9783e-05,\n             -6.1685e-05, -9.7292e-06,  3.2711e-05, -4.6102e-05, -9.0518e-06,\n              1.3711e-04, -4.5816e-05,  3.6701e-05,  2.0758e-04,  1.1059e-04,\n             -1.7675e-05, -5.9349e-05, -8.4646e-05, -1.9598e-05,  5.5656e-05,\n             -1.7080e-04,  1.2023e-04, -5.3527e-05, -2.0743e-04,  6.2251e-05,\n              4.2656e-05, -2.8186e-05, -2.9922e-05, -1.1585e-05,  7.4674e-06,\n             -6.8884e-05,  1.7035e-05, -1.0238e-05, -3.4741e-05, -9.9925e-05,\n              8.3604e-05, -1.5599e-04,  5.2727e-05, -2.8475e-05, -2.1190e-05,\n              5.1884e-05,  1.5287e-04, -4.5269e-05, -5.4544e-06, -2.5807e-06,\n              4.4065e-05,  6.0096e-05, -1.0850e-05, -8.3068e-06,  2.6501e-05,\n              6.3324e-05, -1.6265e-04,  1.2347e-04,  3.1123e-05, -3.8851e-06,\n              7.5203e-05, -1.6256e-04, -9.3779e-05, -1.2805e-04,  2.2442e-05,\n              2.6651e-05,  5.3982e-05,  1.8820e-05, -5.4544e-06,  1.5667e-04,\n             -9.9363e-05,  2.3118e-05, -9.1139e-05, -1.9275e-04, -1.7571e-04,\n              3.9849e-05,  1.2210e-04,  1.2445e-04, -9.9274e-06, -1.7838e-04,\n             -1.8524e-05,  6.9754e-05,  3.6342e-05,  4.5456e-05,  3.1193e-05,\n              7.2983e-05, -1.0135e-04, -4.2796e-05,  4.5976e-05, -3.0592e-05,\n             -1.7113e-05,  2.8941e-05, -3.0514e-06, -9.5530e-05,  1.7033e-05,\n             -8.1364e-05, -5.2612e-06, -9.1750e-05,  7.2644e-05,  1.4009e-04,\n              3.2964e-05,  9.0236e-05]),\n     'exp_avg_sq': tensor([2.3799e-08, 2.2005e-08, 3.7278e-08, 2.4592e-08, 1.9813e-08, 2.4070e-08,\n             2.2772e-08, 2.0641e-08, 1.7239e-08, 2.9558e-08, 2.0513e-08, 1.0738e-08,\n             1.5845e-08, 2.0607e-08, 1.6667e-08, 2.0766e-08, 2.4035e-08, 2.7918e-08,\n             2.7321e-08, 2.6945e-08, 3.1438e-08, 1.7209e-08, 2.3253e-08, 1.4209e-08,\n             2.2391e-08, 2.6791e-08, 2.0750e-08, 2.5187e-08, 3.1033e-08, 1.4359e-08,\n             2.5479e-08, 2.1537e-08, 2.1761e-08, 2.1153e-08, 2.1706e-08, 2.3776e-08,\n             2.4262e-08, 1.9001e-08, 2.3993e-08, 2.1457e-08, 2.8014e-08, 2.1703e-08,\n             1.4134e-08, 3.4034e-08, 2.1673e-08, 2.0750e-08, 1.7836e-08, 3.2632e-08,\n             2.2830e-08, 3.0960e-08, 2.0332e-08, 1.8652e-08, 2.1015e-08, 2.1666e-08,\n             2.1929e-08, 2.9695e-08, 2.5525e-08, 1.6901e-08, 1.7581e-08, 2.6715e-08,\n             1.8263e-08, 1.6821e-08, 2.8283e-08, 1.7670e-08, 2.6000e-08, 2.0895e-08,\n             2.3110e-08, 1.8458e-08, 2.7793e-08, 2.5922e-08, 2.9578e-08, 1.9569e-08,\n             1.9404e-08, 2.6859e-08, 1.8798e-08, 2.0588e-08, 1.6395e-08, 2.0291e-08,\n             3.2093e-08, 2.4840e-08, 2.2639e-08, 2.3476e-08, 2.3810e-08, 1.4824e-08,\n             1.2005e-08, 1.7663e-08, 3.3331e-08, 2.4966e-08, 2.1081e-08, 2.4930e-08,\n             2.6720e-08, 1.7751e-08, 2.1929e-08, 1.7792e-08, 2.3807e-08, 2.2170e-08,\n             4.1708e-08, 2.1991e-08, 2.1422e-08, 2.7959e-08, 2.4454e-08, 1.8883e-08,\n             1.8162e-08, 2.3295e-08, 2.4808e-08, 2.1717e-08, 2.3176e-08, 2.7117e-08,\n             2.3443e-08, 1.3071e-08, 2.1210e-08, 2.5388e-08, 1.9275e-08, 2.2855e-08,\n             2.6099e-08, 1.0870e-08, 2.1034e-08, 1.8647e-08, 1.7766e-08, 2.5082e-08,\n             2.1787e-08, 2.0545e-08, 2.3693e-08, 3.0497e-08, 2.1545e-08, 2.3994e-08,\n             1.3781e-08, 2.1247e-08, 2.1663e-08, 2.5274e-08, 2.3122e-08, 2.2188e-08,\n             2.2508e-08, 2.0251e-08, 2.0926e-08, 2.0645e-08, 1.9384e-08, 2.3755e-08,\n             1.7695e-08, 1.8980e-08, 3.1569e-08, 2.3920e-08, 2.0734e-08, 1.7826e-08,\n             1.8050e-08, 1.5892e-08, 1.8012e-08, 2.1558e-08, 1.6266e-08, 2.0580e-08,\n             2.0443e-08, 2.9438e-08, 2.1213e-08, 2.3456e-08, 2.2016e-08, 3.1629e-08,\n             1.9890e-08, 1.9351e-08, 1.4631e-08, 2.3513e-08, 1.9078e-08, 2.5511e-08,\n             1.1614e-08, 2.2164e-08, 2.3788e-08, 2.1819e-08, 2.2189e-08, 2.5378e-08,\n             1.0844e-08, 2.2229e-08, 2.1977e-08, 1.2047e-08, 1.7207e-08, 2.8264e-08,\n             2.2769e-08, 1.8095e-08, 3.1391e-08, 1.9595e-08, 2.7034e-08, 1.9949e-08,\n             1.6695e-08, 1.2916e-08, 2.5870e-08, 2.2186e-08, 2.0650e-08, 2.7728e-08,\n             1.7397e-08, 2.8672e-08, 2.6693e-08, 2.3679e-08, 2.1522e-08, 2.1754e-08,\n             2.4856e-08, 2.1747e-08, 3.1141e-08, 1.9577e-08, 2.7994e-08, 2.7267e-08,\n             1.3641e-08, 1.7160e-08, 2.1237e-08, 2.5219e-08, 3.2444e-08, 2.4514e-08,\n             1.7847e-08, 1.8061e-08, 1.6908e-08, 2.1920e-08, 1.9511e-08, 2.5548e-08,\n             2.6925e-08, 2.0326e-08, 2.1175e-08, 1.9478e-08, 2.4686e-08, 3.3937e-08,\n             2.2683e-08, 1.8142e-08, 2.3193e-08, 2.3818e-08, 1.9285e-08, 2.7221e-08,\n             2.2221e-08, 1.8594e-08, 1.4028e-08, 2.7647e-08, 1.5100e-08, 3.0682e-08,\n             1.6450e-08, 2.4486e-08, 2.1480e-08, 2.6306e-08, 1.7837e-08, 2.0471e-08,\n             2.5114e-08, 2.3391e-08, 1.4847e-08, 2.8404e-08, 1.8012e-08, 2.2623e-08,\n             1.6519e-08, 2.0699e-08, 2.4708e-08, 2.1762e-08, 2.2118e-08, 2.1307e-08,\n             2.8787e-08, 2.7738e-08, 2.8717e-08, 1.9355e-08, 2.2623e-08, 2.9486e-08,\n             2.3879e-08, 2.1188e-08, 1.9980e-08, 1.9076e-08, 2.4907e-08, 1.8797e-08,\n             2.4318e-08, 2.1298e-08, 1.1679e-08, 1.5674e-08, 2.5126e-08, 2.1936e-08,\n             2.0572e-08, 1.9169e-08, 2.5997e-08, 1.4679e-08, 1.8932e-08, 2.5083e-08,\n             2.6517e-08, 2.2656e-08, 2.1794e-08, 2.9748e-08, 1.5520e-08, 1.9949e-08,\n             2.3878e-08, 1.9147e-08, 2.1053e-08, 1.7568e-08, 2.2728e-08, 2.3748e-08,\n             2.0102e-08, 2.0771e-08, 1.9410e-08, 1.3190e-08, 2.2175e-08, 2.6208e-08,\n             2.1227e-08, 1.9963e-08, 2.5075e-08, 1.2083e-08, 2.0602e-08, 2.1807e-08,\n             2.0036e-08, 1.8724e-08, 1.4890e-08, 1.6954e-08, 2.4318e-08, 2.8329e-08,\n             2.5809e-08, 2.1471e-08, 2.2285e-08, 2.1984e-08, 2.2301e-08, 2.5358e-08,\n             2.8831e-08, 2.0693e-08, 1.8842e-08, 2.2478e-08, 1.8659e-08, 2.6143e-08,\n             2.3608e-08, 2.1611e-08, 2.5769e-08, 1.5382e-08, 2.4720e-08, 1.8213e-08,\n             1.6704e-08, 2.1474e-08, 2.8308e-08, 1.9137e-08, 2.3097e-08, 1.2388e-08,\n             1.7755e-08, 2.0873e-08, 1.6671e-08, 1.8107e-08, 2.6611e-08, 2.3383e-08,\n             1.6312e-08, 1.7625e-08, 2.2350e-08, 2.6971e-08, 1.9747e-08, 2.1843e-08,\n             2.0282e-08, 2.4943e-08, 1.9717e-08, 1.8818e-08, 2.0793e-08, 1.9653e-08,\n             2.4379e-08, 2.3635e-08, 1.4860e-08, 2.0867e-08, 1.4937e-08, 2.2945e-08,\n             2.0056e-08, 2.5637e-08, 2.5273e-08, 2.0393e-08, 2.1170e-08, 2.3740e-08,\n             1.9279e-08, 2.2265e-08, 2.2802e-08, 2.7026e-08, 2.8938e-08, 3.9729e-09,\n             1.3570e-08, 2.2038e-08, 1.9751e-08, 2.9021e-08, 2.1253e-08, 2.4756e-08,\n             1.2068e-08, 2.1639e-08, 2.7139e-08, 2.0076e-08, 2.2739e-08, 3.0579e-08,\n             2.0611e-08, 2.1143e-08, 1.4812e-08, 2.5441e-08, 1.8929e-08, 2.6098e-08,\n             1.8745e-08, 2.3556e-08, 2.3241e-08, 2.3528e-08, 2.4723e-08, 2.4388e-08,\n             2.4206e-08, 2.5779e-08, 2.9591e-08, 2.1922e-08, 2.3861e-08, 2.8063e-08,\n             2.7330e-08, 1.7232e-08, 2.6117e-08, 2.9491e-08, 2.0541e-08, 2.4431e-08,\n             2.3697e-08, 2.2227e-08, 1.9385e-08, 2.1505e-08, 1.7497e-08, 2.5236e-08,\n             2.6363e-08, 1.8747e-08, 2.4552e-08, 2.5561e-08, 1.9943e-08, 2.2278e-08,\n             2.4604e-08, 2.3401e-08, 2.4303e-08, 1.1831e-08, 2.1090e-08, 1.9113e-08,\n             2.4874e-08, 3.9308e-08, 2.7659e-08, 1.2269e-08, 2.4258e-08, 2.8963e-08,\n             1.8104e-08, 1.9597e-08, 2.0712e-08, 2.0033e-08, 2.2246e-08, 2.8073e-08,\n             2.2865e-08, 1.6784e-08, 1.6517e-08, 2.1442e-08, 2.2008e-08, 2.7352e-08,\n             1.6742e-08, 1.7562e-08, 2.0358e-08, 2.1691e-08, 2.3644e-08, 2.7943e-08,\n             2.6656e-08, 2.3779e-08, 1.5963e-08, 2.2071e-08, 2.3665e-08, 2.6456e-08,\n             2.5799e-08, 2.3281e-08, 2.9334e-08, 2.2380e-08, 1.9936e-08, 1.5187e-08,\n             1.9334e-08, 2.5027e-08, 1.8445e-08, 4.5164e-08, 2.1602e-08, 1.4641e-08,\n             2.7218e-08, 1.4556e-08, 1.7177e-08, 2.5511e-08, 2.6038e-08, 2.9961e-08,\n             1.4829e-08, 1.7698e-08, 2.2157e-08, 2.4928e-08, 2.2469e-08, 2.3737e-08,\n             1.9186e-08, 2.8337e-08, 1.5168e-08, 3.0249e-08, 2.0445e-08, 2.5853e-08,\n             2.0523e-08, 2.3883e-08, 1.6772e-08, 1.5556e-08, 1.7707e-08, 1.8249e-08,\n             2.7043e-08, 2.0563e-08, 2.1218e-08, 2.0570e-08, 2.2893e-08, 2.0403e-08,\n             2.3559e-08, 2.6731e-08, 2.3752e-08, 2.4716e-08, 2.0954e-08, 1.8252e-08,\n             2.1774e-08, 2.5342e-08, 1.8994e-08, 2.3347e-08, 2.5893e-08, 1.4381e-08,\n             2.5465e-08, 2.1551e-08, 3.0558e-08, 2.5469e-08, 2.1563e-08, 2.3255e-08,\n             1.4195e-08, 1.4757e-08, 2.2757e-08, 1.8889e-08, 1.5304e-08, 2.5690e-08,\n             1.8025e-08, 1.7778e-08])},\n    90: {'exp_avg': tensor([-4.5176e-05, -2.3752e-04,  9.6717e-05,  ..., -1.4082e-04,\n             -1.1855e-04,  9.8818e-05]),\n     'exp_avg_sq': tensor([1.5505e-08, 3.0372e-08, 2.5158e-08,  ..., 2.6485e-08, 2.7643e-08,\n             2.7330e-08])},\n    91: {'exp_avg': tensor([ 2.8331e-05,  1.4288e-04, -6.2271e-05,  ..., -3.9158e-05,\n              4.1950e-05,  7.9655e-05]),\n     'exp_avg_sq': tensor([7.8864e-09, 1.4664e-08, 1.2573e-08,  ..., 1.7217e-08, 1.5473e-08,\n             1.1651e-08])},\n    92: {'exp_avg': tensor([-4.7663e-05,  2.0826e-04,  5.7103e-06,  ..., -1.1648e-04,\n              9.4595e-05,  1.0010e-04]),\n     'exp_avg_sq': tensor([1.7979e-08, 4.3733e-08, 2.7682e-08,  ..., 3.8246e-08, 4.2428e-08,\n             2.4345e-08])},\n    93: {'exp_avg': tensor([ 2.8331e-05,  1.4288e-04, -6.2271e-05,  ..., -3.9158e-05,\n              4.1950e-05,  7.9655e-05]),\n     'exp_avg_sq': tensor([7.8864e-09, 1.4664e-08, 1.2573e-08,  ..., 1.7217e-08, 1.5473e-08,\n             1.1651e-08])},\n    94: {'exp_avg': tensor([ 1.2674e-04, -1.4368e-04, -5.8569e-05,  1.6986e-04, -8.8275e-05,\n             -2.3225e-05,  7.9773e-05,  1.1126e-04, -2.3999e-04,  6.2632e-05,\n             -3.6487e-04, -4.7472e-04,  2.6599e-04,  1.2132e-04,  5.6241e-05,\n             -1.1498e-04,  3.3775e-04,  2.4967e-04, -7.1976e-05, -2.3552e-04,\n             -1.4290e-05, -6.2036e-05, -8.7473e-04, -2.0334e-04, -8.6714e-05,\n              1.7624e-04,  2.2100e-04, -6.5898e-04, -3.6857e-04, -3.1750e-04,\n             -1.2305e-04, -3.5559e-04,  1.7216e-04, -1.4105e-04,  2.6690e-04,\n              1.4874e-04,  4.4957e-05, -1.1299e-04, -5.3282e-05,  2.1309e-04,\n              1.9065e-04, -3.3826e-04, -1.1274e-04, -3.0245e-05, -1.5571e-05,\n             -3.3230e-05, -2.6580e-05,  1.1332e-04,  5.0167e-04, -2.3145e-04,\n             -2.1780e-04, -2.5378e-04,  1.5596e-04,  1.8487e-04, -1.7353e-05,\n             -1.3523e-04,  5.0636e-04, -1.4647e-04, -4.1218e-06,  2.3200e-04,\n             -2.2875e-04, -3.8074e-04,  4.4705e-04, -1.6066e-04,  1.7215e-04,\n              7.1071e-05,  1.7315e-05,  1.1827e-04,  1.5699e-04, -3.2808e-04,\n             -5.4195e-05,  7.1122e-06,  2.4436e-04,  1.7645e-05, -1.4394e-05,\n              1.7066e-04,  2.7423e-04,  6.4186e-05, -1.5321e-04,  3.4871e-04,\n             -1.6220e-04, -1.0456e-04,  2.1206e-04,  9.1085e-05, -2.5825e-04,\n             -1.3945e-04, -6.0460e-04,  3.2279e-04,  1.3545e-04,  3.4881e-04,\n             -2.9315e-06,  2.4821e-04,  9.4646e-05,  1.8128e-04,  3.6048e-05,\n              2.1522e-04,  9.3799e-05, -2.0086e-04, -2.5804e-05,  2.6256e-04,\n             -1.3273e-04,  4.3527e-04, -3.6568e-04,  4.8947e-05, -2.9091e-04,\n             -2.6054e-05, -3.6879e-05,  3.2318e-04, -3.1654e-05, -4.4629e-05,\n             -8.4966e-05,  1.6522e-05, -1.9374e-05, -4.6308e-05,  3.3424e-04,\n              3.9626e-05, -1.0720e-04,  1.7763e-04,  4.0660e-05,  9.7567e-05,\n              1.7043e-04,  2.2009e-04, -4.2671e-04, -2.4033e-04,  1.6891e-04,\n             -2.3445e-04,  1.1376e-04,  4.1364e-04,  6.4888e-05,  2.3289e-04,\n             -2.0871e-04,  2.6769e-04, -1.3525e-05, -1.7091e-05, -1.6399e-04,\n              1.3978e-04, -5.4665e-04, -1.0977e-04, -1.7588e-04,  1.3669e-04,\n             -3.6033e-04,  1.5868e-04,  4.1112e-04,  2.0135e-04,  6.6087e-05,\n              7.0906e-05,  3.6042e-05, -2.1629e-04, -8.4007e-05, -2.9840e-04,\n             -7.8915e-05, -1.2706e-05,  1.7800e-05,  4.1194e-04, -9.1537e-05,\n              8.7271e-05,  2.6350e-04, -2.0399e-04,  1.6099e-05, -1.5030e-04,\n             -3.7278e-04,  1.8838e-04, -1.8457e-04, -5.4629e-05,  4.7970e-04,\n             -3.0274e-04, -3.4637e-04, -6.3076e-05, -5.5867e-05,  7.5708e-05,\n              2.8575e-04,  6.9693e-04, -6.5329e-05, -1.4583e-04, -2.5372e-04,\n              1.6777e-04, -4.9880e-05,  2.0604e-05, -2.0030e-04, -1.4370e-04,\n             -3.6383e-04,  3.1520e-04, -1.0236e-04, -6.7153e-05,  4.4587e-05,\n              4.4991e-04,  6.8076e-05, -5.6418e-05,  3.1762e-04, -2.3791e-04,\n             -1.4420e-04, -4.2938e-04, -2.8513e-04, -2.5361e-04, -3.0850e-04,\n              4.5827e-05, -1.8522e-04, -1.6577e-04, -1.2402e-04, -3.0324e-04,\n              4.0333e-04, -1.7264e-04,  5.6644e-04,  1.2655e-04, -3.5259e-05,\n             -1.6871e-04, -2.5296e-04,  9.2968e-04, -2.5476e-04,  2.5383e-04,\n             -5.7384e-04,  2.8028e-05, -2.0618e-04, -1.4224e-04, -3.8118e-05,\n              1.6120e-04,  3.4001e-04,  8.9029e-05,  1.5881e-04, -4.3655e-06,\n              2.7909e-05, -1.1480e-05, -8.2609e-05,  3.3650e-05,  3.6952e-05,\n             -4.6147e-04, -2.7314e-04,  1.9953e-04, -1.0268e-04, -3.2954e-04,\n              1.3868e-05,  6.1687e-04, -8.8389e-05,  2.4756e-05, -3.3986e-05,\n              5.0492e-04, -4.9880e-04,  1.4776e-04,  5.3731e-05,  1.6959e-04,\n              2.3505e-04,  4.1533e-05,  1.4188e-04,  2.8843e-04,  5.6222e-04,\n             -1.6309e-04,  1.5763e-04,  5.5070e-04,  2.3041e-04, -9.0390e-05,\n             -1.2350e-04, -3.2087e-04, -3.9535e-04, -2.5420e-04,  6.2038e-04,\n             -3.8474e-04, -1.9092e-04,  7.6849e-05,  8.7366e-05,  3.8398e-05,\n             -7.1360e-04,  3.9296e-04,  8.9224e-06, -2.7964e-04, -5.4931e-04,\n              4.0941e-05,  5.3325e-05,  8.4777e-05, -3.8658e-05, -5.2216e-04,\n              1.9294e-04, -9.0232e-05,  2.8706e-04,  4.4596e-05, -8.4592e-05,\n              2.4836e-04, -3.7434e-04,  8.3274e-05, -3.9607e-04, -3.5053e-04,\n              2.7329e-04,  1.4436e-04, -4.3900e-05, -1.2432e-04,  7.0859e-05,\n             -4.6109e-05, -2.8850e-04, -1.3967e-04, -8.3570e-05, -2.2968e-04,\n              2.8514e-04,  1.5537e-04,  1.0237e-05, -6.5193e-06,  9.0474e-04,\n             -1.6128e-04, -1.1765e-04,  8.1965e-05, -2.2412e-04,  2.3391e-04,\n              3.1187e-04, -5.6411e-04,  2.8825e-04,  8.7071e-05,  1.0162e-04,\n              7.8898e-05,  2.8781e-04, -2.4862e-04,  9.8537e-05, -3.7709e-04,\n              1.6311e-04,  1.2681e-05,  4.2177e-04,  2.5960e-05, -4.7621e-04,\n              1.0450e-04, -3.7107e-04,  1.8236e-04,  2.4526e-04, -9.7500e-06,\n              3.5273e-05,  7.2048e-05,  2.8631e-05,  2.8501e-05, -9.1596e-05,\n              6.8429e-05, -4.1543e-04, -2.0264e-04, -1.6431e-04, -4.9573e-05,\n              1.9973e-04, -9.0238e-05,  2.1490e-05, -1.9070e-04,  1.5174e-04,\n              2.0232e-04,  2.1357e-04,  1.5448e-04, -2.6311e-05, -2.6608e-04,\n              2.0876e-04,  1.1961e-04,  3.9106e-04, -3.9243e-04, -3.7272e-04,\n             -1.2043e-04, -1.4014e-04,  1.9984e-05, -4.6532e-05, -3.0905e-04,\n              2.9041e-05,  3.7165e-04, -1.4114e-04, -2.1565e-04,  5.8481e-05,\n             -1.9197e-05, -5.0867e-04, -2.6023e-04, -1.8689e-04, -4.0953e-04,\n              4.2561e-04,  4.3694e-04,  3.2383e-04,  2.5873e-04,  2.4179e-04,\n              2.8116e-05, -5.8193e-05,  2.0017e-04, -1.6814e-04, -1.7197e-04,\n              1.7330e-04, -3.5639e-04, -8.8894e-05, -3.7907e-05, -1.2792e-04,\n             -5.7580e-05,  5.7287e-05, -1.2571e-04, -5.8173e-05,  2.8987e-04,\n             -1.7742e-04,  7.9393e-05, -4.4662e-04, -1.1723e-04,  9.4924e-05,\n              2.5323e-04,  7.0448e-05, -1.8364e-05, -3.8049e-04, -1.8788e-05,\n              2.1084e-04,  3.2304e-04,  3.0490e-04,  3.1454e-05,  1.0284e-04,\n             -1.3048e-04,  3.5534e-05, -3.4448e-04,  3.7802e-04,  2.8855e-05,\n             -7.0476e-05,  4.4006e-04,  2.0849e-04,  3.8951e-04,  2.7734e-04,\n             -1.5691e-04, -4.1202e-05, -1.7927e-04,  7.8249e-05,  8.4420e-05,\n             -1.7997e-05, -1.6617e-04,  3.9008e-04, -7.2996e-05,  3.3086e-05,\n             -3.8136e-04, -2.2274e-04, -1.4577e-04, -1.0068e-05, -8.0898e-05,\n              4.0831e-05, -2.5202e-04, -4.9640e-04,  8.9612e-05,  1.4150e-04,\n             -1.6781e-04,  4.0569e-04,  2.4120e-04,  2.6091e-04,  4.7320e-04,\n              2.8328e-04,  1.9625e-04,  1.5868e-04, -3.3208e-04, -2.4179e-04,\n             -6.9339e-04,  1.1616e-04, -2.4947e-04,  6.3280e-05,  7.8984e-05,\n              4.2472e-04,  5.3781e-04,  1.3421e-04, -3.6718e-04, -9.4808e-05,\n             -3.9815e-04,  2.8959e-04,  1.2475e-04, -6.2648e-05, -6.7272e-04,\n             -9.7951e-05,  2.2073e-04,  4.7911e-05,  2.2557e-04, -5.3512e-04,\n              2.5599e-04, -1.2813e-04, -4.0433e-04,  1.8050e-06, -1.4091e-04,\n             -9.7033e-05, -1.9249e-04,  3.4125e-04, -2.7414e-04, -1.3445e-04,\n              3.0067e-04, -1.6872e-04,  2.7200e-05,  7.0519e-04,  3.2792e-04,\n              1.3739e-04,  1.2139e-04,  7.4639e-05,  4.6280e-05, -8.8887e-05,\n              4.3391e-04,  3.0845e-04, -2.5724e-04,  1.3598e-04, -4.7267e-04,\n             -2.8817e-04, -3.3997e-05, -1.3449e-04,  2.1409e-04,  3.0506e-05,\n              3.2026e-05, -1.9101e-05, -1.2485e-04,  5.1421e-04, -9.6663e-05,\n             -3.1729e-04, -9.6260e-05,  1.5071e-04,  1.7754e-04, -2.0405e-04,\n             -2.5337e-04, -7.9358e-05, -8.1004e-04, -1.1544e-04, -1.0257e-04,\n             -4.3468e-04, -1.9388e-04, -7.5663e-05, -9.6640e-05,  3.0687e-04,\n              1.2388e-04, -2.9218e-04, -2.1921e-04,  1.5420e-04, -2.3528e-04,\n              5.5326e-04,  2.7665e-04]),\n     'exp_avg_sq': tensor([1.6116e-07, 2.0856e-07, 3.2989e-07, 1.1657e-07, 1.7721e-07, 1.0933e-07,\n             1.7013e-07, 1.4195e-07, 1.8955e-07, 1.5249e-07, 1.0985e-07, 2.9762e-07,\n             2.2926e-07, 1.2724e-07, 1.1945e-07, 1.0430e-07, 2.4958e-07, 1.4513e-07,\n             1.1329e-07, 9.6098e-08, 1.0381e-07, 9.8247e-08, 3.2321e-07, 1.4104e-07,\n             1.1393e-07, 1.1402e-07, 1.7921e-07, 3.3214e-07, 1.8468e-07, 1.3572e-07,\n             1.4017e-07, 1.6740e-07, 1.9853e-07, 1.1043e-07, 2.1513e-07, 1.1396e-07,\n             1.1086e-07, 1.2909e-07, 1.7593e-07, 1.5152e-07, 2.0985e-07, 2.5864e-07,\n             2.6925e-07, 1.0739e-07, 1.0959e-07, 8.3729e-08, 8.8651e-08, 1.5714e-07,\n             1.9794e-07, 2.2781e-07, 1.7135e-07, 1.5233e-07, 1.1747e-07, 1.7210e-07,\n             1.9290e-07, 1.7875e-07, 1.8138e-07, 1.7286e-07, 1.9919e-07, 2.3571e-07,\n             1.2422e-07, 1.1164e-07, 1.4256e-07, 1.2529e-07, 7.2949e-08, 2.3538e-07,\n             9.6223e-08, 1.9961e-07, 1.0525e-07, 1.6343e-07, 2.3272e-07, 1.4149e-07,\n             1.5660e-07, 1.2947e-07, 1.6905e-07, 2.4602e-07, 2.2491e-07, 1.2546e-07,\n             1.3158e-07, 1.1172e-07, 1.1426e-07, 1.6364e-07, 1.3311e-07, 1.9627e-07,\n             1.9414e-07, 1.4842e-07, 1.9700e-07, 1.3651e-07, 1.3083e-07, 1.2954e-07,\n             2.1698e-07, 1.6326e-07, 1.0183e-07, 1.5019e-07, 2.1704e-07, 1.7139e-07,\n             1.2315e-07, 1.7720e-07, 1.5263e-07, 1.2905e-07, 2.0281e-07, 8.9768e-08,\n             1.4909e-07, 1.3596e-07, 1.3933e-07, 1.1701e-07, 1.2132e-07, 1.0261e-07,\n             1.4320e-07, 1.5994e-07, 1.8603e-07, 1.5043e-07, 7.5625e-08, 2.5360e-07,\n             2.6507e-07, 1.0641e-07, 9.3248e-08, 1.6482e-07, 1.4089e-07, 2.2056e-07,\n             1.6554e-07, 1.8772e-07, 1.2707e-07, 3.3054e-07, 1.4378e-07, 2.0032e-07,\n             1.1708e-07, 1.0519e-07, 9.2932e-08, 1.3902e-07, 1.4450e-07, 1.7136e-07,\n             1.5002e-07, 1.4757e-07, 1.6050e-07, 1.2927e-07, 1.8822e-07, 1.7952e-07,\n             1.5787e-07, 1.8092e-07, 1.1873e-07, 2.1345e-07, 3.1076e-07, 7.8069e-08,\n             1.3093e-07, 1.0945e-07, 1.0547e-07, 1.1887e-07, 1.1941e-07, 1.4415e-07,\n             1.2436e-07, 9.7172e-08, 1.5532e-07, 1.1057e-07, 1.2527e-07, 7.9497e-08,\n             1.2868e-07, 3.4665e-07, 1.5314e-07, 9.4683e-08, 1.6051e-07, 1.5417e-07,\n             1.9975e-07, 1.2951e-07, 1.5984e-07, 2.1017e-07, 4.4443e-07, 1.5729e-07,\n             1.8022e-07, 6.6285e-08, 1.8110e-07, 2.0948e-07, 8.8950e-08, 1.3379e-07,\n             1.9260e-07, 1.7451e-07, 2.9670e-07, 1.6823e-07, 1.3073e-07, 1.9695e-07,\n             1.7224e-07, 2.3923e-07, 1.2857e-07, 1.2484e-07, 1.0751e-07, 2.9884e-07,\n             1.7776e-07, 1.2138e-07, 1.6813e-07, 8.5098e-08, 1.5099e-07, 3.3496e-07,\n             1.6014e-07, 2.5489e-07, 1.2840e-07, 2.3897e-07, 1.1017e-07, 1.2019e-07,\n             1.5126e-07, 1.4656e-07, 2.7901e-07, 1.5993e-07, 1.3610e-07, 1.5276e-07,\n             1.2119e-07, 1.3851e-07, 1.3503e-07, 3.1502e-07, 1.1683e-07, 2.2413e-07,\n             1.2644e-07, 1.1835e-07, 1.1449e-07, 1.7575e-07, 1.1119e-07, 1.1262e-07,\n             1.4161e-07, 2.2002e-07, 1.2259e-07, 1.3620e-07, 1.2968e-07, 1.5508e-07,\n             1.7497e-07, 1.8554e-07, 1.2873e-07, 1.8159e-07, 2.0298e-07, 8.5988e-08,\n             1.3792e-07, 1.1072e-07, 1.6117e-07, 7.0976e-07, 1.2431e-07, 1.2101e-07,\n             8.3258e-08, 1.9306e-07, 2.8847e-07, 1.3677e-07, 1.0379e-07, 1.9824e-07,\n             2.0925e-07, 7.3242e-08, 8.7354e-08, 9.2288e-08, 2.8796e-07, 8.9984e-08,\n             2.3310e-07, 2.4458e-07, 1.6895e-07, 2.0651e-07, 8.4207e-08, 1.6733e-07,\n             3.5329e-07, 1.3839e-07, 1.5453e-07, 1.3696e-07, 1.9627e-07, 1.5784e-07,\n             1.5709e-07, 1.8489e-07, 3.8185e-07, 1.7185e-07, 1.8558e-07, 1.8471e-07,\n             1.9175e-07, 1.2894e-07, 9.0869e-08, 2.5996e-07, 1.2202e-07, 2.1784e-07,\n             1.1171e-07, 1.1119e-07, 1.5749e-07, 1.2952e-07, 1.7646e-07, 1.7735e-07,\n             1.2432e-07, 1.6947e-07, 8.1161e-08, 1.4549e-07, 1.5777e-07, 1.9795e-07,\n             3.4376e-07, 1.5615e-07, 1.2191e-07, 1.0321e-07, 1.5757e-07, 2.2385e-07,\n             1.2408e-07, 1.2033e-07, 8.9517e-08, 1.7856e-07, 2.1513e-07, 1.1699e-07,\n             2.8123e-07, 1.6089e-07, 1.1296e-07, 1.5473e-07, 2.6980e-07, 1.2573e-07,\n             2.0289e-07, 1.6706e-07, 1.5186e-07, 1.1813e-07, 1.5252e-07, 1.2175e-07,\n             1.3700e-07, 1.9696e-07, 1.5720e-07, 1.1889e-07, 1.2956e-07, 1.8845e-07,\n             1.5272e-07, 1.7847e-07, 1.3949e-07, 2.3218e-07, 1.2665e-07, 1.4692e-07,\n             1.5366e-07, 1.0766e-07, 1.6853e-07, 1.1602e-07, 1.9134e-07, 1.3866e-07,\n             1.1318e-07, 1.4534e-07, 1.2152e-07, 1.3189e-07, 2.6786e-07, 1.4541e-07,\n             1.0061e-07, 2.4451e-07, 1.0365e-07, 1.2731e-07, 1.8462e-07, 9.2546e-08,\n             1.3351e-07, 1.6284e-07, 2.2661e-07, 1.3776e-07, 1.1570e-07, 1.4928e-07,\n             2.2174e-07, 2.0446e-07, 1.1172e-07, 1.0729e-07, 1.8335e-07, 1.4392e-07,\n             1.4315e-07, 2.8277e-07, 1.6955e-07, 1.6561e-07, 1.1573e-07, 1.7193e-07,\n             2.0102e-07, 1.3378e-07, 1.7957e-07, 1.4020e-07, 1.6141e-07, 5.7018e-07,\n             1.2276e-07, 2.4042e-07, 1.6907e-07, 2.6026e-07, 9.2801e-08, 1.5609e-07,\n             1.4395e-07, 9.3197e-08, 1.4646e-07, 1.1879e-07, 1.4735e-07, 1.9079e-07,\n             1.4934e-07, 1.5995e-07, 1.5996e-07, 1.7204e-07, 1.1025e-07, 1.6138e-07,\n             8.7940e-08, 1.7598e-07, 1.5249e-07, 1.5247e-07, 1.4174e-07, 1.9306e-07,\n             9.3759e-08, 2.2744e-07, 1.5196e-07, 1.2974e-07, 1.7833e-07, 6.5376e-08,\n             8.6074e-08, 1.7438e-07, 1.1682e-07, 2.9610e-07, 9.4568e-08, 1.0231e-07,\n             1.2929e-07, 1.9197e-07, 1.6963e-07, 8.0632e-08, 2.3309e-07, 1.0963e-07,\n             2.7065e-07, 1.4111e-07, 1.9292e-07, 1.5942e-07, 1.6056e-07, 1.4955e-07,\n             1.0665e-07, 9.6384e-08, 8.6730e-08, 1.4649e-07, 1.3668e-07, 1.0007e-07,\n             1.3861e-07, 2.3313e-07, 2.1858e-07, 9.2227e-08, 1.2481e-07, 1.3913e-07,\n             1.5496e-07, 1.3566e-07, 1.4184e-07, 9.1198e-08, 7.7277e-08, 1.5264e-07,\n             1.3693e-07, 2.5143e-07, 2.2562e-07, 1.4817e-07, 2.7658e-07, 1.3970e-07,\n             1.1801e-07, 1.4175e-07, 1.5213e-07, 2.6189e-07, 9.8104e-08, 8.4860e-08,\n             1.6228e-07, 1.5222e-07, 1.4602e-07, 1.1034e-07, 8.1016e-08, 1.5624e-07,\n             1.8522e-07, 1.4065e-07, 2.0822e-07, 1.3887e-07, 8.2932e-08, 2.9693e-07,\n             1.7453e-07, 1.2445e-07, 1.0839e-07, 1.0419e-07, 1.6703e-07, 1.5197e-07,\n             1.3384e-07, 1.3757e-07, 1.1145e-07, 1.5219e-07, 1.9601e-07, 1.8440e-07,\n             2.1448e-07, 1.7191e-07, 1.1108e-07, 3.1035e-07, 2.0560e-07, 1.4463e-07,\n             2.0638e-07, 1.0274e-07, 1.5891e-07, 1.0773e-07, 1.3460e-07, 1.3403e-07,\n             2.2084e-07, 2.0914e-07, 1.5704e-07, 1.2075e-07, 1.7101e-07, 1.5751e-07,\n             1.7509e-07, 1.6166e-07, 1.1924e-07, 1.9973e-07, 1.3481e-07, 1.0523e-07,\n             1.2283e-07, 1.4055e-07, 1.7163e-07, 1.2040e-07, 3.4577e-07, 8.6839e-08,\n             1.7077e-07, 1.4305e-07, 2.1659e-07, 1.9711e-07, 1.6353e-07, 1.9067e-07,\n             1.8979e-07, 1.0823e-07, 1.3533e-07, 2.0544e-07, 1.8487e-07, 1.4706e-07,\n             2.5787e-07, 1.0348e-07, 2.1249e-07, 1.5606e-07, 1.4259e-07, 1.6333e-07,\n             4.5291e-07, 1.4600e-07])},\n    95: {'exp_avg': tensor([ 6.2115e-05,  6.4509e-06, -1.3143e-04,  1.0062e-04, -1.0278e-04,\n             -2.6140e-05,  6.6809e-05,  6.1471e-05, -1.1988e-04, -3.6382e-05,\n             -1.6607e-04, -3.3287e-04,  1.5572e-04, -7.7833e-06,  5.0207e-07,\n             -4.3046e-05,  2.1192e-04,  1.4500e-04, -7.1081e-05, -1.7362e-04,\n             -3.1355e-05,  5.1172e-05, -3.1997e-04, -1.3223e-04, -3.9717e-05,\n              8.6207e-05,  2.1073e-04, -3.3076e-04, -1.5250e-04, -1.4009e-04,\n             -5.0997e-05, -2.0123e-04,  1.5575e-04, -1.1054e-04,  1.8107e-04,\n              1.0599e-04,  2.9135e-05, -5.1110e-05, -1.0966e-04,  1.1686e-04,\n              9.2008e-05, -8.8840e-05, -7.7767e-05,  2.0428e-05,  1.3324e-05,\n             -9.1655e-05,  5.9293e-06, -1.1465e-05,  2.3971e-04, -1.1461e-04,\n             -2.2368e-05, -2.1594e-04,  6.8669e-05,  8.2552e-05,  1.1946e-05,\n             -6.9876e-05,  1.8455e-04, -1.1423e-04, -7.2826e-05,  1.0580e-04,\n             -1.5351e-04, -1.7881e-04,  1.5719e-04, -4.0969e-05,  1.2277e-04,\n             -1.5688e-05, -1.1434e-05, -1.4112e-05,  9.5856e-05, -7.6670e-05,\n             -2.5535e-05, -3.5059e-06,  7.7018e-05,  5.1945e-05,  5.1706e-05,\n              9.1709e-05,  1.3731e-04,  4.1615e-05, -9.4399e-05,  2.1811e-04,\n             -1.1213e-04, -1.0510e-04,  1.5913e-04,  1.0599e-05, -7.7074e-05,\n             -1.6531e-04, -2.8496e-04,  3.3871e-04,  4.0620e-05,  1.4170e-04,\n             -2.5122e-05,  4.9718e-05,  7.2540e-05,  4.8811e-05,  6.1662e-05,\n              1.6393e-04,  2.0677e-05, -9.5018e-05, -6.5301e-05,  1.1273e-04,\n             -2.1253e-05,  2.4093e-04, -1.4636e-04,  3.1352e-05, -1.8562e-04,\n              1.3888e-05,  4.3451e-06,  1.7478e-04, -4.3145e-05,  3.1568e-05,\n             -7.0433e-05,  3.2439e-05, -1.4900e-05, -2.0807e-05,  2.0472e-04,\n              5.3148e-05, -1.4883e-05,  7.3141e-05,  3.7720e-05,  8.6686e-05,\n              3.4589e-05,  9.4158e-05, -2.1744e-04, -1.5534e-04,  1.7889e-04,\n             -3.6736e-05,  1.5542e-05,  2.1748e-04, -4.6913e-05,  1.4519e-04,\n             -1.4576e-04,  8.7716e-05,  4.2489e-05, -8.6940e-05, -7.8847e-05,\n              1.0280e-04, -2.3983e-04, -3.4743e-05, -2.2425e-04,  7.3561e-05,\n             -2.4353e-04,  6.9021e-05,  7.8197e-05,  9.5203e-05, -6.3089e-05,\n              6.4795e-05,  2.0840e-06, -1.0753e-04, -3.9773e-05, -2.1995e-04,\n             -6.3826e-06, -2.7612e-05, -5.9100e-05,  2.0177e-04, -5.5149e-06,\n              5.9789e-05,  1.7724e-04, -1.3490e-04,  2.5777e-05, -1.6177e-04,\n             -1.3641e-04,  8.0190e-05, -4.8277e-05, -2.2588e-05,  1.6142e-04,\n             -1.4348e-04, -1.7062e-04, -4.7055e-05,  4.7316e-05,  6.9311e-05,\n             -2.2292e-05,  3.1443e-04,  1.7109e-05, -8.8923e-05, -1.8196e-04,\n              1.4545e-04, -9.5758e-05,  6.3105e-06, -8.3553e-05, -4.8594e-05,\n             -1.9530e-04,  1.3157e-04, -1.4718e-04,  2.2447e-05, -1.2141e-05,\n              6.0719e-04, -6.9585e-05, -7.8924e-05,  9.9699e-05, -1.0395e-04,\n             -1.6726e-04, -9.3175e-05, -8.5887e-05, -1.2324e-04, -1.6802e-04,\n             -3.4336e-05, -1.1924e-04, -1.4927e-04, -1.6309e-05, -7.5169e-05,\n              5.5878e-05, -5.3735e-05,  2.9234e-04,  1.4499e-04,  2.7697e-05,\n             -5.6931e-05, -1.6831e-04,  8.1565e-04, -7.5312e-05,  1.7696e-04,\n             -2.6705e-04, -1.6168e-05, -1.1505e-04, -1.8521e-05, -1.4852e-04,\n              2.7011e-05,  1.1577e-04, -5.1833e-05,  1.0438e-04,  3.7026e-05,\n             -1.7633e-05, -3.6629e-05, -4.2214e-05,  1.6666e-06,  2.7188e-05,\n             -3.3429e-04, -1.9084e-04,  8.2922e-05, -5.2829e-05, -2.1963e-04,\n             -2.6555e-05,  3.1347e-04, -2.0319e-05,  8.5870e-06,  3.3442e-07,\n              2.9471e-04, -2.4695e-04,  6.9604e-05,  3.0898e-05,  9.5409e-05,\n              1.0994e-04,  7.6410e-05,  1.0751e-04,  1.9178e-04,  2.5518e-04,\n             -9.1460e-05,  2.9438e-05,  2.5511e-04,  1.9503e-04, -4.3915e-05,\n             -6.1032e-05, -2.1384e-04, -1.6807e-04, -1.9919e-04,  2.2066e-04,\n             -2.2440e-04, -7.7797e-05, -5.0566e-05,  1.3536e-04, -3.3315e-05,\n             -3.5762e-04,  2.4333e-04, -2.5986e-05, -3.3666e-05, -2.1604e-04,\n              2.5525e-05,  1.4055e-05,  8.0409e-07, -8.8186e-05, -3.3139e-04,\n              1.1429e-04, -5.4791e-05,  1.4055e-04,  1.1617e-05, -4.6622e-07,\n              1.0887e-04, -2.0150e-04,  3.1109e-05, -1.8699e-04, -1.6830e-04,\n              1.7667e-04,  1.0459e-04, -1.4005e-05, -7.3474e-05, -1.6202e-05,\n              1.3046e-05, -1.2090e-04, -5.6417e-06, -3.7242e-05, -7.2270e-05,\n              1.3315e-04,  6.1876e-05,  6.6025e-06,  4.9653e-05,  3.5718e-04,\n             -8.2633e-05, -9.1497e-05,  6.4366e-05, -1.3108e-04,  1.3680e-04,\n              1.8846e-04, -3.1040e-04,  9.9332e-05, -2.1353e-05,  1.9384e-04,\n              1.2596e-04,  1.4046e-04, -2.0782e-04,  1.5073e-05, -1.1869e-04,\n              7.2294e-05, -1.5730e-05,  1.2554e-04,  6.7823e-05, -2.8495e-04,\n              7.5285e-05, -1.6404e-04,  9.1933e-05,  1.2081e-04, -4.7095e-05,\n              2.7819e-05,  3.8457e-05, -3.6191e-05,  1.3805e-05, -1.1787e-04,\n              2.3562e-05, -2.0860e-04, -1.3194e-04,  3.6129e-06, -8.9937e-05,\n              8.0727e-05, -5.4778e-05, -6.8035e-06, -1.2078e-04,  1.2315e-04,\n              9.0180e-05,  1.2261e-04,  9.7885e-05, -9.8708e-05, -1.6099e-04,\n              1.1020e-04,  3.1965e-05,  1.7386e-04, -1.9950e-04, -2.7456e-04,\n             -5.5576e-05, -7.3176e-05, -1.5858e-05, -6.2346e-05, -2.4460e-04,\n             -1.1028e-05,  6.8302e-05, -1.0698e-04, -2.1397e-04, -1.3284e-04,\n              2.8405e-05, -2.4123e-04, -8.9950e-05, -8.3492e-05, -1.6564e-04,\n              1.4311e-04,  1.8787e-04,  1.2687e-04, -4.6435e-06,  1.5545e-04,\n              2.7877e-05, -8.0028e-05,  1.3275e-04,  7.7213e-06, -1.2127e-04,\n              4.8950e-05, -2.7479e-04, -4.4301e-05, -1.0053e-04, -3.2864e-05,\n              6.4316e-06,  1.2950e-04, -7.5131e-05, -6.8323e-05,  9.8586e-05,\n             -7.1624e-05,  2.7856e-06, -3.2078e-04, -8.7144e-05,  9.2670e-05,\n              1.3039e-04,  4.3955e-05, -2.1161e-05, -1.9975e-04,  1.4289e-05,\n              1.0899e-04,  1.2909e-04,  8.2745e-05, -2.9234e-05, -1.6185e-06,\n             -4.5349e-05,  1.8285e-05, -4.7183e-05,  2.0142e-04, -7.0748e-06,\n             -4.3331e-05,  2.5694e-04,  7.9673e-05,  2.6523e-04,  3.7501e-05,\n             -5.2774e-05, -2.1761e-05, -1.4916e-04,  1.2433e-04,  1.9168e-05,\n              1.1784e-05, -2.7035e-05,  2.1125e-04,  1.7340e-05, -9.6274e-05,\n             -2.8505e-04, -4.8008e-05, -1.1390e-04,  2.7220e-05, -1.0720e-04,\n              1.3999e-04, -2.1098e-04, -2.7900e-04,  3.0807e-05,  1.1056e-04,\n             -5.7796e-05,  2.2962e-04,  1.0362e-04,  1.0532e-04,  3.3290e-04,\n              1.0423e-04,  1.3624e-04,  3.6509e-05, -1.3690e-04, -9.4312e-05,\n             -2.2180e-04,  1.2538e-04, -8.7985e-05,  9.9397e-05,  7.1419e-05,\n              9.7286e-05,  3.3587e-04,  5.9390e-05, -9.4402e-05, -1.0003e-04,\n             -2.2869e-04, -1.3136e-05,  6.2257e-05, -5.4756e-05, -2.8875e-04,\n             -1.3291e-04,  1.0216e-04, -2.2521e-05,  1.2322e-04, -6.6876e-05,\n              1.5603e-04, -1.2590e-04, -1.8588e-04, -7.4968e-05,  9.1166e-06,\n             -2.2553e-05, -1.8942e-04, -1.2249e-04, -2.6873e-04, -5.8287e-05,\n              3.3232e-05, -1.3460e-04,  2.2202e-05,  3.0254e-04,  1.4331e-04,\n              1.7477e-05,  2.1468e-05,  5.6255e-05,  3.4103e-05, -1.1704e-04,\n              2.4085e-04,  2.2094e-04, -7.8804e-05,  3.6264e-06, -2.3819e-04,\n             -1.1431e-04, -1.4029e-05, -9.6762e-05, -1.4130e-05,  4.3190e-05,\n             -1.3387e-05,  7.4538e-05, -6.7987e-05,  3.7918e-04,  1.3698e-05,\n             -1.0807e-04, -5.0335e-05,  1.8529e-04,  1.8739e-05, -1.0641e-04,\n             -1.0577e-04, -3.5928e-05, -4.1606e-04, -5.8141e-05,  1.1776e-05,\n             -1.9518e-04, -1.4388e-04, -3.1904e-05, -2.0772e-05,  5.7970e-05,\n              7.7279e-05, -1.2342e-04, -9.0544e-05,  1.0020e-04, -2.1930e-04,\n              1.9990e-04,  1.0386e-04]),\n     'exp_avg_sq': tensor([3.7491e-08, 2.8884e-08, 5.7192e-08, 3.7901e-08, 4.2483e-08, 3.6596e-08,\n             3.5368e-08, 3.9686e-08, 4.4848e-08, 5.6135e-08, 3.8299e-08, 9.1351e-08,\n             8.1267e-08, 5.4439e-08, 4.2916e-08, 3.4767e-08, 6.1256e-08, 4.1939e-08,\n             3.2667e-08, 3.1816e-08, 4.1478e-08, 4.2339e-08, 7.2366e-08, 5.1404e-08,\n             3.9084e-08, 3.8866e-08, 5.1162e-08, 6.3579e-08, 6.3576e-08, 4.5571e-08,\n             3.2962e-08, 4.1086e-08, 6.6014e-08, 3.7245e-08, 4.9611e-08, 3.1208e-08,\n             3.3760e-08, 3.9323e-08, 5.3995e-08, 3.2906e-08, 6.0701e-08, 3.4689e-08,\n             6.3227e-08, 3.0431e-08, 3.1735e-08, 3.2331e-08, 5.9092e-08, 5.3850e-08,\n             5.7498e-08, 6.4052e-08, 5.6990e-08, 4.7714e-08, 3.5154e-08, 4.5758e-08,\n             5.7864e-08, 4.5331e-08, 5.8813e-08, 7.0710e-08, 5.3921e-08, 7.0406e-08,\n             3.2693e-08, 3.8595e-08, 4.1790e-08, 3.5915e-08, 2.5429e-08, 4.6475e-08,\n             2.8522e-08, 5.0840e-08, 2.4439e-08, 5.0526e-08, 5.3016e-08, 3.9881e-08,\n             4.5843e-08, 4.4742e-08, 5.6303e-08, 4.6715e-08, 6.3165e-08, 3.8355e-08,\n             3.8108e-08, 2.9507e-08, 3.8988e-08, 5.8837e-08, 4.4302e-08, 6.3831e-08,\n             4.2964e-08, 4.3679e-08, 4.8294e-08, 5.1644e-08, 3.9363e-08, 2.8455e-08,\n             5.5985e-08, 4.4755e-08, 3.4494e-08, 4.8657e-08, 6.9212e-08, 7.1949e-08,\n             4.4059e-08, 4.1889e-08, 3.4315e-08, 3.1725e-08, 4.1674e-08, 4.2078e-08,\n             4.8659e-08, 4.0915e-08, 4.0220e-08, 3.1142e-08, 3.7549e-08, 3.6507e-08,\n             5.0163e-08, 3.6610e-08, 5.7231e-08, 3.5317e-08, 2.2445e-08, 4.9134e-08,\n             7.7973e-08, 4.0425e-08, 2.8313e-08, 5.3445e-08, 5.4317e-08, 5.3268e-08,\n             5.1324e-08, 6.1262e-08, 4.4511e-08, 4.7682e-08, 5.2924e-08, 3.7074e-08,\n             8.8863e-08, 3.3444e-08, 4.9523e-08, 3.9696e-08, 4.6722e-08, 4.1812e-08,\n             3.2789e-08, 4.3741e-08, 5.3867e-08, 4.4227e-08, 4.4090e-08, 4.3903e-08,\n             5.6543e-08, 3.8000e-08, 3.0133e-08, 5.9679e-08, 4.3690e-08, 1.9020e-08,\n             2.6220e-08, 4.0694e-08, 3.8072e-08, 2.5589e-08, 3.9647e-08, 4.2039e-08,\n             4.1867e-08, 3.6680e-08, 4.2869e-08, 3.5116e-08, 2.3815e-08, 2.2930e-08,\n             4.0575e-08, 7.5847e-08, 5.0890e-08, 4.2169e-08, 4.6549e-08, 5.1804e-08,\n             5.0635e-08, 4.8505e-08, 2.8319e-08, 8.5748e-08, 7.0123e-08, 4.3435e-08,\n             5.8744e-08, 2.1374e-08, 5.5838e-08, 5.8157e-08, 2.8548e-08, 4.3079e-08,\n             5.8749e-08, 5.0871e-08, 4.4436e-08, 5.6691e-08, 3.6074e-08, 6.2213e-08,\n             7.1169e-08, 6.4515e-08, 4.6674e-08, 4.3089e-08, 3.9234e-08, 1.2897e-07,\n             4.4384e-08, 3.5422e-08, 3.9309e-08, 2.3559e-08, 5.9729e-08, 5.8168e-08,\n             3.9403e-08, 4.8838e-08, 2.0708e-08, 6.0200e-08, 3.9013e-08, 4.1612e-08,\n             5.3253e-08, 3.7777e-08, 4.6315e-08, 4.5175e-08, 3.7418e-08, 3.7848e-08,\n             3.3045e-08, 4.6356e-08, 4.4071e-08, 1.6340e-07, 3.5261e-08, 6.0606e-08,\n             2.9557e-08, 5.7165e-08, 2.9322e-08, 5.1538e-08, 2.6835e-08, 3.2772e-08,\n             4.6846e-08, 5.1253e-08, 5.1435e-08, 4.5241e-08, 3.9780e-08, 3.2182e-08,\n             7.0677e-08, 6.0377e-08, 3.9633e-08, 6.1678e-08, 5.3291e-08, 4.0352e-08,\n             3.1716e-08, 2.6730e-08, 3.8105e-08, 1.5339e-07, 4.4830e-08, 2.1102e-08,\n             2.8024e-08, 5.3725e-08, 8.0684e-08, 4.2324e-08, 3.0414e-08, 5.7263e-08,\n             6.3839e-08, 2.0303e-08, 3.1550e-08, 3.3861e-08, 7.6592e-08, 2.0353e-08,\n             4.7625e-08, 5.6632e-08, 4.0795e-08, 3.8451e-08, 2.5720e-08, 6.6356e-08,\n             6.9404e-08, 5.3300e-08, 4.0588e-08, 5.4774e-08, 5.8200e-08, 3.3834e-08,\n             4.3695e-08, 4.7705e-08, 9.0145e-08, 5.4962e-08, 4.4676e-08, 7.2608e-08,\n             4.9246e-08, 3.7743e-08, 2.1433e-08, 6.3187e-08, 3.4289e-08, 7.5674e-08,\n             3.8624e-08, 3.5962e-08, 4.8479e-08, 3.2820e-08, 5.9931e-08, 4.8051e-08,\n             4.9900e-08, 5.7111e-08, 2.5076e-08, 3.8924e-08, 5.6583e-08, 4.0322e-08,\n             5.4637e-08, 5.7436e-08, 3.2949e-08, 3.9715e-08, 3.5574e-08, 5.5490e-08,\n             4.4720e-08, 2.9944e-08, 5.2566e-08, 4.9694e-08, 5.3683e-08, 3.9222e-08,\n             4.4020e-08, 3.5480e-08, 3.1469e-08, 4.8766e-08, 6.6862e-08, 4.5418e-08,\n             4.8905e-08, 5.5474e-08, 6.0075e-08, 3.2884e-08, 7.1381e-08, 3.3954e-08,\n             4.5853e-08, 7.6092e-08, 4.4547e-08, 3.4049e-08, 4.1024e-08, 5.4949e-08,\n             3.9843e-08, 4.3627e-08, 4.8081e-08, 5.4659e-08, 2.9585e-08, 4.8588e-08,\n             3.7461e-08, 3.3228e-08, 4.1221e-08, 3.5775e-08, 6.1162e-08, 3.8122e-08,\n             3.7571e-08, 4.3595e-08, 4.9999e-08, 3.3255e-08, 5.0644e-08, 4.0159e-08,\n             4.0798e-08, 6.0092e-08, 3.7748e-08, 4.7502e-08, 4.2368e-08, 2.4479e-08,\n             4.8514e-08, 4.7680e-08, 3.9304e-08, 3.9412e-08, 3.2249e-08, 3.5281e-08,\n             5.5266e-08, 4.9049e-08, 3.4860e-08, 4.0359e-08, 3.2657e-08, 3.7256e-08,\n             3.7582e-08, 7.1197e-08, 5.5479e-08, 2.5365e-08, 4.9262e-08, 5.0188e-08,\n             5.7153e-08, 5.1581e-08, 5.5488e-08, 4.2468e-08, 6.0196e-08, 1.0174e-07,\n             4.1299e-08, 5.2791e-08, 4.2661e-08, 5.7114e-08, 3.3101e-08, 5.3707e-08,\n             3.7121e-08, 3.3233e-08, 5.5508e-08, 3.8155e-08, 3.6725e-08, 7.7541e-08,\n             4.2754e-08, 4.7053e-08, 4.4792e-08, 4.2413e-08, 3.8849e-08, 4.5235e-08,\n             2.8821e-08, 4.3526e-08, 4.7618e-08, 6.5193e-08, 3.7787e-08, 3.7360e-08,\n             2.6835e-08, 6.9116e-08, 6.8562e-08, 3.6145e-08, 6.0551e-08, 1.5028e-08,\n             2.7903e-08, 4.4357e-08, 2.2721e-08, 5.7882e-08, 1.6903e-08, 2.0860e-08,\n             3.2763e-08, 4.5556e-08, 4.4949e-08, 1.7135e-08, 4.4830e-08, 3.4594e-08,\n             6.0014e-08, 3.5501e-08, 4.8877e-08, 6.3016e-08, 5.2175e-08, 4.8441e-08,\n             3.8680e-08, 2.3474e-08, 2.9692e-08, 3.5193e-08, 3.8086e-08, 2.5887e-08,\n             3.9806e-08, 7.6415e-08, 5.5895e-08, 2.4541e-08, 3.7384e-08, 5.9338e-08,\n             5.6181e-08, 4.7598e-08, 4.2626e-08, 4.5039e-08, 2.4418e-08, 3.2110e-08,\n             4.1536e-08, 5.5230e-08, 5.7644e-08, 5.4324e-08, 5.1534e-08, 5.5608e-08,\n             3.0340e-08, 3.7960e-08, 3.8041e-08, 6.0192e-08, 3.7367e-08, 2.5110e-08,\n             4.5919e-08, 3.6701e-08, 2.7369e-08, 3.5798e-08, 2.0329e-08, 5.8312e-08,\n             4.8685e-08, 5.6241e-08, 8.5698e-08, 3.4235e-08, 2.6619e-08, 6.4191e-08,\n             4.7428e-08, 4.1111e-08, 2.5068e-08, 3.5461e-08, 4.0412e-08, 5.4539e-08,\n             5.2286e-08, 5.2182e-08, 3.9263e-08, 3.5465e-08, 5.1816e-08, 4.6978e-08,\n             6.1434e-08, 6.1375e-08, 3.3346e-08, 6.7842e-08, 3.9403e-08, 3.6119e-08,\n             4.9817e-08, 2.9778e-08, 4.1695e-08, 2.9370e-08, 5.2248e-08, 3.7259e-08,\n             7.7745e-08, 5.7339e-08, 4.5372e-08, 3.5264e-08, 5.1316e-08, 4.6789e-08,\n             4.7384e-08, 5.2091e-08, 3.7569e-08, 6.4891e-08, 2.2203e-08, 3.0439e-08,\n             3.3727e-08, 3.7732e-08, 5.8412e-08, 3.0306e-08, 5.6204e-08, 2.0115e-08,\n             4.1257e-08, 3.9586e-08, 4.9740e-08, 5.7990e-08, 5.0074e-08, 6.2409e-08,\n             4.6396e-08, 3.1643e-08, 4.8703e-08, 6.3977e-08, 3.3007e-08, 3.0531e-08,\n             7.5456e-08, 3.0416e-08, 4.2901e-08, 4.7329e-08, 4.1613e-08, 4.7423e-08,\n             7.3187e-08, 4.1718e-08])},\n    96: {'exp_avg': tensor([ 2.8036e-04,  3.8865e-05, -3.6328e-05,  8.0313e-05, -3.1146e-04,\n             -1.8473e-04,  3.3035e-04, -1.9736e-04,  9.4085e-05,  1.9025e-04,\n              2.6631e-04,  1.2323e-05, -1.3682e-04, -2.4287e-04,  1.2154e-04,\n             -2.0611e-04, -3.0627e-04,  1.7766e-04, -1.2117e-04, -3.0565e-05,\n             -9.6833e-05, -2.5781e-04, -2.6894e-04,  1.5870e-04,  1.9847e-04,\n             -3.8943e-04, -4.1340e-04, -1.9438e-04,  2.1606e-04,  2.4040e-04,\n             -5.5730e-05, -2.4938e-04,  2.2460e-04, -1.5287e-04, -2.3812e-04,\n             -1.0239e-04, -1.4340e-04,  3.5099e-04, -3.4896e-05,  9.5350e-05,\n             -7.6484e-05,  2.0456e-04, -2.1664e-04,  2.6767e-04, -5.0976e-04,\n             -2.1613e-04,  1.3791e-04, -1.7431e-04, -1.0386e-04, -1.2521e-04,\n              3.8576e-05, -5.3651e-05,  3.9782e-05,  5.2458e-05,  2.9506e-04,\n             -7.7331e-05, -2.1822e-04, -3.0903e-04, -1.7923e-04, -3.9538e-06,\n             -3.1840e-04, -1.2308e-04,  1.2494e-04,  3.4720e-04,  6.5893e-05,\n             -4.5877e-05,  1.5159e-04, -4.0323e-04, -5.6052e-04,  6.9376e-05,\n              2.5452e-05,  3.0249e-06,  3.0211e-04,  2.1021e-04,  1.0375e-04,\n             -2.0091e-05, -1.2776e-04, -4.5615e-04,  2.1918e-04, -6.7687e-06,\n             -2.3283e-04, -1.0453e-05, -2.4097e-04,  3.7329e-04, -1.6643e-05,\n              2.6397e-04, -6.2394e-05, -1.4353e-04,  3.2956e-04,  4.4663e-05,\n              3.6222e-04,  7.4026e-05,  3.0163e-05, -4.0390e-04,  1.4317e-04,\n              1.5291e-04,  6.6903e-05,  3.8178e-06, -2.6420e-04,  2.0661e-04,\n             -3.9779e-05, -2.3663e-04, -3.4085e-05, -9.9669e-05,  2.5297e-04,\n             -3.7518e-05, -2.9059e-05,  5.6221e-05, -2.6871e-04,  1.6173e-04,\n              3.1071e-04,  1.0976e-04,  2.9315e-04, -5.6528e-05, -3.0883e-04,\n             -8.1868e-06,  2.2391e-04,  4.3650e-04,  5.1529e-04,  3.1740e-04,\n              4.1851e-04,  7.1516e-05, -1.8723e-04, -4.1365e-04, -1.4161e-04,\n             -1.9915e-04,  3.9951e-04, -4.7659e-05, -5.3295e-05, -2.4866e-04,\n             -7.3980e-05,  5.1158e-04,  8.1785e-05,  8.4082e-06,  4.0963e-05,\n              1.1105e-04, -5.2684e-04, -5.0044e-04, -3.6966e-04, -3.7793e-04,\n             -1.5434e-04, -1.9882e-04,  2.1669e-04,  6.5644e-05,  3.4850e-05,\n             -1.1927e-04,  1.2366e-04,  3.7493e-04,  2.9032e-04,  9.8946e-05,\n              1.6818e-04, -5.7058e-05,  1.8950e-04, -3.1640e-04,  6.3655e-05,\n              4.9032e-04, -1.8638e-05, -1.2892e-04,  3.2416e-04, -1.1823e-04,\n             -1.0735e-05,  8.4189e-06,  3.7416e-05, -1.8641e-04, -2.4829e-05,\n             -1.5127e-04, -3.1596e-04, -1.4555e-06,  3.0538e-05,  2.1196e-04,\n             -1.4259e-05,  8.7832e-05, -1.7982e-04,  2.3264e-04,  3.9806e-05,\n             -1.3122e-04,  7.3549e-05,  8.9919e-05, -1.9470e-05,  1.5122e-05,\n             -2.4693e-04, -1.8042e-04, -2.8770e-04,  3.5764e-05,  3.4298e-05,\n              2.2112e-04,  1.9645e-04,  3.0809e-04, -4.2711e-04, -5.0030e-05,\n             -3.0678e-04,  7.2252e-05,  2.0655e-04,  2.9740e-04, -8.9960e-05,\n              3.6502e-04, -2.3040e-04, -6.0293e-05,  1.8404e-04, -1.4374e-04,\n             -5.8765e-05,  1.3080e-04, -2.6257e-04,  2.5279e-04, -2.0915e-04,\n              4.3054e-04,  5.7331e-05, -1.1531e-04,  1.6668e-03,  1.7607e-05,\n             -7.4105e-06,  1.4292e-04, -5.1603e-04, -1.3779e-04,  1.0351e-04,\n             -2.2135e-04, -1.8675e-04,  1.8711e-04, -9.6609e-06,  2.8628e-04,\n              8.0641e-05,  6.9094e-05, -3.1443e-04,  2.9119e-04, -7.7956e-05,\n             -4.3356e-04, -3.5515e-04,  1.8566e-04, -2.4573e-04,  2.2414e-04,\n              9.2471e-05,  1.4943e-04, -1.3036e-04, -8.6164e-06,  1.5505e-04,\n             -2.7077e-04, -1.4008e-04, -1.1965e-04, -3.0439e-04, -1.2604e-04,\n              3.2041e-04,  1.5746e-04, -3.8376e-04,  1.7395e-04, -4.8961e-05,\n             -2.4307e-06,  7.1671e-05,  3.1299e-04,  2.3500e-04, -7.4345e-05,\n             -5.7544e-04,  2.3332e-06, -1.1974e-04,  1.6627e-04,  1.0638e-04,\n             -1.1006e-04, -1.3038e-04,  1.6973e-04,  1.1322e-04, -3.9259e-04,\n              1.2065e-04, -3.0611e-05,  1.3623e-04,  1.0143e-04, -1.0850e-04,\n              1.9004e-04, -9.1661e-05, -1.7921e-04,  1.4703e-04,  1.8735e-04,\n              1.1652e-04, -4.2202e-05, -7.0336e-05, -3.5670e-04,  1.5639e-05,\n             -2.4696e-04,  2.8588e-04, -1.1529e-04,  2.1011e-04,  2.7284e-05,\n              1.0162e-04,  1.0447e-04, -3.1556e-04,  4.8878e-05,  6.9062e-04,\n             -1.9796e-04, -2.6258e-04,  5.0220e-04,  5.2538e-04,  3.7734e-04,\n              4.6199e-04,  1.6498e-04,  1.1966e-04,  2.1490e-04, -1.9979e-04,\n             -4.5284e-04,  2.0179e-05, -2.7621e-04, -1.1583e-05, -1.3925e-04,\n              6.7083e-05, -1.2082e-04,  2.3082e-04, -1.9910e-04, -3.7324e-04,\n              2.2087e-04, -2.8681e-06, -1.4960e-04,  1.2709e-04,  3.5632e-04,\n              2.5367e-04,  2.0145e-04, -3.5970e-04,  5.8900e-05, -1.8625e-04,\n             -2.5475e-04, -7.2349e-05, -4.4498e-05, -2.1231e-04,  5.0192e-05,\n              1.0561e-04, -4.3061e-04, -3.7626e-05,  8.5532e-05, -8.0481e-07,\n              5.3242e-06,  2.1784e-04,  4.4555e-04,  1.3140e-06, -5.7476e-06,\n              7.0163e-05,  1.2305e-04,  2.7650e-04, -2.2050e-04,  9.6071e-05,\n             -6.9897e-05, -1.6779e-04,  6.9188e-04,  4.2617e-04, -2.8789e-04,\n              8.5075e-05,  2.7887e-04,  2.2009e-04,  2.0246e-05, -2.0224e-04,\n              6.7957e-05, -2.5765e-04,  2.5348e-04,  2.9207e-04,  1.3919e-04,\n             -2.4812e-04,  2.3973e-04,  4.3596e-04,  6.7117e-05,  2.8429e-04,\n              4.1771e-05, -3.9224e-05, -2.2323e-04,  2.0922e-04, -3.8214e-04,\n              3.1109e-04,  2.2016e-04,  1.1021e-04,  9.8927e-05,  2.9166e-04,\n              2.0241e-04,  1.2366e-04, -6.0146e-05, -1.9401e-04, -2.3300e-04,\n              1.0253e-04,  1.1618e-04, -1.5121e-05, -1.1203e-04,  3.6964e-04,\n             -3.6391e-04,  7.5348e-06, -3.4238e-04, -1.5291e-05, -6.2486e-06,\n             -5.6356e-04, -4.1014e-04,  2.3118e-04, -1.4796e-05, -3.3390e-05,\n             -6.4529e-05,  1.8446e-05, -1.2948e-04,  4.6243e-05, -2.6210e-05,\n             -1.6525e-05, -6.4615e-05, -1.3660e-04,  6.1369e-05,  2.1981e-04,\n              1.3293e-04, -3.2059e-04, -1.4556e-04,  1.3242e-04, -1.2900e-04,\n             -5.9245e-04, -2.8997e-04,  3.7176e-04, -3.9487e-04, -2.5128e-05,\n              2.7047e-05, -1.9558e-04, -1.9667e-04, -3.5968e-04, -2.2188e-04,\n              2.2616e-04,  6.4099e-05,  3.9182e-04, -2.5654e-04,  6.9617e-05,\n             -6.4719e-05,  2.1923e-05,  3.9244e-05,  1.0587e-04,  7.5869e-06,\n              1.4312e-04,  9.6366e-05,  1.1885e-04,  7.1391e-06, -4.9305e-04,\n             -6.0860e-04, -5.7124e-06, -2.1485e-04, -3.2242e-04,  3.4105e-04,\n              1.1253e-04,  1.2342e-04, -3.5717e-04, -2.3076e-04,  3.3341e-04,\n              1.9388e-04,  3.0957e-04,  1.6114e-04, -2.7909e-04,  3.8239e-04,\n             -2.9751e-04,  3.4753e-04, -1.6127e-04,  5.5034e-05, -6.2840e-05,\n              6.4011e-05,  7.4897e-05, -2.0259e-05, -1.4247e-04, -1.6289e-04,\n             -6.2076e-05, -7.8670e-05, -1.0150e-04, -1.1072e-04,  2.2732e-05,\n              2.2090e-04, -2.5377e-05,  1.3310e-04, -2.0867e-04, -3.0171e-04,\n              3.1864e-04, -2.4440e-04, -2.4903e-04,  7.4862e-05,  3.5116e-05,\n              2.5949e-04, -5.8746e-05, -8.4027e-05, -1.2455e-04, -1.9417e-04,\n              4.8872e-07,  2.2689e-04, -1.1563e-04,  2.0324e-04, -8.8198e-05,\n              1.9330e-05,  8.4675e-06,  1.9028e-04, -2.3931e-05, -5.7238e-05,\n              7.6132e-05,  1.2516e-04, -2.8496e-04,  2.4918e-04,  1.6702e-04,\n             -1.7706e-04,  7.6031e-05,  1.9185e-04,  3.5076e-04,  1.8452e-04,\n             -1.8382e-04,  2.0516e-04, -4.9040e-05,  3.8788e-04, -9.9620e-05,\n              2.2794e-04,  1.5866e-04,  2.1500e-04, -2.4002e-04, -8.3061e-05,\n             -2.5597e-04,  3.0406e-04,  2.3387e-05, -4.9394e-05, -2.8424e-04,\n              9.9184e-05,  5.9686e-05,  5.2647e-05,  2.7247e-04, -1.6766e-04,\n              2.8897e-04,  3.4962e-06]),\n     'exp_avg_sq': tensor([9.6651e-08, 6.0117e-08, 8.4937e-08, 9.0875e-08, 3.1384e-07, 1.2584e-07,\n             1.0516e-07, 1.3645e-07, 9.2121e-08, 1.6020e-07, 1.3106e-07, 9.8370e-08,\n             9.1700e-08, 1.5722e-07, 1.1108e-07, 1.3764e-07, 2.9235e-07, 1.4880e-07,\n             9.0240e-08, 1.2135e-07, 1.4311e-07, 1.1649e-07, 2.0028e-07, 7.8843e-08,\n             1.4119e-07, 1.1284e-07, 9.9283e-08, 1.0995e-07, 1.9848e-07, 1.3118e-07,\n             8.9091e-08, 1.1247e-07, 1.4425e-07, 1.2057e-07, 1.0981e-07, 1.6422e-07,\n             1.0352e-07, 1.0755e-07, 6.3816e-08, 1.9268e-07, 2.0013e-07, 1.2272e-07,\n             1.0829e-07, 1.0549e-07, 1.2206e-07, 9.6419e-08, 1.0658e-07, 9.2698e-08,\n             2.0226e-07, 1.9085e-07, 5.7434e-08, 1.5864e-07, 1.1133e-07, 1.0784e-07,\n             1.1462e-07, 1.1066e-07, 1.4846e-07, 1.3724e-07, 1.1898e-07, 1.1860e-07,\n             1.3312e-07, 1.3771e-07, 1.2198e-07, 1.4021e-07, 1.1729e-07, 1.4163e-07,\n             8.2818e-08, 1.3348e-07, 1.5735e-07, 1.7723e-07, 1.8359e-07, 9.7408e-08,\n             1.0568e-07, 1.0029e-07, 1.6633e-07, 1.0103e-07, 1.4298e-07, 1.7574e-07,\n             5.2840e-08, 1.3740e-07, 1.2387e-07, 1.1514e-07, 1.3209e-07, 8.5356e-08,\n             1.2571e-07, 1.0351e-07, 1.5492e-07, 8.7929e-08, 1.4012e-07, 1.2011e-07,\n             1.3434e-07, 1.0257e-07, 8.5993e-08, 1.9510e-07, 1.4101e-07, 1.2970e-07,\n             1.9736e-07, 9.9177e-08, 1.7226e-07, 6.6485e-08, 9.3110e-08, 1.6321e-07,\n             8.7169e-08, 1.4271e-07, 1.5765e-07, 2.0107e-07, 9.8245e-08, 1.0658e-07,\n             8.9563e-08, 1.1561e-07, 1.4837e-07, 1.2579e-07, 8.5506e-08, 1.0209e-07,\n             2.0716e-07, 1.0587e-07, 2.2211e-07, 1.3321e-07, 1.5835e-07, 1.3715e-07,\n             1.3495e-07, 1.0211e-07, 1.7831e-07, 1.1070e-07, 1.5055e-07, 2.1334e-07,\n             1.4785e-07, 1.3350e-07, 1.3861e-07, 1.8145e-07, 7.7011e-08, 1.0401e-07,\n             9.2573e-08, 9.7490e-08, 6.7397e-08, 1.2985e-07, 8.3269e-08, 1.3859e-07,\n             1.8236e-07, 1.3952e-07, 1.2287e-07, 1.0393e-07, 1.2340e-07, 1.3668e-07,\n             2.0312e-07, 7.8083e-08, 1.1929e-07, 1.9069e-07, 1.9583e-07, 1.1787e-07,\n             5.4273e-07, 1.3923e-07, 7.9817e-08, 1.2969e-07, 1.5214e-07, 1.4430e-07,\n             8.3337e-08, 1.7071e-07, 1.2754e-07, 9.6284e-08, 1.3092e-07, 1.9131e-07,\n             1.6182e-07, 1.8629e-07, 1.2138e-07, 8.4441e-08, 1.2197e-07, 9.4757e-08,\n             1.0702e-07, 1.2581e-07, 1.1877e-07, 1.0167e-07, 2.3073e-07, 1.4171e-07,\n             1.8151e-07, 8.8892e-08, 1.1791e-07, 6.9602e-08, 9.5848e-08, 1.0473e-07,\n             8.4202e-08, 1.2985e-07, 1.0508e-07, 1.1492e-07, 7.9873e-08, 1.4648e-07,\n             1.4642e-07, 1.0091e-07, 7.6535e-08, 1.0070e-07, 1.8661e-07, 4.8782e-07,\n             1.0847e-07, 1.9833e-07, 6.5367e-08, 1.1561e-07, 6.7729e-08, 6.3422e-08,\n             6.9878e-08, 1.4753e-07, 1.1665e-07, 1.2348e-07, 1.1267e-07, 1.3540e-07,\n             1.2953e-07, 8.9056e-08, 8.0686e-08, 1.4048e-07, 5.6973e-06, 7.3055e-08,\n             1.4962e-07, 1.3752e-07, 1.2885e-07, 1.7989e-07, 1.8006e-07, 1.3771e-07,\n             1.1283e-07, 1.1070e-07, 1.0790e-07, 7.1096e-08, 1.5304e-07, 1.1380e-07,\n             8.9858e-08, 1.0728e-07, 1.4799e-07, 1.2669e-07, 1.0475e-07, 1.3055e-07,\n             1.0175e-07, 9.8002e-08, 7.7589e-08, 9.8742e-08, 8.5699e-08, 2.0898e-07,\n             1.0774e-07, 1.1056e-07, 1.2368e-07, 8.6416e-08, 1.2616e-07, 7.1109e-08,\n             1.5901e-07, 1.0581e-07, 1.3460e-07, 1.2119e-07, 1.6276e-07, 9.3655e-08,\n             6.5849e-08, 3.6613e-07, 1.3119e-07, 5.1475e-08, 9.6855e-08, 8.9540e-08,\n             1.4376e-07, 1.4034e-07, 1.0705e-07, 1.1241e-07, 1.6797e-07, 1.7906e-07,\n             1.0713e-07, 1.1918e-07, 1.0666e-07, 1.1578e-07, 9.4724e-08, 1.4738e-07,\n             1.5714e-07, 1.3190e-07, 9.6311e-08, 1.4353e-07, 1.3337e-07, 9.7577e-08,\n             1.0864e-07, 9.4239e-08, 1.3175e-07, 9.7882e-08, 1.1299e-07, 7.7435e-08,\n             2.0937e-07, 1.9952e-07, 1.6043e-07, 1.6578e-07, 1.1682e-07, 1.0057e-07,\n             1.3977e-07, 6.6271e-08, 1.6747e-07, 1.0855e-07, 6.0519e-08, 9.0426e-08,\n             1.3455e-07, 1.7913e-07, 3.1642e-07, 1.1313e-07, 2.3224e-07, 1.0430e-07,\n             2.1097e-07, 1.1666e-07, 1.1636e-07, 6.5869e-08, 5.9453e-08, 1.1026e-07,\n             1.2084e-07, 1.1603e-07, 1.6934e-07, 1.1584e-07, 1.4206e-07, 1.0468e-07,\n             1.0477e-07, 1.1013e-07, 9.1573e-08, 1.3181e-07, 1.0798e-07, 9.2352e-08,\n             1.3751e-07, 1.0212e-07, 1.7188e-07, 1.5205e-07, 1.4730e-07, 9.6195e-08,\n             1.5187e-07, 1.7087e-07, 1.2719e-07, 1.6375e-07, 1.3273e-07, 1.0928e-07,\n             8.6476e-08, 1.3454e-07, 2.4940e-07, 9.9888e-08, 2.9576e-07, 8.1293e-08,\n             9.6914e-08, 1.8817e-07, 1.0002e-07, 1.0163e-07, 1.3302e-07, 1.4389e-07,\n             8.7699e-08, 1.6513e-07, 8.6266e-08, 1.9764e-07, 8.3780e-08, 1.1539e-07,\n             1.6874e-07, 1.0330e-07, 1.0368e-07, 4.1534e-08, 1.2146e-07, 1.8977e-07,\n             1.3917e-07, 7.3293e-08, 5.9345e-08, 2.1013e-07, 1.3405e-07, 1.8567e-07,\n             1.0970e-07, 8.7827e-08, 1.3544e-07, 1.3938e-07, 1.2900e-07, 9.9075e-08,\n             1.2899e-07, 1.5978e-07, 1.0106e-07, 1.0557e-07, 1.1516e-07, 1.2602e-07,\n             9.1484e-08, 1.0586e-07, 1.2029e-07, 1.6041e-07, 7.1178e-08, 1.5868e-07,\n             1.5974e-07, 1.0885e-07, 1.1532e-07, 1.7659e-07, 1.1895e-07, 9.3923e-08,\n             1.2484e-07, 1.2825e-07, 1.1173e-07, 1.2203e-07, 1.9622e-07, 9.0099e-08,\n             1.0041e-07, 1.9024e-07, 1.6309e-07, 1.3025e-07, 7.2333e-08, 1.2138e-07,\n             2.2289e-07, 1.1203e-07, 1.2590e-07, 9.7221e-08, 1.0879e-07, 1.1534e-07,\n             9.8892e-08, 1.1142e-07, 1.8179e-07, 1.2878e-07, 1.3302e-07, 1.1859e-07,\n             2.2504e-07, 1.1891e-07, 1.1564e-07, 1.5567e-07, 9.1832e-08, 9.0510e-08,\n             1.8677e-07, 9.4325e-08, 8.7800e-08, 1.1846e-07, 1.9629e-07, 2.3383e-07,\n             8.9869e-08, 7.7870e-08, 9.0844e-08, 1.0858e-07, 7.8121e-08, 1.5728e-07,\n             1.1748e-07, 1.0945e-07, 1.0191e-07, 9.4711e-08, 2.2106e-07, 1.1701e-07,\n             1.4717e-07, 7.5711e-08, 1.9114e-07, 1.1599e-07, 1.6383e-07, 1.8953e-07,\n             2.8361e-07, 1.5208e-07, 8.5896e-08, 1.4103e-07, 1.1143e-07, 1.3582e-07,\n             8.8811e-08, 7.8201e-08, 1.0466e-07, 1.0984e-07, 1.2930e-07, 1.4792e-07,\n             4.8760e-08, 7.5513e-08, 1.0098e-07, 6.7312e-08, 9.5614e-08, 1.1905e-07,\n             5.9463e-08, 1.3328e-07, 1.1856e-07, 7.0868e-08, 1.0567e-07, 7.5812e-08,\n             1.0966e-07, 1.1235e-07, 1.2329e-07, 1.2679e-07, 1.2081e-07, 7.8624e-08,\n             2.2337e-07, 1.2683e-07, 9.5348e-08, 7.0769e-08, 1.7559e-07, 1.0555e-07,\n             7.7330e-08, 1.1993e-07, 1.7653e-07, 1.3138e-07, 2.2321e-07, 8.1387e-08,\n             1.4278e-07, 8.0607e-08, 1.8742e-07, 1.3562e-07, 1.2698e-07, 1.4649e-07,\n             1.5236e-07, 1.0055e-07, 8.5715e-08, 5.5415e-08, 1.0150e-07, 1.8007e-07,\n             9.2354e-08, 1.9502e-07, 1.1097e-07, 1.5319e-07, 1.4557e-07, 1.0344e-07,\n             1.2010e-07, 1.2189e-07, 2.4063e-07, 1.3577e-07, 1.1614e-07, 1.5592e-07,\n             2.5109e-07, 2.0150e-07, 7.1477e-08, 1.1413e-07, 1.3013e-07, 1.1199e-07,\n             1.3705e-07, 8.3050e-08, 1.7017e-07, 7.2582e-08, 9.0941e-08, 8.9972e-08,\n             1.0839e-07, 1.4067e-07])},\n    97: {'exp_avg': tensor([ 3.7472e-05,  6.9092e-05, -7.8527e-05, -9.1654e-06, -7.9938e-05,\n             -1.3531e-04,  1.9427e-04, -1.1607e-04,  5.0473e-05,  4.5783e-05,\n              2.1862e-04,  8.2827e-05, -1.0969e-04, -8.4270e-05,  7.4799e-05,\n             -1.0573e-04, -1.5542e-04,  6.5095e-05, -4.4227e-05, -2.4483e-05,\n             -3.2266e-05, -1.4970e-04, -1.0590e-04,  1.5699e-04,  3.9045e-05,\n             -2.2537e-04, -1.8772e-04, -1.1051e-04,  5.8828e-05,  9.7527e-05,\n             -2.2520e-05, -1.5220e-04,  7.5737e-05, -9.7261e-05, -1.9796e-04,\n             -5.1877e-05, -1.4165e-04,  2.0469e-04, -6.2407e-05,  6.6983e-07,\n             -7.2977e-05,  1.7699e-05, -2.0168e-04,  2.7810e-04, -2.9824e-04,\n             -1.4431e-04,  8.3591e-05, -5.4465e-05, -1.2363e-04,  4.3515e-05,\n              6.1080e-05, -4.0048e-05,  3.2078e-05,  7.6619e-05,  1.4168e-04,\n              9.1818e-05, -4.5700e-05, -1.6656e-04, -2.0613e-04,  9.6300e-05,\n             -2.5931e-04, -4.7984e-05,  7.9145e-05,  2.3182e-04,  5.9056e-05,\n             -4.6107e-05,  1.2799e-04, -2.1005e-04, -2.9194e-04,  1.0789e-05,\n              6.9976e-06, -1.7718e-06,  1.7365e-04,  4.4343e-05,  7.0312e-05,\n             -4.0051e-05, -1.6297e-05, -1.9345e-04,  1.1009e-04,  3.8361e-05,\n             -6.0042e-05,  1.9659e-05, -1.2229e-04,  2.0566e-04, -1.9540e-04,\n              2.1649e-04, -5.0419e-05, -9.9267e-05,  1.8055e-04,  4.8025e-05,\n              1.6050e-04,  2.8868e-05,  8.8606e-05, -1.0691e-04,  5.7176e-05,\n              9.6021e-05,  2.3037e-05,  9.4943e-06, -1.3022e-04,  6.1748e-05,\n             -3.1228e-05, -8.7862e-05, -1.0125e-05, -3.9540e-05,  1.4408e-04,\n             -6.0209e-05, -1.3472e-05,  9.5050e-05, -8.3971e-05,  1.0166e-04,\n              1.6448e-04, -2.4536e-05,  1.5161e-04, -4.2419e-05, -1.4541e-04,\n             -3.9061e-05,  4.1731e-05,  2.3134e-04,  2.3511e-04,  1.5903e-04,\n              1.9086e-04,  5.7861e-05, -1.2487e-04, -3.6475e-04, -4.6352e-05,\n             -9.5912e-05,  1.5935e-04, -3.6444e-05, -4.2553e-05, -5.1429e-05,\n              1.2792e-04,  2.9195e-04,  4.1037e-06, -7.5635e-05,  1.9337e-05,\n              7.7327e-05, -2.8929e-04, -3.1500e-04, -2.7384e-04, -1.6107e-04,\n             -1.1731e-04, -1.7117e-04,  5.4347e-05,  1.4014e-05,  7.7380e-05,\n             -5.9673e-05,  7.4502e-05,  1.9217e-04,  1.0176e-04,  3.8065e-05,\n              8.7593e-05, -6.0661e-05,  8.7169e-05, -3.1062e-04,  7.0823e-05,\n              1.7614e-04, -5.0802e-05, -8.9627e-05,  2.0954e-04, -6.5684e-05,\n             -2.2897e-05, -8.2810e-05,  2.5143e-05, -1.1711e-04,  1.1063e-05,\n             -5.3662e-05, -2.0868e-04,  4.6519e-05,  1.8780e-06,  6.1935e-05,\n             -9.1334e-05, -1.0445e-05, -3.7966e-05,  1.8952e-04,  6.6471e-05,\n             -1.1628e-04,  1.8232e-05,  6.8735e-05, -4.8704e-05,  5.2482e-05,\n             -3.6370e-05, -1.6538e-04, -1.4809e-04, -1.3571e-06,  7.3026e-05,\n              1.1578e-04,  1.9263e-04,  1.4399e-04, -3.3238e-04, -8.1129e-05,\n             -1.8797e-04,  3.6595e-06,  1.3378e-04,  1.5672e-04,  2.4310e-05,\n              1.9654e-04, -2.0521e-04, -2.3657e-05,  1.1327e-04, -4.4499e-05,\n             -1.1039e-05,  5.9111e-05, -2.5611e-04,  1.6514e-04, -3.6734e-05,\n              3.3886e-04,  1.1051e-05,  1.3289e-05,  6.5500e-04, -2.9724e-05,\n              6.5977e-05,  7.1679e-05, -2.7411e-04, -1.3269e-05, -5.0661e-06,\n             -1.8886e-04, -8.5659e-05,  1.3043e-04, -1.1567e-04,  2.2418e-04,\n              1.4035e-05,  8.5497e-07, -1.4900e-04,  2.9996e-04, -7.6762e-06,\n             -3.0595e-04, -1.9782e-04,  3.2730e-05, -1.1688e-04,  1.5832e-04,\n              1.1265e-06,  8.2165e-05, -4.1287e-05,  2.0414e-05, -2.7630e-05,\n             -7.7843e-05, -6.0708e-05, -1.9133e-05, -1.5885e-04, -6.5489e-05,\n              8.1711e-05,  9.5204e-05, -4.3088e-04,  4.6280e-05, -6.4571e-05,\n              1.6131e-05,  5.5568e-05,  5.5509e-05,  1.1663e-04, -2.2630e-06,\n             -3.0077e-04,  2.0065e-06, -7.2014e-05,  4.6189e-05,  8.6778e-05,\n              4.5163e-05, -1.2042e-04,  8.9392e-05,  5.3920e-05, -3.0266e-04,\n              5.3311e-05, -2.4355e-05,  9.0676e-05,  6.8504e-05, -1.2519e-04,\n              3.6479e-05,  1.7535e-05, -1.1732e-04, -1.5285e-05,  4.8403e-05,\n              1.0505e-04, -1.0080e-04, -1.0364e-04, -2.8297e-04,  4.6631e-05,\n             -6.1646e-05,  1.3654e-04, -9.5704e-05,  9.5038e-05,  9.6404e-05,\n              5.0480e-05,  6.6570e-05, -1.4988e-04,  1.2757e-05,  4.0441e-04,\n             -1.1662e-04, -1.1196e-04,  2.2288e-04,  2.7052e-04,  1.6163e-04,\n              2.5439e-04,  5.6531e-05,  4.1635e-05,  1.9201e-04, -1.8096e-04,\n             -2.3713e-04,  2.5628e-06, -2.1481e-04, -6.3694e-05, -8.6098e-05,\n              1.5313e-05, -6.2671e-05,  1.1935e-04, -3.1266e-04, -1.8852e-04,\n              1.1740e-04, -5.8351e-05, -5.5558e-05,  6.9126e-05,  1.3411e-04,\n              1.1673e-04,  2.1388e-05, -1.9760e-04,  4.7680e-05, -1.0828e-04,\n             -7.7702e-05,  7.6700e-05, -7.5023e-05, -5.6504e-05, -1.0994e-04,\n              8.2475e-06, -1.9212e-04, -8.7824e-05, -3.0803e-05,  1.6987e-04,\n              5.2321e-05,  1.2111e-04,  2.3284e-04, -6.6683e-05, -4.4716e-06,\n              2.9705e-05,  1.2840e-04,  3.1845e-04, -1.9584e-04,  2.1221e-05,\n              3.7008e-05, -1.0003e-04,  3.6338e-04,  2.5500e-04, -7.5012e-05,\n              5.4136e-05,  1.6768e-04,  4.1172e-05, -1.9986e-05, -1.0182e-04,\n             -9.0179e-06, -1.4406e-05,  1.4985e-04,  1.1428e-04,  1.0205e-04,\n             -1.6543e-04,  6.2570e-05,  3.2609e-04,  2.2471e-05,  1.0212e-04,\n              4.5678e-05,  3.5701e-05, -1.3773e-04,  1.4908e-04, -1.0957e-04,\n              1.1397e-04,  1.1045e-04,  1.1901e-04,  8.7968e-05,  8.9440e-05,\n              9.8300e-05,  1.6384e-05,  9.4353e-05, -9.7313e-05, -5.1588e-05,\n              1.8647e-05,  4.2800e-05, -4.5993e-05,  9.1363e-06,  2.4569e-04,\n             -2.6470e-04, -6.9423e-05, -2.0433e-04,  7.3559e-05,  1.0104e-04,\n             -2.9476e-04, -2.8825e-04,  1.4952e-04,  6.6959e-05, -6.5355e-05,\n              5.4798e-05,  1.1155e-04, -5.8416e-05, -4.4286e-05, -8.1912e-07,\n              7.5837e-05, -8.2879e-05, -4.9453e-05,  4.9612e-05,  1.4245e-04,\n              4.7932e-05, -1.2152e-04, -8.4577e-05,  7.3909e-05, -6.1568e-07,\n             -2.4326e-04, -2.1156e-04,  1.4637e-04, -2.1945e-04, -3.5473e-05,\n             -4.4607e-05, -7.9268e-05, -1.5896e-04, -2.3893e-04, -3.1341e-04,\n              2.7540e-04,  7.4637e-05,  1.5791e-04,  4.5560e-06,  8.2784e-05,\n             -1.3173e-04, -1.1681e-05,  2.4076e-05,  6.1194e-05, -1.1523e-05,\n              6.8816e-05,  6.6847e-05, -2.5726e-05,  5.9489e-05, -1.4871e-04,\n             -3.2952e-04,  5.9496e-06, -7.3434e-05, -7.6372e-05,  1.5305e-04,\n              3.0403e-05,  3.8052e-06, -4.5479e-05, -1.5327e-04,  1.5449e-04,\n              2.9737e-05,  1.0806e-04,  7.7806e-05, -1.6906e-04,  2.4109e-04,\n             -2.7795e-04,  2.0433e-04,  2.5859e-05,  8.0208e-05, -1.5860e-05,\n              5.5589e-05, -3.1228e-05,  8.0413e-06, -1.9754e-04, -1.4569e-04,\n              3.6211e-06, -1.1263e-04, -7.3271e-05, -9.7628e-05,  1.4477e-04,\n              2.7781e-04, -9.1772e-05,  2.6049e-05, -7.5948e-05, -1.9716e-04,\n              1.9509e-04, -3.1315e-04,  3.3916e-05,  5.1274e-05,  5.2459e-05,\n              1.7484e-04, -7.4628e-05, -7.2067e-05, -6.4893e-05, -1.6454e-04,\n             -7.7024e-06,  6.8359e-05, -1.0477e-04,  7.5952e-05, -4.4538e-05,\n              6.7114e-05, -1.7839e-05,  1.8358e-04,  3.5493e-05,  3.0734e-05,\n              6.8179e-05,  9.9409e-05, -1.7177e-04,  1.3229e-04,  3.2855e-05,\n             -8.6434e-05,  3.3036e-06,  9.8225e-05,  1.7114e-04,  4.4242e-05,\n             -6.1745e-05,  4.8488e-05, -6.3056e-05,  1.1903e-04, -4.2247e-05,\n              1.7024e-04,  1.1754e-04,  1.1046e-04, -9.3989e-05, -5.0676e-06,\n             -1.8870e-04,  1.2022e-04, -1.6058e-06, -1.6588e-05, -1.9009e-04,\n              9.8277e-05, -3.5542e-05,  6.5235e-05,  2.5863e-04, -7.0138e-05,\n              1.5359e-04, -5.2492e-05]),\n     'exp_avg_sq': tensor([4.2561e-08, 3.0778e-08, 3.0661e-08, 2.1744e-08, 6.0415e-08, 3.2903e-08,\n             4.1967e-08, 5.5092e-08, 2.4866e-08, 2.6971e-08, 4.5323e-08, 4.8781e-08,\n             2.1548e-08, 5.5852e-08, 3.5439e-08, 4.5494e-08, 7.4744e-08, 3.7036e-08,\n             2.4276e-08, 4.2142e-08, 3.2939e-08, 4.2095e-08, 5.4023e-08, 3.7589e-08,\n             7.2598e-08, 4.8450e-08, 3.5258e-08, 3.7147e-08, 6.8684e-08, 3.5826e-08,\n             2.6255e-08, 7.2676e-08, 6.1044e-08, 4.7305e-08, 4.3542e-08, 3.3155e-08,\n             3.7327e-08, 4.9928e-08, 2.3037e-08, 4.2169e-08, 5.4054e-08, 6.7573e-08,\n             4.9150e-08, 3.7911e-08, 4.1365e-08, 4.8627e-08, 2.8885e-08, 2.3165e-08,\n             4.4044e-08, 6.0231e-08, 1.8456e-08, 4.1203e-08, 4.3911e-08, 4.0718e-08,\n             3.9287e-08, 5.8146e-08, 3.0479e-08, 4.1950e-08, 5.4234e-08, 5.4926e-08,\n             4.8021e-08, 5.4355e-08, 2.8752e-08, 4.5408e-08, 3.0047e-08, 3.3475e-08,\n             2.8253e-08, 3.5369e-08, 5.0253e-08, 6.1682e-08, 7.2969e-08, 1.9281e-08,\n             3.7317e-08, 3.7606e-08, 3.5798e-08, 3.3958e-08, 5.3915e-08, 3.7306e-08,\n             2.5050e-08, 3.5938e-08, 3.8752e-08, 3.1479e-08, 4.7403e-08, 2.1802e-08,\n             5.7825e-08, 4.0140e-08, 3.6652e-08, 2.3293e-08, 3.6559e-08, 4.9728e-08,\n             3.8715e-08, 3.1523e-08, 3.4671e-08, 4.2534e-08, 4.3050e-08, 3.6693e-08,\n             3.6212e-08, 3.9225e-08, 5.5187e-08, 1.5660e-08, 2.4060e-08, 5.0245e-08,\n             3.0501e-08, 4.5293e-08, 4.6286e-08, 1.0366e-07, 2.8921e-08, 4.5421e-08,\n             3.2512e-08, 3.3851e-08, 4.5816e-08, 4.3195e-08, 3.9717e-08, 2.5421e-08,\n             4.8525e-08, 4.6549e-08, 5.2261e-08, 5.1076e-08, 4.8844e-08, 4.2712e-08,\n             3.4821e-08, 5.2698e-08, 5.7085e-08, 5.8804e-08, 3.0720e-08, 5.1282e-08,\n             2.9972e-08, 3.6582e-08, 4.4490e-08, 4.3395e-08, 3.9232e-08, 3.5856e-08,\n             3.1906e-08, 3.9398e-08, 2.3538e-08, 4.0095e-08, 2.4018e-08, 8.1857e-08,\n             6.8965e-08, 3.6977e-08, 5.3302e-08, 5.0051e-08, 4.1630e-08, 3.2920e-08,\n             6.7253e-08, 2.5230e-08, 3.3373e-08, 3.6596e-08, 3.1319e-08, 5.1515e-08,\n             8.7682e-08, 3.9582e-08, 2.4371e-08, 8.0788e-08, 4.2171e-08, 2.4399e-08,\n             2.1255e-08, 4.5508e-08, 3.6504e-08, 5.0672e-08, 3.5257e-08, 4.7076e-08,\n             6.6019e-08, 5.4753e-08, 3.8680e-08, 2.8813e-08, 4.1475e-08, 4.0732e-08,\n             3.6722e-08, 3.4686e-08, 3.1235e-08, 4.4832e-08, 7.0199e-08, 9.3634e-08,\n             3.2505e-08, 3.4474e-08, 4.9487e-08, 2.1850e-08, 2.6205e-08, 3.4966e-08,\n             4.4107e-08, 3.3174e-08, 2.9025e-08, 6.2537e-08, 4.3934e-08, 3.6868e-08,\n             5.1780e-08, 2.9382e-08, 3.9620e-08, 5.0519e-08, 5.6297e-08, 1.2288e-10,\n             4.7884e-08, 8.9727e-08, 1.7299e-08, 4.0065e-08, 3.1531e-08, 3.1228e-08,\n             2.3739e-08, 4.6060e-08, 3.4606e-08, 5.1968e-08, 4.9265e-08, 3.5123e-08,\n             5.5639e-08, 4.6819e-08, 2.3829e-08, 5.4518e-08, 5.1381e-07, 2.5758e-08,\n             3.4496e-08, 4.1005e-08, 5.9779e-08, 4.7778e-08, 4.4243e-08, 5.8154e-08,\n             3.3113e-08, 5.1634e-08, 3.6377e-08, 5.2560e-08, 3.5914e-08, 5.1002e-08,\n             3.9164e-08, 4.8236e-08, 3.1259e-08, 5.1914e-08, 5.9598e-08, 7.2193e-08,\n             3.3409e-08, 4.5243e-08, 3.6583e-08, 2.8355e-08, 5.1023e-08, 8.4946e-08,\n             5.2264e-08, 3.2860e-08, 4.4302e-08, 1.7980e-08, 4.3580e-08, 2.7625e-08,\n             3.6112e-08, 3.5630e-08, 5.6866e-08, 4.4084e-08, 5.0581e-08, 2.4661e-08,\n             4.7042e-08, 2.7406e-08, 4.7587e-08, 2.8213e-08, 3.1107e-08, 2.6158e-08,\n             3.6797e-08, 4.4372e-08, 3.8536e-08, 8.0989e-08, 6.8299e-08, 5.5622e-08,\n             3.3851e-08, 4.0293e-08, 3.6007e-08, 4.5156e-08, 4.0230e-08, 3.5608e-08,\n             6.3772e-08, 5.2355e-08, 5.7774e-08, 7.6469e-08, 6.1408e-08, 3.1897e-08,\n             4.0183e-08, 4.7772e-08, 4.9152e-08, 4.5453e-08, 3.9666e-08, 2.2908e-08,\n             4.2698e-08, 3.6240e-08, 3.5935e-08, 6.9636e-08, 2.5588e-08, 2.4361e-08,\n             5.0893e-08, 2.4183e-08, 6.2063e-08, 3.4823e-08, 2.1709e-08, 2.0850e-08,\n             4.8734e-08, 6.1786e-08, 8.9912e-08, 3.2527e-08, 6.9901e-08, 4.9480e-08,\n             7.9078e-08, 5.2023e-08, 3.3315e-08, 2.5992e-08, 1.9692e-08, 4.8685e-08,\n             3.5589e-08, 4.7037e-08, 3.9162e-08, 6.0155e-08, 5.2135e-08, 5.9841e-08,\n             5.2109e-08, 4.5830e-08, 3.3674e-08, 3.4866e-08, 2.8621e-08, 3.5165e-08,\n             5.0158e-08, 5.6458e-08, 4.0222e-08, 3.5268e-08, 5.0605e-08, 2.8096e-08,\n             4.0231e-08, 8.8209e-08, 2.5470e-08, 5.4447e-08, 8.5913e-08, 3.3472e-08,\n             3.9533e-08, 3.5645e-08, 3.4986e-08, 2.1657e-08, 8.1188e-08, 3.5795e-08,\n             5.0813e-08, 3.7622e-08, 8.5525e-08, 5.3193e-08, 3.5382e-08, 4.1769e-08,\n             3.4475e-08, 7.2413e-08, 3.0631e-08, 5.6190e-08, 3.4485e-08, 3.8428e-08,\n             3.4760e-08, 3.1270e-08, 2.7859e-08, 1.2925e-08, 4.8077e-08, 4.9058e-08,\n             3.4927e-08, 2.6393e-08, 2.2609e-08, 2.9478e-08, 6.3978e-08, 5.8866e-08,\n             2.8288e-08, 2.9159e-08, 4.7003e-08, 3.3844e-08, 5.6532e-08, 3.2892e-08,\n             2.4148e-08, 4.3189e-08, 4.8071e-08, 3.2490e-08, 2.5630e-08, 4.1835e-08,\n             3.5353e-08, 4.3356e-08, 4.2802e-08, 7.3530e-08, 2.4311e-08, 4.5748e-08,\n             6.1355e-08, 3.4035e-08, 4.5245e-08, 7.6896e-08, 3.5563e-08, 2.5406e-08,\n             2.6970e-08, 6.7341e-08, 3.1890e-08, 4.7144e-08, 5.0093e-08, 4.3046e-08,\n             3.2284e-08, 3.5065e-08, 6.4603e-08, 5.1391e-08, 3.4216e-08, 5.9616e-08,\n             4.2920e-08, 3.3926e-08, 6.0766e-08, 2.9502e-08, 3.5742e-08, 2.8540e-08,\n             4.5120e-08, 4.2465e-08, 5.6047e-08, 2.7578e-08, 3.6661e-08, 4.1174e-08,\n             4.3374e-08, 3.1038e-08, 4.8008e-08, 6.1339e-08, 2.7535e-08, 3.6459e-08,\n             5.7668e-08, 5.7690e-08, 4.1206e-08, 5.3457e-08, 5.1940e-08, 4.7694e-08,\n             2.4033e-08, 4.3514e-08, 3.3799e-08, 3.7304e-08, 2.6356e-08, 3.6077e-08,\n             3.7014e-08, 4.2347e-08, 5.9743e-08, 2.8603e-08, 3.4139e-08, 3.5788e-08,\n             3.3640e-08, 4.3355e-08, 3.5560e-08, 7.3116e-08, 3.8867e-08, 4.6396e-08,\n             5.8053e-08, 5.0690e-08, 1.9020e-08, 6.8545e-08, 3.8967e-08, 4.3709e-08,\n             3.0646e-08, 4.3930e-08, 5.1396e-08, 2.5426e-08, 4.8884e-08, 3.6513e-08,\n             2.1962e-08, 3.0233e-08, 5.0123e-08, 3.8845e-08, 4.9643e-08, 4.3178e-08,\n             4.6577e-08, 5.4232e-08, 3.4135e-08, 3.9237e-08, 5.1555e-08, 5.7522e-08,\n             4.7932e-08, 5.4763e-08, 4.2169e-08, 5.1714e-08, 4.0798e-08, 4.1016e-08,\n             8.9705e-08, 5.1453e-08, 4.1104e-08, 4.2657e-08, 4.6512e-08, 4.7047e-08,\n             4.1827e-08, 5.3441e-08, 3.7387e-08, 4.8216e-08, 5.5138e-08, 2.1162e-08,\n             2.7642e-08, 2.8658e-08, 4.1659e-08, 3.7632e-08, 2.3898e-08, 4.3128e-08,\n             4.1987e-08, 3.4003e-08, 2.2011e-08, 2.3302e-08, 3.7973e-08, 3.2181e-08,\n             3.2232e-08, 3.6096e-08, 4.2494e-08, 4.7240e-08, 3.7028e-08, 5.0094e-08,\n             4.4360e-08, 4.6756e-08, 4.0396e-08, 5.1821e-08, 3.9618e-08, 3.9677e-08,\n             4.1910e-08, 4.9596e-08, 3.3566e-08, 3.0567e-08, 4.0555e-08, 2.9193e-08,\n             6.3149e-08, 2.7696e-08, 3.4283e-08, 1.9409e-08, 4.7666e-08, 2.5497e-08,\n             3.0913e-08, 4.9769e-08])},\n    98: {'exp_avg': tensor([-7.1733e-05, -9.7006e-05,  1.5009e-04,  ..., -1.3593e-04,\n              7.5416e-05,  9.4176e-05]),\n     'exp_avg_sq': tensor([1.7535e-08, 1.9557e-08, 2.1879e-08,  ..., 3.7913e-08, 2.2649e-08,\n             2.0766e-08])},\n    99: {'exp_avg': tensor([ 2.9993e-05,  6.0801e-05, -1.1772e-04,  ..., -4.7603e-06,\n              4.1094e-05, -3.4091e-05]),\n     'exp_avg_sq': tensor([9.9925e-09, 1.3756e-08, 1.7161e-08,  ..., 2.4053e-08, 1.6598e-08,\n             2.1289e-08])},\n    100: {'exp_avg': tensor([-1.6624e-04, -1.3400e-04,  9.1333e-04, -7.3094e-05, -1.1253e-03,\n             -4.9801e-04, -1.5260e-05,  2.3455e-04,  4.4021e-04,  3.0176e-04,\n             -3.0518e-04, -5.8598e-04,  8.1059e-04,  1.4345e-04,  3.9101e-04,\n             -3.4196e-05,  4.9001e-04,  4.3951e-05, -8.9590e-05, -9.3736e-05,\n             -6.7466e-04,  2.6713e-04,  2.5964e-04,  5.0770e-04,  3.5935e-05,\n              1.6089e-04, -1.2250e-03,  3.3440e-04, -7.7258e-04, -5.3334e-04,\n              2.6636e-04, -1.3980e-03, -9.5131e-04,  1.6901e-04, -1.5076e-03,\n             -1.5387e-05,  4.8186e-05,  1.1960e-04,  2.3433e-04,  7.5431e-05,\n              1.2977e-05, -6.0068e-04,  3.3442e-04,  1.0365e-04,  1.2000e-05,\n              1.7041e-04, -1.1483e-04,  3.1440e-03, -1.9007e-03, -8.3939e-04,\n             -1.4217e-05, -4.9236e-04,  3.9008e-04,  3.9848e-04, -6.0040e-04,\n             -1.2250e-03, -2.6500e-04, -4.1276e-05,  1.1061e-03,  2.7087e-04,\n              1.7625e-04, -3.2393e-04,  2.4369e-04, -6.1100e-05, -1.1865e-04,\n             -1.9693e-06,  3.3462e-05, -2.2420e-04, -2.1922e-04, -5.8869e-04,\n             -8.9723e-04,  7.4833e-05, -2.6745e-04,  2.9873e-04, -8.0952e-04,\n              1.2861e-03, -1.0134e-04, -8.5023e-05, -1.6669e-04,  2.3348e-04,\n             -8.3815e-04, -2.4370e-04,  1.2476e-04,  8.4492e-05, -5.4304e-04,\n              1.6311e-04, -5.6567e-05, -3.6275e-04,  1.6830e-03,  2.0059e-04,\n              4.1820e-04, -3.9252e-04, -1.6745e-04, -2.5124e-04,  3.8553e-04,\n              4.4152e-04,  1.8015e-04, -3.7431e-05, -3.7713e-04,  9.2000e-05,\n             -8.5954e-04,  9.6515e-04,  1.9941e-03, -5.2204e-05,  2.5237e-04,\n             -2.3669e-04, -2.0026e-05, -2.3897e-03,  2.3479e-04,  1.9110e-04,\n              2.4119e-04, -2.5781e-04,  2.6655e-04, -1.0960e-03, -2.3588e-04,\n              5.4125e-04, -9.7470e-04,  1.1054e-04,  7.1879e-05,  3.7784e-04,\n              6.1492e-05,  1.9290e-04, -6.2759e-05, -1.0605e-04, -6.6753e-05,\n             -7.3784e-04, -9.5179e-04, -2.0892e-03, -3.1533e-04, -1.2517e-04,\n             -5.5356e-04, -3.3888e-04,  8.7335e-04, -4.3580e-05, -2.1520e-04,\n              5.0161e-04, -1.8687e-03,  2.6182e-05, -1.8098e-05,  6.5399e-04,\n              7.3410e-04,  4.3045e-04,  5.6560e-05,  3.3075e-04,  4.2344e-04,\n              3.3226e-05, -3.2867e-04, -4.9841e-04,  2.2801e-04, -2.7030e-04,\n              1.0075e-04,  1.3219e-03, -3.6168e-05,  1.1935e-04,  2.7856e-05,\n             -1.7334e-04, -1.4660e-04,  3.3522e-05, -5.5425e-04, -1.4474e-04,\n             -1.9263e-07, -7.1447e-04, -1.5752e-04, -8.5576e-04,  6.5136e-05,\n              2.0383e-04,  3.1509e-04,  6.4634e-04, -8.3155e-04, -1.1618e-04,\n              2.7661e-03,  3.7322e-04,  9.3820e-04, -2.0914e-05,  3.7813e-04,\n             -4.5253e-04, -7.8103e-04,  1.8047e-04,  2.4232e-04,  4.7705e-04,\n             -4.2050e-04,  1.1451e-03, -8.9614e-04,  1.4866e-04, -3.4054e-04,\n             -4.2738e-04, -2.4049e-04, -3.5446e-04, -1.0011e-04,  1.6684e-04,\n             -1.2008e-04, -6.6835e-04,  2.1647e-04, -1.9534e-04,  4.0959e-04,\n             -9.5417e-05, -2.9730e-03,  4.3641e-04, -3.3108e-04,  9.7467e-04,\n             -1.1064e-04, -7.5854e-04, -5.4899e-05, -4.4327e-04, -2.7529e-03,\n              9.8354e-04, -9.8052e-06,  2.0157e-04, -6.5734e-04,  3.4517e-04,\n              4.9588e-04,  2.4441e-04, -3.2849e-04, -1.3644e-04, -1.7629e-04,\n             -5.1118e-05, -2.1598e-04, -1.0100e-03, -1.7993e-03,  5.7316e-05,\n              1.5378e-04, -1.1250e-04, -1.9116e-04,  1.1329e-04,  5.8888e-04,\n              2.3863e-04,  3.5073e-04, -3.8386e-04,  1.9177e-04,  2.8416e-04,\n             -1.7959e-03, -3.7269e-04, -9.9935e-04,  1.3073e-04, -7.2600e-04,\n              3.6982e-04,  4.9722e-04, -7.4299e-04, -5.9921e-04,  2.2673e-03,\n              1.6449e-03,  7.0587e-04, -1.3449e-04,  3.4402e-04, -9.7191e-04,\n              5.0537e-04, -1.2065e-03,  5.2520e-04,  9.7814e-05, -1.2133e-03,\n             -4.1362e-04,  1.6737e-04,  1.4707e-04,  5.2292e-04,  2.2558e-04,\n             -3.2688e-03,  1.4110e-04, -1.0349e-03, -1.0579e-04, -8.6839e-04,\n             -6.0087e-05,  2.6161e-04, -1.5653e-05, -9.4630e-05,  8.3893e-05,\n              2.8288e-04,  1.3165e-04,  7.4776e-05, -3.7547e-05, -2.1147e-04,\n             -1.0257e-03, -5.5582e-04,  4.0914e-05, -8.5555e-04, -2.9316e-04,\n             -6.0103e-04, -3.7189e-04,  1.7033e-04, -3.4682e-04, -8.1215e-04,\n             -8.9001e-04, -9.7080e-04,  4.9443e-04,  4.5617e-05,  4.6814e-04,\n             -5.1464e-04,  1.5457e-05,  6.9511e-05, -8.8497e-05, -5.8371e-04,\n              2.7725e-04,  1.9747e-04,  2.2633e-04,  8.5515e-04,  7.1206e-04,\n              5.4992e-05,  4.2553e-05,  3.2684e-04,  2.6967e-04,  1.5493e-03,\n              6.7286e-04,  1.7790e-04, -2.6411e-04,  3.0289e-04,  1.3509e-04,\n              1.9539e-04, -1.4746e-03, -1.9658e-04,  1.0022e-04,  8.2822e-05,\n              1.1979e-03,  2.7941e-06, -1.9386e-04, -3.1926e-04, -5.8658e-04,\n              6.6482e-04,  6.6748e-04,  2.2143e-04,  2.4311e-04, -9.8250e-04,\n              3.2642e-04,  1.6357e-04,  7.3118e-05,  2.0170e-04,  5.1056e-04,\n             -3.4283e-04, -8.0887e-04,  4.8272e-04, -1.7629e-04, -4.6490e-04,\n              5.6794e-04, -1.3190e-03, -4.7475e-04, -2.9677e-04, -4.8014e-05,\n             -6.7323e-04, -1.4946e-05,  4.3353e-04,  3.4400e-05, -1.8172e-04,\n             -1.1492e-04,  2.1242e-04, -3.3368e-04, -3.1015e-04,  3.0942e-04,\n             -1.8120e-03, -2.8941e-03,  4.0933e-04, -3.7238e-05,  1.1830e-03,\n              9.6972e-04,  6.7786e-06, -1.0543e-04,  1.2957e-04, -3.0308e-04,\n              7.6060e-04, -6.7232e-05,  5.7820e-05, -4.8709e-04,  6.1979e-04,\n              3.4025e-05,  3.5888e-04,  7.4684e-04,  3.5612e-04, -9.0721e-04,\n              6.9630e-04,  3.9315e-04, -3.2984e-04,  4.7320e-04,  5.7028e-04,\n              3.7687e-04,  2.7795e-04,  3.1661e-04, -1.1194e-04,  1.6063e-04,\n             -5.3940e-04, -4.5499e-05, -1.2694e-04,  2.9092e-04,  1.3572e-03,\n              3.7800e-04, -4.8748e-05,  6.5105e-04,  2.4152e-05,  4.0631e-04,\n             -5.1047e-05,  5.3291e-04, -4.7777e-04, -2.1245e-04, -3.6669e-04,\n              6.3958e-04,  1.8770e-03, -3.6941e-04, -1.9386e-04, -3.3897e-04,\n              1.3774e-04,  1.1378e-03, -2.4583e-05,  7.7801e-05,  1.4634e-04,\n              1.0879e-03, -6.1475e-05,  6.8949e-07, -8.2274e-05,  5.0382e-04,\n              6.2431e-04, -2.1260e-05,  1.1234e-04, -1.6343e-04,  2.2045e-04,\n              1.2412e-04,  2.4592e-04,  2.8931e-06, -5.9159e-04, -1.5834e-03,\n             -1.6817e-04,  3.1242e-04, -5.5127e-05, -7.2767e-06,  3.0090e-04,\n              3.2360e-04, -8.4617e-04,  5.6242e-05,  5.8855e-04,  3.1397e-04,\n             -2.5414e-05,  1.3898e-04,  3.6586e-04,  1.2537e-04, -3.4333e-04,\n             -2.5521e-05,  2.3139e-04, -1.6733e-04, -2.9087e-04, -3.6565e-05,\n             -9.7656e-05, -2.3969e-04,  3.4194e-04,  4.9932e-04,  6.6879e-05,\n             -2.2610e-04,  3.9740e-06,  2.5489e-04,  1.7409e-03,  8.1926e-04,\n              7.6894e-04, -2.3774e-04, -5.5136e-05,  1.1735e-04,  1.4629e-04,\n             -1.0995e-03,  3.1857e-04, -8.9093e-04, -1.7355e-03, -8.4715e-05,\n             -6.9747e-05,  2.1622e-04, -2.3877e-06,  3.2006e-04, -2.8547e-04,\n              5.0297e-05, -4.8859e-04, -5.5641e-05,  5.0961e-04, -1.8979e-03,\n             -1.0317e-04, -2.3465e-04,  2.7396e-05, -3.7400e-04, -8.3312e-05,\n              2.6097e-04, -1.1967e-04,  3.9354e-04,  1.3949e-04,  8.9623e-04,\n             -7.3650e-06,  1.2338e-03, -2.7637e-04,  1.4823e-04, -3.0777e-05,\n              9.9498e-05, -4.5035e-04,  2.1019e-04,  5.9182e-04,  1.3928e-03,\n              1.4378e-04,  1.1750e-04, -2.4551e-04, -3.1954e-04,  7.2894e-05,\n             -4.4089e-04, -2.4331e-04, -8.5069e-04,  4.0871e-04, -1.2653e-05,\n              4.1494e-04, -2.7821e-04, -7.5745e-05, -4.7192e-04, -1.9846e-04,\n              4.4823e-05, -4.6811e-04, -2.8879e-05,  5.4198e-04,  1.8566e-04,\n             -8.8757e-05,  2.2397e-04,  1.7690e-04,  3.5442e-04,  2.1542e-04,\n              2.4716e-04,  1.6201e-03]),\n     'exp_avg_sq': tensor([1.5079e-07, 8.5425e-07, 8.0192e-07, 1.7872e-06, 9.5825e-07, 4.1031e-07,\n             2.1695e-07, 1.1276e-07, 1.8676e-06, 8.9559e-07, 3.4487e-07, 4.7793e-07,\n             1.6726e-06, 2.0216e-07, 3.8232e-07, 2.6039e-07, 2.5513e-07, 4.8633e-07,\n             1.9866e-07, 4.0593e-07, 1.6598e-07, 7.3221e-07, 7.8425e-07, 2.2371e-07,\n             1.0606e-07, 2.2692e-07, 2.7465e-06, 6.0072e-07, 9.4249e-07, 6.2133e-07,\n             2.8670e-07, 3.5256e-06, 3.2177e-07, 1.3170e-07, 2.6705e-06, 1.2706e-06,\n             1.9172e-06, 1.1068e-07, 3.7522e-07, 3.3438e-07, 1.0319e-07, 1.8616e-07,\n             1.7571e-07, 2.4215e-07, 1.2024e-07, 3.8856e-07, 3.5122e-07, 1.9560e-06,\n             3.1440e-06, 1.4414e-06, 2.1777e-07, 1.3805e-07, 1.0940e-07, 1.9555e-07,\n             2.5271e-07, 6.9391e-07, 9.9758e-08, 1.1781e-07, 6.1605e-07, 1.4184e-07,\n             2.5361e-07, 1.0814e-07, 1.2901e-07, 2.4012e-07, 3.6697e-07, 1.1771e-07,\n             2.3412e-07, 1.0714e-07, 9.7085e-08, 2.1230e-06, 8.2632e-07, 1.4635e-07,\n             2.4340e-07, 1.0427e-07, 6.0877e-07, 7.7955e-07, 8.5283e-08, 6.9088e-07,\n             3.0361e-07, 1.5961e-07, 2.2153e-06, 1.3041e-07, 1.1923e-07, 1.2043e-07,\n             2.9872e-07, 4.0134e-07, 3.1029e-07, 2.2812e-07, 9.4041e-07, 1.4106e-07,\n             2.9685e-07, 3.0851e-07, 2.8612e-06, 6.3115e-07, 1.6118e-07, 1.7838e-07,\n             1.9324e-07, 1.7717e-07, 6.3528e-07, 1.1343e-06, 1.5817e-06, 6.3173e-07,\n             1.1446e-06, 5.8892e-07, 1.6310e-07, 1.5766e-07, 2.9899e-06, 5.9875e-06,\n             2.2978e-07, 1.9640e-07, 3.2668e-07, 3.3897e-06, 3.0637e-07, 1.6905e-06,\n             1.3662e-07, 2.7090e-07, 1.4456e-06, 1.3097e-07, 2.1577e-07, 4.3334e-07,\n             4.0735e-07, 3.5513e-07, 3.0072e-07, 1.3385e-07, 4.3414e-07, 4.4994e-07,\n             6.2459e-07, 1.8657e-06, 4.9347e-07, 9.5690e-07, 1.6714e-07, 1.2488e-07,\n             2.0020e-06, 2.8994e-06, 6.7357e-07, 2.1281e-07, 9.4633e-07, 2.3209e-07,\n             8.4610e-08, 5.5399e-07, 4.0049e-07, 8.2661e-07, 1.4359e-06, 3.7784e-07,\n             4.6044e-07, 9.0143e-08, 2.8150e-07, 5.3730e-07, 1.7300e-07, 1.3147e-06,\n             1.9691e-07, 3.2334e-06, 5.0749e-07, 1.9067e-07, 1.6232e-06, 7.9798e-08,\n             2.3078e-07, 1.1603e-07, 1.2683e-06, 4.2681e-07, 9.4031e-08, 1.1009e-06,\n             3.1997e-07, 1.6315e-06, 1.9005e-07, 1.8765e-07, 2.8660e-07, 2.1805e-07,\n             4.4350e-07, 1.8148e-07, 1.7019e-06, 2.7721e-07, 3.9451e-07, 1.4738e-07,\n             1.6868e-07, 3.5434e-06, 3.0802e-07, 1.2391e-06, 5.7182e-07, 6.3913e-07,\n             2.5431e-07, 1.0646e-06, 1.6112e-06, 2.0124e-07, 4.4335e-07, 2.8262e-07,\n             1.0274e-07, 1.3822e-07, 2.6132e-06, 1.8168e-07, 3.6467e-07, 4.3115e-07,\n             2.1029e-07, 1.4479e-07, 1.7065e-07, 5.6838e-07, 3.8272e-06, 2.1135e-07,\n             4.7697e-06, 2.5575e-06, 2.5320e-07, 4.1458e-06, 6.3555e-07, 1.3783e-07,\n             4.5791e-06, 1.0907e-06, 8.8895e-07, 2.7592e-07, 4.9553e-07, 1.5347e-07,\n             3.1018e-07, 1.8343e-07, 2.0766e-06, 2.7799e-07, 1.6975e-07, 2.0015e-07,\n             8.9849e-07, 1.4102e-06, 8.6165e-07, 2.2881e-07, 1.3835e-07, 1.0336e-07,\n             1.4746e-07, 3.0951e-07, 1.3985e-07, 1.2417e-07, 3.5840e-07, 2.3120e-07,\n             1.3955e-06, 1.6006e-07, 7.1988e-07, 1.0371e-06, 2.3904e-06, 3.8074e-07,\n             1.2386e-06, 4.9338e-07, 2.7792e-07, 1.1994e-06, 3.2819e-07, 2.4053e-06,\n             1.0882e-06, 2.4032e-06, 1.3166e-07, 6.0558e-07, 6.6799e-07, 1.9829e-07,\n             1.0392e-06, 1.9571e-07, 2.7519e-07, 5.7565e-07, 4.7816e-07, 2.7610e-07,\n             1.2707e-07, 5.8997e-07, 1.4886e-07, 1.1542e-05, 8.6001e-07, 1.0181e-06,\n             4.7122e-07, 2.5986e-06, 1.3062e-06, 1.9803e-07, 4.1614e-07, 6.5638e-07,\n             4.7251e-07, 2.9780e-07, 1.3485e-07, 2.3860e-07, 1.1576e-07, 1.7377e-07,\n             1.0384e-06, 2.3736e-07, 1.9255e-07, 3.6983e-06, 2.1823e-07, 7.1013e-07,\n             1.6842e-06, 1.9647e-06, 5.9801e-07, 1.9439e-06, 2.7010e-06, 1.6230e-06,\n             2.5707e-07, 1.4109e-07, 4.2399e-07, 4.9231e-07, 1.9951e-07, 1.7462e-07,\n             7.8519e-07, 1.3787e-06, 8.4221e-07, 2.1460e-07, 9.3218e-07, 1.9848e-06,\n             1.9473e-06, 5.1164e-07, 2.1031e-07, 6.9555e-07, 2.2861e-07, 1.3299e-06,\n             1.0658e-06, 9.7684e-08, 4.6305e-07, 3.5666e-07, 1.5878e-07, 3.8079e-07,\n             3.0751e-06, 5.6021e-07, 9.4958e-08, 2.3467e-07, 7.6731e-07, 2.0517e-07,\n             1.1473e-07, 2.4625e-07, 3.7595e-06, 8.5350e-07, 1.6346e-06, 1.6680e-06,\n             1.2156e-07, 1.2988e-06, 6.4974e-07, 1.4710e-06, 3.0987e-07, 3.2817e-07,\n             4.5615e-07, 2.2650e-07, 7.5757e-07, 1.9783e-07, 2.1741e-07, 2.8638e-06,\n             5.1192e-07, 2.1404e-06, 1.1945e-06, 4.5721e-06, 3.0651e-06, 2.0636e-07,\n             1.7101e-07, 1.4732e-07, 1.7595e-07, 1.6555e-07, 5.0558e-07, 2.5884e-07,\n             3.5747e-07, 4.2873e-07, 1.9858e-07, 3.7123e-06, 3.6647e-06, 1.5212e-07,\n             8.0691e-07, 2.8233e-06, 1.8434e-06, 1.0442e-07, 3.3545e-07, 8.2476e-08,\n             2.4390e-07, 8.2055e-07, 9.0891e-08, 3.7211e-07, 5.2829e-07, 4.2049e-07,\n             1.6000e-07, 3.8200e-07, 1.4963e-06, 3.4923e-07, 3.6731e-07, 2.7789e-07,\n             1.5852e-07, 5.0981e-07, 6.6043e-07, 3.3756e-06, 1.1602e-06, 4.6261e-07,\n             9.5716e-08, 1.0294e-07, 4.8085e-07, 5.2379e-07, 3.3139e-07, 7.7416e-07,\n             2.3432e-07, 2.0467e-06, 9.0808e-07, 3.9990e-07, 4.8680e-07, 3.6282e-07,\n             1.5883e-07, 2.7445e-07, 1.7747e-07, 4.1787e-07, 1.5221e-06, 2.8851e-07,\n             3.0985e-07, 8.1427e-07, 2.2076e-06, 9.0060e-07, 3.4411e-07, 1.6854e-07,\n             9.0129e-07, 4.8054e-07, 3.6625e-07, 6.6703e-07, 7.7951e-07, 1.0448e-06,\n             1.4164e-07, 1.5545e-07, 1.9448e-07, 2.0368e-07, 1.1872e-07, 2.6624e-06,\n             9.1995e-08, 1.2620e-07, 1.8095e-07, 1.5257e-07, 2.3377e-07, 3.3105e-07,\n             1.3130e-06, 3.6271e-06, 1.2872e-07, 1.5882e-07, 8.1149e-08, 1.5732e-07,\n             6.5565e-07, 2.8272e-07, 1.2766e-07, 6.6204e-07, 1.6467e-07, 3.1948e-06,\n             1.1891e-06, 1.6044e-07, 1.4425e-07, 5.8253e-07, 3.9814e-07, 1.0237e-07,\n             2.2240e-07, 2.8069e-07, 2.2783e-07, 2.2230e-07, 1.2970e-07, 9.4957e-07,\n             7.6089e-07, 1.7905e-07, 2.7340e-07, 1.8772e-07, 1.1710e-07, 1.1369e-06,\n             5.4204e-07, 3.7277e-07, 1.6419e-07, 1.8420e-07, 3.0111e-07, 2.2311e-07,\n             2.8952e-06, 9.3804e-07, 2.5326e-06, 2.6008e-06, 1.4490e-07, 1.4208e-06,\n             3.9581e-07, 1.7433e-07, 2.2248e-07, 6.7663e-07, 2.4558e-07, 1.4230e-06,\n             1.8466e-07, 7.6011e-07, 3.5713e-06, 3.0947e-07, 1.0698e-06, 3.6608e-07,\n             2.9516e-06, 2.0714e-07, 7.8185e-08, 3.1324e-07, 1.8066e-06, 1.8501e-07,\n             4.3576e-07, 1.9103e-07, 4.3518e-07, 2.2452e-07, 1.7786e-07, 2.3894e-07,\n             4.3864e-07, 1.7563e-06, 5.5581e-07, 5.5560e-07, 4.8396e-06, 2.6896e-07,\n             1.3724e-07, 3.8944e-07, 2.2689e-07, 9.3438e-07, 1.9544e-07, 2.7849e-07,\n             1.2236e-06, 1.0156e-07, 1.3112e-06, 5.7393e-07, 8.3726e-07, 1.0453e-07,\n             4.4813e-07, 9.4787e-08, 1.1729e-07, 4.4267e-06, 2.0770e-07, 3.3609e-07,\n             1.3639e-07, 3.9343e-07, 2.4900e-06, 2.6752e-06, 2.1267e-07, 3.4731e-07,\n             2.6047e-06, 9.3424e-07])},\n    101: {'exp_avg': tensor([-6.0159e-05, -1.2882e-04,  4.6162e-04, -1.7347e-04, -5.5743e-04,\n             -2.8122e-04, -4.9004e-05,  7.0564e-05,  9.6887e-05,  8.4195e-04,\n             -9.4448e-05, -1.4296e-04,  1.8418e-04,  6.2189e-05,  1.0720e-04,\n             -1.3866e-05,  9.0457e-05,  2.8177e-05,  4.6734e-06,  1.7990e-05,\n             -1.8632e-04,  2.7929e-04,  5.8713e-05,  1.7465e-04,  3.2829e-05,\n              4.1752e-05, -4.6892e-04,  7.9876e-05, -1.0785e-04, -1.2822e-04,\n              1.0245e-04, -5.3403e-04, -3.8991e-04,  5.9469e-05, -4.0240e-04,\n             -8.3390e-05, -6.8246e-05,  3.8566e-05,  8.1586e-05,  2.6111e-05,\n              3.0119e-05, -2.3782e-04,  9.5829e-05,  3.3805e-05, -8.2498e-06,\n              7.0989e-05, -5.1811e-05,  2.6657e-03, -6.2656e-04, -3.3151e-04,\n             -2.7244e-06, -1.8952e-04,  1.6764e-04,  1.4929e-04, -2.4146e-04,\n             -4.6185e-04, -1.1851e-04, -3.1586e-05,  6.4768e-04,  1.0397e-04,\n              8.8855e-05, -1.2087e-04,  8.4256e-05, -1.3116e-04, -1.0097e-04,\n             -8.3187e-06, -2.9950e-06, -1.1232e-04, -8.7770e-05, -3.2181e-04,\n             -3.6033e-04,  2.1548e-05, -1.2168e-04,  1.1758e-04, -4.4781e-04,\n              4.9679e-04, -4.8829e-05, -3.3877e-04, -9.2180e-05,  8.6798e-05,\n             -4.8573e-04, -8.3821e-05,  5.6777e-05,  2.2667e-05, -2.2072e-04,\n              5.7262e-05, -5.1488e-05, -7.3715e-05,  2.5954e-04,  7.5400e-05,\n              1.5948e-04, -1.1761e-04, -6.9507e-05, -1.7496e-04,  1.1793e-04,\n              1.8078e-04,  5.0391e-05, -1.8438e-05, -1.5439e-04,  8.6319e-05,\n             -4.0192e-04,  3.5661e-04,  1.3038e-03, -7.9353e-06,  8.9137e-05,\n             -1.6976e-04,  4.9792e-05, -9.1010e-04,  9.3857e-05,  6.6804e-05,\n              8.7136e-05, -1.0881e-04,  6.7108e-05, -2.7576e-04, -1.0543e-04,\n              2.1164e-04, -5.0547e-04,  4.4849e-05,  3.4089e-05,  3.2203e-04,\n              1.4694e-05,  5.3177e-05, -4.2038e-05, -3.5058e-05,  1.2198e-05,\n             -2.3403e-04, -3.8613e-04, -5.9410e-04, -8.2455e-05, -1.1724e-04,\n             -1.8631e-04, -1.5229e-04,  2.8123e-04,  5.7823e-05, -2.1761e-04,\n              1.9521e-04, -5.4545e-04,  7.5358e-06, -1.1225e-05,  2.8181e-04,\n              2.9085e-04,  5.0780e-05,  3.8770e-05,  1.2373e-04,  1.9871e-04,\n              1.6468e-05, -1.1017e-04, -1.8155e-04,  3.9712e-05, -8.9938e-05,\n              2.9789e-05,  5.7991e-04, -1.3193e-05,  1.3447e-05, -7.8380e-05,\n             -7.2444e-05, -3.2863e-05,  2.8948e-05, -4.4663e-04, -4.1012e-05,\n             -1.8774e-05, -1.3590e-04, -9.5708e-05, -3.5464e-04,  4.1466e-05,\n              6.6902e-05,  1.0840e-04,  2.1335e-04, -3.4849e-04, -3.5248e-05,\n              3.5745e-04,  1.7332e-04,  4.1113e-04,  2.6140e-07,  1.6513e-04,\n              3.9741e-05, -3.3172e-04,  1.6949e-05,  9.1157e-05,  1.1306e-04,\n             -1.5843e-04,  4.3475e-04, -3.6452e-04,  5.2370e-05, -1.3205e-04,\n             -1.9434e-04, -1.0185e-04, -1.5004e-04, -1.0369e-04,  3.7868e-05,\n             -2.3302e-05, -2.4438e-04,  9.1666e-05, -7.3545e-05,  1.1585e-04,\n             -3.9563e-05, -8.2230e-04,  1.7457e-04,  4.0780e-06,  3.8290e-04,\n             -4.8380e-05, -1.3950e-04, -9.9992e-05, -1.7216e-04, -1.0303e-03,\n              2.0173e-04, -5.4788e-05,  5.4076e-05, -1.8568e-04,  1.4233e-04,\n              1.3748e-04,  8.2558e-05, -3.4478e-04, -5.3091e-05, -1.1121e-04,\n             -1.2370e-05, -4.1778e-04, -4.1275e-04, -5.1760e-04,  7.5303e-05,\n              4.4472e-05, -4.9306e-05, -7.2565e-05,  4.5765e-05,  2.2934e-04,\n              1.1172e-04,  1.3335e-04, -1.5989e-04,  8.7760e-05,  1.4802e-04,\n             -9.0340e-04, -1.0324e-04, -3.1643e-04,  6.3017e-05, -2.3994e-04,\n              6.3965e-05,  1.6769e-04, -3.7502e-04, -2.3699e-04,  1.4976e-03,\n              7.1318e-04, -1.4299e-04, -6.1935e-05,  3.7583e-05, -1.9968e-04,\n              1.9726e-04, -3.1978e-04,  1.9110e-04,  1.3370e-04, -5.3003e-04,\n             -9.9124e-05,  4.0823e-05,  4.8446e-05,  1.2841e-04,  7.9082e-05,\n             -6.9956e-04, -9.1856e-05, -3.6043e-04, -3.7565e-05, -1.9727e-04,\n             -2.5199e-04,  1.1511e-04, -1.1921e-04, -1.5383e-04,  1.5304e-05,\n              9.2245e-05,  3.5463e-05,  3.2419e-05, -1.2833e-05, -9.1747e-05,\n             -5.2020e-04, -2.3763e-04, -1.8819e-05, -3.9895e-04, -5.7129e-05,\n             -1.9754e-04,  8.1126e-06,  2.0041e-05, -2.0927e-04, -1.8722e-04,\n             -3.8080e-04, -4.4878e-04,  2.2165e-04, -4.3719e-06,  1.2998e-04,\n             -2.0893e-04,  1.0450e-05,  4.3888e-05,  5.0219e-05, -2.3968e-04,\n              9.0615e-05,  1.1237e-04,  9.1823e-05,  1.3296e-04,  1.9891e-04,\n              1.5548e-06,  1.4140e-05,  8.2207e-05,  1.0383e-04,  4.5876e-04,\n              4.1494e-04,  3.0017e-05, -5.4448e-05,  1.1003e-04,  5.7164e-05,\n              9.3779e-05, -5.8410e-04, -1.1454e-04,  3.3104e-05,  1.8878e-04,\n              5.7188e-04,  1.9021e-05, -5.5380e-05, -1.6324e-04, -8.1778e-06,\n              2.4200e-04,  3.1434e-04, -1.8003e-05,  7.9853e-05, -3.5460e-04,\n              2.2215e-04,  8.2898e-05, -9.9489e-05,  3.9360e-05,  1.7426e-04,\n             -1.5830e-04, -4.0650e-04,  1.9030e-04, -5.9469e-05, -7.7017e-05,\n              1.7723e-04, -6.9449e-04, -2.4625e-04, -8.6931e-05, -2.7681e-05,\n             -3.2618e-04, -5.9690e-05,  1.2969e-04, -4.5616e-06, -8.9286e-05,\n             -5.8648e-05,  1.1463e-04, -1.2035e-04, -1.1237e-04,  1.1208e-04,\n             -5.6553e-04, -1.1466e-03,  1.7913e-04, -1.7247e-05,  3.0072e-04,\n              5.7115e-05, -3.3005e-06, -3.8298e-05,  3.0994e-05, -1.0819e-04,\n              3.3401e-04, -1.1074e-05,  8.9536e-06, -1.8496e-04,  2.3863e-04,\n             -1.1223e-05,  1.5480e-04,  2.0990e-04,  1.1220e-04, -3.3678e-04,\n              2.4955e-04,  1.3990e-04, -1.6963e-04,  4.2654e-05,  1.4867e-04,\n              2.7562e-04,  7.5164e-05,  1.1060e-04, -5.5564e-05,  3.2974e-06,\n             -2.7176e-04, -9.9693e-06, -9.1113e-05,  1.9388e-04,  3.5313e-04,\n              1.6213e-04, -1.0976e-05,  2.6902e-04,  3.4251e-05,  1.1729e-04,\n             -5.3352e-05,  1.7611e-04, -1.8098e-04, -9.7986e-06, -1.6891e-04,\n              2.3254e-04,  1.2826e-03, -2.1654e-04, -1.1562e-04, -1.3003e-04,\n              6.0998e-05,  4.3199e-04, -3.7822e-05,  6.7309e-05,  1.2240e-04,\n              5.9932e-04, -4.4963e-05, -1.5904e-06, -3.6994e-05,  2.0199e-04,\n              2.4487e-04, -2.5339e-05, -1.7632e-04, -6.0575e-05,  9.9647e-05,\n              3.9854e-05,  9.6636e-05,  1.3249e-05, -2.6628e-04, -1.2082e-04,\n              6.5259e-05,  1.1423e-04, -4.8850e-05, -1.9553e-05,  8.0355e-05,\n              1.1663e-04, -3.2024e-04,  2.6027e-05,  3.3006e-04,  1.1794e-04,\n             -1.0249e-04,  3.3827e-05,  1.5100e-04,  3.4164e-05, -2.0648e-04,\n             -6.3264e-06,  7.0856e-05, -7.8468e-05, -1.3042e-04,  8.5522e-06,\n             -5.1660e-05, -9.6467e-05,  1.5775e-05,  2.4151e-04,  5.9981e-05,\n             -1.0373e-04,  2.2576e-05,  7.3626e-05,  4.4253e-04,  3.0417e-04,\n              2.3795e-04, -8.9074e-05,  7.6356e-06,  6.8832e-05,  5.3459e-05,\n             -2.5219e-04,  1.0625e-04, -2.1079e-04, -8.5344e-04, -5.1142e-05,\n             -7.3077e-05,  9.2503e-05, -1.5507e-06,  1.2238e-04, -1.7002e-04,\n              5.7414e-06, -4.3171e-05, -1.8757e-05,  1.5510e-04, -7.2338e-04,\n             -3.2895e-05,  3.2207e-08, -2.1354e-05, -9.0853e-05, -3.8560e-05,\n              1.1166e-04, -5.6577e-05,  5.6697e-05,  7.0157e-05,  3.0993e-04,\n              7.7788e-06,  6.5559e-04, -1.2608e-04,  4.6589e-05, -1.9420e-05,\n              3.9229e-05, -1.1826e-04,  3.8522e-05,  1.5565e-04,  3.7708e-04,\n              1.6941e-04,  4.0273e-05, -9.0005e-05, -9.4857e-05,  3.6379e-05,\n             -1.7036e-04, -1.7955e-05, -2.8119e-04,  1.4023e-04,  2.9681e-05,\n              1.2993e-04, -2.4081e-04, -1.4625e-05, -1.8072e-04, -8.3633e-05,\n              7.1750e-06,  2.2532e-05, -6.1650e-06,  2.1675e-04,  8.9159e-05,\n             -4.0060e-05,  2.1189e-05, -1.1944e-05,  1.1707e-04,  1.1662e-04,\n             -8.5747e-05,  6.7766e-04]),\n     'exp_avg_sq': tensor([1.7685e-08, 1.2393e-07, 1.5599e-07, 4.5017e-07, 1.5615e-07, 7.3248e-08,\n             2.8824e-08, 1.5861e-08, 2.6208e-07, 1.0594e-06, 4.1469e-08, 6.4546e-08,\n             1.9728e-07, 2.8142e-08, 3.7726e-08, 4.0203e-08, 3.1018e-08, 7.9531e-08,\n             3.3417e-08, 5.6927e-08, 1.8760e-08, 2.5285e-07, 1.2198e-07, 3.0766e-08,\n             1.6880e-08, 4.2635e-08, 3.7663e-07, 9.1862e-08, 1.4517e-07, 1.0208e-07,\n             3.9282e-08, 7.3067e-07, 5.3008e-08, 1.5322e-08, 4.1585e-07, 1.3790e-07,\n             3.3954e-07, 1.5876e-08, 5.4985e-08, 5.7282e-08, 1.5828e-08, 2.6992e-08,\n             2.6706e-08, 3.4416e-08, 1.6726e-08, 4.2957e-08, 4.6473e-08, 1.0239e-06,\n             4.5240e-07, 5.6570e-07, 3.6206e-08, 1.7654e-08, 1.6851e-08, 2.8650e-08,\n             4.0419e-08, 8.7197e-08, 1.6570e-08, 1.6886e-08, 2.9565e-07, 2.1993e-08,\n             3.9354e-08, 1.3767e-08, 1.6978e-08, 4.0502e-08, 5.7994e-08, 1.9097e-08,\n             4.1639e-08, 1.4820e-08, 1.4564e-08, 3.0288e-07, 1.3992e-07, 1.5678e-08,\n             3.0365e-08, 1.6967e-08, 1.3950e-07, 1.0794e-07, 1.1843e-08, 2.3914e-07,\n             4.3494e-08, 2.0096e-08, 3.6161e-07, 1.9743e-08, 1.7529e-08, 1.6963e-08,\n             4.9163e-08, 4.6013e-08, 4.5884e-08, 3.3568e-08, 2.9529e-07, 2.0093e-08,\n             3.5578e-08, 4.5845e-08, 4.9516e-07, 9.9934e-08, 2.2453e-08, 2.2262e-08,\n             2.9659e-08, 2.8842e-08, 8.7944e-08, 1.9019e-07, 2.5093e-07, 8.6478e-08,\n             2.5161e-07, 7.4905e-08, 2.6446e-08, 1.2269e-07, 3.8921e-07, 8.6951e-07,\n             3.2375e-08, 2.7490e-08, 3.8729e-08, 4.8647e-07, 2.6217e-08, 2.3690e-07,\n             1.7648e-08, 3.5889e-08, 2.3564e-07, 2.1291e-08, 2.9463e-08, 2.4794e-07,\n             6.3337e-08, 3.7953e-08, 3.9393e-08, 1.8477e-08, 5.3568e-08, 5.5175e-08,\n             8.7664e-08, 2.2813e-07, 8.2558e-08, 1.7186e-07, 2.3705e-08, 2.1003e-08,\n             2.9545e-07, 3.7489e-07, 9.8859e-08, 2.9966e-08, 2.3461e-07, 2.9507e-08,\n             1.2659e-08, 6.3630e-08, 5.8450e-08, 1.1131e-07, 2.1106e-07, 5.6240e-08,\n             6.3234e-08, 1.3870e-08, 4.6881e-08, 5.7964e-08, 2.4417e-08, 1.9755e-07,\n             2.9117e-08, 4.1448e-07, 6.3433e-08, 2.1035e-08, 2.2268e-07, 1.1691e-08,\n             3.0535e-08, 1.6493e-08, 1.8899e-07, 6.5868e-08, 1.4915e-08, 1.5222e-07,\n             4.6263e-08, 2.4272e-07, 2.3605e-08, 2.7886e-08, 3.0133e-08, 3.0949e-08,\n             7.6265e-08, 2.8080e-08, 2.6194e-07, 3.7381e-08, 7.4335e-08, 2.3552e-08,\n             2.3051e-08, 5.7035e-07, 5.9580e-08, 1.8515e-07, 7.2681e-08, 1.5075e-07,\n             3.0229e-08, 3.6464e-07, 2.9021e-07, 2.2272e-08, 4.1813e-07, 4.9838e-08,\n             1.5633e-08, 2.2696e-08, 3.6116e-07, 2.8954e-08, 5.0707e-08, 6.5114e-08,\n             3.3464e-08, 1.9397e-08, 2.1905e-08, 7.9910e-08, 4.0458e-07, 3.2648e-08,\n             6.4612e-07, 3.2339e-07, 4.0545e-08, 5.8850e-07, 8.3410e-08, 1.9793e-08,\n             7.5660e-07, 1.6776e-07, 1.6560e-07, 3.9863e-08, 7.1838e-08, 2.2515e-08,\n             4.3394e-08, 2.3094e-08, 3.2614e-07, 3.5481e-08, 2.5546e-08, 2.6273e-08,\n             5.0502e-07, 2.2924e-07, 9.3453e-08, 4.0114e-08, 1.8887e-08, 1.7686e-08,\n             1.9041e-08, 5.0952e-08, 1.9345e-08, 1.9486e-08, 5.6708e-08, 3.2733e-08,\n             1.7642e-07, 2.4433e-08, 4.1420e-07, 1.7065e-07, 3.7915e-07, 5.9355e-08,\n             1.7699e-07, 8.4923e-08, 3.2124e-08, 1.8034e-07, 5.4703e-08, 9.1556e-07,\n             3.2969e-07, 3.5654e-07, 1.7448e-08, 1.1474e-07, 9.1533e-08, 2.7338e-08,\n             5.9201e-07, 2.6796e-08, 3.2272e-08, 1.0099e-07, 6.0564e-08, 4.7223e-08,\n             1.7108e-08, 9.3377e-08, 1.9837e-08, 1.1641e-06, 1.6024e-07, 1.4816e-07,\n             6.3819e-08, 4.1142e-07, 3.0113e-07, 2.6886e-08, 5.5788e-08, 9.4024e-08,\n             8.3651e-08, 4.2787e-08, 1.5266e-08, 3.3624e-08, 1.8611e-08, 2.5251e-08,\n             5.1947e-07, 4.2671e-08, 2.9871e-08, 5.2939e-07, 2.7569e-08, 1.0844e-07,\n             2.0581e-07, 2.4750e-07, 1.0385e-07, 3.0737e-07, 3.7633e-07, 2.4220e-07,\n             3.3886e-08, 2.0670e-08, 6.1092e-08, 1.5398e-07, 3.6710e-08, 2.8035e-08,\n             1.1447e-07, 2.6753e-07, 1.2641e-07, 2.9771e-08, 1.5041e-07, 2.6811e-07,\n             4.1492e-07, 7.7731e-08, 2.7393e-08, 1.0294e-07, 3.3009e-08, 3.3535e-07,\n             1.6163e-07, 1.1540e-08, 4.9918e-08, 5.7238e-08, 2.4421e-08, 8.3247e-08,\n             4.0182e-07, 9.1484e-08, 1.3484e-08, 1.9808e-07, 2.3311e-07, 3.4526e-08,\n             1.4573e-08, 4.4888e-08, 5.9591e-07, 1.2956e-07, 2.3610e-07, 2.3405e-07,\n             1.6401e-08, 2.5492e-07, 1.8344e-07, 2.0838e-07, 4.6684e-08, 4.3203e-08,\n             6.0495e-08, 3.9243e-08, 1.1895e-07, 3.8065e-08, 2.4012e-08, 3.9714e-07,\n             5.9674e-08, 3.7254e-07, 1.9562e-07, 6.3043e-07, 4.0279e-07, 3.7477e-08,\n             2.6222e-08, 2.0594e-08, 2.4861e-08, 2.3341e-08, 6.7207e-08, 4.6536e-08,\n             5.1865e-08, 6.5743e-08, 2.7838e-08, 5.3303e-07, 6.6790e-07, 2.3885e-08,\n             1.7113e-07, 3.6723e-07, 2.3399e-07, 1.4323e-08, 4.4420e-08, 1.1701e-08,\n             3.8200e-08, 3.7076e-07, 1.4822e-08, 3.7899e-08, 8.6027e-08, 5.4398e-08,\n             2.3618e-08, 6.7337e-08, 2.0786e-07, 4.8189e-08, 4.9866e-08, 3.9033e-08,\n             2.4043e-08, 7.9965e-08, 1.8550e-07, 4.1340e-07, 1.8322e-07, 6.7782e-08,\n             1.4342e-08, 1.5276e-08, 7.2113e-08, 1.0592e-07, 4.7334e-08, 1.0055e-07,\n             3.7826e-08, 2.5934e-07, 1.3170e-07, 6.8455e-08, 6.8187e-08, 6.7774e-08,\n             1.6617e-08, 3.1311e-08, 2.1338e-08, 6.3796e-08, 2.0898e-07, 4.9034e-08,\n             5.3316e-08, 4.2805e-07, 3.1923e-07, 1.2905e-07, 4.8240e-08, 2.1396e-08,\n             1.2225e-07, 7.3033e-08, 5.5954e-08, 1.1394e-07, 2.9631e-07, 1.9399e-07,\n             2.0402e-08, 1.9240e-08, 2.6812e-08, 3.1333e-08, 1.6615e-08, 5.3929e-07,\n             1.4109e-08, 1.8886e-08, 2.5446e-08, 2.6188e-08, 3.0106e-08, 5.4446e-08,\n             3.7385e-08, 5.3774e-07, 1.9685e-08, 2.4646e-08, 1.3227e-08, 1.5750e-08,\n             7.2896e-08, 4.4332e-08, 1.4975e-08, 1.2746e-07, 2.2997e-08, 4.8934e-07,\n             2.0463e-07, 2.3830e-08, 1.8645e-08, 1.0171e-07, 6.2062e-08, 1.2660e-08,\n             3.5141e-08, 3.4413e-08, 3.1928e-08, 2.8523e-08, 2.0493e-08, 1.2451e-07,\n             1.1493e-07, 2.5127e-08, 5.1175e-08, 2.8408e-08, 1.4902e-08, 3.7369e-07,\n             7.7283e-08, 6.6815e-08, 2.3309e-08, 2.7990e-08, 4.0381e-08, 2.8459e-08,\n             4.2868e-07, 1.0387e-07, 4.1195e-07, 4.3854e-07, 1.8614e-08, 2.3814e-07,\n             4.8763e-08, 2.0269e-08, 3.1044e-08, 9.8529e-08, 2.8617e-08, 1.7093e-07,\n             2.8152e-08, 2.7957e-07, 4.8203e-07, 5.2006e-08, 1.5361e-07, 9.5181e-08,\n             4.7997e-07, 3.2726e-08, 1.2685e-08, 4.2892e-08, 2.7372e-07, 3.2133e-08,\n             4.9835e-08, 2.4078e-08, 1.5080e-07, 2.6444e-08, 3.0368e-08, 2.7033e-08,\n             5.1713e-08, 2.6411e-07, 8.3098e-08, 6.7728e-08, 1.8692e-07, 2.7511e-07,\n             2.2812e-08, 5.1239e-08, 2.4570e-08, 1.5834e-07, 2.5420e-08, 3.4814e-08,\n             1.3550e-07, 1.4984e-08, 1.9982e-07, 7.8566e-08, 1.2192e-07, 1.4977e-08,\n             5.5573e-08, 1.6015e-08, 1.7051e-08, 7.1630e-07, 3.3479e-08, 4.5303e-08,\n             2.1648e-08, 4.8901e-08, 3.7076e-07, 3.1830e-07, 2.7923e-08, 5.4567e-08,\n             3.5099e-07, 3.3468e-07])},\n    102: {'exp_avg': tensor([ 7.0601e-05,  3.8136e-04,  6.3944e-05,  1.8842e-04, -1.6864e-04,\n              1.7856e-04, -7.3388e-05, -2.7611e-05,  3.8721e-05,  1.7828e-04,\n              1.0964e-04, -1.5778e-04, -4.4844e-05, -2.8375e-04,  7.9114e-05,\n             -1.8565e-05, -1.6836e-04,  3.0117e-05,  4.0806e-05,  1.4050e-04,\n              1.6449e-04,  2.9348e-04,  1.5302e-04, -3.4066e-04,  1.6748e-04,\n             -1.4770e-04, -5.4684e-06, -8.4763e-05, -5.3335e-05, -2.6754e-04,\n             -9.8943e-05, -2.0723e-04,  6.1777e-05,  3.9607e-04,  2.1531e-04,\n             -4.8182e-04,  1.8759e-04,  6.1819e-05,  1.8657e-04,  1.2079e-04,\n             -8.0411e-06,  9.3645e-05,  1.6632e-04,  1.2399e-04,  2.4538e-04,\n             -7.7024e-05,  1.6395e-05, -1.3241e-04, -5.4574e-04,  2.2909e-04,\n             -2.9278e-05, -2.5161e-04, -1.8963e-04, -4.4020e-05, -2.7401e-04,\n              4.8099e-04, -7.2992e-05,  1.2160e-05,  1.2193e-04,  4.3722e-05,\n              1.5299e-04, -1.2005e-04, -9.6454e-05, -2.7029e-04,  8.1334e-05,\n             -5.2824e-05, -1.3262e-04,  2.1963e-04, -4.9730e-05,  1.5473e-04,\n              1.7342e-04,  7.4544e-05, -1.0989e-04,  2.4296e-04,  9.3341e-05,\n              1.4414e-04, -1.6171e-04,  2.5258e-04, -3.6239e-04, -1.4711e-04,\n              6.8331e-05,  3.1535e-04, -1.1672e-04,  4.9356e-05, -3.8916e-04,\n              1.7865e-04,  7.3469e-05,  2.8242e-05,  1.2900e-04,  2.8037e-05,\n              2.3578e-04,  1.9351e-04,  2.5807e-04,  1.2585e-04,  4.5400e-04,\n              1.1731e-04,  8.2340e-05, -2.6990e-06, -1.0723e-04,  2.3687e-04,\n             -8.3085e-05, -1.2514e-04,  2.2764e-04, -7.7447e-05,  6.3754e-06,\n             -1.0130e-04, -2.7646e-04,  1.0840e-04,  7.9886e-05, -9.4605e-05,\n              1.1240e-05, -1.3845e-04,  1.1754e-04, -1.7747e-04,  2.5187e-04,\n              2.2030e-05, -2.0647e-04, -2.4975e-04,  1.0821e-04,  1.4438e-03,\n             -1.2834e-04, -8.1233e-05,  8.9438e-05,  1.7963e-05, -1.9692e-05,\n              1.1799e-04, -3.2579e-05, -9.3367e-05,  8.6306e-05, -7.4176e-05,\n              1.7118e-04,  1.5234e-04,  5.8356e-05, -2.3233e-04,  2.9842e-04,\n              1.3544e-04, -1.3646e-04,  5.2208e-05,  1.5656e-04, -2.0035e-05,\n              1.9214e-04,  1.8461e-04, -6.6193e-05,  2.9644e-04,  6.8540e-05,\n             -4.3392e-05,  6.4242e-05,  5.2729e-05, -2.2259e-04, -8.5572e-05,\n             -7.8009e-05, -1.1012e-04, -1.6990e-04, -3.6395e-04,  9.0684e-05,\n             -1.3405e-04, -3.8560e-04,  1.6208e-04,  1.5956e-04,  2.0640e-05,\n              1.7037e-04, -1.4677e-04,  6.4308e-05, -5.0773e-04,  9.5309e-05,\n             -1.7377e-04,  1.1596e-05, -1.0505e-04,  1.1427e-04,  2.3994e-04,\n             -7.5594e-05, -4.9978e-04,  3.7836e-04, -1.0897e-04,  5.9845e-05,\n             -9.3711e-05,  7.4303e-05, -3.6912e-05,  9.6454e-06, -1.4497e-04,\n              1.8810e-04,  2.0230e-04, -1.6761e-04,  5.6224e-06, -1.3596e-04,\n             -2.4485e-04, -6.7828e-05, -5.6205e-06,  8.3457e-04, -8.2757e-05,\n             -3.6422e-06, -1.4593e-04,  1.9685e-04,  2.5347e-04, -8.5753e-05,\n              3.5643e-05, -8.2228e-05, -3.1872e-05, -5.1870e-04, -1.3663e-04,\n              1.0436e-04,  2.5206e-04, -1.6264e-04, -1.5284e-04, -2.0837e-04,\n             -2.0008e-04,  1.1941e-04,  1.6512e-04,  8.7552e-05,  2.8279e-05,\n              2.3662e-04,  1.0159e-04, -4.4369e-06,  5.0500e-04,  1.1138e-04,\n              2.2169e-04,  1.1877e-04,  1.5657e-04, -2.3307e-04,  2.4569e-05,\n              1.4190e-05, -1.4293e-04, -1.1242e-04, -3.4548e-05,  8.3778e-05,\n             -1.0739e-04,  1.5635e-04,  6.2904e-05,  1.3650e-04,  1.1313e-04,\n             -3.4380e-05,  1.3456e-04, -2.8928e-04,  5.9643e-05,  5.7924e-05,\n              2.4776e-04,  4.7068e-04,  4.3209e-05,  3.0285e-04, -1.3640e-04,\n              2.8410e-04,  3.8689e-04,  1.5650e-04,  1.9075e-04,  5.1356e-05,\n              3.0137e-04,  1.8838e-04, -3.3021e-05,  3.3794e-04, -4.1761e-04,\n             -4.0021e-05, -4.0327e-04,  1.3545e-04, -1.1537e-04, -3.5681e-04,\n              2.6535e-04, -2.2276e-04, -1.4924e-04,  1.5546e-05, -8.1717e-05,\n             -9.2480e-06, -1.3816e-04,  3.5730e-04,  1.1992e-04, -3.6477e-05,\n              1.6286e-04,  3.5897e-04,  9.7514e-05, -7.5658e-05,  2.9324e-05,\n              2.1457e-04,  6.6517e-06, -1.6348e-05, -1.7441e-04, -3.4815e-04,\n              1.2056e-04,  8.6217e-05, -3.4026e-04,  5.7552e-05,  1.4359e-04,\n              2.7819e-04, -1.9465e-04, -8.7593e-05,  2.9345e-04, -1.2537e-04,\n             -2.4785e-04,  7.5353e-05, -5.9596e-05, -1.0138e-04, -7.6019e-05,\n              4.1541e-05,  3.8620e-04, -1.3434e-04,  3.1570e-04, -7.5629e-05,\n              2.5164e-05, -3.3816e-04,  4.2374e-05, -6.1106e-05,  1.9864e-04,\n              9.4776e-05, -4.9985e-05,  1.0248e-04, -2.1870e-04,  2.7513e-05,\n             -5.2911e-05, -2.0749e-04,  3.1564e-06, -1.8157e-04, -2.1678e-04,\n             -8.8473e-05,  1.1665e-04,  9.8507e-05,  1.3330e-04, -1.2919e-04,\n             -9.2265e-05, -1.0718e-04, -6.0998e-05, -2.1696e-04, -3.3162e-04,\n             -2.0300e-04,  7.3844e-05,  8.2770e-05, -6.3842e-06, -6.1097e-04,\n              4.6217e-05, -1.7892e-04,  1.1982e-05,  2.0676e-04,  1.5085e-04,\n             -1.4830e-04,  3.7074e-04,  5.5621e-05, -1.8985e-04,  2.6396e-04,\n             -1.6996e-04, -9.3539e-07, -1.5721e-04, -3.1115e-04,  2.8400e-05,\n             -3.6782e-04, -1.8316e-04,  1.3716e-04,  1.4610e-04, -1.9589e-04,\n             -2.8651e-04,  5.7520e-04, -3.6531e-04,  1.1065e-04,  8.9541e-05,\n              5.9879e-05, -1.2184e-04,  1.4482e-04,  3.1520e-04, -9.4064e-05,\n              2.6492e-04, -1.1695e-04,  1.9929e-04, -3.0423e-07,  2.0311e-04,\n              6.8588e-05,  1.3715e-04,  2.4610e-04, -3.5989e-05, -2.7473e-04,\n             -1.6796e-04,  2.0987e-04,  3.1840e-04, -1.4322e-04,  1.5385e-04,\n              3.3943e-04,  2.9786e-04,  1.6694e-04,  1.3553e-04, -7.6379e-06,\n              4.3934e-04,  3.9909e-04,  5.4048e-05, -3.0489e-04, -4.5609e-05,\n             -2.3822e-04,  7.3420e-05, -2.6206e-04,  6.9133e-05,  1.8337e-04,\n              1.7393e-04,  1.7450e-06, -8.1450e-05, -9.0446e-05,  1.1674e-04,\n              1.0693e-04, -4.5335e-05, -7.8191e-06, -3.8024e-04, -1.2013e-04,\n              5.0627e-05,  9.9256e-05,  2.2308e-04, -3.1463e-04, -1.2276e-04,\n             -2.7456e-04, -2.3074e-04, -3.4094e-04,  2.5558e-04, -9.4461e-05,\n             -8.6700e-05, -2.7819e-05, -1.6494e-04, -1.0655e-04,  1.4699e-04,\n             -4.0309e-04,  2.7086e-05, -2.7038e-04,  1.5356e-04,  9.5105e-05,\n             -3.0534e-04,  1.1766e-05, -3.4303e-05, -1.9828e-04, -6.5536e-06,\n             -5.4319e-05,  4.6621e-05, -1.7517e-04, -2.3558e-05, -4.6990e-04,\n              2.0112e-05, -7.0822e-05,  2.9392e-04,  1.8300e-04,  3.7714e-05,\n              1.6448e-04,  4.1944e-04,  1.0530e-04, -1.7665e-04, -1.2241e-04,\n             -7.4860e-05,  1.2309e-05,  2.2394e-05,  2.0197e-04, -4.1040e-04,\n              3.4543e-05, -1.5940e-04,  2.4436e-04, -2.2888e-04,  4.4193e-04,\n             -2.0833e-04,  1.7626e-04,  5.0801e-05, -3.2254e-05, -5.0524e-05,\n              1.4569e-04,  7.1158e-05, -1.3527e-05, -1.9525e-04,  5.0578e-04,\n              5.8981e-05, -6.6447e-05, -9.8552e-05,  2.4920e-04, -7.9925e-05,\n             -9.7862e-05, -1.2868e-04,  2.8586e-04, -1.1642e-04,  1.7044e-04,\n              4.6444e-05,  1.2359e-04,  1.0058e-04,  1.5921e-04,  1.0680e-04,\n              3.5911e-04,  2.1734e-04,  1.1606e-04, -1.6869e-04, -4.2774e-04,\n             -1.6255e-04, -3.4572e-04,  9.8880e-05, -1.5720e-04, -5.9474e-04,\n             -2.1782e-05, -1.3031e-04,  2.5855e-04, -9.2496e-08,  2.1611e-04,\n             -1.3203e-04, -1.0085e-04, -5.1137e-06,  3.8633e-04,  1.3397e-05,\n             -8.9585e-05, -2.4432e-04,  2.6878e-04, -6.5996e-05,  1.8347e-06,\n             -2.2327e-04, -5.1678e-06,  1.8945e-04, -2.0397e-04,  2.0178e-04,\n              4.2310e-05,  2.9158e-04,  3.5578e-05,  2.9032e-04,  2.4205e-04,\n              2.1599e-05, -8.6675e-05,  8.3021e-05,  2.4499e-04, -5.4100e-06,\n             -7.3217e-05, -1.7192e-04]),\n     'exp_avg_sq': tensor([2.2397e-08, 5.2025e-08, 1.8521e-08, 1.6297e-08, 1.1307e-07, 1.9131e-08,\n             5.3630e-08, 4.7653e-08, 2.0919e-08, 1.5532e-08, 1.2100e-08, 3.3200e-08,\n             2.8789e-08, 3.5784e-08, 1.7866e-08, 1.8065e-08, 2.2883e-08, 1.8259e-08,\n             1.7799e-08, 1.9983e-08, 1.3697e-08, 4.4147e-08, 6.2339e-08, 6.8315e-08,\n             1.4410e-08, 2.1743e-08, 3.5766e-08, 2.3889e-08, 1.6517e-08, 4.9660e-08,\n             2.9800e-08, 2.8537e-08, 2.2701e-08, 4.3303e-08, 3.0993e-08, 1.1720e-07,\n             2.9306e-08, 8.6193e-09, 2.5978e-08, 2.7198e-08, 3.5263e-08, 1.8899e-08,\n             1.1319e-08, 3.2065e-08, 3.1663e-08, 2.8017e-08, 2.3116e-07, 3.1415e-08,\n             1.0322e-07, 2.0539e-08, 3.3320e-08, 1.1682e-07, 7.6248e-08, 1.8140e-08,\n             4.3319e-08, 1.2461e-07, 2.5714e-08, 1.8509e-08, 3.9668e-08, 2.2365e-08,\n             2.5671e-08, 3.1085e-08, 3.6927e-08, 3.1112e-08, 1.4526e-08, 2.3844e-08,\n             4.3260e-08, 3.2669e-08, 3.2159e-08, 5.3499e-08, 3.9145e-08, 1.2048e-08,\n             2.9339e-08, 2.2687e-08, 5.1405e-08, 2.3328e-08, 2.0143e-08, 6.2219e-08,\n             7.3036e-08, 4.1451e-08, 2.6036e-08, 4.4990e-08, 3.7102e-08, 3.5375e-08,\n             5.8649e-08, 2.1995e-08, 1.4691e-08, 6.1601e-09, 2.9693e-08, 6.5970e-08,\n             1.7863e-08, 7.1639e-08, 7.1256e-08, 1.9527e-08, 3.4517e-08, 2.4621e-08,\n             2.3081e-08, 3.8335e-08, 2.0340e-08, 3.6085e-08, 4.0687e-08, 3.4620e-08,\n             1.1780e-08, 2.7414e-08, 2.2231e-08, 1.7905e-08, 4.5566e-08, 1.6721e-08,\n             2.8977e-08, 3.9007e-08, 5.0369e-08, 5.4642e-08, 3.0928e-08, 3.2544e-08,\n             6.4040e-08, 1.7512e-08, 4.3458e-08, 3.7800e-08, 1.4988e-08, 3.4506e-07,\n             3.3911e-08, 2.8264e-08, 4.9224e-08, 2.6178e-08, 1.6966e-08, 2.7030e-08,\n             3.0031e-08, 3.2178e-08, 2.3043e-08, 2.3013e-08, 3.7148e-08, 2.5029e-08,\n             2.4911e-08, 5.7009e-08, 3.2898e-08, 1.7286e-08, 2.7161e-08, 3.0318e-08,\n             3.4605e-08, 3.3476e-08, 3.1224e-08, 4.0962e-08, 3.2859e-08, 6.8179e-08,\n             2.8343e-08, 2.4847e-08, 2.2305e-08, 1.8320e-08, 6.6955e-08, 6.4594e-08,\n             2.4386e-08, 2.7812e-08, 4.4225e-08, 1.9627e-07, 1.4648e-08, 1.3958e-07,\n             5.6496e-08, 6.3953e-08, 3.0156e-08, 2.2968e-08, 5.2735e-08, 3.1362e-08,\n             1.8735e-08, 1.1701e-07, 2.1841e-08, 2.0870e-08, 2.2143e-08, 2.4312e-08,\n             2.3465e-08, 3.1849e-08, 4.6013e-08, 5.3766e-08, 3.9271e-08, 2.6661e-08,\n             1.7927e-08, 3.8291e-08, 2.7248e-08, 2.4420e-08, 2.2524e-08, 4.9815e-08,\n             3.4243e-08, 2.1810e-08, 2.3380e-08, 6.4472e-08, 2.2959e-08, 4.3125e-08,\n             1.4633e-07, 1.9058e-08, 2.0928e-07, 2.0029e-08, 2.8235e-08, 2.5618e-08,\n             2.9082e-08, 2.7590e-08, 2.4892e-08, 2.0767e-08, 3.0521e-08, 3.6129e-08,\n             1.4498e-07, 3.6196e-08, 1.5492e-08, 3.7521e-08, 3.9882e-08, 3.8042e-08,\n             5.6634e-08, 3.7815e-08, 2.1611e-08, 1.5818e-08, 2.5102e-08, 1.3424e-08,\n             2.4796e-08, 2.5968e-08, 2.4935e-08, 7.3920e-08, 1.8960e-08, 3.4595e-08,\n             3.1084e-08, 2.8227e-08, 6.4097e-08, 1.8241e-08, 1.9288e-08, 2.8618e-08,\n             2.9976e-08, 2.9633e-08, 3.4169e-08, 7.2126e-08, 6.1680e-08, 3.2828e-08,\n             1.5572e-08, 3.2087e-08, 7.4980e-08, 3.3145e-08, 5.1525e-08, 4.3362e-08,\n             4.4903e-08, 5.0082e-08, 1.0627e-07, 1.3272e-08, 3.8814e-08, 4.4311e-08,\n             2.5968e-08, 3.5295e-08, 2.9543e-08, 1.6693e-08, 1.3213e-08, 3.2783e-08,\n             2.4213e-08, 5.4796e-08, 2.5625e-08, 5.0369e-08, 4.3101e-08, 4.0403e-08,\n             2.0005e-08, 1.0043e-07, 4.1214e-08, 2.1024e-08, 3.6264e-08, 3.3808e-08,\n             3.4429e-08, 3.8939e-08, 2.1756e-08, 1.9810e-08, 4.7153e-08, 1.3078e-08,\n             2.3500e-08, 1.3972e-08, 8.0222e-08, 1.7052e-08, 5.2113e-08, 1.6110e-08,\n             7.7097e-08, 4.5403e-08, 3.8457e-08, 3.6227e-08, 4.4250e-08, 4.1104e-08,\n             2.1697e-08, 3.9797e-08, 1.5937e-08, 1.6985e-08, 3.4247e-08, 4.2961e-08,\n             2.2834e-08, 4.4090e-08, 2.3266e-08, 4.3091e-08, 2.3473e-08, 3.6053e-08,\n             1.5524e-07, 9.9527e-08, 4.8606e-08, 2.8309e-08, 4.0122e-08, 2.9456e-08,\n             3.6400e-08, 5.1652e-08, 5.7518e-08, 3.8861e-08, 3.6634e-08, 4.8592e-08,\n             2.2982e-08, 3.9823e-08, 4.8086e-08, 4.6394e-08, 3.5887e-08, 1.3981e-08,\n             4.2690e-08, 3.0655e-08, 6.2977e-08, 2.8502e-08, 2.5090e-08, 3.2700e-08,\n             2.3191e-08, 2.2192e-08, 2.2029e-08, 3.6742e-08, 3.5137e-08, 3.3443e-08,\n             4.4508e-08, 4.1002e-08, 5.9896e-08, 2.6710e-08, 1.7173e-08, 7.7487e-08,\n             8.4896e-08, 2.9409e-08, 2.7424e-08, 4.2807e-08, 4.9056e-08, 1.0425e-08,\n             3.2817e-08, 4.7071e-08, 4.5533e-08, 2.9059e-08, 3.0578e-08, 8.2493e-08,\n             5.4143e-08, 4.4689e-08, 6.0420e-08, 3.7030e-08, 5.8672e-08, 5.1463e-08,\n             1.4581e-08, 2.3165e-08, 3.2964e-08, 3.8367e-08, 1.0863e-07, 6.7610e-08,\n             3.8056e-08, 4.3915e-08, 9.6289e-09, 3.1882e-08, 2.0951e-08, 3.8987e-08,\n             3.3945e-08, 1.4810e-08, 6.4948e-08, 2.5482e-08, 2.9906e-08, 1.5641e-08,\n             1.5486e-08, 2.1719e-08, 2.1862e-08, 3.0673e-08, 5.9744e-08, 4.3451e-08,\n             1.8368e-08, 2.1841e-08, 3.0764e-08, 4.4229e-08, 2.9006e-08, 5.1826e-08,\n             1.3178e-08, 1.9505e-08, 2.2851e-08, 3.7483e-08, 5.8775e-08, 1.3257e-08,\n             6.6953e-08, 2.6323e-08, 5.8991e-08, 2.9783e-08, 3.7533e-08, 2.0999e-08,\n             1.9268e-08, 3.9498e-08, 2.3274e-08, 2.6789e-08, 2.5854e-08, 1.7740e-08,\n             4.0811e-08, 3.2899e-08, 2.9748e-08, 6.1782e-08, 3.5614e-08, 4.5323e-08,\n             2.9189e-08, 6.7083e-08, 3.2547e-08, 2.9398e-08, 4.1123e-08, 2.3224e-08,\n             6.6696e-08, 3.6383e-08, 7.3441e-08, 3.7658e-08, 8.4513e-09, 3.4692e-08,\n             3.8600e-08, 4.0490e-08, 6.5253e-08, 4.8123e-08, 4.0338e-08, 1.5069e-08,\n             1.8409e-08, 5.6336e-08, 2.0419e-08, 1.6926e-08, 6.8228e-08, 2.9529e-08,\n             3.3874e-08, 4.8949e-08, 2.2453e-08, 6.3463e-08, 4.7294e-08, 6.9493e-08,\n             2.6560e-08, 2.1473e-08, 3.6903e-08, 3.6038e-08, 1.0515e-08, 7.5919e-08,\n             2.0525e-08, 7.7282e-08, 5.2426e-08, 8.0046e-08, 1.8530e-08, 1.8451e-08,\n             3.0068e-08, 4.8572e-08, 1.0644e-07, 2.1312e-08, 3.5982e-08, 4.0195e-08,\n             7.9120e-08, 6.6057e-08, 1.8047e-08, 1.8184e-08, 2.0476e-08, 3.2812e-08,\n             7.1778e-09, 2.4638e-08, 1.8165e-08, 2.9742e-08, 9.9032e-08, 3.5996e-08,\n             2.4323e-08, 2.2963e-08, 4.1665e-08, 1.7260e-08, 1.9643e-08, 3.2424e-08,\n             2.7758e-08, 3.4634e-08, 9.6042e-09, 3.2846e-08, 4.0060e-08, 2.5663e-08,\n             3.3068e-08, 2.2880e-08, 8.3344e-08, 2.6005e-08, 2.5628e-08, 2.4614e-08,\n             1.2838e-07, 4.7594e-08, 8.1415e-08, 2.8578e-08, 4.2080e-08, 1.2569e-07,\n             3.3209e-08, 2.3113e-08, 4.0050e-08, 3.4313e-08, 3.2982e-08, 2.2181e-08,\n             2.0971e-08, 2.7192e-08, 6.0330e-08, 4.3440e-08, 3.9771e-08, 3.7149e-08,\n             6.1612e-08, 7.4500e-08, 2.6414e-08, 5.2875e-08, 1.9390e-08, 1.2432e-08,\n             3.4126e-08, 1.7249e-08, 2.1807e-08, 2.8158e-08, 4.4197e-08, 1.6602e-08,\n             1.7116e-08, 2.2259e-08, 2.5414e-08, 5.4047e-09, 3.7224e-08, 4.6103e-08,\n             1.2640e-08, 3.7848e-08])},\n    103: {'exp_avg': tensor([-6.5163e-05,  2.5628e-04, -1.9420e-05,  4.2347e-05, -2.5291e-04,\n              7.7217e-05, -5.1401e-05, -2.8627e-05, -8.0387e-05,  3.3806e-05,\n              7.9598e-05, -1.6038e-04, -3.0459e-05, -1.0630e-05,  1.8642e-05,\n              5.7804e-05, -1.3300e-04, -3.0115e-05, -1.7261e-05,  7.6225e-05,\n              4.3475e-05,  1.0889e-04,  1.4994e-04, -1.8574e-04,  1.9238e-04,\n             -2.1301e-04, -1.5017e-04, -1.1991e-04, -1.3131e-05, -3.9779e-04,\n             -1.1680e-04, -1.0356e-04, -1.0447e-05,  1.2257e-04,  7.6860e-05,\n             -2.8697e-04,  2.0581e-04,  3.0520e-07,  5.2579e-05, -1.4603e-05,\n             -7.7189e-05,  2.4254e-05,  1.5609e-04,  4.1314e-05,  9.0936e-05,\n             -8.1867e-05,  1.6994e-05, -2.5222e-04, -8.0856e-04,  1.2407e-04,\n             -5.9873e-05, -1.5932e-05, -9.7181e-05, -8.5587e-05, -2.7190e-04,\n              1.8640e-04,  5.8122e-05, -3.4082e-05,  1.8669e-05,  6.4407e-05,\n              6.9250e-05, -8.9944e-05, -1.5017e-04, -4.1623e-04,  1.0931e-05,\n             -1.9679e-04, -3.0096e-04,  1.4046e-04, -1.4719e-05,  6.7035e-05,\n              5.1244e-05, -4.8112e-05,  1.5851e-04,  7.3328e-05,  4.4789e-05,\n             -1.5696e-05, -1.8005e-04,  8.2063e-05, -5.4534e-04, -2.2386e-04,\n              3.5883e-05,  1.7915e-04, -2.0943e-04, -1.0473e-04, -6.1939e-05,\n              4.1369e-05,  3.3430e-05, -3.2332e-05,  1.2818e-04, -6.0875e-05,\n              2.0859e-04,  4.9828e-05,  8.5003e-05,  2.2511e-04,  1.9159e-04,\n             -5.8634e-05,  4.5625e-05,  3.1874e-06, -3.1139e-05,  4.2961e-05,\n              1.5178e-05, -1.4491e-04,  8.1565e-05, -6.0321e-05, -1.2251e-04,\n             -4.4157e-06, -1.1001e-04,  2.3752e-05,  2.0163e-05, -1.7346e-04,\n              2.8999e-05, -5.2026e-05,  5.0441e-05, -4.9590e-05,  4.9378e-05,\n              3.2450e-06, -2.1078e-04, -2.7217e-04,  1.0799e-04,  6.0913e-05,\n             -2.8301e-04, -1.3475e-04, -1.5164e-04, -4.5151e-05, -5.6047e-05,\n              2.5784e-05, -3.2592e-05, -7.0883e-05, -1.5873e-05, -1.3039e-04,\n              4.5006e-05,  5.3810e-05,  8.9205e-06, -6.5930e-05,  1.3298e-04,\n              1.2463e-04, -1.9969e-04, -2.4551e-05,  1.4765e-04, -1.0714e-04,\n              6.1426e-05,  8.9346e-05, -4.7076e-05,  1.6645e-04,  2.1369e-05,\n             -5.4559e-05,  1.5631e-05, -1.9332e-05, -5.5647e-04, -7.8258e-05,\n             -8.2512e-05, -2.9616e-04, -1.9863e-04, -6.8800e-05,  5.3167e-06,\n             -5.3391e-06, -3.0299e-04,  3.0279e-05,  3.4951e-05,  9.7180e-06,\n              1.1015e-04,  7.9703e-05,  2.7287e-05, -1.9751e-04,  1.2397e-05,\n             -2.2395e-04,  9.6209e-07, -1.1783e-04,  2.4978e-05,  1.2858e-04,\n             -2.0370e-04, -3.8931e-04,  1.6569e-04, -1.8889e-04, -2.4127e-05,\n             -3.1320e-05,  4.9868e-06, -1.5799e-04, -3.7665e-05, -1.2679e-04,\n              1.3783e-04,  2.4022e-04, -1.0898e-04, -5.5694e-06, -2.2524e-04,\n             -5.2032e-04, -4.6844e-05,  8.3335e-06,  4.6262e-04, -5.7100e-05,\n             -2.8094e-04, -1.1390e-04,  6.2631e-05,  6.8994e-05,  5.1583e-05,\n              2.7938e-05, -5.2214e-05, -9.2254e-05, -5.7449e-04, -3.6942e-05,\n              4.7135e-05,  1.9516e-04, -1.8759e-04, -2.8788e-04, -1.0384e-04,\n             -3.7900e-05,  1.9220e-04,  5.2712e-05,  9.2009e-05,  6.7005e-05,\n              8.5632e-05,  3.7522e-05, -7.1610e-05,  2.7065e-04,  9.9696e-06,\n              2.6679e-04,  2.2128e-05,  4.7796e-05,  2.0865e-05, -1.9626e-05,\n             -4.7213e-05, -1.4531e-04, -1.8602e-04, -2.2065e-04,  2.5279e-05,\n             -1.1825e-04,  6.4642e-05, -2.5026e-04, -5.8748e-06,  3.0104e-05,\n             -8.3367e-05,  4.2648e-05, -1.8868e-04,  1.0352e-05,  2.1065e-05,\n              9.8850e-05,  1.9613e-04, -4.9581e-05,  1.3154e-04, -3.7175e-04,\n              1.4199e-04,  1.3662e-04,  1.9889e-04,  2.1758e-05, -2.0497e-05,\n              9.9525e-05,  8.8759e-05, -1.2102e-04,  1.3776e-04, -2.0847e-04,\n             -5.8352e-05, -1.6467e-04,  5.4626e-05,  3.8977e-06, -2.5184e-04,\n              1.3076e-04, -2.1110e-04, -9.8273e-05,  7.5695e-05, -1.4420e-05,\n             -1.0746e-04, -2.6760e-04,  2.9783e-05,  1.5687e-05, -1.8293e-04,\n              8.5505e-05,  2.0336e-04,  8.0072e-06, -2.9519e-05, -1.9554e-05,\n              4.5587e-05,  1.6317e-05, -5.2075e-06, -2.4803e-04, -5.1008e-04,\n              6.6268e-06,  4.5396e-05, -2.7892e-04, -7.9452e-06,  3.4060e-05,\n              7.9827e-05, -1.9057e-04, -1.4877e-04,  2.6324e-04, -2.2360e-04,\n             -3.2546e-04, -8.2518e-06, -1.2933e-04, -1.0123e-06, -6.1732e-05,\n             -9.5779e-05,  1.4432e-04, -1.9066e-04,  1.3949e-04, -1.2261e-05,\n              4.2370e-05, -5.0851e-05,  1.3968e-05, -4.8413e-05,  8.2272e-05,\n             -2.4920e-05, -1.2230e-04,  1.4779e-04,  3.5327e-06, -2.4420e-05,\n             -9.0142e-05, -1.5060e-04,  1.6192e-08, -7.0380e-05, -1.1756e-04,\n             -7.2240e-05,  2.0993e-05,  9.6124e-06,  2.6246e-05, -1.2062e-04,\n             -5.9095e-05, -1.4680e-04, -1.1380e-04, -3.6051e-04, -2.0418e-04,\n             -1.6014e-04,  7.1867e-05,  9.8202e-05, -5.9245e-05, -6.1298e-04,\n              1.7364e-04, -3.2430e-04,  5.0284e-05,  8.5077e-05,  6.6985e-05,\n             -1.9295e-04,  1.4535e-04,  5.1661e-05, -2.4408e-04,  8.9743e-05,\n             -2.2493e-04, -8.3828e-05, -8.2098e-05, -3.5992e-04,  2.5121e-06,\n             -3.8126e-04, -3.3008e-04,  7.9501e-05,  5.6769e-05, -1.8627e-04,\n             -1.7616e-04,  2.0145e-04, -2.4232e-04,  7.9157e-05,  5.2799e-05,\n             -1.9945e-05, -1.9546e-04,  3.1406e-05,  1.0772e-04, -2.8740e-04,\n              1.3684e-04, -8.6455e-05,  1.5456e-04,  4.7838e-06,  1.1614e-04,\n             -7.8238e-06,  2.9666e-05,  9.3384e-05,  1.4873e-05, -1.2446e-04,\n             -6.3737e-05,  6.0849e-05,  1.2607e-04, -1.0104e-04,  6.0817e-05,\n              1.5643e-04,  8.8368e-05,  4.4083e-05,  3.6813e-05, -3.0531e-05,\n              1.5239e-04,  2.6926e-04,  8.0128e-06, -5.3063e-04, -4.0843e-05,\n             -6.1013e-04, -4.9629e-06, -1.6636e-04,  2.3277e-05,  4.1914e-05,\n              4.2494e-05,  2.7665e-05, -1.9021e-04, -1.5526e-04,  2.1022e-05,\n              8.0773e-05,  3.8543e-05, -4.9952e-05, -2.2515e-04, -9.9496e-05,\n             -2.1058e-05, -4.2003e-05,  1.2544e-04, -2.6445e-05, -2.1573e-04,\n             -7.5019e-05, -1.3197e-04, -2.1170e-04,  1.4373e-04, -1.9154e-05,\n             -1.8437e-04,  6.7740e-07, -4.6771e-05, -1.1413e-05,  1.2456e-04,\n             -1.1926e-04,  1.6648e-05, -4.7918e-04,  2.7036e-05,  3.4450e-05,\n             -2.0807e-04,  1.0477e-05, -1.9734e-06, -4.9109e-05, -5.3668e-06,\n             -1.2621e-05,  1.9475e-05, -2.2681e-04, -3.4539e-04, -1.8453e-04,\n             -1.2421e-05, -1.0645e-04,  1.3580e-04,  6.0411e-05, -1.5307e-04,\n              1.5918e-04,  2.5523e-04,  1.7087e-05,  3.8943e-05, -2.0387e-04,\n             -2.7316e-06,  1.2838e-04, -2.0874e-05,  1.2189e-04, -4.1363e-04,\n              1.8656e-06, -1.8763e-04,  6.7256e-05, -1.6407e-04,  2.0828e-04,\n             -1.2773e-04,  6.0599e-05, -1.1238e-05, -1.0433e-04, -3.2844e-04,\n              1.0727e-04,  1.1167e-05, -1.8456e-05, -9.8061e-05,  1.5476e-04,\n              1.1120e-04,  4.1366e-05, -7.0037e-05,  1.0956e-04, -1.4466e-04,\n             -4.8203e-05, -1.0905e-04,  1.8619e-04, -4.2581e-05,  5.5067e-05,\n              5.0213e-05,  4.4879e-06,  5.2009e-05,  6.8221e-05,  1.8167e-04,\n              2.0254e-04,  9.5093e-05, -8.1262e-08, -1.3400e-04, -6.1251e-04,\n             -3.1391e-04, -3.8162e-04,  1.3265e-05, -8.3447e-05, -7.3370e-04,\n              1.5670e-05, -2.4637e-04,  1.5548e-04, -4.1434e-05,  7.9049e-05,\n             -1.4409e-04, -1.2650e-04,  8.9758e-05,  1.7347e-04,  2.3647e-05,\n             -2.3533e-04, -1.2439e-04,  5.9341e-05, -1.1846e-04,  2.2829e-05,\n             -2.6783e-04, -5.3987e-05,  9.3490e-05, -2.3897e-04,  6.6824e-05,\n             -3.9155e-05,  1.1731e-04,  6.4711e-05,  6.0279e-05,  8.1907e-05,\n             -9.0883e-06, -7.1238e-05,  1.5568e-05,  7.2615e-05, -1.3998e-04,\n             -9.1357e-05, -2.7747e-05]),\n     'exp_avg_sq': tensor([1.6033e-08, 1.5405e-08, 5.6027e-09, 4.9339e-09, 5.1739e-08, 5.9176e-09,\n             1.4700e-08, 1.7859e-08, 1.8917e-08, 2.9175e-09, 1.0078e-08, 2.7288e-08,\n             7.2670e-09, 1.6380e-08, 1.0083e-08, 1.0291e-08, 1.0518e-08, 6.5625e-09,\n             4.5918e-09, 5.9066e-09, 3.1519e-09, 1.4880e-08, 1.5219e-08, 2.0540e-08,\n             1.1542e-08, 1.6272e-08, 2.4791e-08, 1.0214e-08, 1.2274e-08, 4.5571e-08,\n             1.7895e-08, 1.3635e-08, 1.7819e-08, 8.1043e-09, 4.9443e-09, 3.8388e-08,\n             2.3272e-08, 1.5861e-09, 1.1279e-08, 6.2160e-09, 1.3172e-08, 4.3219e-09,\n             9.3935e-09, 9.8251e-09, 7.3680e-09, 8.6219e-09, 2.9109e-08, 2.7161e-08,\n             1.8944e-07, 7.2265e-09, 3.7899e-08, 3.1810e-08, 1.7259e-08, 4.8974e-09,\n             5.5920e-08, 2.1362e-08, 1.4448e-08, 4.6360e-09, 8.2136e-09, 2.0200e-08,\n             7.7585e-09, 2.1770e-08, 3.9398e-08, 4.1809e-08, 3.7274e-09, 2.2327e-08,\n             8.9758e-08, 2.4692e-08, 1.3827e-08, 1.0449e-08, 6.2896e-09, 6.0412e-09,\n             1.1608e-08, 3.9906e-09, 1.0092e-08, 8.2724e-09, 1.1962e-08, 1.0358e-08,\n             1.8771e-07, 3.1717e-08, 1.8358e-08, 1.1286e-08, 4.2719e-08, 1.4503e-08,\n             2.2010e-08, 9.7947e-09, 5.2026e-09, 3.5479e-09, 6.7180e-09, 1.4043e-08,\n             1.5503e-08, 1.4380e-08, 9.7624e-09, 1.7603e-08, 8.1962e-09, 1.4728e-08,\n             8.7513e-09, 7.7536e-09, 1.4288e-08, 7.7135e-09, 1.9729e-08, 4.3505e-08,\n             1.9583e-09, 9.7794e-09, 2.1556e-08, 9.4649e-09, 1.3439e-08, 4.3533e-09,\n             1.1954e-08, 2.0929e-08, 1.5125e-08, 2.6998e-08, 7.3785e-09, 2.1672e-08,\n             1.2391e-08, 4.7601e-09, 5.2161e-08, 2.6502e-08, 1.3743e-08, 3.4942e-09,\n             3.1320e-08, 1.3411e-08, 1.5750e-08, 1.7002e-08, 6.4097e-09, 1.4507e-08,\n             6.6113e-09, 6.1339e-09, 4.6524e-09, 1.2485e-08, 6.2297e-09, 5.8964e-09,\n             3.5860e-09, 8.7522e-09, 7.1739e-09, 1.5466e-08, 3.2636e-08, 1.4435e-08,\n             2.7201e-08, 3.2388e-08, 6.9575e-09, 1.2465e-08, 9.9433e-09, 2.1101e-08,\n             5.8114e-09, 9.5508e-09, 4.3024e-09, 6.4849e-09, 1.3556e-07, 1.5494e-08,\n             7.8882e-09, 3.2539e-08, 2.6792e-08, 2.3346e-08, 3.3654e-09, 1.5784e-08,\n             4.4302e-08, 1.3325e-08, 5.4542e-09, 1.7364e-08, 1.6061e-08, 1.4641e-08,\n             4.2511e-09, 1.9942e-08, 7.7110e-09, 2.6794e-08, 2.0987e-08, 9.6113e-09,\n             7.4847e-09, 7.4665e-09, 4.1319e-08, 6.4636e-08, 7.6381e-09, 1.8741e-08,\n             5.5398e-09, 1.3527e-08, 1.0878e-08, 2.4849e-08, 5.2554e-09, 1.8599e-08,\n             2.3801e-08, 1.8077e-08, 1.3236e-08, 1.5552e-08, 3.0179e-08, 5.4815e-08,\n             2.0826e-08, 5.7383e-09, 4.8627e-08, 1.8993e-08, 4.2269e-08, 6.8660e-09,\n             5.1261e-09, 8.1466e-09, 1.0327e-08, 1.5889e-08, 1.9483e-08, 2.5031e-08,\n             1.5107e-07, 3.9610e-08, 5.4598e-09, 2.4966e-08, 3.1102e-08, 4.6145e-08,\n             3.3378e-08, 1.6306e-08, 1.6355e-08, 5.3429e-09, 1.6669e-08, 9.0435e-09,\n             4.6131e-09, 3.4506e-09, 1.7460e-08, 1.6519e-08, 7.7304e-09, 3.0857e-08,\n             1.3116e-08, 1.0553e-09, 2.2853e-08, 7.1540e-09, 8.1477e-09, 1.3863e-08,\n             1.8421e-08, 5.1296e-08, 8.1130e-09, 8.5267e-09, 1.5528e-08, 3.8244e-08,\n             8.3468e-09, 1.2902e-08, 1.3300e-08, 9.5677e-09, 2.6096e-08, 2.8116e-08,\n             2.6512e-08, 1.1897e-08, 1.7887e-08, 3.1114e-09, 9.3785e-09, 5.4772e-08,\n             1.2599e-08, 7.5974e-09, 3.0743e-08, 4.1189e-09, 3.5632e-09, 1.0982e-08,\n             5.6587e-09, 1.9506e-08, 5.5868e-09, 1.3729e-08, 1.7283e-08, 3.2523e-08,\n             7.1385e-09, 2.5762e-08, 4.0889e-08, 5.8940e-09, 2.9113e-08, 1.2589e-08,\n             1.1764e-08, 9.1860e-09, 1.3886e-08, 2.5867e-08, 6.8517e-09, 4.4670e-09,\n             3.3406e-08, 3.8099e-09, 3.0490e-08, 5.7727e-09, 1.8548e-08, 1.2773e-08,\n             1.0017e-09, 1.1358e-08, 1.6292e-08, 4.8521e-08, 1.4345e-07, 1.6693e-08,\n             1.0353e-08, 3.2130e-08, 5.2156e-09, 3.2239e-09, 1.2020e-08, 3.6747e-08,\n             2.0056e-08, 4.3635e-08, 2.2329e-08, 5.9008e-08, 5.7443e-09, 3.8085e-08,\n             4.9762e-11, 1.9392e-08, 1.2303e-08, 6.0717e-09, 6.1366e-08, 1.0834e-08,\n             1.4893e-08, 1.0584e-08, 1.4627e-08, 5.6379e-09, 1.8357e-08, 1.0594e-08,\n             5.8240e-09, 5.2068e-08, 2.3152e-08, 6.7552e-09, 1.6452e-08, 9.2098e-09,\n             1.1818e-08, 5.5805e-09, 1.2363e-08, 2.6430e-08, 1.3702e-08, 6.2744e-09,\n             8.2275e-09, 4.3638e-09, 9.1087e-09, 1.5686e-08, 1.2902e-08, 2.3627e-08,\n             2.8544e-08, 2.0540e-08, 1.9764e-08, 1.6437e-08, 1.4417e-08, 1.3622e-08,\n             1.0412e-07, 3.2434e-08, 3.4550e-08, 1.0195e-08, 1.5269e-08, 2.9877e-09,\n             2.4094e-08, 9.6375e-09, 1.9696e-08, 2.1704e-08, 7.1730e-09, 2.4372e-08,\n             1.4367e-08, 1.5846e-08, 7.8796e-08, 6.9893e-09, 7.0233e-08, 6.9362e-08,\n             1.5805e-08, 4.6710e-09, 1.7664e-08, 7.7372e-09, 1.8009e-08, 2.7141e-08,\n             9.6813e-09, 1.2075e-08, 2.0490e-09, 2.6463e-08, 4.6421e-09, 1.6881e-08,\n             3.1828e-08, 5.0561e-09, 6.7443e-09, 1.1793e-08, 5.6798e-09, 6.6929e-09,\n             6.5769e-09, 4.2258e-09, 5.6550e-09, 4.6600e-09, 1.2725e-08, 2.9454e-08,\n             4.1247e-09, 6.4246e-09, 1.4310e-08, 8.9996e-09, 8.0963e-09, 7.0303e-09,\n             2.9682e-09, 3.3814e-09, 6.8475e-09, 5.4174e-09, 1.3912e-08, 9.3672e-11,\n             1.1832e-07, 7.2404e-09, 1.3965e-07, 2.2162e-08, 1.8787e-08, 4.0756e-09,\n             3.8357e-09, 5.6888e-09, 1.5392e-08, 3.2426e-08, 2.7301e-08, 6.2264e-09,\n             1.7662e-08, 1.3080e-08, 1.7758e-08, 2.9107e-08, 1.4724e-08, 1.9774e-08,\n             9.1910e-09, 1.1482e-08, 1.1225e-08, 2.3438e-08, 3.8964e-08, 2.0560e-08,\n             2.1824e-08, 1.3519e-08, 1.3237e-08, 2.8859e-08, 9.4169e-09, 1.5052e-08,\n             9.0650e-09, 1.4663e-08, 2.2178e-08, 1.0254e-08, 4.9664e-08, 6.8044e-09,\n             4.9432e-09, 3.0243e-08, 1.4905e-08, 1.1342e-08, 2.2906e-08, 5.4175e-09,\n             2.9151e-08, 8.5184e-09, 1.4874e-08, 3.5423e-08, 2.8516e-08, 1.0841e-08,\n             1.2756e-08, 5.2001e-09, 9.7671e-09, 3.6306e-08, 8.5297e-09, 3.1599e-08,\n             6.5764e-09, 8.7907e-09, 3.7221e-08, 2.4722e-08, 1.2859e-08, 9.4958e-09,\n             1.4195e-08, 4.7101e-08, 1.0298e-08, 1.2137e-08, 5.8834e-09, 2.0279e-08,\n             3.5644e-08, 8.2772e-09, 5.6582e-09, 5.7762e-09, 1.8112e-08, 4.4280e-08,\n             4.9975e-09, 8.5483e-09, 9.4193e-09, 1.7308e-08, 1.9450e-08, 1.0474e-08,\n             1.0887e-08, 1.7638e-08, 9.0936e-09, 1.0102e-08, 1.1398e-08, 3.5052e-08,\n             1.6405e-08, 2.8135e-08, 1.3985e-09, 6.4575e-09, 1.1629e-08, 1.1260e-08,\n             8.5839e-09, 2.1084e-08, 2.6168e-08, 4.5202e-09, 3.2272e-08, 1.1790e-08,\n             2.1095e-07, 7.4386e-08, 1.2185e-07, 9.7055e-09, 1.5100e-08, 2.6094e-07,\n             1.7627e-08, 2.2860e-08, 2.8991e-08, 2.4384e-08, 6.2079e-09, 1.0088e-08,\n             2.0089e-08, 1.5473e-08, 1.4009e-08, 2.7459e-08, 3.0977e-08, 1.9057e-08,\n             1.9874e-08, 1.0709e-08, 1.6132e-08, 3.7066e-08, 5.0722e-09, 3.6455e-09,\n             3.0370e-08, 3.5174e-09, 8.9249e-09, 6.6219e-09, 1.4405e-08, 2.7302e-09,\n             4.1903e-09, 6.5325e-09, 8.4436e-09, 1.0825e-09, 1.2148e-08, 2.8769e-08,\n             7.2777e-09, 1.1735e-08])},\n    104: {'exp_avg': tensor([ 6.1033e-05,  1.2612e-04, -9.9195e-05,  ..., -5.3767e-06,\n              6.6899e-05,  9.4799e-05]),\n     'exp_avg_sq': tensor([1.0177e-08, 1.1039e-08, 1.3219e-08,  ..., 2.8630e-08, 1.3201e-08,\n             1.7603e-08])},\n    105: {'exp_avg': tensor([-6.1835e-05, -1.2374e-04, -1.3198e-04,  ...,  4.0260e-05,\n             -2.8884e-05, -4.1688e-05]),\n     'exp_avg_sq': tensor([1.2533e-08, 1.8952e-08, 2.1565e-08,  ..., 2.7790e-08, 1.4954e-08,\n             2.3840e-08])},\n    107: {'exp_avg': tensor([-1.7521e-05, -2.8974e-05,  6.8154e-09, -1.4118e-04,  1.2251e-05,\n              2.8356e-04,  1.1282e-04,  8.8019e-05, -5.0730e-04,  5.2393e-06,\n             -2.5926e-04, -6.5904e-05,  4.1911e-05, -8.4791e-05,  2.0412e-04,\n             -1.8649e-04, -3.8837e-04,  5.9483e-04, -1.7602e-04, -1.1356e-05,\n             -7.9946e-06,  3.6566e-04, -3.0370e-05,  2.8132e-04,  1.0512e-04,\n              3.3966e-04, -6.7984e-04,  2.6655e-05, -4.0205e-04,  2.6077e-05,\n             -5.9920e-04, -1.0862e-05,  1.5204e-04,  7.5750e-05, -1.0104e-04,\n              2.2497e-04,  1.5801e-04, -1.8162e-04,  1.9766e-04, -6.9828e-05,\n              3.2658e-05, -2.9894e-04, -1.2125e-04,  3.9563e-04,  8.9199e-05,\n              6.5009e-05,  1.6432e-04,  3.7990e-05, -1.6958e-04,  1.0272e-05,\n             -9.8038e-05, -5.3827e-05,  1.9624e-04,  1.0727e-04, -1.5158e-04,\n              9.4466e-05, -2.7641e-04,  4.8875e-05, -2.3331e-04,  1.8955e-05,\n              1.1575e-05,  6.9591e-05, -5.8545e-05,  1.1246e-04, -5.1677e-04,\n              1.8855e-04, -3.3682e-04,  4.7591e-04, -1.3728e-04, -1.0218e-05,\n              1.0433e-05, -8.0924e-05, -7.5840e-06,  1.3925e-04,  1.1057e-04,\n             -2.3357e-04,  6.8249e-05,  8.9910e-05,  1.6069e-04, -1.6505e-04,\n             -1.0160e-05,  1.9568e-04,  3.4696e-04, -2.9321e-04,  9.8491e-05,\n             -8.4991e-05,  2.6204e-04,  3.9946e-05,  1.1521e-04,  1.9150e-05,\n              1.3999e-04, -4.0989e-04,  1.3182e-05, -1.1550e-05,  1.4688e-04,\n             -1.5074e-04,  2.6365e-05,  1.0463e-04, -3.8241e-05,  3.9618e-04]),\n     'exp_avg_sq': tensor([1.3932e-07, 1.3729e-07, 1.3993e-07, 2.2306e-07, 1.3971e-07, 1.5260e-07,\n             1.9487e-07, 1.2807e-07, 2.0717e-07, 6.4078e-08, 2.7147e-07, 1.7818e-07,\n             7.5360e-08, 1.3660e-07, 1.7457e-07, 2.2281e-07, 8.6493e-08, 2.1833e-07,\n             9.5609e-08, 2.6060e-08, 1.2293e-07, 1.3462e-07, 9.1871e-08, 1.1858e-07,\n             5.2868e-08, 1.4979e-07, 2.0601e-07, 9.9044e-08, 1.0650e-07, 1.3661e-07,\n             2.2168e-07, 1.0083e-07, 5.5952e-08, 1.3505e-07, 1.9402e-07, 2.3954e-07,\n             1.9296e-07, 8.4484e-08, 2.1334e-07, 2.1824e-07, 1.4898e-07, 1.4731e-07,\n             1.9676e-07, 1.6396e-07, 1.7522e-07, 1.4698e-07, 1.3425e-07, 2.2464e-07,\n             1.5668e-07, 6.8813e-08, 1.6377e-07, 1.1622e-07, 6.6695e-08, 1.6921e-07,\n             1.5069e-07, 8.4106e-08, 1.3587e-07, 7.0485e-08, 1.3678e-07, 8.5096e-08,\n             8.9101e-08, 6.2680e-08, 4.2341e-08, 1.5534e-07, 1.9398e-07, 1.3480e-07,\n             2.0465e-07, 2.1244e-07, 1.8021e-07, 1.3511e-07, 5.9273e-08, 2.3705e-07,\n             7.1074e-08, 1.6464e-07, 5.1219e-08, 1.5259e-07, 1.0545e-07, 1.1521e-07,\n             1.2968e-07, 6.7350e-08, 2.3782e-07, 5.0713e-08, 2.1690e-07, 1.3950e-07,\n             9.8315e-08, 9.2766e-08, 2.1639e-07, 2.0392e-07, 1.8510e-07, 1.1535e-07,\n             1.4695e-07, 1.8637e-07, 7.3221e-08, 1.6990e-07, 1.2355e-07, 1.9166e-07,\n             4.8089e-08, 1.2173e-07, 8.6266e-08, 1.7371e-07])},\n    108: {'exp_avg': tensor([[[[-9.1938e-04, -6.1198e-04, -8.3171e-04,  ..., -6.9530e-04,\n                -3.5175e-04, -2.5926e-04],\n               [-3.2117e-04, -6.8522e-04, -4.1041e-04,  ...,  8.2434e-05,\n                -5.8942e-05,  4.3039e-05],\n               [ 2.1984e-05,  3.5549e-05,  2.9710e-04,  ..., -7.6547e-05,\n                -1.0357e-05, -2.6618e-04],\n               ...,\n               [-2.3503e-04, -3.0711e-04, -2.0050e-04,  ..., -4.9243e-04,\n                -1.3836e-04, -1.1836e-04],\n               [-3.5413e-04, -3.4224e-04, -6.7054e-04,  ..., -2.7654e-04,\n                 2.0529e-04,  8.1674e-05],\n               [-3.3408e-04, -5.9240e-06, -4.5809e-04,  ..., -6.3188e-05,\n                -8.1957e-05, -1.1127e-04]],\n     \n              [[-6.4344e-04, -3.1013e-04, -5.5607e-04,  ..., -6.5260e-04,\n                -3.6803e-04, -3.1571e-04],\n               [-8.6250e-06, -3.9599e-04, -1.4680e-04,  ...,  1.1231e-04,\n                -8.0881e-05, -2.3943e-05],\n               [ 3.3459e-04,  2.9613e-04,  5.4647e-04,  ..., -4.3281e-05,\n                -1.6619e-05, -3.3110e-04],\n               ...,\n               [-6.5988e-06, -1.4349e-04, -4.7469e-05,  ..., -5.7559e-04,\n                -2.4867e-04, -2.4639e-04],\n               [-1.2101e-04, -2.0262e-04, -5.6105e-04,  ..., -3.4643e-04,\n                 8.8942e-05, -5.8550e-05],\n               [-5.1462e-05,  1.4795e-04, -3.3325e-04,  ..., -1.3014e-04,\n                -2.3013e-04, -2.9178e-04]],\n     \n              [[-7.2839e-04, -4.1783e-04, -6.5113e-04,  ..., -8.6412e-04,\n                -6.0363e-04, -5.4775e-04],\n               [-1.4484e-04, -4.7235e-04, -2.1485e-04,  ..., -1.2262e-04,\n                -3.5664e-04, -2.6727e-04],\n               [ 1.8700e-04,  2.5789e-04,  4.8091e-04,  ..., -2.6040e-04,\n                -2.7434e-04, -5.4658e-04],\n               ...,\n               [-9.0637e-05, -1.6923e-04, -8.4791e-05,  ..., -7.2601e-04,\n                -4.1295e-04, -4.5384e-04],\n               [-1.2483e-04, -2.1063e-04, -5.8276e-04,  ..., -5.1480e-04,\n                -9.1780e-05, -2.4607e-04],\n               [-8.7736e-05,  9.1500e-05, -3.8377e-04,  ..., -2.9255e-04,\n                -4.0994e-04, -4.9905e-04]]],\n     \n     \n             [[[-2.6086e-04,  3.2562e-04,  5.7081e-04,  ..., -2.5852e-04,\n                 1.6655e-04,  4.4670e-04],\n               [-5.2231e-04,  7.9747e-04,  2.5366e-05,  ..., -1.2551e-03,\n                -9.9877e-04, -4.2050e-04],\n               [-2.1483e-03,  9.1773e-04, -7.5309e-04,  ..., -1.9049e-03,\n                -7.0380e-05, -7.3842e-04],\n               ...,\n               [-1.2593e-03, -9.3349e-04, -2.2881e-03,  ..., -1.7398e-03,\n                -7.5058e-04,  6.8162e-04],\n               [-1.0904e-03, -1.0751e-03, -1.1763e-03,  ..., -2.8189e-03,\n                -1.6253e-03, -8.8470e-04],\n               [-1.4199e-03, -1.2076e-03, -1.8406e-04,  ..., -1.0602e-03,\n                -8.8917e-04, -1.6550e-06]],\n     \n              [[-5.2463e-04,  2.2509e-04,  5.0886e-04,  ..., -4.9254e-05,\n                 5.7435e-04,  8.5496e-04],\n               [-4.1544e-04,  1.1592e-03,  4.2300e-04,  ..., -8.9308e-04,\n                -5.5461e-04, -5.7275e-05],\n               [-2.0866e-03,  1.3654e-03, -2.8815e-04,  ..., -1.4621e-03,\n                 3.4829e-04, -4.3792e-04],\n               ...,\n               [-1.4110e-03, -7.0787e-04, -2.0869e-03,  ..., -1.6923e-03,\n                -7.0573e-04,  6.6569e-04],\n               [-1.1240e-03, -8.4610e-04, -8.4310e-04,  ..., -2.7828e-03,\n                -1.5937e-03, -1.0342e-03],\n               [-1.4739e-03, -8.7277e-04,  1.8643e-04,  ..., -8.9793e-04,\n                -1.0096e-03, -2.8022e-04]],\n     \n              [[-5.9831e-04,  5.6320e-04,  8.6294e-04,  ...,  4.9615e-04,\n                 1.0889e-03,  1.4995e-03],\n               [-4.0824e-05,  1.7635e-03,  1.1673e-03,  ..., -3.5770e-05,\n                 3.6687e-04,  9.4082e-04],\n               [-1.6136e-03,  2.1917e-03,  5.4228e-04,  ..., -6.1572e-04,\n                 1.2992e-03,  7.2608e-04],\n               ...,\n               [-8.4429e-04,  2.5254e-04, -1.2504e-03,  ..., -8.0304e-04,\n                 2.5210e-04,  1.7864e-03],\n               [-3.7544e-04,  1.1824e-04,  4.9418e-05,  ..., -1.9423e-03,\n                -5.4514e-04,  1.8798e-04],\n               [-6.0594e-04,  1.7006e-04,  1.2356e-03,  ...,  2.3483e-05,\n                 4.0398e-05,  8.9866e-04]]],\n     \n     \n             [[[-9.5429e-04, -8.2581e-04, -7.0222e-04,  ..., -9.9948e-04,\n                -7.6501e-04, -9.5207e-04],\n               [-9.4678e-04, -5.1208e-04, -4.8790e-04,  ..., -6.8579e-04,\n                -1.0364e-03, -1.0126e-03],\n               [-7.2448e-04, -5.5646e-05, -2.8939e-04,  ..., -5.5342e-04,\n                -6.5628e-04, -5.2683e-04],\n               ...,\n               [-4.5915e-04, -9.5917e-05, -2.8130e-04,  ..., -3.1858e-04,\n                -7.7518e-04, -3.4811e-04],\n               [-1.2767e-04,  8.5884e-05, -1.4349e-04,  ..., -5.0983e-04,\n                -8.4864e-04, -7.5364e-04],\n               [-1.9895e-04,  9.0942e-05,  1.7718e-04,  ..., -2.7014e-04,\n                -6.1753e-04, -4.9849e-04]],\n     \n              [[-4.5568e-04, -3.3695e-04, -2.1118e-04,  ..., -5.1993e-04,\n                -3.2815e-04, -4.8536e-04],\n               [-5.1057e-04, -9.7784e-05, -8.5962e-05,  ..., -3.0408e-04,\n                -7.3521e-04, -6.9270e-04],\n               [-3.1225e-04,  3.2745e-04,  9.2992e-05,  ..., -2.3678e-04,\n                -3.7327e-04, -2.1000e-04],\n               ...,\n               [-1.0800e-04,  1.7680e-04, -2.4478e-05,  ..., -5.0589e-05,\n                -5.4686e-04, -8.7658e-05],\n               [ 1.5599e-04,  2.9680e-04,  4.2405e-05,  ..., -3.0292e-04,\n                -6.4603e-04, -5.4717e-04],\n               [ 8.6749e-05,  3.2111e-04,  3.9415e-04,  ..., -1.3847e-05,\n                -4.0776e-04, -2.6067e-04]],\n     \n              [[-8.9340e-05, -1.1697e-05,  1.4960e-04,  ..., -1.4716e-04,\n                 5.9736e-05, -4.7919e-05],\n               [-1.0855e-04,  1.8567e-04,  2.1741e-04,  ...,  1.2569e-04,\n                -2.5728e-04, -1.6282e-04],\n               [ 7.2600e-05,  6.0365e-04,  4.1259e-04,  ...,  1.9385e-04,\n                 8.9647e-05,  2.6459e-04],\n               ...,\n               [ 3.0215e-04,  5.0325e-04,  3.1958e-04,  ...,  3.4181e-04,\n                -8.7123e-05,  4.1799e-04],\n               [ 5.8909e-04,  6.0764e-04,  4.1020e-04,  ...,  1.1865e-04,\n                -1.7374e-04, -2.2009e-05],\n               [ 5.2439e-04,  6.5424e-04,  7.2691e-04,  ...,  4.1764e-04,\n                 4.7930e-05,  2.4066e-04]]],\n     \n     \n             ...,\n     \n     \n             [[[-6.8666e-04, -3.8459e-04, -4.4420e-04,  ..., -2.9882e-04,\n                -2.5078e-04, -4.9724e-05],\n               [-3.3788e-04, -1.5505e-04, -2.6247e-04,  ...,  1.5401e-04,\n                 3.2985e-04,  5.3962e-04],\n               [-3.3975e-04, -1.2196e-04, -3.1486e-05,  ..., -2.9067e-04,\n                 1.5533e-04,  3.4164e-04],\n               ...,\n               [-5.6927e-04, -2.7950e-04, -6.0612e-05,  ...,  1.8759e-04,\n                 2.8577e-04,  2.8945e-04],\n               [-4.0991e-04, -1.7144e-04, -1.7213e-04,  ...,  2.9807e-04,\n                 4.0634e-04,  2.6744e-04],\n               [-1.2124e-04,  1.1990e-04,  2.1593e-04,  ...,  3.7999e-04,\n                 6.1456e-04,  8.5947e-04]],\n     \n              [[-4.3415e-04, -8.2498e-05, -1.3348e-04,  ...,  2.5750e-06,\n                 1.1299e-04,  3.2092e-04],\n               [-1.2938e-04,  1.1958e-04, -9.5829e-07,  ...,  4.2893e-04,\n                 6.2055e-04,  8.5049e-04],\n               [-1.0681e-04,  1.4345e-04,  2.3939e-04,  ...,  1.6827e-05,\n                 4.4597e-04,  6.5112e-04],\n               ...,\n               [-3.7447e-04, -4.2999e-05,  1.6803e-04,  ...,  4.6854e-04,\n                 5.2794e-04,  5.7014e-04],\n               [-3.3160e-04, -4.0732e-05, -4.7959e-05,  ...,  4.6864e-04,\n                 5.5104e-04,  4.4167e-04],\n               [-2.3331e-05,  2.6373e-04,  3.5489e-04,  ...,  5.2978e-04,\n                 7.3352e-04,  1.0115e-03]],\n     \n              [[-1.5121e-04,  1.8905e-04,  9.4186e-05,  ...,  2.2420e-04,\n                 2.2548e-04,  3.6440e-04],\n               [ 2.2240e-05,  2.9310e-04,  1.6537e-04,  ...,  5.7815e-04,\n                 7.3121e-04,  9.3679e-04],\n               [ 1.9046e-05,  2.8213e-04,  3.4891e-04,  ...,  1.8431e-04,\n                 5.9379e-04,  7.5403e-04],\n               ...,\n               [-2.8056e-04,  1.0977e-04,  3.3122e-04,  ...,  6.8405e-04,\n                 7.7749e-04,  8.1609e-04],\n               [-2.0018e-04,  1.5424e-04,  1.7547e-04,  ...,  7.7382e-04,\n                 8.4831e-04,  7.1361e-04],\n               [ 8.6169e-05,  4.5272e-04,  5.7577e-04,  ...,  8.2495e-04,\n                 1.0075e-03,  1.2728e-03]]],\n     \n     \n             [[[-9.9304e-07, -2.0566e-04, -4.7131e-04,  ..., -6.4686e-04,\n                -3.2647e-04, -2.9927e-04],\n               [-1.6027e-04, -3.4791e-04, -3.3025e-04,  ..., -2.2080e-04,\n                -1.9203e-06, -4.0518e-04],\n               [ 8.4448e-05,  1.4369e-04,  5.1860e-04,  ...,  4.1731e-04,\n                 6.3901e-04,  4.2001e-04],\n               ...,\n               [ 3.8454e-04,  7.2944e-04,  6.3912e-04,  ...,  1.1590e-03,\n                 9.1516e-04,  7.5616e-04],\n               [ 8.3191e-04,  9.9415e-04,  1.1096e-03,  ...,  9.0712e-04,\n                 1.0181e-03,  5.8444e-04],\n               [ 9.0277e-04,  1.1080e-03,  1.2744e-03,  ...,  9.5086e-04,\n                 9.9904e-04,  7.1353e-04]],\n     \n              [[ 1.3080e-04, -5.9943e-05, -3.5182e-04,  ..., -6.2095e-04,\n                -3.5627e-04, -3.5474e-04],\n               [-1.8900e-04, -3.6360e-04, -3.0289e-04,  ..., -2.6222e-04,\n                -1.3635e-04, -5.7500e-04],\n               [ 1.0158e-05,  1.4380e-04,  5.8895e-04,  ...,  3.9758e-04,\n                 5.2350e-04,  2.3666e-04],\n               ...,\n               [ 2.2985e-04,  6.3743e-04,  5.7725e-04,  ...,  1.0936e-03,\n                 7.5720e-04,  5.2947e-04],\n               [ 7.2500e-04,  9.2710e-04,  1.0580e-03,  ...,  7.6512e-04,\n                 8.4121e-04,  3.3651e-04],\n               [ 8.1291e-04,  1.0388e-03,  1.2049e-03,  ...,  7.8515e-04,\n                 8.2002e-04,  4.7592e-04]],\n     \n              [[ 4.6131e-04,  1.9056e-04, -6.6065e-05,  ..., -2.6986e-04,\n                -6.6046e-06,  3.6181e-05],\n               [ 1.5187e-04, -2.2180e-05,  2.9590e-05,  ...,  1.0673e-04,\n                 2.5163e-04, -1.6776e-04],\n               [ 3.2804e-04,  4.2223e-04,  8.6093e-04,  ...,  6.9904e-04,\n                 8.6864e-04,  6.0321e-04],\n               ...,\n               [ 5.4193e-04,  9.2455e-04,  8.6039e-04,  ...,  1.3328e-03,\n                 1.0125e-03,  8.2761e-04],\n               [ 1.0076e-03,  1.1297e-03,  1.2513e-03,  ...,  1.0015e-03,\n                 1.0870e-03,  6.1068e-04],\n               [ 1.0610e-03,  1.1834e-03,  1.3451e-03,  ...,  9.8689e-04,\n                 1.0582e-03,  7.8927e-04]]],\n     \n     \n             [[[-7.6475e-04, -5.8301e-04, -6.1339e-04,  ..., -5.6895e-04,\n                -3.1897e-04, -4.0566e-04],\n               [-8.8986e-04, -8.2620e-04, -8.1796e-04,  ..., -4.9005e-04,\n                -3.2159e-04, -3.9973e-04],\n               [-1.0718e-03, -8.1430e-04, -8.0039e-04,  ..., -4.3810e-04,\n                -2.9325e-04,  2.1803e-04],\n               ...,\n               [-7.2776e-04, -6.0616e-04, -7.1531e-04,  ..., -3.2975e-04,\n                 2.4688e-04,  2.4754e-05],\n               [-5.3360e-04, -3.9569e-04, -1.0348e-03,  ..., -3.9806e-05,\n                 1.9424e-04, -8.5095e-05],\n               [-3.2585e-04, -2.5969e-04, -5.8566e-04,  ...,  1.9979e-04,\n                -4.2880e-05,  2.9219e-04]],\n     \n              [[-3.0785e-05,  1.0678e-04,  2.9218e-05,  ..., -1.6774e-04,\n                -4.6804e-06, -1.2293e-04],\n               [-1.2522e-04, -1.0412e-04, -1.8034e-04,  ..., -1.2277e-04,\n                -6.8654e-05, -1.8132e-04],\n               [-3.3412e-04, -1.3041e-04, -1.9204e-04,  ..., -1.2125e-04,\n                -8.7163e-05,  3.9916e-04],\n               ...,\n               [ 4.0608e-06,  8.0636e-05, -1.1715e-04,  ...,  5.9366e-05,\n                 5.3666e-04,  2.9912e-04],\n               [ 1.2779e-04,  2.5501e-04, -4.2473e-04,  ...,  4.2326e-04,\n                 5.8636e-04,  2.9154e-04],\n               [ 2.9699e-04,  3.6968e-04,  3.7485e-05,  ...,  7.1547e-04,\n                 3.9485e-04,  7.5064e-04]],\n     \n              [[ 4.8910e-04,  7.0085e-04,  6.0344e-04,  ...,  3.1117e-04,\n                 4.4407e-04,  3.1056e-04],\n               [ 5.3973e-04,  5.8767e-04,  5.3157e-04,  ...,  5.1234e-04,\n                 5.2781e-04,  3.8379e-04],\n               [ 3.6597e-04,  6.0753e-04,  5.6576e-04,  ...,  5.6198e-04,\n                 5.5345e-04,  9.7064e-04],\n               ...,\n               [ 6.9494e-04,  8.6102e-04,  6.5245e-04,  ...,  8.2745e-04,\n                 1.1916e-03,  8.9730e-04],\n               [ 6.8872e-04,  8.8264e-04,  2.7137e-04,  ...,  1.0818e-03,\n                 1.1515e-03,  8.4438e-04],\n               [ 8.3957e-04,  9.7722e-04,  6.8239e-04,  ...,  1.3666e-03,\n                 1.0151e-03,  1.3520e-03]]]]),\n     'exp_avg_sq': tensor([[[[1.0973e-06, 1.1546e-06, 1.1299e-06,  ..., 1.0834e-06,\n                1.1290e-06, 1.2269e-06],\n               [1.1966e-06, 1.1142e-06, 1.1508e-06,  ..., 1.1928e-06,\n                1.2712e-06, 1.2321e-06],\n               [1.0337e-06, 9.9801e-07, 1.0100e-06,  ..., 1.0615e-06,\n                1.0440e-06, 1.0403e-06],\n               ...,\n               [1.0417e-06, 1.0220e-06, 9.9747e-07,  ..., 1.1079e-06,\n                1.0641e-06, 1.0932e-06],\n               [1.1618e-06, 1.0876e-06, 1.0686e-06,  ..., 1.0293e-06,\n                1.1416e-06, 1.0606e-06],\n               [1.3184e-06, 1.1817e-06, 1.1145e-06,  ..., 1.0130e-06,\n                1.1499e-06, 1.1077e-06]],\n     \n              [[9.1993e-07, 9.3478e-07, 9.3983e-07,  ..., 8.8465e-07,\n                9.2429e-07, 9.8375e-07],\n               [9.6244e-07, 8.7929e-07, 8.9540e-07,  ..., 9.6894e-07,\n                1.0470e-06, 9.6020e-07],\n               [9.3349e-07, 8.4328e-07, 7.7280e-07,  ..., 8.2732e-07,\n                8.0753e-07, 8.1858e-07],\n               ...,\n               [9.9202e-07, 8.6948e-07, 7.6490e-07,  ..., 8.8586e-07,\n                9.0953e-07, 9.5859e-07],\n               [9.9730e-07, 8.7241e-07, 8.4914e-07,  ..., 7.9610e-07,\n                9.1166e-07, 9.3005e-07],\n               [1.0841e-06, 9.2198e-07, 8.4170e-07,  ..., 7.9353e-07,\n                9.3766e-07, 9.0756e-07]],\n     \n              [[9.6343e-07, 9.8306e-07, 1.0342e-06,  ..., 1.0164e-06,\n                1.0713e-06, 1.0551e-06],\n               [1.0123e-06, 9.9633e-07, 1.0054e-06,  ..., 1.0536e-06,\n                1.1795e-06, 1.0953e-06],\n               [1.0619e-06, 9.7188e-07, 8.5691e-07,  ..., 9.7160e-07,\n                1.0019e-06, 1.0137e-06],\n               ...,\n               [1.1316e-06, 1.0440e-06, 9.2790e-07,  ..., 1.0748e-06,\n                1.1239e-06, 1.1416e-06],\n               [1.0436e-06, 1.0607e-06, 1.0068e-06,  ..., 1.0304e-06,\n                1.0655e-06, 1.1729e-06],\n               [1.1212e-06, 1.1081e-06, 1.0405e-06,  ..., 1.0154e-06,\n                1.2082e-06, 1.2226e-06]]],\n     \n     \n             [[[7.0414e-06, 7.5216e-06, 6.5619e-06,  ..., 6.7813e-06,\n                6.8643e-06, 6.7790e-06],\n               [6.0845e-06, 5.5246e-06, 5.7340e-06,  ..., 5.4306e-06,\n                6.1536e-06, 5.9099e-06],\n               [6.1935e-06, 6.5395e-06, 6.1612e-06,  ..., 4.3640e-06,\n                5.4797e-06, 6.0972e-06],\n               ...,\n               [5.4804e-06, 4.8675e-06, 4.4848e-06,  ..., 3.9818e-06,\n                4.9825e-06, 5.6416e-06],\n               [4.9669e-06, 4.5849e-06, 4.7294e-06,  ..., 4.3397e-06,\n                5.3260e-06, 5.4350e-06],\n               [5.2735e-06, 4.2330e-06, 4.6429e-06,  ..., 4.5403e-06,\n                5.5311e-06, 6.3445e-06]],\n     \n              [[7.0340e-06, 6.5933e-06, 5.9935e-06,  ..., 5.7373e-06,\n                5.7449e-06, 5.2974e-06],\n               [5.7914e-06, 4.6621e-06, 4.7591e-06,  ..., 4.4585e-06,\n                4.6973e-06, 4.5731e-06],\n               [5.6358e-06, 5.1994e-06, 4.6898e-06,  ..., 3.4636e-06,\n                4.5937e-06, 4.8692e-06],\n               ...,\n               [5.6465e-06, 4.6893e-06, 3.6846e-06,  ..., 3.1598e-06,\n                4.0383e-06, 4.2910e-06],\n               [5.2658e-06, 4.7894e-06, 4.0917e-06,  ..., 4.0337e-06,\n                4.6896e-06, 4.3404e-06],\n               [5.3347e-06, 4.7910e-06, 4.6335e-06,  ..., 4.5562e-06,\n                4.7539e-06, 5.2239e-06]],\n     \n              [[8.5991e-06, 7.3030e-06, 7.2243e-06,  ..., 6.8805e-06,\n                6.1878e-06, 5.7896e-06],\n               [7.4101e-06, 6.3515e-06, 6.4636e-06,  ..., 5.6258e-06,\n                5.4080e-06, 5.5890e-06],\n               [7.3325e-06, 6.7094e-06, 6.1528e-06,  ..., 4.9817e-06,\n                6.2579e-06, 6.3710e-06],\n               ...,\n               [7.2493e-06, 6.1535e-06, 4.7825e-06,  ..., 4.3249e-06,\n                5.0430e-06, 5.4926e-06],\n               [7.5047e-06, 6.7584e-06, 5.2522e-06,  ..., 5.2395e-06,\n                5.5372e-06, 5.5971e-06],\n               [7.7090e-06, 7.2743e-06, 6.7530e-06,  ..., 5.7488e-06,\n                5.7053e-06, 6.5671e-06]]],\n     \n     \n             [[[9.8218e-07, 9.0546e-07, 8.8481e-07,  ..., 8.9212e-07,\n                9.0116e-07, 9.3671e-07],\n               [9.7294e-07, 9.2687e-07, 8.2089e-07,  ..., 9.6323e-07,\n                9.4224e-07, 9.4067e-07],\n               [9.4484e-07, 8.2709e-07, 7.6940e-07,  ..., 8.4124e-07,\n                8.5093e-07, 8.7212e-07],\n               ...,\n               [9.5975e-07, 9.0468e-07, 8.8377e-07,  ..., 8.0483e-07,\n                8.7493e-07, 8.6433e-07],\n               [1.0470e-06, 8.8476e-07, 8.5093e-07,  ..., 7.9785e-07,\n                8.8513e-07, 8.7424e-07],\n               [1.0329e-06, 9.3301e-07, 8.7124e-07,  ..., 8.2177e-07,\n                9.1375e-07, 9.8187e-07]],\n     \n              [[8.3254e-07, 6.9251e-07, 6.4757e-07,  ..., 6.6602e-07,\n                7.1657e-07, 7.0233e-07],\n               [7.5465e-07, 6.5478e-07, 5.5731e-07,  ..., 6.4262e-07,\n                6.7734e-07, 6.6421e-07],\n               [7.3270e-07, 5.5609e-07, 4.8924e-07,  ..., 5.7197e-07,\n                5.4350e-07, 5.9384e-07],\n               ...,\n               [7.3204e-07, 6.3175e-07, 6.1969e-07,  ..., 5.2313e-07,\n                5.5831e-07, 5.4326e-07],\n               [8.4206e-07, 6.4123e-07, 5.9907e-07,  ..., 5.5099e-07,\n                6.0003e-07, 6.2852e-07],\n               [8.2652e-07, 7.3410e-07, 6.5965e-07,  ..., 6.3622e-07,\n                6.7993e-07, 6.9952e-07]],\n     \n              [[9.1642e-07, 7.8419e-07, 7.5061e-07,  ..., 8.0841e-07,\n                8.4580e-07, 8.2682e-07],\n               [7.8238e-07, 7.0750e-07, 6.0282e-07,  ..., 7.0489e-07,\n                7.3982e-07, 7.1348e-07],\n               [7.8809e-07, 6.4584e-07, 5.5934e-07,  ..., 6.7055e-07,\n                6.2197e-07, 6.5151e-07],\n               ...,\n               [7.4203e-07, 7.1578e-07, 6.7941e-07,  ..., 7.1344e-07,\n                6.6238e-07, 6.6252e-07],\n               [8.6067e-07, 6.9893e-07, 7.1579e-07,  ..., 6.7569e-07,\n                7.3129e-07, 7.2578e-07],\n               [8.6674e-07, 8.2902e-07, 7.7965e-07,  ..., 7.4490e-07,\n                7.7363e-07, 7.7520e-07]]],\n     \n     \n             ...,\n     \n     \n             [[[1.0314e-06, 1.0964e-06, 1.0741e-06,  ..., 1.0990e-06,\n                9.8552e-07, 1.0369e-06],\n               [1.0493e-06, 1.1675e-06, 1.0722e-06,  ..., 1.1267e-06,\n                1.0994e-06, 1.1616e-06],\n               [1.0836e-06, 1.1436e-06, 1.0237e-06,  ..., 1.0504e-06,\n                1.1134e-06, 1.0795e-06],\n               ...,\n               [1.0742e-06, 1.1210e-06, 1.0288e-06,  ..., 1.0586e-06,\n                9.7441e-07, 1.0764e-06],\n               [1.0693e-06, 1.0835e-06, 1.1473e-06,  ..., 1.0803e-06,\n                1.0354e-06, 1.0915e-06],\n               [1.1182e-06, 1.0939e-06, 1.0965e-06,  ..., 1.1531e-06,\n                1.0670e-06, 1.1763e-06]],\n     \n              [[9.6641e-07, 1.0475e-06, 9.9603e-07,  ..., 1.0214e-06,\n                9.1408e-07, 1.0017e-06],\n               [9.6950e-07, 1.0795e-06, 1.0397e-06,  ..., 1.0427e-06,\n                1.0052e-06, 1.0981e-06],\n               [1.0022e-06, 1.0472e-06, 9.6990e-07,  ..., 9.5419e-07,\n                9.9716e-07, 1.0062e-06],\n               ...,\n               [9.6690e-07, 9.9404e-07, 9.4223e-07,  ..., 9.7519e-07,\n                8.5977e-07, 9.7020e-07],\n               [9.1760e-07, 9.7571e-07, 1.0812e-06,  ..., 9.6155e-07,\n                9.1415e-07, 9.5714e-07],\n               [9.8812e-07, 1.0284e-06, 1.0925e-06,  ..., 1.0461e-06,\n                9.6471e-07, 1.0533e-06]],\n     \n              [[1.0097e-06, 1.1046e-06, 1.0550e-06,  ..., 1.0352e-06,\n                9.4591e-07, 1.0254e-06],\n               [9.7445e-07, 1.1092e-06, 1.0869e-06,  ..., 1.0622e-06,\n                1.0314e-06, 1.1055e-06],\n               [1.0376e-06, 1.0739e-06, 1.0194e-06,  ..., 1.0055e-06,\n                9.9199e-07, 1.0264e-06],\n               ...,\n               [1.0340e-06, 1.0397e-06, 1.0108e-06,  ..., 1.0837e-06,\n                9.5629e-07, 1.0272e-06],\n               [9.9447e-07, 1.0504e-06, 1.1548e-06,  ..., 1.0610e-06,\n                9.9670e-07, 9.8495e-07],\n               [1.0672e-06, 1.1313e-06, 1.1873e-06,  ..., 1.1416e-06,\n                1.0533e-06, 1.0852e-06]]],\n     \n     \n             [[[1.2199e-06, 1.2372e-06, 1.1949e-06,  ..., 1.2818e-06,\n                1.1866e-06, 1.1787e-06],\n               [1.2532e-06, 1.2474e-06, 1.1699e-06,  ..., 1.2624e-06,\n                1.2709e-06, 1.1172e-06],\n               [1.3032e-06, 1.2009e-06, 1.2425e-06,  ..., 1.1413e-06,\n                1.1949e-06, 1.1298e-06],\n               ...,\n               [1.2367e-06, 1.3028e-06, 1.2647e-06,  ..., 1.3173e-06,\n                1.1642e-06, 1.1291e-06],\n               [1.2899e-06, 1.3606e-06, 1.3298e-06,  ..., 1.2539e-06,\n                1.2895e-06, 1.2169e-06],\n               [1.5365e-06, 1.4586e-06, 1.4419e-06,  ..., 1.3375e-06,\n                1.3870e-06, 1.2678e-06]],\n     \n              [[1.0664e-06, 9.9530e-07, 9.6462e-07,  ..., 1.0025e-06,\n                9.0297e-07, 8.8491e-07],\n               [1.0682e-06, 1.0848e-06, 1.0144e-06,  ..., 1.0456e-06,\n                1.0430e-06, 8.2692e-07],\n               [1.0775e-06, 9.9826e-07, 1.0672e-06,  ..., 9.2259e-07,\n                9.6387e-07, 8.6687e-07],\n               ...,\n               [9.8322e-07, 9.7079e-07, 9.6106e-07,  ..., 9.5571e-07,\n                8.6958e-07, 8.2663e-07],\n               [9.9484e-07, 1.0205e-06, 9.9863e-07,  ..., 9.2145e-07,\n                9.0773e-07, 8.9974e-07],\n               [1.1584e-06, 1.0669e-06, 1.0429e-06,  ..., 1.0049e-06,\n                9.9504e-07, 9.8463e-07]],\n     \n              [[1.1750e-06, 1.0929e-06, 1.0180e-06,  ..., 9.6925e-07,\n                9.1541e-07, 8.8664e-07],\n               [1.1504e-06, 1.1601e-06, 1.0276e-06,  ..., 1.0959e-06,\n                1.0930e-06, 9.2837e-07],\n               [1.0808e-06, 9.8289e-07, 1.0230e-06,  ..., 9.6251e-07,\n                1.0237e-06, 9.2363e-07],\n               ...,\n               [1.0074e-06, 9.8360e-07, 9.4205e-07,  ..., 9.1848e-07,\n                8.6884e-07, 8.9002e-07],\n               [1.0730e-06, 1.1038e-06, 1.0392e-06,  ..., 9.0963e-07,\n                9.1736e-07, 9.6043e-07],\n               [1.2287e-06, 1.1542e-06, 1.1108e-06,  ..., 1.0023e-06,\n                9.9096e-07, 1.0130e-06]]],\n     \n     \n             [[[1.3017e-06, 1.2777e-06, 1.1688e-06,  ..., 1.3385e-06,\n                1.3562e-06, 1.5138e-06],\n               [1.1958e-06, 1.2873e-06, 1.2610e-06,  ..., 1.2904e-06,\n                1.3092e-06, 1.4351e-06],\n               [1.1213e-06, 1.1419e-06, 1.1221e-06,  ..., 1.1839e-06,\n                1.2410e-06, 1.3809e-06],\n               ...,\n               [1.2236e-06, 1.0855e-06, 1.1119e-06,  ..., 1.1539e-06,\n                1.1518e-06, 1.2157e-06],\n               [1.0868e-06, 1.0994e-06, 1.0913e-06,  ..., 1.0308e-06,\n                1.0433e-06, 1.1869e-06],\n               [1.0285e-06, 1.0266e-06, 1.0296e-06,  ..., 1.0312e-06,\n                1.0748e-06, 1.0537e-06]],\n     \n              [[1.5160e-06, 1.4210e-06, 1.3034e-06,  ..., 1.4588e-06,\n                1.3887e-06, 1.5427e-06],\n               [1.3670e-06, 1.4528e-06, 1.4297e-06,  ..., 1.3841e-06,\n                1.2867e-06, 1.4194e-06],\n               [1.2171e-06, 1.2612e-06, 1.2239e-06,  ..., 1.2265e-06,\n                1.1529e-06, 1.3255e-06],\n               ...,\n               [1.2383e-06, 1.1847e-06, 1.1988e-06,  ..., 1.1814e-06,\n                1.0501e-06, 1.1897e-06],\n               [1.2134e-06, 1.2786e-06, 1.2203e-06,  ..., 1.0954e-06,\n                9.9970e-07, 1.1975e-06],\n               [1.1004e-06, 1.1568e-06, 1.1725e-06,  ..., 1.0915e-06,\n                1.0084e-06, 1.0845e-06]],\n     \n              [[1.9655e-06, 1.9134e-06, 1.7543e-06,  ..., 1.8426e-06,\n                1.7884e-06, 1.9759e-06],\n               [1.8748e-06, 2.0396e-06, 1.9557e-06,  ..., 1.9032e-06,\n                1.7692e-06, 1.9110e-06],\n               [1.5979e-06, 1.7812e-06, 1.6640e-06,  ..., 1.6557e-06,\n                1.5443e-06, 1.7455e-06],\n               ...,\n               [1.6238e-06, 1.6519e-06, 1.5594e-06,  ..., 1.6075e-06,\n                1.4256e-06, 1.5791e-06],\n               [1.6392e-06, 1.8479e-06, 1.7043e-06,  ..., 1.5946e-06,\n                1.4359e-06, 1.6065e-06],\n               [1.4782e-06, 1.6146e-06, 1.6332e-06,  ..., 1.5218e-06,\n                1.4006e-06, 1.4870e-06]]]])},\n    109: {'exp_avg': tensor([[[[ 2.3097e-05]],\n     \n              [[-1.8665e-04]],\n     \n              [[ 1.9350e-04]],\n     \n              ...,\n     \n              [[-3.4713e-04]],\n     \n              [[ 3.2963e-05]],\n     \n              [[-2.4370e-04]]],\n     \n     \n             [[[ 4.5631e-04]],\n     \n              [[-1.6450e-04]],\n     \n              [[ 3.0287e-04]],\n     \n              ...,\n     \n              [[-2.0144e-04]],\n     \n              [[-2.7269e-04]],\n     \n              [[ 6.8149e-05]]],\n     \n     \n             [[[ 8.1855e-04]],\n     \n              [[ 2.4895e-04]],\n     \n              [[ 9.7862e-05]],\n     \n              ...,\n     \n              [[-2.4013e-04]],\n     \n              [[ 2.8917e-04]],\n     \n              [[ 8.2454e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-6.2870e-05]],\n     \n              [[ 4.2307e-05]],\n     \n              [[-1.0456e-04]],\n     \n              ...,\n     \n              [[-1.5253e-04]],\n     \n              [[ 3.4359e-04]],\n     \n              [[-1.2929e-05]]],\n     \n     \n             [[[-3.5779e-04]],\n     \n              [[ 4.4660e-05]],\n     \n              [[-1.4999e-04]],\n     \n              ...,\n     \n              [[-1.6520e-04]],\n     \n              [[-6.6304e-05]],\n     \n              [[-2.0523e-05]]],\n     \n     \n             [[[-1.0264e-04]],\n     \n              [[-1.2155e-04]],\n     \n              [[ 1.5334e-05]],\n     \n              ...,\n     \n              [[-4.7827e-05]],\n     \n              [[ 7.8804e-05]],\n     \n              [[ 1.7716e-05]]]]),\n     'exp_avg_sq': tensor([[[[4.5154e-07]],\n     \n              [[1.3280e-07]],\n     \n              [[1.5275e-07]],\n     \n              ...,\n     \n              [[4.4192e-07]],\n     \n              [[5.4484e-07]],\n     \n              [[5.3561e-07]]],\n     \n     \n             [[[3.7576e-07]],\n     \n              [[3.6832e-08]],\n     \n              [[1.7945e-07]],\n     \n              ...,\n     \n              [[3.4025e-07]],\n     \n              [[2.5424e-07]],\n     \n              [[4.8926e-07]]],\n     \n     \n             [[[4.7692e-07]],\n     \n              [[1.3638e-07]],\n     \n              [[1.9723e-07]],\n     \n              ...,\n     \n              [[3.4088e-07]],\n     \n              [[4.0281e-07]],\n     \n              [[4.8979e-07]]],\n     \n     \n             ...,\n     \n     \n             [[[1.6238e-07]],\n     \n              [[1.4573e-07]],\n     \n              [[4.5085e-08]],\n     \n              ...,\n     \n              [[1.4484e-07]],\n     \n              [[1.7349e-07]],\n     \n              [[3.2676e-08]]],\n     \n     \n             [[[1.2988e-07]],\n     \n              [[1.2413e-07]],\n     \n              [[3.6640e-08]],\n     \n              ...,\n     \n              [[1.2920e-07]],\n     \n              [[2.5295e-08]],\n     \n              [[4.0511e-08]]],\n     \n     \n             [[[1.4918e-08]],\n     \n              [[2.7115e-08]],\n     \n              [[3.5012e-09]],\n     \n              ...,\n     \n              [[2.0340e-08]],\n     \n              [[1.8151e-08]],\n     \n              [[2.0997e-08]]]])},\n    110: {'exp_avg': tensor([[[[ 8.9400e-05, -7.1299e-06,  8.3488e-05],\n               [-6.7473e-06,  1.4754e-04,  7.6516e-05],\n               [-4.6182e-05,  5.1512e-05,  1.3872e-04]],\n     \n              [[-1.1357e-04,  7.9823e-05,  1.8628e-04],\n               [-1.3885e-04,  6.5177e-05,  1.9735e-04],\n               [-1.8182e-04, -5.1750e-06,  1.3409e-04]],\n     \n              [[ 7.4394e-05,  4.5385e-05,  8.2755e-05],\n               [-3.8128e-05,  3.0238e-05,  7.5649e-05],\n               [-5.2841e-05,  4.9264e-05,  7.9559e-05]],\n     \n              ...,\n     \n              [[-2.1619e-05, -7.2666e-05, -5.0955e-05],\n               [-4.0442e-05,  5.7887e-05, -1.4087e-05],\n               [-3.0786e-05, -2.6034e-05, -8.8467e-05]],\n     \n              [[-1.4697e-04, -1.5355e-05, -7.2320e-05],\n               [-7.2339e-05,  8.5482e-05, -3.0670e-05],\n               [-4.1043e-05,  9.3255e-05, -2.2269e-06]],\n     \n              [[ 8.0609e-06, -3.9457e-05, -1.2607e-04],\n               [-6.2179e-06, -8.0499e-05, -1.2105e-04],\n               [-5.1700e-05, -1.0420e-04, -1.3051e-04]]],\n     \n     \n             [[[ 2.1922e-05, -6.1284e-05, -3.6544e-05],\n               [-5.6588e-05, -1.0603e-04, -1.4663e-04],\n               [-7.0962e-05, -4.7355e-05, -1.2317e-05]],\n     \n              [[-2.2704e-05,  8.3913e-06,  2.0822e-05],\n               [ 1.7078e-05,  1.3503e-05, -1.2283e-05],\n               [ 4.5446e-05,  7.4388e-05,  1.2683e-05]],\n     \n              [[ 9.1907e-06, -1.8493e-05, -2.9853e-06],\n               [-9.0327e-05, -1.5339e-05, -5.1933e-05],\n               [-8.2403e-05, -1.7798e-05, -6.0199e-05]],\n     \n              ...,\n     \n              [[-2.7876e-05,  6.7841e-05,  4.5572e-05],\n               [ 6.3227e-05,  7.6257e-05,  7.7811e-06],\n               [ 3.5414e-05,  5.9120e-05,  3.2895e-05]],\n     \n              [[ 5.7603e-05,  6.0588e-05, -1.7222e-05],\n               [ 1.2920e-05, -2.0152e-05, -8.0692e-05],\n               [ 8.6495e-05,  8.9591e-05,  4.4369e-05]],\n     \n              [[ 3.9038e-05,  1.7485e-05,  3.7884e-06],\n               [-5.1396e-05, -5.9810e-05, -3.0612e-05],\n               [-3.4338e-05, -8.9926e-06,  8.6971e-06]]],\n     \n     \n             [[[ 4.8019e-05,  7.6217e-05,  2.3117e-05],\n               [ 4.5317e-05,  8.3317e-05, -4.8254e-06],\n               [ 7.3266e-05,  1.1168e-04,  2.6655e-05]],\n     \n              [[-3.2313e-05, -2.4702e-05, -1.8808e-05],\n               [-3.0612e-05, -2.1559e-05, -2.6694e-05],\n               [-7.8907e-06,  3.7356e-06, -1.1932e-05]],\n     \n              [[-1.1027e-04, -9.0155e-05, -9.3090e-05],\n               [-8.8808e-05, -6.8746e-05, -6.8600e-05],\n               [-5.8988e-05, -1.1616e-05, -3.1550e-05]],\n     \n              ...,\n     \n              [[-9.4002e-05, -8.9067e-05, -1.4703e-04],\n               [-1.0274e-04, -9.2572e-05, -1.4197e-04],\n               [-2.0727e-05, -8.7563e-06, -1.8274e-05]],\n     \n              [[-2.9698e-05, -7.9784e-05, -3.2240e-06],\n               [-9.3284e-05, -1.4255e-04, -4.9662e-05],\n               [ 9.2486e-06, -3.1120e-05,  4.2828e-05]],\n     \n              [[ 6.0068e-05,  3.0088e-05,  9.1423e-05],\n               [ 1.1336e-04,  8.2112e-05,  1.5747e-04],\n               [ 1.3490e-04,  1.1571e-04,  2.0263e-04]]],\n     \n     \n             ...,\n     \n     \n             [[[-1.4567e-04,  8.4318e-05, -8.6494e-05],\n               [-8.8134e-05,  1.0884e-05, -4.2472e-05],\n               [-8.6006e-05, -6.4370e-05, -7.1885e-05]],\n     \n              [[ 1.1152e-04,  3.0630e-05,  1.1621e-04],\n               [ 2.4402e-04,  1.3921e-04,  1.7370e-04],\n               [ 1.7033e-04,  1.5139e-04,  1.0892e-04]],\n     \n              [[-4.2150e-05,  9.2032e-05, -4.1006e-05],\n               [ 6.8727e-05,  1.2888e-04, -5.2241e-05],\n               [ 9.7001e-05,  4.0236e-05, -1.1296e-04]],\n     \n              ...,\n     \n              [[-1.9361e-05,  2.8335e-05,  4.5638e-05],\n               [-2.7234e-05, -2.0591e-05, -1.9922e-06],\n               [-6.1695e-05, -1.4525e-04, -7.7792e-05]],\n     \n              [[ 4.5637e-05, -2.1894e-05,  3.7754e-05],\n               [ 5.6154e-07,  8.0087e-06, -6.9779e-05],\n               [-5.9299e-06, -4.8668e-05, -1.8812e-04]],\n     \n              [[-8.1167e-05,  8.3048e-06,  3.1422e-05],\n               [-4.3289e-05,  5.3197e-05, -2.6981e-05],\n               [-4.3801e-05,  3.6470e-05, -6.5780e-05]]],\n     \n     \n             [[[-6.5306e-05, -1.8775e-04, -2.1161e-04],\n               [-1.2965e-04, -1.6926e-04, -1.7529e-04],\n               [-2.2034e-04, -1.9485e-04, -1.6441e-04]],\n     \n              [[-2.3873e-04, -2.1281e-04, -2.3009e-04],\n               [-2.0283e-04, -9.5925e-05, -1.6894e-04],\n               [-1.6812e-04, -1.1083e-04, -1.4188e-04]],\n     \n              [[ 8.0868e-05,  1.3075e-04, -3.3127e-05],\n               [ 1.3210e-05, -1.3009e-04, -2.2797e-04],\n               [ 4.1014e-05, -2.5746e-05, -5.2284e-05]],\n     \n              ...,\n     \n              [[ 8.9335e-05,  3.6918e-05, -4.1214e-05],\n               [-8.7834e-05, -1.9970e-04, -1.2855e-04],\n               [ 6.3213e-05, -2.0600e-05, -8.2020e-07]],\n     \n              [[-5.8401e-05, -6.7745e-05, -1.4666e-04],\n               [ 4.1069e-05,  3.3238e-05, -2.9583e-05],\n               [-5.9654e-05, -3.7573e-05, -1.1640e-04]],\n     \n              [[ 1.7999e-05,  2.4564e-05, -5.4911e-05],\n               [-2.8030e-05, -3.6313e-05, -6.9374e-05],\n               [-6.5822e-05, -6.2133e-05, -9.9382e-05]]],\n     \n     \n             [[[ 8.6294e-06,  2.2344e-04,  2.0671e-04],\n               [ 1.5133e-04,  1.8625e-04,  2.4721e-04],\n               [ 4.2239e-05, -1.1423e-05, -3.0128e-05]],\n     \n              [[ 1.7696e-04,  7.4242e-05,  4.5758e-04],\n               [ 1.8343e-04,  5.6117e-06,  3.0307e-04],\n               [ 1.7663e-05, -9.2229e-05,  1.2850e-04]],\n     \n              [[-1.6900e-04,  4.3245e-05, -1.6425e-04],\n               [ 2.3069e-04,  2.9558e-04, -6.6311e-06],\n               [ 1.2504e-04, -1.8798e-05, -8.5913e-05]],\n     \n              ...,\n     \n              [[-1.0651e-04, -1.6276e-04,  1.5673e-04],\n               [-1.4646e-04, -5.4737e-05,  2.3179e-04],\n               [-1.3236e-04, -6.0071e-06,  2.8704e-04]],\n     \n              [[ 2.8265e-05,  2.4456e-04,  1.3935e-04],\n               [ 1.8241e-04,  4.1842e-04,  3.3918e-04],\n               [-3.1933e-05, -3.2022e-05,  1.1051e-04]],\n     \n              [[-1.5759e-04,  5.5164e-05,  1.4650e-04],\n               [-5.0046e-05,  1.2269e-04,  2.0716e-04],\n               [-2.0169e-04, -3.2309e-05,  2.2320e-05]]]]),\n     'exp_avg_sq': tensor([[[[2.8342e-08, 2.7109e-08, 2.1691e-08],\n               [2.8108e-08, 3.2247e-08, 2.6330e-08],\n               [2.7980e-08, 3.3569e-08, 2.6341e-08]],\n     \n              [[1.4106e-07, 1.4748e-07, 1.3385e-07],\n               [1.3317e-07, 1.3657e-07, 1.2883e-07],\n               [1.2627e-07, 1.2517e-07, 1.1799e-07]],\n     \n              [[2.4013e-08, 2.5369e-08, 2.6672e-08],\n               [2.7587e-08, 2.8045e-08, 2.5812e-08],\n               [2.6133e-08, 2.9486e-08, 3.1501e-08]],\n     \n              ...,\n     \n              [[1.2864e-08, 2.0135e-08, 1.7569e-08],\n               [1.5193e-08, 1.9623e-08, 1.6679e-08],\n               [1.3101e-08, 1.8225e-08, 1.4852e-08]],\n     \n              [[1.0600e-08, 1.2513e-08, 9.5188e-09],\n               [1.0269e-08, 1.6713e-08, 1.2001e-08],\n               [1.2012e-08, 1.8003e-08, 1.3426e-08]],\n     \n              [[1.2973e-08, 1.7019e-08, 1.5538e-08],\n               [1.4803e-08, 2.0060e-08, 1.8323e-08],\n               [1.2142e-08, 1.6442e-08, 1.6775e-08]]],\n     \n     \n             [[[2.5653e-08, 2.5091e-08, 2.0766e-08],\n               [2.1323e-08, 1.9690e-08, 1.9702e-08],\n               [2.1224e-08, 1.7374e-08, 1.7533e-08]],\n     \n              [[1.0459e-07, 1.0739e-07, 1.0567e-07],\n               [1.1161e-07, 1.1368e-07, 1.1389e-07],\n               [1.0097e-07, 1.0413e-07, 1.0408e-07]],\n     \n              [[1.9648e-08, 1.9829e-08, 2.1440e-08],\n               [2.3408e-08, 2.2239e-08, 1.8129e-08],\n               [2.3589e-08, 2.1146e-08, 2.2590e-08]],\n     \n              ...,\n     \n              [[1.7802e-08, 1.5458e-08, 1.3108e-08],\n               [1.9644e-08, 1.6066e-08, 1.3198e-08],\n               [1.4768e-08, 1.2742e-08, 9.7366e-09]],\n     \n              [[9.3049e-09, 9.3864e-09, 7.9801e-09],\n               [1.0789e-08, 1.1144e-08, 7.7768e-09],\n               [1.0101e-08, 9.9327e-09, 6.2293e-09]],\n     \n              [[1.2334e-08, 9.9817e-09, 9.3851e-09],\n               [1.1289e-08, 9.2422e-09, 7.6335e-09],\n               [9.1793e-09, 7.8702e-09, 6.0757e-09]]],\n     \n     \n             [[[3.0809e-08, 2.5884e-08, 2.1128e-08],\n               [2.3315e-08, 1.8677e-08, 1.5551e-08],\n               [2.4038e-08, 2.0734e-08, 1.5373e-08]],\n     \n              [[1.8593e-08, 1.7384e-08, 1.5119e-08],\n               [1.8717e-08, 1.7496e-08, 1.4964e-08],\n               [1.8390e-08, 1.7276e-08, 1.4778e-08]],\n     \n              [[7.0261e-09, 7.1330e-09, 1.1382e-08],\n               [5.3498e-09, 9.0045e-09, 1.1133e-08],\n               [4.5235e-09, 3.7799e-09, 7.2708e-09]],\n     \n              ...,\n     \n              [[2.2321e-08, 1.9307e-08, 1.8012e-08],\n               [2.0185e-08, 1.5646e-08, 1.3657e-08],\n               [3.7555e-08, 3.2171e-08, 2.6044e-08]],\n     \n              [[9.5855e-09, 8.2761e-09, 6.6986e-09],\n               [1.3172e-08, 1.3601e-08, 1.0143e-08],\n               [1.1767e-08, 1.2745e-08, 1.0777e-08]],\n     \n              [[8.8971e-08, 7.6821e-08, 6.6223e-08],\n               [8.9666e-08, 7.2055e-08, 6.4312e-08],\n               [9.5834e-08, 8.1773e-08, 7.0028e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[3.7960e-08, 4.0639e-08, 3.0039e-08],\n               [3.0785e-08, 3.6919e-08, 3.2924e-08],\n               [3.5714e-08, 3.4825e-08, 3.7362e-08]],\n     \n              [[1.5190e-07, 1.5462e-07, 1.4367e-07],\n               [1.4923e-07, 1.5366e-07, 1.4653e-07],\n               [1.4304e-07, 1.5097e-07, 1.3931e-07]],\n     \n              [[2.7260e-08, 2.9961e-08, 2.7190e-08],\n               [2.4975e-08, 3.1786e-08, 3.0528e-08],\n               [2.8817e-08, 3.1840e-08, 3.6588e-08]],\n     \n              ...,\n     \n              [[3.7700e-08, 4.1546e-08, 3.5263e-08],\n               [3.3345e-08, 3.9154e-08, 3.6857e-08],\n               [3.3059e-08, 4.0496e-08, 3.5113e-08]],\n     \n              [[1.6248e-08, 1.8268e-08, 1.4425e-08],\n               [1.7198e-08, 2.0820e-08, 1.7087e-08],\n               [2.3932e-08, 2.4478e-08, 2.2308e-08]],\n     \n              [[5.2003e-08, 5.4578e-08, 4.6472e-08],\n               [5.7629e-08, 5.9131e-08, 4.9793e-08],\n               [5.8738e-08, 5.9287e-08, 5.1351e-08]]],\n     \n     \n             [[[5.4575e-08, 5.1313e-08, 5.9737e-08],\n               [5.6140e-08, 5.7518e-08, 5.8293e-08],\n               [4.8006e-08, 4.6063e-08, 5.1473e-08]],\n     \n              [[2.0094e-07, 1.9761e-07, 2.0589e-07],\n               [2.1236e-07, 2.2214e-07, 2.3945e-07],\n               [2.1028e-07, 2.1600e-07, 2.2686e-07]],\n     \n              [[5.7420e-08, 6.2807e-08, 5.2164e-08],\n               [5.1856e-08, 5.4444e-08, 4.2526e-08],\n               [4.7825e-08, 5.1206e-08, 5.1165e-08]],\n     \n              ...,\n     \n              [[3.9227e-08, 4.5006e-08, 4.5992e-08],\n               [3.8962e-08, 4.1808e-08, 4.7117e-08],\n               [3.4991e-08, 3.8161e-08, 4.3421e-08]],\n     \n              [[2.3650e-08, 2.5298e-08, 2.6181e-08],\n               [2.7628e-08, 3.1762e-08, 2.7880e-08],\n               [2.4072e-08, 3.0304e-08, 2.4253e-08]],\n     \n              [[3.9102e-08, 4.4727e-08, 4.5407e-08],\n               [3.9905e-08, 4.2406e-08, 4.5248e-08],\n               [3.8230e-08, 4.0439e-08, 4.2597e-08]]],\n     \n     \n             [[[1.2164e-07, 1.0194e-07, 1.1233e-07],\n               [1.2178e-07, 1.0255e-07, 1.0053e-07],\n               [1.2101e-07, 1.1339e-07, 8.7257e-08]],\n     \n              [[3.6298e-07, 3.8911e-07, 3.4614e-07],\n               [3.8659e-07, 4.0757e-07, 3.5044e-07],\n               [3.7976e-07, 3.7511e-07, 3.3166e-07]],\n     \n              [[7.9118e-08, 8.3835e-08, 8.4391e-08],\n               [7.8728e-08, 9.3609e-08, 1.0889e-07],\n               [8.2086e-08, 8.0199e-08, 8.3239e-08]],\n     \n              ...,\n     \n              [[1.2395e-07, 1.4035e-07, 1.0374e-07],\n               [1.4855e-07, 1.5536e-07, 1.1456e-07],\n               [1.4947e-07, 1.6764e-07, 1.3294e-07]],\n     \n              [[5.2703e-08, 6.4691e-08, 5.2404e-08],\n               [7.8468e-08, 9.4657e-08, 7.5275e-08],\n               [7.6114e-08, 7.0908e-08, 5.8975e-08]],\n     \n              [[2.0385e-07, 2.0519e-07, 1.5938e-07],\n               [2.3731e-07, 2.4629e-07, 1.7519e-07],\n               [2.5562e-07, 2.6457e-07, 1.8293e-07]]]])},\n    111: {'exp_avg': tensor([[[[ 1.6798e-04]],\n     \n              [[ 1.0204e-04]],\n     \n              [[-1.2809e-05]],\n     \n              ...,\n     \n              [[-1.6463e-04]],\n     \n              [[ 9.3168e-07]],\n     \n              [[ 3.3478e-04]]],\n     \n     \n             [[[-8.1863e-05]],\n     \n              [[-4.8441e-05]],\n     \n              [[ 8.0406e-05]],\n     \n              ...,\n     \n              [[-3.2388e-05]],\n     \n              [[ 5.4868e-05]],\n     \n              [[-2.2969e-05]]],\n     \n     \n             [[[ 8.9638e-05]],\n     \n              [[-3.0129e-06]],\n     \n              [[-3.8397e-05]],\n     \n              ...,\n     \n              [[-1.2288e-04]],\n     \n              [[ 7.4580e-05]],\n     \n              [[-1.4019e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-1.6345e-04]],\n     \n              [[ 1.2433e-04]],\n     \n              [[-6.7530e-06]],\n     \n              ...,\n     \n              [[ 2.9161e-04]],\n     \n              [[ 8.8984e-06]],\n     \n              [[-2.8664e-04]]],\n     \n     \n             [[[ 1.0060e-05]],\n     \n              [[ 4.0865e-05]],\n     \n              [[ 4.0712e-05]],\n     \n              ...,\n     \n              [[-1.0419e-04]],\n     \n              [[ 1.4680e-04]],\n     \n              [[ 8.5847e-05]]],\n     \n     \n             [[[-2.7144e-05]],\n     \n              [[-7.6020e-05]],\n     \n              [[ 2.4450e-05]],\n     \n              ...,\n     \n              [[-1.0626e-04]],\n     \n              [[ 9.5579e-05]],\n     \n              [[-1.0534e-03]]]]),\n     'exp_avg_sq': tensor([[[[6.0092e-08]],\n     \n              [[5.5155e-08]],\n     \n              [[8.1515e-08]],\n     \n              ...,\n     \n              [[5.6725e-08]],\n     \n              [[3.9107e-08]],\n     \n              [[1.0533e-07]]],\n     \n     \n             [[[5.3185e-08]],\n     \n              [[7.1763e-08]],\n     \n              [[6.9014e-08]],\n     \n              ...,\n     \n              [[5.4880e-08]],\n     \n              [[4.2851e-08]],\n     \n              [[5.0314e-08]]],\n     \n     \n             [[[3.8933e-08]],\n     \n              [[2.8125e-08]],\n     \n              [[4.1273e-08]],\n     \n              ...,\n     \n              [[2.9855e-08]],\n     \n              [[2.8505e-08]],\n     \n              [[2.0908e-07]]],\n     \n     \n             ...,\n     \n     \n             [[[1.1935e-07]],\n     \n              [[1.4024e-07]],\n     \n              [[3.6446e-08]],\n     \n              ...,\n     \n              [[1.1677e-07]],\n     \n              [[1.0006e-07]],\n     \n              [[4.6290e-07]]],\n     \n     \n             [[[4.0089e-08]],\n     \n              [[5.8407e-08]],\n     \n              [[3.3723e-08]],\n     \n              ...,\n     \n              [[4.4032e-08]],\n     \n              [[4.4977e-08]],\n     \n              [[4.7896e-08]]],\n     \n     \n             [[[2.3291e-07]],\n     \n              [[1.6112e-07]],\n     \n              [[7.1567e-08]],\n     \n              ...,\n     \n              [[2.0859e-07]],\n     \n              [[1.6313e-07]],\n     \n              [[7.0006e-07]]]])},\n    112: {'exp_avg': tensor([[[[ 8.0511e-05]],\n     \n              [[ 8.1952e-05]],\n     \n              [[ 7.8917e-05]],\n     \n              ...,\n     \n              [[ 2.7538e-04]],\n     \n              [[ 9.1112e-06]],\n     \n              [[-6.5377e-05]]],\n     \n     \n             [[[ 2.1899e-04]],\n     \n              [[ 2.0864e-04]],\n     \n              [[ 1.4012e-04]],\n     \n              ...,\n     \n              [[ 1.9062e-04]],\n     \n              [[ 2.6186e-04]],\n     \n              [[-3.9921e-04]]],\n     \n     \n             [[[ 3.6149e-05]],\n     \n              [[-5.0080e-05]],\n     \n              [[ 2.3771e-05]],\n     \n              ...,\n     \n              [[-3.1791e-04]],\n     \n              [[ 6.9632e-06]],\n     \n              [[-3.5049e-04]]],\n     \n     \n             ...,\n     \n     \n             [[[-1.1965e-04]],\n     \n              [[ 6.9826e-05]],\n     \n              [[ 9.7854e-06]],\n     \n              ...,\n     \n              [[-2.2087e-05]],\n     \n              [[ 3.6705e-04]],\n     \n              [[ 5.5366e-04]]],\n     \n     \n             [[[-1.6725e-05]],\n     \n              [[-7.5917e-05]],\n     \n              [[-2.2592e-05]],\n     \n              ...,\n     \n              [[-2.6073e-04]],\n     \n              [[-6.0169e-05]],\n     \n              [[-1.3891e-04]]],\n     \n     \n             [[[ 2.5217e-05]],\n     \n              [[-2.3044e-05]],\n     \n              [[-1.2245e-04]],\n     \n              ...,\n     \n              [[-4.3258e-04]],\n     \n              [[-2.3122e-04]],\n     \n              [[ 1.6034e-05]]]]),\n     'exp_avg_sq': tensor([[[[6.0739e-08]],\n     \n              [[7.0140e-08]],\n     \n              [[1.6217e-08]],\n     \n              ...,\n     \n              [[8.4852e-08]],\n     \n              [[2.3850e-08]],\n     \n              [[5.7894e-08]]],\n     \n     \n             [[[2.8943e-07]],\n     \n              [[2.2737e-07]],\n     \n              [[1.3380e-07]],\n     \n              ...,\n     \n              [[3.6861e-07]],\n     \n              [[3.7117e-07]],\n     \n              [[3.4697e-07]]],\n     \n     \n             [[[1.4424e-07]],\n     \n              [[3.7485e-08]],\n     \n              [[8.0754e-08]],\n     \n              ...,\n     \n              [[2.1656e-07]],\n     \n              [[8.9466e-08]],\n     \n              [[2.0006e-07]]],\n     \n     \n             ...,\n     \n     \n             [[[5.6675e-07]],\n     \n              [[1.1942e-07]],\n     \n              [[2.8825e-07]],\n     \n              ...,\n     \n              [[5.1327e-07]],\n     \n              [[4.6648e-07]],\n     \n              [[7.7102e-07]]],\n     \n     \n             [[[1.2729e-07]],\n     \n              [[3.1577e-08]],\n     \n              [[4.6547e-08]],\n     \n              ...,\n     \n              [[7.3818e-08]],\n     \n              [[1.0685e-07]],\n     \n              [[1.1414e-07]]],\n     \n     \n             [[[2.6377e-07]],\n     \n              [[5.9665e-08]],\n     \n              [[1.2687e-07]],\n     \n              ...,\n     \n              [[3.0479e-07]],\n     \n              [[1.8212e-07]],\n     \n              [[3.5012e-07]]]])},\n    113: {'exp_avg': tensor([[[[ 7.2424e-05]],\n     \n              [[ 1.0583e-04]],\n     \n              [[ 7.0931e-06]],\n     \n              ...,\n     \n              [[-5.0452e-05]],\n     \n              [[-6.8171e-05]],\n     \n              [[-1.4321e-04]]],\n     \n     \n             [[[-1.4804e-05]],\n     \n              [[-2.2949e-04]],\n     \n              [[-4.1180e-04]],\n     \n              ...,\n     \n              [[-1.7479e-04]],\n     \n              [[ 8.9076e-05]],\n     \n              [[-3.8330e-05]]],\n     \n     \n             [[[ 6.6188e-06]],\n     \n              [[ 7.4582e-05]],\n     \n              [[ 3.5609e-04]],\n     \n              ...,\n     \n              [[-4.5881e-05]],\n     \n              [[ 5.8987e-05]],\n     \n              [[-4.3348e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-1.4077e-04]],\n     \n              [[-5.6183e-05]],\n     \n              [[-7.2678e-05]],\n     \n              ...,\n     \n              [[ 3.3437e-05]],\n     \n              [[-1.4144e-04]],\n     \n              [[ 1.0724e-04]]],\n     \n     \n             [[[-5.2607e-05]],\n     \n              [[ 4.9766e-05]],\n     \n              [[-1.6721e-04]],\n     \n              ...,\n     \n              [[ 1.1405e-04]],\n     \n              [[-1.9601e-04]],\n     \n              [[-1.1132e-04]]],\n     \n     \n             [[[ 1.8310e-05]],\n     \n              [[ 7.8189e-05]],\n     \n              [[ 2.5604e-04]],\n     \n              ...,\n     \n              [[ 5.3311e-05]],\n     \n              [[ 1.7744e-06]],\n     \n              [[ 3.7754e-06]]]]),\n     'exp_avg_sq': tensor([[[[1.2805e-08]],\n     \n              [[1.5532e-08]],\n     \n              [[8.3810e-08]],\n     \n              ...,\n     \n              [[2.4038e-08]],\n     \n              [[1.1600e-08]],\n     \n              [[2.6880e-08]]],\n     \n     \n             [[[7.7524e-09]],\n     \n              [[3.3759e-08]],\n     \n              [[1.7962e-07]],\n     \n              ...,\n     \n              [[9.8519e-08]],\n     \n              [[3.9872e-08]],\n     \n              [[1.0130e-07]]],\n     \n     \n             [[[5.5669e-09]],\n     \n              [[1.4910e-08]],\n     \n              [[1.1811e-07]],\n     \n              ...,\n     \n              [[4.8691e-08]],\n     \n              [[2.1480e-08]],\n     \n              [[5.9820e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[2.4352e-07]],\n     \n              [[1.0128e-07]],\n     \n              [[1.1200e-06]],\n     \n              ...,\n     \n              [[2.5890e-07]],\n     \n              [[1.1473e-07]],\n     \n              [[1.9392e-07]]],\n     \n     \n             [[[4.6095e-09]],\n     \n              [[2.4932e-08]],\n     \n              [[1.5012e-07]],\n     \n              ...,\n     \n              [[6.0418e-08]],\n     \n              [[2.9203e-08]],\n     \n              [[5.8700e-08]]],\n     \n     \n             [[[2.7228e-09]],\n     \n              [[2.3105e-08]],\n     \n              [[1.7121e-07]],\n     \n              ...,\n     \n              [[7.8071e-08]],\n     \n              [[2.0309e-08]],\n     \n              [[6.0109e-08]]]])},\n    114: {'exp_avg': tensor([[[[-7.6374e-05, -8.7465e-05, -1.3511e-04],\n               [ 4.0405e-05, -6.0332e-05,  6.8125e-05],\n               [ 1.0928e-05, -2.1826e-05,  1.9472e-05]],\n     \n              [[ 1.3353e-04,  1.3085e-04, -3.5039e-05],\n               [-2.9288e-05, -1.2480e-05,  1.1938e-05],\n               [-8.6945e-05, -3.9924e-05, -1.8475e-04]],\n     \n              [[ 6.5346e-06,  6.8473e-05,  3.0853e-05],\n               [ 1.5260e-05,  1.1220e-04,  1.1161e-04],\n               [-1.1200e-04, -2.1717e-05,  9.8958e-05]],\n     \n              ...,\n     \n              [[ 7.6562e-05, -6.7227e-05, -4.0063e-05],\n               [ 8.8672e-05, -1.5163e-05,  1.5901e-05],\n               [ 6.9918e-05, -1.9571e-05, -9.9037e-06]],\n     \n              [[-2.3884e-04,  1.7049e-05,  1.3710e-04],\n               [-1.0255e-04, -9.9311e-05, -3.8369e-05],\n               [-3.3684e-06, -3.1160e-05,  5.1492e-06]],\n     \n              [[-4.4960e-05, -4.9503e-05, -9.4273e-05],\n               [ 7.2201e-05, -1.1262e-04, -1.1162e-04],\n               [ 9.9052e-05,  7.6065e-05,  6.3084e-05]]],\n     \n     \n             [[[ 2.4434e-04,  7.5913e-05, -6.0794e-05],\n               [ 3.1469e-04,  1.3244e-04,  1.2538e-04],\n               [ 3.6136e-04,  2.2454e-04,  1.4837e-04]],\n     \n              [[ 1.3617e-04,  3.0518e-05,  1.4134e-04],\n               [ 1.2263e-04, -1.8361e-05,  4.6285e-05],\n               [ 4.0631e-05, -8.1325e-05,  9.9288e-05]],\n     \n              [[-1.5667e-04, -7.1388e-05,  1.4321e-04],\n               [ 1.4151e-04, -2.8390e-05,  2.0011e-04],\n               [-1.5219e-05, -1.3892e-04, -2.3712e-05]],\n     \n              ...,\n     \n              [[ 1.9270e-04,  3.3302e-05, -1.7922e-05],\n               [ 2.1729e-04,  1.7571e-04,  1.1225e-04],\n               [ 1.8318e-04,  1.1609e-04,  4.8773e-06]],\n     \n              [[-2.3410e-04,  4.6061e-05,  3.2202e-04],\n               [-1.2543e-04, -1.0473e-04, -7.0541e-05],\n               [-5.3340e-05, -1.1803e-04, -4.9926e-05]],\n     \n              [[-8.4863e-05,  1.3087e-04,  2.0714e-04],\n               [-5.5714e-05,  1.6324e-04,  1.1437e-04],\n               [ 1.0385e-04,  1.4372e-04, -3.5480e-06]]],\n     \n     \n             [[[-4.0220e-05, -3.5056e-06,  4.0829e-05],\n               [ 2.1561e-05,  5.5091e-05,  7.2562e-05],\n               [ 1.4485e-05, -8.8853e-07,  9.6597e-05]],\n     \n              [[-2.4504e-05,  4.3466e-05, -6.3825e-05],\n               [ 7.5243e-05,  1.0468e-04,  2.2082e-05],\n               [ 1.6318e-04,  3.9788e-05,  2.5283e-05]],\n     \n              [[ 9.6718e-05, -2.0744e-05, -1.1998e-04],\n               [ 9.3761e-06,  1.8367e-05, -6.3748e-05],\n               [ 2.6815e-05,  8.8936e-05,  3.0647e-06]],\n     \n              ...,\n     \n              [[-1.7838e-05,  9.4872e-05,  1.2210e-04],\n               [ 7.7314e-05,  7.0555e-05,  8.3910e-05],\n               [ 1.2838e-04,  1.2998e-04,  1.0723e-04]],\n     \n              [[-9.1360e-05, -9.8973e-05, -1.3731e-04],\n               [-1.3471e-04, -1.1485e-04, -1.4655e-04],\n               [-1.9830e-04, -7.8077e-06, -1.7863e-04]],\n     \n              [[ 7.9054e-05,  1.7408e-04, -3.2859e-05],\n               [ 9.7459e-05,  1.3731e-04, -1.2718e-04],\n               [ 7.4627e-05,  2.8493e-05, -1.1172e-04]]],\n     \n     \n             ...,\n     \n     \n             [[[-1.0979e-04, -5.7507e-05, -1.0425e-04],\n               [-9.2670e-05, -1.0681e-04, -5.3825e-05],\n               [-1.0115e-04, -2.0308e-04, -1.0319e-04]],\n     \n              [[ 1.1657e-04,  1.7254e-04,  1.4530e-04],\n               [ 5.2354e-05,  1.2355e-04,  9.2835e-05],\n               [-7.1165e-06,  7.8989e-05,  3.5147e-06]],\n     \n              [[-8.6376e-07, -2.5029e-05,  1.4834e-04],\n               [ 2.1949e-06, -1.0070e-04,  1.7379e-04],\n               [-1.4352e-05, -1.0200e-04,  1.3705e-04]],\n     \n              ...,\n     \n              [[ 2.7194e-05, -6.8543e-05, -1.2168e-04],\n               [ 6.3188e-05, -6.1292e-06, -2.2870e-05],\n               [ 1.7356e-06,  6.3127e-06, -1.2978e-04]],\n     \n              [[-1.5477e-04, -1.2936e-04,  1.1724e-04],\n               [-1.9234e-04, -1.2700e-04, -4.8108e-06],\n               [-1.6055e-04, -1.5149e-04, -1.7820e-04]],\n     \n              [[-4.7467e-05,  4.1456e-05,  1.8494e-05],\n               [-7.6614e-05,  2.3095e-05, -3.7353e-05],\n               [-2.4155e-05,  3.4454e-05, -6.0675e-05]]],\n     \n     \n             [[[ 1.3951e-05, -1.0043e-04, -8.4998e-05],\n               [ 1.2982e-04, -4.2892e-05, -7.1911e-05],\n               [ 1.3856e-04, -4.3275e-05, -4.7065e-05]],\n     \n              [[-6.8943e-05,  1.1426e-05, -2.0577e-04],\n               [ 3.5383e-05,  1.1200e-05, -2.9564e-05],\n               [ 4.4090e-05,  3.7664e-05,  4.1815e-05]],\n     \n              [[-3.1771e-05, -5.7291e-05, -2.8811e-05],\n               [-1.4667e-05,  3.4300e-05, -1.2564e-05],\n               [ 1.1703e-04,  1.1366e-04, -2.1320e-05]],\n     \n              ...,\n     \n              [[ 1.2173e-05, -1.3280e-04, -1.9283e-04],\n               [ 3.9473e-05, -2.0823e-04, -1.7909e-04],\n               [ 6.3496e-05, -9.7229e-05, -3.7363e-05]],\n     \n              [[ 5.1856e-05,  1.3791e-05, -1.2310e-05],\n               [ 9.1412e-05,  4.0901e-05,  8.8130e-05],\n               [ 1.0823e-04,  1.0111e-04,  4.7439e-05]],\n     \n              [[ 9.9067e-06,  1.9864e-05,  4.3655e-05],\n               [-4.4263e-06,  2.7812e-05,  5.3990e-05],\n               [ 1.8797e-05, -1.4878e-05,  4.2291e-05]]],\n     \n     \n             [[[ 9.3337e-05,  1.6024e-05, -2.7107e-05],\n               [-3.1315e-05,  6.3289e-06, -2.8026e-05],\n               [-6.7285e-06,  1.1117e-05, -9.4026e-05]],\n     \n              [[ 5.0249e-05, -8.8536e-05, -1.4132e-04],\n               [-5.2019e-05, -3.3445e-05, -1.5299e-04],\n               [-1.5414e-04, -1.4638e-04, -1.5719e-04]],\n     \n              [[ 3.5590e-05, -1.8609e-04, -2.6541e-04],\n               [-4.5142e-05, -4.8219e-05, -1.5925e-04],\n               [ 4.1188e-05,  1.3689e-05, -4.2881e-05]],\n     \n              ...,\n     \n              [[-5.8778e-05, -1.9454e-05, -1.1763e-04],\n               [-3.0557e-05,  6.8028e-05,  2.2614e-05],\n               [ 3.8011e-05,  1.4430e-05, -2.0077e-06]],\n     \n              [[ 2.2766e-04,  2.6461e-04,  1.0010e-04],\n               [-6.1215e-05, -6.1849e-06, -1.3727e-04],\n               [ 1.3067e-04,  8.4108e-05, -5.5580e-05]],\n     \n              [[ 4.4969e-05, -1.1757e-05, -6.0094e-05],\n               [ 1.3233e-04, -3.6607e-07, -4.9492e-05],\n               [ 1.6388e-04,  6.0573e-05,  4.3009e-05]]]]),\n     'exp_avg_sq': tensor([[[[3.0403e-08, 3.0057e-08, 3.0827e-08],\n               [3.1817e-08, 2.8483e-08, 2.5990e-08],\n               [2.5202e-08, 2.2970e-08, 2.0995e-08]],\n     \n              [[4.4268e-08, 5.1229e-08, 4.2515e-08],\n               [4.2626e-08, 5.3564e-08, 4.3064e-08],\n               [4.5238e-08, 4.4252e-08, 5.1729e-08]],\n     \n              [[4.8643e-08, 3.7221e-08, 4.1295e-08],\n               [3.8435e-08, 3.4630e-08, 5.6525e-08],\n               [4.2828e-08, 4.1509e-08, 3.9249e-08]],\n     \n              ...,\n     \n              [[3.3400e-08, 3.1414e-08, 2.8131e-08],\n               [3.2455e-08, 3.0441e-08, 2.7898e-08],\n               [2.8923e-08, 2.7999e-08, 2.2340e-08]],\n     \n              [[8.9234e-08, 8.5904e-08, 7.4114e-08],\n               [8.7471e-08, 9.7349e-08, 6.4211e-08],\n               [7.3549e-08, 7.6206e-08, 6.5273e-08]],\n     \n              [[6.6888e-08, 5.7440e-08, 5.5879e-08],\n               [6.2315e-08, 6.2498e-08, 7.1852e-08],\n               [5.9405e-08, 6.9856e-08, 7.2104e-08]]],\n     \n     \n             [[[2.9251e-08, 2.5046e-08, 2.4931e-08],\n               [3.0518e-08, 2.7256e-08, 2.3897e-08],\n               [2.7889e-08, 2.2024e-08, 1.9697e-08]],\n     \n              [[4.1947e-08, 4.0674e-08, 3.7084e-08],\n               [4.1721e-08, 3.9536e-08, 4.0761e-08],\n               [3.9109e-08, 3.9940e-08, 4.2536e-08]],\n     \n              [[4.8906e-08, 4.6140e-08, 3.7472e-08],\n               [3.9984e-08, 4.0125e-08, 3.6581e-08],\n               [4.0031e-08, 4.1919e-08, 3.1273e-08]],\n     \n              ...,\n     \n              [[2.3531e-08, 2.3023e-08, 2.1451e-08],\n               [2.1781e-08, 2.4997e-08, 2.1086e-08],\n               [2.0789e-08, 1.8803e-08, 1.8119e-08]],\n     \n              [[5.3356e-08, 5.8678e-08, 6.5283e-08],\n               [5.3953e-08, 6.4726e-08, 5.5309e-08],\n               [6.8698e-08, 5.8308e-08, 5.7802e-08]],\n     \n              [[3.6110e-08, 3.6116e-08, 4.7978e-08],\n               [3.8093e-08, 5.7064e-08, 4.9578e-08],\n               [5.1901e-08, 6.2471e-08, 4.8036e-08]]],\n     \n     \n             [[[2.5077e-08, 3.0203e-08, 3.1393e-08],\n               [1.9489e-08, 2.5614e-08, 2.4403e-08],\n               [1.5987e-08, 1.5605e-08, 1.5285e-08]],\n     \n              [[3.9439e-08, 3.9415e-08, 3.6480e-08],\n               [4.5440e-08, 3.5261e-08, 3.3280e-08],\n               [6.2365e-08, 4.2624e-08, 4.0556e-08]],\n     \n              [[3.3907e-08, 3.4362e-08, 2.8178e-08],\n               [2.7531e-08, 3.1106e-08, 3.5043e-08],\n               [2.6560e-08, 2.7275e-08, 3.1272e-08]],\n     \n              ...,\n     \n              [[1.8814e-08, 1.9971e-08, 2.2531e-08],\n               [1.5712e-08, 1.7356e-08, 1.6609e-08],\n               [1.5029e-08, 1.4255e-08, 1.2694e-08]],\n     \n              [[7.4651e-08, 7.1519e-08, 6.1608e-08],\n               [6.0234e-08, 6.8164e-08, 6.8566e-08],\n               [6.5583e-08, 5.7503e-08, 5.1757e-08]],\n     \n              [[5.1627e-08, 6.0634e-08, 4.3078e-08],\n               [4.7183e-08, 6.3378e-08, 4.4965e-08],\n               [5.3265e-08, 5.1051e-08, 4.7752e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[2.5284e-08, 2.3805e-08, 2.2446e-08],\n               [3.0818e-08, 2.6720e-08, 2.7993e-08],\n               [3.0941e-08, 2.7109e-08, 2.4699e-08]],\n     \n              [[3.7463e-08, 5.5231e-08, 4.7009e-08],\n               [3.9126e-08, 4.9636e-08, 4.8055e-08],\n               [4.4419e-08, 5.6580e-08, 5.4375e-08]],\n     \n              [[3.9069e-08, 2.5624e-08, 3.0453e-08],\n               [3.4382e-08, 3.0819e-08, 4.3145e-08],\n               [3.1575e-08, 2.4953e-08, 3.6123e-08]],\n     \n              ...,\n     \n              [[3.0689e-08, 3.0059e-08, 2.7151e-08],\n               [3.8528e-08, 4.4611e-08, 3.5884e-08],\n               [3.1359e-08, 4.0272e-08, 3.6301e-08]],\n     \n              [[8.4821e-08, 7.2002e-08, 8.4948e-08],\n               [7.9683e-08, 8.2963e-08, 8.2817e-08],\n               [7.9066e-08, 7.4463e-08, 8.7675e-08]],\n     \n              [[5.8012e-08, 4.5555e-08, 4.1574e-08],\n               [6.0282e-08, 5.3873e-08, 5.4561e-08],\n               [5.4543e-08, 5.2672e-08, 6.0873e-08]]],\n     \n     \n             [[[2.4951e-08, 2.3206e-08, 2.1403e-08],\n               [3.4618e-08, 2.8130e-08, 2.8107e-08],\n               [3.3064e-08, 2.6890e-08, 2.3573e-08]],\n     \n              [[1.5036e-08, 1.4578e-08, 1.6706e-08],\n               [1.2926e-08, 1.3494e-08, 1.0748e-08],\n               [1.2012e-08, 1.1237e-08, 1.1179e-08]],\n     \n              [[2.1515e-08, 1.1876e-08, 7.9357e-09],\n               [2.3865e-08, 1.1853e-08, 8.8111e-09],\n               [2.3336e-08, 1.4081e-08, 1.0309e-08]],\n     \n              ...,\n     \n              [[5.6027e-08, 4.9476e-08, 4.2018e-08],\n               [8.4967e-08, 8.1037e-08, 6.3607e-08],\n               [8.2847e-08, 8.0963e-08, 5.9127e-08]],\n     \n              [[2.7734e-08, 1.6119e-08, 3.3372e-08],\n               [1.7014e-08, 9.3309e-09, 2.6690e-08],\n               [2.3246e-08, 1.6508e-08, 3.0988e-08]],\n     \n              [[1.2931e-08, 6.0430e-09, 8.2176e-09],\n               [8.4946e-09, 5.1769e-09, 9.6780e-09],\n               [5.7577e-09, 6.8497e-09, 1.6174e-08]]],\n     \n     \n             [[[1.4329e-08, 1.6795e-08, 1.8878e-08],\n               [1.2130e-08, 1.7386e-08, 1.9827e-08],\n               [6.7590e-09, 9.4836e-09, 1.3776e-08]],\n     \n              [[2.4459e-08, 2.0016e-08, 2.4377e-08],\n               [2.9038e-08, 2.4340e-08, 2.4295e-08],\n               [3.3711e-08, 2.4299e-08, 2.6325e-08]],\n     \n              [[2.8352e-08, 2.6124e-08, 2.3895e-08],\n               [2.2727e-08, 2.5195e-08, 2.8617e-08],\n               [2.0783e-08, 2.2454e-08, 2.9980e-08]],\n     \n              ...,\n     \n              [[1.0237e-08, 1.8837e-08, 1.9564e-08],\n               [6.0815e-09, 1.6399e-08, 2.0083e-08],\n               [3.4945e-09, 1.2806e-08, 1.8493e-08]],\n     \n              [[4.4011e-08, 3.6181e-08, 4.4434e-08],\n               [4.5854e-08, 3.1568e-08, 3.0428e-08],\n               [4.1252e-08, 4.1563e-08, 3.5476e-08]],\n     \n              [[3.1442e-08, 3.2089e-08, 2.7077e-08],\n               [3.0947e-08, 2.2818e-08, 2.8525e-08],\n               [3.7170e-08, 3.0302e-08, 2.5119e-08]]]])},\n    115: {'exp_avg': tensor([[[[ 1.8579e-04]],\n     \n              [[-2.2875e-04]],\n     \n              [[ 4.0351e-04]],\n     \n              ...,\n     \n              [[-1.5580e-04]],\n     \n              [[-1.3884e-04]],\n     \n              [[ 1.3574e-05]]],\n     \n     \n             [[[ 1.3537e-04]],\n     \n              [[ 3.0562e-04]],\n     \n              [[ 1.7239e-05]],\n     \n              ...,\n     \n              [[-5.2066e-06]],\n     \n              [[ 1.5750e-04]],\n     \n              [[ 1.8546e-04]]],\n     \n     \n             [[[ 3.7969e-05]],\n     \n              [[-7.8660e-05]],\n     \n              [[ 6.8629e-06]],\n     \n              ...,\n     \n              [[-5.9454e-05]],\n     \n              [[ 3.4177e-05]],\n     \n              [[-3.2020e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 4.6601e-05]],\n     \n              [[ 2.2910e-04]],\n     \n              [[-1.4283e-04]],\n     \n              ...,\n     \n              [[-9.5899e-06]],\n     \n              [[ 1.0829e-04]],\n     \n              [[ 1.6614e-04]]],\n     \n     \n             [[[-1.9163e-04]],\n     \n              [[-2.3080e-04]],\n     \n              [[ 1.3279e-04]],\n     \n              ...,\n     \n              [[ 3.2031e-04]],\n     \n              [[ 1.4511e-04]],\n     \n              [[ 9.9202e-05]]],\n     \n     \n             [[[ 1.7330e-05]],\n     \n              [[-2.4740e-04]],\n     \n              [[-1.6573e-04]],\n     \n              ...,\n     \n              [[-1.2294e-04]],\n     \n              [[ 2.9967e-05]],\n     \n              [[-1.5292e-04]]]]),\n     'exp_avg_sq': tensor([[[[1.6383e-07]],\n     \n              [[1.3796e-07]],\n     \n              [[1.8979e-07]],\n     \n              ...,\n     \n              [[2.2155e-07]],\n     \n              [[2.0341e-07]],\n     \n              [[1.0930e-07]]],\n     \n     \n             [[[5.9948e-08]],\n     \n              [[7.0543e-08]],\n     \n              [[5.3067e-08]],\n     \n              ...,\n     \n              [[7.7941e-08]],\n     \n              [[8.6147e-08]],\n     \n              [[5.9340e-08]]],\n     \n     \n             [[[2.5149e-08]],\n     \n              [[1.9109e-08]],\n     \n              [[1.7532e-08]],\n     \n              ...,\n     \n              [[1.7046e-08]],\n     \n              [[2.2745e-08]],\n     \n              [[1.0973e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[2.3984e-08]],\n     \n              [[2.1442e-08]],\n     \n              [[2.1626e-08]],\n     \n              ...,\n     \n              [[1.7250e-08]],\n     \n              [[8.6303e-09]],\n     \n              [[1.4472e-08]]],\n     \n     \n             [[[1.0419e-07]],\n     \n              [[9.8303e-08]],\n     \n              [[1.0130e-07]],\n     \n              ...,\n     \n              [[8.8895e-08]],\n     \n              [[4.0657e-08]],\n     \n              [[5.9258e-08]]],\n     \n     \n             [[[1.1395e-07]],\n     \n              [[9.3948e-08]],\n     \n              [[1.0347e-07]],\n     \n              ...,\n     \n              [[8.0193e-08]],\n     \n              [[5.2219e-08]],\n     \n              [[5.7752e-08]]]])},\n    116: {'exp_avg': tensor([[[[-1.5167e-04]],\n     \n              [[ 5.0325e-05]],\n     \n              [[ 4.6954e-05]],\n     \n              ...,\n     \n              [[-1.2303e-04]],\n     \n              [[ 1.7387e-04]],\n     \n              [[-4.1616e-05]]],\n     \n     \n             [[[-1.1833e-04]],\n     \n              [[-1.5790e-04]],\n     \n              [[-1.5669e-04]],\n     \n              ...,\n     \n              [[-8.7146e-05]],\n     \n              [[ 1.4650e-04]],\n     \n              [[ 1.6975e-05]]],\n     \n     \n             [[[-8.0377e-05]],\n     \n              [[-1.0789e-04]],\n     \n              [[-1.7036e-04]],\n     \n              ...,\n     \n              [[ 1.2987e-04]],\n     \n              [[-5.8955e-05]],\n     \n              [[ 3.7943e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-1.0249e-05]],\n     \n              [[-9.5899e-05]],\n     \n              [[ 6.1505e-05]],\n     \n              ...,\n     \n              [[ 1.2891e-04]],\n     \n              [[ 1.2606e-04]],\n     \n              [[-9.8845e-05]]],\n     \n     \n             [[[-5.0791e-05]],\n     \n              [[ 1.9287e-04]],\n     \n              [[-1.8778e-04]],\n     \n              ...,\n     \n              [[ 1.2456e-04]],\n     \n              [[ 5.1164e-05]],\n     \n              [[ 1.0186e-05]]],\n     \n     \n             [[[ 1.2240e-04]],\n     \n              [[-6.7780e-05]],\n     \n              [[ 1.9636e-04]],\n     \n              ...,\n     \n              [[-1.2233e-04]],\n     \n              [[ 2.4353e-04]],\n     \n              [[ 1.3795e-05]]]]),\n     'exp_avg_sq': tensor([[[[1.8488e-08]],\n     \n              [[2.0308e-08]],\n     \n              [[6.3673e-08]],\n     \n              ...,\n     \n              [[4.5465e-08]],\n     \n              [[2.7898e-08]],\n     \n              [[3.5327e-08]]],\n     \n     \n             [[[2.6156e-08]],\n     \n              [[2.9547e-08]],\n     \n              [[5.3018e-08]],\n     \n              ...,\n     \n              [[3.6217e-08]],\n     \n              [[4.3781e-08]],\n     \n              [[4.4856e-08]]],\n     \n     \n             [[[2.8148e-08]],\n     \n              [[4.9964e-08]],\n     \n              [[8.3550e-08]],\n     \n              ...,\n     \n              [[7.6033e-08]],\n     \n              [[5.4544e-08]],\n     \n              [[9.1388e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[1.4273e-08]],\n     \n              [[2.1972e-08]],\n     \n              [[2.7283e-08]],\n     \n              ...,\n     \n              [[2.8036e-08]],\n     \n              [[2.9582e-08]],\n     \n              [[2.9550e-08]]],\n     \n     \n             [[[1.6090e-08]],\n     \n              [[2.3313e-08]],\n     \n              [[3.3505e-08]],\n     \n              ...,\n     \n              [[2.3654e-08]],\n     \n              [[2.3596e-08]],\n     \n              [[2.6759e-08]]],\n     \n     \n             [[[4.4031e-08]],\n     \n              [[2.8902e-08]],\n     \n              [[5.7077e-08]],\n     \n              ...,\n     \n              [[2.4340e-08]],\n     \n              [[4.3105e-08]],\n     \n              [[3.0677e-08]]]])},\n    117: {'exp_avg': tensor([[[[-2.3005e-04, -2.5237e-04, -1.1437e-04],\n               [-1.1322e-04, -2.0352e-04, -4.9224e-05],\n               [-2.1366e-04, -2.6212e-04, -6.0364e-05]],\n     \n              [[-1.0143e-04,  2.5138e-05,  2.3381e-05],\n               [-4.4169e-05, -2.8983e-06, -1.1113e-04],\n               [-1.1086e-04,  2.3267e-05,  4.1715e-05]],\n     \n              [[-1.4485e-04, -2.1350e-04, -1.0899e-04],\n               [-1.2770e-04, -2.6513e-04, -5.8810e-05],\n               [-2.2627e-04, -1.7518e-04, -4.4253e-05]],\n     \n              ...,\n     \n              [[-8.9607e-07,  2.1481e-05, -6.7525e-05],\n               [ 1.2366e-04, -3.7663e-05,  1.4982e-04],\n               [ 1.1189e-04, -4.6319e-05,  6.0187e-05]],\n     \n              [[ 7.8965e-05, -2.6842e-05,  4.9353e-05],\n               [ 2.8266e-05, -8.7899e-05, -7.8738e-05],\n               [-5.4040e-06,  8.7431e-05,  3.5921e-05]],\n     \n              [[-9.7460e-05, -7.0474e-05, -6.0117e-05],\n               [-9.2168e-06,  1.4207e-04, -1.9755e-05],\n               [ 1.4666e-04,  1.0411e-04,  6.4157e-05]]],\n     \n     \n             [[[-1.0697e-04, -1.2866e-04, -4.0049e-07],\n               [ 1.6495e-05, -2.6331e-06, -4.6703e-05],\n               [ 5.0887e-05, -6.9438e-05, -8.0347e-05]],\n     \n              [[ 4.0645e-05, -5.0788e-05, -4.3218e-05],\n               [ 3.6977e-04,  1.2694e-04,  1.2759e-04],\n               [ 4.1095e-04,  1.0938e-04, -2.6164e-04]],\n     \n              [[ 2.9902e-04, -1.2186e-05, -1.1810e-04],\n               [ 1.2084e-04, -1.8719e-04, -5.5360e-05],\n               [ 1.5286e-04, -4.2674e-05, -1.1774e-04]],\n     \n              ...,\n     \n              [[-1.4379e-04,  2.6107e-05, -1.5278e-04],\n               [-7.5022e-05, -2.0673e-04, -3.8619e-04],\n               [ 1.0209e-04, -1.6385e-04, -1.9060e-04]],\n     \n              [[ 2.6973e-05, -2.1546e-04, -1.0013e-05],\n               [ 1.5119e-04, -1.4396e-04, -5.3914e-05],\n               [ 2.7440e-04,  1.6478e-05,  5.1669e-06]],\n     \n              [[-2.9476e-04, -3.9463e-04,  8.4524e-05],\n               [-8.4448e-05, -2.1908e-04,  7.6095e-04],\n               [ 1.9002e-06,  8.5546e-05,  1.0506e-03]]],\n     \n     \n             [[[ 2.7656e-05,  1.6106e-05,  4.6541e-05],\n               [ 2.7132e-06,  4.2186e-05,  6.2246e-05],\n               [-5.2120e-05, -6.1533e-05,  4.4965e-05]],\n     \n              [[ 4.4914e-05, -1.8075e-04, -1.7529e-04],\n               [-7.6977e-06, -4.6876e-05, -8.6722e-05],\n               [-4.9030e-05, -1.8566e-04, -1.7394e-04]],\n     \n              [[ 7.4566e-05, -1.2588e-06, -1.0431e-05],\n               [ 2.2536e-04,  2.4291e-04,  2.6185e-04],\n               [ 8.8518e-05,  1.4002e-04,  1.7972e-04]],\n     \n              ...,\n     \n              [[ 1.2405e-04, -1.1586e-04,  1.5696e-05],\n               [ 1.0882e-04, -5.0835e-05,  6.6633e-05],\n               [ 4.6308e-05, -2.4457e-05,  1.7884e-05]],\n     \n              [[ 1.5211e-05,  1.9276e-05, -5.4697e-05],\n               [ 1.3213e-04,  1.2329e-04,  1.6510e-04],\n               [ 5.0759e-05, -1.4814e-05,  2.1504e-04]],\n     \n              [[-4.3347e-05,  1.7801e-05, -2.4703e-04],\n               [-1.9656e-05,  7.0627e-05, -1.5206e-04],\n               [-2.5688e-05, -3.2044e-05, -2.7920e-04]]],\n     \n     \n             ...,\n     \n     \n             [[[ 9.6481e-05,  1.6624e-04,  8.3704e-05],\n               [ 6.0585e-05,  6.4813e-05,  8.5728e-05],\n               [ 3.6450e-05,  1.5127e-04,  1.8121e-04]],\n     \n              [[-3.8792e-05, -1.1470e-05,  3.5875e-08],\n               [ 2.0129e-05,  1.6769e-05, -2.6795e-05],\n               [ 2.8399e-05,  6.2144e-05,  7.5072e-05]],\n     \n              [[ 2.9946e-04,  2.3872e-04,  8.5991e-05],\n               [ 2.2289e-04,  1.3451e-04,  9.5176e-05],\n               [ 6.8362e-05, -1.9258e-05,  1.6259e-04]],\n     \n              ...,\n     \n              [[-2.1309e-05, -6.9031e-06, -9.0852e-05],\n               [ 5.3634e-05,  6.1781e-05,  4.0805e-05],\n               [-9.1821e-05, -7.8810e-05, -2.1758e-04]],\n     \n              [[-5.8165e-05,  4.9998e-05,  1.4056e-04],\n               [ 6.5172e-05,  1.2013e-04,  1.9347e-04],\n               [ 8.3021e-05,  5.5154e-05,  1.2763e-04]],\n     \n              [[-9.5079e-05, -9.2042e-05, -3.7230e-05],\n               [-4.0062e-05, -2.4898e-05,  3.6158e-05],\n               [-2.4971e-06, -7.8812e-05, -1.9964e-05]]],\n     \n     \n             [[[ 1.0956e-04,  4.0234e-05, -2.0724e-04],\n               [ 1.0788e-04,  8.6835e-05, -6.4279e-05],\n               [-1.1491e-04,  4.2286e-05,  1.2536e-05]],\n     \n              [[-3.3844e-05, -1.7565e-05,  1.4484e-04],\n               [-1.0645e-04,  8.0688e-05,  1.3583e-04],\n               [-8.3533e-05, -1.1286e-04,  7.0541e-05]],\n     \n              [[ 1.7220e-04,  5.0355e-05,  8.8888e-05],\n               [ 1.7823e-04,  5.3102e-07,  9.4001e-05],\n               [-1.3064e-04, -1.3082e-04, -1.8008e-04]],\n     \n              ...,\n     \n              [[ 1.0973e-04,  3.6871e-05, -7.9901e-05],\n               [ 7.3078e-05,  5.8564e-05,  2.6687e-05],\n               [ 1.3692e-04, -3.9901e-05, -5.0103e-05]],\n     \n              [[ 4.8945e-05,  8.2135e-05, -8.9804e-05],\n               [ 9.4558e-05,  8.0013e-05,  8.9953e-05],\n               [-5.6184e-05, -1.2828e-04,  1.4593e-04]],\n     \n              [[ 2.1022e-04,  1.9548e-04, -3.9733e-04],\n               [ 2.0851e-04,  2.9669e-04, -5.4561e-04],\n               [ 3.4062e-04,  3.5381e-04, -5.0244e-04]]],\n     \n     \n             [[[ 7.8828e-05, -4.2547e-05, -9.5590e-05],\n               [-1.7447e-04, -1.4177e-04, -1.4192e-04],\n               [-5.6069e-05, -8.6621e-05, -3.0979e-05]],\n     \n              [[ 4.0400e-05, -5.0203e-05,  1.7536e-05],\n               [-4.7011e-06, -9.3060e-07,  7.0504e-05],\n               [ 3.9875e-05,  1.5289e-05,  1.5930e-05]],\n     \n              [[-1.6583e-05,  1.1868e-04, -1.2155e-04],\n               [-6.3505e-05,  2.5603e-06, -2.5131e-04],\n               [-1.5137e-04, -1.5912e-04, -1.2202e-04]],\n     \n              ...,\n     \n              [[-1.3374e-04, -5.2540e-05,  7.0826e-05],\n               [ 6.1416e-05,  3.0845e-04,  1.3051e-04],\n               [ 1.7703e-04,  2.0304e-04,  1.2650e-04]],\n     \n              [[ 1.6381e-04,  1.9090e-04,  2.0732e-05],\n               [ 1.4362e-04,  5.2305e-05, -6.7338e-06],\n               [ 9.0242e-06, -8.5536e-06,  3.3809e-05]],\n     \n              [[-1.0271e-04, -1.0512e-04, -2.4736e-04],\n               [ 1.0827e-04,  1.0881e-04,  3.2701e-05],\n               [ 8.0066e-05,  5.6072e-05, -2.7393e-05]]]]),\n     'exp_avg_sq': tensor([[[[3.3446e-08, 4.2349e-08, 3.0766e-08],\n               [3.5192e-08, 5.2892e-08, 4.1257e-08],\n               [3.2601e-08, 4.1058e-08, 3.2767e-08]],\n     \n              [[2.8192e-08, 3.0549e-08, 2.7956e-08],\n               [2.8436e-08, 3.2362e-08, 2.5506e-08],\n               [2.9711e-08, 3.9231e-08, 2.9601e-08]],\n     \n              [[4.8674e-08, 6.1666e-08, 6.2308e-08],\n               [5.4680e-08, 5.8216e-08, 5.0120e-08],\n               [5.2955e-08, 4.0839e-08, 5.2645e-08]],\n     \n              ...,\n     \n              [[4.6221e-08, 4.9467e-08, 3.7833e-08],\n               [3.6971e-08, 3.7503e-08, 2.9980e-08],\n               [4.7056e-08, 5.0600e-08, 4.1728e-08]],\n     \n              [[3.5357e-08, 3.2241e-08, 3.5586e-08],\n               [2.8743e-08, 2.4241e-08, 3.0885e-08],\n               [2.9859e-08, 3.0496e-08, 3.3207e-08]],\n     \n              [[3.1194e-08, 3.4473e-08, 4.3964e-08],\n               [1.9968e-08, 2.5558e-08, 4.2602e-08],\n               [3.0962e-08, 2.9708e-08, 5.7667e-08]]],\n     \n     \n             [[[5.1553e-08, 4.2512e-08, 5.0361e-08],\n               [6.3729e-08, 5.9702e-08, 5.0559e-08],\n               [7.7127e-08, 4.8949e-08, 4.2234e-08]],\n     \n              [[5.6056e-08, 6.9911e-08, 5.2702e-08],\n               [5.3425e-08, 6.8396e-08, 5.7851e-08],\n               [5.7537e-08, 5.6790e-08, 4.1627e-08]],\n     \n              [[1.0545e-07, 9.2239e-08, 8.0355e-08],\n               [9.2191e-08, 1.1107e-07, 8.3867e-08],\n               [1.1823e-07, 1.0399e-07, 7.1671e-08]],\n     \n              ...,\n     \n              [[6.4693e-08, 5.9659e-08, 5.2433e-08],\n               [8.0147e-08, 5.8881e-08, 6.4987e-08],\n               [6.2373e-08, 8.4797e-08, 6.9945e-08]],\n     \n              [[5.6399e-08, 4.4552e-08, 5.4796e-08],\n               [6.2960e-08, 6.4934e-08, 5.0806e-08],\n               [5.9864e-08, 5.7762e-08, 4.5852e-08]],\n     \n              [[1.8511e-07, 3.3090e-07, 6.1423e-07],\n               [3.1359e-07, 5.2511e-07, 8.4573e-07],\n               [1.7679e-07, 3.0533e-07, 8.7451e-07]]],\n     \n     \n             [[[2.2379e-08, 1.9308e-08, 2.1780e-08],\n               [2.1295e-08, 2.3700e-08, 2.4193e-08],\n               [2.2711e-08, 2.5701e-08, 2.0750e-08]],\n     \n              [[2.0502e-08, 2.2488e-08, 1.7516e-08],\n               [1.7403e-08, 1.4596e-08, 1.6110e-08],\n               [1.6907e-08, 2.7712e-08, 2.7012e-08]],\n     \n              [[3.9159e-08, 3.4559e-08, 3.4305e-08],\n               [3.0479e-08, 3.3505e-08, 3.5474e-08],\n               [3.7491e-08, 3.6978e-08, 3.6075e-08]],\n     \n              ...,\n     \n              [[3.0669e-08, 2.6421e-08, 3.3470e-08],\n               [2.6786e-08, 3.2238e-08, 3.0547e-08],\n               [2.9219e-08, 3.1387e-08, 2.7719e-08]],\n     \n              [[2.5110e-08, 2.7085e-08, 2.4336e-08],\n               [2.5502e-08, 2.7210e-08, 2.6608e-08],\n               [1.9924e-08, 2.7782e-08, 2.9564e-08]],\n     \n              [[5.8778e-08, 8.8466e-08, 8.5466e-08],\n               [7.4554e-08, 1.1484e-07, 1.0940e-07],\n               [6.6796e-08, 9.1359e-08, 9.3542e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[2.6032e-08, 3.2769e-08, 2.8260e-08],\n               [2.8900e-08, 4.9363e-08, 2.9126e-08],\n               [2.5847e-08, 3.7307e-08, 2.8889e-08]],\n     \n              [[1.9645e-08, 1.5327e-08, 2.3229e-08],\n               [1.9398e-08, 1.6764e-08, 2.4202e-08],\n               [1.4252e-08, 1.8338e-08, 2.4016e-08]],\n     \n              [[4.5084e-08, 4.4093e-08, 3.3545e-08],\n               [4.7714e-08, 4.1278e-08, 3.9769e-08],\n               [4.6641e-08, 3.7173e-08, 3.6798e-08]],\n     \n              ...,\n     \n              [[3.3505e-08, 3.2595e-08, 2.9417e-08],\n               [3.0867e-08, 2.4840e-08, 2.6095e-08],\n               [3.6026e-08, 3.5944e-08, 3.4259e-08]],\n     \n              [[2.6200e-08, 2.1035e-08, 1.6619e-08],\n               [2.4423e-08, 1.0377e-08, 1.6940e-08],\n               [2.2569e-08, 1.6592e-08, 2.5332e-08]],\n     \n              [[9.3696e-09, 8.0938e-09, 1.6167e-08],\n               [5.8701e-09, 4.4769e-09, 7.4802e-09],\n               [1.2664e-08, 1.2333e-08, 1.6719e-08]]],\n     \n     \n             [[[3.5872e-08, 4.0144e-08, 3.4922e-08],\n               [4.1494e-08, 5.3877e-08, 3.3952e-08],\n               [3.5893e-08, 4.5036e-08, 4.3660e-08]],\n     \n              [[3.5440e-08, 4.1644e-08, 4.0490e-08],\n               [3.5379e-08, 3.5459e-08, 3.7151e-08],\n               [3.4053e-08, 3.1794e-08, 3.4422e-08]],\n     \n              [[4.5982e-08, 5.9322e-08, 6.0576e-08],\n               [6.0772e-08, 6.9356e-08, 6.8043e-08],\n               [5.3112e-08, 6.1930e-08, 6.2966e-08]],\n     \n              ...,\n     \n              [[5.2169e-08, 3.8479e-08, 3.6855e-08],\n               [4.1867e-08, 4.0298e-08, 4.0360e-08],\n               [4.6893e-08, 4.1862e-08, 3.8453e-08]],\n     \n              [[4.0842e-08, 3.5076e-08, 3.6758e-08],\n               [3.4903e-08, 3.7644e-08, 3.6995e-08],\n               [4.3258e-08, 4.0980e-08, 3.5775e-08]],\n     \n              [[9.6658e-08, 9.0076e-08, 3.1581e-07],\n               [9.3912e-08, 1.2369e-07, 5.3466e-07],\n               [9.9211e-08, 1.0878e-07, 6.1650e-07]]],\n     \n     \n             [[[3.1040e-08, 3.3805e-08, 2.8623e-08],\n               [3.1894e-08, 3.9172e-08, 3.4740e-08],\n               [3.1467e-08, 3.5445e-08, 3.6685e-08]],\n     \n              [[2.5040e-08, 2.6369e-08, 2.1454e-08],\n               [2.7117e-08, 3.0167e-08, 2.7047e-08],\n               [2.3174e-08, 2.6810e-08, 2.9793e-08]],\n     \n              [[6.5747e-08, 6.5147e-08, 5.8967e-08],\n               [5.6077e-08, 5.5662e-08, 5.2547e-08],\n               [4.4777e-08, 4.7677e-08, 4.5969e-08]],\n     \n              ...,\n     \n              [[3.4496e-08, 3.9807e-08, 3.4768e-08],\n               [3.1616e-08, 4.1371e-08, 3.8872e-08],\n               [4.0274e-08, 3.8388e-08, 3.2415e-08]],\n     \n              [[3.6553e-08, 3.2199e-08, 3.0670e-08],\n               [1.9128e-08, 1.4927e-08, 1.7489e-08],\n               [2.1761e-08, 3.0339e-08, 2.9513e-08]],\n     \n              [[4.4038e-08, 4.9573e-08, 5.0418e-08],\n               [3.1599e-08, 3.7145e-08, 3.7125e-08],\n               [4.2930e-08, 3.9287e-08, 4.0247e-08]]]])},\n    118: {'exp_avg': tensor([[[[-8.8736e-05]],\n     \n              [[-1.9358e-04]],\n     \n              [[-1.9828e-04]],\n     \n              ...,\n     \n              [[-2.0772e-06]],\n     \n              [[-1.5769e-04]],\n     \n              [[ 1.8833e-05]]],\n     \n     \n             [[[-2.4589e-05]],\n     \n              [[-1.8249e-04]],\n     \n              [[ 8.1838e-05]],\n     \n              ...,\n     \n              [[-1.1670e-04]],\n     \n              [[-2.5577e-04]],\n     \n              [[-2.3766e-04]]],\n     \n     \n             [[[-7.1487e-06]],\n     \n              [[ 1.9052e-04]],\n     \n              [[ 3.5151e-05]],\n     \n              ...,\n     \n              [[ 4.6771e-05]],\n     \n              [[ 6.0610e-05]],\n     \n              [[-2.4740e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 2.8748e-06]],\n     \n              [[ 2.4795e-06]],\n     \n              [[-4.5231e-06]],\n     \n              ...,\n     \n              [[-6.7552e-06]],\n     \n              [[ 1.3159e-06]],\n     \n              [[-7.2969e-06]]],\n     \n     \n             [[[ 2.5743e-05]],\n     \n              [[ 2.7900e-05]],\n     \n              [[ 8.0896e-05]],\n     \n              ...,\n     \n              [[-1.7181e-04]],\n     \n              [[-1.0035e-04]],\n     \n              [[-2.1130e-05]]],\n     \n     \n             [[[-1.0269e-05]],\n     \n              [[ 2.7960e-06]],\n     \n              [[ 3.6067e-06]],\n     \n              ...,\n     \n              [[-5.0137e-06]],\n     \n              [[ 5.4293e-06]],\n     \n              [[-1.3687e-05]]]]),\n     'exp_avg_sq': tensor([[[[3.3090e-08]],\n     \n              [[2.4095e-07]],\n     \n              [[2.8900e-08]],\n     \n              ...,\n     \n              [[1.7153e-08]],\n     \n              [[6.1711e-08]],\n     \n              [[1.6493e-08]]],\n     \n     \n             [[[4.7722e-08]],\n     \n              [[4.8293e-08]],\n     \n              [[3.5414e-08]],\n     \n              ...,\n     \n              [[2.8503e-08]],\n     \n              [[6.4581e-08]],\n     \n              [[4.6458e-08]]],\n     \n     \n             [[[6.6620e-09]],\n     \n              [[2.5448e-08]],\n     \n              [[6.9960e-09]],\n     \n              ...,\n     \n              [[4.3271e-09]],\n     \n              [[1.1209e-08]],\n     \n              [[4.3097e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[2.6801e-10]],\n     \n              [[3.2799e-11]],\n     \n              [[1.6280e-10]],\n     \n              ...,\n     \n              [[1.8302e-10]],\n     \n              [[3.7882e-10]],\n     \n              [[2.2551e-10]]],\n     \n     \n             [[[4.9633e-08]],\n     \n              [[1.5510e-07]],\n     \n              [[5.0972e-08]],\n     \n              ...,\n     \n              [[3.1163e-08]],\n     \n              [[5.9713e-08]],\n     \n              [[3.7722e-08]]],\n     \n     \n             [[[9.9692e-11]],\n     \n              [[2.5512e-11]],\n     \n              [[7.0139e-11]],\n     \n              ...,\n     \n              [[6.2132e-11]],\n     \n              [[1.4230e-10]],\n     \n              [[8.2149e-11]]]])},\n    119: {'exp_avg': tensor([[[[-4.6443e-05]],\n     \n              [[-4.0310e-06]],\n     \n              [[ 6.5275e-06]],\n     \n              ...,\n     \n              [[ 3.9098e-05]],\n     \n              [[ 9.4871e-05]],\n     \n              [[-1.0081e-04]]],\n     \n     \n             [[[-2.5614e-05]],\n     \n              [[ 1.8668e-05]],\n     \n              [[ 6.5366e-05]],\n     \n              ...,\n     \n              [[ 9.4128e-05]],\n     \n              [[-2.7101e-06]],\n     \n              [[ 9.8176e-05]]],\n     \n     \n             [[[-6.3632e-05]],\n     \n              [[-1.7140e-04]],\n     \n              [[-3.8800e-06]],\n     \n              ...,\n     \n              [[ 1.5387e-05]],\n     \n              [[-2.9053e-05]],\n     \n              [[-2.0837e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 1.7731e-05]],\n     \n              [[-8.2957e-05]],\n     \n              [[ 1.3907e-04]],\n     \n              ...,\n     \n              [[ 2.1637e-04]],\n     \n              [[ 1.1417e-04]],\n     \n              [[-2.1530e-04]]],\n     \n     \n             [[[ 6.6260e-05]],\n     \n              [[ 3.5871e-05]],\n     \n              [[ 3.0607e-04]],\n     \n              ...,\n     \n              [[ 1.6391e-04]],\n     \n              [[-9.4203e-05]],\n     \n              [[ 1.3846e-04]]],\n     \n     \n             [[[ 4.3892e-05]],\n     \n              [[ 2.2327e-04]],\n     \n              [[ 8.1477e-05]],\n     \n              ...,\n     \n              [[ 1.1676e-04]],\n     \n              [[ 2.1608e-04]],\n     \n              [[ 1.7679e-04]]]]),\n     'exp_avg_sq': tensor([[[[9.4762e-09]],\n     \n              [[2.0236e-08]],\n     \n              [[2.3323e-08]],\n     \n              ...,\n     \n              [[2.1227e-08]],\n     \n              [[3.0526e-08]],\n     \n              [[2.3062e-08]]],\n     \n     \n             [[[2.4154e-08]],\n     \n              [[7.8703e-09]],\n     \n              [[9.9522e-09]],\n     \n              ...,\n     \n              [[1.1229e-08]],\n     \n              [[1.4579e-08]],\n     \n              [[8.3215e-09]]],\n     \n     \n             [[[9.3425e-09]],\n     \n              [[2.6657e-08]],\n     \n              [[3.8169e-08]],\n     \n              ...,\n     \n              [[3.2957e-08]],\n     \n              [[3.2416e-08]],\n     \n              [[2.7823e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[6.4406e-09]],\n     \n              [[2.5838e-08]],\n     \n              [[3.8103e-08]],\n     \n              ...,\n     \n              [[3.7031e-08]],\n     \n              [[4.0484e-08]],\n     \n              [[3.1575e-08]]],\n     \n     \n             [[[1.7647e-08]],\n     \n              [[2.6030e-08]],\n     \n              [[7.7780e-08]],\n     \n              ...,\n     \n              [[6.1316e-08]],\n     \n              [[6.1926e-08]],\n     \n              [[4.2744e-08]]],\n     \n     \n             [[[8.9195e-09]],\n     \n              [[7.7938e-08]],\n     \n              [[6.3547e-08]],\n     \n              ...,\n     \n              [[6.9820e-08]],\n     \n              [[8.5540e-08]],\n     \n              [[7.4639e-08]]]])},\n    120: {'exp_avg': tensor([[[[-1.0219e-04,  1.7012e-05, -3.5116e-05],\n               [-6.6409e-05, -6.1167e-05, -3.1240e-05],\n               [-7.3657e-05, -1.1939e-04, -1.7754e-04]],\n     \n              [[-1.2369e-06,  1.3827e-05, -4.4969e-06],\n               [-4.7626e-05, -2.3531e-05, -4.6404e-06],\n               [ 1.0400e-05,  1.7678e-05,  7.9490e-06]],\n     \n              [[-2.8874e-05, -1.7391e-05, -2.3550e-05],\n               [ 3.0215e-05,  4.5005e-05, -4.1086e-05],\n               [ 1.2663e-05,  1.0685e-04, -2.1936e-05]],\n     \n              ...,\n     \n              [[ 2.9084e-05,  3.4881e-05,  2.2465e-05],\n               [-7.5887e-05,  5.1467e-05, -4.8820e-05],\n               [-1.6265e-05,  2.0280e-05,  2.8650e-05]],\n     \n              [[ 8.8635e-06,  2.4963e-06, -8.1927e-05],\n               [-8.1667e-05, -9.5548e-05, -1.0010e-05],\n               [-9.3759e-05, -1.8188e-04, -2.5679e-05]],\n     \n              [[-8.6647e-05, -7.5804e-05, -1.2444e-04],\n               [-7.7490e-05, -7.2921e-05, -2.4601e-05],\n               [ 1.7369e-05, -4.3497e-05, -1.1194e-04]]],\n     \n     \n             [[[ 7.9319e-06, -8.5844e-05, -4.5441e-05],\n               [-1.1391e-04, -1.3568e-04, -1.1622e-04],\n               [-1.8350e-05, -9.8715e-05, -7.4755e-05]],\n     \n              [[-4.4687e-06, -8.8646e-06, -6.4975e-05],\n               [-2.0328e-05, -1.0992e-06, -3.0551e-06],\n               [ 2.3503e-05,  3.0746e-05,  3.5184e-06]],\n     \n              [[-1.4491e-04, -1.1513e-04, -9.6926e-05],\n               [-9.8812e-06, -7.2610e-05, -8.3461e-05],\n               [-4.3591e-05,  1.8463e-05, -1.0422e-04]],\n     \n              ...,\n     \n              [[-4.6789e-05, -1.4495e-05, -6.3601e-05],\n               [-2.7654e-05,  5.2984e-05, -6.5625e-05],\n               [ 3.2311e-05,  1.0241e-04, -9.3708e-06]],\n     \n              [[ 1.0039e-05,  4.8447e-05, -6.1518e-05],\n               [ 1.6405e-05,  9.3981e-05,  2.8243e-05],\n               [ 3.0515e-06,  8.0566e-05, -1.6636e-05]],\n     \n              [[-1.4345e-05,  3.4705e-05, -1.6768e-05],\n               [-2.6008e-05, -3.5164e-05,  4.9594e-06],\n               [ 1.5604e-05, -1.2221e-04,  5.5280e-05]]],\n     \n     \n             [[[-2.6973e-05,  1.6044e-06, -9.2206e-05],\n               [-1.4206e-04, -4.4125e-05, -1.5453e-04],\n               [-1.0289e-04, -1.3346e-05,  1.8393e-05]],\n     \n              [[-5.4254e-05, -2.1664e-05, -4.1421e-05],\n               [-1.2249e-05,  3.9158e-06, -2.8853e-05],\n               [-2.7053e-05, -7.1232e-06,  4.7660e-06]],\n     \n              [[-6.6328e-06,  1.4682e-05, -4.1098e-05],\n               [-5.5748e-05,  3.3577e-05, -1.1439e-04],\n               [-1.4629e-05,  2.8379e-05, -4.6471e-05]],\n     \n              ...,\n     \n              [[ 1.4580e-05, -1.1816e-05, -7.3089e-06],\n               [-1.4434e-05, -6.4029e-05, -4.3767e-05],\n               [-2.6108e-05,  9.0348e-05,  1.1793e-04]],\n     \n              [[ 9.7420e-05,  1.0827e-04,  7.8443e-05],\n               [-4.8136e-06, -3.7754e-06, -4.1465e-05],\n               [ 8.8724e-05,  1.0595e-04,  5.2302e-05]],\n     \n              [[-3.3138e-05, -5.2118e-05,  7.3983e-05],\n               [ 1.9440e-05, -8.0819e-05,  5.3550e-05],\n               [-4.9615e-05, -2.6211e-05,  1.1408e-04]]],\n     \n     \n             ...,\n     \n     \n             [[[ 5.1351e-05, -1.5366e-05, -5.7816e-08],\n               [ 1.2858e-04,  6.9962e-05,  6.8120e-05],\n               [ 1.0487e-04,  2.0591e-05,  8.5215e-05]],\n     \n              [[ 8.0174e-06,  1.3753e-05, -1.5218e-05],\n               [-1.5299e-05, -1.8904e-05, -8.6150e-06],\n               [-2.3765e-05,  8.5420e-06, -9.3380e-06]],\n     \n              [[ 2.8395e-06, -3.5215e-05,  3.1291e-05],\n               [ 1.7346e-05, -7.5293e-05, -1.8879e-05],\n               [ 1.2456e-05, -1.4615e-05,  2.5605e-05]],\n     \n              ...,\n     \n              [[ 1.2557e-05,  3.6546e-05,  4.6369e-05],\n               [ 2.5305e-05, -8.0548e-07,  2.0844e-05],\n               [ 1.0956e-05, -1.4429e-05,  2.2898e-06]],\n     \n              [[ 2.0328e-05,  2.4173e-05,  1.7708e-05],\n               [ 2.8309e-05,  1.8074e-05, -7.3625e-05],\n               [ 5.8777e-05,  2.0001e-05, -7.2589e-05]],\n     \n              [[-3.0116e-05, -8.5573e-05, -5.1936e-05],\n               [-3.4352e-05, -6.7488e-05, -4.8352e-05],\n               [-1.1644e-04, -1.0846e-04, -7.0593e-05]]],\n     \n     \n             [[[ 2.9231e-06,  4.2232e-05,  1.1742e-04],\n               [-1.0693e-04,  1.0199e-04, -3.0169e-05],\n               [ 4.0088e-05,  4.4017e-05, -1.1422e-05]],\n     \n              [[ 4.9373e-05,  1.8596e-06,  3.3745e-05],\n               [ 1.4830e-05,  1.5374e-05,  3.0306e-05],\n               [-8.5361e-06,  6.2508e-06, -3.8899e-06]],\n     \n              [[-7.4369e-05, -8.4416e-07, -5.0899e-05],\n               [ 3.6321e-06, -3.0168e-06, -1.0224e-04],\n               [-3.1758e-05, -1.8483e-05, -1.3512e-04]],\n     \n              ...,\n     \n              [[ 1.6596e-05, -3.2592e-05, -2.3658e-05],\n               [ 5.1169e-05, -1.8988e-04, -1.2485e-04],\n               [ 3.1190e-05,  5.8167e-06, -9.3700e-05]],\n     \n              [[-5.9832e-05,  1.0928e-05, -4.5428e-05],\n               [-4.6518e-05,  4.5475e-05,  2.0124e-04],\n               [ 1.4700e-05, -8.0869e-05,  7.1281e-05]],\n     \n              [[-4.5109e-05,  3.3635e-05, -3.0420e-05],\n               [-4.1492e-05, -5.6981e-05, -1.5852e-05],\n               [ 3.7722e-05, -2.1330e-05,  2.0263e-05]]],\n     \n     \n             [[[-7.8689e-05, -7.5236e-05, -1.3314e-05],\n               [ 5.3789e-05, -4.5129e-05,  2.0417e-05],\n               [-2.6987e-05, -5.9602e-05, -1.1326e-04]],\n     \n              [[ 3.9378e-05,  3.5567e-05,  4.8532e-05],\n               [-6.8392e-06, -8.3972e-06, -9.5277e-06],\n               [ 6.7098e-06,  5.8958e-06,  4.2070e-05]],\n     \n              [[-1.0197e-05,  4.7436e-05, -1.1622e-05],\n               [-7.9855e-05,  1.0605e-04,  8.1619e-06],\n               [-1.7602e-05,  1.0947e-04,  5.6610e-05]],\n     \n              ...,\n     \n              [[ 6.1745e-05,  1.2558e-04,  5.7688e-05],\n               [-3.7860e-05,  8.1271e-06,  2.2267e-05],\n               [-4.3833e-05,  6.6690e-06, -3.2317e-05]],\n     \n              [[-1.0928e-05, -9.8202e-05,  4.4243e-05],\n               [ 2.7965e-05,  2.5087e-05, -9.0620e-05],\n               [-6.6274e-05,  3.9716e-05,  3.8731e-05]],\n     \n              [[ 4.9428e-06,  7.5870e-05, -2.2212e-05],\n               [-1.0933e-04,  9.7971e-05,  2.0910e-05],\n               [-1.0280e-04,  1.9752e-04,  1.6572e-04]]]]),\n     'exp_avg_sq': tensor([[[[6.5524e-09, 6.2298e-09, 6.3002e-09],\n               [5.0242e-09, 5.9936e-09, 5.8216e-09],\n               [1.0889e-08, 1.0707e-08, 1.2181e-08]],\n     \n              [[6.2970e-10, 7.6572e-10, 6.5021e-10],\n               [4.1263e-10, 4.1008e-10, 4.5188e-10],\n               [3.5871e-10, 4.0810e-10, 4.7200e-10]],\n     \n              [[8.4628e-09, 8.9924e-09, 9.8803e-09],\n               [9.7388e-09, 7.8022e-09, 8.8580e-09],\n               [9.8836e-09, 1.0034e-08, 1.0142e-08]],\n     \n              ...,\n     \n              [[5.0715e-09, 4.9201e-09, 5.8007e-09],\n               [5.3565e-09, 7.4859e-09, 8.0412e-09],\n               [5.2683e-09, 1.0597e-08, 9.8337e-09]],\n     \n              [[1.0889e-08, 1.4307e-08, 1.5563e-08],\n               [1.7519e-08, 1.4490e-08, 1.5890e-08],\n               [1.4193e-08, 1.4185e-08, 1.2972e-08]],\n     \n              [[8.9430e-09, 9.6835e-09, 7.7321e-09],\n               [1.1036e-08, 1.5393e-08, 1.4108e-08],\n               [1.8461e-08, 2.0324e-08, 1.7780e-08]]],\n     \n     \n             [[[1.1669e-08, 1.5558e-08, 1.1487e-08],\n               [1.8309e-08, 1.6678e-08, 2.1036e-08],\n               [1.6909e-08, 2.0874e-08, 1.7074e-08]],\n     \n              [[1.0988e-09, 1.5049e-09, 1.1227e-09],\n               [6.3137e-10, 4.9105e-10, 6.2911e-10],\n               [9.8178e-10, 1.2509e-09, 1.3733e-09]],\n     \n              [[1.7649e-08, 1.9460e-08, 1.9173e-08],\n               [1.7707e-08, 2.2124e-08, 1.8631e-08],\n               [1.9733e-08, 2.3795e-08, 1.9152e-08]],\n     \n              ...,\n     \n              [[1.0522e-08, 1.3485e-08, 1.0552e-08],\n               [9.0355e-09, 1.3564e-08, 1.4071e-08],\n               [1.0715e-08, 1.2248e-08, 1.0344e-08]],\n     \n              [[2.2242e-08, 2.6753e-08, 3.0536e-08],\n               [2.9469e-08, 2.9760e-08, 2.6464e-08],\n               [2.6298e-08, 2.7946e-08, 2.5630e-08]],\n     \n              [[3.5648e-08, 3.8305e-08, 4.2544e-08],\n               [3.2276e-08, 3.6467e-08, 3.4534e-08],\n               [3.8953e-08, 3.6852e-08, 4.0619e-08]]],\n     \n     \n             [[[1.2686e-08, 1.0512e-08, 1.1772e-08],\n               [1.2197e-08, 1.3639e-08, 1.3092e-08],\n               [1.5811e-08, 1.3577e-08, 1.4308e-08]],\n     \n              [[1.0266e-09, 1.0553e-09, 8.9476e-10],\n               [4.4300e-10, 7.3348e-10, 6.6030e-10],\n               [6.7711e-10, 1.0359e-09, 8.1878e-10]],\n     \n              [[1.4447e-08, 1.6727e-08, 1.8489e-08],\n               [1.6152e-08, 1.5244e-08, 1.8859e-08],\n               [1.4792e-08, 1.7565e-08, 1.4846e-08]],\n     \n              ...,\n     \n              [[8.4043e-09, 9.3533e-09, 8.7757e-09],\n               [8.2325e-09, 9.9085e-09, 1.1385e-08],\n               [9.8894e-09, 1.0901e-08, 1.2056e-08]],\n     \n              [[1.7328e-08, 1.9817e-08, 2.0472e-08],\n               [1.9006e-08, 2.2688e-08, 2.6779e-08],\n               [1.9311e-08, 2.1730e-08, 2.2182e-08]],\n     \n              [[2.7709e-08, 3.0432e-08, 3.0186e-08],\n               [2.7389e-08, 3.3391e-08, 3.5887e-08],\n               [2.8091e-08, 3.5281e-08, 3.8812e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[5.1085e-09, 3.1033e-09, 5.2682e-09],\n               [8.8013e-09, 4.0540e-09, 8.1665e-09],\n               [1.0789e-08, 5.2789e-09, 8.2044e-09]],\n     \n              [[4.2525e-10, 3.9023e-10, 5.1672e-10],\n               [2.4168e-10, 3.7193e-10, 3.9080e-10],\n               [5.6221e-10, 5.1993e-10, 4.0865e-10]],\n     \n              [[5.8789e-09, 6.9727e-09, 5.6686e-09],\n               [5.7057e-09, 5.9334e-09, 5.6509e-09],\n               [4.8359e-09, 6.8852e-09, 5.9557e-09]],\n     \n              ...,\n     \n              [[2.9798e-09, 4.3369e-09, 6.6452e-09],\n               [4.6245e-09, 5.3823e-09, 6.8487e-09],\n               [4.8734e-09, 4.1763e-09, 5.5132e-09]],\n     \n              [[8.2648e-09, 1.0665e-08, 7.2697e-09],\n               [9.1545e-09, 1.5120e-08, 9.6468e-09],\n               [8.9149e-09, 1.2228e-08, 1.0442e-08]],\n     \n              [[1.2704e-08, 1.2958e-08, 1.4237e-08],\n               [1.3533e-08, 1.2641e-08, 1.3652e-08],\n               [1.1226e-08, 1.1623e-08, 1.6019e-08]]],\n     \n     \n             [[[1.0700e-08, 1.1833e-08, 1.3309e-08],\n               [1.6648e-08, 1.4033e-08, 1.6490e-08],\n               [1.4841e-08, 1.2885e-08, 1.4433e-08]],\n     \n              [[1.3749e-09, 1.7301e-09, 1.0356e-09],\n               [7.0712e-10, 6.9519e-10, 6.4390e-10],\n               [8.8920e-10, 1.0609e-09, 7.9130e-10]],\n     \n              [[1.8805e-08, 1.7405e-08, 1.8887e-08],\n               [2.0372e-08, 1.9334e-08, 1.8268e-08],\n               [1.7595e-08, 1.9376e-08, 1.7742e-08]],\n     \n              ...,\n     \n              [[1.0535e-08, 1.0338e-08, 1.0791e-08],\n               [9.3083e-09, 1.4530e-08, 1.4379e-08],\n               [1.1994e-08, 1.4109e-08, 1.3276e-08]],\n     \n              [[1.9536e-08, 2.7929e-08, 2.5786e-08],\n               [2.3578e-08, 3.5189e-08, 3.7109e-08],\n               [2.4878e-08, 2.4909e-08, 2.9378e-08]],\n     \n              [[3.0685e-08, 3.3851e-08, 3.4341e-08],\n               [3.0937e-08, 3.6013e-08, 3.9928e-08],\n               [3.0166e-08, 3.9294e-08, 3.9504e-08]]],\n     \n     \n             [[[1.1297e-08, 1.0874e-08, 1.0665e-08],\n               [1.3157e-08, 1.6222e-08, 1.3394e-08],\n               [1.3912e-08, 1.6113e-08, 1.7298e-08]],\n     \n              [[1.5415e-09, 1.7520e-09, 1.2963e-09],\n               [4.6731e-10, 7.1518e-10, 6.2323e-10],\n               [1.0598e-09, 1.4236e-09, 9.4599e-10]],\n     \n              [[1.4297e-08, 1.6848e-08, 1.9002e-08],\n               [1.6363e-08, 2.0203e-08, 2.1334e-08],\n               [1.5721e-08, 1.4317e-08, 1.6008e-08]],\n     \n              ...,\n     \n              [[8.4811e-09, 1.2283e-08, 1.1190e-08],\n               [9.6254e-09, 1.2964e-08, 1.3047e-08],\n               [1.1677e-08, 1.2394e-08, 1.3384e-08]],\n     \n              [[1.9579e-08, 2.4301e-08, 2.4434e-08],\n               [2.1822e-08, 2.6149e-08, 3.0759e-08],\n               [1.7429e-08, 2.1803e-08, 2.6505e-08]],\n     \n              [[3.2523e-08, 3.6356e-08, 3.5054e-08],\n               [4.0369e-08, 4.0161e-08, 3.6754e-08],\n               [4.3563e-08, 4.2376e-08, 3.9387e-08]]]])},\n    121: {'exp_avg': tensor([[[[ 1.7235e-06]],\n     \n              [[-9.5395e-05]],\n     \n              [[ 8.5403e-05]],\n     \n              ...,\n     \n              [[ 5.4515e-05]],\n     \n              [[ 1.4891e-05]],\n     \n              [[ 3.3223e-05]]],\n     \n     \n             [[[ 4.8508e-05]],\n     \n              [[-5.8410e-05]],\n     \n              [[-1.2506e-06]],\n     \n              ...,\n     \n              [[-5.8342e-05]],\n     \n              [[ 6.1898e-05]],\n     \n              [[ 8.7520e-05]]],\n     \n     \n             [[[-8.4177e-05]],\n     \n              [[-1.7890e-06]],\n     \n              [[-1.6134e-04]],\n     \n              ...,\n     \n              [[ 1.0360e-04]],\n     \n              [[-1.6408e-04]],\n     \n              [[ 2.1659e-04]]],\n     \n     \n             ...,\n     \n     \n             [[[ 2.5690e-05]],\n     \n              [[ 3.4096e-05]],\n     \n              [[ 1.2318e-04]],\n     \n              ...,\n     \n              [[-1.6217e-05]],\n     \n              [[ 1.7860e-05]],\n     \n              [[ 8.0485e-05]]],\n     \n     \n             [[[ 3.1530e-05]],\n     \n              [[ 1.1682e-04]],\n     \n              [[-7.3855e-05]],\n     \n              ...,\n     \n              [[ 1.7363e-04]],\n     \n              [[ 7.0364e-05]],\n     \n              [[ 1.6217e-04]]],\n     \n     \n             [[[ 5.9616e-05]],\n     \n              [[ 6.9726e-06]],\n     \n              [[-6.6286e-05]],\n     \n              ...,\n     \n              [[ 1.2577e-05]],\n     \n              [[-1.2613e-04]],\n     \n              [[ 9.1806e-05]]]]),\n     'exp_avg_sq': tensor([[[[3.7240e-09]],\n     \n              [[1.0849e-08]],\n     \n              [[9.6164e-09]],\n     \n              ...,\n     \n              [[6.0671e-09]],\n     \n              [[8.7401e-09]],\n     \n              [[8.4996e-09]]],\n     \n     \n             [[[2.2051e-08]],\n     \n              [[1.1530e-08]],\n     \n              [[1.2504e-08]],\n     \n              ...,\n     \n              [[5.3158e-09]],\n     \n              [[2.2931e-08]],\n     \n              [[3.3031e-08]]],\n     \n     \n             [[[2.6030e-08]],\n     \n              [[7.0135e-08]],\n     \n              [[4.4771e-08]],\n     \n              ...,\n     \n              [[2.6725e-08]],\n     \n              [[6.7980e-08]],\n     \n              [[5.3506e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[1.2714e-08]],\n     \n              [[2.4059e-08]],\n     \n              [[1.7082e-08]],\n     \n              ...,\n     \n              [[7.8702e-09]],\n     \n              [[2.1029e-08]],\n     \n              [[2.0195e-08]]],\n     \n     \n             [[[2.1977e-08]],\n     \n              [[5.7941e-08]],\n     \n              [[5.3761e-08]],\n     \n              ...,\n     \n              [[2.1517e-08]],\n     \n              [[5.8094e-08]],\n     \n              [[5.6402e-08]]],\n     \n     \n             [[[1.2785e-08]],\n     \n              [[2.5038e-08]],\n     \n              [[2.1401e-08]],\n     \n              ...,\n     \n              [[1.2235e-08]],\n     \n              [[2.6669e-08]],\n     \n              [[2.1992e-08]]]])},\n    122: {'exp_avg': tensor([[[[-2.5376e-06]],\n     \n              [[-3.4074e-05]],\n     \n              [[-2.5225e-05]],\n     \n              ...,\n     \n              [[-2.5342e-05]],\n     \n              [[ 1.0959e-06]],\n     \n              [[-2.7592e-05]]],\n     \n     \n             [[[ 1.5960e-04]],\n     \n              [[ 6.0072e-05]],\n     \n              [[ 7.5484e-05]],\n     \n              ...,\n     \n              [[ 1.0356e-05]],\n     \n              [[ 1.6543e-05]],\n     \n              [[ 2.8070e-06]]],\n     \n     \n             [[[-2.0406e-05]],\n     \n              [[ 3.6793e-05]],\n     \n              [[ 4.4546e-06]],\n     \n              ...,\n     \n              [[ 7.8736e-05]],\n     \n              [[-2.4526e-05]],\n     \n              [[ 3.7719e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-2.8893e-05]],\n     \n              [[-1.1292e-05]],\n     \n              [[-5.2519e-05]],\n     \n              ...,\n     \n              [[-7.2095e-05]],\n     \n              [[ 2.9687e-05]],\n     \n              [[-1.4316e-05]]],\n     \n     \n             [[[ 3.4725e-06]],\n     \n              [[ 3.8242e-05]],\n     \n              [[ 3.4161e-05]],\n     \n              ...,\n     \n              [[ 7.1556e-05]],\n     \n              [[ 5.2092e-05]],\n     \n              [[-1.1942e-05]]],\n     \n     \n             [[[ 2.0587e-05]],\n     \n              [[-3.1158e-05]],\n     \n              [[ 3.7851e-05]],\n     \n              ...,\n     \n              [[ 8.1681e-06]],\n     \n              [[ 6.6976e-05]],\n     \n              [[-1.4283e-05]]]]),\n     'exp_avg_sq': tensor([[[[8.6067e-10]],\n     \n              [[4.2304e-09]],\n     \n              [[3.7127e-09]],\n     \n              ...,\n     \n              [[2.3909e-09]],\n     \n              [[4.9382e-09]],\n     \n              [[3.0883e-09]]],\n     \n     \n             [[[1.3480e-07]],\n     \n              [[1.4000e-08]],\n     \n              [[1.3248e-08]],\n     \n              ...,\n     \n              [[5.0248e-09]],\n     \n              [[1.7251e-08]],\n     \n              [[7.8036e-09]]],\n     \n     \n             [[[1.6418e-09]],\n     \n              [[6.2298e-09]],\n     \n              [[5.6390e-09]],\n     \n              ...,\n     \n              [[5.5302e-09]],\n     \n              [[5.9890e-09]],\n     \n              [[5.9697e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[1.1428e-09]],\n     \n              [[5.8523e-09]],\n     \n              [[2.9575e-09]],\n     \n              ...,\n     \n              [[3.0579e-09]],\n     \n              [[8.2582e-09]],\n     \n              [[3.4749e-09]]],\n     \n     \n             [[[2.4081e-09]],\n     \n              [[8.8707e-09]],\n     \n              [[9.6840e-09]],\n     \n              ...,\n     \n              [[1.0494e-08]],\n     \n              [[1.0846e-08]],\n     \n              [[8.0253e-09]]],\n     \n     \n             [[[9.5996e-10]],\n     \n              [[7.6142e-09]],\n     \n              [[4.7508e-09]],\n     \n              ...,\n     \n              [[4.6064e-09]],\n     \n              [[6.8169e-09]],\n     \n              [[3.7756e-09]]]])},\n    123: {'exp_avg': tensor([[[[-8.8762e-06]],\n     \n              [[ 5.5631e-06]],\n     \n              [[-1.1483e-04]],\n     \n              ...,\n     \n              [[-3.6988e-05]],\n     \n              [[-8.9724e-05]],\n     \n              [[-1.0435e-04]]],\n     \n     \n             [[[ 1.1940e-05]],\n     \n              [[ 1.5066e-05]],\n     \n              [[ 7.1332e-05]],\n     \n              ...,\n     \n              [[ 5.0209e-05]],\n     \n              [[ 3.9649e-05]],\n     \n              [[-1.5908e-05]]],\n     \n     \n             [[[ 1.3671e-05]],\n     \n              [[-4.3626e-06]],\n     \n              [[-4.7038e-05]],\n     \n              ...,\n     \n              [[ 1.0257e-04]],\n     \n              [[-3.1540e-06]],\n     \n              [[ 3.5078e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 2.7461e-05]],\n     \n              [[ 2.3179e-04]],\n     \n              [[ 1.7847e-05]],\n     \n              ...,\n     \n              [[ 7.7718e-06]],\n     \n              [[-1.1242e-04]],\n     \n              [[ 3.4616e-05]]],\n     \n     \n             [[[ 2.0088e-05]],\n     \n              [[-8.7476e-05]],\n     \n              [[ 4.5743e-05]],\n     \n              ...,\n     \n              [[ 2.8049e-05]],\n     \n              [[-6.9629e-05]],\n     \n              [[-9.4015e-06]]],\n     \n     \n             [[[-1.8770e-06]],\n     \n              [[-2.6703e-05]],\n     \n              [[ 4.9997e-05]],\n     \n              ...,\n     \n              [[ 5.7155e-05]],\n     \n              [[-3.6982e-05]],\n     \n              [[ 1.0579e-05]]]]),\n     'exp_avg_sq': tensor([[[[4.0847e-09]],\n     \n              [[4.1487e-07]],\n     \n              [[3.7418e-08]],\n     \n              ...,\n     \n              [[2.3635e-08]],\n     \n              [[4.9173e-08]],\n     \n              [[2.3193e-08]]],\n     \n     \n             [[[1.3203e-09]],\n     \n              [[6.6386e-09]],\n     \n              [[9.0047e-09]],\n     \n              ...,\n     \n              [[5.8673e-09]],\n     \n              [[1.2574e-08]],\n     \n              [[1.8503e-09]]],\n     \n     \n             [[[1.7503e-09]],\n     \n              [[2.6976e-08]],\n     \n              [[9.5016e-09]],\n     \n              ...,\n     \n              [[5.8750e-09]],\n     \n              [[1.5764e-08]],\n     \n              [[6.7632e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[7.3983e-10]],\n     \n              [[2.6539e-07]],\n     \n              [[6.6072e-09]],\n     \n              ...,\n     \n              [[3.5001e-09]],\n     \n              [[1.1802e-08]],\n     \n              [[3.1265e-09]]],\n     \n     \n             [[[1.7037e-09]],\n     \n              [[1.2515e-08]],\n     \n              [[1.3703e-08]],\n     \n              ...,\n     \n              [[5.5492e-09]],\n     \n              [[2.0940e-08]],\n     \n              [[7.9182e-09]]],\n     \n     \n             [[[1.0504e-09]],\n     \n              [[1.0532e-08]],\n     \n              [[7.9101e-09]],\n     \n              ...,\n     \n              [[3.8908e-09]],\n     \n              [[9.9398e-09]],\n     \n              [[4.2655e-09]]]])},\n    124: {'exp_avg': tensor([[[[ 2.3643e-05,  3.3219e-06,  1.9576e-05],\n               [-2.7837e-05, -5.9551e-05, -1.4627e-05],\n               [-4.7428e-07, -1.2621e-05, -5.4469e-06]],\n     \n              [[-1.6331e-05,  1.0767e-04,  4.1470e-05],\n               [-1.0882e-04,  9.0466e-05,  6.1179e-05],\n               [-1.1931e-04,  1.1207e-05, -1.6759e-05]],\n     \n              [[ 4.5717e-05,  2.1495e-05,  5.6074e-05],\n               [ 2.9595e-05,  8.9739e-06,  1.1923e-05],\n               [ 8.9605e-06,  3.7706e-05,  6.8874e-05]],\n     \n              ...,\n     \n              [[ 9.7598e-06,  5.6776e-05,  6.9007e-05],\n               [ 5.6558e-05,  5.8623e-05,  3.0863e-05],\n               [ 3.9670e-05,  1.1055e-05,  1.1018e-05]],\n     \n              [[ 1.0491e-04,  6.3138e-05,  2.6417e-06],\n               [ 6.7046e-05,  3.7681e-05, -4.2496e-06],\n               [-5.9033e-06,  5.2313e-06, -1.8440e-05]],\n     \n              [[ 2.5371e-05,  1.7751e-06, -4.5139e-05],\n               [ 2.5326e-05, -2.2812e-05, -3.2165e-05],\n               [ 6.2430e-05, -5.6644e-06,  2.3599e-05]]],\n     \n     \n             [[[ 2.5330e-05, -6.3756e-06,  2.6947e-05],\n               [ 4.4236e-05,  1.1136e-05,  7.0882e-06],\n               [ 1.3624e-05, -5.2227e-05,  2.0575e-05]],\n     \n              [[-1.5009e-04, -1.8024e-05, -1.0102e-05],\n               [-1.0579e-04, -1.1773e-04, -7.4632e-05],\n               [-7.2693e-05, -7.3733e-05, -4.2547e-06]],\n     \n              [[-6.2662e-06, -5.5598e-05, -1.8875e-05],\n               [-4.6219e-06, -3.7689e-05, -4.7930e-06],\n               [-8.4800e-06, -4.1845e-05, -7.2600e-05]],\n     \n              ...,\n     \n              [[-1.9558e-05,  1.4234e-05,  2.4187e-05],\n               [ 1.5600e-06, -3.3811e-06, -1.3871e-06],\n               [-2.4967e-05, -2.1499e-05, -3.0732e-05]],\n     \n              [[ 1.6858e-05,  1.2938e-05,  2.6090e-05],\n               [-2.7935e-05, -5.4979e-06, -2.1195e-05],\n               [-7.5274e-06,  4.2210e-05,  2.4531e-05]],\n     \n              [[-4.8887e-05, -1.7969e-05,  2.2420e-05],\n               [-2.1202e-05, -1.2338e-05,  7.2738e-06],\n               [-1.7408e-05,  2.1478e-05, -3.5099e-05]]],\n     \n     \n             [[[ 4.1526e-06,  3.6399e-05, -1.2479e-05],\n               [ 1.7386e-05, -3.6935e-05, -3.5520e-05],\n               [ 4.0342e-05, -5.5321e-05, -9.6384e-06]],\n     \n              [[ 5.4043e-05,  9.8651e-05,  1.8634e-05],\n               [ 2.8657e-05,  4.4670e-05,  3.2011e-05],\n               [ 9.0611e-06,  3.3466e-05,  6.0679e-05]],\n     \n              [[-1.7219e-05, -4.6062e-05,  1.4872e-05],\n               [-8.8753e-06, -1.7570e-05, -2.0135e-05],\n               [-5.3417e-05, -7.7142e-05, -5.8945e-06]],\n     \n              ...,\n     \n              [[-1.7303e-04, -1.2098e-04, -1.7467e-04],\n               [-8.2453e-05, -6.5793e-06, -5.1833e-05],\n               [-2.6481e-05, -1.0802e-04, -3.6993e-05]],\n     \n              [[ 4.3898e-05, -5.7397e-05, -8.0987e-05],\n               [ 4.8783e-05, -1.6051e-04, -1.1532e-04],\n               [ 3.9331e-05, -4.6858e-05, -5.2333e-07]],\n     \n              [[-3.2464e-06, -2.8566e-05,  2.4287e-05],\n               [ 1.2024e-05,  4.7597e-05,  3.9825e-05],\n               [ 9.8243e-05,  1.1071e-04,  6.9011e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 5.1554e-06, -5.3092e-05,  1.8426e-05],\n               [-1.2765e-06, -9.4151e-06,  2.9544e-05],\n               [-5.0336e-06,  3.8190e-05,  1.0550e-06]],\n     \n              [[-1.9908e-05,  2.0622e-05,  1.3004e-04],\n               [-4.2131e-05,  5.5294e-05,  6.7115e-05],\n               [-4.6363e-05,  2.1528e-07, -6.4133e-06]],\n     \n              [[-2.4108e-05,  1.6916e-05,  1.2047e-06],\n               [ 6.8228e-06,  2.4308e-05,  1.2336e-05],\n               [ 9.8879e-07,  6.6594e-05,  2.1109e-05]],\n     \n              ...,\n     \n              [[ 6.3763e-05,  1.0725e-04,  6.1703e-06],\n               [ 6.2719e-05,  5.5479e-05,  4.6466e-05],\n               [ 7.5373e-05,  2.3600e-05, -6.8172e-05]],\n     \n              [[ 8.4648e-05,  3.5600e-05, -3.1874e-06],\n               [ 4.4452e-05,  2.6919e-05,  5.6014e-05],\n               [ 1.1301e-04,  2.7775e-05,  1.4710e-05]],\n     \n              [[ 2.3636e-05, -3.7578e-05, -6.9342e-05],\n               [ 4.9882e-05, -2.0624e-05, -6.0345e-05],\n               [ 5.0143e-06, -3.5017e-05, -9.2137e-06]]],\n     \n     \n             [[[ 7.2903e-06,  4.9873e-06,  8.7611e-05],\n               [-7.1474e-06,  3.5259e-06, -3.9330e-06],\n               [-7.1273e-05,  2.6133e-05,  5.8761e-05]],\n     \n              [[-3.6909e-05, -1.7725e-06,  9.1780e-05],\n               [ 2.8123e-05,  6.3334e-05,  1.2435e-04],\n               [-3.3540e-05,  7.2659e-05,  5.4508e-05]],\n     \n              [[-6.2412e-05, -6.0090e-05, -4.3662e-05],\n               [-2.7001e-05, -7.1975e-05, -2.5658e-06],\n               [ 3.4953e-05,  5.6592e-05,  3.1049e-05]],\n     \n              ...,\n     \n              [[ 6.1858e-05,  4.9993e-05,  5.4039e-05],\n               [ 6.6421e-05,  2.2625e-05,  1.8637e-05],\n               [ 4.3549e-05,  1.0976e-05,  1.6991e-05]],\n     \n              [[-1.4506e-05, -7.1081e-05, -7.1947e-05],\n               [ 6.7457e-05, -5.5511e-05, -1.1297e-04],\n               [ 5.4290e-05,  1.5401e-05,  2.4604e-05]],\n     \n              [[-4.2985e-06,  3.9679e-05,  2.3484e-06],\n               [ 4.3810e-05,  5.0244e-05,  2.8459e-06],\n               [ 6.6115e-05,  3.2059e-05,  1.4961e-05]]],\n     \n     \n             [[[-3.9754e-05,  1.2030e-05, -5.9190e-06],\n               [-4.1686e-06, -6.8849e-06,  1.0988e-05],\n               [-2.3319e-05,  6.5210e-07, -8.0555e-08]],\n     \n              [[-2.3031e-05, -2.3718e-05,  1.0461e-04],\n               [-6.0427e-06, -1.7731e-05,  6.1154e-05],\n               [-4.9765e-05,  6.1502e-06,  2.3098e-05]],\n     \n              [[-5.8927e-05, -6.2803e-05, -1.6812e-05],\n               [-3.6572e-05, -3.9599e-05,  9.7070e-06],\n               [-5.6125e-05, -4.2503e-05,  2.0118e-05]],\n     \n              ...,\n     \n              [[ 1.0247e-06,  3.1118e-05,  1.9276e-05],\n               [ 7.0245e-06,  3.1668e-05,  2.1813e-05],\n               [ 3.0636e-06,  1.4920e-05,  1.7118e-05]],\n     \n              [[-3.5189e-05,  1.4936e-05,  6.6622e-05],\n               [ 3.8131e-06,  8.7242e-06, -4.1430e-05],\n               [ 2.6449e-05,  4.7661e-05,  3.3397e-06]],\n     \n              [[ 3.2697e-05,  3.1555e-05,  1.5748e-05],\n               [ 4.5676e-06, -3.4983e-05, -3.1928e-05],\n               [-2.7266e-05, -4.4916e-05,  1.2400e-05]]]]),\n     'exp_avg_sq': tensor([[[[3.3495e-09, 4.1172e-09, 3.4097e-09],\n               [4.1017e-09, 5.1915e-09, 4.1850e-09],\n               [4.2968e-09, 5.3197e-09, 5.7374e-09]],\n     \n              [[1.3078e-08, 1.4135e-08, 1.1667e-08],\n               [1.6362e-08, 1.9015e-08, 1.4256e-08],\n               [1.9028e-08, 1.9706e-08, 1.4615e-08]],\n     \n              [[7.9833e-09, 9.0241e-09, 6.7724e-09],\n               [8.5381e-09, 1.0563e-08, 6.9675e-09],\n               [9.6682e-09, 1.2034e-08, 8.7616e-09]],\n     \n              ...,\n     \n              [[8.4676e-09, 5.2289e-09, 3.8697e-09],\n               [7.2515e-09, 8.1524e-09, 6.1384e-09],\n               [4.8108e-09, 7.8194e-09, 6.3562e-09]],\n     \n              [[1.3338e-08, 1.3818e-08, 1.1795e-08],\n               [1.5441e-08, 1.5313e-08, 1.0158e-08],\n               [2.0082e-08, 2.0780e-08, 1.7813e-08]],\n     \n              [[7.5680e-09, 8.2054e-09, 8.4685e-09],\n               [8.0078e-09, 8.6630e-09, 8.6657e-09],\n               [6.3987e-09, 1.0710e-08, 9.9216e-09]]],\n     \n     \n             [[[1.9904e-09, 2.2755e-09, 2.4519e-09],\n               [2.6916e-09, 3.0792e-09, 2.9672e-09],\n               [2.0106e-09, 2.9009e-09, 2.7010e-09]],\n     \n              [[2.1425e-08, 1.9327e-08, 1.0139e-08],\n               [2.1704e-08, 2.6050e-08, 1.4328e-08],\n               [1.0683e-08, 1.3547e-08, 1.1346e-08]],\n     \n              [[4.9455e-09, 5.3427e-09, 5.0427e-09],\n               [7.3584e-09, 7.7326e-09, 6.9191e-09],\n               [6.0232e-09, 6.4931e-09, 5.9420e-09]],\n     \n              ...,\n     \n              [[1.1151e-09, 1.4009e-09, 1.9153e-09],\n               [1.1742e-09, 1.5057e-09, 1.2028e-09],\n               [1.2818e-09, 1.3185e-09, 2.2051e-09]],\n     \n              [[5.5804e-09, 4.1483e-09, 3.7272e-09],\n               [5.4082e-09, 2.6303e-09, 5.0981e-09],\n               [6.8303e-09, 4.5932e-09, 6.2296e-09]],\n     \n              [[4.0073e-09, 3.3458e-09, 2.8574e-09],\n               [4.9980e-09, 3.7602e-09, 3.3364e-09],\n               [5.6193e-09, 5.7982e-09, 5.0405e-09]]],\n     \n     \n             [[[1.8490e-09, 3.8729e-09, 3.2626e-09],\n               [1.8995e-09, 3.7904e-09, 3.8640e-09],\n               [2.0937e-09, 3.7995e-09, 3.2961e-09]],\n     \n              [[5.9502e-09, 1.4582e-08, 1.5119e-08],\n               [3.5808e-09, 9.1102e-09, 1.6149e-08],\n               [3.7370e-09, 6.1963e-09, 1.1882e-08]],\n     \n              [[5.3096e-09, 7.8982e-09, 7.8676e-09],\n               [5.7527e-09, 1.0396e-08, 7.8730e-09],\n               [6.1331e-09, 9.3236e-09, 8.2278e-09]],\n     \n              ...,\n     \n              [[1.6382e-08, 1.5630e-08, 1.4858e-08],\n               [1.8280e-08, 1.7281e-08, 1.4456e-08],\n               [1.6627e-08, 1.6629e-08, 1.2612e-08]],\n     \n              [[9.7615e-09, 1.3488e-08, 1.4978e-08],\n               [9.5425e-09, 2.0664e-08, 2.1375e-08],\n               [1.0847e-08, 1.9917e-08, 1.7303e-08]],\n     \n              [[4.3988e-09, 4.4139e-09, 7.7879e-09],\n               [5.0630e-09, 4.9756e-09, 8.3534e-09],\n               [6.3611e-09, 6.9958e-09, 1.0550e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[2.1532e-09, 3.6899e-09, 2.7758e-09],\n               [3.2344e-09, 3.9820e-09, 3.3386e-09],\n               [3.1476e-09, 4.5004e-09, 2.7563e-09]],\n     \n              [[8.2882e-09, 1.3416e-08, 1.0098e-08],\n               [1.2602e-08, 1.3362e-08, 1.2238e-08],\n               [1.0321e-08, 1.3499e-08, 1.3094e-08]],\n     \n              [[7.0203e-09, 9.3535e-09, 7.8888e-09],\n               [5.0447e-09, 6.4962e-09, 7.2638e-09],\n               [4.0691e-09, 3.9338e-09, 4.9240e-09]],\n     \n              ...,\n     \n              [[1.1046e-08, 5.1894e-09, 4.3485e-09],\n               [8.9044e-09, 5.5321e-09, 5.6387e-09],\n               [6.0617e-09, 5.0935e-09, 5.9211e-09]],\n     \n              [[7.4943e-09, 1.1430e-08, 1.0966e-08],\n               [1.2092e-08, 1.7589e-08, 1.5064e-08],\n               [1.0267e-08, 1.2141e-08, 1.0735e-08]],\n     \n              [[4.8162e-09, 5.9955e-09, 5.0063e-09],\n               [4.2563e-09, 5.8274e-09, 5.7913e-09],\n               [5.0733e-09, 6.3621e-09, 5.8597e-09]]],\n     \n     \n             [[[2.7297e-09, 3.6410e-09, 3.0627e-09],\n               [3.3422e-09, 5.4097e-09, 4.2680e-09],\n               [3.3550e-09, 4.7427e-09, 3.9326e-09]],\n     \n              [[8.1418e-09, 1.0008e-08, 1.0027e-08],\n               [1.0725e-08, 1.1182e-08, 1.3405e-08],\n               [8.2745e-09, 7.6408e-09, 8.6083e-09]],\n     \n              [[6.6004e-09, 8.2982e-09, 7.4324e-09],\n               [1.0104e-08, 1.2035e-08, 7.2808e-09],\n               [7.3024e-09, 9.2273e-09, 6.5196e-09]],\n     \n              ...,\n     \n              [[3.7046e-09, 2.9910e-09, 3.2009e-09],\n               [2.9416e-09, 2.3565e-09, 2.2476e-09],\n               [2.2457e-09, 2.4291e-09, 2.9474e-09]],\n     \n              [[1.2418e-08, 1.6132e-08, 1.2859e-08],\n               [1.4081e-08, 1.4311e-08, 1.1584e-08],\n               [9.8371e-09, 1.2944e-08, 1.1805e-08]],\n     \n              [[4.6943e-09, 6.9713e-09, 6.7815e-09],\n               [6.3449e-09, 9.9657e-09, 7.2577e-09],\n               [5.1942e-09, 6.4566e-09, 6.5951e-09]]],\n     \n     \n             [[[9.9649e-10, 1.5751e-09, 1.0057e-09],\n               [1.0215e-09, 2.0117e-09, 1.2938e-09],\n               [1.1835e-09, 2.8830e-09, 1.2989e-09]],\n     \n              [[4.8598e-09, 6.7029e-09, 7.0659e-09],\n               [5.7765e-09, 5.0683e-09, 6.5825e-09],\n               [7.7664e-09, 5.7363e-09, 4.8030e-09]],\n     \n              [[7.8580e-09, 9.2702e-09, 7.8647e-09],\n               [9.2143e-09, 9.1667e-09, 9.8853e-09],\n               [7.4659e-09, 8.5152e-09, 9.6335e-09]],\n     \n              ...,\n     \n              [[1.7611e-09, 3.6683e-09, 2.1989e-09],\n               [3.3628e-09, 7.3979e-09, 4.4883e-09],\n               [3.0809e-09, 4.6028e-09, 3.6426e-09]],\n     \n              [[6.8907e-09, 7.0794e-09, 6.2617e-09],\n               [7.1876e-09, 6.0079e-09, 6.3226e-09],\n               [4.7706e-09, 7.8384e-09, 8.8582e-09]],\n     \n              [[3.2585e-09, 3.8772e-09, 2.5521e-09],\n               [4.9628e-09, 3.2282e-09, 3.2576e-09],\n               [2.9879e-09, 3.7662e-09, 4.1327e-09]]]])},\n    125: {'exp_avg': tensor([[[[ 3.1560e-07]],\n     \n              [[-1.4450e-05]],\n     \n              [[-1.0521e-04]],\n     \n              ...,\n     \n              [[-6.5038e-05]],\n     \n              [[-7.3807e-05]],\n     \n              [[-8.5511e-05]]],\n     \n     \n             [[[ 2.3008e-04]],\n     \n              [[-6.9461e-05]],\n     \n              [[ 3.6293e-04]],\n     \n              ...,\n     \n              [[ 7.0039e-05]],\n     \n              [[-1.6028e-05]],\n     \n              [[-2.0435e-05]]],\n     \n     \n             [[[ 1.0952e-05]],\n     \n              [[-4.0352e-05]],\n     \n              [[-1.3034e-05]],\n     \n              ...,\n     \n              [[-2.6385e-05]],\n     \n              [[ 2.1484e-05]],\n     \n              [[ 1.1425e-06]]],\n     \n     \n             ...,\n     \n     \n             [[[-4.1737e-06]],\n     \n              [[-2.6999e-06]],\n     \n              [[-8.2742e-05]],\n     \n              ...,\n     \n              [[-7.5749e-06]],\n     \n              [[-3.0197e-05]],\n     \n              [[ 2.8639e-05]]],\n     \n     \n             [[[ 5.9752e-07]],\n     \n              [[ 4.0712e-06]],\n     \n              [[ 6.9366e-07]],\n     \n              ...,\n     \n              [[-1.5345e-06]],\n     \n              [[ 1.4724e-06]],\n     \n              [[ 3.6037e-07]]],\n     \n     \n             [[[-3.6645e-06]],\n     \n              [[-7.9588e-05]],\n     \n              [[ 5.6862e-05]],\n     \n              ...,\n     \n              [[ 2.2321e-05]],\n     \n              [[-8.4977e-06]],\n     \n              [[-3.1809e-05]]]]),\n     'exp_avg_sq': tensor([[[[2.2031e-08]],\n     \n              [[1.5449e-08]],\n     \n              [[2.9506e-08]],\n     \n              ...,\n     \n              [[1.9348e-08]],\n     \n              [[2.0333e-08]],\n     \n              [[5.0603e-09]]],\n     \n     \n             [[[2.8514e-08]],\n     \n              [[7.4848e-09]],\n     \n              [[2.4685e-07]],\n     \n              ...,\n     \n              [[1.7046e-08]],\n     \n              [[1.4759e-08]],\n     \n              [[8.6222e-09]]],\n     \n     \n             [[[1.5145e-09]],\n     \n              [[1.2408e-09]],\n     \n              [[1.3117e-09]],\n     \n              ...,\n     \n              [[1.1993e-09]],\n     \n              [[1.8560e-09]],\n     \n              [[2.4141e-10]]],\n     \n     \n             ...,\n     \n     \n             [[[6.1686e-09]],\n     \n              [[8.8481e-09]],\n     \n              [[5.7409e-09]],\n     \n              ...,\n     \n              [[8.1933e-09]],\n     \n              [[1.1240e-08]],\n     \n              [[1.7388e-09]]],\n     \n     \n             [[[1.1143e-11]],\n     \n              [[1.4910e-11]],\n     \n              [[8.7076e-12]],\n     \n              ...,\n     \n              [[1.0560e-11]],\n     \n              [[2.7137e-11]],\n     \n              [[2.7278e-12]]],\n     \n     \n             [[[9.4498e-09]],\n     \n              [[1.0024e-08]],\n     \n              [[8.8300e-09]],\n     \n              ...,\n     \n              [[9.8156e-09]],\n     \n              [[1.4584e-08]],\n     \n              [[1.9610e-09]]]])},\n    126: {'exp_avg': tensor([[[[-8.2840e-05]],\n     \n              [[-1.0822e-04]],\n     \n              [[ 1.6004e-05]],\n     \n              ...,\n     \n              [[ 8.5143e-05]],\n     \n              [[-8.6511e-05]],\n     \n              [[-9.4560e-05]]],\n     \n     \n             [[[ 2.6127e-05]],\n     \n              [[ 6.0057e-04]],\n     \n              [[ 6.6115e-05]],\n     \n              ...,\n     \n              [[-3.4183e-05]],\n     \n              [[-1.1135e-04]],\n     \n              [[ 9.0464e-05]]],\n     \n     \n             [[[ 1.2193e-05]],\n     \n              [[-4.5945e-05]],\n     \n              [[ 3.3290e-05]],\n     \n              ...,\n     \n              [[-7.7986e-05]],\n     \n              [[-8.7297e-05]],\n     \n              [[-7.9321e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 1.3782e-05]],\n     \n              [[-1.5250e-05]],\n     \n              [[ 2.7044e-05]],\n     \n              ...,\n     \n              [[ 6.9770e-06]],\n     \n              [[-1.7416e-04]],\n     \n              [[ 6.4528e-05]]],\n     \n     \n             [[[-1.5541e-05]],\n     \n              [[-2.5080e-05]],\n     \n              [[-1.8774e-05]],\n     \n              ...,\n     \n              [[-2.2085e-05]],\n     \n              [[-8.4500e-06]],\n     \n              [[-8.0845e-05]]],\n     \n     \n             [[[ 2.6903e-05]],\n     \n              [[ 3.2186e-04]],\n     \n              [[ 8.2898e-05]],\n     \n              ...,\n     \n              [[-1.6993e-05]],\n     \n              [[ 6.6582e-05]],\n     \n              [[ 3.8061e-05]]]]),\n     'exp_avg_sq': tensor([[[[6.3559e-09]],\n     \n              [[2.5734e-08]],\n     \n              [[1.5024e-08]],\n     \n              ...,\n     \n              [[8.7648e-09]],\n     \n              [[2.5509e-08]],\n     \n              [[1.0593e-08]]],\n     \n     \n             [[[2.2832e-08]],\n     \n              [[7.7318e-07]],\n     \n              [[1.6282e-08]],\n     \n              ...,\n     \n              [[6.9512e-09]],\n     \n              [[2.6462e-08]],\n     \n              [[1.6339e-08]]],\n     \n     \n             [[[5.4510e-09]],\n     \n              [[3.4141e-08]],\n     \n              [[1.3643e-08]],\n     \n              ...,\n     \n              [[1.1024e-08]],\n     \n              [[1.9393e-08]],\n     \n              [[6.9478e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[7.5446e-09]],\n     \n              [[3.3668e-08]],\n     \n              [[9.0560e-09]],\n     \n              ...,\n     \n              [[4.5578e-09]],\n     \n              [[2.0727e-08]],\n     \n              [[5.3827e-09]]],\n     \n     \n             [[[7.8185e-09]],\n     \n              [[3.9775e-08]],\n     \n              [[1.0028e-08]],\n     \n              ...,\n     \n              [[1.0717e-08]],\n     \n              [[1.9663e-08]],\n     \n              [[1.0469e-08]]],\n     \n     \n             [[[7.5307e-09]],\n     \n              [[5.5047e-08]],\n     \n              [[1.0619e-08]],\n     \n              ...,\n     \n              [[5.9338e-09]],\n     \n              [[2.2178e-08]],\n     \n              [[1.0159e-08]]]])},\n    127: {'exp_avg': tensor([[[[-1.8560e-05, -7.2418e-05,  1.2117e-05],\n               [-5.6911e-05, -7.9767e-05,  6.5554e-05],\n               [-4.5528e-05, -3.2318e-05,  1.5482e-05]],\n     \n              [[-1.8441e-06, -3.4980e-05, -2.6725e-05],\n               [-6.9330e-06, -3.7813e-05, -4.0346e-05],\n               [-4.2932e-05, -6.6559e-05, -3.7962e-05]],\n     \n              [[-7.5517e-06, -2.2595e-05, -3.6069e-05],\n               [ 3.6949e-05, -8.4105e-05, -8.7400e-06],\n               [ 2.4265e-05,  1.7411e-05,  4.5680e-05]],\n     \n              ...,\n     \n              [[ 1.4411e-07, -1.2255e-05, -3.0305e-05],\n               [ 4.8575e-05,  3.5467e-05,  1.9353e-05],\n               [ 1.6794e-05, -1.6244e-05, -3.0302e-05]],\n     \n              [[ 6.2187e-05, -1.8045e-05, -6.8576e-06],\n               [ 7.9813e-05, -7.4800e-05, -4.4082e-05],\n               [ 5.7759e-06, -2.0219e-05,  2.1319e-05]],\n     \n              [[-9.1166e-05, -1.2397e-04, -8.3518e-05],\n               [-4.8309e-05, -7.1787e-05, -3.3486e-05],\n               [-3.2950e-05, -5.0235e-05, -4.5516e-05]]],\n     \n     \n             [[[ 2.5314e-05,  8.9238e-05,  4.2554e-05],\n               [-8.8608e-06,  7.8629e-05,  8.4095e-05],\n               [-2.4273e-05, -2.3176e-06,  6.0685e-05]],\n     \n              [[-4.3565e-05, -7.6976e-05, -9.6981e-05],\n               [ 1.6444e-05,  2.1698e-05, -4.5372e-05],\n               [-3.1593e-05, -5.1899e-05, -6.6996e-05]],\n     \n              [[-1.5943e-05, -4.4945e-05, -5.3548e-05],\n               [-1.7881e-05, -5.0099e-05, -3.7130e-05],\n               [-1.8646e-05, -1.6549e-05, -4.7687e-05]],\n     \n              ...,\n     \n              [[-4.2520e-05,  1.2135e-05, -1.0306e-06],\n               [ 3.6937e-05, -1.2814e-05,  2.1840e-05],\n               [ 9.6596e-06,  1.1741e-05,  6.9875e-06]],\n     \n              [[ 5.8002e-05,  7.6586e-06, -3.0613e-05],\n               [-1.3072e-05, -2.4202e-05, -5.5811e-05],\n               [-5.1182e-05, -1.1271e-04, -5.6527e-06]],\n     \n              [[ 3.7238e-06, -6.8646e-05,  1.0489e-05],\n               [-6.8739e-06, -3.3972e-05, -1.1549e-05],\n               [-3.3929e-05, -1.1879e-05, -4.7858e-05]]],\n     \n     \n             [[[-9.7562e-05, -6.2169e-05, -2.1856e-05],\n               [-6.8964e-05,  1.2459e-05, -4.9871e-05],\n               [ 9.5585e-05,  9.1884e-05, -1.5948e-05]],\n     \n              [[-7.9620e-05, -4.2316e-05, -3.0550e-05],\n               [-8.3044e-05, -3.7728e-05,  1.7289e-06],\n               [ 3.9296e-05,  3.2179e-06,  2.8972e-05]],\n     \n              [[ 1.7407e-05,  7.1190e-05,  5.7601e-05],\n               [-9.1375e-06,  7.6613e-05, -2.2262e-05],\n               [-6.5622e-06,  2.0046e-05, -5.1050e-06]],\n     \n              ...,\n     \n              [[-1.7194e-05, -5.2919e-05, -1.5094e-05],\n               [ 7.9308e-06,  2.4345e-05,  2.7881e-05],\n               [ 4.3144e-06, -6.7973e-05,  2.3782e-05]],\n     \n              [[-4.1852e-05, -4.2580e-05, -7.5573e-05],\n               [-3.9270e-05, -3.9081e-05,  9.2321e-06],\n               [-2.5698e-05,  1.7683e-05, -3.6411e-05]],\n     \n              [[ 5.3302e-05, -9.9557e-06, -4.6571e-06],\n               [ 3.0908e-06, -2.6997e-05, -2.6630e-05],\n               [ 4.5030e-05,  1.2276e-05,  3.1961e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 4.6998e-05,  1.3953e-04, -3.1048e-05],\n               [-1.9443e-05,  6.0505e-06,  4.0091e-05],\n               [-7.5670e-05, -6.6910e-05, -2.3487e-05]],\n     \n              [[ 4.3507e-05,  4.8573e-05, -8.5145e-06],\n               [ 8.2373e-06,  3.6305e-05, -4.1470e-06],\n               [ 3.9701e-05, -3.3811e-05, -2.6086e-05]],\n     \n              [[-2.0548e-05,  3.6620e-05,  1.4968e-05],\n               [ 4.1215e-05,  1.8394e-05, -6.4836e-07],\n               [ 7.9261e-06, -1.1537e-06, -2.7010e-05]],\n     \n              ...,\n     \n              [[ 4.4367e-05,  9.4485e-05,  1.3877e-05],\n               [ 3.0693e-05,  6.3949e-05, -3.5315e-05],\n               [ 5.5980e-05,  1.9168e-05,  3.2759e-05]],\n     \n              [[ 1.1661e-05,  3.6612e-05,  1.1900e-04],\n               [-7.2469e-06, -4.0546e-05,  2.8559e-05],\n               [ 1.8444e-05,  1.3322e-05,  6.7366e-05]],\n     \n              [[ 3.9150e-05,  3.1249e-05, -5.6903e-05],\n               [-2.0345e-05, -2.3229e-05, -3.1571e-05],\n               [ 7.2168e-06, -5.3158e-05, -3.6945e-05]]],\n     \n     \n             [[[-8.1625e-05,  2.9844e-05,  2.8118e-06],\n               [-2.3043e-05,  4.7930e-05,  1.6713e-05],\n               [ 5.9872e-07,  5.1995e-05,  4.9765e-05]],\n     \n              [[-3.5441e-05, -1.1904e-05,  1.2401e-05],\n               [ 2.1666e-05,  1.7103e-05,  2.4810e-05],\n               [-1.0607e-05,  8.7902e-05, -1.8077e-05]],\n     \n              [[ 2.8385e-05,  2.8803e-05,  7.7484e-06],\n               [-6.9315e-05, -2.0503e-05, -6.6214e-05],\n               [-1.0514e-04, -1.0886e-04, -2.2955e-05]],\n     \n              ...,\n     \n              [[-1.2200e-04, -5.9088e-05,  1.3488e-05],\n               [-3.3021e-05, -7.2951e-05,  2.1246e-05],\n               [ 9.3161e-06, -1.0526e-05,  4.6485e-05]],\n     \n              [[-6.0024e-06, -1.4944e-05,  5.4255e-05],\n               [-8.6682e-06, -2.3722e-05,  2.0383e-05],\n               [-6.9207e-06, -3.9899e-05, -1.0910e-04]],\n     \n              [[ 8.1087e-06,  3.9446e-05,  4.6460e-05],\n               [ 4.7200e-05,  8.9418e-05,  1.2212e-05],\n               [ 7.0125e-05,  1.7363e-04,  2.4143e-05]]],\n     \n     \n             [[[-1.4150e-05, -2.7442e-05, -1.8990e-05],\n               [ 1.3424e-05,  7.2262e-05,  6.9388e-06],\n               [-6.5249e-05, -2.7889e-05,  1.1048e-06]],\n     \n              [[-1.3531e-05, -3.8669e-05,  6.9849e-06],\n               [ 4.0191e-06, -2.4752e-05, -5.5580e-05],\n               [ 3.6146e-05, -1.5252e-05, -5.8165e-05]],\n     \n              [[ 6.9378e-06,  2.2254e-05,  3.7269e-05],\n               [ 1.4229e-05,  5.6367e-05, -2.8995e-05],\n               [ 2.4040e-05,  3.1204e-05, -1.8645e-05]],\n     \n              ...,\n     \n              [[-6.1345e-05, -5.8977e-05, -7.8322e-05],\n               [-1.0530e-05, -1.9624e-05, -3.1112e-05],\n               [-2.6000e-06, -7.0091e-05, -2.4802e-05]],\n     \n              [[-3.1807e-05, -4.9950e-05, -5.2775e-06],\n               [-3.0031e-05, -4.9886e-05, -4.5957e-05],\n               [-3.3926e-05, -3.0546e-05, -4.2483e-05]],\n     \n              [[-4.5982e-05, -6.7219e-05, -2.9761e-05],\n               [-4.6878e-05, -4.7767e-05, -2.7174e-05],\n               [-4.3405e-05, -1.6033e-05,  1.3413e-05]]]]),\n     'exp_avg_sq': tensor([[[[1.1028e-08, 9.1674e-09, 6.5518e-09],\n               [1.3096e-08, 1.1669e-08, 1.0872e-08],\n               [1.2132e-08, 9.2296e-09, 1.0659e-08]],\n     \n              [[5.6762e-09, 5.7857e-09, 5.3299e-09],\n               [6.5446e-09, 7.1889e-09, 6.9316e-09],\n               [6.2717e-09, 7.1355e-09, 7.2457e-09]],\n     \n              [[3.8703e-09, 4.2997e-09, 3.2082e-09],\n               [3.0041e-09, 5.1012e-09, 3.3818e-09],\n               [2.7693e-09, 3.4664e-09, 3.9586e-09]],\n     \n              ...,\n     \n              [[5.3881e-09, 5.3501e-09, 4.4913e-09],\n               [5.3865e-09, 6.6475e-09, 5.6962e-09],\n               [4.3395e-09, 5.5530e-09, 4.4901e-09]],\n     \n              [[9.4047e-09, 8.7721e-09, 5.6822e-09],\n               [1.2015e-08, 8.5651e-09, 6.1881e-09],\n               [1.0236e-08, 9.5951e-09, 6.7963e-09]],\n     \n              [[2.2819e-09, 3.5257e-09, 2.5426e-09],\n               [3.3410e-09, 4.2875e-09, 2.9989e-09],\n               [2.6506e-09, 4.2547e-09, 2.9736e-09]]],\n     \n     \n             [[[6.9097e-09, 8.3990e-09, 7.7619e-09],\n               [7.5360e-09, 9.5003e-09, 9.1205e-09],\n               [6.7483e-09, 7.9741e-09, 8.1351e-09]],\n     \n              [[4.9004e-09, 3.8227e-09, 4.1558e-09],\n               [5.7042e-09, 4.7991e-09, 4.9493e-09],\n               [5.3411e-09, 5.3068e-09, 4.5845e-09]],\n     \n              [[2.6108e-09, 3.0250e-09, 2.8665e-09],\n               [3.1858e-09, 3.3546e-09, 3.2300e-09],\n               [4.2036e-09, 2.6884e-09, 2.6124e-09]],\n     \n              ...,\n     \n              [[3.7212e-09, 3.7458e-09, 3.5850e-09],\n               [3.7567e-09, 3.2824e-09, 3.3799e-09],\n               [4.9181e-09, 4.2866e-09, 3.7847e-09]],\n     \n              [[6.4419e-09, 5.1383e-09, 5.1426e-09],\n               [6.6043e-09, 4.5953e-09, 5.7298e-09],\n               [5.8379e-09, 5.9115e-09, 5.6677e-09]],\n     \n              [[2.2047e-09, 2.1360e-09, 1.2957e-09],\n               [2.5767e-09, 2.8134e-09, 1.7469e-09],\n               [2.8262e-09, 3.0321e-09, 2.1238e-09]]],\n     \n     \n             [[[1.2093e-08, 1.1911e-08, 8.5870e-09],\n               [1.6199e-08, 1.3723e-08, 9.5011e-09],\n               [1.3051e-08, 1.1226e-08, 9.7266e-09]],\n     \n              [[6.6617e-09, 7.5871e-09, 7.1547e-09],\n               [8.7801e-09, 1.0417e-08, 1.1023e-08],\n               [6.4664e-09, 6.7239e-09, 6.9493e-09]],\n     \n              [[3.5598e-09, 4.4067e-09, 3.6101e-09],\n               [4.0317e-09, 6.4859e-09, 4.9493e-09],\n               [3.7341e-09, 5.9315e-09, 3.8682e-09]],\n     \n              ...,\n     \n              [[4.4015e-09, 5.7078e-09, 5.0875e-09],\n               [5.6711e-09, 9.7576e-09, 7.0762e-09],\n               [4.0641e-09, 6.4522e-09, 5.8350e-09]],\n     \n              [[1.2141e-08, 1.2281e-08, 1.2175e-08],\n               [1.2914e-08, 1.3391e-08, 1.3609e-08],\n               [1.1540e-08, 1.2656e-08, 1.4241e-08]],\n     \n              [[3.2704e-09, 3.2464e-09, 3.6108e-09],\n               [4.2855e-09, 4.5823e-09, 3.9241e-09],\n               [3.5954e-09, 5.0706e-09, 3.3419e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[7.3624e-09, 1.1057e-08, 1.1056e-08],\n               [7.6383e-09, 6.3412e-09, 1.0265e-08],\n               [6.7456e-09, 6.9688e-09, 6.6582e-09]],\n     \n              [[4.2170e-09, 5.5461e-09, 6.2003e-09],\n               [3.5915e-09, 4.7818e-09, 7.0919e-09],\n               [4.1328e-09, 5.0949e-09, 5.2196e-09]],\n     \n              [[3.8245e-09, 3.7009e-09, 2.3032e-09],\n               [4.1957e-09, 3.6370e-09, 1.8461e-09],\n               [2.3227e-09, 1.8532e-09, 1.6769e-09]],\n     \n              ...,\n     \n              [[4.1779e-09, 3.8989e-09, 5.6347e-09],\n               [4.9570e-09, 3.2540e-09, 5.8153e-09],\n               [5.8017e-09, 5.1027e-09, 5.0128e-09]],\n     \n              [[4.0587e-09, 6.0595e-09, 8.9781e-09],\n               [3.4256e-09, 7.6304e-09, 1.0137e-08],\n               [3.8109e-09, 5.6378e-09, 5.4450e-09]],\n     \n              [[3.4336e-09, 2.9652e-09, 2.9605e-09],\n               [2.7700e-09, 2.0237e-09, 2.4354e-09],\n               [2.6215e-09, 2.1840e-09, 2.0172e-09]]],\n     \n     \n             [[[1.0839e-08, 9.1489e-09, 9.1918e-09],\n               [1.3714e-08, 1.5134e-08, 1.0777e-08],\n               [1.1570e-08, 9.9239e-09, 8.2901e-09]],\n     \n              [[5.3383e-09, 5.4452e-09, 5.8015e-09],\n               [6.0890e-09, 6.7110e-09, 6.7441e-09],\n               [5.0239e-09, 5.9666e-09, 5.5850e-09]],\n     \n              [[3.6602e-09, 4.5340e-09, 3.8313e-09],\n               [3.2438e-09, 3.6197e-09, 3.5187e-09],\n               [4.4586e-09, 8.0296e-09, 5.0806e-09]],\n     \n              ...,\n     \n              [[5.4186e-09, 5.6695e-09, 5.6445e-09],\n               [6.6572e-09, 8.7769e-09, 6.4744e-09],\n               [4.2733e-09, 7.0112e-09, 6.3806e-09]],\n     \n              [[8.8044e-09, 1.1768e-08, 1.0139e-08],\n               [1.0072e-08, 1.1919e-08, 1.0930e-08],\n               [7.9824e-09, 8.6367e-09, 7.8169e-09]],\n     \n              [[2.8647e-09, 3.1793e-09, 3.5311e-09],\n               [3.8920e-09, 6.7971e-09, 4.4374e-09],\n               [4.0319e-09, 7.8781e-09, 4.6264e-09]]],\n     \n     \n             [[[5.8747e-09, 9.3211e-09, 1.0683e-08],\n               [6.2462e-09, 1.1271e-08, 1.3401e-08],\n               [5.0159e-09, 7.2269e-09, 9.9596e-09]],\n     \n              [[4.9364e-09, 5.6371e-09, 4.1150e-09],\n               [4.6307e-09, 6.1778e-09, 5.6802e-09],\n               [4.0704e-09, 4.8864e-09, 5.4546e-09]],\n     \n              [[1.7027e-09, 2.8344e-09, 4.5219e-09],\n               [1.3740e-09, 2.8543e-09, 5.6113e-09],\n               [1.5943e-09, 2.3262e-09, 3.6777e-09]],\n     \n              ...,\n     \n              [[3.6727e-09, 3.7914e-09, 4.9883e-09],\n               [4.8785e-09, 3.5224e-09, 4.6725e-09],\n               [3.3503e-09, 2.4796e-09, 3.6011e-09]],\n     \n              [[5.1642e-09, 4.8844e-09, 5.4521e-09],\n               [4.3937e-09, 5.9281e-09, 9.2878e-09],\n               [3.4523e-09, 6.7670e-09, 1.2263e-08]],\n     \n              [[2.2326e-09, 4.0838e-09, 3.3833e-09],\n               [2.5599e-09, 4.8612e-09, 3.8792e-09],\n               [2.3387e-09, 3.1843e-09, 2.6048e-09]]]])},\n    128: {'exp_avg': tensor([[[[-4.1870e-07]],\n     \n              [[-7.4590e-07]],\n     \n              [[ 4.1671e-05]],\n     \n              ...,\n     \n              [[ 4.7538e-05]],\n     \n              [[-9.9555e-06]],\n     \n              [[-3.4691e-05]]],\n     \n     \n             [[[ 9.7647e-05]],\n     \n              [[-3.8772e-05]],\n     \n              [[-1.1387e-04]],\n     \n              ...,\n     \n              [[ 1.1478e-04]],\n     \n              [[ 5.4299e-05]],\n     \n              [[ 9.8169e-05]]],\n     \n     \n             [[[-7.1695e-05]],\n     \n              [[-3.7534e-05]],\n     \n              [[-7.9440e-05]],\n     \n              ...,\n     \n              [[ 8.3359e-05]],\n     \n              [[ 1.1164e-04]],\n     \n              [[ 9.9909e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-5.7900e-05]],\n     \n              [[ 4.1429e-05]],\n     \n              [[-5.3216e-05]],\n     \n              ...,\n     \n              [[ 9.6545e-06]],\n     \n              [[ 1.1086e-04]],\n     \n              [[ 1.0588e-04]]],\n     \n     \n             [[[ 2.1846e-05]],\n     \n              [[-3.4379e-05]],\n     \n              [[-3.7476e-05]],\n     \n              ...,\n     \n              [[ 3.2001e-06]],\n     \n              [[ 3.7157e-06]],\n     \n              [[-2.0111e-05]]],\n     \n     \n             [[[-2.3970e-05]],\n     \n              [[-1.2132e-04]],\n     \n              [[ 1.2499e-04]],\n     \n              ...,\n     \n              [[-3.2947e-05]],\n     \n              [[ 6.5958e-05]],\n     \n              [[-2.9851e-04]]]]),\n     'exp_avg_sq': tensor([[[[6.9940e-09]],\n     \n              [[5.5294e-09]],\n     \n              [[6.0407e-09]],\n     \n              ...,\n     \n              [[3.7581e-09]],\n     \n              [[5.4090e-09]],\n     \n              [[8.0612e-09]]],\n     \n     \n             [[[2.8379e-08]],\n     \n              [[4.3475e-08]],\n     \n              [[2.5771e-08]],\n     \n              ...,\n     \n              [[1.4316e-08]],\n     \n              [[2.0959e-08]],\n     \n              [[2.2084e-08]]],\n     \n     \n             [[[1.0095e-08]],\n     \n              [[7.0999e-09]],\n     \n              [[7.5273e-09]],\n     \n              ...,\n     \n              [[5.8440e-09]],\n     \n              [[6.1401e-09]],\n     \n              [[9.5103e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[1.0864e-08]],\n     \n              [[9.5039e-09]],\n     \n              [[2.0286e-08]],\n     \n              ...,\n     \n              [[5.7276e-09]],\n     \n              [[2.0726e-08]],\n     \n              [[9.1087e-09]]],\n     \n     \n             [[[1.2305e-09]],\n     \n              [[5.5274e-10]],\n     \n              [[6.5291e-10]],\n     \n              ...,\n     \n              [[3.3580e-10]],\n     \n              [[5.0838e-10]],\n     \n              [[1.0366e-09]]],\n     \n     \n             [[[2.5074e-08]],\n     \n              [[1.5696e-08]],\n     \n              [[1.6526e-08]],\n     \n              ...,\n     \n              [[1.0087e-08]],\n     \n              [[1.4590e-08]],\n     \n              [[3.1192e-08]]]])},\n    129: {'exp_avg': tensor([[[[ 1.4727e-04]],\n     \n              [[ 1.3867e-04]],\n     \n              [[-2.1358e-05]],\n     \n              ...,\n     \n              [[-7.7511e-05]],\n     \n              [[ 9.8499e-06]],\n     \n              [[-2.5707e-05]]],\n     \n     \n             [[[ 5.7643e-05]],\n     \n              [[ 1.5779e-04]],\n     \n              [[-1.5393e-04]],\n     \n              ...,\n     \n              [[ 3.3565e-05]],\n     \n              [[ 1.3826e-04]],\n     \n              [[-8.2949e-05]]],\n     \n     \n             [[[ 5.6586e-05]],\n     \n              [[ 2.1788e-04]],\n     \n              [[-3.6642e-05]],\n     \n              ...,\n     \n              [[ 1.1226e-06]],\n     \n              [[ 2.2510e-06]],\n     \n              [[-8.0948e-06]]],\n     \n     \n             ...,\n     \n     \n             [[[-3.7028e-06]],\n     \n              [[ 2.9465e-05]],\n     \n              [[ 1.4368e-05]],\n     \n              ...,\n     \n              [[-1.1068e-06]],\n     \n              [[-2.0510e-05]],\n     \n              [[-1.1562e-05]]],\n     \n     \n             [[[-2.4199e-05]],\n     \n              [[ 1.0376e-05]],\n     \n              [[ 1.8285e-04]],\n     \n              ...,\n     \n              [[ 4.1889e-05]],\n     \n              [[ 6.7819e-05]],\n     \n              [[-1.7740e-04]]],\n     \n     \n             [[[ 1.0628e-04]],\n     \n              [[-2.2016e-05]],\n     \n              [[ 1.3514e-04]],\n     \n              ...,\n     \n              [[-6.7643e-05]],\n     \n              [[-1.5837e-06]],\n     \n              [[ 1.0518e-05]]]]),\n     'exp_avg_sq': tensor([[[[1.7339e-08]],\n     \n              [[1.0027e-07]],\n     \n              [[1.7114e-08]],\n     \n              ...,\n     \n              [[1.2863e-08]],\n     \n              [[1.9884e-08]],\n     \n              [[2.6561e-08]]],\n     \n     \n             [[[1.1823e-08]],\n     \n              [[3.7409e-08]],\n     \n              [[1.4108e-08]],\n     \n              ...,\n     \n              [[1.2971e-08]],\n     \n              [[2.0330e-08]],\n     \n              [[1.0964e-08]]],\n     \n     \n             [[[1.1003e-08]],\n     \n              [[6.9460e-08]],\n     \n              [[1.2839e-08]],\n     \n              ...,\n     \n              [[8.0403e-09]],\n     \n              [[1.5521e-08]],\n     \n              [[1.0965e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[9.6003e-09]],\n     \n              [[4.1266e-08]],\n     \n              [[1.1369e-08]],\n     \n              ...,\n     \n              [[7.3593e-09]],\n     \n              [[1.4206e-08]],\n     \n              [[1.1908e-08]]],\n     \n     \n             [[[1.6209e-08]],\n     \n              [[1.0394e-07]],\n     \n              [[2.4701e-08]],\n     \n              ...,\n     \n              [[1.1300e-08]],\n     \n              [[2.8737e-08]],\n     \n              [[3.1635e-08]]],\n     \n     \n             [[[8.0418e-09]],\n     \n              [[5.4264e-09]],\n     \n              [[1.2537e-08]],\n     \n              ...,\n     \n              [[8.9643e-09]],\n     \n              [[1.0134e-08]],\n     \n              [[1.2233e-08]]]])},\n    130: {'exp_avg': tensor([[[[-5.9744e-05, -7.4192e-05,  2.0471e-05],\n               [-2.8448e-05,  1.7800e-06,  1.7631e-05],\n               [-1.1984e-04, -5.9433e-05, -1.2436e-04]],\n     \n              [[ 5.9507e-05,  1.2934e-04,  1.6846e-05],\n               [ 3.1983e-05, -5.7545e-05,  1.6738e-05],\n               [ 1.9008e-05, -1.0971e-05,  4.0755e-06]],\n     \n              [[-1.4805e-05, -8.4874e-05, -1.9437e-05],\n               [ 2.8697e-05,  4.4921e-06, -1.2751e-05],\n               [ 6.9241e-06, -5.9702e-07,  2.2444e-05]],\n     \n              ...,\n     \n              [[ 2.3553e-05, -5.8814e-06, -1.3945e-05],\n               [ 7.5502e-05, -2.3220e-05,  8.7386e-05],\n               [-2.3829e-05,  4.9550e-06,  2.8252e-05]],\n     \n              [[ 6.6832e-05,  8.1427e-05,  2.3101e-05],\n               [-1.8222e-05,  2.7250e-05,  3.8036e-06],\n               [-3.0475e-06,  1.2753e-06, -4.7622e-05]],\n     \n              [[ 1.5385e-05,  8.7590e-08,  4.8394e-05],\n               [-7.1029e-06,  2.3333e-05,  6.6228e-05],\n               [-1.6238e-05,  5.5134e-05,  7.0645e-05]]],\n     \n     \n             [[[ 3.2615e-05,  3.4941e-06,  8.4848e-06],\n               [ 2.4713e-05,  6.7161e-05,  6.8045e-05],\n               [-5.8133e-05,  1.0450e-05,  7.0149e-06]],\n     \n              [[ 8.5787e-05,  5.3083e-05,  8.5075e-05],\n               [ 8.8302e-05, -1.0375e-04, -2.2569e-05],\n               [ 7.5932e-05,  8.0053e-05,  3.7866e-05]],\n     \n              [[ 4.8970e-06, -3.1031e-05, -1.0226e-05],\n               [-1.7473e-05,  2.2799e-06, -8.5023e-06],\n               [ 1.5105e-05, -4.6264e-05, -7.3257e-06]],\n     \n              ...,\n     \n              [[ 4.5988e-05,  7.6696e-05, -1.4496e-05],\n               [ 3.2245e-05,  8.3724e-05,  8.5644e-06],\n               [-1.6051e-05,  6.2215e-06, -2.9656e-05]],\n     \n              [[ 1.7810e-05, -6.7069e-06,  1.4331e-05],\n               [-2.9089e-06, -5.6309e-05, -2.4490e-05],\n               [-2.1291e-06, -2.3147e-06, -4.0769e-05]],\n     \n              [[ 3.2787e-05,  3.0205e-05, -9.3373e-05],\n               [-9.4663e-06, -9.0832e-05, -2.0916e-05],\n               [ 2.2092e-05, -5.2233e-05, -5.7066e-05]]],\n     \n     \n             [[[ 6.9038e-05, -3.2701e-05,  1.0334e-04],\n               [-9.6845e-05, -3.2315e-05, -1.9576e-05],\n               [ 4.7885e-05,  2.0806e-05,  4.6892e-05]],\n     \n              [[-4.9099e-05,  7.4240e-05, -1.2016e-04],\n               [-9.3200e-05,  2.7758e-05, -1.2085e-04],\n               [-6.4643e-05, -6.1685e-06, -5.3259e-06]],\n     \n              [[-2.7226e-05, -9.4708e-06, -1.2660e-05],\n               [-5.0345e-05, -8.8296e-05, -4.1064e-05],\n               [ 5.6147e-06,  4.2166e-06,  3.5232e-05]],\n     \n              ...,\n     \n              [[ 6.4806e-05,  4.6596e-06,  5.4327e-05],\n               [ 2.9389e-05, -1.2810e-05,  4.4423e-05],\n               [-1.7711e-05,  2.1231e-05,  6.5669e-06]],\n     \n              [[ 2.0632e-05,  4.9895e-06,  3.7659e-06],\n               [-6.9649e-06, -1.0731e-05, -5.9455e-05],\n               [-3.6968e-06,  2.3115e-05, -1.3526e-05]],\n     \n              [[-8.1728e-07, -8.3631e-05, -6.9340e-05],\n               [ 2.7686e-05, -3.2453e-05, -3.3232e-05],\n               [-3.1265e-05, -1.2527e-04, -1.1347e-04]]],\n     \n     \n             ...,\n     \n     \n             [[[-1.4769e-05,  8.6173e-05,  2.8109e-05],\n               [ 7.2082e-05, -5.0623e-06,  1.0590e-04],\n               [ 8.7670e-05,  7.9717e-05,  2.0056e-04]],\n     \n              [[-7.6448e-06,  3.0498e-05, -4.6206e-05],\n               [ 2.2863e-05,  6.9929e-05, -6.0966e-05],\n               [ 4.5046e-05,  5.4518e-05, -5.8872e-05]],\n     \n              [[-1.0013e-05, -2.6641e-05, -1.6900e-06],\n               [ 1.3023e-06,  1.2433e-05,  4.2079e-05],\n               [-4.1963e-06,  3.0788e-05,  5.6937e-05]],\n     \n              ...,\n     \n              [[-5.2844e-05, -7.5962e-05,  1.1091e-05],\n               [-2.5231e-05,  3.0679e-05,  1.8375e-05],\n               [-1.8024e-05, -7.6097e-06,  8.4027e-07]],\n     \n              [[ 2.2461e-05,  9.3181e-06,  8.1453e-06],\n               [-1.5041e-05, -1.5667e-05, -4.1787e-05],\n               [-1.5609e-05, -3.5260e-05, -1.0363e-05]],\n     \n              [[ 4.5259e-06,  6.0547e-05, -6.8437e-06],\n               [-6.9969e-05, -4.8036e-05, -1.9649e-05],\n               [ 1.4849e-05, -4.3357e-05,  2.3634e-05]]],\n     \n     \n             [[[ 4.0851e-06, -6.0548e-05, -3.5396e-05],\n               [ 1.8903e-05, -2.8999e-05,  1.3779e-05],\n               [ 2.5317e-05,  2.8800e-05, -1.0849e-05]],\n     \n              [[-3.0853e-05, -1.4393e-05,  1.7893e-05],\n               [-4.9928e-05, -1.1651e-05, -6.0015e-05],\n               [ 4.6133e-05,  3.1325e-05,  4.2952e-05]],\n     \n              [[-4.5061e-05, -4.3762e-05, -2.4103e-05],\n               [-2.2296e-05,  3.0345e-06, -2.2566e-05],\n               [-9.7588e-06,  2.0190e-05,  3.3379e-06]],\n     \n              ...,\n     \n              [[ 2.9648e-05, -4.4872e-05,  1.8578e-06],\n               [ 3.7047e-05,  2.6658e-05,  2.6220e-05],\n               [ 6.1807e-06, -5.6964e-07,  1.4773e-06]],\n     \n              [[-2.4479e-06,  3.0214e-06, -4.4609e-06],\n               [-6.4559e-06,  3.0160e-05,  4.1962e-06],\n               [ 2.2897e-05, -1.0102e-05,  6.8070e-06]],\n     \n              [[-5.5124e-07, -3.0849e-05, -8.7560e-05],\n               [ 9.0071e-06, -5.3120e-05, -8.6909e-05],\n               [-2.5536e-06, -6.3068e-05, -7.8005e-05]]],\n     \n     \n             [[[-2.6187e-05,  5.5506e-06,  1.0368e-04],\n               [-9.6748e-05, -2.7806e-05,  6.0746e-05],\n               [-3.5232e-05, -6.3145e-05,  2.8998e-05]],\n     \n              [[ 6.2539e-05,  2.9671e-05,  7.1127e-05],\n               [ 1.0096e-04,  6.4224e-05,  7.2697e-05],\n               [-1.2892e-05, -7.7165e-05, -7.8622e-05]],\n     \n              [[-9.5033e-06,  9.6562e-06,  5.3126e-06],\n               [ 1.3556e-05, -8.5901e-06,  2.5400e-05],\n               [-5.1511e-05, -1.0884e-05,  1.1024e-05]],\n     \n              ...,\n     \n              [[ 9.7852e-06,  1.1055e-05,  1.2670e-05],\n               [ 1.7763e-05, -2.9715e-05, -5.1280e-05],\n               [-3.7527e-06, -6.8688e-05, -4.8936e-05]],\n     \n              [[ 2.4555e-05,  3.4152e-05,  3.5741e-05],\n               [ 5.5369e-06, -4.4649e-05,  1.9939e-05],\n               [ 1.6869e-05, -5.6125e-05, -2.1653e-05]],\n     \n              [[ 2.4600e-05,  2.8512e-05, -2.1859e-05],\n               [-4.1773e-06, -1.3789e-05, -2.4032e-05],\n               [ 3.5036e-05,  1.1307e-05,  4.0044e-05]]]]),\n     'exp_avg_sq': tensor([[[[7.2540e-09, 1.0039e-08, 7.9944e-09],\n               [7.3915e-09, 3.9479e-09, 7.9736e-09],\n               [1.1167e-08, 1.0049e-08, 1.0292e-08]],\n     \n              [[1.0346e-08, 1.1940e-08, 1.2301e-08],\n               [1.3949e-08, 1.2899e-08, 1.7005e-08],\n               [3.1060e-08, 4.1740e-08, 3.6451e-08]],\n     \n              [[3.3511e-09, 5.1460e-09, 2.7198e-09],\n               [2.2501e-09, 1.9721e-09, 2.1621e-09],\n               [4.1947e-09, 2.2603e-09, 3.0559e-09]],\n     \n              ...,\n     \n              [[3.9246e-09, 4.1310e-09, 6.0254e-09],\n               [5.4985e-09, 4.2976e-09, 6.3580e-09],\n               [3.1772e-09, 3.3093e-09, 4.0979e-09]],\n     \n              [[1.2319e-09, 1.5954e-09, 1.2105e-09],\n               [4.2599e-09, 1.0731e-08, 3.7033e-09],\n               [1.0467e-09, 2.2528e-09, 1.2876e-09]],\n     \n              [[8.8961e-09, 1.4720e-08, 1.1602e-08],\n               [7.1821e-09, 1.2898e-08, 7.7522e-09],\n               [6.4099e-09, 7.2227e-09, 5.7530e-09]]],\n     \n     \n             [[[1.0621e-08, 1.2730e-08, 1.0559e-08],\n               [1.0414e-08, 1.3435e-08, 1.0583e-08],\n               [8.0100e-09, 9.6028e-09, 8.3017e-09]],\n     \n              [[9.8011e-09, 1.3072e-08, 1.2655e-08],\n               [1.3716e-08, 1.9200e-08, 1.3931e-08],\n               [9.7988e-09, 1.3881e-08, 1.3118e-08]],\n     \n              [[2.8564e-09, 3.0176e-09, 2.9985e-09],\n               [3.8849e-09, 5.3053e-09, 3.1597e-09],\n               [2.7078e-09, 3.0034e-09, 2.6618e-09]],\n     \n              ...,\n     \n              [[4.1193e-09, 4.5505e-09, 3.0451e-09],\n               [3.7643e-09, 6.9103e-09, 3.7633e-09],\n               [2.9409e-09, 5.8778e-09, 2.7272e-09]],\n     \n              [[8.3937e-10, 1.1624e-09, 9.8356e-10],\n               [1.2949e-09, 6.5566e-09, 1.7876e-09],\n               [9.4836e-10, 1.6310e-09, 1.3082e-09]],\n     \n              [[7.2698e-09, 1.1853e-08, 9.5750e-09],\n               [5.4132e-09, 1.0200e-08, 7.5476e-09],\n               [5.9448e-09, 6.5382e-09, 6.0515e-09]]],\n     \n     \n             [[[9.2468e-09, 1.2803e-08, 8.2826e-09],\n               [1.3880e-08, 1.8178e-08, 1.1832e-08],\n               [7.7333e-09, 9.8787e-09, 7.8450e-09]],\n     \n              [[1.5653e-08, 1.9450e-08, 1.8030e-08],\n               [1.9042e-08, 2.3680e-08, 2.2029e-08],\n               [1.4614e-08, 1.8246e-08, 1.8836e-08]],\n     \n              [[3.3997e-09, 4.1113e-09, 3.6041e-09],\n               [4.3342e-09, 8.9389e-09, 5.0391e-09],\n               [3.3275e-09, 5.0841e-09, 3.3907e-09]],\n     \n              ...,\n     \n              [[4.5202e-09, 5.2942e-09, 4.0620e-09],\n               [7.2556e-09, 8.7321e-09, 5.8275e-09],\n               [3.3177e-09, 4.8920e-09, 2.8274e-09]],\n     \n              [[1.0134e-09, 1.4729e-09, 9.9314e-10],\n               [1.8550e-09, 9.1809e-09, 2.9396e-09],\n               [1.2772e-09, 2.2991e-09, 1.4576e-09]],\n     \n              [[6.1525e-09, 1.0363e-08, 7.7589e-09],\n               [6.7523e-09, 7.4906e-09, 6.7719e-09],\n               [6.5646e-09, 7.6602e-09, 6.8523e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[3.5421e-09, 4.2535e-09, 6.0763e-09],\n               [4.4776e-09, 8.2715e-09, 9.3107e-09],\n               [4.6614e-09, 7.7489e-09, 9.3819e-09]],\n     \n              [[3.1304e-09, 4.9648e-09, 8.1049e-09],\n               [4.1608e-09, 6.9154e-09, 1.0990e-08],\n               [5.3585e-09, 9.6110e-09, 1.2093e-08]],\n     \n              [[1.3733e-09, 2.2000e-09, 2.0088e-09],\n               [1.8268e-09, 3.4878e-09, 2.8657e-09],\n               [1.7503e-09, 2.9492e-09, 3.6595e-09]],\n     \n              ...,\n     \n              [[3.6464e-09, 7.1438e-09, 3.7745e-09],\n               [4.5000e-09, 7.2984e-09, 4.3630e-09],\n               [4.1638e-09, 4.1088e-09, 2.2975e-09]],\n     \n              [[1.6664e-09, 2.0942e-09, 8.2476e-10],\n               [2.7513e-09, 5.3286e-09, 1.4154e-09],\n               [1.4896e-09, 2.0704e-09, 1.0970e-09]],\n     \n              [[5.3187e-09, 4.6242e-09, 4.0754e-09],\n               [5.0529e-09, 4.0423e-09, 5.5703e-09],\n               [3.6062e-09, 5.3867e-09, 8.9949e-09]]],\n     \n     \n             [[[5.6753e-09, 3.8062e-09, 5.1072e-09],\n               [6.7797e-09, 2.5597e-09, 7.0974e-09],\n               [4.7415e-09, 3.3702e-09, 5.2582e-09]],\n     \n              [[7.6395e-09, 1.1037e-08, 6.9075e-09],\n               [7.7623e-09, 1.5270e-08, 7.4548e-09],\n               [5.8230e-09, 9.1704e-09, 6.2306e-09]],\n     \n              [[1.6455e-09, 1.4186e-09, 1.6629e-09],\n               [1.7454e-09, 9.0082e-10, 1.2668e-09],\n               [1.7749e-09, 1.0038e-09, 1.2821e-09]],\n     \n              ...,\n     \n              [[1.5931e-09, 2.3254e-09, 1.9048e-09],\n               [2.3155e-09, 3.2963e-09, 2.5599e-09],\n               [1.6758e-09, 2.8658e-09, 1.7744e-09]],\n     \n              [[5.4542e-10, 5.5196e-10, 5.9092e-10],\n               [6.8939e-10, 1.4999e-09, 1.0369e-09],\n               [5.3983e-10, 6.7461e-10, 8.2792e-10]],\n     \n              [[3.8192e-09, 7.2935e-09, 3.6736e-09],\n               [3.4711e-09, 6.9470e-09, 4.2036e-09],\n               [2.8193e-09, 4.3249e-09, 2.8713e-09]]],\n     \n     \n             [[[5.4919e-09, 7.1771e-09, 6.7631e-09],\n               [7.1564e-09, 9.1542e-09, 7.6414e-09],\n               [6.8641e-09, 9.4530e-09, 6.3187e-09]],\n     \n              [[6.0778e-09, 7.4508e-09, 8.3443e-09],\n               [1.0851e-08, 1.1223e-08, 8.3507e-09],\n               [7.0777e-09, 8.2774e-09, 6.6802e-09]],\n     \n              [[1.4322e-09, 2.1498e-09, 1.7660e-09],\n               [2.1116e-09, 3.6651e-09, 2.1426e-09],\n               [1.5369e-09, 3.1522e-09, 1.8055e-09]],\n     \n              ...,\n     \n              [[1.9937e-09, 2.8120e-09, 2.2642e-09],\n               [2.8030e-09, 4.3965e-09, 2.5819e-09],\n               [1.6188e-09, 2.8785e-09, 1.5873e-09]],\n     \n              [[7.3801e-10, 9.4218e-10, 8.0828e-10],\n               [9.5769e-10, 4.1282e-09, 1.2226e-09],\n               [7.7929e-10, 1.8405e-09, 1.1869e-09]],\n     \n              [[5.6276e-09, 7.7198e-09, 5.5059e-09],\n               [4.0456e-09, 6.5376e-09, 4.4903e-09],\n               [2.7703e-09, 3.3390e-09, 3.0962e-09]]]])},\n    131: {'exp_avg': tensor([[[[ 4.9328e-05]],\n     \n              [[ 9.1909e-05]],\n     \n              [[ 8.1126e-05]],\n     \n              ...,\n     \n              [[ 1.5989e-04]],\n     \n              [[-6.2200e-05]],\n     \n              [[ 8.7589e-05]]],\n     \n     \n             [[[-7.1071e-05]],\n     \n              [[ 8.4671e-05]],\n     \n              [[ 2.2138e-05]],\n     \n              ...,\n     \n              [[-4.4951e-05]],\n     \n              [[-5.4154e-05]],\n     \n              [[-1.5372e-05]]],\n     \n     \n             [[[ 1.2508e-05]],\n     \n              [[-2.7162e-05]],\n     \n              [[ 7.3741e-06]],\n     \n              ...,\n     \n              [[ 2.5308e-05]],\n     \n              [[-3.3138e-05]],\n     \n              [[-2.1046e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-5.7003e-05]],\n     \n              [[ 5.5392e-05]],\n     \n              [[-1.5616e-04]],\n     \n              ...,\n     \n              [[-3.6660e-05]],\n     \n              [[-2.0444e-05]],\n     \n              [[-3.5649e-05]]],\n     \n     \n             [[[-3.4297e-05]],\n     \n              [[-1.4494e-04]],\n     \n              [[ 4.7496e-05]],\n     \n              ...,\n     \n              [[-2.7975e-06]],\n     \n              [[-3.2091e-05]],\n     \n              [[-5.1150e-05]]],\n     \n     \n             [[[ 4.6439e-06]],\n     \n              [[ 2.4818e-05]],\n     \n              [[ 3.2361e-05]],\n     \n              ...,\n     \n              [[ 9.7892e-06]],\n     \n              [[-5.0301e-06]],\n     \n              [[ 2.1704e-05]]]]),\n     'exp_avg_sq': tensor([[[[1.8634e-08]],\n     \n              [[2.9380e-08]],\n     \n              [[2.6150e-08]],\n     \n              ...,\n     \n              [[2.5560e-08]],\n     \n              [[2.1677e-08]],\n     \n              [[2.0233e-08]]],\n     \n     \n             [[[2.2863e-08]],\n     \n              [[2.0810e-08]],\n     \n              [[1.7638e-08]],\n     \n              ...,\n     \n              [[1.5207e-08]],\n     \n              [[1.0846e-08]],\n     \n              [[1.6734e-08]]],\n     \n     \n             [[[4.7721e-10]],\n     \n              [[1.4062e-09]],\n     \n              [[1.8768e-09]],\n     \n              ...,\n     \n              [[7.9713e-10]],\n     \n              [[8.1943e-10]],\n     \n              [[7.5379e-10]]],\n     \n     \n             ...,\n     \n     \n             [[[6.4266e-09]],\n     \n              [[1.1686e-08]],\n     \n              [[1.2496e-08]],\n     \n              ...,\n     \n              [[2.1350e-09]],\n     \n              [[1.7035e-08]],\n     \n              [[6.1729e-09]]],\n     \n     \n             [[[3.3485e-09]],\n     \n              [[9.3795e-09]],\n     \n              [[1.2265e-08]],\n     \n              ...,\n     \n              [[4.1859e-09]],\n     \n              [[5.5795e-09]],\n     \n              [[4.1351e-09]]],\n     \n     \n             [[[1.9640e-09]],\n     \n              [[4.1579e-09]],\n     \n              [[7.0326e-09]],\n     \n              ...,\n     \n              [[2.9973e-09]],\n     \n              [[2.8294e-09]],\n     \n              [[2.8648e-09]]]])},\n    132: {'exp_avg': tensor([[[[-8.4695e-05]],\n     \n              [[-4.4296e-05]],\n     \n              [[-2.5973e-05]],\n     \n              ...,\n     \n              [[-3.1140e-05]],\n     \n              [[-9.3291e-05]],\n     \n              [[-8.6542e-06]]],\n     \n     \n             [[[-4.0593e-05]],\n     \n              [[ 7.9731e-06]],\n     \n              [[ 1.9456e-05]],\n     \n              ...,\n     \n              [[-7.8889e-05]],\n     \n              [[ 3.6602e-05]],\n     \n              [[-4.1044e-06]]],\n     \n     \n             [[[ 3.5232e-05]],\n     \n              [[ 2.3398e-05]],\n     \n              [[-2.6800e-05]],\n     \n              ...,\n     \n              [[-8.0902e-05]],\n     \n              [[ 2.5062e-05]],\n     \n              [[-8.1030e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 1.7193e-05]],\n     \n              [[ 7.6388e-05]],\n     \n              [[-2.2453e-05]],\n     \n              ...,\n     \n              [[ 9.8902e-06]],\n     \n              [[-3.9820e-05]],\n     \n              [[-1.5684e-05]]],\n     \n     \n             [[[ 6.6777e-05]],\n     \n              [[-3.9122e-05]],\n     \n              [[ 4.4883e-05]],\n     \n              ...,\n     \n              [[-2.0422e-05]],\n     \n              [[ 1.5797e-04]],\n     \n              [[ 2.1849e-05]]],\n     \n     \n             [[[ 1.2010e-05]],\n     \n              [[ 6.0741e-05]],\n     \n              [[ 9.8572e-05]],\n     \n              ...,\n     \n              [[ 4.5726e-05]],\n     \n              [[-7.2732e-05]],\n     \n              [[-3.3875e-06]]]]),\n     'exp_avg_sq': tensor([[[[1.3487e-08]],\n     \n              [[2.7751e-09]],\n     \n              [[7.7251e-09]],\n     \n              ...,\n     \n              [[2.6944e-09]],\n     \n              [[2.3327e-08]],\n     \n              [[1.1415e-08]]],\n     \n     \n             [[[1.8587e-08]],\n     \n              [[4.4067e-09]],\n     \n              [[1.1529e-08]],\n     \n              ...,\n     \n              [[1.2633e-08]],\n     \n              [[1.4815e-08]],\n     \n              [[1.1599e-08]]],\n     \n     \n             [[[1.2703e-08]],\n     \n              [[8.7494e-09]],\n     \n              [[1.2035e-08]],\n     \n              ...,\n     \n              [[1.0822e-08]],\n     \n              [[1.6269e-08]],\n     \n              [[1.1434e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[1.4076e-08]],\n     \n              [[9.6624e-09]],\n     \n              [[1.0279e-08]],\n     \n              ...,\n     \n              [[3.5971e-09]],\n     \n              [[7.7313e-09]],\n     \n              [[8.3490e-09]]],\n     \n     \n             [[[1.7401e-08]],\n     \n              [[1.7037e-08]],\n     \n              [[1.0795e-08]],\n     \n              ...,\n     \n              [[8.9543e-09]],\n     \n              [[1.6743e-08]],\n     \n              [[1.0690e-08]]],\n     \n     \n             [[[1.6751e-08]],\n     \n              [[1.0267e-08]],\n     \n              [[1.9209e-08]],\n     \n              ...,\n     \n              [[1.2989e-08]],\n     \n              [[1.4259e-08]],\n     \n              [[1.2450e-08]]]])},\n    133: {'exp_avg': tensor([[[[-1.4964e-05, -4.8436e-05,  6.0693e-05],\n               [ 5.1977e-06,  4.5127e-05, -3.2090e-05],\n               [-1.6332e-06,  5.0646e-05,  3.3227e-05]],\n     \n              [[-5.1274e-05, -2.4845e-06, -1.6081e-05],\n               [-1.6023e-05, -3.1937e-05, -5.6135e-05],\n               [ 7.8014e-06, -6.0163e-06, -2.0059e-05]],\n     \n              [[ 2.3508e-05,  4.2692e-05,  1.8116e-05],\n               [ 2.8184e-06, -2.7061e-05, -2.7121e-06],\n               [-3.2769e-05, -6.4696e-05, -2.2174e-05]],\n     \n              ...,\n     \n              [[ 6.2443e-06, -2.5135e-07,  1.4449e-05],\n               [-5.2553e-05, -1.2689e-06, -3.5886e-05],\n               [-3.1028e-05, -4.2494e-05, -1.3298e-05]],\n     \n              [[-4.2018e-05,  4.5481e-05,  1.1179e-05],\n               [ 9.0305e-05,  2.1251e-05,  1.6968e-05],\n               [ 6.1823e-06, -4.0494e-06, -3.4678e-05]],\n     \n              [[-1.9257e-05,  2.0869e-06,  1.1641e-05],\n               [-2.1788e-05,  1.5478e-05,  9.6266e-06],\n               [-1.1226e-06,  1.5887e-05, -2.1176e-05]]],\n     \n     \n             [[[ 9.0954e-06, -5.5719e-05, -9.6511e-06],\n               [ 1.0481e-04,  4.6045e-05,  1.3985e-04],\n               [ 5.8440e-05,  7.2729e-05,  8.6713e-05]],\n     \n              [[-3.4929e-05, -5.5546e-05, -5.6257e-05],\n               [ 3.2103e-05,  1.4446e-05, -2.0224e-05],\n               [ 2.6263e-05, -6.4188e-06,  3.3551e-05]],\n     \n              [[-3.9464e-05, -2.2481e-05, -4.7887e-05],\n               [-3.4924e-05, -6.1086e-05, -6.7075e-05],\n               [ 1.2261e-05,  7.8445e-07, -1.0716e-05]],\n     \n              ...,\n     \n              [[ 6.4324e-06, -4.1293e-05, -2.3244e-05],\n               [ 2.1514e-05, -1.7337e-05, -2.8455e-05],\n               [-6.2087e-06, -1.2589e-04, -5.5215e-05]],\n     \n              [[-6.5218e-06,  3.2997e-05,  1.6560e-05],\n               [-4.9807e-05, -1.5350e-05, -5.1452e-05],\n               [-3.3492e-05,  1.4514e-05,  1.6610e-06]],\n     \n              [[-5.1280e-05,  7.0252e-05, -4.5326e-05],\n               [ 2.9723e-06,  3.1338e-05, -5.4116e-05],\n               [-6.3033e-05,  2.6065e-05, -9.4936e-06]]],\n     \n     \n             [[[-1.0970e-05,  1.9328e-05, -8.8719e-06],\n               [-4.5200e-05, -1.1834e-05, -9.1213e-06],\n               [ 9.8128e-06,  1.2138e-05,  3.2164e-05]],\n     \n              [[ 1.2660e-05, -2.5100e-05,  1.0852e-05],\n               [ 1.3488e-06, -7.4307e-06, -1.0720e-05],\n               [ 2.8119e-05, -2.0132e-05, -1.9904e-05]],\n     \n              [[-1.0064e-05,  9.0053e-06,  2.5908e-06],\n               [-2.3662e-05, -1.6527e-05,  3.7877e-06],\n               [-4.0660e-05, -2.3449e-07, -1.5970e-05]],\n     \n              ...,\n     \n              [[ 2.0875e-05, -1.7194e-05,  1.4356e-05],\n               [ 5.7722e-05,  2.7051e-06, -7.9598e-06],\n               [ 8.1704e-06,  2.8722e-06, -6.8593e-06]],\n     \n              [[ 3.5518e-06,  2.0658e-05, -3.4081e-05],\n               [-2.1843e-05, -9.0436e-05, -5.5769e-05],\n               [ 2.0569e-05,  3.7974e-05, -3.5629e-06]],\n     \n              [[-5.1712e-05, -3.4660e-05, -3.3362e-05],\n               [-6.9207e-05, -8.0610e-05, -3.0405e-05],\n               [ 5.7448e-05, -9.2091e-06, -1.9783e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 4.7846e-05,  6.4526e-05, -7.5997e-05],\n               [ 1.9846e-06, -4.1827e-05, -4.2231e-05],\n               [ 2.8245e-05,  2.7406e-05,  2.6828e-05]],\n     \n              [[-1.1239e-05,  2.0664e-05,  2.0743e-05],\n               [-2.7858e-05,  2.4529e-05, -3.8951e-05],\n               [ 1.0694e-05, -6.5320e-07, -1.6611e-05]],\n     \n              [[-4.7405e-05, -1.1619e-05,  4.3502e-06],\n               [-1.4175e-05, -3.3400e-05, -2.8479e-05],\n               [ 1.9999e-05,  4.3940e-06,  5.1858e-07]],\n     \n              ...,\n     \n              [[-1.8861e-05,  2.8131e-05,  3.3745e-05],\n               [-1.7952e-05,  9.6006e-07,  4.1528e-05],\n               [-1.4112e-05,  5.3441e-05,  7.3810e-05]],\n     \n              [[ 1.5290e-05,  1.0731e-05, -6.3658e-06],\n               [ 5.2544e-05, -1.1491e-05,  2.9467e-07],\n               [-6.0260e-06, -3.0804e-05, -1.4163e-05]],\n     \n              [[ 2.4207e-05,  2.6748e-05, -2.8531e-05],\n               [ 1.2013e-06,  1.3368e-05, -5.6073e-05],\n               [ 6.3341e-07,  2.8842e-05, -4.3476e-05]]],\n     \n     \n             [[[-5.6758e-06,  1.1327e-05, -1.6487e-05],\n               [-1.7506e-05,  3.3304e-05,  5.7043e-06],\n               [ 9.2262e-05,  9.9338e-05,  3.0809e-05]],\n     \n              [[-6.0170e-06, -1.8367e-05, -3.7106e-06],\n               [ 9.8882e-05,  4.9088e-05,  1.0503e-04],\n               [ 1.0515e-05,  2.3958e-05,  4.2618e-05]],\n     \n              [[ 5.5297e-05, -5.3483e-05, -7.5959e-06],\n               [ 2.1263e-05,  1.1936e-05, -5.5360e-05],\n               [ 7.0897e-05, -2.2221e-06,  1.0400e-05]],\n     \n              ...,\n     \n              [[ 2.9057e-05,  4.1803e-06, -1.0351e-06],\n               [ 1.0731e-05, -2.7983e-05, -3.5261e-05],\n               [-8.5060e-06,  2.5771e-05,  4.5223e-05]],\n     \n              [[ 2.8127e-05,  8.9176e-05,  3.4282e-05],\n               [ 5.8363e-05,  9.4604e-05, -3.9007e-08],\n               [ 2.7647e-05,  4.1377e-05,  2.5747e-05]],\n     \n              [[ 9.4576e-05,  6.0359e-05,  3.4622e-05],\n               [ 1.5954e-05, -2.8495e-05,  3.8354e-05],\n               [-3.0869e-05,  1.8853e-05, -1.4614e-05]]],\n     \n     \n             [[[ 6.0870e-06,  2.9834e-05, -3.0203e-05],\n               [-1.3880e-06,  3.3154e-05, -3.1099e-05],\n               [-6.2755e-06,  1.9247e-05, -3.1362e-05]],\n     \n              [[ 1.7940e-05, -1.7245e-05,  7.5122e-06],\n               [ 9.3260e-06, -6.1636e-06,  1.8181e-05],\n               [ 1.1866e-06, -2.9305e-05,  4.1081e-05]],\n     \n              [[ 5.0230e-05,  3.9431e-05,  2.3680e-05],\n               [ 6.0712e-05,  2.4631e-06,  2.7927e-05],\n               [ 7.8371e-05,  2.0549e-05, -1.1779e-06]],\n     \n              ...,\n     \n              [[ 8.6588e-06, -1.8368e-05,  2.7087e-05],\n               [-1.4382e-05, -1.9353e-05,  6.1605e-06],\n               [ 1.8194e-05, -5.2160e-05,  3.1363e-05]],\n     \n              [[ 2.8955e-05, -3.9717e-05, -1.0623e-05],\n               [ 3.0583e-05, -9.6380e-05, -5.5920e-06],\n               [ 2.2488e-05, -4.2620e-05,  4.1277e-05]],\n     \n              [[ 2.1020e-05, -2.4487e-05, -1.0932e-06],\n               [ 4.3459e-05, -1.8155e-05,  7.5260e-06],\n               [ 3.7641e-05, -1.7394e-05,  2.4704e-05]]]]),\n     'exp_avg_sq': tensor([[[[3.2865e-09, 5.0500e-09, 3.5459e-09],\n               [3.4326e-09, 4.9972e-09, 3.4012e-09],\n               [2.1947e-09, 4.4125e-09, 3.0635e-09]],\n     \n              [[3.4643e-09, 4.0129e-09, 3.4135e-09],\n               [5.4116e-09, 5.9233e-09, 5.8968e-09],\n               [4.2362e-09, 4.5766e-09, 4.1059e-09]],\n     \n              [[3.2964e-09, 4.1954e-09, 3.0950e-09],\n               [4.2661e-09, 5.1203e-09, 3.6441e-09],\n               [3.3315e-09, 4.3204e-09, 3.4389e-09]],\n     \n              ...,\n     \n              [[2.2927e-09, 2.6343e-09, 2.2535e-09],\n               [2.7653e-09, 3.2959e-09, 2.9771e-09],\n               [2.5907e-09, 2.9398e-09, 2.4339e-09]],\n     \n              [[2.2840e-09, 2.3357e-09, 2.1239e-09],\n               [3.9156e-09, 4.7079e-09, 4.0041e-09],\n               [2.1076e-09, 4.0189e-09, 2.1256e-09]],\n     \n              [[2.9537e-09, 3.8116e-09, 2.9861e-09],\n               [5.1732e-09, 4.7051e-09, 4.6475e-09],\n               [4.1266e-09, 4.3723e-09, 3.8431e-09]]],\n     \n     \n             [[[4.2455e-09, 5.3478e-09, 4.6269e-09],\n               [4.4385e-09, 5.0748e-09, 5.5096e-09],\n               [3.2945e-09, 4.1866e-09, 3.4832e-09]],\n     \n              [[5.5379e-09, 4.8065e-09, 5.6900e-09],\n               [7.7157e-09, 7.4631e-09, 7.6552e-09],\n               [5.2675e-09, 4.8574e-09, 5.5816e-09]],\n     \n              [[3.9893e-09, 5.9359e-09, 4.4628e-09],\n               [5.1804e-09, 7.0606e-09, 6.3186e-09],\n               [4.2589e-09, 5.1996e-09, 4.3907e-09]],\n     \n              ...,\n     \n              [[3.4342e-09, 4.4149e-09, 3.6969e-09],\n               [5.3928e-09, 5.7333e-09, 4.6225e-09],\n               [3.3248e-09, 5.9390e-09, 4.2221e-09]],\n     \n              [[2.6421e-09, 4.3241e-09, 3.1030e-09],\n               [4.3030e-09, 6.7859e-09, 3.8015e-09],\n               [2.9573e-09, 4.1597e-09, 2.7802e-09]],\n     \n              [[4.9077e-09, 4.2130e-09, 5.4229e-09],\n               [6.1249e-09, 4.4740e-09, 5.7605e-09],\n               [4.7954e-09, 5.7521e-09, 4.5295e-09]]],\n     \n     \n             [[[2.4181e-09, 1.9504e-09, 8.7282e-10],\n               [2.4253e-09, 2.4956e-09, 6.5477e-10],\n               [1.2305e-09, 1.6623e-09, 1.7134e-09]],\n     \n              [[2.2960e-09, 2.0426e-09, 9.0238e-10],\n               [3.0161e-09, 2.4010e-09, 1.1816e-09],\n               [2.3498e-09, 1.6965e-09, 7.3141e-10]],\n     \n              [[2.5038e-09, 2.0085e-09, 9.7831e-10],\n               [2.9469e-09, 2.4144e-09, 9.7401e-10],\n               [1.9874e-09, 1.9366e-09, 7.7744e-10]],\n     \n              ...,\n     \n              [[1.3717e-09, 1.1428e-09, 8.0693e-10],\n               [1.7672e-09, 1.4206e-09, 1.1840e-09],\n               [1.1371e-09, 8.9633e-10, 8.5186e-10]],\n     \n              [[1.3119e-09, 1.7541e-09, 9.5042e-10],\n               [2.1417e-09, 2.4230e-09, 1.2629e-09],\n               [1.7030e-09, 1.6409e-09, 7.4542e-10]],\n     \n              [[2.2049e-09, 2.0789e-09, 1.0463e-09],\n               [2.6964e-09, 2.9152e-09, 1.3317e-09],\n               [2.2401e-09, 2.1518e-09, 1.0428e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[1.8416e-09, 3.6293e-09, 2.4963e-09],\n               [2.2865e-09, 2.9809e-09, 2.6148e-09],\n               [1.4766e-09, 1.6813e-09, 2.0120e-09]],\n     \n              [[1.9559e-09, 2.1704e-09, 2.0484e-09],\n               [3.3251e-09, 4.0255e-09, 2.9055e-09],\n               [3.1341e-09, 2.8000e-09, 2.5853e-09]],\n     \n              [[2.5640e-09, 2.7172e-09, 1.6965e-09],\n               [2.2503e-09, 3.5910e-09, 2.7237e-09],\n               [1.8943e-09, 2.5831e-09, 1.8098e-09]],\n     \n              ...,\n     \n              [[1.6542e-09, 1.5816e-09, 1.2629e-09],\n               [6.1135e-09, 1.0508e-08, 6.1253e-09],\n               [4.4648e-09, 5.4168e-09, 4.0829e-09]],\n     \n              [[1.4844e-09, 2.2777e-09, 1.3392e-09],\n               [1.8535e-09, 2.8351e-09, 1.7085e-09],\n               [1.7307e-09, 2.7060e-09, 1.2544e-09]],\n     \n              [[2.4219e-09, 3.4253e-09, 2.4167e-09],\n               [2.8290e-09, 3.3943e-09, 2.6858e-09],\n               [2.0946e-09, 2.1166e-09, 2.2475e-09]]],\n     \n     \n             [[[5.1353e-09, 7.0286e-09, 5.0244e-09],\n               [5.3918e-09, 8.0737e-09, 6.5693e-09],\n               [4.3192e-09, 6.3719e-09, 4.6136e-09]],\n     \n              [[7.0900e-09, 5.0733e-09, 5.1776e-09],\n               [6.3499e-09, 7.5208e-09, 8.1206e-09],\n               [7.0636e-09, 6.1945e-09, 6.9774e-09]],\n     \n              [[4.9798e-09, 7.1850e-09, 4.6789e-09],\n               [6.2044e-09, 8.1754e-09, 7.2136e-09],\n               [6.0707e-09, 6.7711e-09, 5.0400e-09]],\n     \n              ...,\n     \n              [[4.9980e-09, 5.7068e-09, 4.0833e-09],\n               [6.9548e-09, 7.2852e-09, 6.4775e-09],\n               [4.8535e-09, 5.1178e-09, 5.0614e-09]],\n     \n              [[3.7738e-09, 7.2029e-09, 3.7896e-09],\n               [7.2449e-09, 8.8592e-09, 4.7855e-09],\n               [4.6573e-09, 6.5428e-09, 3.8689e-09]],\n     \n              [[7.2560e-09, 6.6369e-09, 6.7876e-09],\n               [9.4763e-09, 7.0456e-09, 8.3673e-09],\n               [5.7616e-09, 5.1059e-09, 5.2865e-09]]],\n     \n     \n             [[[2.0990e-09, 3.1434e-09, 2.1711e-09],\n               [1.7174e-09, 2.4435e-09, 2.2892e-09],\n               [1.4146e-09, 1.8192e-09, 1.9362e-09]],\n     \n              [[2.9950e-09, 2.5666e-09, 2.8465e-09],\n               [3.5600e-09, 3.4231e-09, 2.9039e-09],\n               [2.0224e-09, 2.8741e-09, 1.9065e-09]],\n     \n              [[3.4422e-09, 3.7373e-09, 3.4598e-09],\n               [3.2788e-09, 4.1952e-09, 3.5788e-09],\n               [3.2128e-09, 4.0899e-09, 2.5240e-09]],\n     \n              ...,\n     \n              [[3.9635e-09, 5.2568e-09, 4.2702e-09],\n               [6.1362e-09, 7.8879e-09, 5.6938e-09],\n               [3.9540e-09, 4.7058e-09, 3.1466e-09]],\n     \n              [[1.2293e-09, 2.5176e-09, 1.4668e-09],\n               [2.7268e-09, 3.6234e-09, 2.4189e-09],\n               [1.8980e-09, 2.0605e-09, 2.4566e-09]],\n     \n              [[2.2569e-09, 2.6373e-09, 3.1565e-09],\n               [2.7737e-09, 2.7910e-09, 3.8066e-09],\n               [2.9319e-09, 2.6716e-09, 2.7967e-09]]]])},\n    134: {'exp_avg': tensor([[[[-4.4453e-05]],\n     \n              [[-1.1397e-05]],\n     \n              [[-1.7286e-06]],\n     \n              ...,\n     \n              [[-2.9468e-05]],\n     \n              [[-7.1860e-05]],\n     \n              [[-1.8198e-07]]],\n     \n     \n             [[[ 9.4538e-06]],\n     \n              [[ 3.5335e-05]],\n     \n              [[-3.3419e-05]],\n     \n              ...,\n     \n              [[-4.6871e-05]],\n     \n              [[-2.5246e-05]],\n     \n              [[-6.6761e-06]]],\n     \n     \n             [[[ 7.3670e-05]],\n     \n              [[-5.7814e-05]],\n     \n              [[ 7.9710e-06]],\n     \n              ...,\n     \n              [[ 1.6509e-05]],\n     \n              [[-4.2560e-05]],\n     \n              [[ 4.4470e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 4.6492e-05]],\n     \n              [[-1.1080e-04]],\n     \n              [[-4.2469e-05]],\n     \n              ...,\n     \n              [[ 3.3628e-05]],\n     \n              [[ 2.7026e-05]],\n     \n              [[ 3.9227e-05]]],\n     \n     \n             [[[-8.6149e-05]],\n     \n              [[ 2.0706e-05]],\n     \n              [[-2.8376e-05]],\n     \n              ...,\n     \n              [[-3.1923e-05]],\n     \n              [[ 2.5033e-05]],\n     \n              [[ 6.4389e-05]]],\n     \n     \n             [[[ 5.9668e-05]],\n     \n              [[ 2.0462e-05]],\n     \n              [[ 2.4799e-05]],\n     \n              ...,\n     \n              [[-4.1866e-05]],\n     \n              [[-9.2900e-05]],\n     \n              [[ 7.1153e-05]]]]),\n     'exp_avg_sq': tensor([[[[8.0453e-09]],\n     \n              [[7.2107e-09]],\n     \n              [[3.2696e-09]],\n     \n              ...,\n     \n              [[3.2519e-09]],\n     \n              [[7.3181e-09]],\n     \n              [[3.5928e-09]]],\n     \n     \n             [[[1.1723e-08]],\n     \n              [[6.8116e-09]],\n     \n              [[4.4787e-09]],\n     \n              ...,\n     \n              [[2.9205e-09]],\n     \n              [[1.0245e-08]],\n     \n              [[5.1897e-09]]],\n     \n     \n             [[[7.9670e-09]],\n     \n              [[7.2800e-09]],\n     \n              [[3.0565e-09]],\n     \n              ...,\n     \n              [[5.8578e-09]],\n     \n              [[6.5127e-09]],\n     \n              [[6.5228e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[1.0896e-08]],\n     \n              [[1.1150e-08]],\n     \n              [[4.9621e-09]],\n     \n              ...,\n     \n              [[4.8689e-09]],\n     \n              [[1.0300e-08]],\n     \n              [[5.1670e-09]]],\n     \n     \n             [[[1.1387e-08]],\n     \n              [[8.5250e-09]],\n     \n              [[2.7650e-09]],\n     \n              ...,\n     \n              [[5.7350e-09]],\n     \n              [[6.9038e-09]],\n     \n              [[9.1614e-09]]],\n     \n     \n             [[[9.9328e-09]],\n     \n              [[8.7716e-09]],\n     \n              [[3.4492e-09]],\n     \n              ...,\n     \n              [[4.2684e-09]],\n     \n              [[1.0164e-08]],\n     \n              [[6.2765e-09]]]])},\n    135: {'exp_avg': tensor([[[[-4.7625e-05]],\n     \n              [[ 4.9550e-05]],\n     \n              [[-2.9717e-05]],\n     \n              ...,\n     \n              [[ 7.7073e-06]],\n     \n              [[ 5.7325e-06]],\n     \n              [[-1.0897e-05]]],\n     \n     \n             [[[-2.1680e-05]],\n     \n              [[-8.3481e-06]],\n     \n              [[-7.7507e-06]],\n     \n              ...,\n     \n              [[ 2.7649e-05]],\n     \n              [[ 9.0041e-06]],\n     \n              [[ 5.5431e-06]]],\n     \n     \n             [[[-9.6121e-06]],\n     \n              [[ 1.1773e-05]],\n     \n              [[ 1.4511e-05]],\n     \n              ...,\n     \n              [[ 1.7355e-05]],\n     \n              [[ 9.0397e-07]],\n     \n              [[ 2.1103e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-4.8428e-05]],\n     \n              [[ 2.4241e-05]],\n     \n              [[ 1.9488e-05]],\n     \n              ...,\n     \n              [[ 6.3331e-05]],\n     \n              [[ 6.8691e-05]],\n     \n              [[ 7.0566e-05]]],\n     \n     \n             [[[ 5.0589e-05]],\n     \n              [[ 3.4563e-04]],\n     \n              [[ 2.4084e-05]],\n     \n              ...,\n     \n              [[-3.2518e-05]],\n     \n              [[-6.9620e-05]],\n     \n              [[ 2.5698e-05]]],\n     \n     \n             [[[ 2.9157e-05]],\n     \n              [[-5.3506e-05]],\n     \n              [[ 9.9370e-07]],\n     \n              ...,\n     \n              [[-1.0450e-05]],\n     \n              [[-1.2677e-05]],\n     \n              [[ 3.3543e-05]]]]),\n     'exp_avg_sq': tensor([[[[4.1868e-09]],\n     \n              [[3.4128e-09]],\n     \n              [[2.6455e-09]],\n     \n              ...,\n     \n              [[2.2359e-09]],\n     \n              [[3.7059e-09]],\n     \n              [[2.7728e-09]]],\n     \n     \n             [[[2.0325e-09]],\n     \n              [[1.3926e-09]],\n     \n              [[2.2323e-09]],\n     \n              ...,\n     \n              [[2.4529e-09]],\n     \n              [[2.6941e-09]],\n     \n              [[2.0204e-09]]],\n     \n     \n             [[[3.6767e-09]],\n     \n              [[1.4136e-09]],\n     \n              [[2.5776e-09]],\n     \n              ...,\n     \n              [[9.2092e-10]],\n     \n              [[3.3357e-09]],\n     \n              [[2.9079e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[5.4644e-09]],\n     \n              [[6.6341e-09]],\n     \n              [[3.8193e-09]],\n     \n              ...,\n     \n              [[5.4422e-09]],\n     \n              [[5.9438e-09]],\n     \n              [[4.6234e-09]]],\n     \n     \n             [[[5.5204e-09]],\n     \n              [[3.5580e-08]],\n     \n              [[2.8972e-09]],\n     \n              ...,\n     \n              [[7.2350e-10]],\n     \n              [[3.8414e-09]],\n     \n              [[3.1959e-09]]],\n     \n     \n             [[[6.0200e-09]],\n     \n              [[3.7431e-09]],\n     \n              [[3.1360e-09]],\n     \n              ...,\n     \n              [[1.3374e-09]],\n     \n              [[4.2478e-09]],\n     \n              [[3.0427e-09]]]])},\n    136: {'exp_avg': tensor([[[[ 2.2320e-05]],\n     \n              [[-2.6228e-05]],\n     \n              [[-8.9914e-06]],\n     \n              ...,\n     \n              [[-5.5293e-05]],\n     \n              [[-5.3528e-06]],\n     \n              [[-1.4241e-06]]],\n     \n     \n             [[[-6.0490e-06]],\n     \n              [[-1.2110e-05]],\n     \n              [[-7.0001e-06]],\n     \n              ...,\n     \n              [[ 2.7733e-05]],\n     \n              [[-2.6232e-05]],\n     \n              [[-1.4749e-05]]],\n     \n     \n             [[[ 1.7173e-05]],\n     \n              [[-5.6491e-05]],\n     \n              [[ 1.7894e-05]],\n     \n              ...,\n     \n              [[-7.9964e-05]],\n     \n              [[ 3.0446e-05]],\n     \n              [[-1.2852e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 2.5019e-05]],\n     \n              [[ 4.3703e-05]],\n     \n              [[-2.0654e-05]],\n     \n              ...,\n     \n              [[ 5.6476e-05]],\n     \n              [[-3.3747e-05]],\n     \n              [[ 6.3434e-05]]],\n     \n     \n             [[[-3.5243e-05]],\n     \n              [[-4.6425e-05]],\n     \n              [[ 1.8021e-05]],\n     \n              ...,\n     \n              [[-1.9624e-05]],\n     \n              [[ 8.2347e-06]],\n     \n              [[-4.4801e-05]]],\n     \n     \n             [[[ 1.2022e-05]],\n     \n              [[ 1.4922e-05]],\n     \n              [[-1.2967e-05]],\n     \n              ...,\n     \n              [[-2.5585e-05]],\n     \n              [[ 4.3906e-05]],\n     \n              [[-3.8744e-05]]]]),\n     'exp_avg_sq': tensor([[[[2.0114e-09]],\n     \n              [[2.5734e-09]],\n     \n              [[3.9429e-09]],\n     \n              ...,\n     \n              [[3.7671e-09]],\n     \n              [[5.2596e-09]],\n     \n              [[1.6727e-09]]],\n     \n     \n             [[[5.4090e-09]],\n     \n              [[4.1700e-09]],\n     \n              [[3.9406e-09]],\n     \n              ...,\n     \n              [[4.6602e-09]],\n     \n              [[8.4722e-09]],\n     \n              [[2.5732e-09]]],\n     \n     \n             [[[4.6738e-09]],\n     \n              [[2.9900e-09]],\n     \n              [[2.2722e-09]],\n     \n              ...,\n     \n              [[3.7324e-09]],\n     \n              [[3.6155e-09]],\n     \n              [[2.0912e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[5.2114e-09]],\n     \n              [[4.6922e-09]],\n     \n              [[7.8199e-09]],\n     \n              ...,\n     \n              [[6.6377e-09]],\n     \n              [[8.6341e-09]],\n     \n              [[4.3490e-09]]],\n     \n     \n             [[[3.7185e-09]],\n     \n              [[5.8441e-09]],\n     \n              [[3.8907e-09]],\n     \n              ...,\n     \n              [[3.2923e-09]],\n     \n              [[3.0618e-09]],\n     \n              [[3.3875e-09]]],\n     \n     \n             [[[4.6328e-09]],\n     \n              [[7.6190e-09]],\n     \n              [[4.6353e-09]],\n     \n              ...,\n     \n              [[3.7685e-09]],\n     \n              [[6.5243e-09]],\n     \n              [[3.1996e-09]]]])},\n    137: {'exp_avg': tensor([[[[ 2.6383e-06,  2.0271e-05,  1.7056e-05],\n               [ 1.5527e-05,  1.3762e-06, -1.7471e-05],\n               [ 1.4851e-05, -2.2023e-05, -2.0932e-05]],\n     \n              [[-2.6834e-05, -1.2275e-05, -1.5559e-05],\n               [ 1.2102e-05,  1.5178e-05, -3.6418e-06],\n               [ 1.0256e-05, -1.5546e-05, -5.0318e-05]],\n     \n              [[ 6.5565e-05,  6.2448e-05,  5.2765e-05],\n               [-2.6535e-05, -1.6230e-05, -7.0307e-05],\n               [-2.0267e-05, -3.6790e-05, -1.3231e-05]],\n     \n              ...,\n     \n              [[-3.6908e-06,  8.6287e-06, -2.1830e-05],\n               [-5.8042e-06,  5.8242e-05,  4.9625e-05],\n               [-1.1547e-05,  5.7694e-05,  4.1751e-06]],\n     \n              [[ 4.7335e-06,  8.6556e-06,  2.9387e-06],\n               [ 1.4951e-06,  1.0357e-05,  2.0390e-05],\n               [ 6.9180e-06, -4.4031e-06, -7.1134e-06]],\n     \n              [[ 1.3141e-05, -1.2388e-05,  1.7675e-05],\n               [ 4.1582e-05, -2.3492e-05,  7.8597e-06],\n               [-1.9403e-05, -6.4458e-05,  9.2860e-06]]],\n     \n     \n             [[[-2.6068e-05, -5.7163e-05, -3.3013e-05],\n               [-1.0509e-05, -3.0318e-05, -6.4459e-06],\n               [ 1.0056e-05, -1.0824e-05,  1.9552e-05]],\n     \n              [[-4.5156e-05, -3.6352e-06, -6.1581e-05],\n               [-1.1428e-05,  4.6887e-06, -3.1982e-05],\n               [ 5.6559e-06,  2.1644e-05, -6.6649e-06]],\n     \n              [[ 4.1854e-05, -3.6894e-05, -4.1845e-05],\n               [ 1.0156e-04, -1.9477e-05,  2.9005e-05],\n               [ 7.3664e-05, -5.4556e-05,  1.6834e-05]],\n     \n              ...,\n     \n              [[-1.8384e-05,  1.0314e-05,  4.1273e-05],\n               [-1.5102e-05,  4.1461e-05,  6.3763e-05],\n               [-1.3722e-06,  5.2542e-05,  5.0913e-05]],\n     \n              [[ 1.3799e-06, -7.3987e-06, -6.0091e-07],\n               [ 6.9211e-07,  2.4764e-05,  5.7074e-06],\n               [-3.2442e-06,  4.1828e-05,  3.2364e-05]],\n     \n              [[ 5.1871e-05, -1.2254e-05, -8.4579e-06],\n               [ 9.1438e-05,  2.2161e-05,  2.4690e-05],\n               [ 1.5857e-05, -1.5828e-05,  8.0175e-06]]],\n     \n     \n             [[[ 2.1163e-05,  1.1241e-05,  3.3791e-05],\n               [-6.7639e-06,  1.3862e-05,  3.5864e-05],\n               [-2.1789e-05, -3.2299e-05, -1.5025e-05]],\n     \n              [[ 2.5351e-07,  2.1016e-05,  1.5853e-05],\n               [ 1.5289e-05, -2.4204e-05,  7.9400e-06],\n               [-4.9935e-05, -3.2029e-05, -8.2186e-06]],\n     \n              [[ 6.4444e-05,  4.5149e-06,  1.2875e-04],\n               [-1.1347e-04, -3.0447e-05, -4.8601e-05],\n               [ 6.3316e-06,  1.4417e-05, -2.3473e-05]],\n     \n              ...,\n     \n              [[-2.5216e-05, -5.7680e-05,  4.3261e-05],\n               [-1.5989e-05, -1.0185e-05,  3.9096e-05],\n               [-2.2822e-05,  4.4784e-08, -3.5079e-05]],\n     \n              [[ 5.0036e-06, -6.5607e-06, -5.6220e-07],\n               [ 7.5714e-06, -6.8782e-06, -2.0284e-05],\n               [ 8.8959e-06,  8.8308e-06, -2.9676e-06]],\n     \n              [[-2.3970e-05, -2.5659e-05,  1.1131e-05],\n               [-3.2448e-05, -1.7202e-05,  2.1477e-05],\n               [-2.1658e-05, -4.3833e-06,  1.6374e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 2.4649e-06,  6.9461e-06, -3.5210e-05],\n               [ 6.3118e-06,  3.6119e-06, -5.5054e-05],\n               [ 4.2205e-06, -1.8101e-05, -1.2349e-05]],\n     \n              [[-3.9324e-05, -3.1434e-05, -1.5415e-05],\n               [-3.8124e-05, -4.8535e-06,  2.8126e-05],\n               [-2.9719e-05,  4.1284e-05,  4.6212e-05]],\n     \n              [[-1.7192e-06,  9.0167e-05, -5.6751e-05],\n               [-9.9598e-05,  2.3438e-04,  2.5263e-05],\n               [ 4.7523e-05, -1.2974e-05, -1.7514e-05]],\n     \n              ...,\n     \n              [[ 6.3763e-05, -3.4455e-05, -2.3108e-05],\n               [ 5.2873e-05,  4.5249e-05,  3.7550e-05],\n               [ 2.0547e-05, -3.7967e-05, -2.3659e-05]],\n     \n              [[ 1.1863e-05,  2.0545e-06,  1.0653e-06],\n               [ 7.0810e-05, -5.6409e-05, -4.1862e-05],\n               [-4.3273e-06,  2.2583e-05,  2.6219e-05]],\n     \n              [[-7.4427e-06,  7.3297e-05, -3.2242e-05],\n               [ 4.5664e-05,  7.2270e-05, -4.9405e-06],\n               [ 5.1279e-06, -1.1418e-04, -1.4582e-05]]],\n     \n     \n             [[[ 2.2661e-05,  2.3618e-05,  2.9918e-05],\n               [ 1.3768e-05,  1.1163e-05,  2.2591e-05],\n               [ 3.4247e-05, -1.5589e-06, -9.4574e-07]],\n     \n              [[ 9.8277e-05,  7.2698e-05,  8.7076e-05],\n               [ 7.4089e-05,  5.4565e-05,  3.3911e-05],\n               [ 2.7871e-06, -7.7714e-06,  1.9713e-05]],\n     \n              [[ 2.5407e-05,  5.4973e-05,  9.3309e-06],\n               [-2.2456e-05, -6.7721e-06, -1.6014e-05],\n               [-3.1808e-05,  1.9677e-05,  6.5050e-06]],\n     \n              ...,\n     \n              [[-3.5589e-05,  2.4795e-05, -1.3702e-05],\n               [-2.5230e-05,  2.4698e-05,  4.3727e-05],\n               [-2.9082e-05, -2.6336e-05,  2.9277e-06]],\n     \n              [[-6.6721e-06,  6.0929e-06, -2.2718e-06],\n               [ 1.7000e-05,  1.8355e-05,  8.9027e-06],\n               [-6.1003e-06,  7.9153e-07, -1.1187e-06]],\n     \n              [[-4.3689e-05, -1.8091e-05,  4.5647e-06],\n               [-3.0803e-05,  1.0027e-05, -1.5078e-05],\n               [-3.7772e-05,  1.8389e-05, -1.0057e-07]]],\n     \n     \n             [[[-5.5003e-05, -4.6676e-05, -2.2217e-05],\n               [-3.6545e-05, -4.7945e-05, -4.3117e-05],\n               [-3.9059e-05, -3.9982e-05, -2.1393e-05]],\n     \n              [[ 1.0006e-06,  6.1723e-05,  3.7258e-05],\n               [ 1.0425e-05,  3.7333e-05,  3.0801e-05],\n               [ 1.2113e-05,  1.0090e-05,  2.4804e-05]],\n     \n              [[-1.3616e-05,  6.7663e-06, -9.5307e-05],\n               [-7.5182e-06, -3.9198e-05,  4.0602e-05],\n               [ 1.1461e-05,  6.8612e-05,  1.9625e-05]],\n     \n              ...,\n     \n              [[ 2.5649e-05, -7.2439e-07,  3.2867e-05],\n               [ 4.2525e-06, -1.3440e-06, -3.0443e-05],\n               [-1.7781e-06, -1.3053e-05, -1.5584e-05]],\n     \n              [[ 5.3575e-06,  8.5220e-06,  5.8135e-06],\n               [-1.4607e-05,  2.0443e-05,  2.5859e-06],\n               [-9.6117e-06,  6.4595e-06,  3.4836e-05]],\n     \n              [[-1.8840e-05,  4.0790e-06, -3.2952e-06],\n               [-9.0498e-06,  1.4557e-05,  1.9384e-05],\n               [-6.8136e-05, -9.3991e-05,  1.4433e-05]]]]),\n     'exp_avg_sq': tensor([[[[1.3463e-09, 1.2400e-09, 1.1182e-09],\n               [1.0697e-09, 1.0389e-09, 9.5435e-10],\n               [1.2067e-09, 1.1345e-09, 1.0051e-09]],\n     \n              [[1.5967e-09, 3.6476e-09, 1.8888e-09],\n               [2.6355e-09, 4.0493e-09, 2.4866e-09],\n               [2.0810e-09, 2.6699e-09, 3.0028e-09]],\n     \n              [[5.5887e-09, 4.3821e-09, 5.9958e-09],\n               [3.8049e-09, 1.2619e-08, 4.3199e-09],\n               [4.9128e-09, 5.2726e-09, 6.1718e-09]],\n     \n              ...,\n     \n              [[2.8644e-09, 3.1311e-09, 2.8535e-09],\n               [3.1068e-09, 6.8144e-09, 4.3170e-09],\n               [2.8803e-09, 4.1781e-09, 3.4540e-09]],\n     \n              [[2.1839e-10, 2.3051e-10, 1.6816e-10],\n               [5.3842e-10, 7.1903e-10, 5.2853e-10],\n               [7.6994e-10, 1.1417e-09, 9.4481e-10]],\n     \n              [[1.4699e-09, 1.4052e-09, 1.5893e-09],\n               [3.0601e-09, 3.1851e-09, 2.8626e-09],\n               [3.6280e-09, 3.2510e-09, 2.9796e-09]]],\n     \n     \n             [[[6.9507e-10, 9.4054e-10, 7.5388e-10],\n               [6.0604e-10, 6.0336e-10, 5.1385e-10],\n               [5.9934e-10, 6.8119e-10, 5.2751e-10]],\n     \n              [[2.7268e-09, 3.2192e-09, 2.6606e-09],\n               [2.5741e-09, 3.2694e-09, 1.9275e-09],\n               [1.1021e-09, 1.3133e-09, 1.0433e-09]],\n     \n              [[3.5948e-09, 4.8267e-09, 3.4598e-09],\n               [4.7734e-09, 7.7961e-09, 5.2024e-09],\n               [3.3981e-09, 5.5221e-09, 3.8336e-09]],\n     \n              ...,\n     \n              [[2.8271e-09, 4.9113e-09, 3.3552e-09],\n               [3.9134e-09, 6.2693e-09, 3.7541e-09],\n               [2.3060e-09, 3.8866e-09, 2.8678e-09]],\n     \n              [[2.1252e-10, 2.3116e-10, 1.9024e-10],\n               [6.4041e-10, 8.9051e-10, 7.1697e-10],\n               [5.4129e-10, 8.6946e-10, 7.0238e-10]],\n     \n              [[2.3416e-09, 2.5250e-09, 1.8003e-09],\n               [2.9819e-09, 2.7063e-09, 2.8771e-09],\n               [2.8305e-09, 3.2810e-09, 2.7972e-09]]],\n     \n     \n             [[[9.3781e-10, 9.8487e-10, 1.3949e-09],\n               [9.6242e-10, 1.0989e-09, 2.0644e-09],\n               [1.0285e-09, 1.0921e-09, 1.4594e-09]],\n     \n              [[2.6129e-09, 3.2773e-09, 2.9671e-09],\n               [3.0609e-09, 3.0898e-09, 2.6217e-09],\n               [1.4858e-09, 2.0321e-09, 1.7961e-09]],\n     \n              [[5.0441e-09, 9.2836e-10, 5.2343e-09],\n               [8.4415e-09, 1.9303e-09, 7.4395e-09],\n               [4.8184e-09, 1.1838e-09, 6.6308e-09]],\n     \n              ...,\n     \n              [[2.8239e-09, 3.9004e-09, 2.3197e-09],\n               [4.7581e-09, 6.1451e-09, 2.3756e-09],\n               [3.1804e-09, 3.0021e-09, 2.2519e-09]],\n     \n              [[1.7932e-10, 2.9079e-10, 2.4952e-10],\n               [5.6523e-10, 8.4775e-10, 5.9096e-10],\n               [6.4587e-10, 8.8251e-10, 5.2467e-10]],\n     \n              [[1.5346e-09, 1.1178e-09, 2.6239e-09],\n               [1.8283e-09, 2.0618e-09, 5.4287e-09],\n               [2.5257e-09, 2.3416e-09, 4.0513e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[3.5386e-09, 5.8248e-09, 3.0658e-09],\n               [4.1494e-09, 7.1425e-09, 4.7898e-09],\n               [1.6668e-09, 3.7857e-09, 1.4301e-09]],\n     \n              [[9.4933e-09, 1.0350e-08, 7.9426e-09],\n               [6.0915e-09, 7.6996e-09, 3.0640e-09],\n               [3.8440e-09, 4.5734e-09, 2.9401e-09]],\n     \n              [[2.6969e-09, 3.6854e-08, 5.8650e-09],\n               [1.2064e-08, 4.6084e-08, 2.7166e-08],\n               [3.8696e-09, 1.7313e-08, 1.4180e-09]],\n     \n              ...,\n     \n              [[1.1616e-08, 9.2534e-09, 6.2251e-09],\n               [7.9302e-09, 7.9712e-09, 4.9059e-09],\n               [6.3312e-09, 5.6928e-09, 3.1648e-09]],\n     \n              [[9.3441e-10, 8.5570e-10, 1.0774e-09],\n               [3.4852e-09, 3.7669e-09, 2.2998e-09],\n               [1.5064e-09, 5.5729e-10, 1.0062e-09]],\n     \n              [[8.1081e-09, 1.1588e-08, 8.9167e-09],\n               [1.0073e-08, 1.4389e-08, 1.2078e-08],\n               [4.4000e-09, 1.1066e-08, 2.1376e-09]]],\n     \n     \n             [[[1.2284e-09, 9.8812e-10, 8.2897e-10],\n               [1.1529e-09, 9.3614e-10, 7.6537e-10],\n               [1.0783e-09, 8.6745e-10, 6.0232e-10]],\n     \n              [[2.3864e-09, 2.7620e-09, 2.3894e-09],\n               [3.7392e-09, 2.7321e-09, 1.8530e-09],\n               [1.2397e-09, 1.2790e-09, 7.6633e-10]],\n     \n              [[3.9326e-09, 4.2119e-09, 5.1000e-09],\n               [4.3360e-09, 4.8130e-09, 6.5752e-09],\n               [2.9136e-09, 3.0428e-09, 5.2424e-09]],\n     \n              ...,\n     \n              [[3.2223e-09, 3.2212e-09, 2.0284e-09],\n               [3.3365e-09, 3.8052e-09, 2.1831e-09],\n               [2.4345e-09, 2.1044e-09, 1.5823e-09]],\n     \n              [[2.5523e-10, 2.6649e-10, 1.2915e-10],\n               [7.2014e-10, 6.8054e-10, 2.5785e-10],\n               [6.8430e-10, 8.7606e-10, 3.3067e-10]],\n     \n              [[1.4044e-09, 1.6073e-09, 1.3762e-09],\n               [1.8765e-09, 2.6190e-09, 2.2953e-09],\n               [1.9474e-09, 2.3885e-09, 2.5056e-09]]],\n     \n     \n             [[[1.4370e-09, 1.6571e-09, 1.3501e-09],\n               [1.9249e-09, 2.1986e-09, 1.6172e-09],\n               [1.5009e-09, 1.9362e-09, 1.5471e-09]],\n     \n              [[1.9087e-09, 3.0607e-09, 1.9681e-09],\n               [1.4381e-09, 2.4413e-09, 1.4708e-09],\n               [8.7340e-10, 1.0375e-09, 6.4870e-10]],\n     \n              [[2.8314e-09, 4.8980e-09, 3.3246e-09],\n               [4.3217e-09, 9.1070e-09, 4.6600e-09],\n               [3.5232e-09, 5.1782e-09, 4.1738e-09]],\n     \n              ...,\n     \n              [[9.7739e-10, 1.1376e-09, 9.9076e-10],\n               [6.7570e-10, 1.6154e-09, 1.1157e-09],\n               [4.2259e-10, 7.2497e-10, 6.7310e-10]],\n     \n              [[2.3324e-10, 2.0660e-10, 1.8849e-10],\n               [6.0724e-10, 9.0919e-10, 5.8753e-10],\n               [5.5371e-10, 6.4268e-10, 6.8806e-10]],\n     \n              [[2.5134e-09, 2.7660e-09, 2.7947e-09],\n               [3.1606e-09, 4.3148e-09, 3.3543e-09],\n               [3.2077e-09, 4.3977e-09, 3.4601e-09]]]])},\n    138: {'exp_avg': tensor([[[[-5.1813e-06]],\n     \n              [[-2.0553e-05]],\n     \n              [[-4.8867e-05]],\n     \n              ...,\n     \n              [[ 2.9220e-05]],\n     \n              [[ 1.0643e-06]],\n     \n              [[ 1.0293e-05]]],\n     \n     \n             [[[-1.1134e-06]],\n     \n              [[-3.8490e-05]],\n     \n              [[-1.3379e-05]],\n     \n              ...,\n     \n              [[-2.0970e-06]],\n     \n              [[ 1.7781e-06]],\n     \n              [[-4.6413e-05]]],\n     \n     \n             [[[-2.7344e-05]],\n     \n              [[-1.5277e-05]],\n     \n              [[-8.1234e-06]],\n     \n              ...,\n     \n              [[-2.5557e-05]],\n     \n              [[-2.3530e-05]],\n     \n              [[-1.9438e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-4.4883e-05]],\n     \n              [[-3.9038e-05]],\n     \n              [[ 6.8983e-06]],\n     \n              ...,\n     \n              [[ 5.7201e-06]],\n     \n              [[-4.3150e-05]],\n     \n              [[-5.4552e-05]]],\n     \n     \n             [[[-6.0748e-05]],\n     \n              [[-2.3377e-06]],\n     \n              [[-1.5033e-06]],\n     \n              ...,\n     \n              [[-2.2384e-05]],\n     \n              [[-1.3055e-05]],\n     \n              [[-3.7883e-05]]],\n     \n     \n             [[[ 1.7621e-05]],\n     \n              [[-3.5044e-05]],\n     \n              [[-2.3449e-05]],\n     \n              ...,\n     \n              [[ 1.5757e-05]],\n     \n              [[ 3.9193e-06]],\n     \n              [[ 4.9709e-05]]]]),\n     'exp_avg_sq': tensor([[[[3.2018e-09]],\n     \n              [[3.9836e-09]],\n     \n              [[3.0609e-09]],\n     \n              ...,\n     \n              [[2.5914e-09]],\n     \n              [[2.3343e-09]],\n     \n              [[3.6742e-09]]],\n     \n     \n             [[[1.7218e-09]],\n     \n              [[2.1039e-09]],\n     \n              [[1.3131e-09]],\n     \n              ...,\n     \n              [[2.0300e-09]],\n     \n              [[1.0526e-09]],\n     \n              [[2.2429e-09]]],\n     \n     \n             [[[5.1476e-09]],\n     \n              [[5.2346e-09]],\n     \n              [[2.7722e-09]],\n     \n              ...,\n     \n              [[3.7630e-09]],\n     \n              [[2.0535e-09]],\n     \n              [[5.5347e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[6.5196e-09]],\n     \n              [[6.5898e-09]],\n     \n              [[4.4106e-09]],\n     \n              ...,\n     \n              [[5.0661e-09]],\n     \n              [[3.1435e-09]],\n     \n              [[8.5377e-09]]],\n     \n     \n             [[[2.3412e-09]],\n     \n              [[4.3223e-09]],\n     \n              [[1.8978e-09]],\n     \n              ...,\n     \n              [[4.5638e-09]],\n     \n              [[1.1145e-09]],\n     \n              [[5.1061e-09]]],\n     \n     \n             [[[2.0225e-09]],\n     \n              [[3.3664e-09]],\n     \n              [[1.5174e-09]],\n     \n              ...,\n     \n              [[2.4723e-09]],\n     \n              [[1.5197e-09]],\n     \n              [[2.2071e-09]]]])},\n    139: {'exp_avg': tensor([[[[ 7.8563e-05]],\n     \n              [[-9.9399e-06]],\n     \n              [[-1.5407e-05]],\n     \n              ...,\n     \n              [[ 2.5770e-05]],\n     \n              [[-2.9827e-05]],\n     \n              [[ 5.8618e-05]]],\n     \n     \n             [[[ 6.0341e-06]],\n     \n              [[-2.4841e-05]],\n     \n              [[-1.7408e-05]],\n     \n              ...,\n     \n              [[-6.6274e-07]],\n     \n              [[-8.5585e-07]],\n     \n              [[ 4.6216e-06]]],\n     \n     \n             [[[-5.7470e-05]],\n     \n              [[-3.2296e-05]],\n     \n              [[ 1.7374e-05]],\n     \n              ...,\n     \n              [[-6.4563e-05]],\n     \n              [[ 7.2398e-05]],\n     \n              [[ 2.1158e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-1.3301e-05]],\n     \n              [[ 2.9083e-06]],\n     \n              [[-9.5611e-05]],\n     \n              ...,\n     \n              [[-2.0114e-05]],\n     \n              [[ 3.4571e-05]],\n     \n              [[-4.7147e-05]]],\n     \n     \n             [[[ 4.8176e-05]],\n     \n              [[ 3.6106e-05]],\n     \n              [[ 6.8940e-06]],\n     \n              ...,\n     \n              [[ 8.4252e-05]],\n     \n              [[-6.2596e-05]],\n     \n              [[ 7.5264e-05]]],\n     \n     \n             [[[-1.2087e-06]],\n     \n              [[ 3.9116e-05]],\n     \n              [[-7.0883e-08]],\n     \n              ...,\n     \n              [[-2.8218e-05]],\n     \n              [[ 3.2380e-05]],\n     \n              [[ 6.8175e-06]]]]),\n     'exp_avg_sq': tensor([[[[3.4078e-09]],\n     \n              [[5.5324e-09]],\n     \n              [[6.0437e-09]],\n     \n              ...,\n     \n              [[6.9629e-09]],\n     \n              [[5.5038e-09]],\n     \n              [[4.3080e-09]]],\n     \n     \n             [[[3.1050e-09]],\n     \n              [[3.9085e-09]],\n     \n              [[3.8984e-09]],\n     \n              ...,\n     \n              [[3.1535e-09]],\n     \n              [[3.5276e-09]],\n     \n              [[4.4773e-09]]],\n     \n     \n             [[[2.4679e-09]],\n     \n              [[3.0560e-09]],\n     \n              [[3.7160e-09]],\n     \n              ...,\n     \n              [[5.5949e-09]],\n     \n              [[5.6536e-09]],\n     \n              [[4.0371e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[2.2626e-09]],\n     \n              [[5.8892e-09]],\n     \n              [[4.0414e-09]],\n     \n              ...,\n     \n              [[4.4498e-09]],\n     \n              [[6.7211e-09]],\n     \n              [[4.0701e-09]]],\n     \n     \n             [[[1.4803e-09]],\n     \n              [[5.1674e-09]],\n     \n              [[2.4604e-09]],\n     \n              ...,\n     \n              [[4.3782e-09]],\n     \n              [[7.7002e-09]],\n     \n              [[2.8077e-09]]],\n     \n     \n             [[[2.3195e-09]],\n     \n              [[3.6015e-09]],\n     \n              [[2.6667e-09]],\n     \n              ...,\n     \n              [[3.7771e-09]],\n     \n              [[3.6289e-09]],\n     \n              [[3.1843e-09]]]])},\n    140: {'exp_avg': tensor([[[[-1.5042e-05, -2.3362e-05, -2.7238e-05],\n               [-1.9228e-05, -1.9845e-05,  4.6373e-05],\n               [-3.2165e-05, -1.7053e-05,  3.5003e-05]],\n     \n              [[-1.8467e-08, -5.8725e-06, -2.6037e-05],\n               [ 3.8407e-05,  3.5803e-05,  4.5506e-06],\n               [-3.3552e-06,  2.7462e-05, -8.1875e-06]],\n     \n              [[ 3.6027e-05,  1.4350e-05,  1.3506e-05],\n               [ 1.0350e-05,  2.0624e-05,  1.8520e-05],\n               [-3.6290e-06,  7.2656e-06,  1.7055e-05]],\n     \n              ...,\n     \n              [[-6.9827e-06, -3.1799e-06,  1.8322e-05],\n               [ 2.5805e-05,  1.9657e-05,  5.6789e-05],\n               [ 5.0681e-07,  2.9943e-05, -1.3646e-05]],\n     \n              [[-2.4467e-05, -8.1802e-06,  1.3904e-05],\n               [-1.2617e-05,  5.9152e-06,  8.6973e-07],\n               [-1.8209e-05,  2.3389e-05, -1.0018e-05]],\n     \n              [[-1.0341e-05, -1.2895e-05, -3.1739e-06],\n               [-1.0627e-06,  8.0957e-05, -2.6702e-05],\n               [-8.8658e-06, -4.2197e-06, -4.8898e-05]]],\n     \n     \n             [[[ 1.0861e-06,  3.0912e-05,  6.6546e-06],\n               [-2.5249e-06, -9.1915e-06, -6.5182e-06],\n               [-1.5550e-05, -2.1317e-05, -5.2404e-05]],\n     \n              [[-6.9154e-06, -2.8958e-05, -6.5552e-06],\n               [ 5.4266e-06, -9.8021e-06, -8.0409e-06],\n               [-9.2534e-06,  7.4143e-06,  4.1869e-06]],\n     \n              [[ 3.0039e-06,  9.6419e-06, -7.9492e-07],\n               [-3.2342e-05, -4.5597e-05, -5.3516e-05],\n               [-1.9571e-05, -5.0000e-05, -2.7325e-05]],\n     \n              ...,\n     \n              [[-3.6169e-06,  4.5360e-06,  3.3246e-05],\n               [-1.7899e-06, -3.7293e-05, -2.7046e-05],\n               [-2.0542e-05, -2.2037e-05, -2.1553e-05]],\n     \n              [[ 1.1576e-05,  3.0677e-05,  2.0354e-05],\n               [ 9.8641e-06,  4.0041e-05,  5.3029e-05],\n               [ 2.9637e-07, -2.4344e-05,  2.0731e-05]],\n     \n              [[-3.3011e-05, -5.2369e-05,  2.4976e-05],\n               [-1.2376e-05,  1.1057e-05, -5.3347e-05],\n               [-1.0088e-05,  1.3103e-04,  1.3783e-05]]],\n     \n     \n             [[[ 3.6224e-05,  1.3812e-05, -2.8965e-05],\n               [ 4.5525e-05,  8.3554e-05,  7.1218e-06],\n               [ 3.7169e-05,  6.3289e-05,  5.3787e-05]],\n     \n              [[ 2.6473e-05, -6.0099e-06, -9.2656e-06],\n               [-4.5814e-06, -2.5292e-06,  3.2547e-05],\n               [ 2.0920e-06, -2.2334e-06,  3.7813e-05]],\n     \n              [[ 1.0790e-05, -1.5856e-05,  6.7155e-06],\n               [ 2.8043e-05, -3.7728e-05, -5.0310e-05],\n               [ 1.5054e-05,  2.7612e-06, -2.9338e-06]],\n     \n              ...,\n     \n              [[ 6.1314e-05, -1.4329e-05,  1.1112e-05],\n               [ 3.9349e-05,  3.4206e-05,  5.0894e-05],\n               [ 5.1739e-05, -8.6482e-07,  2.6631e-06]],\n     \n              [[ 6.1406e-05,  2.0546e-05, -2.2903e-05],\n               [ 3.0838e-05,  3.7548e-05,  2.8291e-06],\n               [ 5.6118e-06,  2.0916e-05,  2.3543e-05]],\n     \n              [[-5.6868e-05,  6.7432e-05, -2.2847e-05],\n               [ 3.0108e-05,  5.9090e-06,  5.5523e-05],\n               [ 2.0151e-05, -8.7027e-05,  3.3928e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 4.4065e-05,  1.2040e-05,  8.2586e-06],\n               [ 8.1265e-07,  1.7512e-05, -1.8645e-05],\n               [-5.5182e-05,  2.2813e-05,  2.4437e-05]],\n     \n              [[ 5.5617e-06,  2.5649e-05,  3.0995e-05],\n               [-1.7804e-05, -7.1244e-05,  5.3815e-06],\n               [-1.8011e-05, -2.4313e-05,  8.2239e-06]],\n     \n              [[ 2.8681e-05,  3.4475e-05,  2.0738e-05],\n               [ 3.6995e-05,  3.5046e-05,  5.7911e-05],\n               [ 6.7411e-05,  1.0365e-04,  6.4836e-05]],\n     \n              ...,\n     \n              [[ 1.9359e-05,  1.3524e-05,  3.8129e-05],\n               [ 1.4243e-05,  2.4055e-05,  3.4941e-05],\n               [ 1.9479e-05,  2.5010e-05,  4.3876e-05]],\n     \n              [[-1.2803e-05,  2.5919e-05, -1.4117e-05],\n               [ 6.9944e-05,  2.2123e-05,  5.0566e-05],\n               [ 2.5726e-05, -5.4287e-05,  3.0210e-05]],\n     \n              [[ 7.4128e-06, -3.3797e-05, -3.1325e-05],\n               [ 4.5536e-05, -6.0156e-05, -8.3519e-06],\n               [ 5.5338e-05, -1.6812e-05,  1.7806e-05]]],\n     \n     \n             [[[-9.5066e-06,  8.8315e-06,  2.1800e-06],\n               [-1.9603e-05,  4.2260e-06,  4.6397e-06],\n               [-2.2633e-05, -5.8287e-06,  5.8154e-06]],\n     \n              [[-2.4843e-05,  4.6909e-06,  1.2726e-05],\n               [-1.4088e-05, -1.8191e-05,  2.8429e-05],\n               [ 1.1384e-05, -1.0190e-05, -9.9471e-08]],\n     \n              [[ 1.1694e-05,  7.1461e-06, -1.1828e-06],\n               [ 2.1391e-07, -2.5631e-05, -3.3521e-05],\n               [ 2.1267e-05,  8.1985e-06,  2.6091e-05]],\n     \n              ...,\n     \n              [[ 3.8387e-05,  2.4309e-05,  4.4423e-05],\n               [ 3.0374e-05,  2.0220e-05,  2.2006e-05],\n               [ 3.3625e-05,  6.5013e-06,  3.9591e-05]],\n     \n              [[ 2.3053e-05,  5.6671e-06, -1.6738e-05],\n               [ 1.9924e-05,  3.9991e-05,  1.2874e-05],\n               [-2.1495e-05,  3.0336e-06,  2.1926e-05]],\n     \n              [[ 3.8451e-05, -7.8937e-05,  3.3637e-05],\n               [-2.2224e-05, -6.9328e-05, -2.6187e-05],\n               [ 2.9893e-05, -8.4268e-05,  5.9290e-05]]],\n     \n     \n             [[[ 2.9707e-06,  2.4674e-05,  3.1720e-05],\n               [ 2.4059e-05,  3.1902e-05,  3.4292e-05],\n               [-1.2760e-05,  8.5934e-07,  5.8055e-06]],\n     \n              [[ 1.9797e-06,  1.1733e-05,  1.2287e-05],\n               [-2.1700e-05, -5.3853e-05, -2.6553e-05],\n               [-6.4790e-06,  1.1557e-05, -8.5603e-06]],\n     \n              [[-5.2044e-06, -2.7079e-05,  2.7068e-05],\n               [-1.8012e-05, -3.9603e-05, -8.7052e-06],\n               [ 3.0113e-06, -2.7070e-05,  1.0137e-05]],\n     \n              ...,\n     \n              [[ 3.0528e-05,  2.5076e-05,  5.6087e-05],\n               [ 4.3287e-06,  2.8262e-05,  4.0933e-05],\n               [ 1.4719e-06,  1.4193e-05,  3.3557e-05]],\n     \n              [[-4.9971e-06, -1.6977e-06,  6.7704e-05],\n               [-1.4102e-05, -1.2061e-05,  5.7832e-05],\n               [-2.1914e-08, -1.7935e-06, -3.1294e-06]],\n     \n              [[ 1.7409e-05, -1.7794e-05,  7.3444e-05],\n               [-3.3147e-05, -1.3936e-04, -6.1481e-05],\n               [-1.4958e-05,  7.3488e-05,  6.8115e-05]]]]),\n     'exp_avg_sq': tensor([[[[9.5534e-10, 1.6661e-09, 1.3735e-09],\n               [1.3898e-09, 1.6812e-09, 1.8491e-09],\n               [1.1851e-09, 1.2682e-09, 1.6965e-09]],\n     \n              [[9.6054e-10, 9.5848e-10, 7.1816e-10],\n               [1.2721e-09, 1.6340e-09, 1.2717e-09],\n               [9.9796e-10, 2.0945e-09, 1.4556e-09]],\n     \n              [[1.5178e-09, 1.2384e-09, 1.2465e-09],\n               [1.4896e-09, 2.0930e-09, 1.1707e-09],\n               [1.3241e-09, 2.0089e-09, 1.8839e-09]],\n     \n              ...,\n     \n              [[1.6275e-09, 1.6896e-09, 1.1447e-09],\n               [2.0951e-09, 2.4292e-09, 1.5453e-09],\n               [1.6971e-09, 2.3543e-09, 2.0557e-09]],\n     \n              [[1.2454e-09, 1.2896e-09, 1.2536e-09],\n               [1.4700e-09, 1.7366e-09, 1.7935e-09],\n               [1.5051e-09, 1.9336e-09, 1.7314e-09]],\n     \n              [[4.0249e-09, 1.4673e-09, 1.2981e-09],\n               [5.7985e-09, 7.6091e-09, 3.2029e-09],\n               [3.9974e-09, 4.9439e-09, 3.8962e-09]]],\n     \n     \n             [[[1.5794e-09, 2.3982e-09, 1.9168e-09],\n               [2.4351e-09, 2.6294e-09, 3.4880e-09],\n               [2.1860e-09, 3.3842e-09, 3.1767e-09]],\n     \n              [[7.3385e-10, 1.1210e-09, 9.0369e-10],\n               [1.3928e-09, 2.4855e-09, 2.0898e-09],\n               [2.5005e-09, 3.4521e-09, 2.7373e-09]],\n     \n              [[1.2959e-09, 2.1456e-09, 1.6843e-09],\n               [1.7823e-09, 2.3289e-09, 2.4848e-09],\n               [1.4151e-09, 2.9211e-09, 3.1540e-09]],\n     \n              ...,\n     \n              [[1.8988e-09, 2.7724e-09, 3.0531e-09],\n               [3.3622e-09, 4.1554e-09, 4.8292e-09],\n               [2.9831e-09, 5.8610e-09, 4.8439e-09]],\n     \n              [[8.5708e-10, 1.5048e-09, 1.3859e-09],\n               [1.6247e-09, 2.1493e-09, 2.2769e-09],\n               [1.6887e-09, 2.3420e-09, 2.0970e-09]],\n     \n              [[3.6733e-09, 3.9016e-09, 1.7622e-09],\n               [3.4657e-09, 1.0239e-08, 7.0737e-09],\n               [1.8349e-09, 9.2087e-09, 1.3337e-08]]],\n     \n     \n             [[[1.5324e-09, 1.2214e-09, 1.7290e-09],\n               [2.4985e-09, 2.0015e-09, 1.9062e-09],\n               [2.2207e-09, 2.1585e-09, 1.8456e-09]],\n     \n              [[1.6255e-09, 1.0035e-09, 1.1191e-09],\n               [2.0223e-09, 1.6396e-09, 2.1215e-09],\n               [2.5396e-09, 3.2032e-09, 2.6442e-09]],\n     \n              [[2.0315e-09, 1.8886e-09, 2.3581e-09],\n               [2.3671e-09, 1.4487e-09, 2.0555e-09],\n               [2.4758e-09, 2.2205e-09, 2.6884e-09]],\n     \n              ...,\n     \n              [[1.6463e-09, 1.8337e-09, 1.5643e-09],\n               [2.5747e-09, 2.0035e-09, 2.1223e-09],\n               [2.3933e-09, 2.6643e-09, 2.4423e-09]],\n     \n              [[1.8458e-09, 1.6002e-09, 1.4138e-09],\n               [2.1476e-09, 1.1774e-09, 1.6024e-09],\n               [1.6142e-09, 1.4487e-09, 1.8944e-09]],\n     \n              [[6.1283e-09, 4.5847e-09, 4.0669e-09],\n               [4.9984e-09, 6.2490e-09, 6.2527e-09],\n               [3.4910e-09, 4.6788e-09, 1.0498e-08]]],\n     \n     \n             ...,\n     \n     \n             [[[2.2439e-09, 2.7245e-09, 3.1814e-09],\n               [2.7771e-09, 2.3162e-09, 2.8469e-09],\n               [2.5308e-09, 3.6374e-09, 2.9591e-09]],\n     \n              [[1.0969e-09, 1.2055e-09, 1.2154e-09],\n               [1.8165e-09, 2.9609e-09, 2.3169e-09],\n               [2.2162e-09, 3.0267e-09, 3.2393e-09]],\n     \n              [[1.6803e-09, 2.7842e-09, 2.4178e-09],\n               [1.9133e-09, 3.9563e-09, 2.7425e-09],\n               [2.5669e-09, 3.9463e-09, 3.7334e-09]],\n     \n              ...,\n     \n              [[1.8471e-09, 2.5681e-09, 2.8947e-09],\n               [2.9974e-09, 3.9169e-09, 4.3779e-09],\n               [3.4134e-09, 4.1867e-09, 4.2027e-09]],\n     \n              [[2.3040e-09, 3.2736e-09, 2.9791e-09],\n               [3.1728e-09, 4.1574e-09, 3.1729e-09],\n               [2.4632e-09, 3.5351e-09, 3.0711e-09]],\n     \n              [[3.6929e-09, 3.8791e-09, 2.4543e-09],\n               [3.8876e-09, 1.3962e-08, 7.2075e-09],\n               [2.2232e-09, 5.8703e-09, 1.1492e-08]]],\n     \n     \n             [[[1.5165e-09, 1.7741e-09, 1.8468e-09],\n               [1.6974e-09, 1.6760e-09, 1.4780e-09],\n               [1.3132e-09, 1.7480e-09, 1.6073e-09]],\n     \n              [[7.6512e-10, 1.0029e-09, 7.4843e-10],\n               [1.4317e-09, 2.4141e-09, 2.0539e-09],\n               [1.2422e-09, 2.1193e-09, 1.2757e-09]],\n     \n              [[1.1997e-09, 1.8825e-09, 1.2180e-09],\n               [1.9482e-09, 3.8748e-09, 2.5200e-09],\n               [1.1094e-09, 2.5547e-09, 1.7103e-09]],\n     \n              ...,\n     \n              [[1.4793e-09, 1.8435e-09, 1.5501e-09],\n               [2.2837e-09, 2.8042e-09, 2.2460e-09],\n               [1.8619e-09, 2.2810e-09, 1.7534e-09]],\n     \n              [[1.8406e-09, 2.5269e-09, 1.7355e-09],\n               [1.7065e-09, 2.5179e-09, 2.1588e-09],\n               [1.6437e-09, 1.8110e-09, 1.4675e-09]],\n     \n              [[3.5837e-09, 5.9390e-09, 2.5493e-09],\n               [4.2188e-09, 1.2120e-08, 5.8892e-09],\n               [2.8665e-09, 5.8302e-09, 3.8616e-09]]],\n     \n     \n             [[[7.9732e-10, 1.5452e-09, 1.6855e-09],\n               [1.5414e-09, 2.1795e-09, 1.9505e-09],\n               [1.2812e-09, 1.5080e-09, 1.3019e-09]],\n     \n              [[5.1192e-10, 8.1288e-10, 5.8041e-10],\n               [7.9748e-10, 1.6804e-09, 1.1036e-09],\n               [1.0372e-09, 9.4187e-10, 1.0329e-09]],\n     \n              [[8.9549e-10, 9.6260e-10, 7.5605e-10],\n               [1.1755e-09, 2.1351e-09, 1.0434e-09],\n               [9.6495e-10, 1.3338e-09, 1.2746e-09]],\n     \n              ...,\n     \n              [[1.2718e-09, 1.4702e-09, 1.2727e-09],\n               [1.4441e-09, 1.7502e-09, 2.0372e-09],\n               [1.5696e-09, 2.5294e-09, 2.2305e-09]],\n     \n              [[8.5945e-10, 1.2235e-09, 1.0368e-09],\n               [1.3223e-09, 1.8094e-09, 1.3082e-09],\n               [7.2408e-10, 1.4393e-09, 1.4176e-09]],\n     \n              [[3.5428e-09, 3.2807e-09, 3.4881e-09],\n               [2.9696e-09, 2.2902e-08, 3.5254e-09],\n               [2.5158e-09, 3.9446e-09, 6.2119e-09]]]])},\n    141: {'exp_avg': tensor([[[[ 1.1116e-05]],\n     \n              [[-3.8642e-05]],\n     \n              [[ 5.7437e-05]],\n     \n              ...,\n     \n              [[-5.8301e-07]],\n     \n              [[ 2.7826e-08]],\n     \n              [[-1.6164e-05]]],\n     \n     \n             [[[ 4.0614e-05]],\n     \n              [[-1.0916e-05]],\n     \n              [[-8.1301e-06]],\n     \n              ...,\n     \n              [[ 1.8520e-06]],\n     \n              [[ 3.0592e-06]],\n     \n              [[ 4.7034e-05]]],\n     \n     \n             [[[ 3.1758e-05]],\n     \n              [[ 1.9267e-05]],\n     \n              [[ 3.1582e-06]],\n     \n              ...,\n     \n              [[ 4.0152e-05]],\n     \n              [[-1.0275e-05]],\n     \n              [[ 1.8904e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-2.4233e-05]],\n     \n              [[ 1.3742e-05]],\n     \n              [[-1.0478e-05]],\n     \n              ...,\n     \n              [[-5.2623e-05]],\n     \n              [[-5.1140e-05]],\n     \n              [[ 1.8683e-06]]],\n     \n     \n             [[[-3.5372e-05]],\n     \n              [[-1.3243e-06]],\n     \n              [[ 3.1458e-05]],\n     \n              ...,\n     \n              [[ 3.8710e-05]],\n     \n              [[-5.8075e-06]],\n     \n              [[-2.0015e-05]]],\n     \n     \n             [[[ 8.2971e-07]],\n     \n              [[ 4.3145e-05]],\n     \n              [[ 2.3014e-05]],\n     \n              ...,\n     \n              [[ 4.6731e-06]],\n     \n              [[-3.5592e-05]],\n     \n              [[ 2.4306e-05]]]]),\n     'exp_avg_sq': tensor([[[[2.2792e-09]],\n     \n              [[3.9220e-09]],\n     \n              [[1.9443e-09]],\n     \n              ...,\n     \n              [[6.2100e-09]],\n     \n              [[2.6832e-09]],\n     \n              [[5.1328e-09]]],\n     \n     \n             [[[1.4004e-09]],\n     \n              [[2.7286e-09]],\n     \n              [[1.8092e-09]],\n     \n              ...,\n     \n              [[2.7224e-09]],\n     \n              [[1.5652e-09]],\n     \n              [[3.0702e-09]]],\n     \n     \n             [[[1.2606e-09]],\n     \n              [[2.3028e-09]],\n     \n              [[1.7755e-09]],\n     \n              ...,\n     \n              [[2.5259e-09]],\n     \n              [[1.4256e-09]],\n     \n              [[1.8816e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[1.4819e-09]],\n     \n              [[4.3086e-09]],\n     \n              [[2.6696e-09]],\n     \n              ...,\n     \n              [[2.8610e-09]],\n     \n              [[2.1514e-09]],\n     \n              [[4.3306e-09]]],\n     \n     \n             [[[1.5674e-09]],\n     \n              [[5.8354e-09]],\n     \n              [[1.8649e-09]],\n     \n              ...,\n     \n              [[5.1995e-09]],\n     \n              [[2.6033e-09]],\n     \n              [[2.2337e-09]]],\n     \n     \n             [[[1.8550e-09]],\n     \n              [[5.7997e-09]],\n     \n              [[2.7762e-09]],\n     \n              ...,\n     \n              [[3.6582e-09]],\n     \n              [[2.9291e-09]],\n     \n              [[1.6930e-09]]]])},\n    142: {'exp_avg': tensor([[[[ 2.1689e-05]],\n     \n              [[-3.8427e-05]],\n     \n              [[-3.0337e-05]],\n     \n              ...,\n     \n              [[-3.1318e-05]],\n     \n              [[ 3.4598e-07]],\n     \n              [[-1.8716e-05]]],\n     \n     \n             [[[-9.3771e-06]],\n     \n              [[-1.0448e-04]],\n     \n              [[ 3.7968e-05]],\n     \n              ...,\n     \n              [[ 1.2099e-05]],\n     \n              [[ 4.6149e-05]],\n     \n              [[ 6.5799e-05]]],\n     \n     \n             [[[ 2.5217e-06]],\n     \n              [[ 1.6008e-05]],\n     \n              [[-3.2744e-05]],\n     \n              ...,\n     \n              [[ 1.2992e-05]],\n     \n              [[-1.8667e-06]],\n     \n              [[ 1.2219e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 3.5546e-05]],\n     \n              [[ 1.2135e-05]],\n     \n              [[-3.5411e-05]],\n     \n              ...,\n     \n              [[-7.0930e-05]],\n     \n              [[-4.2010e-05]],\n     \n              [[-2.6219e-05]]],\n     \n     \n             [[[ 4.9701e-05]],\n     \n              [[ 3.3730e-05]],\n     \n              [[-1.7748e-06]],\n     \n              ...,\n     \n              [[-2.6803e-05]],\n     \n              [[ 2.0111e-05]],\n     \n              [[ 1.7888e-05]]],\n     \n     \n             [[[ 3.7704e-05]],\n     \n              [[-6.6084e-05]],\n     \n              [[ 6.4519e-05]],\n     \n              ...,\n     \n              [[-1.1493e-04]],\n     \n              [[ 8.8754e-06]],\n     \n              [[ 3.3393e-05]]]]),\n     'exp_avg_sq': tensor([[[[1.6365e-09]],\n     \n              [[2.2331e-09]],\n     \n              [[7.3766e-09]],\n     \n              ...,\n     \n              [[5.2857e-09]],\n     \n              [[7.9930e-09]],\n     \n              [[4.0605e-09]]],\n     \n     \n             [[[2.3088e-09]],\n     \n              [[4.7687e-09]],\n     \n              [[1.6752e-09]],\n     \n              ...,\n     \n              [[3.0128e-09]],\n     \n              [[2.2943e-09]],\n     \n              [[2.0479e-09]]],\n     \n     \n             [[[2.3699e-09]],\n     \n              [[3.1184e-09]],\n     \n              [[2.8753e-09]],\n     \n              ...,\n     \n              [[3.3356e-09]],\n     \n              [[2.2176e-09]],\n     \n              [[2.2967e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[3.9127e-09]],\n     \n              [[3.1343e-09]],\n     \n              [[3.2549e-09]],\n     \n              ...,\n     \n              [[4.4994e-09]],\n     \n              [[3.6521e-09]],\n     \n              [[3.2536e-09]]],\n     \n     \n             [[[1.4474e-09]],\n     \n              [[2.7087e-09]],\n     \n              [[2.1783e-09]],\n     \n              ...,\n     \n              [[4.3737e-09]],\n     \n              [[3.9172e-09]],\n     \n              [[1.7132e-09]]],\n     \n     \n             [[[3.0123e-09]],\n     \n              [[3.9472e-09]],\n     \n              [[4.2381e-09]],\n     \n              ...,\n     \n              [[6.0983e-09]],\n     \n              [[3.5485e-09]],\n     \n              [[4.5470e-09]]]])},\n    143: {'exp_avg': tensor([[[[ 3.0274e-05,  2.0648e-05, -2.4156e-06],\n               [ 4.4368e-05, -1.8765e-05, -5.0106e-06],\n               [ 5.5463e-05,  2.1840e-05,  3.2008e-05]],\n     \n              [[-5.9767e-06, -1.8084e-05, -3.5841e-05],\n               [-1.6756e-05, -6.9090e-05, -1.0095e-05],\n               [-1.4710e-06, -6.4311e-05, -6.5062e-05]],\n     \n              [[ 3.9478e-06, -7.7336e-06,  5.2934e-06],\n               [-1.4940e-06, -2.1476e-05, -2.5675e-06],\n               [ 9.5625e-06,  1.6580e-05,  8.7635e-06]],\n     \n              ...,\n     \n              [[-4.2769e-05, -5.6165e-05, -1.3617e-05],\n               [-9.6261e-05, -1.2407e-04, -6.9836e-05],\n               [-3.8443e-05, -8.1767e-05, -1.8276e-06]],\n     \n              [[ 8.3980e-06,  1.1185e-05,  7.1593e-06],\n               [ 4.9206e-06,  1.8847e-05,  1.0378e-05],\n               [ 1.0213e-05,  8.8656e-06,  9.4419e-07]],\n     \n              [[-2.6567e-05, -1.5615e-05, -1.2889e-05],\n               [-4.6555e-05, -1.2947e-05,  1.5794e-05],\n               [-2.4872e-05, -7.1182e-07,  3.5026e-05]]],\n     \n     \n             [[[ 9.1053e-06, -3.0640e-05, -1.5127e-05],\n               [ 1.2054e-05,  6.8088e-06,  3.4312e-05],\n               [ 8.2549e-06, -4.3288e-05,  5.5502e-06]],\n     \n              [[-1.1845e-05, -7.5598e-05,  1.6382e-06],\n               [ 2.6951e-05, -8.7656e-05, -5.6825e-05],\n               [-7.5676e-05, -9.6530e-05, -7.5928e-05]],\n     \n              [[-2.1792e-06,  2.8462e-06,  8.7562e-06],\n               [ 4.8846e-05,  1.5988e-05,  2.2604e-05],\n               [ 3.9170e-05,  3.6171e-05, -1.0472e-05]],\n     \n              ...,\n     \n              [[ 1.9793e-05, -7.3067e-06,  4.0416e-05],\n               [ 1.1647e-06,  4.8114e-06,  4.1918e-05],\n               [-1.9779e-05, -3.2105e-05,  4.0080e-05]],\n     \n              [[ 2.9968e-06, -4.5280e-06,  3.6427e-06],\n               [ 7.1581e-06,  2.9406e-05,  1.7842e-05],\n               [ 1.8776e-05, -3.1118e-06,  2.4135e-05]],\n     \n              [[-3.5258e-05, -4.6766e-05, -5.0559e-05],\n               [ 1.4881e-05,  3.5989e-05,  4.5147e-05],\n               [ 3.7638e-06,  5.4069e-05,  4.3692e-05]]],\n     \n     \n             [[[-1.0912e-06,  3.0697e-05,  1.5799e-05],\n               [-1.0178e-05, -7.7757e-06, -2.6255e-05],\n               [ 1.6884e-05, -6.4470e-06, -7.0772e-06]],\n     \n              [[-3.2650e-05, -1.6819e-05, -4.2731e-05],\n               [ 6.9961e-06, -2.3867e-05, -3.3788e-05],\n               [ 1.8029e-05,  1.0368e-05, -1.0124e-05]],\n     \n              [[-1.9161e-05, -2.1066e-05, -3.6497e-05],\n               [-3.7379e-05, -9.6718e-06,  1.5926e-05],\n               [-3.2224e-05, -8.3472e-06,  1.0059e-05]],\n     \n              ...,\n     \n              [[ 5.1874e-05,  1.9072e-05,  1.0660e-05],\n               [ 7.8011e-07,  6.1033e-06, -9.4379e-06],\n               [ 1.6117e-05, -2.3461e-05, -1.5145e-05]],\n     \n              [[-4.0938e-05, -1.4216e-05, -3.0755e-06],\n               [-2.5333e-05,  1.2951e-05,  2.2180e-06],\n               [-1.1675e-05, -5.0089e-06,  1.3253e-05]],\n     \n              [[ 2.1953e-05,  2.5943e-05, -5.6344e-06],\n               [ 2.2648e-05,  4.2961e-05, -2.4080e-05],\n               [ 3.3378e-05, -5.9196e-06, -2.5587e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-3.5169e-05, -2.8620e-05, -3.1496e-05],\n               [-3.8956e-05,  1.5743e-05,  2.3551e-06],\n               [ 1.0587e-05,  1.5999e-05,  1.4169e-05]],\n     \n              [[ 1.2978e-05,  2.4039e-05,  4.7400e-07],\n               [ 3.8770e-05,  2.8482e-05,  3.9568e-05],\n               [ 1.8795e-06, -2.6364e-05, -3.4508e-05]],\n     \n              [[-2.7315e-05, -2.8304e-05, -1.9098e-05],\n               [ 1.5261e-05, -9.9937e-06, -4.1894e-05],\n               [ 4.7290e-06,  3.3444e-06, -1.6035e-05]],\n     \n              ...,\n     \n              [[-1.6318e-05, -6.5958e-05, -5.1873e-05],\n               [ 5.3734e-06, -2.4598e-05, -2.4926e-05],\n               [ 7.2603e-06, -1.9208e-05, -5.3926e-05]],\n     \n              [[-1.5488e-05,  6.9006e-06, -1.2863e-05],\n               [ 6.7542e-06,  3.8926e-06, -1.5649e-05],\n               [ 1.3797e-05, -4.3386e-06, -2.1656e-05]],\n     \n              [[-1.3680e-05, -1.4756e-05, -3.0966e-05],\n               [-1.4279e-05, -1.6645e-05, -4.9964e-05],\n               [-1.0494e-05, -2.4370e-05, -5.8297e-05]]],\n     \n     \n             [[[ 1.7186e-05,  8.2237e-06, -1.4806e-05],\n               [ 1.7956e-05,  4.3527e-06,  1.1227e-05],\n               [-5.0660e-06, -1.0069e-05, -9.8046e-06]],\n     \n              [[-2.4169e-06,  1.3639e-05, -1.1628e-05],\n               [-6.4180e-05, -3.2126e-05, -1.7918e-05],\n               [-2.1063e-05,  6.5513e-06, -3.4648e-05]],\n     \n              [[ 7.3768e-06,  5.4777e-06,  1.9539e-05],\n               [ 1.1916e-05, -9.8831e-06, -1.8618e-06],\n               [-1.5876e-05,  2.8886e-05,  2.9515e-06]],\n     \n              ...,\n     \n              [[ 3.9384e-05,  2.5248e-05,  7.6232e-06],\n               [ 2.1571e-06,  2.4737e-05,  1.5534e-05],\n               [ 4.7742e-05,  4.7951e-05,  7.2713e-05]],\n     \n              [[ 2.2230e-06,  1.6858e-06,  1.8462e-06],\n               [-2.4151e-05, -2.6435e-05, -2.3257e-05],\n               [-8.8363e-06, -6.3879e-06, -1.0245e-05]],\n     \n              [[-4.4380e-05, -3.0007e-05, -1.1345e-05],\n               [ 2.9663e-05,  1.7479e-05,  7.6100e-06],\n               [-1.3016e-05,  7.0761e-06,  3.1235e-05]]],\n     \n     \n             [[[-1.8628e-06, -1.7968e-06, -7.8047e-06],\n               [ 7.9331e-06,  3.2926e-05,  3.7269e-06],\n               [-1.0783e-05, -1.2967e-05,  3.9022e-06]],\n     \n              [[ 1.7538e-05, -2.2230e-05,  9.2509e-06],\n               [ 1.1205e-05,  1.9986e-05,  8.5030e-07],\n               [ 2.8162e-05,  4.3015e-05,  2.6103e-05]],\n     \n              [[ 3.1551e-05,  1.2501e-05,  7.4250e-05],\n               [ 2.5753e-05,  1.4445e-07, -4.3792e-07],\n               [ 2.9588e-05, -2.0275e-05, -2.8185e-05]],\n     \n              ...,\n     \n              [[-1.7121e-05,  4.5972e-05,  2.9276e-06],\n               [-2.6966e-06, -3.1443e-05, -3.8453e-05],\n               [-1.0114e-05, -2.8793e-05, -3.3809e-05]],\n     \n              [[ 5.2230e-05,  5.2176e-05,  3.7191e-05],\n               [ 4.3426e-05,  3.8803e-05,  3.0039e-05],\n               [ 2.9577e-05,  3.4527e-05,  1.1298e-05]],\n     \n              [[-8.0493e-05, -9.1888e-05, -3.7348e-05],\n               [-4.5829e-05, -3.3630e-05, -2.8035e-05],\n               [ 2.3524e-06, -1.6599e-05,  4.0907e-06]]]]),\n     'exp_avg_sq': tensor([[[[1.0533e-09, 1.0013e-09, 1.2739e-09],\n               [1.8669e-09, 1.8394e-09, 2.2449e-09],\n               [1.8771e-09, 2.0345e-09, 2.5411e-09]],\n     \n              [[4.7951e-10, 8.4492e-10, 6.3005e-10],\n               [1.7184e-09, 2.2941e-09, 2.0560e-09],\n               [2.1224e-09, 3.3297e-09, 2.7658e-09]],\n     \n              [[7.9233e-10, 1.0667e-09, 8.0189e-10],\n               [1.4733e-09, 2.2167e-09, 1.7128e-09],\n               [1.3744e-09, 2.1751e-09, 1.8463e-09]],\n     \n              ...,\n     \n              [[1.0435e-09, 1.7773e-09, 1.0871e-09],\n               [2.1107e-09, 3.4108e-09, 2.4816e-09],\n               [2.2704e-09, 3.4460e-09, 1.9754e-09]],\n     \n              [[4.6058e-10, 7.6604e-10, 5.1337e-10],\n               [1.0136e-09, 2.0916e-09, 1.5076e-09],\n               [8.0071e-10, 1.6737e-09, 1.1104e-09]],\n     \n              [[7.4138e-10, 1.6508e-09, 1.0389e-09],\n               [2.4916e-09, 3.2317e-09, 2.7746e-09],\n               [2.6284e-09, 4.0078e-09, 3.0821e-09]]],\n     \n     \n             [[[1.9523e-09, 2.0126e-09, 2.2694e-09],\n               [2.6837e-09, 3.3723e-09, 3.2574e-09],\n               [1.7910e-09, 3.7410e-09, 3.7902e-09]],\n     \n              [[1.1747e-09, 1.9981e-09, 2.3554e-09],\n               [2.6283e-09, 3.4379e-09, 3.1767e-09],\n               [3.2202e-09, 4.0252e-09, 3.5246e-09]],\n     \n              [[1.2585e-09, 1.5191e-09, 1.1798e-09],\n               [1.6952e-09, 2.3761e-09, 1.9757e-09],\n               [1.5504e-09, 1.8419e-09, 1.7140e-09]],\n     \n              ...,\n     \n              [[1.4937e-09, 2.7559e-09, 1.8322e-09],\n               [2.0916e-09, 2.7684e-09, 2.2884e-09],\n               [2.0892e-09, 2.9203e-09, 2.1551e-09]],\n     \n              [[6.1183e-10, 8.7968e-10, 5.9564e-10],\n               [1.1095e-09, 2.0032e-09, 1.9099e-09],\n               [9.5789e-10, 1.9037e-09, 1.6652e-09]],\n     \n              [[1.5804e-09, 2.5947e-09, 1.8944e-09],\n               [2.3943e-09, 2.3426e-09, 2.4432e-09],\n               [2.2507e-09, 3.0795e-09, 3.2044e-09]]],\n     \n     \n             [[[1.6101e-09, 1.8904e-09, 2.8769e-09],\n               [1.7631e-09, 2.0542e-09, 3.8367e-09],\n               [1.6050e-09, 1.6116e-09, 3.3973e-09]],\n     \n              [[1.5081e-09, 1.6366e-09, 9.8429e-10],\n               [1.9293e-09, 1.4002e-09, 1.3929e-09],\n               [1.5672e-09, 1.7357e-09, 1.0033e-09]],\n     \n              [[1.1722e-09, 1.1612e-09, 1.1244e-09],\n               [1.5622e-09, 1.7212e-09, 1.1174e-09],\n               [1.1969e-09, 1.2223e-09, 9.3407e-10]],\n     \n              ...,\n     \n              [[1.0640e-09, 2.1498e-09, 2.0674e-09],\n               [1.2443e-09, 2.4097e-09, 4.1880e-09],\n               [1.5570e-09, 2.4344e-09, 2.4585e-09]],\n     \n              [[4.3535e-10, 6.0678e-10, 6.0285e-10],\n               [6.9472e-10, 9.8995e-10, 1.0128e-09],\n               [4.9037e-10, 1.0049e-09, 1.1327e-09]],\n     \n              [[2.2072e-09, 2.5396e-09, 1.3585e-09],\n               [2.8238e-09, 3.1017e-09, 2.0188e-09],\n               [1.8721e-09, 2.8545e-09, 3.1622e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[1.4883e-09, 1.4497e-09, 1.4346e-09],\n               [1.6801e-09, 1.7455e-09, 1.9224e-09],\n               [1.5831e-09, 1.5588e-09, 1.5339e-09]],\n     \n              [[7.3746e-10, 1.1561e-09, 8.2756e-10],\n               [1.6416e-09, 3.3901e-09, 2.1120e-09],\n               [1.5746e-09, 1.9512e-09, 1.7808e-09]],\n     \n              [[1.2147e-09, 1.7183e-09, 1.6899e-09],\n               [2.0555e-09, 2.1588e-09, 1.8538e-09],\n               [1.6571e-09, 1.3825e-09, 1.3861e-09]],\n     \n              ...,\n     \n              [[1.7571e-09, 2.2651e-09, 1.5543e-09],\n               [3.1301e-09, 4.1476e-09, 2.8801e-09],\n               [2.3196e-09, 2.1671e-09, 2.5157e-09]],\n     \n              [[5.5782e-10, 1.0530e-09, 9.1484e-10],\n               [1.7255e-09, 3.5230e-09, 1.8818e-09],\n               [1.5162e-09, 2.0730e-09, 1.0826e-09]],\n     \n              [[9.5226e-10, 8.1694e-10, 6.7563e-10],\n               [2.0742e-09, 3.0307e-09, 2.1517e-09],\n               [2.4781e-09, 4.0181e-09, 3.2440e-09]]],\n     \n     \n             [[[8.6734e-10, 1.3491e-09, 1.1308e-09],\n               [1.0452e-09, 1.3480e-09, 1.8071e-09],\n               [9.3378e-10, 1.4708e-09, 1.2320e-09]],\n     \n              [[1.1760e-09, 2.2346e-09, 1.6129e-09],\n               [2.0648e-09, 2.8751e-09, 2.4799e-09],\n               [1.7877e-09, 3.0733e-09, 2.0871e-09]],\n     \n              [[9.0956e-10, 1.3779e-09, 1.0626e-09],\n               [1.2463e-09, 3.0132e-09, 2.0649e-09],\n               [9.5611e-10, 2.1568e-09, 1.6573e-09]],\n     \n              ...,\n     \n              [[2.5530e-09, 3.1388e-09, 2.3823e-09],\n               [2.9233e-09, 4.5768e-09, 3.7759e-09],\n               [2.3646e-09, 4.0598e-09, 3.5538e-09]],\n     \n              [[6.4074e-10, 1.2399e-09, 8.8231e-10],\n               [9.3071e-10, 1.8548e-09, 1.6121e-09],\n               [7.6003e-10, 1.7185e-09, 1.4875e-09]],\n     \n              [[1.1910e-09, 1.9563e-09, 1.2506e-09],\n               [1.5134e-09, 2.3009e-09, 2.2519e-09],\n               [1.4249e-09, 2.7626e-09, 2.0802e-09]]],\n     \n     \n             [[[1.9552e-09, 2.6162e-09, 2.3250e-09],\n               [1.4269e-09, 1.5269e-09, 1.5928e-09],\n               [1.0545e-09, 2.0131e-09, 1.6456e-09]],\n     \n              [[1.6006e-09, 1.8464e-09, 1.4379e-09],\n               [1.2328e-09, 1.9810e-09, 1.5817e-09],\n               [1.4010e-09, 2.2680e-09, 1.8429e-09]],\n     \n              [[1.1492e-09, 1.5773e-09, 1.5634e-09],\n               [1.0251e-09, 1.2344e-09, 1.2456e-09],\n               [1.0905e-09, 1.4296e-09, 1.0586e-09]],\n     \n              ...,\n     \n              [[2.0515e-09, 3.1678e-09, 2.9334e-09],\n               [2.1472e-09, 3.6215e-09, 3.2204e-09],\n               [1.2697e-09, 1.4805e-09, 1.0965e-09]],\n     \n              [[7.3845e-10, 1.3020e-09, 9.3343e-10],\n               [8.9116e-10, 1.4636e-09, 9.5727e-10],\n               [5.5922e-10, 7.4872e-10, 7.9148e-10]],\n     \n              [[2.9565e-09, 4.0535e-09, 2.3880e-09],\n               [2.7164e-09, 3.7348e-09, 2.9263e-09],\n               [1.6695e-09, 2.0948e-09, 1.4794e-09]]]])},\n    144: {'exp_avg': tensor([[[[ 7.8628e-05]],\n     \n              [[ 3.1793e-05]],\n     \n              [[-6.0825e-06]],\n     \n              ...,\n     \n              [[-8.0486e-06]],\n     \n              [[-1.2334e-04]],\n     \n              [[ 6.2169e-06]]],\n     \n     \n             [[[ 8.4085e-06]],\n     \n              [[ 1.2764e-05]],\n     \n              [[ 5.4589e-05]],\n     \n              ...,\n     \n              [[-1.3486e-06]],\n     \n              [[-4.8716e-05]],\n     \n              [[-3.6029e-05]]],\n     \n     \n             [[[ 5.9334e-05]],\n     \n              [[-3.8539e-05]],\n     \n              [[-6.7581e-07]],\n     \n              ...,\n     \n              [[-4.4158e-05]],\n     \n              [[-2.0231e-05]],\n     \n              [[ 6.9299e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-1.2807e-05]],\n     \n              [[-3.4318e-05]],\n     \n              [[-7.7364e-05]],\n     \n              ...,\n     \n              [[ 3.9957e-06]],\n     \n              [[-3.0753e-05]],\n     \n              [[-1.8333e-05]]],\n     \n     \n             [[[-3.0580e-05]],\n     \n              [[ 2.5446e-05]],\n     \n              [[-1.3292e-05]],\n     \n              ...,\n     \n              [[ 2.1429e-05]],\n     \n              [[-5.4620e-05]],\n     \n              [[-1.2839e-07]]],\n     \n     \n             [[[ 7.9219e-05]],\n     \n              [[ 1.3743e-04]],\n     \n              [[ 2.7475e-05]],\n     \n              ...,\n     \n              [[-4.1080e-05]],\n     \n              [[ 1.9281e-05]],\n     \n              [[ 8.6761e-05]]]]),\n     'exp_avg_sq': tensor([[[[6.3990e-09]],\n     \n              [[5.9442e-09]],\n     \n              [[3.1492e-09]],\n     \n              ...,\n     \n              [[6.0963e-09]],\n     \n              [[1.0898e-08]],\n     \n              [[5.2707e-09]]],\n     \n     \n             [[[1.9739e-09]],\n     \n              [[3.4311e-09]],\n     \n              [[2.5914e-09]],\n     \n              ...,\n     \n              [[1.4990e-09]],\n     \n              [[3.1024e-09]],\n     \n              [[7.5760e-09]]],\n     \n     \n             [[[4.0865e-09]],\n     \n              [[7.6737e-09]],\n     \n              [[2.8336e-09]],\n     \n              ...,\n     \n              [[4.0077e-09]],\n     \n              [[5.0168e-09]],\n     \n              [[5.1884e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[4.6915e-09]],\n     \n              [[7.2315e-09]],\n     \n              [[3.4465e-09]],\n     \n              ...,\n     \n              [[3.6879e-09]],\n     \n              [[5.9834e-09]],\n     \n              [[5.8755e-09]]],\n     \n     \n             [[[4.2467e-09]],\n     \n              [[6.3197e-09]],\n     \n              [[2.3254e-09]],\n     \n              ...,\n     \n              [[3.1116e-09]],\n     \n              [[3.0069e-09]],\n     \n              [[3.6522e-09]]],\n     \n     \n             [[[6.5144e-09]],\n     \n              [[1.2245e-08]],\n     \n              [[3.9185e-09]],\n     \n              ...,\n     \n              [[6.0881e-09]],\n     \n              [[8.6163e-09]],\n     \n              [[5.1737e-09]]]])},\n    145: {'exp_avg': tensor([[[[ 8.7422e-06]],\n     \n              [[ 1.8862e-05]],\n     \n              [[-1.7093e-05]],\n     \n              ...,\n     \n              [[-7.3656e-06]],\n     \n              [[-2.9669e-07]],\n     \n              [[ 1.9853e-05]]],\n     \n     \n             [[[-5.5435e-05]],\n     \n              [[ 5.5374e-05]],\n     \n              [[ 3.7234e-05]],\n     \n              ...,\n     \n              [[ 2.5932e-05]],\n     \n              [[ 4.5209e-05]],\n     \n              [[-8.2330e-05]]],\n     \n     \n             [[[ 6.9893e-06]],\n     \n              [[ 9.9159e-06]],\n     \n              [[-1.0925e-05]],\n     \n              ...,\n     \n              [[-1.4513e-05]],\n     \n              [[-2.5752e-05]],\n     \n              [[ 2.4137e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 2.6049e-05]],\n     \n              [[-4.2305e-05]],\n     \n              [[ 3.4175e-05]],\n     \n              ...,\n     \n              [[-2.6620e-05]],\n     \n              [[-9.3259e-05]],\n     \n              [[-1.5853e-05]]],\n     \n     \n             [[[ 2.4543e-05]],\n     \n              [[-6.8555e-06]],\n     \n              [[-5.0519e-06]],\n     \n              ...,\n     \n              [[ 1.8442e-05]],\n     \n              [[ 1.1466e-04]],\n     \n              [[-6.3060e-06]]],\n     \n     \n             [[[ 3.1928e-05]],\n     \n              [[ 1.5146e-05]],\n     \n              [[ 1.5495e-05]],\n     \n              ...,\n     \n              [[ 3.8724e-05]],\n     \n              [[-2.2104e-05]],\n     \n              [[ 5.0538e-05]]]]),\n     'exp_avg_sq': tensor([[[[6.2997e-09]],\n     \n              [[4.4884e-09]],\n     \n              [[2.0017e-09]],\n     \n              ...,\n     \n              [[3.4418e-09]],\n     \n              [[8.8533e-10]],\n     \n              [[1.7464e-09]]],\n     \n     \n             [[[6.1064e-09]],\n     \n              [[6.6530e-09]],\n     \n              [[4.1251e-09]],\n     \n              ...,\n     \n              [[4.4830e-09]],\n     \n              [[5.3987e-09]],\n     \n              [[5.0441e-09]]],\n     \n     \n             [[[5.0187e-09]],\n     \n              [[4.6825e-09]],\n     \n              [[3.8954e-09]],\n     \n              ...,\n     \n              [[3.6857e-09]],\n     \n              [[3.5252e-09]],\n     \n              [[3.5961e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[1.2471e-09]],\n     \n              [[2.6390e-09]],\n     \n              [[4.8941e-09]],\n     \n              ...,\n     \n              [[3.0238e-09]],\n     \n              [[1.0221e-08]],\n     \n              [[3.4745e-09]]],\n     \n     \n             [[[1.9324e-09]],\n     \n              [[1.5602e-09]],\n     \n              [[4.6570e-09]],\n     \n              ...,\n     \n              [[2.4340e-09]],\n     \n              [[7.0874e-09]],\n     \n              [[2.8763e-09]]],\n     \n     \n             [[[3.4066e-09]],\n     \n              [[2.8086e-09]],\n     \n              [[3.2428e-09]],\n     \n              ...,\n     \n              [[3.2612e-09]],\n     \n              [[4.6903e-09]],\n     \n              [[4.0107e-09]]]])},\n    146: {'exp_avg': tensor([[[[-2.5510e-05,  2.3996e-05,  1.1864e-05],\n               [-1.4129e-05,  3.9896e-06, -1.2572e-05],\n               [-1.7463e-05, -2.7465e-05, -2.1919e-05]],\n     \n              [[ 3.7786e-05,  1.5678e-06,  6.1918e-06],\n               [-6.2795e-06, -2.3006e-05, -5.4155e-05],\n               [-2.1788e-06, -1.0592e-05, -4.1084e-05]],\n     \n              [[-4.7680e-06, -2.1397e-05, -2.0645e-05],\n               [-2.0888e-05,  1.0753e-05, -1.4169e-05],\n               [ 1.5877e-05,  3.9399e-06, -2.9468e-05]],\n     \n              ...,\n     \n              [[-3.1417e-05,  3.2850e-05, -3.6470e-05],\n               [ 1.4219e-06,  4.3359e-05, -1.5015e-05],\n               [ 9.7804e-06,  2.9802e-05,  3.4839e-05]],\n     \n              [[ 3.3962e-05,  3.9681e-05, -9.4122e-06],\n               [ 4.8418e-05,  3.4952e-05,  1.1139e-05],\n               [ 1.6073e-05,  2.7991e-05,  8.1792e-06]],\n     \n              [[-1.8793e-05,  3.1204e-05, -3.6109e-05],\n               [-1.8856e-05,  2.7498e-05, -7.8706e-06],\n               [ 1.5023e-05,  1.1322e-05,  5.1267e-05]]],\n     \n     \n             [[[-2.0507e-05, -3.1468e-05, -2.2519e-05],\n               [-1.4113e-05,  6.8018e-06, -9.9546e-06],\n               [ 1.0701e-05,  2.1659e-05,  2.0564e-05]],\n     \n              [[ 1.2493e-05,  3.8381e-05,  1.3964e-05],\n               [ 3.2132e-06, -1.7243e-05, -1.0350e-05],\n               [-3.2156e-05,  1.3862e-05,  3.6864e-06]],\n     \n              [[-1.1558e-05, -1.8237e-05,  8.0661e-07],\n               [-1.4928e-05, -1.7659e-05, -1.7398e-05],\n               [ 1.5895e-05,  2.3753e-05,  1.9151e-05]],\n     \n              ...,\n     \n              [[ 2.1975e-05,  5.6163e-07, -2.7477e-05],\n               [ 4.0451e-05, -2.0438e-05, -3.6617e-05],\n               [ 1.9535e-05, -1.0465e-05, -2.4292e-05]],\n     \n              [[-8.7340e-06,  3.6618e-07, -4.5390e-06],\n               [ 2.1567e-07,  6.7930e-06,  6.7448e-06],\n               [ 5.5405e-06, -1.7407e-05,  3.0614e-06]],\n     \n              [[ 4.3991e-05,  1.4069e-05,  1.1072e-05],\n               [ 4.5258e-05,  3.5591e-05, -1.7732e-05],\n               [ 3.7687e-05,  2.5060e-05,  6.5348e-06]]],\n     \n     \n             [[[-8.0763e-06, -3.6704e-05, -4.6316e-05],\n               [ 1.2848e-05,  1.5035e-05,  4.0492e-05],\n               [ 4.4778e-05,  1.5296e-06,  3.1094e-06]],\n     \n              [[ 8.9591e-07,  3.3656e-05,  2.0559e-05],\n               [ 3.5997e-05,  5.3719e-05,  5.0285e-06],\n               [ 6.4739e-05,  7.2021e-05, -3.6904e-06]],\n     \n              [[ 2.1312e-05,  2.6524e-05, -1.8721e-05],\n               [ 2.8104e-05,  1.0154e-05, -4.4663e-05],\n               [ 3.5870e-05, -2.2592e-05, -3.3921e-05]],\n     \n              ...,\n     \n              [[ 2.0005e-05,  4.5851e-05, -1.0870e-05],\n               [-2.3874e-05,  1.6844e-05, -2.6212e-05],\n               [ 7.8379e-06,  3.5952e-07, -3.3148e-05]],\n     \n              [[-1.0198e-05, -2.5557e-05, -1.1949e-05],\n               [-3.9904e-05, -1.0411e-05, -4.9106e-05],\n               [-3.4048e-05, -1.2270e-05,  1.0648e-05]],\n     \n              [[-3.2341e-05, -2.7180e-05, -5.3119e-05],\n               [-8.9187e-06, -5.4955e-05, -3.8291e-05],\n               [-9.9483e-06, -4.4093e-06,  7.9555e-06]]],\n     \n     \n             ...,\n     \n     \n             [[[ 2.3923e-05, -1.1421e-05,  4.2380e-07],\n               [ 4.6627e-05, -4.3525e-05,  1.0205e-05],\n               [ 8.9918e-06,  2.2126e-06, -4.1924e-05]],\n     \n              [[-1.1435e-05,  5.5760e-06,  2.0870e-05],\n               [ 4.4427e-05, -6.8631e-05, -2.3661e-05],\n               [ 9.4605e-06, -1.1665e-04, -5.5581e-05]],\n     \n              [[-1.2387e-05,  5.1368e-07, -3.1561e-06],\n               [ 2.7303e-05,  1.0150e-05,  1.6090e-05],\n               [ 1.8723e-05,  6.1467e-05,  2.1834e-05]],\n     \n              ...,\n     \n              [[-1.6833e-05,  5.0621e-07,  5.1411e-05],\n               [ 8.4501e-06,  3.9132e-05,  1.6882e-05],\n               [-4.1363e-06,  2.1664e-05, -2.0611e-05]],\n     \n              [[-5.3137e-06, -2.7002e-05, -2.1493e-05],\n               [-2.6108e-05, -1.9781e-05, -1.6104e-05],\n               [-1.9883e-05, -2.9014e-06, -4.6821e-06]],\n     \n              [[ 2.1830e-06, -3.8558e-06,  1.7034e-05],\n               [-3.2904e-05, -2.2711e-05, -1.7946e-05],\n               [-3.7950e-05, -2.6487e-05, -9.2790e-06]]],\n     \n     \n             [[[-1.1302e-05,  2.7764e-05,  5.2608e-05],\n               [-2.6890e-05,  2.3070e-05,  5.5429e-05],\n               [ 3.1908e-05, -2.6403e-05, -6.7665e-06]],\n     \n              [[-3.1134e-05, -5.6460e-05, -1.7227e-05],\n               [-1.0644e-05, -2.1374e-05, -1.8313e-05],\n               [ 2.3317e-05, -1.7427e-06,  4.9727e-05]],\n     \n              [[ 1.0457e-05, -1.5152e-05, -1.7406e-05],\n               [-1.3850e-05,  2.4435e-07, -3.8441e-05],\n               [-1.4782e-05, -5.0779e-06, -2.6494e-05]],\n     \n              ...,\n     \n              [[-1.1592e-05,  1.0534e-05, -5.5012e-06],\n               [-6.4997e-06,  8.1462e-06,  2.6401e-05],\n               [-6.2497e-05,  7.8753e-06,  1.0111e-05]],\n     \n              [[-2.6087e-05, -3.8667e-05, -4.3460e-05],\n               [-2.4428e-05, -8.8035e-05, -8.9604e-05],\n               [-3.2146e-05, -1.9193e-05, -5.3088e-05]],\n     \n              [[ 2.5790e-06,  9.0919e-06,  3.7478e-05],\n               [-5.4344e-06,  5.0406e-05,  5.3909e-05],\n               [-2.1497e-05,  1.2596e-05,  3.4585e-05]]],\n     \n     \n             [[[-3.7378e-05, -2.2355e-06,  1.9029e-05],\n               [-1.5917e-05, -6.7371e-06,  4.3411e-05],\n               [-3.0470e-06, -6.8695e-06,  5.6546e-05]],\n     \n              [[-8.8252e-06, -2.8176e-06,  1.6335e-06],\n               [-2.1699e-05,  5.8432e-07, -2.3955e-06],\n               [ 5.8026e-06, -1.2909e-05, -1.4984e-05]],\n     \n              [[-1.9872e-05,  2.2263e-05,  4.5191e-05],\n               [ 1.5922e-05,  6.4048e-05,  7.1766e-06],\n               [ 6.8463e-07, -1.7727e-05, -2.3311e-05]],\n     \n              ...,\n     \n              [[-3.6418e-05, -3.3857e-05, -1.1632e-05],\n               [-1.3522e-06,  9.2557e-06, -1.7237e-05],\n               [ 2.2278e-05, -1.0654e-05, -2.9226e-05]],\n     \n              [[ 1.9970e-05,  2.1053e-05,  4.0182e-05],\n               [ 9.4133e-06,  4.6658e-06,  3.6394e-05],\n               [ 2.3949e-06, -4.5899e-06, -1.3089e-05]],\n     \n              [[ 2.9393e-05, -2.8838e-05, -1.5707e-05],\n               [ 5.3142e-05,  1.5106e-05, -1.3549e-06],\n               [ 8.1737e-06,  1.2256e-05,  1.8264e-05]]]]),\n     'exp_avg_sq': tensor([[[[1.2928e-09, 9.1619e-10, 5.4504e-10],\n               [2.1961e-09, 1.9568e-09, 5.7745e-10],\n               [1.6750e-09, 1.3461e-09, 8.4959e-10]],\n     \n              [[2.6349e-09, 5.1584e-09, 4.5072e-09],\n               [3.2078e-09, 3.7021e-09, 3.0659e-09],\n               [4.3658e-09, 2.4347e-09, 2.6783e-09]],\n     \n              [[1.4569e-09, 1.5599e-09, 8.6371e-10],\n               [2.9393e-09, 2.3231e-09, 8.9449e-10],\n               [2.6683e-09, 2.8334e-09, 7.1811e-10]],\n     \n              ...,\n     \n              [[4.6049e-10, 1.3577e-09, 3.0635e-09],\n               [4.0762e-10, 1.7780e-09, 3.1112e-09],\n               [3.6076e-10, 1.0821e-09, 2.0102e-09]],\n     \n              [[1.6284e-09, 1.1728e-09, 8.4914e-10],\n               [2.3053e-09, 1.8411e-09, 9.0043e-10],\n               [2.0432e-09, 1.5405e-09, 9.5115e-10]],\n     \n              [[1.4013e-09, 1.8195e-09, 2.4028e-09],\n               [1.2405e-09, 2.6055e-09, 3.4561e-09],\n               [1.7239e-09, 2.5335e-09, 2.3522e-09]]],\n     \n     \n             [[[1.7738e-09, 2.6311e-09, 1.7463e-09],\n               [1.9262e-09, 2.2575e-09, 2.0033e-09],\n               [7.8575e-10, 1.1844e-09, 8.8397e-10]],\n     \n              [[1.6887e-09, 3.8068e-09, 4.8274e-09],\n               [1.8138e-09, 3.3505e-09, 2.6143e-09],\n               [2.0291e-09, 2.8885e-09, 2.3981e-09]],\n     \n              [[1.0984e-09, 1.8101e-09, 1.5921e-09],\n               [1.7171e-09, 3.0251e-09, 2.6258e-09],\n               [1.7209e-09, 3.3291e-09, 2.4115e-09]],\n     \n              ...,\n     \n              [[9.9759e-10, 1.2723e-09, 1.2689e-09],\n               [1.1102e-09, 1.1059e-09, 1.5052e-09],\n               [6.7792e-10, 1.3614e-09, 1.6501e-09]],\n     \n              [[6.4056e-10, 7.9937e-10, 6.3033e-10],\n               [9.6074e-10, 1.4773e-09, 1.1898e-09],\n               [6.6243e-10, 8.4989e-10, 7.5761e-10]],\n     \n              [[1.3455e-09, 1.2804e-09, 1.1047e-09],\n               [1.7354e-09, 1.7515e-09, 1.6119e-09],\n               [1.2920e-09, 1.2373e-09, 1.0354e-09]]],\n     \n     \n             [[[1.2365e-09, 2.7755e-09, 2.4583e-09],\n               [1.5995e-09, 3.7554e-09, 3.0047e-09],\n               [1.3980e-09, 2.7030e-09, 2.3902e-09]],\n     \n              [[1.2283e-09, 2.5687e-09, 2.7438e-09],\n               [2.1135e-09, 4.3388e-09, 4.7526e-09],\n               [2.9318e-09, 3.7324e-09, 4.6697e-09]],\n     \n              [[1.4660e-09, 2.1702e-09, 2.1374e-09],\n               [1.6682e-09, 4.1959e-09, 3.0672e-09],\n               [1.7093e-09, 3.4211e-09, 2.9055e-09]],\n     \n              ...,\n     \n              [[8.9489e-10, 2.5339e-09, 2.9674e-09],\n               [1.3776e-09, 2.6659e-09, 3.7657e-09],\n               [1.2378e-09, 2.6341e-09, 4.2046e-09]],\n     \n              [[5.3169e-10, 5.5492e-10, 5.3198e-10],\n               [1.4505e-09, 1.2693e-09, 1.2364e-09],\n               [1.3465e-09, 1.2111e-09, 1.0749e-09]],\n     \n              [[9.2942e-10, 1.4670e-09, 1.2371e-09],\n               [1.1776e-09, 2.2645e-09, 1.6790e-09],\n               [1.6513e-09, 1.7451e-09, 1.4399e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[1.2952e-09, 1.6015e-09, 1.8775e-09],\n               [2.1756e-09, 2.8521e-09, 2.6625e-09],\n               [2.9030e-09, 3.5109e-09, 2.9478e-09]],\n     \n              [[1.4180e-09, 2.5438e-09, 3.3087e-09],\n               [2.2346e-09, 3.3155e-09, 5.5440e-09],\n               [1.9365e-09, 4.4248e-09, 5.2399e-09]],\n     \n              [[2.7860e-09, 4.5802e-09, 2.7543e-09],\n               [3.8966e-09, 5.8695e-09, 3.6390e-09],\n               [3.3996e-09, 5.8228e-09, 3.3074e-09]],\n     \n              ...,\n     \n              [[3.0333e-09, 1.5182e-09, 4.2161e-09],\n               [3.1433e-09, 1.4199e-09, 3.7026e-09],\n               [1.9467e-09, 1.0884e-09, 3.7356e-09]],\n     \n              [[1.3967e-09, 1.8101e-09, 1.7196e-09],\n               [1.6666e-09, 2.0494e-09, 1.8152e-09],\n               [1.2938e-09, 1.4145e-09, 1.2955e-09]],\n     \n              [[1.3944e-09, 1.0426e-09, 1.2503e-09],\n               [1.6461e-09, 1.3453e-09, 1.5524e-09],\n               [1.7821e-09, 1.2812e-09, 1.4722e-09]]],\n     \n     \n             [[[1.4325e-09, 2.4336e-09, 2.6650e-09],\n               [1.5179e-09, 2.9569e-09, 2.7735e-09],\n               [1.2890e-09, 1.4396e-09, 1.4715e-09]],\n     \n              [[1.7241e-09, 3.3256e-09, 4.0837e-09],\n               [2.0680e-09, 2.7199e-09, 5.3146e-09],\n               [2.4572e-09, 3.0956e-09, 4.9183e-09]],\n     \n              [[1.4251e-09, 2.7208e-09, 2.5873e-09],\n               [1.8311e-09, 4.2119e-09, 3.9937e-09],\n               [1.8219e-09, 3.0819e-09, 3.1260e-09]],\n     \n              ...,\n     \n              [[1.6833e-09, 1.5582e-09, 1.3736e-09],\n               [2.6648e-09, 1.7770e-09, 1.0907e-09],\n               [2.0627e-09, 2.0975e-09, 1.4153e-09]],\n     \n              [[6.2938e-10, 2.0093e-09, 3.2419e-09],\n               [9.4516e-10, 3.8885e-09, 4.9671e-09],\n               [7.6359e-10, 1.8893e-09, 2.9683e-09]],\n     \n              [[1.3369e-09, 1.3842e-09, 1.2341e-09],\n               [2.0651e-09, 2.5363e-09, 1.9172e-09],\n               [1.7327e-09, 1.9132e-09, 1.8943e-09]]],\n     \n     \n             [[[8.4381e-10, 1.1118e-09, 1.3175e-09],\n               [1.2218e-09, 1.5222e-09, 1.9813e-09],\n               [7.7647e-10, 1.3229e-09, 1.6135e-09]],\n     \n              [[4.1371e-09, 7.0609e-09, 5.4618e-09],\n               [2.3068e-09, 3.3696e-09, 3.3568e-09],\n               [8.7045e-10, 1.1190e-09, 1.6429e-09]],\n     \n              [[1.4961e-09, 2.4548e-09, 2.0284e-09],\n               [2.4051e-09, 5.1552e-09, 3.6566e-09],\n               [1.5019e-09, 3.3650e-09, 2.6258e-09]],\n     \n              ...,\n     \n              [[2.2203e-09, 1.8783e-09, 2.0734e-09],\n               [1.9827e-09, 3.1234e-09, 2.6080e-09],\n               [1.4293e-09, 1.9627e-09, 2.2582e-09]],\n     \n              [[1.2280e-09, 2.4517e-09, 1.5955e-09],\n               [1.2202e-09, 2.3087e-09, 1.3953e-09],\n               [1.4838e-09, 1.7371e-09, 1.3386e-09]],\n     \n              [[1.6551e-09, 1.2792e-09, 9.9699e-10],\n               [1.6520e-09, 1.5397e-09, 1.1939e-09],\n               [2.1962e-09, 2.2164e-09, 1.4245e-09]]]])},\n    147: {'exp_avg': tensor([[[[-1.9017e-05]],\n     \n              [[ 1.8783e-05]],\n     \n              [[ 3.8005e-05]],\n     \n              ...,\n     \n              [[-1.8222e-05]],\n     \n              [[-3.2918e-05]],\n     \n              [[ 1.2666e-05]]],\n     \n     \n             [[[ 2.3694e-05]],\n     \n              [[-2.4618e-05]],\n     \n              [[-4.7551e-05]],\n     \n              ...,\n     \n              [[ 5.7454e-05]],\n     \n              [[ 7.2285e-06]],\n     \n              [[ 2.5809e-05]]],\n     \n     \n             [[[-1.6537e-05]],\n     \n              [[ 3.5777e-06]],\n     \n              [[-1.2711e-05]],\n     \n              ...,\n     \n              [[ 5.5397e-05]],\n     \n              [[-1.5506e-05]],\n     \n              [[ 3.3291e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-6.6059e-05]],\n     \n              [[ 3.5136e-05]],\n     \n              [[-7.0716e-05]],\n     \n              ...,\n     \n              [[-3.6451e-05]],\n     \n              [[ 2.1089e-05]],\n     \n              [[-4.4837e-05]]],\n     \n     \n             [[[-3.2994e-05]],\n     \n              [[-4.1090e-05]],\n     \n              [[ 5.1414e-05]],\n     \n              ...,\n     \n              [[ 2.4674e-05]],\n     \n              [[ 4.2195e-06]],\n     \n              [[ 2.4216e-05]]],\n     \n     \n             [[[-3.6545e-05]],\n     \n              [[-1.6735e-05]],\n     \n              [[ 2.9192e-05]],\n     \n              ...,\n     \n              [[-3.9651e-05]],\n     \n              [[-1.4555e-05]],\n     \n              [[-2.5432e-05]]]]),\n     'exp_avg_sq': tensor([[[[5.0485e-10]],\n     \n              [[5.6577e-10]],\n     \n              [[1.6937e-09]],\n     \n              ...,\n     \n              [[9.8951e-10]],\n     \n              [[1.1537e-09]],\n     \n              [[7.6383e-10]]],\n     \n     \n             [[[2.5894e-09]],\n     \n              [[2.2297e-09]],\n     \n              [[6.4188e-09]],\n     \n              ...,\n     \n              [[5.1252e-09]],\n     \n              [[4.2655e-09]],\n     \n              [[7.6639e-09]]],\n     \n     \n             [[[1.6493e-09]],\n     \n              [[1.1476e-09]],\n     \n              [[2.2191e-09]],\n     \n              ...,\n     \n              [[2.9082e-09]],\n     \n              [[2.0167e-09]],\n     \n              [[1.7095e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[1.8037e-09]],\n     \n              [[1.7793e-09]],\n     \n              [[3.3677e-09]],\n     \n              ...,\n     \n              [[3.7685e-09]],\n     \n              [[2.9871e-09]],\n     \n              [[2.0145e-09]]],\n     \n     \n             [[[2.2715e-09]],\n     \n              [[1.7606e-09]],\n     \n              [[4.1552e-09]],\n     \n              ...,\n     \n              [[6.2999e-09]],\n     \n              [[6.0296e-09]],\n     \n              [[2.3283e-09]]],\n     \n     \n             [[[1.4168e-09]],\n     \n              [[1.2273e-09]],\n     \n              [[2.3635e-09]],\n     \n              ...,\n     \n              [[2.4400e-09]],\n     \n              [[2.6969e-09]],\n     \n              [[1.3987e-09]]]])},\n    148: {'exp_avg': tensor([[[[-6.1059e-05]],\n     \n              [[-7.7664e-05]],\n     \n              [[ 5.5388e-05]],\n     \n              ...,\n     \n              [[ 2.3899e-05]],\n     \n              [[-5.3131e-06]],\n     \n              [[-4.1462e-05]]],\n     \n     \n             [[[-1.2414e-05]],\n     \n              [[ 1.4135e-05]],\n     \n              [[-7.0447e-05]],\n     \n              ...,\n     \n              [[ 3.6205e-05]],\n     \n              [[ 1.2667e-05]],\n     \n              [[ 4.3845e-06]]],\n     \n     \n             [[[-9.0268e-06]],\n     \n              [[-4.0843e-05]],\n     \n              [[ 2.1858e-05]],\n     \n              ...,\n     \n              [[-3.0045e-05]],\n     \n              [[ 9.4377e-06]],\n     \n              [[-2.1185e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 1.3376e-05]],\n     \n              [[ 5.8091e-05]],\n     \n              [[-4.5323e-05]],\n     \n              ...,\n     \n              [[-2.9542e-05]],\n     \n              [[-2.8802e-05]],\n     \n              [[ 3.0062e-05]]],\n     \n     \n             [[[-4.1129e-05]],\n     \n              [[-3.0544e-05]],\n     \n              [[-3.8903e-05]],\n     \n              ...,\n     \n              [[-1.3847e-05]],\n     \n              [[-2.4730e-05]],\n     \n              [[ 4.0120e-05]]],\n     \n     \n             [[[ 5.8510e-05]],\n     \n              [[-4.6803e-05]],\n     \n              [[ 7.7616e-06]],\n     \n              ...,\n     \n              [[ 2.7119e-05]],\n     \n              [[ 5.7677e-05]],\n     \n              [[-1.9188e-05]]]]),\n     'exp_avg_sq': tensor([[[[5.8151e-09]],\n     \n              [[6.6080e-09]],\n     \n              [[2.9023e-09]],\n     \n              ...,\n     \n              [[4.1388e-09]],\n     \n              [[2.2587e-09]],\n     \n              [[3.4245e-09]]],\n     \n     \n             [[[4.6593e-09]],\n     \n              [[5.8829e-09]],\n     \n              [[3.3973e-09]],\n     \n              ...,\n     \n              [[3.1743e-09]],\n     \n              [[4.5727e-09]],\n     \n              [[3.1209e-09]]],\n     \n     \n             [[[4.9699e-09]],\n     \n              [[7.6603e-09]],\n     \n              [[2.0731e-09]],\n     \n              ...,\n     \n              [[3.7566e-09]],\n     \n              [[1.5494e-09]],\n     \n              [[3.4344e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[7.6289e-09]],\n     \n              [[1.2051e-08]],\n     \n              [[6.6379e-09]],\n     \n              ...,\n     \n              [[4.1005e-09]],\n     \n              [[3.6381e-09]],\n     \n              [[2.5842e-09]]],\n     \n     \n             [[[1.7633e-09]],\n     \n              [[3.7642e-09]],\n     \n              [[3.0991e-09]],\n     \n              ...,\n     \n              [[4.5090e-09]],\n     \n              [[1.2882e-09]],\n     \n              [[2.9664e-09]]],\n     \n     \n             [[[3.2518e-09]],\n     \n              [[3.9023e-09]],\n     \n              [[4.6470e-09]],\n     \n              ...,\n     \n              [[4.1523e-09]],\n     \n              [[1.1668e-08]],\n     \n              [[3.5738e-09]]]])},\n    149: {'exp_avg': tensor([[[[-1.6501e-05,  9.3267e-06,  6.3589e-06],\n               [-7.5236e-05, -4.2558e-05, -1.8428e-05],\n               [-5.3290e-06, -3.8253e-05, -6.8851e-06]],\n     \n              [[-1.6383e-05, -1.2728e-05,  3.5989e-06],\n               [ 8.1614e-06, -2.1321e-06,  1.4718e-05],\n               [-4.8756e-05, -2.0510e-05, -2.5451e-05]],\n     \n              [[ 1.3667e-05, -2.1936e-05, -3.6775e-05],\n               [-3.5595e-05, -2.4849e-05, -1.7348e-05],\n               [-3.0091e-05, -1.1621e-05, -4.7888e-05]],\n     \n              ...,\n     \n              [[ 3.6147e-06,  2.1127e-05,  2.8489e-05],\n               [-1.6825e-05,  3.2746e-05,  2.8778e-05],\n               [-2.1974e-05, -4.0934e-06,  1.7123e-05]],\n     \n              [[ 1.8646e-05,  3.5901e-05,  3.8827e-05],\n               [-2.3260e-05,  4.4843e-06, -6.7223e-06],\n               [ 8.5947e-06,  1.9556e-05,  9.3474e-06]],\n     \n              [[ 3.4162e-05, -8.5727e-06,  6.9367e-07],\n               [-2.3383e-05,  9.0418e-06, -1.9719e-05],\n               [-1.5771e-05, -1.3542e-05,  4.4726e-05]]],\n     \n     \n             [[[-1.4093e-05,  2.6823e-05, -4.2937e-06],\n               [ 2.5819e-06,  5.3671e-05, -9.8360e-06],\n               [ 1.0419e-06, -5.8096e-07, -1.0438e-05]],\n     \n              [[-1.7296e-05, -8.7705e-06, -1.7045e-05],\n               [ 1.4612e-05,  6.9852e-06, -8.2079e-06],\n               [-4.8624e-06, -1.0191e-08,  2.1440e-05]],\n     \n              [[ 1.8222e-05,  8.7995e-06,  3.5600e-07],\n               [ 8.7199e-06,  2.3094e-05, -1.1750e-05],\n               [ 1.3089e-05,  2.4077e-06, -1.8377e-05]],\n     \n              ...,\n     \n              [[ 9.6116e-06,  2.0738e-05,  1.3745e-05],\n               [-1.4549e-05, -3.8934e-05, -3.8068e-05],\n               [-5.1950e-05, -4.2761e-05, -2.7037e-05]],\n     \n              [[ 1.5317e-05, -2.0951e-05, -4.3687e-05],\n               [-1.5602e-05, -2.5011e-05, -5.1990e-05],\n               [ 1.6344e-05,  2.2163e-05,  6.2091e-06]],\n     \n              [[ 3.2060e-05,  9.0716e-05,  1.4540e-05],\n               [ 3.6568e-05,  7.5900e-05,  1.7048e-05],\n               [ 8.2016e-06,  5.3746e-05,  4.0000e-06]]],\n     \n     \n             [[[ 3.4646e-06, -1.0895e-05, -1.1855e-05],\n               [-9.5826e-06,  7.8975e-06,  1.8163e-05],\n               [-1.0770e-05, -2.6173e-05, -3.7389e-06]],\n     \n              [[-4.3597e-05, -6.1104e-05, -3.8410e-06],\n               [-2.6141e-05, -3.7339e-05,  1.6244e-05],\n               [-8.5555e-06, -1.7211e-05, -1.4592e-05]],\n     \n              [[-8.5750e-07,  4.1864e-05,  1.3499e-06],\n               [ 2.1496e-05, -2.5162e-06,  2.7056e-05],\n               [ 1.0798e-06,  2.0239e-06,  1.2310e-05]],\n     \n              ...,\n     \n              [[-6.4385e-06,  8.8816e-06,  2.6542e-05],\n               [ 1.9069e-05,  7.3388e-05,  3.0354e-05],\n               [-1.9627e-05,  7.2865e-05,  3.1086e-05]],\n     \n              [[ 2.5413e-05,  5.7335e-06, -1.5551e-06],\n               [ 1.4437e-05,  4.0071e-05,  1.1955e-05],\n               [ 1.0365e-05,  1.4073e-05, -1.0709e-05]],\n     \n              [[-2.6608e-05, -2.6670e-05, -2.3776e-05],\n               [-5.6522e-05,  4.1376e-06,  1.2422e-05],\n               [-5.4631e-05, -8.0513e-07,  1.6543e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-5.7903e-05, -9.2872e-05, -6.9425e-05],\n               [-5.7475e-06, -6.0719e-05, -1.0197e-04],\n               [-1.8816e-05, -3.0463e-05, -1.9589e-05]],\n     \n              [[-2.0480e-05, -2.7122e-06,  3.6998e-06],\n               [-7.5497e-06, -1.7974e-05, -1.4055e-05],\n               [ 1.6235e-05,  4.0713e-05,  4.2609e-05]],\n     \n              [[-3.0283e-05, -1.7212e-05, -8.6785e-06],\n               [-3.3107e-05, -5.9047e-05, -7.1279e-06],\n               [-6.9318e-05, -4.6147e-05, -1.7109e-05]],\n     \n              ...,\n     \n              [[ 3.0944e-05,  5.6126e-05,  4.7474e-05],\n               [-2.0215e-07,  2.2024e-05, -1.3768e-06],\n               [ 1.4846e-05,  5.2726e-06,  4.7099e-07]],\n     \n              [[-1.5154e-05, -2.1396e-05,  8.4317e-06],\n               [-2.3599e-05,  1.4706e-05,  1.4084e-06],\n               [ 6.5821e-06,  1.2195e-06,  3.4732e-06]],\n     \n              [[-2.5142e-05, -2.6513e-05, -1.8248e-05],\n               [-6.8978e-06, -2.4576e-05, -5.7043e-06],\n               [-2.4034e-06, -2.6692e-05, -5.4341e-06]]],\n     \n     \n             [[[-5.2936e-05, -5.9607e-05,  2.6031e-06],\n               [-2.8942e-05, -3.7759e-05, -3.9224e-05],\n               [-2.7020e-05, -2.1552e-05, -3.7455e-05]],\n     \n              [[-2.1928e-05, -4.5943e-06, -1.8473e-06],\n               [-4.6612e-05,  2.1044e-05, -1.1902e-05],\n               [-2.4883e-05,  1.3085e-05,  1.7410e-05]],\n     \n              [[ 1.2568e-05,  3.5088e-05, -2.4558e-05],\n               [-3.9656e-07,  2.1696e-05,  4.6187e-05],\n               [ 2.5238e-05,  3.6021e-05,  4.3432e-05]],\n     \n              ...,\n     \n              [[ 1.9845e-05,  7.4429e-06,  3.9730e-05],\n               [-1.0995e-05, -1.6251e-05, -4.6667e-05],\n               [-4.3497e-05, -7.8931e-05,  3.1283e-05]],\n     \n              [[-1.2837e-05, -3.7602e-05, -1.7978e-05],\n               [-1.4463e-05,  5.8638e-05, -5.3927e-05],\n               [ 4.1373e-05, -3.9525e-05, -2.0178e-05]],\n     \n              [[ 1.7600e-05, -3.6937e-06, -1.2290e-05],\n               [-1.4414e-05, -7.7580e-05, -1.3082e-05],\n               [ 9.3898e-06, -8.0682e-05, -2.1185e-05]]],\n     \n     \n             [[[-2.3309e-05, -3.0459e-05, -3.7370e-05],\n               [ 3.2962e-06,  1.2715e-05, -9.3965e-06],\n               [-1.3901e-06, -6.3206e-06,  9.9984e-06]],\n     \n              [[ 1.5578e-05,  2.2404e-06, -7.9987e-06],\n               [ 2.7884e-05,  2.2950e-05,  3.5451e-05],\n               [ 2.9164e-05, -5.2854e-06, -1.2984e-05]],\n     \n              [[-2.3614e-06, -1.6803e-05,  3.8053e-07],\n               [ 1.1508e-07, -2.0228e-05, -2.6715e-05],\n               [ 2.2205e-05, -6.0356e-06, -3.3587e-06]],\n     \n              ...,\n     \n              [[ 7.5359e-07, -1.4742e-05, -3.7259e-05],\n               [ 6.0540e-06,  1.3267e-05,  1.9248e-05],\n               [ 2.6606e-06,  1.4831e-05,  4.7199e-05]],\n     \n              [[ 2.6477e-06,  2.0788e-05, -2.5730e-05],\n               [ 5.6880e-06,  4.9515e-06, -2.2579e-05],\n               [-1.6660e-06, -1.3243e-05, -2.6817e-05]],\n     \n              [[-5.9857e-06,  1.5462e-05,  2.0402e-05],\n               [-5.9766e-06, -9.7391e-06, -5.7274e-06],\n               [ 3.5611e-06,  9.2085e-07, -1.3636e-05]]]]),\n     'exp_avg_sq': tensor([[[[1.5554e-09, 2.6157e-09, 1.7191e-09],\n               [3.1913e-09, 3.0132e-09, 3.7075e-09],\n               [1.4177e-09, 2.6394e-09, 2.1484e-09]],\n     \n              [[1.8396e-09, 2.1448e-09, 1.9201e-09],\n               [2.4480e-09, 2.6979e-09, 2.6750e-09],\n               [2.0901e-09, 2.6710e-09, 2.2802e-09]],\n     \n              [[9.0993e-10, 1.4168e-09, 1.6021e-09],\n               [2.9547e-09, 5.0054e-09, 3.9671e-09],\n               [2.7793e-09, 3.6138e-09, 4.1854e-09]],\n     \n              ...,\n     \n              [[1.9643e-09, 2.2519e-09, 1.8896e-09],\n               [3.3366e-09, 3.7144e-09, 4.1576e-09],\n               [2.9379e-09, 4.3556e-09, 5.1026e-09]],\n     \n              [[1.4405e-09, 2.0964e-09, 1.6713e-09],\n               [1.9384e-09, 1.5175e-09, 1.8700e-09],\n               [1.6064e-09, 1.8890e-09, 1.9093e-09]],\n     \n              [[2.5126e-09, 4.6964e-09, 2.7406e-09],\n               [3.2837e-09, 5.3685e-09, 3.4872e-09],\n               [3.2602e-09, 3.6036e-09, 2.5565e-09]]],\n     \n     \n             [[[1.0781e-09, 2.6452e-09, 9.3494e-10],\n               [1.4695e-09, 3.9805e-09, 1.0164e-09],\n               [9.9617e-10, 2.1889e-09, 7.3382e-10]],\n     \n              [[1.3983e-09, 1.8504e-09, 1.2590e-09],\n               [2.1402e-09, 2.3733e-09, 1.8214e-09],\n               [1.3949e-09, 1.8127e-09, 1.4045e-09]],\n     \n              [[6.0507e-10, 1.0228e-09, 7.4258e-10],\n               [2.2333e-09, 3.4101e-09, 1.6916e-09],\n               [1.8207e-09, 2.5509e-09, 1.4486e-09]],\n     \n              ...,\n     \n              [[1.0187e-09, 1.5467e-09, 8.9715e-10],\n               [2.3048e-09, 4.0721e-09, 2.0144e-09],\n               [3.2198e-09, 3.5156e-09, 2.0730e-09]],\n     \n              [[9.2924e-10, 1.4525e-09, 8.9853e-10],\n               [1.1457e-09, 2.0631e-09, 1.0644e-09],\n               [7.4678e-10, 1.4174e-09, 7.4770e-10]],\n     \n              [[1.6171e-09, 2.7482e-09, 9.4825e-10],\n               [2.3894e-09, 2.8931e-09, 8.3674e-10],\n               [1.9231e-09, 2.8587e-09, 6.0317e-10]]],\n     \n     \n             [[[1.2023e-09, 2.0073e-09, 1.5244e-09],\n               [1.2436e-09, 1.7436e-09, 1.5075e-09],\n               [5.6853e-10, 8.8912e-10, 7.4104e-10]],\n     \n              [[2.2222e-09, 2.6976e-09, 2.0817e-09],\n               [1.9854e-09, 2.3743e-09, 2.1449e-09],\n               [1.0527e-09, 1.4164e-09, 1.1068e-09]],\n     \n              [[1.3555e-09, 1.7391e-09, 1.5958e-09],\n               [2.2926e-09, 3.5907e-09, 2.7947e-09],\n               [2.9619e-09, 3.5379e-09, 3.7969e-09]],\n     \n              ...,\n     \n              [[1.0124e-09, 1.3169e-09, 1.3880e-09],\n               [2.2861e-09, 3.4366e-09, 3.1076e-09],\n               [2.1633e-09, 3.3094e-09, 3.0191e-09]],\n     \n              [[1.0007e-09, 1.3586e-09, 8.2951e-10],\n               [6.6176e-10, 8.6847e-10, 7.6636e-10],\n               [2.6771e-10, 5.3195e-10, 4.1848e-10]],\n     \n              [[2.5385e-09, 3.1571e-09, 2.3641e-09],\n               [2.4850e-09, 2.5949e-09, 2.3710e-09],\n               [1.5338e-09, 1.4299e-09, 1.1635e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[1.9728e-09, 4.4479e-09, 3.7160e-09],\n               [2.8387e-09, 5.0018e-09, 4.2101e-09],\n               [1.4892e-09, 2.9737e-09, 2.3684e-09]],\n     \n              [[1.1947e-09, 1.5700e-09, 1.4638e-09],\n               [2.0376e-09, 3.0944e-09, 2.2713e-09],\n               [1.9367e-09, 2.7541e-09, 1.7130e-09]],\n     \n              [[9.8473e-10, 1.2850e-09, 8.5966e-10],\n               [2.0111e-09, 2.7917e-09, 2.1734e-09],\n               [2.7692e-09, 3.5703e-09, 2.4679e-09]],\n     \n              ...,\n     \n              [[1.1712e-09, 1.7562e-09, 1.8418e-09],\n               [2.8142e-09, 4.8819e-09, 2.8529e-09],\n               [3.0571e-09, 4.3493e-09, 4.2825e-09]],\n     \n              [[2.4914e-10, 3.8069e-10, 3.3868e-10],\n               [3.7714e-10, 6.4814e-10, 3.7359e-10],\n               [2.4505e-10, 4.7106e-10, 2.9905e-10]],\n     \n              [[1.8215e-09, 2.9217e-09, 2.0444e-09],\n               [1.9875e-09, 2.9408e-09, 2.2742e-09],\n               [1.4006e-09, 2.3896e-09, 1.6628e-09]]],\n     \n     \n             [[[1.5234e-09, 2.7424e-09, 1.7937e-09],\n               [2.9298e-09, 4.4655e-09, 3.4492e-09],\n               [1.9636e-09, 2.8347e-09, 2.1843e-09]],\n     \n              [[2.2906e-09, 3.0212e-09, 2.9010e-09],\n               [2.6920e-09, 3.5243e-09, 3.8349e-09],\n               [2.1009e-09, 2.8696e-09, 2.7939e-09]],\n     \n              [[1.4045e-09, 2.0289e-09, 1.6857e-09],\n               [3.3866e-09, 6.7749e-09, 3.4946e-09],\n               [4.1987e-09, 4.5711e-09, 4.1607e-09]],\n     \n              ...,\n     \n              [[1.3468e-09, 2.5305e-09, 2.2596e-09],\n               [2.3603e-09, 4.1228e-09, 3.8178e-09],\n               [3.6556e-09, 3.8910e-09, 4.6917e-09]],\n     \n              [[1.8959e-09, 2.7841e-09, 1.7719e-09],\n               [2.5112e-09, 1.8127e-09, 2.4698e-09],\n               [1.8406e-09, 2.2149e-09, 2.3031e-09]],\n     \n              [[2.4687e-09, 3.1325e-09, 2.3778e-09],\n               [2.9159e-09, 3.4679e-09, 3.7920e-09],\n               [2.9824e-09, 3.8236e-09, 2.5612e-09]]],\n     \n     \n             [[[4.0181e-10, 1.4770e-09, 1.5100e-09],\n               [9.7635e-10, 1.8659e-09, 1.5902e-09],\n               [4.7522e-10, 8.9416e-10, 7.7458e-10]],\n     \n              [[4.2013e-10, 1.0509e-09, 1.1030e-09],\n               [7.7409e-10, 1.3747e-09, 1.6034e-09],\n               [6.5310e-10, 9.6039e-10, 1.3293e-09]],\n     \n              [[2.7460e-10, 5.8308e-10, 1.0408e-09],\n               [6.9180e-10, 1.6665e-09, 2.4056e-09],\n               [8.5153e-10, 1.6523e-09, 3.0610e-09]],\n     \n              ...,\n     \n              [[4.3290e-10, 9.0056e-10, 9.0408e-10],\n               [6.0840e-10, 1.4275e-09, 2.3674e-09],\n               [9.8824e-10, 1.7124e-09, 2.7113e-09]],\n     \n              [[3.9237e-10, 1.3016e-09, 1.2049e-09],\n               [5.9403e-10, 1.0801e-09, 1.3161e-09],\n               [8.4170e-10, 1.3206e-09, 1.3303e-09]],\n     \n              [[3.3986e-10, 8.0264e-10, 1.3571e-09],\n               [8.7392e-10, 1.4200e-09, 1.8066e-09],\n               [9.1817e-10, 1.3956e-09, 1.6218e-09]]]])},\n    150: {'exp_avg': tensor([[[[ 2.1633e-05]],\n     \n              [[-4.4164e-05]],\n     \n              [[-4.0180e-05]],\n     \n              ...,\n     \n              [[-1.7764e-05]],\n     \n              [[ 4.4028e-05]],\n     \n              [[-1.4062e-05]]],\n     \n     \n             [[[ 1.7825e-05]],\n     \n              [[ 2.3740e-05]],\n     \n              [[-5.5761e-05]],\n     \n              ...,\n     \n              [[-5.2451e-05]],\n     \n              [[-1.1524e-04]],\n     \n              [[-1.5823e-05]]],\n     \n     \n             [[[-5.5358e-05]],\n     \n              [[-7.1914e-05]],\n     \n              [[-9.6432e-05]],\n     \n              ...,\n     \n              [[ 3.0098e-05]],\n     \n              [[-6.9418e-05]],\n     \n              [[ 3.5167e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-2.8156e-05]],\n     \n              [[ 1.9511e-05]],\n     \n              [[ 3.9246e-05]],\n     \n              ...,\n     \n              [[ 2.1671e-05]],\n     \n              [[-6.2625e-05]],\n     \n              [[ 1.1352e-05]]],\n     \n     \n             [[[ 8.9476e-06]],\n     \n              [[-5.7863e-05]],\n     \n              [[-2.5885e-05]],\n     \n              ...,\n     \n              [[-4.1115e-05]],\n     \n              [[-7.3128e-06]],\n     \n              [[-6.6215e-06]]],\n     \n     \n             [[[ 5.9191e-05]],\n     \n              [[ 1.9402e-05]],\n     \n              [[-1.6649e-05]],\n     \n              ...,\n     \n              [[-1.1498e-05]],\n     \n              [[ 1.1932e-07]],\n     \n              [[-6.9935e-06]]]]),\n     'exp_avg_sq': tensor([[[[4.7438e-09]],\n     \n              [[4.4622e-09]],\n     \n              [[5.4860e-09]],\n     \n              ...,\n     \n              [[5.5668e-09]],\n     \n              [[6.5840e-09]],\n     \n              [[2.3950e-09]]],\n     \n     \n             [[[7.4119e-09]],\n     \n              [[4.8087e-09]],\n     \n              [[1.0872e-08]],\n     \n              ...,\n     \n              [[1.7177e-08]],\n     \n              [[8.7426e-09]],\n     \n              [[4.3852e-09]]],\n     \n     \n             [[[5.9575e-09]],\n     \n              [[3.3627e-09]],\n     \n              [[6.7460e-09]],\n     \n              ...,\n     \n              [[6.1478e-09]],\n     \n              [[6.9170e-09]],\n     \n              [[2.5430e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[2.7111e-09]],\n     \n              [[1.0602e-09]],\n     \n              [[2.5157e-09]],\n     \n              ...,\n     \n              [[3.8853e-09]],\n     \n              [[2.4849e-09]],\n     \n              [[7.7394e-10]]],\n     \n     \n             [[[5.4595e-09]],\n     \n              [[2.2945e-09]],\n     \n              [[3.9651e-09]],\n     \n              ...,\n     \n              [[4.4724e-09]],\n     \n              [[5.5826e-09]],\n     \n              [[2.0974e-09]]],\n     \n     \n             [[[5.2668e-09]],\n     \n              [[1.8724e-09]],\n     \n              [[4.3079e-09]],\n     \n              ...,\n     \n              [[4.6829e-09]],\n     \n              [[4.9858e-09]],\n     \n              [[2.1217e-09]]]])},\n    151: {'exp_avg': tensor([[[[ 1.9262e-05]],\n     \n              [[-4.5272e-05]],\n     \n              [[ 2.1773e-05]],\n     \n              ...,\n     \n              [[ 4.7631e-05]],\n     \n              [[-2.2994e-05]],\n     \n              [[ 6.1177e-05]]],\n     \n     \n             [[[ 8.9428e-06]],\n     \n              [[-3.8475e-05]],\n     \n              [[ 1.1941e-04]],\n     \n              ...,\n     \n              [[ 1.9207e-05]],\n     \n              [[ 3.6756e-05]],\n     \n              [[ 8.2925e-05]]],\n     \n     \n             [[[ 6.0346e-06]],\n     \n              [[-1.3106e-05]],\n     \n              [[ 9.6565e-06]],\n     \n              ...,\n     \n              [[-4.1018e-06]],\n     \n              [[ 3.5002e-05]],\n     \n              [[ 4.0351e-06]]],\n     \n     \n             ...,\n     \n     \n             [[[-6.2987e-05]],\n     \n              [[ 1.2463e-05]],\n     \n              [[-7.7034e-05]],\n     \n              ...,\n     \n              [[ 7.8385e-05]],\n     \n              [[-6.0378e-05]],\n     \n              [[-5.0366e-05]]],\n     \n     \n             [[[-1.9034e-05]],\n     \n              [[ 7.7274e-06]],\n     \n              [[ 2.5912e-05]],\n     \n              ...,\n     \n              [[-4.3695e-06]],\n     \n              [[-1.2233e-05]],\n     \n              [[-1.7231e-05]]],\n     \n     \n             [[[-3.2103e-05]],\n     \n              [[-2.9313e-05]],\n     \n              [[ 5.1140e-05]],\n     \n              ...,\n     \n              [[-1.0026e-04]],\n     \n              [[ 7.6683e-07]],\n     \n              [[-3.0543e-05]]]]),\n     'exp_avg_sq': tensor([[[[5.8298e-09]],\n     \n              [[5.9249e-09]],\n     \n              [[4.2291e-09]],\n     \n              ...,\n     \n              [[2.9067e-09]],\n     \n              [[5.1588e-09]],\n     \n              [[4.5392e-09]]],\n     \n     \n             [[[3.7722e-09]],\n     \n              [[5.0238e-09]],\n     \n              [[6.4963e-09]],\n     \n              ...,\n     \n              [[4.9475e-09]],\n     \n              [[5.3584e-09]],\n     \n              [[4.5391e-09]]],\n     \n     \n             [[[3.4136e-09]],\n     \n              [[4.5449e-09]],\n     \n              [[2.9432e-09]],\n     \n              ...,\n     \n              [[4.2836e-09]],\n     \n              [[4.1336e-09]],\n     \n              [[3.7183e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[2.8380e-09]],\n     \n              [[2.1327e-09]],\n     \n              [[5.8068e-09]],\n     \n              ...,\n     \n              [[3.1357e-09]],\n     \n              [[1.2366e-08]],\n     \n              [[4.3176e-09]]],\n     \n     \n             [[[5.1812e-09]],\n     \n              [[2.8082e-09]],\n     \n              [[2.0250e-09]],\n     \n              ...,\n     \n              [[2.8706e-09]],\n     \n              [[1.4094e-09]],\n     \n              [[2.7325e-09]]],\n     \n     \n             [[[2.1515e-09]],\n     \n              [[5.6840e-09]],\n     \n              [[4.9800e-09]],\n     \n              ...,\n     \n              [[4.3746e-09]],\n     \n              [[3.1330e-09]],\n     \n              [[3.3502e-09]]]])},\n    152: {'exp_avg': tensor([[[[ 1.1428e-05,  3.3913e-05,  8.5786e-06],\n               [-1.3373e-05,  3.9730e-05,  3.8078e-05],\n               [-1.1915e-04,  3.3950e-06,  3.8451e-05]],\n     \n              [[ 3.0845e-07,  1.1204e-05,  2.6774e-05],\n               [-4.8167e-05, -4.4405e-05, -3.3439e-05],\n               [ 1.3969e-06,  2.0283e-05,  6.1260e-06]],\n     \n              [[ 1.6207e-05, -3.9254e-05, -3.1572e-06],\n               [ 1.8267e-05, -2.3544e-05,  2.0573e-05],\n               [-3.0341e-05, -3.1940e-05, -1.5021e-05]],\n     \n              ...,\n     \n              [[-2.2185e-06, -2.0687e-05,  8.9076e-06],\n               [ 8.9087e-06,  1.1718e-05, -9.6079e-07],\n               [-1.7248e-05, -1.8870e-05, -1.9611e-05]],\n     \n              [[ 6.5665e-06,  7.8755e-08,  2.7217e-05],\n               [-5.3633e-06,  1.4911e-05, -1.2620e-05],\n               [ 1.4768e-05,  1.7154e-05, -1.8665e-05]],\n     \n              [[ 1.4278e-05, -4.6696e-05,  3.5365e-05],\n               [-5.3924e-05, -8.8217e-06, -5.3400e-05],\n               [-2.7472e-05, -1.1579e-05,  3.5474e-05]]],\n     \n     \n             [[[ 8.1140e-06, -4.2539e-06,  1.6774e-05],\n               [ 7.0708e-06,  3.0871e-05,  4.2124e-05],\n               [ 4.3586e-05,  4.2590e-05,  3.1775e-05]],\n     \n              [[-5.9266e-05, -3.9404e-05, -2.5425e-05],\n               [-1.0663e-05, -9.4016e-06, -3.4167e-05],\n               [-3.1105e-06,  1.6454e-05, -8.7845e-06]],\n     \n              [[-3.4847e-05,  1.1947e-05,  2.2004e-06],\n               [-2.3924e-05,  3.0575e-05, -1.8450e-05],\n               [-1.6199e-05, -1.7161e-05, -1.5411e-05]],\n     \n              ...,\n     \n              [[-7.4971e-06,  1.5190e-05,  1.9715e-06],\n               [-1.2724e-05,  1.7142e-05, -3.0957e-05],\n               [-2.3053e-05,  1.7785e-05, -1.0245e-05]],\n     \n              [[-2.1118e-05, -3.6581e-05, -6.2926e-06],\n               [ 1.2555e-05, -1.2082e-05,  1.8768e-05],\n               [-1.7281e-05, -3.6822e-05, -9.2876e-06]],\n     \n              [[-4.9081e-05, -1.2799e-06,  2.9486e-05],\n               [-2.2740e-05, -2.3183e-05, -2.2034e-05],\n               [ 1.1088e-05, -4.6160e-06,  2.9803e-06]]],\n     \n     \n             [[[ 1.7059e-05,  1.4694e-05,  8.9860e-06],\n               [-4.0435e-05,  1.1506e-05, -3.4477e-05],\n               [-1.4861e-05, -7.6294e-07,  1.4820e-05]],\n     \n              [[-1.6076e-05, -1.3700e-05, -1.6049e-05],\n               [-1.2347e-05, -3.5548e-05, -2.7004e-05],\n               [-2.5060e-05, -2.0552e-05, -3.9464e-06]],\n     \n              [[ 7.8846e-06, -1.5372e-05,  3.9132e-06],\n               [-2.0835e-05,  1.1663e-05,  8.7373e-07],\n               [-1.3987e-05,  1.7923e-05,  3.4763e-05]],\n     \n              ...,\n     \n              [[ 3.4873e-05,  8.6276e-06, -2.4553e-05],\n               [ 1.3975e-05, -2.3916e-06, -1.2681e-05],\n               [-1.7498e-05, -1.5054e-05, -2.5438e-05]],\n     \n              [[ 8.6220e-07, -1.5220e-05, -8.5318e-07],\n               [ 2.3400e-06,  1.3534e-05,  2.2013e-05],\n               [ 2.0296e-05,  5.6963e-05,  3.2679e-05]],\n     \n              [[ 2.5441e-06,  7.5089e-06,  2.4496e-05],\n               [-3.7277e-05, -2.5080e-07,  4.7257e-05],\n               [-5.1065e-05, -3.8903e-05,  1.2999e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 1.3710e-05, -5.4393e-06, -2.2467e-05],\n               [-1.2748e-05,  4.3095e-05,  5.0165e-05],\n               [ 1.4474e-05,  6.6083e-05,  4.3611e-05]],\n     \n              [[-1.9230e-05, -1.6775e-05, -1.4516e-05],\n               [-3.8090e-05, -1.9278e-05, -6.3087e-05],\n               [-3.3464e-05, -5.5066e-05, -1.8730e-05]],\n     \n              [[-3.9321e-05, -2.1598e-05,  1.7821e-06],\n               [-9.9791e-06,  9.0494e-06, -2.7211e-06],\n               [-2.3224e-05, -2.5125e-05, -2.1839e-05]],\n     \n              ...,\n     \n              [[-3.6379e-05, -1.8703e-05, -4.1112e-06],\n               [-6.3639e-05, -6.3928e-05,  2.2041e-06],\n               [-3.9640e-05, -2.5890e-05,  7.7821e-06]],\n     \n              [[-2.2028e-05, -5.1301e-06, -2.1679e-05],\n               [-1.2281e-05, -4.4029e-06,  5.4108e-06],\n               [-2.3794e-05, -2.8334e-05, -2.2765e-05]],\n     \n              [[-3.1059e-05, -1.4265e-05,  1.6758e-06],\n               [-2.7201e-05,  8.7198e-06,  2.3279e-05],\n               [ 3.1547e-05,  4.7705e-05,  4.1575e-05]]],\n     \n     \n             [[[-1.6932e-05, -3.2432e-05, -5.2650e-05],\n               [ 1.6747e-06, -4.1884e-05, -3.2509e-05],\n               [-4.2879e-05, -7.1184e-05, -7.2819e-05]],\n     \n              [[ 2.7670e-05,  1.3897e-05,  1.6840e-05],\n               [-2.3181e-06,  9.5316e-06,  2.2080e-05],\n               [ 1.5074e-05,  1.6249e-05,  4.3610e-05]],\n     \n              [[-2.4185e-05, -4.2818e-06,  1.2784e-05],\n               [-1.6722e-06,  1.7541e-05, -2.2235e-05],\n               [ 1.0171e-06, -1.9812e-05, -1.6053e-05]],\n     \n              ...,\n     \n              [[-4.5458e-05, -5.4961e-05, -6.3065e-05],\n               [ 4.9498e-07, -6.0058e-05, -3.3903e-05],\n               [-7.4451e-05, -6.6858e-05, -7.9005e-05]],\n     \n              [[ 9.8112e-06,  2.2897e-05, -3.7149e-08],\n               [-1.8258e-05,  1.5302e-05, -2.2873e-05],\n               [ 2.8430e-05,  2.3326e-07, -7.2087e-06]],\n     \n              [[ 4.7673e-05,  1.0182e-04,  5.0475e-05],\n               [-1.4737e-05,  4.5388e-05,  1.9034e-05],\n               [ 7.4366e-06,  4.4777e-06,  6.0665e-05]]],\n     \n     \n             [[[-1.4178e-05,  2.1970e-05,  4.6400e-05],\n               [ 7.4815e-06,  1.5047e-05,  6.0345e-06],\n               [-5.2373e-05, -1.0912e-05, -3.3632e-05]],\n     \n              [[ 4.0636e-05,  2.7550e-05,  6.8205e-05],\n               [ 9.6517e-06,  6.8143e-05,  6.5810e-05],\n               [-5.5144e-06,  3.0454e-05, -1.3266e-05]],\n     \n              [[-4.3631e-06, -1.3663e-06, -2.4077e-05],\n               [-1.4766e-07,  2.8574e-06,  1.7387e-05],\n               [ 4.7426e-06, -3.7764e-06, -3.2815e-05]],\n     \n              ...,\n     \n              [[-1.6604e-05,  2.4504e-05,  3.5352e-06],\n               [ 3.7683e-06,  5.6894e-05,  2.0852e-05],\n               [-1.4646e-05,  1.6146e-05,  4.9683e-05]],\n     \n              [[-2.8694e-06,  8.4362e-06,  7.0006e-06],\n               [-1.2005e-06,  1.0016e-05,  4.7386e-05],\n               [-1.5710e-05,  1.2745e-05, -1.3082e-06]],\n     \n              [[ 2.6580e-05,  4.0023e-05,  2.0396e-05],\n               [ 2.7132e-05,  2.7638e-05,  7.2436e-06],\n               [-4.2085e-05, -3.9193e-05, -3.2350e-06]]]]),\n     'exp_avg_sq': tensor([[[[8.4826e-10, 1.3889e-09, 1.9268e-09],\n               [1.3540e-09, 2.6088e-09, 2.7786e-09],\n               [2.3667e-09, 3.7219e-09, 4.3161e-09]],\n     \n              [[9.8480e-10, 1.6412e-09, 1.4508e-09],\n               [1.4899e-09, 1.6501e-09, 1.1609e-09],\n               [7.8788e-10, 1.2020e-09, 8.5104e-10]],\n     \n              [[1.6487e-09, 2.4158e-09, 2.0388e-09],\n               [1.4196e-09, 1.8468e-09, 1.6511e-09],\n               [9.2118e-10, 1.0875e-09, 9.8799e-10]],\n     \n              ...,\n     \n              [[8.6705e-10, 1.2516e-09, 1.0479e-09],\n               [1.0769e-09, 2.2077e-09, 1.2384e-09],\n               [1.5239e-09, 1.7284e-09, 1.8221e-09]],\n     \n              [[6.1032e-10, 9.5044e-10, 1.1419e-09],\n               [7.3512e-10, 5.6368e-10, 9.7138e-10],\n               [3.6680e-10, 7.2088e-10, 7.4189e-10]],\n     \n              [[1.6844e-09, 2.6424e-09, 1.8781e-09],\n               [2.5546e-09, 1.9720e-09, 2.5715e-09],\n               [1.2262e-09, 1.3624e-09, 1.6823e-09]]],\n     \n     \n             [[[5.1015e-10, 9.8965e-10, 1.0746e-09],\n               [9.6207e-10, 1.5954e-09, 1.5092e-09],\n               [1.8771e-09, 2.5570e-09, 2.6023e-09]],\n     \n              [[1.1063e-09, 1.6943e-09, 1.3168e-09],\n               [1.0698e-09, 1.6181e-09, 1.8604e-09],\n               [1.3958e-09, 1.6862e-09, 1.6655e-09]],\n     \n              [[1.1805e-09, 1.7371e-09, 1.4151e-09],\n               [1.1501e-09, 1.5792e-09, 2.0838e-09],\n               [1.4693e-09, 1.3815e-09, 1.1356e-09]],\n     \n              ...,\n     \n              [[9.8357e-10, 8.3232e-10, 1.2375e-09],\n               [9.2677e-10, 1.8460e-09, 1.6318e-09],\n               [1.2862e-09, 1.4325e-09, 1.9370e-09]],\n     \n              [[2.4750e-10, 5.0386e-10, 4.1000e-10],\n               [4.0775e-10, 2.8257e-10, 8.0014e-10],\n               [3.6537e-10, 8.7698e-10, 5.5959e-10]],\n     \n              [[2.0729e-09, 2.7546e-09, 2.2853e-09],\n               [1.6633e-09, 1.8399e-09, 2.3141e-09],\n               [1.7189e-09, 2.1327e-09, 2.0679e-09]]],\n     \n     \n             [[[9.4685e-10, 8.2497e-10, 1.2254e-09],\n               [1.0105e-09, 1.8259e-09, 2.2505e-09],\n               [2.0536e-09, 2.8346e-09, 3.9863e-09]],\n     \n              [[8.8060e-10, 1.2911e-09, 1.0561e-09],\n               [1.3344e-09, 1.8710e-09, 1.3868e-09],\n               [1.2458e-09, 1.2536e-09, 1.0020e-09]],\n     \n              [[1.3172e-09, 1.7682e-09, 1.5381e-09],\n               [1.5837e-09, 2.0719e-09, 1.6696e-09],\n               [1.2973e-09, 2.0095e-09, 1.3641e-09]],\n     \n              ...,\n     \n              [[1.0977e-09, 1.2240e-09, 1.8317e-09],\n               [1.4501e-09, 2.6386e-09, 2.5042e-09],\n               [2.5007e-09, 2.7909e-09, 2.5703e-09]],\n     \n              [[3.8044e-10, 1.0930e-09, 7.8006e-10],\n               [5.6018e-10, 7.7371e-10, 1.0107e-09],\n               [4.9983e-10, 1.1342e-09, 9.2700e-10]],\n     \n              [[1.7898e-09, 3.0172e-09, 2.6259e-09],\n               [2.5235e-09, 4.0003e-09, 2.7914e-09],\n               [2.3852e-09, 2.5638e-09, 2.3961e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[9.5371e-10, 8.0337e-10, 1.5857e-09],\n               [1.4194e-09, 2.9437e-09, 2.7179e-09],\n               [1.5120e-09, 3.0097e-09, 4.6951e-09]],\n     \n              [[2.0039e-09, 2.5117e-09, 1.3178e-09],\n               [2.2933e-09, 2.8232e-09, 1.8483e-09],\n               [1.2719e-09, 1.7870e-09, 1.2064e-09]],\n     \n              [[1.6719e-09, 1.5535e-09, 1.2940e-09],\n               [1.8584e-09, 2.0608e-09, 1.6834e-09],\n               [9.8905e-10, 1.2796e-09, 1.3556e-09]],\n     \n              ...,\n     \n              [[4.0043e-09, 3.4225e-09, 2.5557e-09],\n               [3.5204e-09, 8.5103e-09, 4.5256e-09],\n               [3.2496e-09, 3.8484e-09, 6.3190e-09]],\n     \n              [[4.8397e-10, 9.6332e-10, 3.8741e-10],\n               [6.6905e-10, 8.5012e-10, 7.6164e-10],\n               [3.7303e-10, 9.0665e-10, 6.4035e-10]],\n     \n              [[2.2074e-09, 2.3377e-09, 2.0105e-09],\n               [2.5981e-09, 3.0439e-09, 2.7525e-09],\n               [1.5924e-09, 2.5324e-09, 1.9139e-09]]],\n     \n     \n             [[[6.7463e-10, 9.4858e-10, 1.4440e-09],\n               [1.1371e-09, 2.2537e-09, 2.2185e-09],\n               [2.3460e-09, 4.1788e-09, 4.2579e-09]],\n     \n              [[1.6034e-09, 2.3426e-09, 1.2685e-09],\n               [1.0283e-09, 2.4864e-09, 1.8694e-09],\n               [8.4239e-10, 1.3391e-09, 1.5247e-09]],\n     \n              [[1.4123e-09, 1.6237e-09, 1.8540e-09],\n               [1.6556e-09, 2.3471e-09, 1.6540e-09],\n               [1.3410e-09, 1.5224e-09, 1.5977e-09]],\n     \n              ...,\n     \n              [[1.1637e-09, 9.0880e-10, 1.6322e-09],\n               [8.5300e-10, 1.4353e-09, 1.6727e-09],\n               [1.6926e-09, 2.0141e-09, 2.8350e-09]],\n     \n              [[3.3153e-10, 9.3910e-10, 3.6603e-10],\n               [6.7928e-10, 9.3888e-10, 9.7826e-10],\n               [6.5757e-10, 1.3110e-09, 9.9902e-10]],\n     \n              [[1.5105e-09, 2.8499e-09, 1.7017e-09],\n               [1.5105e-09, 2.5192e-09, 1.8806e-09],\n               [1.7502e-09, 1.4990e-09, 1.9209e-09]]],\n     \n     \n             [[[3.3932e-10, 6.2470e-10, 1.3701e-09],\n               [7.2205e-10, 1.0983e-09, 1.2306e-09],\n               [1.5624e-09, 2.0677e-09, 2.6992e-09]],\n     \n              [[1.6658e-09, 1.6325e-09, 1.9281e-09],\n               [1.3432e-09, 2.7873e-09, 1.6789e-09],\n               [1.2821e-09, 1.8953e-09, 1.0525e-09]],\n     \n              [[9.5121e-10, 1.1152e-09, 1.0640e-09],\n               [1.0701e-09, 1.4141e-09, 1.0086e-09],\n               [1.1864e-09, 1.7479e-09, 1.1029e-09]],\n     \n              ...,\n     \n              [[1.5246e-09, 1.5507e-09, 1.2170e-09],\n               [1.5854e-09, 2.4375e-09, 1.0967e-09],\n               [2.7851e-09, 1.9913e-09, 1.9013e-09]],\n     \n              [[3.7660e-10, 6.9068e-10, 5.8643e-10],\n               [7.0048e-10, 8.9683e-10, 1.3928e-09],\n               [5.2796e-10, 1.0937e-09, 1.4988e-09]],\n     \n              [[1.8406e-09, 1.9120e-09, 1.8984e-09],\n               [1.5109e-09, 2.2846e-09, 1.4868e-09],\n               [2.0506e-09, 1.9136e-09, 1.0973e-09]]]])},\n    153: {'exp_avg': tensor([[[[-1.5142e-05]],\n     \n              [[-1.5784e-06]],\n     \n              [[-1.1372e-05]],\n     \n              ...,\n     \n              [[-1.7029e-05]],\n     \n              [[ 9.0021e-06]],\n     \n              [[ 3.7142e-06]]],\n     \n     \n             [[[-5.9083e-06]],\n     \n              [[ 3.9766e-05]],\n     \n              [[-6.7403e-05]],\n     \n              ...,\n     \n              [[-3.3638e-05]],\n     \n              [[ 1.6913e-05]],\n     \n              [[ 5.7249e-05]]],\n     \n     \n             [[[-7.2722e-06]],\n     \n              [[ 3.5099e-05]],\n     \n              [[-3.6214e-05]],\n     \n              ...,\n     \n              [[ 1.2414e-05]],\n     \n              [[ 1.8797e-06]],\n     \n              [[-4.5975e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 4.1207e-05]],\n     \n              [[-2.4557e-05]],\n     \n              [[ 3.6536e-05]],\n     \n              ...,\n     \n              [[-2.7881e-05]],\n     \n              [[ 3.2021e-05]],\n     \n              [[ 1.6266e-06]]],\n     \n     \n             [[[ 3.0011e-05]],\n     \n              [[-1.8793e-05]],\n     \n              [[ 1.0915e-04]],\n     \n              ...,\n     \n              [[-9.4186e-05]],\n     \n              [[-3.0133e-05]],\n     \n              [[ 4.1314e-05]]],\n     \n     \n             [[[-4.3997e-05]],\n     \n              [[-5.9323e-05]],\n     \n              [[-2.2135e-05]],\n     \n              ...,\n     \n              [[-2.5604e-05]],\n     \n              [[-3.9918e-05]],\n     \n              [[-3.2427e-05]]]]),\n     'exp_avg_sq': tensor([[[[2.1521e-09]],\n     \n              [[2.7603e-09]],\n     \n              [[4.4899e-09]],\n     \n              ...,\n     \n              [[2.6850e-09]],\n     \n              [[2.9954e-09]],\n     \n              [[2.0209e-09]]],\n     \n     \n             [[[5.9857e-09]],\n     \n              [[5.8665e-09]],\n     \n              [[7.2681e-09]],\n     \n              ...,\n     \n              [[3.8147e-09]],\n     \n              [[5.7268e-09]],\n     \n              [[3.7135e-09]]],\n     \n     \n             [[[4.6434e-09]],\n     \n              [[3.6223e-09]],\n     \n              [[3.7411e-09]],\n     \n              ...,\n     \n              [[2.9157e-09]],\n     \n              [[5.3945e-09]],\n     \n              [[3.4604e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[7.2516e-09]],\n     \n              [[6.3227e-09]],\n     \n              [[6.4791e-09]],\n     \n              ...,\n     \n              [[4.7725e-09]],\n     \n              [[2.8175e-09]],\n     \n              [[5.3360e-09]]],\n     \n     \n             [[[4.1799e-09]],\n     \n              [[5.3470e-09]],\n     \n              [[1.0425e-08]],\n     \n              ...,\n     \n              [[9.0885e-09]],\n     \n              [[5.9435e-09]],\n     \n              [[2.9402e-09]]],\n     \n     \n             [[[8.4932e-09]],\n     \n              [[1.0768e-08]],\n     \n              [[7.8379e-09]],\n     \n              ...,\n     \n              [[4.3304e-09]],\n     \n              [[4.4864e-09]],\n     \n              [[4.5521e-09]]]])},\n    154: {'exp_avg': tensor([[[[-2.7436e-05]],\n     \n              [[-1.6669e-06]],\n     \n              [[ 2.0912e-05]],\n     \n              ...,\n     \n              [[ 3.8361e-05]],\n     \n              [[-3.2781e-05]],\n     \n              [[-2.0036e-05]]],\n     \n     \n             [[[ 5.6239e-05]],\n     \n              [[ 1.9224e-05]],\n     \n              [[ 2.9366e-05]],\n     \n              ...,\n     \n              [[-6.5287e-05]],\n     \n              [[-8.9534e-05]],\n     \n              [[-2.8578e-06]]],\n     \n     \n             [[[-3.0026e-05]],\n     \n              [[-2.3931e-05]],\n     \n              [[-4.4421e-06]],\n     \n              ...,\n     \n              [[-2.2554e-05]],\n     \n              [[ 2.8584e-05]],\n     \n              [[-3.4126e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-1.4024e-05]],\n     \n              [[-4.0067e-05]],\n     \n              [[ 1.1071e-04]],\n     \n              ...,\n     \n              [[ 3.2657e-06]],\n     \n              [[-7.2913e-06]],\n     \n              [[-2.8570e-05]]],\n     \n     \n             [[[-3.3746e-06]],\n     \n              [[-4.8971e-05]],\n     \n              [[ 8.1314e-05]],\n     \n              ...,\n     \n              [[-1.3185e-05]],\n     \n              [[-2.3388e-05]],\n     \n              [[-5.8410e-05]]],\n     \n     \n             [[[ 9.2963e-05]],\n     \n              [[ 8.6767e-05]],\n     \n              [[-1.3914e-05]],\n     \n              ...,\n     \n              [[ 7.7567e-06]],\n     \n              [[-5.5697e-06]],\n     \n              [[ 2.8492e-07]]]]),\n     'exp_avg_sq': tensor([[[[3.2113e-09]],\n     \n              [[2.4509e-09]],\n     \n              [[1.4671e-09]],\n     \n              ...,\n     \n              [[1.6706e-09]],\n     \n              [[2.3343e-09]],\n     \n              [[1.2203e-09]]],\n     \n     \n             [[[3.4334e-09]],\n     \n              [[2.9076e-09]],\n     \n              [[1.4986e-09]],\n     \n              ...,\n     \n              [[2.5094e-09]],\n     \n              [[5.0763e-09]],\n     \n              [[1.9482e-09]]],\n     \n     \n             [[[4.2121e-09]],\n     \n              [[4.7670e-09]],\n     \n              [[2.7170e-09]],\n     \n              ...,\n     \n              [[2.1755e-09]],\n     \n              [[9.7483e-09]],\n     \n              [[2.2517e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[9.4644e-09]],\n     \n              [[3.0358e-09]],\n     \n              [[3.0236e-09]],\n     \n              ...,\n     \n              [[1.9107e-09]],\n     \n              [[1.1944e-09]],\n     \n              [[3.2865e-09]]],\n     \n     \n             [[[6.6880e-09]],\n     \n              [[3.7260e-09]],\n     \n              [[3.0306e-09]],\n     \n              ...,\n     \n              [[2.5135e-09]],\n     \n              [[6.5334e-09]],\n     \n              [[2.7545e-09]]],\n     \n     \n             [[[5.4179e-09]],\n     \n              [[6.2346e-09]],\n     \n              [[2.2443e-09]],\n     \n              ...,\n     \n              [[1.8240e-09]],\n     \n              [[1.7121e-09]],\n     \n              [[1.9514e-09]]]])},\n    155: {'exp_avg': tensor([[[[-5.9344e-06]],\n     \n              [[-1.5102e-05]],\n     \n              [[ 4.0058e-05]],\n     \n              ...,\n     \n              [[ 2.9462e-06]],\n     \n              [[ 4.4956e-05]],\n     \n              [[-6.1913e-06]]],\n     \n     \n             [[[ 5.5727e-05]],\n     \n              [[-2.1979e-05]],\n     \n              [[-1.0555e-05]],\n     \n              ...,\n     \n              [[-1.9518e-06]],\n     \n              [[-3.0188e-05]],\n     \n              [[-1.1083e-05]]],\n     \n     \n             [[[ 1.6032e-04]],\n     \n              [[ 1.3868e-05]],\n     \n              [[ 1.1890e-05]],\n     \n              ...,\n     \n              [[-1.5849e-05]],\n     \n              [[ 1.6608e-04]],\n     \n              [[ 4.1531e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 3.2141e-06]],\n     \n              [[ 1.6116e-05]],\n     \n              [[ 4.8034e-05]],\n     \n              ...,\n     \n              [[-2.4430e-06]],\n     \n              [[-6.1099e-05]],\n     \n              [[ 3.9166e-05]]],\n     \n     \n             [[[-1.3343e-05]],\n     \n              [[ 1.7563e-05]],\n     \n              [[-1.4697e-05]],\n     \n              ...,\n     \n              [[ 5.9185e-05]],\n     \n              [[-6.6117e-05]],\n     \n              [[ 8.4070e-05]]],\n     \n     \n             [[[-4.5876e-05]],\n     \n              [[ 3.3515e-05]],\n     \n              [[ 1.1254e-05]],\n     \n              ...,\n     \n              [[-4.3586e-05]],\n     \n              [[-5.2686e-05]],\n     \n              [[ 4.7839e-06]]]]),\n     'exp_avg_sq': tensor([[[[2.5564e-09]],\n     \n              [[9.0511e-10]],\n     \n              [[1.9391e-09]],\n     \n              ...,\n     \n              [[2.5959e-09]],\n     \n              [[1.5610e-09]],\n     \n              [[1.1156e-09]]],\n     \n     \n             [[[5.6327e-09]],\n     \n              [[2.2894e-09]],\n     \n              [[5.5152e-09]],\n     \n              ...,\n     \n              [[1.9610e-09]],\n     \n              [[4.6083e-09]],\n     \n              [[1.6546e-09]]],\n     \n     \n             [[[1.1047e-08]],\n     \n              [[5.8541e-09]],\n     \n              [[5.4952e-09]],\n     \n              ...,\n     \n              [[4.1621e-09]],\n     \n              [[2.1701e-08]],\n     \n              [[5.3288e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[5.7872e-09]],\n     \n              [[3.8379e-09]],\n     \n              [[2.8782e-09]],\n     \n              ...,\n     \n              [[2.3888e-09]],\n     \n              [[5.2303e-09]],\n     \n              [[7.3162e-09]]],\n     \n     \n             [[[1.1201e-09]],\n     \n              [[5.6079e-09]],\n     \n              [[4.4815e-10]],\n     \n              ...,\n     \n              [[8.5201e-09]],\n     \n              [[6.2837e-09]],\n     \n              [[4.9819e-09]]],\n     \n     \n             [[[5.8822e-09]],\n     \n              [[1.5370e-09]],\n     \n              [[2.2406e-09]],\n     \n              ...,\n     \n              [[3.7269e-09]],\n     \n              [[3.8463e-09]],\n     \n              [[4.6212e-09]]]])},\n    156: {'exp_avg': tensor([[[[-6.2699e-06,  1.8357e-05,  2.4121e-06],\n               [-1.1939e-05,  9.2084e-06,  2.7883e-05],\n               [-4.5297e-07, -3.7164e-06, -3.7487e-06]],\n     \n              [[-3.2250e-06,  4.2109e-06,  5.7658e-06],\n               [-1.7750e-06, -3.1146e-05, -3.5751e-05],\n               [ 2.5565e-06,  1.8377e-05,  1.7291e-05]],\n     \n              [[-1.6244e-05, -2.3939e-05,  2.4406e-06],\n               [-4.7403e-05, -2.8376e-05, -3.8409e-06],\n               [-2.1126e-05, -2.5577e-05, -2.4692e-07]],\n     \n              ...,\n     \n              [[-4.7273e-06, -1.9013e-05,  1.3615e-06],\n               [-1.6646e-05,  5.5068e-05,  3.2001e-05],\n               [-2.3687e-06, -2.6931e-05, -1.9490e-05]],\n     \n              [[-2.3675e-05, -6.3830e-06,  1.1161e-06],\n               [-6.3762e-05, -3.2309e-05, -3.3484e-06],\n               [-2.4025e-05, -2.2105e-05,  1.2259e-06]],\n     \n              [[ 1.1576e-05,  7.3502e-06,  3.4072e-06],\n               [ 5.5238e-06,  5.9401e-05,  3.6840e-06],\n               [-1.7815e-05, -1.8897e-05,  1.0923e-05]]],\n     \n     \n             [[[-7.9079e-06, -1.6148e-05, -1.4429e-05],\n               [-4.4087e-06,  2.6102e-05, -7.3667e-06],\n               [ 2.9569e-05, -3.3776e-05, -3.0617e-05]],\n     \n              [[ 1.2895e-05, -3.8456e-05, -3.0125e-05],\n               [ 8.6360e-06, -9.1576e-07,  5.4239e-06],\n               [-7.0217e-06,  5.7743e-06, -6.0532e-06]],\n     \n              [[ 7.0565e-06, -5.6422e-06, -2.8881e-05],\n               [-5.1823e-06, -1.3928e-05, -3.8018e-05],\n               [ 1.9738e-05,  4.5980e-05,  2.7990e-05]],\n     \n              ...,\n     \n              [[ 4.9032e-06, -9.5946e-06, -1.2693e-05],\n               [ 1.1054e-06, -2.0703e-06, -2.6764e-05],\n               [-6.9104e-06, -2.4238e-05, -1.7603e-05]],\n     \n              [[-1.4113e-05,  4.8776e-06, -2.4572e-05],\n               [ 4.7308e-05,  7.1784e-05,  8.1153e-05],\n               [ 3.6692e-05, -2.2528e-05,  2.4308e-05]],\n     \n              [[ 6.3932e-06,  3.6745e-05,  1.6385e-05],\n               [ 4.5663e-07, -1.3757e-05,  2.2634e-05],\n               [ 4.9088e-06, -1.3079e-06,  4.4646e-05]]],\n     \n     \n             [[[-2.7787e-05, -1.7761e-05, -6.1667e-06],\n               [-2.5007e-05, -4.9616e-05, -1.9690e-05],\n               [-2.2259e-06,  9.2635e-06, -5.7622e-07]],\n     \n              [[ 6.1826e-06,  3.6880e-05,  2.9904e-05],\n               [ 1.7995e-05,  6.5976e-05,  5.2097e-05],\n               [-2.9659e-05,  3.2766e-06,  4.2009e-06]],\n     \n              [[ 1.2662e-05,  3.9264e-05, -4.3123e-06],\n               [ 9.1473e-06,  1.9781e-05,  3.3820e-05],\n               [-1.6156e-05,  8.7016e-06,  4.6304e-06]],\n     \n              ...,\n     \n              [[-9.7910e-06,  7.7911e-06,  2.0648e-05],\n               [-2.4092e-05, -3.9238e-05,  4.5415e-07],\n               [-2.4623e-06, -1.8528e-05,  1.0128e-05]],\n     \n              [[-1.7832e-05,  1.5660e-05,  3.6418e-06],\n               [-1.5680e-05,  1.2262e-05,  2.5105e-05],\n               [ 1.9343e-06,  2.0549e-05,  2.7333e-06]],\n     \n              [[ 5.4852e-06, -8.2773e-07,  5.4154e-06],\n               [-4.1862e-05, -1.5676e-06,  3.3758e-05],\n               [-1.2528e-05, -5.6806e-06,  3.2284e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 1.6277e-05,  3.6129e-06, -2.8578e-06],\n               [ 8.9412e-06,  2.2658e-06,  2.9281e-06],\n               [-1.2668e-06,  6.5874e-06, -7.8307e-07]],\n     \n              [[ 4.7554e-05,  8.2033e-06, -6.0137e-06],\n               [ 2.8143e-05, -3.3596e-06,  2.9360e-06],\n               [ 1.4122e-05,  3.6144e-06, -6.1408e-06]],\n     \n              [[ 9.6271e-06, -5.9977e-06, -1.4812e-05],\n               [ 2.0758e-05,  2.6054e-05,  1.9698e-05],\n               [ 4.6016e-06,  3.1333e-05,  1.5205e-05]],\n     \n              ...,\n     \n              [[-1.9151e-05, -3.9279e-06,  2.2307e-06],\n               [ 1.5991e-05, -8.7789e-06, -7.6910e-06],\n               [ 2.1337e-05,  2.9053e-05,  7.6215e-07]],\n     \n              [[ 6.2915e-06,  1.9737e-06,  1.8976e-07],\n               [-1.0489e-05, -1.1114e-05,  2.3509e-05],\n               [ 8.8805e-06,  5.4834e-06,  2.7809e-05]],\n     \n              [[-1.3117e-08, -1.3385e-05,  9.2185e-06],\n               [-3.3514e-05,  2.0898e-05,  6.2971e-06],\n               [-6.4558e-06, -2.6909e-06,  1.9864e-05]]],\n     \n     \n             [[[-6.1782e-06,  1.5976e-05,  1.0586e-05],\n               [ 1.5094e-05,  2.1844e-06, -5.9918e-06],\n               [ 1.6684e-05, -1.1770e-05, -1.6491e-05]],\n     \n              [[-9.4927e-06,  2.8813e-05,  1.5468e-06],\n               [-9.2912e-06,  2.6030e-08, -1.7927e-05],\n               [-6.0345e-06,  1.2971e-05, -4.8457e-07]],\n     \n              [[ 1.3468e-05,  4.7856e-05,  3.0840e-05],\n               [-1.0010e-05,  2.1152e-05,  2.4112e-05],\n               [-9.5494e-07, -1.3625e-05, -2.4418e-06]],\n     \n              ...,\n     \n              [[-4.6741e-06,  1.3074e-05,  1.5586e-05],\n               [-1.8569e-05, -9.5427e-06, -2.2024e-05],\n               [-1.2449e-05, -2.8833e-05, -1.2065e-05]],\n     \n              [[ 1.2794e-05, -3.1123e-05, -5.7157e-06],\n               [ 2.2707e-05,  8.6752e-07,  1.7072e-05],\n               [ 2.6711e-05,  3.5298e-05,  3.0740e-05]],\n     \n              [[ 6.5093e-06,  4.0558e-06,  3.7292e-07],\n               [ 1.0764e-05,  2.0550e-05,  1.9921e-06],\n               [-1.2367e-05, -1.9108e-05, -2.3183e-05]]],\n     \n     \n             [[[-6.4740e-07, -3.0429e-06, -1.2963e-05],\n               [ 9.2502e-06,  2.6676e-05,  1.2757e-06],\n               [ 1.3175e-05,  2.2859e-05, -8.3034e-07]],\n     \n              [[-1.4783e-05, -3.0288e-05, -1.5106e-05],\n               [-4.4176e-05,  1.3658e-05,  8.3247e-06],\n               [-5.4984e-06,  2.0804e-05,  3.7359e-05]],\n     \n              [[-1.5728e-05, -4.5126e-05, -3.7786e-05],\n               [ 1.8321e-05,  3.5920e-06,  2.4567e-05],\n               [-4.6320e-06,  3.9556e-05,  1.9741e-05]],\n     \n              ...,\n     \n              [[ 4.3695e-06,  2.7964e-06,  6.2355e-06],\n               [ 2.2569e-05,  5.2114e-05,  3.9346e-05],\n               [ 3.4510e-05,  7.4361e-05,  6.8565e-06]],\n     \n              [[-1.9960e-05, -2.9297e-05, -3.2719e-05],\n               [-4.6128e-05, -1.0639e-04, -6.0916e-05],\n               [ 2.3775e-05, -3.3969e-05, -4.1312e-05]],\n     \n              [[ 1.7676e-05,  3.0482e-05,  6.1509e-06],\n               [-3.0651e-05, -6.4464e-05, -3.1935e-05],\n               [-9.4630e-06, -5.8453e-05, -6.9019e-06]]]]),\n     'exp_avg_sq': tensor([[[[3.8236e-10, 1.0674e-09, 3.1572e-10],\n               [7.2725e-10, 2.5235e-09, 1.0753e-09],\n               [3.6365e-10, 8.6065e-10, 4.2618e-10]],\n     \n              [[1.1349e-09, 5.5364e-09, 1.5798e-09],\n               [1.3705e-09, 6.3247e-09, 3.0906e-09],\n               [1.3348e-09, 5.1687e-09, 1.5074e-09]],\n     \n              [[4.0239e-10, 1.2822e-09, 4.3649e-10],\n               [1.9015e-09, 5.1524e-09, 1.7028e-09],\n               [9.2585e-10, 2.4599e-09, 1.2672e-09]],\n     \n              ...,\n     \n              [[3.4103e-10, 1.0228e-09, 4.3207e-10],\n               [1.3653e-09, 5.3085e-09, 1.7972e-09],\n               [7.1425e-10, 3.8554e-09, 1.7263e-09]],\n     \n              [[6.4569e-10, 5.8942e-10, 2.0759e-10],\n               [2.3001e-09, 5.2491e-09, 1.6105e-09],\n               [2.0570e-09, 4.7404e-09, 2.3570e-09]],\n     \n              [[2.9869e-10, 9.1126e-10, 3.9490e-10],\n               [1.8343e-09, 4.0336e-09, 1.1318e-09],\n               [1.2448e-09, 3.4353e-09, 1.7962e-09]]],\n     \n     \n             [[[2.8609e-10, 9.3420e-10, 3.6693e-10],\n               [1.1444e-09, 3.0634e-09, 1.2347e-09],\n               [6.1104e-10, 3.4460e-09, 1.0920e-09]],\n     \n              [[7.8701e-10, 2.2507e-09, 8.6725e-10],\n               [1.4345e-09, 3.8145e-09, 1.9146e-09],\n               [3.3827e-10, 1.2475e-09, 6.2604e-10]],\n     \n              [[7.5873e-10, 1.6424e-09, 5.1813e-10],\n               [1.0604e-09, 2.8895e-09, 1.0647e-09],\n               [3.3249e-10, 1.2548e-09, 5.3384e-10]],\n     \n              ...,\n     \n              [[3.7100e-10, 1.5227e-09, 6.9686e-10],\n               [1.9268e-09, 4.3054e-09, 2.2325e-09],\n               [1.7711e-09, 2.6698e-09, 1.6646e-09]],\n     \n              [[1.2734e-09, 2.4759e-09, 1.5087e-09],\n               [4.2524e-09, 1.0530e-08, 6.4256e-09],\n               [2.2616e-09, 5.1031e-09, 2.0089e-09]],\n     \n              [[2.5270e-10, 1.5328e-09, 2.9228e-10],\n               [1.2570e-09, 4.9880e-09, 2.4889e-09],\n               [4.4602e-10, 1.3587e-09, 8.9077e-10]]],\n     \n     \n             [[[3.5241e-10, 6.2148e-10, 3.8567e-10],\n               [8.6330e-10, 2.3028e-09, 1.5030e-09],\n               [4.3592e-10, 8.8927e-10, 6.5971e-10]],\n     \n              [[5.0886e-10, 3.1302e-09, 1.4523e-09],\n               [1.2750e-09, 3.6953e-09, 1.9671e-09],\n               [9.5148e-10, 1.4372e-09, 5.2776e-10]],\n     \n              [[4.7663e-10, 8.6553e-10, 3.6592e-10],\n               [1.5644e-09, 3.2496e-09, 1.2252e-09],\n               [1.3442e-09, 2.7053e-09, 4.1466e-10]],\n     \n              ...,\n     \n              [[5.3817e-10, 1.4784e-09, 8.0846e-10],\n               [1.5957e-09, 5.8516e-09, 2.0689e-09],\n               [7.1419e-10, 2.1737e-09, 1.0693e-09]],\n     \n              [[3.4934e-10, 7.9891e-10, 3.6172e-10],\n               [7.2619e-10, 1.3086e-09, 6.8681e-10],\n               [2.6768e-10, 6.5771e-10, 2.7329e-10]],\n     \n              [[3.5261e-10, 1.3084e-09, 6.1368e-10],\n               [1.6327e-09, 5.7504e-09, 2.1765e-09],\n               [8.8932e-10, 2.2765e-09, 1.8958e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[2.3299e-10, 3.9169e-10, 1.8448e-10],\n               [3.1752e-10, 6.5377e-10, 2.4670e-10],\n               [1.2129e-10, 3.9225e-10, 2.4441e-10]],\n     \n              [[6.3998e-10, 1.1026e-09, 5.5238e-10],\n               [2.5503e-09, 1.3187e-09, 4.3568e-10],\n               [3.7598e-10, 7.3219e-10, 4.3351e-10]],\n     \n              [[1.2209e-09, 1.4678e-09, 5.7681e-10],\n               [9.1632e-10, 2.9451e-09, 1.3187e-09],\n               [2.3962e-10, 8.9974e-10, 4.6784e-10]],\n     \n              ...,\n     \n              [[1.5095e-10, 7.4215e-10, 6.0469e-10],\n               [1.7778e-09, 3.9617e-09, 1.3411e-09],\n               [6.2135e-10, 9.6633e-10, 5.5151e-10]],\n     \n              [[2.4278e-10, 1.0100e-09, 3.3253e-10],\n               [2.7183e-09, 3.1065e-09, 8.8055e-10],\n               [1.2594e-09, 1.7050e-09, 9.0069e-10]],\n     \n              [[3.4877e-10, 1.3205e-09, 5.2301e-10],\n               [1.1868e-09, 4.1655e-09, 1.2788e-09],\n               [3.7841e-10, 1.0416e-09, 4.2508e-10]]],\n     \n     \n             [[[9.8966e-10, 2.7515e-09, 9.2200e-10],\n               [2.3305e-09, 5.5951e-09, 1.9700e-09],\n               [1.1071e-09, 2.6896e-09, 6.9787e-10]],\n     \n              [[2.5556e-10, 6.1493e-10, 2.2205e-10],\n               [3.3298e-10, 1.0977e-09, 5.4406e-10],\n               [1.8971e-10, 3.8419e-10, 2.0692e-10]],\n     \n              [[5.6752e-10, 1.3334e-09, 6.1923e-10],\n               [9.8907e-10, 2.2742e-09, 1.0538e-09],\n               [1.2555e-10, 6.3885e-10, 2.5439e-10]],\n     \n              ...,\n     \n              [[2.6549e-10, 1.2879e-09, 1.1664e-09],\n               [8.8108e-10, 5.2108e-09, 3.2530e-09],\n               [3.4460e-10, 1.7406e-09, 7.2648e-10]],\n     \n              [[1.4781e-09, 1.9403e-09, 1.3146e-09],\n               [2.3181e-09, 6.6740e-09, 1.5943e-09],\n               [1.2959e-09, 2.2867e-09, 6.7946e-10]],\n     \n              [[1.0934e-09, 7.6881e-10, 1.4650e-10],\n               [1.4928e-09, 2.7491e-09, 6.6729e-10],\n               [1.2260e-09, 2.9135e-09, 1.0893e-09]]],\n     \n     \n             [[[1.7419e-10, 2.7348e-10, 1.6020e-10],\n               [4.7497e-10, 1.2107e-09, 3.4969e-10],\n               [3.2850e-10, 6.3107e-10, 2.8272e-10]],\n     \n              [[4.8540e-10, 9.2024e-10, 5.8181e-10],\n               [1.1436e-09, 2.8344e-09, 1.5010e-09],\n               [1.0473e-09, 1.7382e-09, 7.8161e-10]],\n     \n              [[1.0395e-09, 3.7212e-09, 1.0706e-09],\n               [1.6896e-09, 4.4692e-09, 1.7251e-09],\n               [4.6042e-10, 1.9101e-09, 6.6401e-10]],\n     \n              ...,\n     \n              [[5.6348e-10, 9.1159e-10, 5.0812e-10],\n               [1.6855e-09, 5.4519e-09, 1.8590e-09],\n               [1.1460e-09, 3.1305e-09, 1.7499e-09]],\n     \n              [[8.9987e-10, 1.5410e-09, 8.6882e-10],\n               [4.1091e-09, 8.7541e-09, 4.0216e-09],\n               [5.3102e-09, 8.1375e-09, 3.2450e-09]],\n     \n              [[4.3401e-10, 1.5752e-09, 6.3213e-10],\n               [1.9464e-09, 5.9452e-09, 2.8268e-09],\n               [7.7842e-10, 2.5786e-09, 1.0750e-09]]]])},\n    157: {'exp_avg': tensor([[[[-7.6103e-06]],\n     \n              [[-2.1475e-05]],\n     \n              [[ 1.9475e-05]],\n     \n              ...,\n     \n              [[-1.4950e-05]],\n     \n              [[ 7.6601e-05]],\n     \n              [[ 6.4939e-05]]],\n     \n     \n             [[[-2.1118e-06]],\n     \n              [[ 5.1939e-05]],\n     \n              [[-3.9988e-05]],\n     \n              ...,\n     \n              [[ 8.0369e-07]],\n     \n              [[-5.5351e-05]],\n     \n              [[-2.3974e-05]]],\n     \n     \n             [[[ 3.5917e-05]],\n     \n              [[-1.1912e-05]],\n     \n              [[ 7.2893e-05]],\n     \n              ...,\n     \n              [[ 2.2873e-05]],\n     \n              [[ 1.3386e-05]],\n     \n              [[ 4.0494e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[-7.9185e-06]],\n     \n              [[ 3.0115e-05]],\n     \n              [[ 1.4902e-07]],\n     \n              ...,\n     \n              [[-2.4457e-05]],\n     \n              [[-6.7864e-05]],\n     \n              [[-1.4680e-06]]],\n     \n     \n             [[[ 2.6657e-05]],\n     \n              [[-2.1395e-05]],\n     \n              [[ 3.3959e-05]],\n     \n              ...,\n     \n              [[-2.6782e-05]],\n     \n              [[ 2.0353e-05]],\n     \n              [[ 1.9701e-05]]],\n     \n     \n             [[[ 1.7234e-05]],\n     \n              [[-2.8807e-05]],\n     \n              [[-5.7478e-05]],\n     \n              ...,\n     \n              [[-8.2236e-05]],\n     \n              [[-1.5523e-05]],\n     \n              [[-1.8623e-06]]]]),\n     'exp_avg_sq': tensor([[[[2.8251e-09]],\n     \n              [[3.1694e-09]],\n     \n              [[2.2110e-09]],\n     \n              ...,\n     \n              [[2.9140e-09]],\n     \n              [[3.7575e-09]],\n     \n              [[3.4885e-09]]],\n     \n     \n             [[[3.3645e-09]],\n     \n              [[3.6415e-09]],\n     \n              [[1.5416e-09]],\n     \n              ...,\n     \n              [[4.8683e-09]],\n     \n              [[4.5178e-09]],\n     \n              [[5.0061e-09]]],\n     \n     \n             [[[3.8817e-09]],\n     \n              [[3.5351e-09]],\n     \n              [[1.0202e-08]],\n     \n              ...,\n     \n              [[4.3669e-09]],\n     \n              [[2.1998e-09]],\n     \n              [[3.4861e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[4.2197e-09]],\n     \n              [[6.3815e-09]],\n     \n              [[5.6231e-09]],\n     \n              ...,\n     \n              [[2.6554e-09]],\n     \n              [[5.1545e-09]],\n     \n              [[3.5588e-09]]],\n     \n     \n             [[[4.5858e-09]],\n     \n              [[4.0291e-09]],\n     \n              [[5.0638e-09]],\n     \n              ...,\n     \n              [[6.0991e-09]],\n     \n              [[5.6175e-09]],\n     \n              [[5.8517e-09]]],\n     \n     \n             [[[4.4344e-09]],\n     \n              [[2.8189e-09]],\n     \n              [[6.5897e-09]],\n     \n              ...,\n     \n              [[3.3266e-09]],\n     \n              [[4.1920e-09]],\n     \n              [[5.3189e-09]]]])},\n    158: {'exp_avg': tensor([[[[-1.6233e-05]],\n     \n              [[-2.5316e-05]],\n     \n              [[ 3.5179e-05]],\n     \n              ...,\n     \n              [[ 4.2754e-05]],\n     \n              [[ 3.7966e-05]],\n     \n              [[-3.1435e-05]]],\n     \n     \n             [[[-2.0708e-05]],\n     \n              [[ 1.6472e-05]],\n     \n              [[ 4.3627e-06]],\n     \n              ...,\n     \n              [[ 4.6608e-05]],\n     \n              [[ 2.5158e-05]],\n     \n              [[-7.7814e-05]]],\n     \n     \n             [[[ 5.3754e-05]],\n     \n              [[-2.2082e-05]],\n     \n              [[-1.1789e-07]],\n     \n              ...,\n     \n              [[-1.7417e-05]],\n     \n              [[-6.6565e-06]],\n     \n              [[ 4.4990e-07]]],\n     \n     \n             ...,\n     \n     \n             [[[-2.3130e-05]],\n     \n              [[-2.6240e-05]],\n     \n              [[-1.2750e-05]],\n     \n              ...,\n     \n              [[ 2.6249e-05]],\n     \n              [[-1.0013e-05]],\n     \n              [[-3.1092e-05]]],\n     \n     \n             [[[ 7.0856e-06]],\n     \n              [[ 4.8697e-05]],\n     \n              [[-5.5142e-05]],\n     \n              ...,\n     \n              [[-2.3130e-05]],\n     \n              [[-5.5119e-05]],\n     \n              [[ 2.5093e-05]]],\n     \n     \n             [[[ 5.5714e-06]],\n     \n              [[ 4.7692e-05]],\n     \n              [[ 4.2068e-05]],\n     \n              ...,\n     \n              [[-6.5660e-05]],\n     \n              [[-1.6023e-05]],\n     \n              [[ 4.7385e-05]]]]),\n     'exp_avg_sq': tensor([[[[7.9139e-10]],\n     \n              [[4.3154e-09]],\n     \n              [[9.1769e-10]],\n     \n              ...,\n     \n              [[1.0025e-09]],\n     \n              [[2.4717e-09]],\n     \n              [[1.5192e-09]]],\n     \n     \n             [[[4.3112e-09]],\n     \n              [[8.1362e-09]],\n     \n              [[5.1789e-09]],\n     \n              ...,\n     \n              [[3.9882e-09]],\n     \n              [[5.2162e-09]],\n     \n              [[5.5349e-09]]],\n     \n     \n             [[[1.7775e-09]],\n     \n              [[1.9637e-09]],\n     \n              [[9.0576e-10]],\n     \n              ...,\n     \n              [[4.2726e-09]],\n     \n              [[3.0235e-09]],\n     \n              [[1.4848e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[5.7197e-10]],\n     \n              [[2.0946e-09]],\n     \n              [[6.8749e-10]],\n     \n              ...,\n     \n              [[1.8901e-09]],\n     \n              [[1.8360e-09]],\n     \n              [[9.4814e-10]]],\n     \n     \n             [[[8.4878e-09]],\n     \n              [[2.6233e-08]],\n     \n              [[3.4858e-08]],\n     \n              ...,\n     \n              [[1.0581e-08]],\n     \n              [[9.6951e-09]],\n     \n              [[8.9694e-09]]],\n     \n     \n             [[[3.0815e-09]],\n     \n              [[3.9917e-09]],\n     \n              [[2.1355e-09]],\n     \n              ...,\n     \n              [[3.3096e-09]],\n     \n              [[3.5407e-09]],\n     \n              [[2.3360e-09]]]])},\n    159: {'exp_avg': tensor([[[[ 1.0519e-06,  1.6200e-06,  1.3641e-05],\n               [ 1.9787e-05,  5.8499e-05,  4.0747e-05],\n               [ 1.1207e-06,  5.9395e-06,  7.7282e-06]],\n     \n              [[ 3.5264e-06, -2.9099e-06,  3.9781e-06],\n               [-8.8312e-06, -1.6733e-05, -3.1665e-05],\n               [-3.9577e-05, -7.2448e-05, -2.5874e-05]],\n     \n              [[-2.3906e-05, -5.0305e-05, -3.6294e-05],\n               [-2.9658e-05, -1.0130e-04, -6.4009e-05],\n               [-5.6385e-06, -6.5687e-05, -3.1343e-05]],\n     \n              ...,\n     \n              [[-5.3198e-06,  3.5392e-05,  2.5680e-05],\n               [-4.1857e-06,  2.0493e-05,  7.8945e-06],\n               [-1.2313e-05,  1.0730e-05,  9.1399e-06]],\n     \n              [[-6.4747e-06, -1.3852e-05, -4.3857e-06],\n               [ 3.2499e-05,  7.4930e-05,  7.5392e-07],\n               [ 1.2415e-05,  7.2256e-05,  1.5529e-05]],\n     \n              [[ 6.4496e-06,  3.2232e-05, -6.0709e-06],\n               [ 3.0813e-05,  8.9903e-05,  2.0797e-05],\n               [ 2.6821e-08,  5.2908e-05,  1.4362e-05]]],\n     \n     \n             [[[-9.2023e-06, -2.3709e-06, -9.1745e-06],\n               [-2.4496e-05, -6.5911e-06,  2.2219e-05],\n               [-7.3782e-06, -1.4482e-05,  1.3648e-05]],\n     \n              [[ 5.5977e-07, -2.0827e-06, -7.4014e-06],\n               [-5.4517e-06, -1.6810e-05, -8.4959e-06],\n               [-1.7026e-05, -7.1682e-06,  1.6358e-06]],\n     \n              [[ 2.6267e-06,  1.8400e-05, -1.6885e-06],\n               [ 5.4704e-08,  7.5582e-06,  1.7643e-05],\n               [-9.4159e-08,  3.0539e-05,  1.7408e-05]],\n     \n              ...,\n     \n              [[ 1.9712e-07, -9.3101e-06, -5.8935e-06],\n               [-3.0624e-06,  2.6834e-05,  1.5777e-05],\n               [-2.9244e-06,  1.6537e-05,  8.0151e-06]],\n     \n              [[ 8.7101e-07, -2.3028e-05, -4.5581e-06],\n               [-1.7827e-05, -3.7955e-05,  1.7048e-07],\n               [-2.5543e-06, -3.5515e-05, -1.8185e-05]],\n     \n              [[ 2.5550e-05,  1.9268e-05,  3.1394e-06],\n               [-4.7729e-05,  1.9121e-05,  1.7843e-06],\n               [-1.5870e-05,  8.4663e-08,  2.3789e-05]]],\n     \n     \n             [[[-5.5186e-06,  2.4730e-05,  3.8763e-05],\n               [-6.1994e-06, -1.8885e-05, -8.9765e-06],\n               [-3.5160e-06, -3.8620e-06, -7.1194e-07]],\n     \n              [[-6.3733e-06,  9.6864e-06,  3.5361e-06],\n               [-1.9158e-06,  1.0329e-05,  6.4310e-06],\n               [ 3.8454e-06,  6.1307e-06,  2.6418e-06]],\n     \n              [[-1.6613e-05,  3.1035e-06, -2.8893e-06],\n               [-6.3507e-06,  1.4230e-05,  8.9679e-06],\n               [-4.6440e-07,  1.7102e-06,  2.7370e-06]],\n     \n              ...,\n     \n              [[-1.3946e-09,  1.0115e-05,  3.6378e-06],\n               [-8.7139e-06, -8.6078e-06, -2.8460e-06],\n               [-1.0834e-06, -2.6398e-06, -2.6932e-07]],\n     \n              [[ 4.4848e-07,  4.0973e-06,  2.9900e-06],\n               [-1.2483e-05,  9.6288e-06,  2.9695e-06],\n               [ 9.7227e-07,  1.0021e-05,  4.7035e-07]],\n     \n              [[-5.8322e-05, -3.7851e-05, -7.7127e-06],\n               [-1.0642e-05, -3.2078e-05,  7.4112e-06],\n               [-1.7008e-05, -9.9291e-06,  1.5864e-05]]],\n     \n     \n             ...,\n     \n     \n             [[[ 1.7652e-05,  9.6407e-06,  3.6477e-06],\n               [ 2.4653e-05,  1.1878e-05,  5.3591e-07],\n               [ 6.0460e-07, -4.8128e-06,  2.7296e-06]],\n     \n              [[ 1.3204e-05,  3.9477e-05,  7.0735e-07],\n               [ 5.2160e-05,  6.4400e-05,  2.5994e-05],\n               [ 1.8952e-05,  3.5618e-05,  3.1975e-05]],\n     \n              [[-1.7685e-05, -3.2059e-05, -2.5859e-05],\n               [-6.2506e-06,  1.3918e-06, -3.3494e-05],\n               [ 4.2356e-06, -2.8649e-05, -6.7111e-06]],\n     \n              ...,\n     \n              [[-3.8337e-06, -6.8114e-06, -6.9664e-07],\n               [-5.8303e-06, -8.0908e-06,  5.3243e-06],\n               [-1.9797e-05, -3.0246e-05, -1.3284e-05]],\n     \n              [[-5.0941e-06,  1.1614e-05,  9.0628e-06],\n               [ 7.0611e-06,  1.5474e-05, -4.0323e-06],\n               [ 3.3635e-06,  9.6437e-06,  4.1025e-06]],\n     \n              [[ 3.8777e-05,  4.2505e-05,  2.5202e-05],\n               [ 6.6849e-05,  7.7556e-05,  5.8810e-05],\n               [ 2.2365e-05,  4.4452e-05,  3.2567e-05]]],\n     \n     \n             [[[ 1.1371e-05,  1.9111e-05,  1.1199e-05],\n               [ 1.6462e-05, -4.8775e-06,  7.5787e-08],\n               [ 5.7368e-06,  1.0698e-05, -2.6964e-06]],\n     \n              [[-5.0649e-07, -8.3282e-06,  6.2976e-07],\n               [ 1.0157e-05,  1.1281e-05,  4.3114e-06],\n               [-1.5468e-05, -4.0045e-05, -1.4101e-05]],\n     \n              [[-7.1831e-06, -3.0180e-07,  1.0008e-05],\n               [-2.3406e-06,  3.1908e-05,  2.6856e-05],\n               [-2.6927e-05, -4.8156e-06,  1.8991e-06]],\n     \n              ...,\n     \n              [[ 4.6707e-06,  2.6057e-06, -8.2679e-07],\n               [ 3.2478e-07,  1.9150e-06,  3.3415e-06],\n               [ 2.6342e-06, -1.3830e-06,  6.3707e-06]],\n     \n              [[-7.7969e-06, -8.4653e-06,  5.1243e-06],\n               [ 8.0365e-07,  2.9260e-05,  4.2661e-06],\n               [ 5.0188e-07,  3.1325e-05,  1.3930e-05]],\n     \n              [[-8.7860e-06,  9.6662e-06,  1.1353e-05],\n               [-3.5935e-05, -1.8112e-05,  9.4152e-06],\n               [ 4.9495e-06,  1.7568e-05,  2.1942e-05]]],\n     \n     \n             [[[ 6.4296e-06,  1.2445e-06, -2.8364e-06],\n               [ 2.3723e-06,  2.1711e-05, -2.3950e-06],\n               [-6.0050e-07, -4.9071e-06, -8.0976e-06]],\n     \n              [[-3.3618e-05, -3.2456e-05, -1.0205e-05],\n               [-9.0320e-05, -1.2313e-04, -5.4631e-05],\n               [-4.5270e-05, -7.5007e-05, -5.2226e-06]],\n     \n              [[-3.2135e-06,  3.1888e-05,  1.7152e-05],\n               [-1.8845e-06,  1.6527e-05,  2.1670e-05],\n               [-2.0076e-05, -4.0637e-06, -4.9522e-06]],\n     \n              ...,\n     \n              [[-7.1124e-07, -6.6807e-06,  4.2255e-06],\n               [-8.5040e-06, -5.2175e-06,  1.0431e-05],\n               [-1.3132e-05, -2.7951e-06,  4.8987e-08]],\n     \n              [[-5.6050e-06, -5.9340e-06,  4.1142e-06],\n               [ 2.8897e-06, -9.8364e-06,  3.2064e-07],\n               [ 3.7478e-06, -5.7462e-06, -3.1789e-05]],\n     \n              [[-2.9095e-05,  4.3223e-06,  6.5413e-06],\n               [-9.4162e-06,  2.5507e-05,  4.7904e-05],\n               [-7.3218e-06, -1.7551e-05,  3.6630e-06]]]]),\n     'exp_avg_sq': tensor([[[[2.1398e-10, 6.2074e-10, 3.8811e-10],\n               [7.7030e-10, 1.3640e-09, 6.4972e-10],\n               [4.8782e-10, 6.0230e-10, 4.2664e-10]],\n     \n              [[2.5526e-10, 4.3104e-10, 1.5434e-10],\n               [7.0271e-10, 2.2755e-09, 1.3956e-09],\n               [4.9466e-10, 1.9938e-09, 1.0119e-09]],\n     \n              [[5.2310e-10, 1.6407e-09, 5.9610e-10],\n               [1.3880e-09, 5.4282e-09, 1.9866e-09],\n               [6.0483e-10, 2.3302e-09, 9.9455e-10]],\n     \n              ...,\n     \n              [[9.9337e-11, 5.3069e-10, 3.7739e-10],\n               [6.7035e-10, 1.7789e-09, 1.1675e-09],\n               [5.1544e-10, 1.1756e-09, 4.3241e-10]],\n     \n              [[1.0564e-09, 3.0230e-09, 7.8416e-10],\n               [2.6068e-09, 7.4033e-09, 2.5543e-09],\n               [1.8569e-09, 3.9259e-09, 1.4597e-09]],\n     \n              [[9.7939e-10, 1.9129e-09, 7.1863e-10],\n               [2.4579e-09, 5.3003e-09, 1.6947e-09],\n               [9.7607e-10, 2.1297e-09, 8.1918e-10]]],\n     \n     \n             [[[1.6239e-10, 5.3648e-10, 4.8739e-10],\n               [8.4897e-10, 1.1888e-09, 7.5155e-10],\n               [2.8404e-10, 1.1354e-09, 2.9486e-10]],\n     \n              [[2.0326e-11, 1.6544e-10, 3.3284e-10],\n               [5.8202e-10, 1.5250e-09, 4.8373e-10],\n               [3.2626e-10, 1.0963e-09, 6.9880e-10]],\n     \n              [[2.8794e-11, 2.3696e-10, 2.8144e-10],\n               [2.3746e-10, 1.7407e-09, 8.8733e-10],\n               [3.5810e-10, 9.2354e-10, 3.7095e-10]],\n     \n              ...,\n     \n              [[1.5693e-10, 6.4791e-10, 6.5443e-10],\n               [8.7109e-10, 3.3919e-09, 1.1938e-09],\n               [6.1476e-10, 1.6440e-09, 6.6360e-10]],\n     \n              [[7.2363e-11, 6.4808e-10, 6.8296e-10],\n               [5.6152e-10, 4.4585e-09, 1.5077e-09],\n               [4.5892e-10, 3.2573e-09, 2.7485e-10]],\n     \n              [[2.0076e-09, 3.0764e-09, 1.2568e-09],\n               [2.1676e-09, 3.6016e-09, 1.5421e-09],\n               [5.9446e-10, 1.1301e-09, 6.5300e-10]]],\n     \n     \n             [[[1.2770e-10, 3.4700e-10, 2.6308e-10],\n               [8.8265e-11, 1.9603e-10, 1.3061e-10],\n               [3.1238e-11, 7.5314e-11, 2.9014e-10]],\n     \n              [[1.5701e-10, 6.3391e-10, 2.7961e-10],\n               [3.0925e-10, 1.7974e-09, 7.9234e-10],\n               [6.9035e-11, 3.0890e-10, 2.3561e-10]],\n     \n              [[1.0547e-10, 4.3232e-10, 1.8638e-10],\n               [3.5279e-10, 9.4244e-10, 3.4292e-10],\n               [2.3932e-10, 4.2419e-10, 9.2888e-11]],\n     \n              ...,\n     \n              [[6.8228e-11, 1.1260e-10, 3.0465e-11],\n               [5.4651e-10, 5.0973e-10, 6.0668e-11],\n               [1.3641e-10, 3.0763e-10, 5.5801e-11]],\n     \n              [[8.3721e-11, 2.2736e-10, 3.8597e-11],\n               [2.6685e-10, 4.7501e-10, 3.2689e-10],\n               [1.5541e-10, 3.2030e-10, 1.9543e-10]],\n     \n              [[1.1435e-09, 1.7983e-09, 5.5819e-10],\n               [1.6887e-09, 4.1409e-09, 1.8193e-09],\n               [6.3059e-10, 1.7313e-09, 7.0298e-10]]],\n     \n     \n             ...,\n     \n     \n             [[[3.5756e-10, 6.1617e-10, 1.9960e-10],\n               [6.4203e-10, 1.4054e-09, 4.1484e-10],\n               [2.8728e-10, 5.6949e-10, 3.4286e-10]],\n     \n              [[3.8821e-10, 1.1600e-09, 4.5542e-10],\n               [8.3018e-10, 3.1088e-09, 1.4437e-09],\n               [4.9998e-10, 1.5821e-09, 6.3534e-10]],\n     \n              [[6.5339e-10, 2.3554e-09, 6.4475e-10],\n               [1.6998e-09, 7.6082e-09, 2.8468e-09],\n               [6.2199e-10, 2.6020e-09, 1.2625e-09]],\n     \n              ...,\n     \n              [[7.6625e-11, 2.8523e-10, 1.2043e-10],\n               [4.8993e-10, 1.2580e-09, 7.2503e-10],\n               [4.0462e-10, 1.2777e-09, 5.4128e-10]],\n     \n              [[2.1821e-10, 4.3543e-10, 3.8972e-10],\n               [5.2090e-10, 1.5740e-09, 8.7816e-10],\n               [3.3588e-10, 1.1659e-09, 7.1279e-10]],\n     \n              [[1.5026e-09, 3.0398e-09, 9.9865e-10],\n               [2.5335e-09, 6.1371e-09, 2.3465e-09],\n               [7.5769e-10, 1.9626e-09, 7.3821e-10]]],\n     \n     \n             [[[5.2865e-11, 1.0865e-10, 7.0447e-11],\n               [3.4772e-10, 3.7906e-10, 2.0678e-10],\n               [1.1781e-10, 5.7957e-10, 1.8223e-10]],\n     \n              [[1.3405e-10, 2.7591e-10, 6.2431e-11],\n               [2.6972e-10, 1.0132e-09, 9.3459e-10],\n               [1.8849e-10, 7.4194e-10, 2.5232e-10]],\n     \n              [[6.8780e-10, 1.9943e-09, 4.8477e-10],\n               [1.5515e-09, 2.7353e-09, 9.1842e-10],\n               [7.3306e-10, 8.9841e-10, 4.6429e-10]],\n     \n              ...,\n     \n              [[1.0680e-10, 1.1488e-10, 5.9826e-11],\n               [3.4964e-10, 4.2737e-10, 2.1045e-10],\n               [1.8532e-10, 2.1538e-10, 1.6241e-10]],\n     \n              [[2.7186e-10, 8.2985e-10, 2.4179e-10],\n               [1.1737e-09, 2.9246e-09, 1.0906e-09],\n               [6.3493e-10, 1.3321e-09, 7.2971e-10]],\n     \n              [[7.8156e-10, 1.2454e-09, 6.0902e-10],\n               [1.8947e-09, 3.4775e-09, 1.1699e-09],\n               [4.9619e-10, 1.1666e-09, 6.6998e-10]]],\n     \n     \n             [[[2.4925e-11, 1.5946e-10, 1.1887e-10],\n               [2.7290e-10, 3.5745e-10, 2.3466e-10],\n               [5.1036e-11, 1.8392e-10, 7.5231e-11]],\n     \n              [[6.9746e-10, 1.1929e-09, 5.8219e-10],\n               [4.3415e-09, 7.1844e-09, 2.2581e-09],\n               [1.2744e-09, 1.9955e-09, 9.6339e-10]],\n     \n              [[2.6980e-10, 1.1162e-09, 7.5747e-10],\n               [6.6864e-10, 3.5978e-09, 1.2715e-09],\n               [4.1852e-10, 1.5854e-09, 7.4628e-10]],\n     \n              ...,\n     \n              [[1.8943e-10, 3.7954e-10, 1.3596e-10],\n               [8.2674e-10, 1.6744e-09, 5.2787e-10],\n               [6.1034e-10, 1.0625e-09, 4.5168e-10]],\n     \n              [[1.3689e-10, 4.4244e-10, 2.0708e-10],\n               [3.5920e-10, 2.1338e-09, 8.0314e-10],\n               [2.4994e-10, 1.3218e-09, 8.0121e-10]],\n     \n              [[1.9238e-09, 2.5117e-09, 8.7546e-10],\n               [2.3577e-09, 2.1745e-09, 1.2685e-09],\n               [5.6629e-10, 8.1315e-10, 4.8456e-10]]]])},\n    160: {'exp_avg': tensor([[[[-6.2368e-05]],\n     \n              [[ 8.9508e-06]],\n     \n              [[-3.7625e-06]],\n     \n              ...,\n     \n              [[-4.9792e-05]],\n     \n              [[-3.3558e-05]],\n     \n              [[-2.8478e-05]]],\n     \n     \n             [[[ 4.8930e-05]],\n     \n              [[-9.7538e-06]],\n     \n              [[ 9.9021e-06]],\n     \n              ...,\n     \n              [[-3.5109e-05]],\n     \n              [[-2.9016e-06]],\n     \n              [[ 5.8889e-06]]],\n     \n     \n             [[[-7.3856e-05]],\n     \n              [[-1.5529e-06]],\n     \n              [[-1.0808e-05]],\n     \n              ...,\n     \n              [[ 7.0869e-06]],\n     \n              [[ 3.5327e-05]],\n     \n              [[ 5.1303e-06]]],\n     \n     \n             ...,\n     \n     \n             [[[ 1.8746e-06]],\n     \n              [[-1.6900e-05]],\n     \n              [[ 1.7361e-05]],\n     \n              ...,\n     \n              [[-1.7450e-05]],\n     \n              [[ 5.0997e-06]],\n     \n              [[-1.0441e-05]]],\n     \n     \n             [[[ 4.0749e-05]],\n     \n              [[-2.7065e-05]],\n     \n              [[ 1.9423e-05]],\n     \n              ...,\n     \n              [[ 2.6345e-05]],\n     \n              [[-7.9256e-06]],\n     \n              [[-2.4996e-05]]],\n     \n     \n             [[[-5.3421e-05]],\n     \n              [[ 3.8653e-06]],\n     \n              [[-2.5331e-06]],\n     \n              ...,\n     \n              [[-1.6566e-07]],\n     \n              [[ 7.7007e-05]],\n     \n              [[ 2.9122e-05]]]]),\n     'exp_avg_sq': tensor([[[[3.0448e-09]],\n     \n              [[1.4653e-09]],\n     \n              [[1.6080e-09]],\n     \n              ...,\n     \n              [[2.1931e-09]],\n     \n              [[9.9597e-10]],\n     \n              [[1.3030e-09]]],\n     \n     \n             [[[2.6229e-09]],\n     \n              [[1.2785e-09]],\n     \n              [[6.7474e-10]],\n     \n              ...,\n     \n              [[2.1431e-09]],\n     \n              [[1.8800e-09]],\n     \n              [[1.5457e-09]]],\n     \n     \n             [[[3.2365e-09]],\n     \n              [[2.9864e-09]],\n     \n              [[9.6616e-10]],\n     \n              ...,\n     \n              [[2.6750e-09]],\n     \n              [[1.1033e-09]],\n     \n              [[2.2239e-09]]],\n     \n     \n             ...,\n     \n     \n             [[[4.5576e-09]],\n     \n              [[3.2928e-09]],\n     \n              [[8.3912e-10]],\n     \n              ...,\n     \n              [[2.7229e-09]],\n     \n              [[1.4891e-09]],\n     \n              [[1.1986e-08]]],\n     \n     \n             [[[3.5456e-09]],\n     \n              [[1.5151e-09]],\n     \n              [[6.1925e-10]],\n     \n              ...,\n     \n              [[2.6336e-09]],\n     \n              [[1.1619e-09]],\n     \n              [[1.6129e-09]]],\n     \n     \n             [[[2.1823e-09]],\n     \n              [[2.1284e-09]],\n     \n              [[7.8837e-10]],\n     \n              ...,\n     \n              [[2.8085e-09]],\n     \n              [[2.3228e-09]],\n     \n              [[1.2176e-09]]]])},\n    162: {'exp_avg': tensor([[ 4.8636e-06, -7.5938e-05, -6.1819e-05,  ...,  2.3770e-05,\n               5.0096e-05,  2.0931e-05],\n             [-6.5918e-05, -4.9793e-05,  8.4233e-05,  ...,  4.6430e-05,\n               3.5112e-05, -4.2154e-05],\n             [-4.1661e-05,  1.2661e-05,  1.1509e-05,  ...,  2.6560e-05,\n              -4.3526e-04, -1.6750e-05],\n             ...,\n             [ 5.6633e-05,  8.9646e-05,  1.1054e-05,  ...,  4.4532e-05,\n              -5.5942e-05, -3.8194e-05],\n             [ 1.9280e-05,  3.3410e-05,  2.4996e-05,  ..., -2.5129e-06,\n              -7.4553e-05, -4.7905e-05],\n             [ 4.0665e-05,  2.1887e-04,  2.1942e-04,  ...,  1.7679e-04,\n               1.1673e-04,  6.1735e-05]]),\n     'exp_avg_sq': tensor([[1.3261e-08, 3.5121e-08, 5.3378e-08,  ..., 3.5834e-08, 2.7760e-08,\n              4.9967e-08],\n             [4.9712e-08, 2.3034e-08, 4.9207e-08,  ..., 1.9714e-08, 4.0091e-08,\n              3.7229e-08],\n             [6.4974e-08, 5.8663e-08, 5.1015e-08,  ..., 8.7574e-09, 2.9604e-07,\n              2.8381e-08],\n             ...,\n             [4.0187e-08, 3.8047e-08, 3.4346e-08,  ..., 2.6677e-08, 8.7578e-08,\n              7.1167e-08],\n             [1.0888e-08, 2.0458e-08, 1.2154e-08,  ..., 1.8024e-08, 6.0925e-08,\n              1.3790e-08],\n             [2.2528e-08, 9.3329e-08, 4.3279e-08,  ..., 9.1548e-08, 4.1716e-08,\n              2.8880e-08]])}},\n   'param_groups': [{'weight_decay': 0.0,\n     'lr': 8.89120000000007e-05,\n     'bias_correction': True,\n     'betas': (0.9, 0.999),\n     'eps': 1e-06,\n     'grad_averaging': True,\n     'max_grad_norm': 1.0,\n     'trust_clip': False,\n     'always_adapt': False,\n     'initial_lr': 0.001,\n     'step': 2046,\n     'params': [0,\n      1,\n      2,\n      3,\n      4,\n      5,\n      6,\n      7,\n      8,\n      9,\n      10,\n      11,\n      12,\n      13,\n      14,\n      15,\n      16,\n      17,\n      18,\n      19,\n      20,\n      21,\n      22,\n      23,\n      24,\n      25,\n      26,\n      27,\n      28,\n      29,\n      30,\n      31,\n      32,\n      33,\n      34,\n      35,\n      36,\n      37,\n      38,\n      39,\n      40,\n      41,\n      42,\n      43,\n      44,\n      45,\n      46,\n      47,\n      48,\n      49,\n      50,\n      51,\n      52,\n      53,\n      54,\n      55,\n      56,\n      57,\n      58,\n      59,\n      60,\n      61,\n      62,\n      63,\n      64,\n      65,\n      66,\n      67,\n      68,\n      69,\n      70,\n      71,\n      72,\n      73,\n      74,\n      75,\n      76,\n      77,\n      78,\n      79,\n      80,\n      81,\n      82,\n      83,\n      84,\n      85,\n      86,\n      87,\n      88,\n      89,\n      90,\n      91,\n      92,\n      93,\n      94,\n      95,\n      96,\n      97,\n      98,\n      99,\n      100,\n      101,\n      102,\n      103,\n      104,\n      105,\n      107,\n      107]},\n    {'weight_decay': 0.0001,\n     'lr': 8.89120000000007e-05,\n     'bias_correction': True,\n     'betas': (0.9, 0.999),\n     'eps': 1e-06,\n     'grad_averaging': True,\n     'max_grad_norm': 1.0,\n     'trust_clip': False,\n     'always_adapt': False,\n     'initial_lr': 0.001,\n     'step': 2046,\n     'params': [108,\n      109,\n      110,\n      111,\n      112,\n      113,\n      114,\n      115,\n      116,\n      117,\n      118,\n      119,\n      120,\n      121,\n      122,\n      123,\n      124,\n      125,\n      126,\n      127,\n      128,\n      129,\n      130,\n      131,\n      132,\n      133,\n      134,\n      135,\n      136,\n      137,\n      138,\n      139,\n      140,\n      141,\n      142,\n      143,\n      144,\n      145,\n      146,\n      147,\n      148,\n      149,\n      150,\n      151,\n      152,\n      153,\n      154,\n      155,\n      156,\n      157,\n      158,\n      159,\n      160,\n      162,\n      162]}]}],\n 'lr_schedulers': [{'_milestones': [23250, 93000, 116250],\n   'last_epoch': 2046,\n   '_last_lr': [8.89120000000007e-05, 8.89120000000007e-05],\n   '_schedulers': [{'start_factor': 0.001,\n     'end_factor': 1.0,\n     'total_iters': 23250,\n     'base_lrs': [0.001, 0.001],\n     'last_epoch': 2046,\n     'verbose': False,\n     '_step_count': 2047,\n     '_get_lr_called_within_step': False,\n     '_last_lr': [8.89120000000007e-05, 8.89120000000007e-05]},\n    {'T_max': 69750,\n     'eta_min': 0,\n     'base_lrs': [0.001, 0.001],\n     'last_epoch': -1,\n     'verbose': False,\n     '_step_count': 1,\n     '_get_lr_called_within_step': False,\n     '_last_lr': [1e-06, 1e-06]},\n    {'start_factor': 0.001,\n     'end_factor': 1.0,\n     'total_iters': 23250,\n     'base_lrs': [0.001, 0.001],\n     'last_epoch': -1,\n     'verbose': False,\n     '_step_count': 1,\n     '_get_lr_called_within_step': False,\n     '_last_lr': [1e-09, 1e-09]},\n    {'T_max': 116250,\n     'eta_min': 0,\n     'base_lrs': [0.001, 0.001],\n     'last_epoch': -1,\n     'verbose': False,\n     '_step_count': 1,\n     '_get_lr_called_within_step': False,\n     '_last_lr': [1e-09, 1e-09]}]}],\n 'hparams_name': 'kwargs',\n 'hyper_parameters': {'unfreeze_backbone_at_epoch': 20,\n  'unfreeze_only_ensemble_weights': False,\n  'warmup_epochs': 5,\n  'lr': 0.001,\n  'momentum': 0.9,\n  'weight_decay': 0.0001},\n 'datamodule_hparams_name': 'kwargs',\n 'datamodule_hyper_parameters': {'path': '/home/doved/Data/AAIT/task1',\n  'hq_path': '/home/doved/Data/AAIT_upsampled/task1',\n  'load_hq_images': False,\n  'num_train_workers': 8,\n  'num_val_workers': 8,\n  'num_test_workers': 8,\n  'batch_size': 1024,\n  'labeled': True,\n  'unlabeled': False,\n  'val_size': 0.2,\n  'no_train_augmentations': True,\n  'byol': False,\n  'train_dataset_replicas': 5}}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision.io\n",
    "\n",
    "ckpt = torch.load(\"./resnet50.lr01.final.ckpt\", map_location=\"cpu\")\n",
    "ckpt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T16:27:42.952285324Z",
     "start_time": "2024-01-07T16:27:36.601390636Z"
    }
   },
   "id": "99d9779170e3a374"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters', 'datamodule_hparams_name', 'datamodule_hyper_parameters'])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T16:28:08.832720966Z",
     "start_time": "2024-01-07T16:28:08.180470265Z"
    }
   },
   "id": "a73bfc9bca312a3b",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "odict_keys(['backbone.ensemble_weights', 'backbone.models.0.model.conv1.weight', 'backbone.models.0.model.bn1.weight', 'backbone.models.0.model.bn1.bias', 'backbone.models.0.model.bn1.running_mean', 'backbone.models.0.model.bn1.running_var', 'backbone.models.0.model.bn1.num_batches_tracked', 'backbone.models.0.model.layer1.0.conv1.weight', 'backbone.models.0.model.layer1.0.bn1.weight', 'backbone.models.0.model.layer1.0.bn1.bias', 'backbone.models.0.model.layer1.0.bn1.running_mean', 'backbone.models.0.model.layer1.0.bn1.running_var', 'backbone.models.0.model.layer1.0.bn1.num_batches_tracked', 'backbone.models.0.model.layer1.0.conv2.weight', 'backbone.models.0.model.layer1.0.bn2.weight', 'backbone.models.0.model.layer1.0.bn2.bias', 'backbone.models.0.model.layer1.0.bn2.running_mean', 'backbone.models.0.model.layer1.0.bn2.running_var', 'backbone.models.0.model.layer1.0.bn2.num_batches_tracked', 'backbone.models.0.model.layer1.0.conv3.weight', 'backbone.models.0.model.layer1.0.bn3.weight', 'backbone.models.0.model.layer1.0.bn3.bias', 'backbone.models.0.model.layer1.0.bn3.running_mean', 'backbone.models.0.model.layer1.0.bn3.running_var', 'backbone.models.0.model.layer1.0.bn3.num_batches_tracked', 'backbone.models.0.model.layer1.0.downsample.0.weight', 'backbone.models.0.model.layer1.0.downsample.1.weight', 'backbone.models.0.model.layer1.0.downsample.1.bias', 'backbone.models.0.model.layer1.0.downsample.1.running_mean', 'backbone.models.0.model.layer1.0.downsample.1.running_var', 'backbone.models.0.model.layer1.0.downsample.1.num_batches_tracked', 'backbone.models.0.model.layer1.1.conv1.weight', 'backbone.models.0.model.layer1.1.bn1.weight', 'backbone.models.0.model.layer1.1.bn1.bias', 'backbone.models.0.model.layer1.1.bn1.running_mean', 'backbone.models.0.model.layer1.1.bn1.running_var', 'backbone.models.0.model.layer1.1.bn1.num_batches_tracked', 'backbone.models.0.model.layer1.1.conv2.weight', 'backbone.models.0.model.layer1.1.bn2.weight', 'backbone.models.0.model.layer1.1.bn2.bias', 'backbone.models.0.model.layer1.1.bn2.running_mean', 'backbone.models.0.model.layer1.1.bn2.running_var', 'backbone.models.0.model.layer1.1.bn2.num_batches_tracked', 'backbone.models.0.model.layer1.1.conv3.weight', 'backbone.models.0.model.layer1.1.bn3.weight', 'backbone.models.0.model.layer1.1.bn3.bias', 'backbone.models.0.model.layer1.1.bn3.running_mean', 'backbone.models.0.model.layer1.1.bn3.running_var', 'backbone.models.0.model.layer1.1.bn3.num_batches_tracked', 'backbone.models.0.model.layer1.2.conv1.weight', 'backbone.models.0.model.layer1.2.bn1.weight', 'backbone.models.0.model.layer1.2.bn1.bias', 'backbone.models.0.model.layer1.2.bn1.running_mean', 'backbone.models.0.model.layer1.2.bn1.running_var', 'backbone.models.0.model.layer1.2.bn1.num_batches_tracked', 'backbone.models.0.model.layer1.2.conv2.weight', 'backbone.models.0.model.layer1.2.bn2.weight', 'backbone.models.0.model.layer1.2.bn2.bias', 'backbone.models.0.model.layer1.2.bn2.running_mean', 'backbone.models.0.model.layer1.2.bn2.running_var', 'backbone.models.0.model.layer1.2.bn2.num_batches_tracked', 'backbone.models.0.model.layer1.2.conv3.weight', 'backbone.models.0.model.layer1.2.bn3.weight', 'backbone.models.0.model.layer1.2.bn3.bias', 'backbone.models.0.model.layer1.2.bn3.running_mean', 'backbone.models.0.model.layer1.2.bn3.running_var', 'backbone.models.0.model.layer1.2.bn3.num_batches_tracked', 'backbone.models.0.model.layer2.0.conv1.weight', 'backbone.models.0.model.layer2.0.bn1.weight', 'backbone.models.0.model.layer2.0.bn1.bias', 'backbone.models.0.model.layer2.0.bn1.running_mean', 'backbone.models.0.model.layer2.0.bn1.running_var', 'backbone.models.0.model.layer2.0.bn1.num_batches_tracked', 'backbone.models.0.model.layer2.0.conv2.weight', 'backbone.models.0.model.layer2.0.bn2.weight', 'backbone.models.0.model.layer2.0.bn2.bias', 'backbone.models.0.model.layer2.0.bn2.running_mean', 'backbone.models.0.model.layer2.0.bn2.running_var', 'backbone.models.0.model.layer2.0.bn2.num_batches_tracked', 'backbone.models.0.model.layer2.0.conv3.weight', 'backbone.models.0.model.layer2.0.bn3.weight', 'backbone.models.0.model.layer2.0.bn3.bias', 'backbone.models.0.model.layer2.0.bn3.running_mean', 'backbone.models.0.model.layer2.0.bn3.running_var', 'backbone.models.0.model.layer2.0.bn3.num_batches_tracked', 'backbone.models.0.model.layer2.0.downsample.0.weight', 'backbone.models.0.model.layer2.0.downsample.1.weight', 'backbone.models.0.model.layer2.0.downsample.1.bias', 'backbone.models.0.model.layer2.0.downsample.1.running_mean', 'backbone.models.0.model.layer2.0.downsample.1.running_var', 'backbone.models.0.model.layer2.0.downsample.1.num_batches_tracked', 'backbone.models.0.model.layer2.1.conv1.weight', 'backbone.models.0.model.layer2.1.bn1.weight', 'backbone.models.0.model.layer2.1.bn1.bias', 'backbone.models.0.model.layer2.1.bn1.running_mean', 'backbone.models.0.model.layer2.1.bn1.running_var', 'backbone.models.0.model.layer2.1.bn1.num_batches_tracked', 'backbone.models.0.model.layer2.1.conv2.weight', 'backbone.models.0.model.layer2.1.bn2.weight', 'backbone.models.0.model.layer2.1.bn2.bias', 'backbone.models.0.model.layer2.1.bn2.running_mean', 'backbone.models.0.model.layer2.1.bn2.running_var', 'backbone.models.0.model.layer2.1.bn2.num_batches_tracked', 'backbone.models.0.model.layer2.1.conv3.weight', 'backbone.models.0.model.layer2.1.bn3.weight', 'backbone.models.0.model.layer2.1.bn3.bias', 'backbone.models.0.model.layer2.1.bn3.running_mean', 'backbone.models.0.model.layer2.1.bn3.running_var', 'backbone.models.0.model.layer2.1.bn3.num_batches_tracked', 'backbone.models.0.model.layer2.2.conv1.weight', 'backbone.models.0.model.layer2.2.bn1.weight', 'backbone.models.0.model.layer2.2.bn1.bias', 'backbone.models.0.model.layer2.2.bn1.running_mean', 'backbone.models.0.model.layer2.2.bn1.running_var', 'backbone.models.0.model.layer2.2.bn1.num_batches_tracked', 'backbone.models.0.model.layer2.2.conv2.weight', 'backbone.models.0.model.layer2.2.bn2.weight', 'backbone.models.0.model.layer2.2.bn2.bias', 'backbone.models.0.model.layer2.2.bn2.running_mean', 'backbone.models.0.model.layer2.2.bn2.running_var', 'backbone.models.0.model.layer2.2.bn2.num_batches_tracked', 'backbone.models.0.model.layer2.2.conv3.weight', 'backbone.models.0.model.layer2.2.bn3.weight', 'backbone.models.0.model.layer2.2.bn3.bias', 'backbone.models.0.model.layer2.2.bn3.running_mean', 'backbone.models.0.model.layer2.2.bn3.running_var', 'backbone.models.0.model.layer2.2.bn3.num_batches_tracked', 'backbone.models.0.model.layer2.3.conv1.weight', 'backbone.models.0.model.layer2.3.bn1.weight', 'backbone.models.0.model.layer2.3.bn1.bias', 'backbone.models.0.model.layer2.3.bn1.running_mean', 'backbone.models.0.model.layer2.3.bn1.running_var', 'backbone.models.0.model.layer2.3.bn1.num_batches_tracked', 'backbone.models.0.model.layer2.3.conv2.weight', 'backbone.models.0.model.layer2.3.bn2.weight', 'backbone.models.0.model.layer2.3.bn2.bias', 'backbone.models.0.model.layer2.3.bn2.running_mean', 'backbone.models.0.model.layer2.3.bn2.running_var', 'backbone.models.0.model.layer2.3.bn2.num_batches_tracked', 'backbone.models.0.model.layer2.3.conv3.weight', 'backbone.models.0.model.layer2.3.bn3.weight', 'backbone.models.0.model.layer2.3.bn3.bias', 'backbone.models.0.model.layer2.3.bn3.running_mean', 'backbone.models.0.model.layer2.3.bn3.running_var', 'backbone.models.0.model.layer2.3.bn3.num_batches_tracked', 'backbone.models.0.model.layer3.0.conv1.weight', 'backbone.models.0.model.layer3.0.bn1.weight', 'backbone.models.0.model.layer3.0.bn1.bias', 'backbone.models.0.model.layer3.0.bn1.running_mean', 'backbone.models.0.model.layer3.0.bn1.running_var', 'backbone.models.0.model.layer3.0.bn1.num_batches_tracked', 'backbone.models.0.model.layer3.0.conv2.weight', 'backbone.models.0.model.layer3.0.bn2.weight', 'backbone.models.0.model.layer3.0.bn2.bias', 'backbone.models.0.model.layer3.0.bn2.running_mean', 'backbone.models.0.model.layer3.0.bn2.running_var', 'backbone.models.0.model.layer3.0.bn2.num_batches_tracked', 'backbone.models.0.model.layer3.0.conv3.weight', 'backbone.models.0.model.layer3.0.bn3.weight', 'backbone.models.0.model.layer3.0.bn3.bias', 'backbone.models.0.model.layer3.0.bn3.running_mean', 'backbone.models.0.model.layer3.0.bn3.running_var', 'backbone.models.0.model.layer3.0.bn3.num_batches_tracked', 'backbone.models.0.model.layer3.0.downsample.0.weight', 'backbone.models.0.model.layer3.0.downsample.1.weight', 'backbone.models.0.model.layer3.0.downsample.1.bias', 'backbone.models.0.model.layer3.0.downsample.1.running_mean', 'backbone.models.0.model.layer3.0.downsample.1.running_var', 'backbone.models.0.model.layer3.0.downsample.1.num_batches_tracked', 'backbone.models.0.model.layer3.1.conv1.weight', 'backbone.models.0.model.layer3.1.bn1.weight', 'backbone.models.0.model.layer3.1.bn1.bias', 'backbone.models.0.model.layer3.1.bn1.running_mean', 'backbone.models.0.model.layer3.1.bn1.running_var', 'backbone.models.0.model.layer3.1.bn1.num_batches_tracked', 'backbone.models.0.model.layer3.1.conv2.weight', 'backbone.models.0.model.layer3.1.bn2.weight', 'backbone.models.0.model.layer3.1.bn2.bias', 'backbone.models.0.model.layer3.1.bn2.running_mean', 'backbone.models.0.model.layer3.1.bn2.running_var', 'backbone.models.0.model.layer3.1.bn2.num_batches_tracked', 'backbone.models.0.model.layer3.1.conv3.weight', 'backbone.models.0.model.layer3.1.bn3.weight', 'backbone.models.0.model.layer3.1.bn3.bias', 'backbone.models.0.model.layer3.1.bn3.running_mean', 'backbone.models.0.model.layer3.1.bn3.running_var', 'backbone.models.0.model.layer3.1.bn3.num_batches_tracked', 'backbone.models.0.model.layer3.2.conv1.weight', 'backbone.models.0.model.layer3.2.bn1.weight', 'backbone.models.0.model.layer3.2.bn1.bias', 'backbone.models.0.model.layer3.2.bn1.running_mean', 'backbone.models.0.model.layer3.2.bn1.running_var', 'backbone.models.0.model.layer3.2.bn1.num_batches_tracked', 'backbone.models.0.model.layer3.2.conv2.weight', 'backbone.models.0.model.layer3.2.bn2.weight', 'backbone.models.0.model.layer3.2.bn2.bias', 'backbone.models.0.model.layer3.2.bn2.running_mean', 'backbone.models.0.model.layer3.2.bn2.running_var', 'backbone.models.0.model.layer3.2.bn2.num_batches_tracked', 'backbone.models.0.model.layer3.2.conv3.weight', 'backbone.models.0.model.layer3.2.bn3.weight', 'backbone.models.0.model.layer3.2.bn3.bias', 'backbone.models.0.model.layer3.2.bn3.running_mean', 'backbone.models.0.model.layer3.2.bn3.running_var', 'backbone.models.0.model.layer3.2.bn3.num_batches_tracked', 'backbone.models.0.model.layer3.3.conv1.weight', 'backbone.models.0.model.layer3.3.bn1.weight', 'backbone.models.0.model.layer3.3.bn1.bias', 'backbone.models.0.model.layer3.3.bn1.running_mean', 'backbone.models.0.model.layer3.3.bn1.running_var', 'backbone.models.0.model.layer3.3.bn1.num_batches_tracked', 'backbone.models.0.model.layer3.3.conv2.weight', 'backbone.models.0.model.layer3.3.bn2.weight', 'backbone.models.0.model.layer3.3.bn2.bias', 'backbone.models.0.model.layer3.3.bn2.running_mean', 'backbone.models.0.model.layer3.3.bn2.running_var', 'backbone.models.0.model.layer3.3.bn2.num_batches_tracked', 'backbone.models.0.model.layer3.3.conv3.weight', 'backbone.models.0.model.layer3.3.bn3.weight', 'backbone.models.0.model.layer3.3.bn3.bias', 'backbone.models.0.model.layer3.3.bn3.running_mean', 'backbone.models.0.model.layer3.3.bn3.running_var', 'backbone.models.0.model.layer3.3.bn3.num_batches_tracked', 'backbone.models.0.model.layer3.4.conv1.weight', 'backbone.models.0.model.layer3.4.bn1.weight', 'backbone.models.0.model.layer3.4.bn1.bias', 'backbone.models.0.model.layer3.4.bn1.running_mean', 'backbone.models.0.model.layer3.4.bn1.running_var', 'backbone.models.0.model.layer3.4.bn1.num_batches_tracked', 'backbone.models.0.model.layer3.4.conv2.weight', 'backbone.models.0.model.layer3.4.bn2.weight', 'backbone.models.0.model.layer3.4.bn2.bias', 'backbone.models.0.model.layer3.4.bn2.running_mean', 'backbone.models.0.model.layer3.4.bn2.running_var', 'backbone.models.0.model.layer3.4.bn2.num_batches_tracked', 'backbone.models.0.model.layer3.4.conv3.weight', 'backbone.models.0.model.layer3.4.bn3.weight', 'backbone.models.0.model.layer3.4.bn3.bias', 'backbone.models.0.model.layer3.4.bn3.running_mean', 'backbone.models.0.model.layer3.4.bn3.running_var', 'backbone.models.0.model.layer3.4.bn3.num_batches_tracked', 'backbone.models.0.model.layer3.5.conv1.weight', 'backbone.models.0.model.layer3.5.bn1.weight', 'backbone.models.0.model.layer3.5.bn1.bias', 'backbone.models.0.model.layer3.5.bn1.running_mean', 'backbone.models.0.model.layer3.5.bn1.running_var', 'backbone.models.0.model.layer3.5.bn1.num_batches_tracked', 'backbone.models.0.model.layer3.5.conv2.weight', 'backbone.models.0.model.layer3.5.bn2.weight', 'backbone.models.0.model.layer3.5.bn2.bias', 'backbone.models.0.model.layer3.5.bn2.running_mean', 'backbone.models.0.model.layer3.5.bn2.running_var', 'backbone.models.0.model.layer3.5.bn2.num_batches_tracked', 'backbone.models.0.model.layer3.5.conv3.weight', 'backbone.models.0.model.layer3.5.bn3.weight', 'backbone.models.0.model.layer3.5.bn3.bias', 'backbone.models.0.model.layer3.5.bn3.running_mean', 'backbone.models.0.model.layer3.5.bn3.running_var', 'backbone.models.0.model.layer3.5.bn3.num_batches_tracked', 'backbone.models.0.model.layer4.0.conv1.weight', 'backbone.models.0.model.layer4.0.bn1.weight', 'backbone.models.0.model.layer4.0.bn1.bias', 'backbone.models.0.model.layer4.0.bn1.running_mean', 'backbone.models.0.model.layer4.0.bn1.running_var', 'backbone.models.0.model.layer4.0.bn1.num_batches_tracked', 'backbone.models.0.model.layer4.0.conv2.weight', 'backbone.models.0.model.layer4.0.bn2.weight', 'backbone.models.0.model.layer4.0.bn2.bias', 'backbone.models.0.model.layer4.0.bn2.running_mean', 'backbone.models.0.model.layer4.0.bn2.running_var', 'backbone.models.0.model.layer4.0.bn2.num_batches_tracked', 'backbone.models.0.model.layer4.0.conv3.weight', 'backbone.models.0.model.layer4.0.bn3.weight', 'backbone.models.0.model.layer4.0.bn3.bias', 'backbone.models.0.model.layer4.0.bn3.running_mean', 'backbone.models.0.model.layer4.0.bn3.running_var', 'backbone.models.0.model.layer4.0.bn3.num_batches_tracked', 'backbone.models.0.model.layer4.0.downsample.0.weight', 'backbone.models.0.model.layer4.0.downsample.1.weight', 'backbone.models.0.model.layer4.0.downsample.1.bias', 'backbone.models.0.model.layer4.0.downsample.1.running_mean', 'backbone.models.0.model.layer4.0.downsample.1.running_var', 'backbone.models.0.model.layer4.0.downsample.1.num_batches_tracked', 'backbone.models.0.model.layer4.1.conv1.weight', 'backbone.models.0.model.layer4.1.bn1.weight', 'backbone.models.0.model.layer4.1.bn1.bias', 'backbone.models.0.model.layer4.1.bn1.running_mean', 'backbone.models.0.model.layer4.1.bn1.running_var', 'backbone.models.0.model.layer4.1.bn1.num_batches_tracked', 'backbone.models.0.model.layer4.1.conv2.weight', 'backbone.models.0.model.layer4.1.bn2.weight', 'backbone.models.0.model.layer4.1.bn2.bias', 'backbone.models.0.model.layer4.1.bn2.running_mean', 'backbone.models.0.model.layer4.1.bn2.running_var', 'backbone.models.0.model.layer4.1.bn2.num_batches_tracked', 'backbone.models.0.model.layer4.1.conv3.weight', 'backbone.models.0.model.layer4.1.bn3.weight', 'backbone.models.0.model.layer4.1.bn3.bias', 'backbone.models.0.model.layer4.1.bn3.running_mean', 'backbone.models.0.model.layer4.1.bn3.running_var', 'backbone.models.0.model.layer4.1.bn3.num_batches_tracked', 'backbone.models.0.model.layer4.2.conv1.weight', 'backbone.models.0.model.layer4.2.bn1.weight', 'backbone.models.0.model.layer4.2.bn1.bias', 'backbone.models.0.model.layer4.2.bn1.running_mean', 'backbone.models.0.model.layer4.2.bn1.running_var', 'backbone.models.0.model.layer4.2.bn1.num_batches_tracked', 'backbone.models.0.model.layer4.2.conv2.weight', 'backbone.models.0.model.layer4.2.bn2.weight', 'backbone.models.0.model.layer4.2.bn2.bias', 'backbone.models.0.model.layer4.2.bn2.running_mean', 'backbone.models.0.model.layer4.2.bn2.running_var', 'backbone.models.0.model.layer4.2.bn2.num_batches_tracked', 'backbone.models.0.model.layer4.2.conv3.weight', 'backbone.models.0.model.layer4.2.bn3.weight', 'backbone.models.0.model.layer4.2.bn3.bias', 'backbone.models.0.model.layer4.2.bn3.running_mean', 'backbone.models.0.model.layer4.2.bn3.running_var', 'backbone.models.0.model.layer4.2.bn3.num_batches_tracked', 'backbone.models.0.model.fc.weight', 'backbone.models.0.model.fc.bias', 'backbone.classifiers.0.weight', 'backbone.classifiers.0.bias'])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"state_dict\"].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T16:28:26.657307675Z",
     "start_time": "2024-01-07T16:28:26.176445233Z"
    }
   },
   "id": "9afc5b6523d6f202",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "206211395ba64f80"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "p = Path(\"./config.yaml\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T10:09:00.919914687Z",
     "start_time": "2024-01-07T10:09:00.901363231Z"
    }
   },
   "id": "f64171053c5d71e7",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'config.png'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.with_suffix(\".png\").name"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T10:09:27.481275843Z",
     "start_time": "2024-01-07T10:09:27.223119856Z"
    }
   },
   "id": "6da5ae76c3f5a55a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7af6da3a6baf7928"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f32851808fa2db3f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n         [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n\n        [[ 100,  101,  102,  103,  104,  105,  106,  107,  108,  109],\n         [ 110,  111,  112,  113,  114,  115,  116,  117,  118,  119],\n         [ 120,  121,  122,  123,  124,  125,  126,  127,  128,  129],\n         [ 130,  131,  132,  133,  134,  135,  136,  137,  138,  139],\n         [ 140,  141,  142,  143,  144,  145,  146,  147,  148,  149],\n         [ 150,  151,  152,  153,  154,  155,  156,  157,  158,  159],\n         [ 160,  161,  162,  163,  164,  165,  166,  167,  168,  169],\n         [ 170,  171,  172,  173,  174,  175,  176,  177,  178,  179],\n         [ 180,  181,  182,  183,  184,  185,  186,  187,  188,  189],\n         [ 190,  191,  192,  193,  194,  195,  196,  197,  198,  199]],\n\n        [[ 400,  402,  404,  406,  408,  410,  412,  414,  416,  418],\n         [ 420,  422,  424,  426,  428,  430,  432,  434,  436,  438],\n         [ 440,  442,  444,  446,  448,  450,  452,  454,  456,  458],\n         [ 460,  462,  464,  466,  468,  470,  472,  474,  476,  478],\n         [ 480,  482,  484,  486,  488,  490,  492,  494,  496,  498],\n         [ 500,  502,  504,  506,  508,  510,  512,  514,  516,  518],\n         [ 520,  522,  524,  526,  528,  530,  532,  534,  536,  538],\n         [ 540,  542,  544,  546,  548,  550,  552,  554,  556,  558],\n         [ 560,  562,  564,  566,  568,  570,  572,  574,  576,  578],\n         [ 580,  582,  584,  586,  588,  590,  592,  594,  596,  598]],\n\n        [[ 900,  903,  906,  909,  912,  915,  918,  921,  924,  927],\n         [ 930,  933,  936,  939,  942,  945,  948,  951,  954,  957],\n         [ 960,  963,  966,  969,  972,  975,  978,  981,  984,  987],\n         [ 990,  993,  996,  999, 1002, 1005, 1008, 1011, 1014, 1017],\n         [1020, 1023, 1026, 1029, 1032, 1035, 1038, 1041, 1044, 1047],\n         [1050, 1053, 1056, 1059, 1062, 1065, 1068, 1071, 1074, 1077],\n         [1080, 1083, 1086, 1089, 1092, 1095, 1098, 1101, 1104, 1107],\n         [1110, 1113, 1116, 1119, 1122, 1125, 1128, 1131, 1134, 1137],\n         [1140, 1143, 1146, 1149, 1152, 1155, 1158, 1161, 1164, 1167],\n         [1170, 1173, 1176, 1179, 1182, 1185, 1188, 1191, 1194, 1197]],\n\n        [[1600, 1604, 1608, 1612, 1616, 1620, 1624, 1628, 1632, 1636],\n         [1640, 1644, 1648, 1652, 1656, 1660, 1664, 1668, 1672, 1676],\n         [1680, 1684, 1688, 1692, 1696, 1700, 1704, 1708, 1712, 1716],\n         [1720, 1724, 1728, 1732, 1736, 1740, 1744, 1748, 1752, 1756],\n         [1760, 1764, 1768, 1772, 1776, 1780, 1784, 1788, 1792, 1796],\n         [1800, 1804, 1808, 1812, 1816, 1820, 1824, 1828, 1832, 1836],\n         [1840, 1844, 1848, 1852, 1856, 1860, 1864, 1868, 1872, 1876],\n         [1880, 1884, 1888, 1892, 1896, 1900, 1904, 1908, 1912, 1916],\n         [1920, 1924, 1928, 1932, 1936, 1940, 1944, 1948, 1952, 1956],\n         [1960, 1964, 1968, 1972, 1976, 1980, 1984, 1988, 1992, 1996]],\n\n        [[2500, 2505, 2510, 2515, 2520, 2525, 2530, 2535, 2540, 2545],\n         [2550, 2555, 2560, 2565, 2570, 2575, 2580, 2585, 2590, 2595],\n         [2600, 2605, 2610, 2615, 2620, 2625, 2630, 2635, 2640, 2645],\n         [2650, 2655, 2660, 2665, 2670, 2675, 2680, 2685, 2690, 2695],\n         [2700, 2705, 2710, 2715, 2720, 2725, 2730, 2735, 2740, 2745],\n         [2750, 2755, 2760, 2765, 2770, 2775, 2780, 2785, 2790, 2795],\n         [2800, 2805, 2810, 2815, 2820, 2825, 2830, 2835, 2840, 2845],\n         [2850, 2855, 2860, 2865, 2870, 2875, 2880, 2885, 2890, 2895],\n         [2900, 2905, 2910, 2915, 2920, 2925, 2930, 2935, 2940, 2945],\n         [2950, 2955, 2960, 2965, 2970, 2975, 2980, 2985, 2990, 2995]],\n\n        [[3600, 3606, 3612, 3618, 3624, 3630, 3636, 3642, 3648, 3654],\n         [3660, 3666, 3672, 3678, 3684, 3690, 3696, 3702, 3708, 3714],\n         [3720, 3726, 3732, 3738, 3744, 3750, 3756, 3762, 3768, 3774],\n         [3780, 3786, 3792, 3798, 3804, 3810, 3816, 3822, 3828, 3834],\n         [3840, 3846, 3852, 3858, 3864, 3870, 3876, 3882, 3888, 3894],\n         [3900, 3906, 3912, 3918, 3924, 3930, 3936, 3942, 3948, 3954],\n         [3960, 3966, 3972, 3978, 3984, 3990, 3996, 4002, 4008, 4014],\n         [4020, 4026, 4032, 4038, 4044, 4050, 4056, 4062, 4068, 4074],\n         [4080, 4086, 4092, 4098, 4104, 4110, 4116, 4122, 4128, 4134],\n         [4140, 4146, 4152, 4158, 4164, 4170, 4176, 4182, 4188, 4194]],\n\n        [[4900, 4907, 4914, 4921, 4928, 4935, 4942, 4949, 4956, 4963],\n         [4970, 4977, 4984, 4991, 4998, 5005, 5012, 5019, 5026, 5033],\n         [5040, 5047, 5054, 5061, 5068, 5075, 5082, 5089, 5096, 5103],\n         [5110, 5117, 5124, 5131, 5138, 5145, 5152, 5159, 5166, 5173],\n         [5180, 5187, 5194, 5201, 5208, 5215, 5222, 5229, 5236, 5243],\n         [5250, 5257, 5264, 5271, 5278, 5285, 5292, 5299, 5306, 5313],\n         [5320, 5327, 5334, 5341, 5348, 5355, 5362, 5369, 5376, 5383],\n         [5390, 5397, 5404, 5411, 5418, 5425, 5432, 5439, 5446, 5453],\n         [5460, 5467, 5474, 5481, 5488, 5495, 5502, 5509, 5516, 5523],\n         [5530, 5537, 5544, 5551, 5558, 5565, 5572, 5579, 5586, 5593]],\n\n        [[6400, 6408, 6416, 6424, 6432, 6440, 6448, 6456, 6464, 6472],\n         [6480, 6488, 6496, 6504, 6512, 6520, 6528, 6536, 6544, 6552],\n         [6560, 6568, 6576, 6584, 6592, 6600, 6608, 6616, 6624, 6632],\n         [6640, 6648, 6656, 6664, 6672, 6680, 6688, 6696, 6704, 6712],\n         [6720, 6728, 6736, 6744, 6752, 6760, 6768, 6776, 6784, 6792],\n         [6800, 6808, 6816, 6824, 6832, 6840, 6848, 6856, 6864, 6872],\n         [6880, 6888, 6896, 6904, 6912, 6920, 6928, 6936, 6944, 6952],\n         [6960, 6968, 6976, 6984, 6992, 7000, 7008, 7016, 7024, 7032],\n         [7040, 7048, 7056, 7064, 7072, 7080, 7088, 7096, 7104, 7112],\n         [7120, 7128, 7136, 7144, 7152, 7160, 7168, 7176, 7184, 7192]],\n\n        [[8100, 8109, 8118, 8127, 8136, 8145, 8154, 8163, 8172, 8181],\n         [8190, 8199, 8208, 8217, 8226, 8235, 8244, 8253, 8262, 8271],\n         [8280, 8289, 8298, 8307, 8316, 8325, 8334, 8343, 8352, 8361],\n         [8370, 8379, 8388, 8397, 8406, 8415, 8424, 8433, 8442, 8451],\n         [8460, 8469, 8478, 8487, 8496, 8505, 8514, 8523, 8532, 8541],\n         [8550, 8559, 8568, 8577, 8586, 8595, 8604, 8613, 8622, 8631],\n         [8640, 8649, 8658, 8667, 8676, 8685, 8694, 8703, 8712, 8721],\n         [8730, 8739, 8748, 8757, 8766, 8775, 8784, 8793, 8802, 8811],\n         [8820, 8829, 8838, 8847, 8856, 8865, 8874, 8883, 8892, 8901],\n         [8910, 8919, 8928, 8937, 8946, 8955, 8964, 8973, 8982, 8991]]])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(1000).view(10, 10, 10)\n",
    "y = torch.arange(10).view(10, 1, 1)\n",
    "x * y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T07:58:51.752836225Z",
     "start_time": "2024-01-07T07:58:47.744814206Z"
    }
   },
   "id": "f13ebea21fbf1ab4",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "da39b0f583bf8e6c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"state_dict\"].keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T12:52:17.528219155Z",
     "start_time": "2024-01-06T12:52:16.957836587Z"
    }
   },
   "id": "be1227018bd1768a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "NpzFile '/home/doved/Data/Imagenet64_train/train_data_batch_1.npz' with keys: data, mean, labels"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "b = np.load(\"/home/doved/Data/Imagenet64_train/train_data_batch_1.npz\")\n",
    "b"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T07:09:13.667299362Z",
     "start_time": "2024-01-06T07:09:13.385062254Z"
    }
   },
   "id": "d7733742a3e3db8d",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img1 = b[\"data\"][10000]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T07:09:25.397918978Z",
     "start_time": "2024-01-06T07:09:14.372298625Z"
    }
   },
   "id": "5d0455341498c6f3",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7f678828a910>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:54:16.885856442Z",
     "start_time": "2024-01-06T06:54:16.148351051Z"
    }
   },
   "id": "4858a519923c4db3",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128116/128116 [01:39<00:00, 1284.70it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "labels = b[\"labels\"]\n",
    "data = b[\"data\"]\n",
    "filenames = {}\n",
    "dest = Path(\"/home/doved/Data/Imagenet64/train\")\n",
    "for i in tqdm(range(len(labels))):\n",
    "    img = data[i]\n",
    "    label = labels[i] - 1\n",
    "    if label not in filenames:\n",
    "        filenames[label] = 0\n",
    "        os.mkdir(dest/f\"{label}\")\n",
    "    p = dest/f\"{label}\"/f\"{filenames[label]}.png\"\n",
    "    filenames[label] += 1\n",
    "    torchvision.io.write_png(torch.tensor(img.reshape(3, 64, 64)), str(p))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T07:18:20.844430684Z",
     "start_time": "2024-01-06T07:16:27.380184344Z"
    }
   },
   "id": "9eab518ee9eeb727",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128116/128116 [01:46<00:00, 1207.74it/s]\n",
      "100%|██████████| 128116/128116 [01:44<00:00, 1223.03it/s]\n",
      "100%|██████████| 128116/128116 [01:41<00:00, 1257.11it/s]\n",
      "100%|██████████| 128116/128116 [01:38<00:00, 1296.85it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in range(2, 6):\n",
    "    b = np.load(f\"/home/doved/Data/Imagenet64_train/train_data_batch_{batch}.npz\")\n",
    "    labels = b[\"labels\"]\n",
    "    data = b[\"data\"]\n",
    "    dest = Path(\"/home/doved/Data/Imagenet64/train\")\n",
    "    for i in tqdm(range(len(labels))):\n",
    "        img = data[i]\n",
    "        label = labels[i] - 1\n",
    "        if label not in filenames:\n",
    "            filenames[label] = 0\n",
    "            os.mkdir(dest/f\"{label}\")\n",
    "        p = dest/f\"{label}\"/f\"{filenames[label]}.png\"\n",
    "        filenames[label] += 1\n",
    "        torchvision.io.write_png(torch.tensor(img.reshape(3, 64, 64)), str(p))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T07:26:27.918222158Z",
     "start_time": "2024-01-06T07:18:20.927484527Z"
    }
   },
   "id": "1514f975a5e98335",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:37<00:00, 1323.68it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "b = np.load(f\"/home/doved/Data/Imagenet64_val/val_data.npz\")\n",
    "labels = b[\"labels\"]\n",
    "data = b[\"data\"]\n",
    "val_filenames = {}\n",
    "dest = Path(\"/home/doved/Data/Imagenet64/val\")\n",
    "for i in tqdm(range(len(labels))):\n",
    "    img = data[i]\n",
    "    label = labels[i] - 1\n",
    "    if label not in val_filenames:\n",
    "        val_filenames[label] = 0\n",
    "        os.mkdir(dest/f\"{label}\")\n",
    "    p = dest/f\"{label}\"/f\"{val_filenames[label]}.png\"\n",
    "    val_filenames[label] += 1\n",
    "    torchvision.io.write_png(torch.tensor(img.reshape(3, 64, 64)), str(p))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T07:27:16.960765876Z",
     "start_time": "2024-01-06T07:26:27.926375060Z"
    }
   },
   "id": "abbcb83b5e80ba46",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 64, 64)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = img1.reshape(3, 64, 64)\n",
    "img1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:50:37.552964577Z",
     "start_time": "2024-01-06T06:50:37.069902976Z"
    }
   },
   "id": "e788601cb25a23ae",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(64, 64, 3)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1 = np.transpose(img1, (1, 2, 0))\n",
    "img1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:52:15.030933822Z",
     "start_time": "2024-01-06T06:52:14.669347466Z"
    }
   },
   "id": "fc3897fc60572f4f",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "img1 = np.ascontiguousarray(img1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:52:38.645485693Z",
     "start_time": "2024-01-06T06:52:38.383461634Z"
    }
   },
   "id": "84e567795fb456b3",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'abcdef'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"aaabcdef\".removeprefix(\"aa\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T08:59:22.656858134Z",
     "start_time": "2024-01-04T08:59:22.406325632Z"
    }
   },
   "id": "4f867675b48d3a69",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'123'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"123.jpeg\"[:-5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-04T10:26:29.296074458Z",
     "start_time": "2024-01-04T10:26:29.022594246Z"
    }
   },
   "id": "911fb2c57892e220",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[ 14.,  16.,  39.],\n        [ 14.,  17.,  40.],\n        [ 14.,  17.,  41.],\n        ...,\n        [ 28.,  18.,  14.],\n        [ 29.,  17.,  13.],\n        [ 25.,  15.,  11.]],\n\n       [[ 13.,  17.,  39.],\n        [ 14.,  17.,  40.],\n        [ 13.,  17.,  42.],\n        ...,\n        [ 16.,   7.,   5.],\n        [ 19.,   7.,   5.],\n        [ 11.,   4.,   3.]],\n\n       [[ 14.,  16.,  39.],\n        [ 14.,  17.,  41.],\n        [ 14.,  17.,  43.],\n        ...,\n        [ 19.,   7.,   5.],\n        [ 19.,   7.,   5.],\n        [  8.,   3.,   3.]],\n\n       ...,\n\n       [[ 16.,   5.,   3.],\n        [ 19.,   6.,   4.],\n        [ 85.,  57.,  61.],\n        ...,\n        [116.,   8.,  22.],\n        [129.,  13.,  28.],\n        [140.,  17.,  33.]],\n\n       [[ 15.,   5.,   3.],\n        [ 17.,   5.,   4.],\n        [ 25.,  12.,  13.],\n        ...,\n        [131.,  16.,  31.],\n        [123.,  13.,  26.],\n        [132.,  19.,  32.]],\n\n       [[ 15.,   4.,   3.],\n        [ 17.,   4.,   3.],\n        [ 17.,   5.,   4.],\n        ...,\n        [109.,   8.,  19.],\n        [106.,   4.,  13.],\n        [118.,   7.,  19.]]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1.astype(float)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T06:53:19.343140834Z",
     "start_time": "2024-01-06T06:53:19.041513816Z"
    }
   },
   "id": "f1d300e7c4e51e3a",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "['resnet50']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "timm.list_models(\"resnet50\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:38:41.633630500Z",
     "start_time": "2023-12-28T15:38:36.543484400Z"
    }
   },
   "id": "889b9df4bf280ee1"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "resnet50 = timm.create_model(\"resnet50\")\n",
    "efficientnet_b0 = timm.create_model(\"efficientnet_b0\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:38:42.347685500Z",
     "start_time": "2023-12-28T15:38:41.639597200Z"
    }
   },
   "id": "66aa8a3baf33ba77"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "24.373085021972656"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) / 1024 / 1024\n",
    "\n",
    "count_parameters(resnet50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:19.488872Z",
     "start_time": "2023-12-28T10:43:19.475873600Z"
    }
   },
   "id": "c38ddb077a6572d5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "5.043552398681641"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(efficientnet_b0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:19.562905400Z",
     "start_time": "2023-12-28T10:43:19.489870500Z"
    }
   },
   "id": "f17f24f07ec7178b"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(12, 3, 224, 224)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:38:42.347685500Z",
     "start_time": "2023-12-28T15:38:42.059690100Z"
    }
   },
   "id": "d55a864e50c9eb57"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "927 ms ± 19 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit resnet50(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:27.346869Z",
     "start_time": "2023-12-28T10:43:19.536869700Z"
    }
   },
   "id": "462d84c5248568d3"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "efficientnet_v2 = timm.create_model(\"efficientnetv2_s\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:27.750871500Z",
     "start_time": "2023-12-28T10:43:27.348872500Z"
    }
   },
   "id": "60928451764ed32a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "20.46440887451172"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(efficientnet_v2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:27.768882500Z",
     "start_time": "2023-12-28T10:43:27.754873300Z"
    }
   },
   "id": "de27b3a492232949"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.22 s ± 28.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit efficientnet_v2(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:37.745914Z",
     "start_time": "2023-12-28T10:43:27.770873800Z"
    }
   },
   "id": "9d54053da6f776b8"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "8.687967300415039"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "efficientnet_b2 = timm.create_model(\"efficientnet_b2\")\n",
    "count_parameters(efficientnet_b2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:37.989905100Z",
     "start_time": "2023-12-28T10:43:37.748905700Z"
    }
   },
   "id": "28328e00e90edf95"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839 ms ± 27.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit efficientnet_b2(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:44.751420800Z",
     "start_time": "2023-12-28T10:43:37.976905100Z"
    }
   },
   "id": "f3f33a50a5da8172"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:43:52.528613600Z",
     "start_time": "2023-12-28T10:43:52.497573600Z"
    }
   },
   "id": "452c0fb3bbb399f1"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "['T_destination',\n '__annotations__',\n '__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattr__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_apply',\n '_backward_hooks',\n '_backward_pre_hooks',\n '_buffers',\n '_call_impl',\n '_compiled_call_impl',\n '_forward_hooks',\n '_forward_hooks_always_called',\n '_forward_hooks_with_kwargs',\n '_forward_pre_hooks',\n '_forward_pre_hooks_with_kwargs',\n '_get_backward_hooks',\n '_get_backward_pre_hooks',\n '_get_name',\n '_is_full_backward_hook',\n '_load_from_state_dict',\n '_load_state_dict_post_hooks',\n '_load_state_dict_pre_hooks',\n '_maybe_warn_non_full_backward_hook',\n '_modules',\n '_named_members',\n '_non_persistent_buffers_set',\n '_parameters',\n '_register_load_state_dict_pre_hook',\n '_register_state_dict_hook',\n '_replicate_for_data_parallel',\n '_save_to_state_dict',\n '_slow_forward',\n '_state_dict_hooks',\n '_state_dict_pre_hooks',\n '_version',\n '_wrapped_call_impl',\n 'act1',\n 'add_module',\n 'apply',\n 'bfloat16',\n 'bn1',\n 'buffers',\n 'call_super_init',\n 'children',\n 'compile',\n 'conv1',\n 'cpu',\n 'cuda',\n 'default_cfg',\n 'double',\n 'drop_rate',\n 'dump_patches',\n 'eval',\n 'extra_repr',\n 'fc',\n 'feature_info',\n 'float',\n 'forward',\n 'forward_features',\n 'forward_head',\n 'get_buffer',\n 'get_classifier',\n 'get_extra_state',\n 'get_parameter',\n 'get_submodule',\n 'global_pool',\n 'grad_checkpointing',\n 'group_matcher',\n 'half',\n 'init_weights',\n 'ipu',\n 'layer1',\n 'layer2',\n 'layer3',\n 'layer4',\n 'load_state_dict',\n 'maxpool',\n 'modules',\n 'named_buffers',\n 'named_children',\n 'named_modules',\n 'named_parameters',\n 'num_classes',\n 'num_features',\n 'parameters',\n 'pretrained_cfg',\n 'register_backward_hook',\n 'register_buffer',\n 'register_forward_hook',\n 'register_forward_pre_hook',\n 'register_full_backward_hook',\n 'register_full_backward_pre_hook',\n 'register_load_state_dict_post_hook',\n 'register_module',\n 'register_parameter',\n 'register_state_dict_pre_hook',\n 'requires_grad_',\n 'reset_classifier',\n 'set_extra_state',\n 'set_grad_checkpointing',\n 'share_memory',\n 'state_dict',\n 'to',\n 'to_empty',\n 'train',\n 'training',\n 'type',\n 'xpu',\n 'zero_grad']"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(resnet50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T10:44:10.274677800Z",
     "start_time": "2023-12-28T10:44:10.151648900Z"
    }
   },
   "id": "86a345dfa58b7f6e"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "['conv1.weight',\n 'bn1.weight',\n 'bn1.bias',\n 'layer1.0.conv1.weight',\n 'layer1.0.bn1.weight',\n 'layer1.0.bn1.bias',\n 'layer1.0.conv2.weight',\n 'layer1.0.bn2.weight',\n 'layer1.0.bn2.bias',\n 'layer1.0.conv3.weight',\n 'layer1.0.bn3.weight',\n 'layer1.0.bn3.bias',\n 'layer1.0.downsample.0.weight',\n 'layer1.0.downsample.1.weight',\n 'layer1.0.downsample.1.bias',\n 'layer1.1.conv1.weight',\n 'layer1.1.bn1.weight',\n 'layer1.1.bn1.bias',\n 'layer1.1.conv2.weight',\n 'layer1.1.bn2.weight',\n 'layer1.1.bn2.bias',\n 'layer1.1.conv3.weight',\n 'layer1.1.bn3.weight',\n 'layer1.1.bn3.bias',\n 'layer1.2.conv1.weight',\n 'layer1.2.bn1.weight',\n 'layer1.2.bn1.bias',\n 'layer1.2.conv2.weight',\n 'layer1.2.bn2.weight',\n 'layer1.2.bn2.bias',\n 'layer1.2.conv3.weight',\n 'layer1.2.bn3.weight',\n 'layer1.2.bn3.bias',\n 'layer2.0.conv1.weight',\n 'layer2.0.bn1.weight',\n 'layer2.0.bn1.bias',\n 'layer2.0.conv2.weight',\n 'layer2.0.bn2.weight',\n 'layer2.0.bn2.bias',\n 'layer2.0.conv3.weight',\n 'layer2.0.bn3.weight',\n 'layer2.0.bn3.bias',\n 'layer2.0.downsample.0.weight',\n 'layer2.0.downsample.1.weight',\n 'layer2.0.downsample.1.bias',\n 'layer2.1.conv1.weight',\n 'layer2.1.bn1.weight',\n 'layer2.1.bn1.bias',\n 'layer2.1.conv2.weight',\n 'layer2.1.bn2.weight',\n 'layer2.1.bn2.bias',\n 'layer2.1.conv3.weight',\n 'layer2.1.bn3.weight',\n 'layer2.1.bn3.bias',\n 'layer2.2.conv1.weight',\n 'layer2.2.bn1.weight',\n 'layer2.2.bn1.bias',\n 'layer2.2.conv2.weight',\n 'layer2.2.bn2.weight',\n 'layer2.2.bn2.bias',\n 'layer2.2.conv3.weight',\n 'layer2.2.bn3.weight',\n 'layer2.2.bn3.bias',\n 'layer2.3.conv1.weight',\n 'layer2.3.bn1.weight',\n 'layer2.3.bn1.bias',\n 'layer2.3.conv2.weight',\n 'layer2.3.bn2.weight',\n 'layer2.3.bn2.bias',\n 'layer2.3.conv3.weight',\n 'layer2.3.bn3.weight',\n 'layer2.3.bn3.bias',\n 'layer3.0.conv1.weight',\n 'layer3.0.bn1.weight',\n 'layer3.0.bn1.bias',\n 'layer3.0.conv2.weight',\n 'layer3.0.bn2.weight',\n 'layer3.0.bn2.bias',\n 'layer3.0.conv3.weight',\n 'layer3.0.bn3.weight',\n 'layer3.0.bn3.bias',\n 'layer3.0.downsample.0.weight',\n 'layer3.0.downsample.1.weight',\n 'layer3.0.downsample.1.bias',\n 'layer3.1.conv1.weight',\n 'layer3.1.bn1.weight',\n 'layer3.1.bn1.bias',\n 'layer3.1.conv2.weight',\n 'layer3.1.bn2.weight',\n 'layer3.1.bn2.bias',\n 'layer3.1.conv3.weight',\n 'layer3.1.bn3.weight',\n 'layer3.1.bn3.bias',\n 'layer3.2.conv1.weight',\n 'layer3.2.bn1.weight',\n 'layer3.2.bn1.bias',\n 'layer3.2.conv2.weight',\n 'layer3.2.bn2.weight',\n 'layer3.2.bn2.bias',\n 'layer3.2.conv3.weight',\n 'layer3.2.bn3.weight',\n 'layer3.2.bn3.bias',\n 'layer3.3.conv1.weight',\n 'layer3.3.bn1.weight',\n 'layer3.3.bn1.bias',\n 'layer3.3.conv2.weight',\n 'layer3.3.bn2.weight',\n 'layer3.3.bn2.bias',\n 'layer3.3.conv3.weight',\n 'layer3.3.bn3.weight',\n 'layer3.3.bn3.bias',\n 'layer3.4.conv1.weight',\n 'layer3.4.bn1.weight',\n 'layer3.4.bn1.bias',\n 'layer3.4.conv2.weight',\n 'layer3.4.bn2.weight',\n 'layer3.4.bn2.bias',\n 'layer3.4.conv3.weight',\n 'layer3.4.bn3.weight',\n 'layer3.4.bn3.bias',\n 'layer3.5.conv1.weight',\n 'layer3.5.bn1.weight',\n 'layer3.5.bn1.bias',\n 'layer3.5.conv2.weight',\n 'layer3.5.bn2.weight',\n 'layer3.5.bn2.bias',\n 'layer3.5.conv3.weight',\n 'layer3.5.bn3.weight',\n 'layer3.5.bn3.bias',\n 'layer4.0.conv1.weight',\n 'layer4.0.bn1.weight',\n 'layer4.0.bn1.bias',\n 'layer4.0.conv2.weight',\n 'layer4.0.bn2.weight',\n 'layer4.0.bn2.bias',\n 'layer4.0.conv3.weight',\n 'layer4.0.bn3.weight',\n 'layer4.0.bn3.bias',\n 'layer4.0.downsample.0.weight',\n 'layer4.0.downsample.1.weight',\n 'layer4.0.downsample.1.bias',\n 'layer4.1.conv1.weight',\n 'layer4.1.bn1.weight',\n 'layer4.1.bn1.bias',\n 'layer4.1.conv2.weight',\n 'layer4.1.bn2.weight',\n 'layer4.1.bn2.bias',\n 'layer4.1.conv3.weight',\n 'layer4.1.bn3.weight',\n 'layer4.1.bn3.bias',\n 'layer4.2.conv1.weight',\n 'layer4.2.bn1.weight',\n 'layer4.2.bn1.bias',\n 'layer4.2.conv2.weight',\n 'layer4.2.bn2.weight',\n 'layer4.2.bn2.bias',\n 'layer4.2.conv3.weight',\n 'layer4.2.bn3.weight',\n 'layer4.2.bn3.bias',\n 'fc.weight',\n 'fc.bias']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x[0] for x in resnet50.named_parameters()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T11:04:18.949743400Z",
     "start_time": "2023-12-28T11:04:18.827744600Z"
    }
   },
   "id": "bc2688a6216df11c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "['H',\n 'T',\n '__abs__',\n '__add__',\n '__and__',\n '__array__',\n '__array_priority__',\n '__array_wrap__',\n '__bool__',\n '__class__',\n '__complex__',\n '__contains__',\n '__deepcopy__',\n '__delattr__',\n '__delitem__',\n '__dict__',\n '__dir__',\n '__div__',\n '__dlpack__',\n '__dlpack_device__',\n '__doc__',\n '__eq__',\n '__float__',\n '__floordiv__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__iand__',\n '__idiv__',\n '__ifloordiv__',\n '__ilshift__',\n '__imod__',\n '__imul__',\n '__index__',\n '__init__',\n '__init_subclass__',\n '__int__',\n '__invert__',\n '__ior__',\n '__ipow__',\n '__irshift__',\n '__isub__',\n '__iter__',\n '__itruediv__',\n '__ixor__',\n '__le__',\n '__len__',\n '__long__',\n '__lshift__',\n '__lt__',\n '__matmul__',\n '__mod__',\n '__module__',\n '__mul__',\n '__ne__',\n '__neg__',\n '__new__',\n '__nonzero__',\n '__or__',\n '__pos__',\n '__pow__',\n '__radd__',\n '__rand__',\n '__rdiv__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rfloordiv__',\n '__rlshift__',\n '__rmatmul__',\n '__rmod__',\n '__rmul__',\n '__ror__',\n '__rpow__',\n '__rrshift__',\n '__rshift__',\n '__rsub__',\n '__rtruediv__',\n '__rxor__',\n '__setattr__',\n '__setitem__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__sub__',\n '__subclasshook__',\n '__torch_dispatch__',\n '__torch_function__',\n '__truediv__',\n '__weakref__',\n '__xor__',\n '_addmm_activation',\n '_autocast_to_full_precision',\n '_autocast_to_reduced_precision',\n '_backward_hooks',\n '_base',\n '_cdata',\n '_coalesced_',\n '_conj',\n '_conj_physical',\n '_dimI',\n '_dimV',\n '_fix_weakref',\n '_grad',\n '_grad_fn',\n '_has_symbolic_sizes_strides',\n '_indices',\n '_is_all_true',\n '_is_any_true',\n '_is_view',\n '_is_zerotensor',\n '_make_subclass',\n '_make_wrapper_subclass',\n '_neg_view',\n '_nested_tensor_size',\n '_nested_tensor_storage_offsets',\n '_nested_tensor_strides',\n '_nnz',\n '_post_accumulate_grad_hooks',\n '_python_dispatch',\n '_reduce_ex_internal',\n '_sparse_mask_projection',\n '_to_dense',\n '_to_sparse',\n '_to_sparse_bsc',\n '_to_sparse_bsr',\n '_to_sparse_csc',\n '_to_sparse_csr',\n '_typed_storage',\n '_update_names',\n '_values',\n '_version',\n '_view_func',\n 'abs',\n 'abs_',\n 'absolute',\n 'absolute_',\n 'acos',\n 'acos_',\n 'acosh',\n 'acosh_',\n 'add',\n 'add_',\n 'addbmm',\n 'addbmm_',\n 'addcdiv',\n 'addcdiv_',\n 'addcmul',\n 'addcmul_',\n 'addmm',\n 'addmm_',\n 'addmv',\n 'addmv_',\n 'addr',\n 'addr_',\n 'adjoint',\n 'align_as',\n 'align_to',\n 'all',\n 'allclose',\n 'amax',\n 'amin',\n 'aminmax',\n 'angle',\n 'any',\n 'apply_',\n 'arccos',\n 'arccos_',\n 'arccosh',\n 'arccosh_',\n 'arcsin',\n 'arcsin_',\n 'arcsinh',\n 'arcsinh_',\n 'arctan',\n 'arctan2',\n 'arctan2_',\n 'arctan_',\n 'arctanh',\n 'arctanh_',\n 'argmax',\n 'argmin',\n 'argsort',\n 'argwhere',\n 'as_strided',\n 'as_strided_',\n 'as_strided_scatter',\n 'as_subclass',\n 'asin',\n 'asin_',\n 'asinh',\n 'asinh_',\n 'atan',\n 'atan2',\n 'atan2_',\n 'atan_',\n 'atanh',\n 'atanh_',\n 'backward',\n 'baddbmm',\n 'baddbmm_',\n 'bernoulli',\n 'bernoulli_',\n 'bfloat16',\n 'bincount',\n 'bitwise_and',\n 'bitwise_and_',\n 'bitwise_left_shift',\n 'bitwise_left_shift_',\n 'bitwise_not',\n 'bitwise_not_',\n 'bitwise_or',\n 'bitwise_or_',\n 'bitwise_right_shift',\n 'bitwise_right_shift_',\n 'bitwise_xor',\n 'bitwise_xor_',\n 'bmm',\n 'bool',\n 'broadcast_to',\n 'byte',\n 'cauchy_',\n 'ccol_indices',\n 'cdouble',\n 'ceil',\n 'ceil_',\n 'cfloat',\n 'chalf',\n 'char',\n 'cholesky',\n 'cholesky_inverse',\n 'cholesky_solve',\n 'chunk',\n 'clamp',\n 'clamp_',\n 'clamp_max',\n 'clamp_max_',\n 'clamp_min',\n 'clamp_min_',\n 'clip',\n 'clip_',\n 'clone',\n 'coalesce',\n 'col_indices',\n 'conj',\n 'conj_physical',\n 'conj_physical_',\n 'contiguous',\n 'copy_',\n 'copysign',\n 'copysign_',\n 'corrcoef',\n 'cos',\n 'cos_',\n 'cosh',\n 'cosh_',\n 'count_nonzero',\n 'cov',\n 'cpu',\n 'cross',\n 'crow_indices',\n 'cuda',\n 'cummax',\n 'cummin',\n 'cumprod',\n 'cumprod_',\n 'cumsum',\n 'cumsum_',\n 'data',\n 'data_ptr',\n 'deg2rad',\n 'deg2rad_',\n 'dense_dim',\n 'dequantize',\n 'det',\n 'detach',\n 'detach_',\n 'device',\n 'diag',\n 'diag_embed',\n 'diagflat',\n 'diagonal',\n 'diagonal_scatter',\n 'diff',\n 'digamma',\n 'digamma_',\n 'dim',\n 'dim_order',\n 'dist',\n 'div',\n 'div_',\n 'divide',\n 'divide_',\n 'dot',\n 'double',\n 'dsplit',\n 'dtype',\n 'eig',\n 'element_size',\n 'eq',\n 'eq_',\n 'equal',\n 'erf',\n 'erf_',\n 'erfc',\n 'erfc_',\n 'erfinv',\n 'erfinv_',\n 'exp',\n 'exp2',\n 'exp2_',\n 'exp_',\n 'expand',\n 'expand_as',\n 'expm1',\n 'expm1_',\n 'exponential_',\n 'fill_',\n 'fill_diagonal_',\n 'fix',\n 'fix_',\n 'flatten',\n 'flip',\n 'fliplr',\n 'flipud',\n 'float',\n 'float_power',\n 'float_power_',\n 'floor',\n 'floor_',\n 'floor_divide',\n 'floor_divide_',\n 'fmax',\n 'fmin',\n 'fmod',\n 'fmod_',\n 'frac',\n 'frac_',\n 'frexp',\n 'gather',\n 'gcd',\n 'gcd_',\n 'ge',\n 'ge_',\n 'geometric_',\n 'geqrf',\n 'ger',\n 'get_device',\n 'grad',\n 'grad_fn',\n 'greater',\n 'greater_',\n 'greater_equal',\n 'greater_equal_',\n 'gt',\n 'gt_',\n 'half',\n 'hardshrink',\n 'has_names',\n 'heaviside',\n 'heaviside_',\n 'histc',\n 'histogram',\n 'hsplit',\n 'hypot',\n 'hypot_',\n 'i0',\n 'i0_',\n 'igamma',\n 'igamma_',\n 'igammac',\n 'igammac_',\n 'imag',\n 'index_add',\n 'index_add_',\n 'index_copy',\n 'index_copy_',\n 'index_fill',\n 'index_fill_',\n 'index_put',\n 'index_put_',\n 'index_reduce',\n 'index_reduce_',\n 'index_select',\n 'indices',\n 'inner',\n 'int',\n 'int_repr',\n 'inverse',\n 'ipu',\n 'is_coalesced',\n 'is_complex',\n 'is_conj',\n 'is_contiguous',\n 'is_cpu',\n 'is_cuda',\n 'is_distributed',\n 'is_floating_point',\n 'is_inference',\n 'is_ipu',\n 'is_leaf',\n 'is_meta',\n 'is_mkldnn',\n 'is_mps',\n 'is_neg',\n 'is_nested',\n 'is_nonzero',\n 'is_ort',\n 'is_pinned',\n 'is_quantized',\n 'is_same_size',\n 'is_set_to',\n 'is_shared',\n 'is_signed',\n 'is_sparse',\n 'is_sparse_csr',\n 'is_vulkan',\n 'is_xla',\n 'is_xpu',\n 'isclose',\n 'isfinite',\n 'isinf',\n 'isnan',\n 'isneginf',\n 'isposinf',\n 'isreal',\n 'istft',\n 'item',\n 'itemsize',\n 'kron',\n 'kthvalue',\n 'layout',\n 'lcm',\n 'lcm_',\n 'ldexp',\n 'ldexp_',\n 'le',\n 'le_',\n 'lerp',\n 'lerp_',\n 'less',\n 'less_',\n 'less_equal',\n 'less_equal_',\n 'lgamma',\n 'lgamma_',\n 'log',\n 'log10',\n 'log10_',\n 'log1p',\n 'log1p_',\n 'log2',\n 'log2_',\n 'log_',\n 'log_normal_',\n 'log_softmax',\n 'logaddexp',\n 'logaddexp2',\n 'logcumsumexp',\n 'logdet',\n 'logical_and',\n 'logical_and_',\n 'logical_not',\n 'logical_not_',\n 'logical_or',\n 'logical_or_',\n 'logical_xor',\n 'logical_xor_',\n 'logit',\n 'logit_',\n 'logsumexp',\n 'long',\n 'lstsq',\n 'lt',\n 'lt_',\n 'lu',\n 'lu_solve',\n 'mH',\n 'mT',\n 'map2_',\n 'map_',\n 'masked_fill',\n 'masked_fill_',\n 'masked_scatter',\n 'masked_scatter_',\n 'masked_select',\n 'matmul',\n 'matrix_exp',\n 'matrix_power',\n 'max',\n 'maximum',\n 'mean',\n 'median',\n 'min',\n 'minimum',\n 'mm',\n 'mode',\n 'moveaxis',\n 'movedim',\n 'msort',\n 'mul',\n 'mul_',\n 'multinomial',\n 'multiply',\n 'multiply_',\n 'mv',\n 'mvlgamma',\n 'mvlgamma_',\n 'name',\n 'names',\n 'nan_to_num',\n 'nan_to_num_',\n 'nanmean',\n 'nanmedian',\n 'nanquantile',\n 'nansum',\n 'narrow',\n 'narrow_copy',\n 'nbytes',\n 'ndim',\n 'ndimension',\n 'ne',\n 'ne_',\n 'neg',\n 'neg_',\n 'negative',\n 'negative_',\n 'nelement',\n 'new',\n 'new_empty',\n 'new_empty_strided',\n 'new_full',\n 'new_ones',\n 'new_tensor',\n 'new_zeros',\n 'nextafter',\n 'nextafter_',\n 'nonzero',\n 'nonzero_static',\n 'norm',\n 'normal_',\n 'not_equal',\n 'not_equal_',\n 'numel',\n 'numpy',\n 'orgqr',\n 'ormqr',\n 'outer',\n 'output_nr',\n 'permute',\n 'pin_memory',\n 'pinverse',\n 'polygamma',\n 'polygamma_',\n 'positive',\n 'pow',\n 'pow_',\n 'prelu',\n 'prod',\n 'put',\n 'put_',\n 'q_per_channel_axis',\n 'q_per_channel_scales',\n 'q_per_channel_zero_points',\n 'q_scale',\n 'q_zero_point',\n 'qr',\n 'qscheme',\n 'quantile',\n 'rad2deg',\n 'rad2deg_',\n 'random_',\n 'ravel',\n 'real',\n 'reciprocal',\n 'reciprocal_',\n 'record_stream',\n 'refine_names',\n 'register_hook',\n 'register_post_accumulate_grad_hook',\n 'reinforce',\n 'relu',\n 'relu_',\n 'remainder',\n 'remainder_',\n 'rename',\n 'rename_',\n 'renorm',\n 'renorm_',\n 'repeat',\n 'repeat_interleave',\n 'requires_grad',\n 'requires_grad_',\n 'reshape',\n 'reshape_as',\n 'resize',\n 'resize_',\n 'resize_as',\n 'resize_as_',\n 'resize_as_sparse_',\n 'resolve_conj',\n 'resolve_neg',\n 'retain_grad',\n 'retains_grad',\n 'roll',\n 'rot90',\n 'round',\n 'round_',\n 'row_indices',\n 'rsqrt',\n 'rsqrt_',\n 'scatter',\n 'scatter_',\n 'scatter_add',\n 'scatter_add_',\n 'scatter_reduce',\n 'scatter_reduce_',\n 'select',\n 'select_scatter',\n 'set_',\n 'sgn',\n 'sgn_',\n 'shape',\n 'share_memory_',\n 'short',\n 'sigmoid',\n 'sigmoid_',\n 'sign',\n 'sign_',\n 'signbit',\n 'sin',\n 'sin_',\n 'sinc',\n 'sinc_',\n 'sinh',\n 'sinh_',\n 'size',\n 'slice_scatter',\n 'slogdet',\n 'smm',\n 'softmax',\n 'solve',\n 'sort',\n 'sparse_dim',\n 'sparse_mask',\n 'sparse_resize_',\n 'sparse_resize_and_clear_',\n 'split',\n 'split_with_sizes',\n 'sqrt',\n 'sqrt_',\n 'square',\n 'square_',\n 'squeeze',\n 'squeeze_',\n 'sspaddmm',\n 'std',\n 'stft',\n 'storage',\n 'storage_offset',\n 'storage_type',\n 'stride',\n 'sub',\n 'sub_',\n 'subtract',\n 'subtract_',\n 'sum',\n 'sum_to_size',\n 'svd',\n 'swapaxes',\n 'swapaxes_',\n 'swapdims',\n 'swapdims_',\n 'symeig',\n 't',\n 't_',\n 'take',\n 'take_along_dim',\n 'tan',\n 'tan_',\n 'tanh',\n 'tanh_',\n 'tensor_split',\n 'tile',\n 'to',\n 'to_dense',\n 'to_mkldnn',\n 'to_padded_tensor',\n 'to_sparse',\n 'to_sparse_bsc',\n 'to_sparse_bsr',\n 'to_sparse_coo',\n 'to_sparse_csc',\n 'to_sparse_csr',\n 'tolist',\n 'topk',\n 'trace',\n 'transpose',\n 'transpose_',\n 'triangular_solve',\n 'tril',\n 'tril_',\n 'triu',\n 'triu_',\n 'true_divide',\n 'true_divide_',\n 'trunc',\n 'trunc_',\n 'type',\n 'type_as',\n 'unbind',\n 'unflatten',\n 'unfold',\n 'uniform_',\n 'unique',\n 'unique_consecutive',\n 'unsafe_chunk',\n 'unsafe_split',\n 'unsafe_split_with_sizes',\n 'unsqueeze',\n 'unsqueeze_',\n 'untyped_storage',\n 'values',\n 'var',\n 'vdot',\n 'view',\n 'view_as',\n 'vsplit',\n 'where',\n 'xlogy',\n 'xlogy_',\n 'xpu',\n 'zero_']"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(next(resnet50.named_parameters())[1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T11:05:54.236405500Z",
     "start_time": "2023-12-28T11:05:54.006430900Z"
    }
   },
   "id": "f2c3e1b5b834317"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([5, 10])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn((10, 10))\n",
    "a[:5].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T18:05:34.980586Z",
     "start_time": "2023-12-28T18:05:33.924508200Z"
    }
   },
   "id": "bcdfa5eeb76ae993"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12, 2048, 7, 7])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = resnet50.forward_features(x)\n",
    "x1.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:14:09.087456Z",
     "start_time": "2023-12-28T13:14:07.941931200Z"
    }
   },
   "id": "75abe02f8fe1eced"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12, 2048])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.global_pool(x1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:14:15.630462800Z",
     "start_time": "2023-12-28T13:14:15.394465400Z"
    }
   },
   "id": "d0e6cf75fc0b1f41"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "2048"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.num_features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:15:37.774278300Z",
     "start_time": "2023-12-28T13:15:37.666562600Z"
    }
   },
   "id": "2b0678883d27eb7b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['conv1.weight',\n 'bn1.weight',\n 'bn1.bias',\n 'layer1.0.conv1.weight',\n 'layer1.0.bn1.weight',\n 'layer1.0.bn1.bias',\n 'layer1.0.conv2.weight',\n 'layer1.0.bn2.weight',\n 'layer1.0.bn2.bias',\n 'layer1.0.conv3.weight',\n 'layer1.0.bn3.weight',\n 'layer1.0.bn3.bias',\n 'layer1.0.downsample.0.weight',\n 'layer1.0.downsample.1.weight',\n 'layer1.0.downsample.1.bias',\n 'layer1.1.conv1.weight',\n 'layer1.1.bn1.weight',\n 'layer1.1.bn1.bias',\n 'layer1.1.conv2.weight',\n 'layer1.1.bn2.weight',\n 'layer1.1.bn2.bias',\n 'layer1.1.conv3.weight',\n 'layer1.1.bn3.weight',\n 'layer1.1.bn3.bias',\n 'layer1.2.conv1.weight',\n 'layer1.2.bn1.weight',\n 'layer1.2.bn1.bias',\n 'layer1.2.conv2.weight',\n 'layer1.2.bn2.weight',\n 'layer1.2.bn2.bias',\n 'layer1.2.conv3.weight',\n 'layer1.2.bn3.weight',\n 'layer1.2.bn3.bias',\n 'layer2.0.conv1.weight',\n 'layer2.0.bn1.weight',\n 'layer2.0.bn1.bias',\n 'layer2.0.conv2.weight',\n 'layer2.0.bn2.weight',\n 'layer2.0.bn2.bias',\n 'layer2.0.conv3.weight',\n 'layer2.0.bn3.weight',\n 'layer2.0.bn3.bias',\n 'layer2.0.downsample.0.weight',\n 'layer2.0.downsample.1.weight',\n 'layer2.0.downsample.1.bias',\n 'layer2.1.conv1.weight',\n 'layer2.1.bn1.weight',\n 'layer2.1.bn1.bias',\n 'layer2.1.conv2.weight',\n 'layer2.1.bn2.weight',\n 'layer2.1.bn2.bias',\n 'layer2.1.conv3.weight',\n 'layer2.1.bn3.weight',\n 'layer2.1.bn3.bias',\n 'layer2.2.conv1.weight',\n 'layer2.2.bn1.weight',\n 'layer2.2.bn1.bias',\n 'layer2.2.conv2.weight',\n 'layer2.2.bn2.weight',\n 'layer2.2.bn2.bias',\n 'layer2.2.conv3.weight',\n 'layer2.2.bn3.weight',\n 'layer2.2.bn3.bias',\n 'layer2.3.conv1.weight',\n 'layer2.3.bn1.weight',\n 'layer2.3.bn1.bias',\n 'layer2.3.conv2.weight',\n 'layer2.3.bn2.weight',\n 'layer2.3.bn2.bias',\n 'layer2.3.conv3.weight',\n 'layer2.3.bn3.weight',\n 'layer2.3.bn3.bias',\n 'layer3.0.conv1.weight',\n 'layer3.0.bn1.weight',\n 'layer3.0.bn1.bias',\n 'layer3.0.conv2.weight',\n 'layer3.0.bn2.weight',\n 'layer3.0.bn2.bias',\n 'layer3.0.conv3.weight',\n 'layer3.0.bn3.weight',\n 'layer3.0.bn3.bias',\n 'layer3.0.downsample.0.weight',\n 'layer3.0.downsample.1.weight',\n 'layer3.0.downsample.1.bias',\n 'layer3.1.conv1.weight',\n 'layer3.1.bn1.weight',\n 'layer3.1.bn1.bias',\n 'layer3.1.conv2.weight',\n 'layer3.1.bn2.weight',\n 'layer3.1.bn2.bias',\n 'layer3.1.conv3.weight',\n 'layer3.1.bn3.weight',\n 'layer3.1.bn3.bias',\n 'layer3.2.conv1.weight',\n 'layer3.2.bn1.weight',\n 'layer3.2.bn1.bias',\n 'layer3.2.conv2.weight',\n 'layer3.2.bn2.weight',\n 'layer3.2.bn2.bias',\n 'layer3.2.conv3.weight',\n 'layer3.2.bn3.weight',\n 'layer3.2.bn3.bias',\n 'layer3.3.conv1.weight',\n 'layer3.3.bn1.weight',\n 'layer3.3.bn1.bias',\n 'layer3.3.conv2.weight',\n 'layer3.3.bn2.weight',\n 'layer3.3.bn2.bias',\n 'layer3.3.conv3.weight',\n 'layer3.3.bn3.weight',\n 'layer3.3.bn3.bias',\n 'layer3.4.conv1.weight',\n 'layer3.4.bn1.weight',\n 'layer3.4.bn1.bias',\n 'layer3.4.conv2.weight',\n 'layer3.4.bn2.weight',\n 'layer3.4.bn2.bias',\n 'layer3.4.conv3.weight',\n 'layer3.4.bn3.weight',\n 'layer3.4.bn3.bias',\n 'layer3.5.conv1.weight',\n 'layer3.5.bn1.weight',\n 'layer3.5.bn1.bias',\n 'layer3.5.conv2.weight',\n 'layer3.5.bn2.weight',\n 'layer3.5.bn2.bias',\n 'layer3.5.conv3.weight',\n 'layer3.5.bn3.weight',\n 'layer3.5.bn3.bias',\n 'layer4.0.conv1.weight',\n 'layer4.0.bn1.weight',\n 'layer4.0.bn1.bias',\n 'layer4.0.conv2.weight',\n 'layer4.0.bn2.weight',\n 'layer4.0.bn2.bias',\n 'layer4.0.conv3.weight',\n 'layer4.0.bn3.weight',\n 'layer4.0.bn3.bias',\n 'layer4.0.downsample.0.weight',\n 'layer4.0.downsample.1.weight',\n 'layer4.0.downsample.1.bias',\n 'layer4.1.conv1.weight',\n 'layer4.1.bn1.weight',\n 'layer4.1.bn1.bias',\n 'layer4.1.conv2.weight',\n 'layer4.1.bn2.weight',\n 'layer4.1.bn2.bias',\n 'layer4.1.conv3.weight',\n 'layer4.1.bn3.weight',\n 'layer4.1.bn3.bias',\n 'layer4.2.conv1.weight',\n 'layer4.2.bn1.weight',\n 'layer4.2.bn1.bias',\n 'layer4.2.conv2.weight',\n 'layer4.2.bn2.weight',\n 'layer4.2.bn2.bias',\n 'layer4.2.conv3.weight',\n 'layer4.2.bn3.weight',\n 'layer4.2.bn3.bias',\n 'fc.weight',\n 'fc.bias']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m, k in resnet50.named_parameters()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T14:31:39.288373100Z",
     "start_time": "2023-12-28T14:31:38.837268300Z"
    }
   },
   "id": "3585eabc1e883d38"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "[('',\n  ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n  )),\n ('conv1',\n  Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)),\n ('bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('act1', ReLU(inplace=True)),\n ('maxpool',\n  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)),\n ('layer1',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer1.0',\n  Bottleneck(\n    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer1.0.conv1',\n  Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.act1', ReLU(inplace=True)),\n ('layer1.0.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.0.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.drop_block', Identity()),\n ('layer1.0.act2', ReLU(inplace=True)),\n ('layer1.0.aa', Identity()),\n ('layer1.0.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.act3', ReLU(inplace=True)),\n ('layer1.0.downsample',\n  Sequential(\n    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer1.0.downsample.0',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.downsample.1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1',\n  Bottleneck(\n    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer1.1.conv1',\n  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.1.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.act1', ReLU(inplace=True)),\n ('layer1.1.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.1.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.drop_block', Identity()),\n ('layer1.1.act2', ReLU(inplace=True)),\n ('layer1.1.aa', Identity()),\n ('layer1.1.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.1.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.act3', ReLU(inplace=True)),\n ('layer1.2',\n  Bottleneck(\n    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer1.2.conv1',\n  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.2.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.act1', ReLU(inplace=True)),\n ('layer1.2.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.2.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.drop_block', Identity()),\n ('layer1.2.act2', ReLU(inplace=True)),\n ('layer1.2.aa', Identity()),\n ('layer1.2.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.2.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.act3', ReLU(inplace=True)),\n ('layer2',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer2.0',\n  Bottleneck(\n    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer2.0.conv1',\n  Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.0.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.act1', ReLU(inplace=True)),\n ('layer2.0.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer2.0.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.drop_block', Identity()),\n ('layer2.0.act2', ReLU(inplace=True)),\n ('layer2.0.aa', Identity()),\n ('layer2.0.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.0.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.act3', ReLU(inplace=True)),\n ('layer2.0.downsample',\n  Sequential(\n    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer2.0.downsample.0',\n  Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer2.0.downsample.1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.1.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.1.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.act1', ReLU(inplace=True)),\n ('layer2.1.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.1.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.drop_block', Identity()),\n ('layer2.1.act2', ReLU(inplace=True)),\n ('layer2.1.aa', Identity()),\n ('layer2.1.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.1.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.act3', ReLU(inplace=True)),\n ('layer2.2',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.2.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.2.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.act1', ReLU(inplace=True)),\n ('layer2.2.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.2.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.drop_block', Identity()),\n ('layer2.2.act2', ReLU(inplace=True)),\n ('layer2.2.aa', Identity()),\n ('layer2.2.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.2.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.act3', ReLU(inplace=True)),\n ('layer2.3',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.3.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.3.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.act1', ReLU(inplace=True)),\n ('layer2.3.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.3.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.drop_block', Identity()),\n ('layer2.3.act2', ReLU(inplace=True)),\n ('layer2.3.aa', Identity()),\n ('layer2.3.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.3.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.act3', ReLU(inplace=True)),\n ('layer3',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer3.0',\n  Bottleneck(\n    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer3.0.conv1',\n  Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.0.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.act1', ReLU(inplace=True)),\n ('layer3.0.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer3.0.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.drop_block', Identity()),\n ('layer3.0.act2', ReLU(inplace=True)),\n ('layer3.0.aa', Identity()),\n ('layer3.0.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.0.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.act3', ReLU(inplace=True)),\n ('layer3.0.downsample',\n  Sequential(\n    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer3.0.downsample.0',\n  Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer3.0.downsample.1',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.1.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.1.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.act1', ReLU(inplace=True)),\n ('layer3.1.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.1.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.drop_block', Identity()),\n ('layer3.1.act2', ReLU(inplace=True)),\n ('layer3.1.aa', Identity()),\n ('layer3.1.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.1.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.act3', ReLU(inplace=True)),\n ('layer3.2',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.2.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.2.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.act1', ReLU(inplace=True)),\n ('layer3.2.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.2.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.drop_block', Identity()),\n ('layer3.2.act2', ReLU(inplace=True)),\n ('layer3.2.aa', Identity()),\n ('layer3.2.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.2.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.act3', ReLU(inplace=True)),\n ('layer3.3',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.3.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.3.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.act1', ReLU(inplace=True)),\n ('layer3.3.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.3.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.drop_block', Identity()),\n ('layer3.3.act2', ReLU(inplace=True)),\n ('layer3.3.aa', Identity()),\n ('layer3.3.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.3.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.act3', ReLU(inplace=True)),\n ('layer3.4',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.4.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.4.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.act1', ReLU(inplace=True)),\n ('layer3.4.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.4.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.drop_block', Identity()),\n ('layer3.4.act2', ReLU(inplace=True)),\n ('layer3.4.aa', Identity()),\n ('layer3.4.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.4.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.act3', ReLU(inplace=True)),\n ('layer3.5',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.5.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.5.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.act1', ReLU(inplace=True)),\n ('layer3.5.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.5.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.drop_block', Identity()),\n ('layer3.5.act2', ReLU(inplace=True)),\n ('layer3.5.aa', Identity()),\n ('layer3.5.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.5.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.act3', ReLU(inplace=True)),\n ('layer4',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer4.0',\n  Bottleneck(\n    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer4.0.conv1',\n  Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.0.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.act1', ReLU(inplace=True)),\n ('layer4.0.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer4.0.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.drop_block', Identity()),\n ('layer4.0.act2', ReLU(inplace=True)),\n ('layer4.0.aa', Identity()),\n ('layer4.0.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.0.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.act3', ReLU(inplace=True)),\n ('layer4.0.downsample',\n  Sequential(\n    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer4.0.downsample.0',\n  Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer4.0.downsample.1',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1',\n  Bottleneck(\n    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer4.1.conv1',\n  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.1.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.act1', ReLU(inplace=True)),\n ('layer4.1.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer4.1.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.drop_block', Identity()),\n ('layer4.1.act2', ReLU(inplace=True)),\n ('layer4.1.aa', Identity()),\n ('layer4.1.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.1.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.act3', ReLU(inplace=True)),\n ('layer4.2',\n  Bottleneck(\n    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer4.2.conv1',\n  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.2.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.act1', ReLU(inplace=True)),\n ('layer4.2.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer4.2.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.drop_block', Identity()),\n ('layer4.2.act2', ReLU(inplace=True)),\n ('layer4.2.aa', Identity()),\n ('layer4.2.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.2.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.act3', ReLU(inplace=True)),\n ('global_pool',\n  SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))),\n ('global_pool.pool', AdaptiveAvgPool2d(output_size=1)),\n ('global_pool.flatten', Flatten(start_dim=1, end_dim=-1)),\n ('fc', Linear(in_features=2048, out_features=1000, bias=True))]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(m, k) for m, k in resnet50.named_modules()]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:11:40.874466Z",
     "start_time": "2023-12-28T15:11:40.486874400Z"
    }
   },
   "id": "9cf4be64c4cdd3f6"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "['T_destination',\n '__annotations__',\n '__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattr__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_apply',\n '_backward_hooks',\n '_backward_pre_hooks',\n '_buffers',\n '_call_impl',\n '_compiled_call_impl',\n '_forward_hooks',\n '_forward_hooks_always_called',\n '_forward_hooks_with_kwargs',\n '_forward_pre_hooks',\n '_forward_pre_hooks_with_kwargs',\n '_get_backward_hooks',\n '_get_backward_pre_hooks',\n '_get_name',\n '_is_full_backward_hook',\n '_load_from_state_dict',\n '_load_state_dict_post_hooks',\n '_load_state_dict_pre_hooks',\n '_maybe_warn_non_full_backward_hook',\n '_modules',\n '_named_members',\n '_non_persistent_buffers_set',\n '_parameters',\n '_register_load_state_dict_pre_hook',\n '_register_state_dict_hook',\n '_replicate_for_data_parallel',\n '_save_to_state_dict',\n '_slow_forward',\n '_state_dict_hooks',\n '_state_dict_pre_hooks',\n '_version',\n '_wrapped_call_impl',\n 'act1',\n 'add_module',\n 'apply',\n 'bfloat16',\n 'bn1',\n 'buffers',\n 'call_super_init',\n 'children',\n 'compile',\n 'conv1',\n 'cpu',\n 'cuda',\n 'default_cfg',\n 'double',\n 'drop_rate',\n 'dump_patches',\n 'eval',\n 'extra_repr',\n 'fc',\n 'feature_info',\n 'float',\n 'forward',\n 'forward_features',\n 'forward_head',\n 'get_buffer',\n 'get_classifier',\n 'get_extra_state',\n 'get_parameter',\n 'get_submodule',\n 'global_pool',\n 'grad_checkpointing',\n 'group_matcher',\n 'half',\n 'init_weights',\n 'ipu',\n 'layer1',\n 'layer2',\n 'layer3',\n 'layer4',\n 'load_state_dict',\n 'maxpool',\n 'modules',\n 'named_buffers',\n 'named_children',\n 'named_modules',\n 'named_parameters',\n 'num_classes',\n 'num_features',\n 'parameters',\n 'pretrained_cfg',\n 'register_backward_hook',\n 'register_buffer',\n 'register_forward_hook',\n 'register_forward_pre_hook',\n 'register_full_backward_hook',\n 'register_full_backward_pre_hook',\n 'register_load_state_dict_post_hook',\n 'register_module',\n 'register_parameter',\n 'register_state_dict_pre_hook',\n 'requires_grad_',\n 'reset_classifier',\n 'set_extra_state',\n 'set_grad_checkpointing',\n 'share_memory',\n 'state_dict',\n 'to',\n 'to_empty',\n 'train',\n 'training',\n 'type',\n 'xpu',\n 'zero_grad']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(resnet50)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:11:16.406114700Z",
     "start_time": "2023-12-28T15:11:16.030064400Z"
    }
   },
   "id": "ef30b8d4f11871c0"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[('',\n  ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (drop_block): Identity()\n        (act2): ReLU(inplace=True)\n        (aa): Identity()\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (act3): ReLU(inplace=True)\n      )\n    )\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n  )),\n ('conv1',\n  Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)),\n ('bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('act1', ReLU(inplace=True)),\n ('maxpool',\n  MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)),\n ('layer1',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer1.0',\n  Bottleneck(\n    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer1.0.conv1',\n  Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.act1', ReLU(inplace=True)),\n ('layer1.0.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.0.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.drop_block', Identity()),\n ('layer1.0.act2', ReLU(inplace=True)),\n ('layer1.0.aa', Identity()),\n ('layer1.0.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.0.act3', ReLU(inplace=True)),\n ('layer1.0.downsample',\n  Sequential(\n    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer1.0.downsample.0',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.0.downsample.1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1',\n  Bottleneck(\n    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer1.1.conv1',\n  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.1.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.act1', ReLU(inplace=True)),\n ('layer1.1.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.1.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.drop_block', Identity()),\n ('layer1.1.act2', ReLU(inplace=True)),\n ('layer1.1.aa', Identity()),\n ('layer1.1.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.1.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.1.act3', ReLU(inplace=True)),\n ('layer1.2',\n  Bottleneck(\n    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer1.2.conv1',\n  Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.2.bn1',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.act1', ReLU(inplace=True)),\n ('layer1.2.conv2',\n  Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer1.2.bn2',\n  BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.drop_block', Identity()),\n ('layer1.2.act2', ReLU(inplace=True)),\n ('layer1.2.aa', Identity()),\n ('layer1.2.conv3',\n  Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer1.2.bn3',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer1.2.act3', ReLU(inplace=True)),\n ('layer2',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer2.0',\n  Bottleneck(\n    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer2.0.conv1',\n  Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.0.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.act1', ReLU(inplace=True)),\n ('layer2.0.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer2.0.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.drop_block', Identity()),\n ('layer2.0.act2', ReLU(inplace=True)),\n ('layer2.0.aa', Identity()),\n ('layer2.0.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.0.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.0.act3', ReLU(inplace=True)),\n ('layer2.0.downsample',\n  Sequential(\n    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer2.0.downsample.0',\n  Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer2.0.downsample.1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.1.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.1.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.act1', ReLU(inplace=True)),\n ('layer2.1.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.1.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.drop_block', Identity()),\n ('layer2.1.act2', ReLU(inplace=True)),\n ('layer2.1.aa', Identity()),\n ('layer2.1.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.1.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.1.act3', ReLU(inplace=True)),\n ('layer2.2',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.2.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.2.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.act1', ReLU(inplace=True)),\n ('layer2.2.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.2.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.drop_block', Identity()),\n ('layer2.2.act2', ReLU(inplace=True)),\n ('layer2.2.aa', Identity()),\n ('layer2.2.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.2.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.2.act3', ReLU(inplace=True)),\n ('layer2.3',\n  Bottleneck(\n    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer2.3.conv1',\n  Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.3.bn1',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.act1', ReLU(inplace=True)),\n ('layer2.3.conv2',\n  Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer2.3.bn2',\n  BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.drop_block', Identity()),\n ('layer2.3.act2', ReLU(inplace=True)),\n ('layer2.3.aa', Identity()),\n ('layer2.3.conv3',\n  Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer2.3.bn3',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer2.3.act3', ReLU(inplace=True)),\n ('layer3',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer3.0',\n  Bottleneck(\n    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer3.0.conv1',\n  Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.0.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.act1', ReLU(inplace=True)),\n ('layer3.0.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer3.0.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.drop_block', Identity()),\n ('layer3.0.act2', ReLU(inplace=True)),\n ('layer3.0.aa', Identity()),\n ('layer3.0.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.0.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.0.act3', ReLU(inplace=True)),\n ('layer3.0.downsample',\n  Sequential(\n    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer3.0.downsample.0',\n  Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer3.0.downsample.1',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.1.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.1.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.act1', ReLU(inplace=True)),\n ('layer3.1.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.1.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.drop_block', Identity()),\n ('layer3.1.act2', ReLU(inplace=True)),\n ('layer3.1.aa', Identity()),\n ('layer3.1.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.1.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.1.act3', ReLU(inplace=True)),\n ('layer3.2',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.2.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.2.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.act1', ReLU(inplace=True)),\n ('layer3.2.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.2.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.drop_block', Identity()),\n ('layer3.2.act2', ReLU(inplace=True)),\n ('layer3.2.aa', Identity()),\n ('layer3.2.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.2.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.2.act3', ReLU(inplace=True)),\n ('layer3.3',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.3.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.3.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.act1', ReLU(inplace=True)),\n ('layer3.3.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.3.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.drop_block', Identity()),\n ('layer3.3.act2', ReLU(inplace=True)),\n ('layer3.3.aa', Identity()),\n ('layer3.3.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.3.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.3.act3', ReLU(inplace=True)),\n ('layer3.4',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.4.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.4.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.act1', ReLU(inplace=True)),\n ('layer3.4.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.4.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.drop_block', Identity()),\n ('layer3.4.act2', ReLU(inplace=True)),\n ('layer3.4.aa', Identity()),\n ('layer3.4.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.4.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.4.act3', ReLU(inplace=True)),\n ('layer3.5',\n  Bottleneck(\n    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer3.5.conv1',\n  Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.5.bn1',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.act1', ReLU(inplace=True)),\n ('layer3.5.conv2',\n  Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer3.5.bn2',\n  BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.drop_block', Identity()),\n ('layer3.5.act2', ReLU(inplace=True)),\n ('layer3.5.aa', Identity()),\n ('layer3.5.conv3',\n  Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer3.5.bn3',\n  BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer3.5.act3', ReLU(inplace=True)),\n ('layer4',\n  Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )),\n ('layer4.0',\n  Bottleneck(\n    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n    (downsample): Sequential(\n      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )),\n ('layer4.0.conv1',\n  Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.0.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.act1', ReLU(inplace=True)),\n ('layer4.0.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)),\n ('layer4.0.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.drop_block', Identity()),\n ('layer4.0.act2', ReLU(inplace=True)),\n ('layer4.0.aa', Identity()),\n ('layer4.0.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.0.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.0.act3', ReLU(inplace=True)),\n ('layer4.0.downsample',\n  Sequential(\n    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )),\n ('layer4.0.downsample.0',\n  Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)),\n ('layer4.0.downsample.1',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1',\n  Bottleneck(\n    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer4.1.conv1',\n  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.1.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.act1', ReLU(inplace=True)),\n ('layer4.1.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer4.1.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.drop_block', Identity()),\n ('layer4.1.act2', ReLU(inplace=True)),\n ('layer4.1.aa', Identity()),\n ('layer4.1.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.1.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.1.act3', ReLU(inplace=True)),\n ('layer4.2',\n  Bottleneck(\n    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act1): ReLU(inplace=True)\n    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (drop_block): Identity()\n    (act2): ReLU(inplace=True)\n    (aa): Identity()\n    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (act3): ReLU(inplace=True)\n  )),\n ('layer4.2.conv1',\n  Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.2.bn1',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.act1', ReLU(inplace=True)),\n ('layer4.2.conv2',\n  Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)),\n ('layer4.2.bn2',\n  BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.drop_block', Identity()),\n ('layer4.2.act2', ReLU(inplace=True)),\n ('layer4.2.aa', Identity()),\n ('layer4.2.conv3',\n  Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)),\n ('layer4.2.bn3',\n  BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n ('layer4.2.act3', ReLU(inplace=True)),\n ('global_pool',\n  SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))),\n ('global_pool.pool', AdaptiveAvgPool2d(output_size=1)),\n ('global_pool.flatten', Flatten(start_dim=1, end_dim=-1)),\n ('fc', Linear(in_features=2048, out_features=1000, bias=True))]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(name, m) for name, m in resnet50.named_modules()][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:17:40.421823700Z",
     "start_time": "2023-12-28T15:17:39.981823900Z"
    }
   },
   "id": "742f27bdba1c5676"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[('conv1.weight',\n  Parameter containing:\n  tensor([[[[ 2.0205e-02, -2.3905e-03, -2.0692e-03,  ..., -2.1685e-02,\n             -2.6140e-02,  3.5137e-02],\n            [ 1.1919e-02, -3.9269e-02,  1.0223e-02,  ...,  1.5147e-02,\n              2.0462e-02,  3.0057e-02],\n            [-5.4055e-06,  3.5655e-02, -3.1106e-02,  ...,  2.5908e-02,\n             -8.2757e-03,  9.2408e-03],\n            ...,\n            [ 3.1922e-03, -2.9917e-02, -6.8023e-04,  ...,  8.9421e-03,\n              2.0288e-02, -1.6921e-02],\n            [ 9.2214e-03,  2.8107e-02, -3.1560e-03,  ...,  5.4679e-02,\n              4.0747e-02,  7.1635e-03],\n            [-1.4354e-02,  1.2380e-02,  3.8668e-03,  ...,  1.0404e-02,\n              2.7850e-03, -2.4757e-02]],\n  \n           [[ 1.5083e-02, -4.7006e-02,  1.2246e-03,  ..., -1.4765e-02,\n              4.3166e-02,  1.3303e-02],\n            [ 3.0001e-02, -1.1653e-02,  2.1985e-02,  ..., -1.8013e-03,\n              1.0435e-02, -1.1959e-02],\n            [ 7.8141e-03, -1.2133e-02,  1.5068e-02,  ...,  3.5813e-02,\n             -1.2394e-02,  1.2446e-02],\n            ...,\n            [ 8.6308e-03,  2.7011e-02,  4.3209e-03,  ..., -2.6139e-02,\n             -3.6308e-02, -5.5036e-03],\n            [-2.3940e-02,  2.6287e-03, -2.3679e-03,  ...,  2.8741e-02,\n              4.8739e-02,  1.8239e-02],\n            [-8.5269e-03, -3.5215e-02,  2.1482e-02,  ...,  4.1576e-02,\n              1.9360e-02,  1.3195e-02]],\n  \n           [[ 3.1602e-02, -2.4201e-02, -3.5680e-03,  ..., -1.5726e-02,\n              2.6034e-02, -7.8508e-03],\n            [-1.5276e-02,  1.1890e-02, -1.4376e-03,  ..., -5.4867e-03,\n              2.0695e-03,  2.8955e-02],\n            [-2.2527e-02, -5.8025e-04,  2.0670e-02,  ...,  3.4252e-02,\n             -2.5036e-03, -1.2419e-02],\n            ...,\n            [ 2.7202e-03,  1.5048e-02, -1.5641e-02,  ..., -1.0753e-02,\n              1.1381e-02,  5.9074e-02],\n            [ 2.0294e-02, -3.4114e-02, -1.4550e-03,  ..., -8.5207e-03,\n              3.1333e-02,  3.1698e-02],\n            [-3.4379e-02, -1.2889e-02,  3.1761e-02,  ...,  3.4554e-02,\n              2.3809e-02, -1.6432e-02]]],\n  \n  \n          [[[ 5.7036e-03,  7.0347e-03,  6.1319e-02,  ...,  2.7848e-02,\n             -6.6134e-03,  1.3288e-02],\n            [ 1.1711e-02, -1.4123e-02,  5.0940e-02,  ..., -8.8190e-03,\n              5.8778e-03, -1.8456e-02],\n            [ 1.4140e-02,  2.3809e-02,  1.8546e-02,  ..., -5.7463e-03,\n              1.2362e-03,  1.6378e-02],\n            ...,\n            [-1.6107e-02, -2.9566e-03,  3.8190e-02,  ...,  3.5610e-02,\n             -2.1969e-02, -4.0934e-02],\n            [ 3.9458e-02,  4.3749e-02, -7.5573e-03,  ..., -1.4327e-03,\n             -1.9045e-02,  2.3340e-02],\n            [ 3.1615e-02, -3.2027e-02,  9.8964e-03,  ...,  3.8477e-02,\n             -2.0704e-02,  1.5991e-02]],\n  \n           [[ 5.5651e-02, -5.1981e-02,  5.8360e-03,  ..., -2.8437e-02,\n              2.1817e-02,  3.8454e-02],\n            [-5.1833e-03, -4.1325e-03,  6.5840e-03,  ..., -1.6406e-02,\n              2.7683e-02,  1.2991e-02],\n            [ 3.0617e-02,  6.3705e-02,  1.4437e-03,  ..., -1.6320e-03,\n             -1.5508e-02, -1.4128e-02],\n            ...,\n            [-2.9388e-02, -1.7309e-02, -2.9122e-02,  ...,  1.4107e-02,\n              2.8365e-02,  8.2677e-03],\n            [ 1.3414e-02,  1.0735e-02, -3.2278e-03,  ...,  9.1359e-03,\n             -3.9283e-02, -2.0034e-02],\n            [ 1.7134e-02, -1.7056e-02, -2.5197e-02,  ...,  2.5079e-03,\n              2.1150e-02, -3.2634e-02]],\n  \n           [[ 1.1848e-02, -2.5567e-03,  1.3417e-02,  ..., -1.1782e-02,\n             -6.7100e-03,  1.3251e-02],\n            [-1.3709e-02,  2.0225e-02,  3.3524e-02,  ..., -4.2197e-03,\n              1.0391e-02, -1.3892e-02],\n            [-1.0397e-02, -4.1764e-02,  4.0211e-02,  ...,  2.9085e-02,\n             -2.0469e-02, -7.0829e-03],\n            ...,\n            [ 5.4001e-02,  5.0901e-02, -1.8122e-02,  ...,  1.6229e-02,\n             -4.9057e-02,  7.3125e-03],\n            [ 3.6255e-02, -1.1498e-02, -3.0255e-03,  ...,  4.9947e-02,\n              7.9241e-03,  2.1390e-02],\n            [-1.1954e-02,  2.5755e-02, -4.2196e-03,  ..., -9.7114e-03,\n             -4.3517e-02, -2.1725e-02]]],\n  \n  \n          [[[ 1.9441e-02, -6.3138e-03, -2.8066e-02,  ...,  2.0818e-02,\n              2.8176e-03, -2.0657e-02],\n            [-1.0248e-02,  2.3290e-02, -2.1973e-04,  ..., -3.7387e-03,\n             -9.0462e-03, -5.1965e-02],\n            [ 1.7139e-03, -9.5017e-04,  2.7556e-02,  ..., -1.3388e-03,\n             -4.5942e-02, -6.7081e-03],\n            ...,\n            [-5.5261e-03,  1.1537e-02, -3.7207e-03,  ...,  5.0064e-03,\n              2.3429e-02,  1.4456e-02],\n            [ 5.1691e-02, -6.1622e-03, -9.1988e-04,  ...,  2.5942e-02,\n             -6.2018e-02, -1.5029e-02],\n            [-2.8239e-02, -9.4054e-03, -4.7031e-03,  ..., -5.9704e-02,\n             -2.1722e-02,  1.6728e-02]],\n  \n           [[ 1.2953e-02, -2.1262e-02, -1.7656e-02,  ..., -3.3261e-02,\n              8.1959e-03,  1.2398e-02],\n            [-1.0173e-02, -1.6911e-02,  1.0614e-02,  ...,  3.2688e-02,\n             -1.8414e-02, -3.5086e-02],\n            [ 2.2271e-02, -4.4208e-02,  1.1553e-02,  ...,  7.8297e-03,\n             -3.5210e-02, -2.1322e-02],\n            ...,\n            [-5.5005e-02,  8.4252e-03,  1.1382e-02,  ..., -3.5067e-02,\n             -2.5263e-03, -4.1092e-02],\n            [ 4.4021e-02,  3.7711e-02,  2.5611e-02,  ..., -1.7772e-02,\n             -3.4644e-02, -2.7270e-02],\n            [-1.9713e-02, -9.6579e-03, -4.4251e-03,  ...,  2.3424e-03,\n             -1.6846e-02,  2.0349e-04]],\n  \n           [[ 4.1014e-02,  3.1967e-03, -1.5065e-02,  ..., -2.9923e-02,\n              2.3460e-02,  8.7633e-03],\n            [-1.1828e-02, -3.9624e-02,  1.0316e-02,  ...,  1.6076e-02,\n              3.1923e-03, -8.4323e-03],\n            [ 2.0841e-02,  1.8511e-02, -1.8693e-02,  ...,  1.8843e-02,\n              1.4783e-02, -8.2095e-03],\n            ...,\n            [-8.6175e-03,  4.2012e-03, -2.5294e-02,  ...,  5.6677e-03,\n             -5.6201e-02,  1.2731e-02],\n            [-4.8295e-03,  2.1909e-02,  4.9577e-03,  ..., -4.0834e-03,\n              2.8378e-02,  5.1507e-02],\n            [ 1.2024e-02,  2.4257e-02, -1.7502e-02,  ..., -2.4755e-02,\n              6.6706e-03, -1.9776e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 1.6508e-02,  3.0904e-02, -2.9062e-02,  ..., -2.9244e-02,\n              2.9432e-02,  5.0518e-03],\n            [ 1.1300e-02,  2.7522e-02,  2.7583e-02,  ..., -4.9017e-02,\n              4.5015e-02,  1.4122e-03],\n            [-2.9580e-02, -2.1407e-02,  3.4995e-02,  ..., -4.8124e-03,\n             -1.2429e-02, -1.6051e-02],\n            ...,\n            [-5.2089e-02, -2.6876e-02, -2.0504e-02,  ..., -2.5680e-03,\n             -3.0872e-04,  2.9511e-02],\n            [-1.3734e-02, -6.4345e-03,  1.1440e-02,  ..., -2.9836e-02,\n             -1.4929e-02,  1.2519e-02],\n            [-2.3012e-03,  3.5196e-02, -3.6532e-03,  ...,  1.9822e-02,\n             -2.1415e-02, -9.7333e-03]],\n  \n           [[ 1.2571e-02, -4.4891e-02, -5.0075e-03,  ...,  2.1384e-02,\n             -2.4733e-02,  5.5107e-03],\n            [ 1.2609e-02,  9.9834e-03,  7.1271e-03,  ..., -1.7604e-02,\n              1.4591e-02, -1.1797e-02],\n            [-3.5269e-02,  8.7674e-03,  3.6029e-02,  ..., -8.4927e-03,\n             -3.3031e-02, -5.0926e-02],\n            ...,\n            [-4.1607e-02,  1.7718e-02, -4.0338e-02,  ...,  1.0660e-02,\n             -5.8099e-02,  1.2495e-02],\n            [ 3.3713e-02,  2.1249e-02,  1.0700e-02,  ..., -7.9082e-02,\n             -2.9711e-02, -1.7088e-02],\n            [ 1.6588e-02,  3.4100e-02, -1.5876e-02,  ...,  3.2419e-02,\n             -2.8723e-02, -4.2624e-02]],\n  \n           [[-1.7437e-02,  3.9583e-02,  2.4515e-02,  ...,  2.8756e-02,\n             -2.3897e-02,  1.3300e-03],\n            [-8.8991e-03, -2.0622e-02, -2.3253e-02,  ...,  9.0366e-03,\n              2.7050e-04, -1.0827e-02],\n            [ 2.2254e-02,  2.3756e-02,  3.3088e-03,  ..., -1.7154e-02,\n             -1.8019e-02,  2.2955e-02],\n            ...,\n            [ 1.0251e-02, -3.0935e-02,  3.1150e-03,  ..., -1.1252e-02,\n              1.0673e-03,  2.5444e-02],\n            [ 8.2619e-03, -2.6377e-02,  2.7242e-02,  ..., -3.0989e-03,\n             -2.5490e-02,  3.0521e-02],\n            [-2.6266e-02,  3.0251e-02,  9.1010e-03,  ...,  1.5956e-02,\n             -4.6953e-03, -2.0908e-02]]],\n  \n  \n          [[[-7.4897e-03,  3.2680e-02,  2.0491e-02,  ...,  5.9584e-02,\n             -1.9463e-02,  3.4768e-02],\n            [-6.7759e-03, -2.4649e-02, -2.3188e-02,  ..., -3.0446e-03,\n              5.9373e-02,  4.3334e-03],\n            [-1.9322e-02,  4.4271e-02,  1.3837e-02,  ..., -2.4099e-02,\n             -5.0359e-03, -3.8554e-03],\n            ...,\n            [ 1.3820e-02, -7.0580e-03,  1.6318e-03,  ...,  1.6081e-02,\n             -3.8098e-02,  1.2108e-02],\n            [ 2.7690e-03, -1.7610e-02, -3.5126e-02,  ...,  4.7488e-03,\n             -5.1283e-02, -2.3960e-02],\n            [ 2.0676e-02, -1.5036e-02,  2.5873e-02,  ..., -3.0309e-02,\n             -1.1146e-02,  1.2897e-02]],\n  \n           [[-1.8908e-02, -6.6267e-03, -1.5720e-02,  ...,  5.6900e-02,\n              5.7605e-03,  2.0269e-02],\n            [-1.2481e-02, -2.2107e-03, -5.7907e-02,  ..., -1.1214e-03,\n             -3.9593e-02,  1.6617e-02],\n            [ 1.6587e-02,  1.6491e-02, -3.6589e-03,  ...,  2.4241e-02,\n             -1.0081e-02,  4.5497e-02],\n            ...,\n            [ 6.1241e-03, -1.5664e-02, -2.1847e-02,  ..., -1.9028e-02,\n              1.3661e-02, -1.2527e-02],\n            [ 1.8520e-02,  3.0073e-02, -1.5109e-02,  ..., -4.1136e-03,\n             -2.4439e-02,  2.8699e-02],\n            [ 8.1089e-03,  3.7619e-02, -1.2772e-02,  ...,  2.7639e-02,\n             -3.7560e-02, -5.0457e-02]],\n  \n           [[ 5.3597e-02, -3.0653e-02,  9.3787e-03,  ..., -2.6674e-02,\n              1.8336e-02,  6.6573e-03],\n            [ 2.6618e-02, -5.0091e-02,  1.4210e-03,  ..., -2.7360e-02,\n             -1.8585e-02,  1.0534e-03],\n            [-2.5282e-02, -2.2415e-02, -4.4411e-03,  ..., -8.7972e-03,\n              2.6992e-02, -9.2498e-03],\n            ...,\n            [-1.4720e-02,  1.8461e-02,  2.7196e-02,  ...,  2.1060e-02,\n             -1.9724e-02,  1.9480e-02],\n            [ 4.9876e-02,  1.5148e-03, -1.0424e-02,  ..., -2.8956e-02,\n             -1.0594e-02,  7.2250e-03],\n            [ 4.2594e-03,  6.1981e-03,  1.1039e-02,  ..., -5.8941e-03,\n             -5.8101e-03,  7.1369e-03]]],\n  \n  \n          [[[ 2.4372e-02,  1.5509e-02, -2.0794e-02,  ...,  3.9159e-02,\n             -3.8332e-02, -1.8619e-02],\n            [-3.7797e-02, -3.6067e-02,  2.2466e-02,  ...,  3.8821e-03,\n              6.1536e-03,  4.1941e-02],\n            [-1.6141e-03, -1.2965e-03,  1.1418e-03,  ..., -3.4387e-03,\n             -4.2280e-03, -1.7032e-02],\n            ...,\n            [ 2.2596e-02, -4.5576e-03, -3.6427e-02,  ..., -1.7975e-02,\n             -2.9819e-02,  3.0867e-02],\n            [-1.3974e-02, -2.3854e-02, -2.4647e-02,  ..., -2.7752e-02,\n             -6.6875e-02,  7.4949e-03],\n            [-4.1861e-02,  1.9089e-02,  2.2661e-02,  ..., -1.0697e-02,\n             -2.7676e-03,  1.0051e-02]],\n  \n           [[-2.9766e-02,  1.9077e-02,  1.0466e-02,  ...,  1.8746e-02,\n              3.3052e-02, -3.3485e-02],\n            [ 4.4829e-02, -1.3520e-02,  2.8138e-02,  ...,  6.1510e-03,\n             -6.1483e-03, -1.9508e-02],\n            [ 1.9231e-02,  1.9132e-02, -2.1079e-02,  ...,  8.7133e-03,\n              1.5779e-02, -2.4805e-02],\n            ...,\n            [ 3.6441e-02, -4.4241e-02,  8.3280e-03,  ..., -2.9894e-02,\n             -2.7145e-02, -2.3498e-02],\n            [-7.5467e-03, -1.9729e-02, -1.3039e-03,  ...,  3.5926e-03,\n             -1.6647e-03, -3.0189e-02],\n            [ 4.7935e-03,  2.0252e-02, -2.7340e-02,  ...,  4.3277e-03,\n              1.8503e-02,  4.7513e-02]],\n  \n           [[-6.1403e-02,  1.4447e-02, -2.9383e-02,  ...,  2.0712e-03,\n             -3.2192e-02, -9.2196e-03],\n            [ 2.5356e-03, -2.8008e-02,  6.3749e-03,  ...,  1.0467e-03,\n             -2.9662e-02,  3.6803e-02],\n            [-1.5732e-02, -4.8111e-04,  6.4498e-03,  ..., -1.5811e-02,\n              4.2455e-03, -3.5927e-03],\n            ...,\n            [ 9.1832e-03,  3.7838e-03, -1.3741e-03,  ..., -1.8789e-03,\n             -3.0376e-03,  2.7973e-02],\n            [ 1.1624e-02,  2.0685e-02, -8.5090e-03,  ...,  5.1945e-03,\n             -3.5213e-02, -1.0521e-02],\n            [ 1.4765e-02, -2.5245e-02, -2.3807e-02,  ...,  9.2163e-03,\n             -1.8324e-02, -1.8349e-02]]]], requires_grad=True)),\n ('bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.0.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.2290]],\n  \n           [[ 0.3313]],\n  \n           [[ 0.2362]],\n  \n           ...,\n  \n           [[-0.1768]],\n  \n           [[-0.1309]],\n  \n           [[-0.0832]]],\n  \n  \n          [[[-0.3692]],\n  \n           [[ 0.0679]],\n  \n           [[-0.0160]],\n  \n           ...,\n  \n           [[-0.3867]],\n  \n           [[-0.0800]],\n  \n           [[ 0.0887]]],\n  \n  \n          [[[ 0.0321]],\n  \n           [[ 0.0199]],\n  \n           [[ 0.1873]],\n  \n           ...,\n  \n           [[-0.0699]],\n  \n           [[-0.0163]],\n  \n           [[-0.1113]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.1393]],\n  \n           [[-0.4019]],\n  \n           [[-0.3346]],\n  \n           ...,\n  \n           [[-0.2075]],\n  \n           [[ 0.0176]],\n  \n           [[ 0.0399]]],\n  \n  \n          [[[-0.0983]],\n  \n           [[ 0.0173]],\n  \n           [[-0.1739]],\n  \n           ...,\n  \n           [[-0.0412]],\n  \n           [[-0.1317]],\n  \n           [[-0.1213]]],\n  \n  \n          [[[-0.3507]],\n  \n           [[ 0.1722]],\n  \n           [[ 0.0333]],\n  \n           ...,\n  \n           [[-0.1155]],\n  \n           [[-0.0241]],\n  \n           [[ 0.0263]]]], requires_grad=True)),\n ('layer1.0.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.0.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.0.conv2.weight',\n  Parameter containing:\n  tensor([[[[-8.5353e-02,  4.2442e-02, -1.9138e-03],\n            [-1.4604e-02, -8.3252e-02, -1.5588e-02],\n            [-2.2293e-02,  7.0880e-03, -2.1843e-02]],\n  \n           [[ 1.2756e-02, -5.8847e-02, -2.8348e-02],\n            [ 4.7153e-02, -9.5202e-02,  1.3774e-01],\n            [-6.3986e-02,  1.3814e-01,  4.2420e-02]],\n  \n           [[ 4.5159e-02,  9.7097e-02,  1.9015e-02],\n            [-1.1463e-01,  1.5932e-02, -5.9595e-02],\n            [-2.8581e-02, -6.7515e-02, -8.0742e-02]],\n  \n           ...,\n  \n           [[ 1.3945e-01, -3.7596e-02, -8.4238e-02],\n            [ 9.0191e-02,  3.0739e-02, -8.3794e-03],\n            [-2.9000e-03,  2.9931e-03,  9.9263e-02]],\n  \n           [[-9.4439e-02, -7.9937e-02,  1.1385e-01],\n            [ 1.0231e-02, -5.5462e-02, -3.1065e-02],\n            [-2.7779e-02,  8.5615e-04, -2.8768e-02]],\n  \n           [[ 5.6608e-02, -3.2057e-03, -5.5263e-02],\n            [-8.3164e-02, -4.3020e-03,  2.5182e-02],\n            [-4.3467e-02, -1.0800e-01, -3.3470e-02]]],\n  \n  \n          [[[ 6.6404e-02, -1.4066e-02,  6.1656e-02],\n            [-2.8239e-02,  3.9282e-02,  4.5282e-02],\n            [ 9.5756e-02,  4.7193e-02, -3.2316e-02]],\n  \n           [[-4.0710e-02, -4.9333e-02, -5.9756e-02],\n            [-8.1629e-02, -2.4763e-02, -3.1091e-02],\n            [-3.9833e-03, -4.6530e-02,  9.1292e-03]],\n  \n           [[-1.1391e-02,  2.1991e-02, -6.1529e-03],\n            [-5.5138e-02,  7.5181e-03,  3.8683e-02],\n            [-8.3326e-03, -4.9492e-02,  1.4074e-01]],\n  \n           ...,\n  \n           [[-9.3771e-02,  1.0060e-02, -4.4185e-02],\n            [ 1.1426e-02, -4.9989e-02,  5.2989e-02],\n            [-3.5208e-02, -8.4469e-02,  2.2738e-02]],\n  \n           [[-9.3101e-03,  5.8356e-02, -6.1444e-03],\n            [-2.3899e-02, -9.9446e-03, -1.6147e-03],\n            [-1.1913e-01, -6.7731e-04,  6.3689e-02]],\n  \n           [[ 5.8050e-02,  1.0001e-01, -2.0225e-02],\n            [ 8.8134e-04,  3.7452e-02, -6.9153e-02],\n            [ 6.8750e-02, -4.4218e-02,  4.4150e-02]]],\n  \n  \n          [[[ 6.8471e-02, -3.5197e-02, -1.4969e-02],\n            [-6.3379e-02,  1.0913e-01, -4.1560e-02],\n            [ 2.6482e-02,  4.8737e-02, -2.8062e-02]],\n  \n           [[-5.5004e-02,  9.2907e-03,  1.2454e-02],\n            [ 1.4338e-02, -8.4946e-02,  5.0657e-02],\n            [-5.1343e-02, -1.8879e-02,  6.4731e-02]],\n  \n           [[-1.2408e-03,  7.7626e-02, -2.3187e-02],\n            [-3.9377e-03, -3.2439e-02, -4.1149e-03],\n            [ 5.1900e-02, -7.4798e-02,  2.9986e-02]],\n  \n           ...,\n  \n           [[ 8.0931e-02,  1.2289e-01, -8.4175e-03],\n            [ 7.5686e-02,  3.4618e-03, -5.7763e-03],\n            [-9.1568e-02, -6.6277e-02,  8.0384e-02]],\n  \n           [[-2.8032e-02,  1.3912e-02, -3.4598e-02],\n            [ 2.5609e-03, -1.0839e-01,  6.4283e-02],\n            [-2.4107e-03,  2.2428e-02, -1.7362e-02]],\n  \n           [[ 2.9961e-02,  2.0006e-02, -5.3228e-03],\n            [ 4.6292e-03, -8.1682e-02, -5.6117e-03],\n            [ 8.6949e-02,  2.0804e-02,  1.1615e-01]]],\n  \n  \n          ...,\n  \n  \n          [[[ 1.4988e-02,  1.5524e-01, -1.2087e-01],\n            [-2.7630e-02, -5.5988e-02, -4.6526e-02],\n            [-1.5355e-01, -4.5186e-02, -1.0135e-01]],\n  \n           [[ 5.7352e-03, -4.8523e-02,  1.6264e-01],\n            [-7.0921e-02,  7.9327e-03, -2.5498e-02],\n            [ 4.3608e-02, -3.4504e-02,  4.2297e-02]],\n  \n           [[ 1.6033e-02, -8.8280e-03,  2.7813e-02],\n            [ 4.6721e-02,  4.7857e-02, -4.3148e-02],\n            [-4.4466e-04, -6.5594e-02,  1.7914e-02]],\n  \n           ...,\n  \n           [[-1.0129e-02, -2.9319e-02,  4.2583e-02],\n            [-1.2842e-01,  1.3437e-04, -5.2542e-02],\n            [ 9.0520e-02,  2.2589e-02, -3.6202e-02]],\n  \n           [[ 5.1656e-02, -8.9629e-02,  8.8598e-02],\n            [ 2.6451e-02,  7.1046e-02, -8.4856e-03],\n            [-1.0367e-01,  8.8904e-02, -3.7408e-02]],\n  \n           [[ 4.7444e-02,  2.9483e-02,  1.0843e-01],\n            [ 1.4208e-01,  3.0472e-02, -3.7760e-03],\n            [ 2.1232e-02,  2.1296e-03,  1.0800e-02]]],\n  \n  \n          [[[-7.9437e-02, -4.7137e-02,  3.2004e-02],\n            [ 3.4575e-03, -8.6786e-02, -1.1978e-01],\n            [-1.0690e-01, -1.7928e-02, -2.0724e-02]],\n  \n           [[-5.8107e-02, -5.7194e-02,  1.7888e-01],\n            [ 4.1697e-02,  5.3274e-02, -1.0917e-01],\n            [ 3.3153e-02, -4.3406e-03,  2.8869e-02]],\n  \n           [[-1.0578e-01,  2.4505e-02, -3.9027e-02],\n            [ 1.0042e-01,  1.8018e-02, -6.0525e-02],\n            [-3.1232e-02,  2.0422e-02,  3.9941e-02]],\n  \n           ...,\n  \n           [[-8.5304e-03,  1.2059e-01,  1.0680e-02],\n            [-3.6759e-02,  6.6216e-03, -6.9169e-02],\n            [-3.9427e-02,  4.9240e-02, -7.6128e-02]],\n  \n           [[-2.2726e-03, -3.5626e-02, -4.9596e-02],\n            [-9.9419e-02, -2.6064e-02,  3.2886e-02],\n            [ 3.7754e-02, -4.9676e-02,  3.7577e-02]],\n  \n           [[ 1.1832e-01,  4.5453e-03,  4.4521e-02],\n            [ 5.2852e-02, -1.2235e-02, -3.3951e-02],\n            [-2.3239e-02,  4.8260e-02,  5.4950e-02]]],\n  \n  \n          [[[ 9.1501e-03,  4.3327e-04,  6.2598e-02],\n            [-1.3631e-02, -1.3479e-01,  1.0200e-01],\n            [-1.6141e-02,  3.0046e-02,  6.8658e-02]],\n  \n           [[ 2.1715e-02,  7.0487e-02,  9.3667e-02],\n            [ 1.1754e-02, -5.1640e-02, -1.1317e-02],\n            [ 2.0853e-03, -3.5191e-02, -2.5556e-02]],\n  \n           [[ 1.1396e-01, -1.7334e-02,  1.1268e-01],\n            [ 2.0064e-02,  1.0131e-01, -1.1123e-01],\n            [-9.5416e-02, -8.4598e-02,  9.5427e-02]],\n  \n           ...,\n  \n           [[ 1.1394e-01,  2.4958e-02, -8.8216e-03],\n            [ 6.2458e-02, -1.2677e-02, -4.4292e-02],\n            [-1.2797e-01,  6.6629e-04, -8.6260e-02]],\n  \n           [[ 6.5938e-03, -6.4041e-02,  2.2439e-02],\n            [-2.1487e-03,  5.1897e-02,  8.9510e-02],\n            [ 3.5998e-02,  4.4589e-02,  1.1359e-02]],\n  \n           [[ 1.3785e-02, -4.7691e-02,  1.1545e-01],\n            [ 8.9681e-02,  1.9578e-02,  1.0743e-02],\n            [ 1.7497e-02,  1.4757e-02, -8.0502e-02]]]], requires_grad=True)),\n ('layer1.0.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.0.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.0.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0413]],\n  \n           [[ 0.0872]],\n  \n           [[-0.1247]],\n  \n           ...,\n  \n           [[-0.1366]],\n  \n           [[-0.0578]],\n  \n           [[ 0.0542]]],\n  \n  \n          [[[-0.0034]],\n  \n           [[ 0.1183]],\n  \n           [[ 0.0281]],\n  \n           ...,\n  \n           [[-0.1057]],\n  \n           [[ 0.0387]],\n  \n           [[ 0.0256]]],\n  \n  \n          [[[ 0.0482]],\n  \n           [[-0.0497]],\n  \n           [[-0.0084]],\n  \n           ...,\n  \n           [[-0.0399]],\n  \n           [[-0.0327]],\n  \n           [[-0.0984]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.1554]],\n  \n           [[ 0.1927]],\n  \n           [[ 0.0380]],\n  \n           ...,\n  \n           [[-0.0671]],\n  \n           [[-0.0318]],\n  \n           [[-0.0181]]],\n  \n  \n          [[[ 0.0598]],\n  \n           [[ 0.0496]],\n  \n           [[ 0.0455]],\n  \n           ...,\n  \n           [[-0.0472]],\n  \n           [[ 0.1054]],\n  \n           [[ 0.0357]]],\n  \n  \n          [[[ 0.0682]],\n  \n           [[ 0.0668]],\n  \n           [[ 0.1178]],\n  \n           ...,\n  \n           [[ 0.0272]],\n  \n           [[ 0.0508]],\n  \n           [[ 0.0411]]]], requires_grad=True)),\n ('layer1.0.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.0.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.0.downsample.0.weight',\n  Parameter containing:\n  tensor([[[[ 0.2302]],\n  \n           [[ 0.0115]],\n  \n           [[ 0.3872]],\n  \n           ...,\n  \n           [[ 0.0548]],\n  \n           [[ 0.1249]],\n  \n           [[-0.0445]]],\n  \n  \n          [[[ 0.1131]],\n  \n           [[ 0.0776]],\n  \n           [[ 0.0465]],\n  \n           ...,\n  \n           [[ 0.0942]],\n  \n           [[-0.0379]],\n  \n           [[-0.0159]]],\n  \n  \n          [[[ 0.0495]],\n  \n           [[ 0.1434]],\n  \n           [[-0.0829]],\n  \n           ...,\n  \n           [[ 0.0878]],\n  \n           [[-0.0151]],\n  \n           [[ 0.0321]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.1055]],\n  \n           [[-0.2234]],\n  \n           [[ 0.0616]],\n  \n           ...,\n  \n           [[ 0.0533]],\n  \n           [[ 0.0322]],\n  \n           [[ 0.0866]]],\n  \n  \n          [[[-0.1012]],\n  \n           [[-0.0883]],\n  \n           [[ 0.1247]],\n  \n           ...,\n  \n           [[-0.0140]],\n  \n           [[ 0.1246]],\n  \n           [[ 0.0889]]],\n  \n  \n          [[[-0.0217]],\n  \n           [[-0.2150]],\n  \n           [[-0.1290]],\n  \n           ...,\n  \n           [[-0.0731]],\n  \n           [[-0.0035]],\n  \n           [[ 0.0307]]]], requires_grad=True)),\n ('layer1.0.downsample.1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer1.0.downsample.1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.1.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.2611]],\n  \n           [[ 0.1386]],\n  \n           [[-0.0270]],\n  \n           ...,\n  \n           [[ 0.1107]],\n  \n           [[ 0.2469]],\n  \n           [[-0.2767]]],\n  \n  \n          [[[-0.0702]],\n  \n           [[ 0.2575]],\n  \n           [[-0.1334]],\n  \n           ...,\n  \n           [[-0.0319]],\n  \n           [[ 0.1562]],\n  \n           [[-0.0166]]],\n  \n  \n          [[[-0.0584]],\n  \n           [[ 0.0050]],\n  \n           [[-0.0705]],\n  \n           ...,\n  \n           [[-0.0733]],\n  \n           [[-0.0407]],\n  \n           [[ 0.0555]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.4171]],\n  \n           [[ 0.1203]],\n  \n           [[-0.0161]],\n  \n           ...,\n  \n           [[ 0.0299]],\n  \n           [[ 0.0792]],\n  \n           [[-0.1504]]],\n  \n  \n          [[[ 0.1538]],\n  \n           [[ 0.4424]],\n  \n           [[-0.2124]],\n  \n           ...,\n  \n           [[ 0.0160]],\n  \n           [[-0.0894]],\n  \n           [[-0.0954]]],\n  \n  \n          [[[ 0.2508]],\n  \n           [[ 0.0981]],\n  \n           [[ 0.1517]],\n  \n           ...,\n  \n           [[-0.0328]],\n  \n           [[ 0.0270]],\n  \n           [[-0.5096]]]], requires_grad=True)),\n ('layer1.1.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.1.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.1.conv2.weight',\n  Parameter containing:\n  tensor([[[[-0.0761, -0.0680,  0.1190],\n            [-0.0220,  0.0170,  0.1041],\n            [-0.1102, -0.0218,  0.0276]],\n  \n           [[-0.0449,  0.0087, -0.0510],\n            [ 0.0544,  0.0295, -0.0865],\n            [ 0.0440, -0.0022,  0.0425]],\n  \n           [[ 0.0111, -0.0058, -0.0094],\n            [-0.0358, -0.0008,  0.1008],\n            [-0.1092, -0.0342, -0.0803]],\n  \n           ...,\n  \n           [[-0.0304, -0.0038,  0.0153],\n            [-0.0090, -0.0025,  0.1180],\n            [ 0.0202, -0.0396,  0.0919]],\n  \n           [[ 0.0480, -0.0301,  0.0307],\n            [ 0.0235,  0.0152,  0.0921],\n            [-0.0579,  0.0070, -0.0962]],\n  \n           [[-0.0308, -0.0284,  0.0663],\n            [-0.1260,  0.0022,  0.0029],\n            [ 0.0653,  0.0226, -0.0320]]],\n  \n  \n          [[[ 0.0536,  0.0759,  0.0370],\n            [ 0.0595,  0.0877, -0.1594],\n            [ 0.0149,  0.0525,  0.1823]],\n  \n           [[ 0.0306, -0.0366,  0.0387],\n            [-0.0209, -0.0651, -0.0072],\n            [ 0.1328,  0.0492,  0.0556]],\n  \n           [[ 0.0480, -0.0496, -0.1207],\n            [-0.0277, -0.0344, -0.0428],\n            [-0.1035, -0.0300,  0.0669]],\n  \n           ...,\n  \n           [[ 0.0179,  0.0032,  0.0266],\n            [ 0.0428, -0.0178, -0.0024],\n            [ 0.0625,  0.0131,  0.0136]],\n  \n           [[ 0.0190, -0.0036,  0.1004],\n            [-0.1120, -0.0176,  0.0060],\n            [-0.0099, -0.1138, -0.0483]],\n  \n           [[-0.0273,  0.0170,  0.0589],\n            [-0.0367, -0.0033,  0.0358],\n            [ 0.0008, -0.1269,  0.0433]]],\n  \n  \n          [[[-0.0309,  0.0196,  0.0111],\n            [-0.0149,  0.0639,  0.0440],\n            [-0.0299, -0.0455, -0.0161]],\n  \n           [[ 0.1299,  0.0826,  0.0206],\n            [-0.0026, -0.0634, -0.0422],\n            [-0.0221,  0.0322,  0.0217]],\n  \n           [[-0.0822,  0.0262, -0.0140],\n            [-0.1324, -0.0146, -0.0364],\n            [ 0.0331, -0.0344,  0.0996]],\n  \n           ...,\n  \n           [[-0.0180, -0.0299,  0.0010],\n            [-0.0444, -0.0364,  0.0259],\n            [-0.0607, -0.0079, -0.0413]],\n  \n           [[-0.0712, -0.0613, -0.0099],\n            [-0.0326,  0.0697, -0.1162],\n            [ 0.0466, -0.0305,  0.0081]],\n  \n           [[-0.0030, -0.0225,  0.0573],\n            [-0.0579,  0.0566, -0.0257],\n            [ 0.0212, -0.0669,  0.0343]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0075,  0.0533, -0.0252],\n            [-0.0002,  0.0185, -0.0457],\n            [ 0.0575, -0.0279, -0.0231]],\n  \n           [[-0.0025, -0.0967, -0.0964],\n            [ 0.0077, -0.0874,  0.0063],\n            [ 0.0214, -0.0251,  0.0103]],\n  \n           [[-0.1013,  0.0515,  0.0510],\n            [ 0.0216,  0.0175, -0.0474],\n            [-0.0415,  0.0455, -0.0269]],\n  \n           ...,\n  \n           [[ 0.0778, -0.0191, -0.0706],\n            [ 0.0573,  0.0219, -0.0233],\n            [ 0.0186,  0.0261, -0.0428]],\n  \n           [[-0.0150,  0.0065,  0.1109],\n            [ 0.0983, -0.0402, -0.0577],\n            [ 0.0291,  0.0630,  0.0320]],\n  \n           [[ 0.1271,  0.0369, -0.0152],\n            [ 0.0477,  0.0073, -0.0525],\n            [-0.0083,  0.0534, -0.0394]]],\n  \n  \n          [[[ 0.0219,  0.0118, -0.0518],\n            [-0.0484, -0.0842,  0.0487],\n            [-0.0443,  0.0006, -0.0173]],\n  \n           [[-0.0271, -0.0089,  0.0509],\n            [ 0.0078, -0.0025, -0.0208],\n            [-0.0011, -0.0077, -0.0575]],\n  \n           [[ 0.0249, -0.0075, -0.0122],\n            [ 0.0842,  0.0048, -0.0334],\n            [ 0.0288,  0.0258,  0.0602]],\n  \n           ...,\n  \n           [[ 0.1379, -0.0036,  0.0563],\n            [-0.0203, -0.0756,  0.0138],\n            [-0.0086, -0.0492, -0.0315]],\n  \n           [[-0.0203,  0.0524,  0.0591],\n            [ 0.0119, -0.0162,  0.0316],\n            [-0.0638, -0.0052, -0.0103]],\n  \n           [[ 0.0402,  0.0109,  0.0299],\n            [ 0.0133,  0.0444,  0.0548],\n            [ 0.0247, -0.1040,  0.0890]]],\n  \n  \n          [[[-0.0281, -0.0561,  0.0212],\n            [ 0.0479,  0.0497, -0.0372],\n            [-0.0873,  0.0718, -0.0501]],\n  \n           [[-0.0032, -0.0296,  0.0230],\n            [-0.0203, -0.0180,  0.0390],\n            [ 0.1703,  0.0383,  0.1231]],\n  \n           [[-0.0237,  0.0717,  0.0343],\n            [ 0.0196, -0.0072,  0.0537],\n            [ 0.0045,  0.0019, -0.0254]],\n  \n           ...,\n  \n           [[-0.0180,  0.0322,  0.0653],\n            [-0.0365,  0.0197,  0.0718],\n            [-0.0059,  0.0274,  0.0364]],\n  \n           [[ 0.0402, -0.1024,  0.0109],\n            [-0.1263,  0.0491,  0.0409],\n            [-0.0649,  0.1100,  0.0808]],\n  \n           [[ 0.0184, -0.1448, -0.0140],\n            [-0.0274,  0.0083, -0.0272],\n            [ 0.0826, -0.0148, -0.0603]]]], requires_grad=True)),\n ('layer1.1.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.1.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.1.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0495]],\n  \n           [[ 0.1060]],\n  \n           [[ 0.0348]],\n  \n           ...,\n  \n           [[ 0.0021]],\n  \n           [[ 0.0008]],\n  \n           [[-0.0600]]],\n  \n  \n          [[[-0.0754]],\n  \n           [[ 0.0518]],\n  \n           [[-0.1467]],\n  \n           ...,\n  \n           [[ 0.0112]],\n  \n           [[ 0.1063]],\n  \n           [[-0.1654]]],\n  \n  \n          [[[-0.0530]],\n  \n           [[ 0.1251]],\n  \n           [[ 0.0805]],\n  \n           ...,\n  \n           [[ 0.0032]],\n  \n           [[ 0.0285]],\n  \n           [[ 0.0513]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.1960]],\n  \n           [[ 0.0398]],\n  \n           [[ 0.0405]],\n  \n           ...,\n  \n           [[-0.0247]],\n  \n           [[ 0.0511]],\n  \n           [[ 0.1070]]],\n  \n  \n          [[[ 0.0446]],\n  \n           [[ 0.0621]],\n  \n           [[ 0.1272]],\n  \n           ...,\n  \n           [[-0.0241]],\n  \n           [[ 0.0305]],\n  \n           [[ 0.0363]]],\n  \n  \n          [[[-0.2069]],\n  \n           [[ 0.0013]],\n  \n           [[-0.1190]],\n  \n           ...,\n  \n           [[-0.0037]],\n  \n           [[-0.0831]],\n  \n           [[-0.1900]]]], requires_grad=True)),\n ('layer1.1.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.1.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.2.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.1843]],\n  \n           [[-0.1826]],\n  \n           [[-0.2861]],\n  \n           ...,\n  \n           [[ 0.0362]],\n  \n           [[ 0.2487]],\n  \n           [[-0.1056]]],\n  \n  \n          [[[-0.1508]],\n  \n           [[-0.2946]],\n  \n           [[ 0.1051]],\n  \n           ...,\n  \n           [[ 0.1143]],\n  \n           [[ 0.1828]],\n  \n           [[-0.1549]]],\n  \n  \n          [[[ 0.0008]],\n  \n           [[-0.4955]],\n  \n           [[ 0.0088]],\n  \n           ...,\n  \n           [[-0.0345]],\n  \n           [[ 0.2328]],\n  \n           [[ 0.1095]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0046]],\n  \n           [[ 0.0422]],\n  \n           [[ 0.1480]],\n  \n           ...,\n  \n           [[-0.3768]],\n  \n           [[ 0.1282]],\n  \n           [[-0.1075]]],\n  \n  \n          [[[ 0.0360]],\n  \n           [[-0.0755]],\n  \n           [[-0.0259]],\n  \n           ...,\n  \n           [[ 0.0494]],\n  \n           [[-0.3663]],\n  \n           [[ 0.0763]]],\n  \n  \n          [[[ 0.0492]],\n  \n           [[ 0.0731]],\n  \n           [[-0.0499]],\n  \n           ...,\n  \n           [[-0.1093]],\n  \n           [[ 0.1039]],\n  \n           [[-0.0451]]]], requires_grad=True)),\n ('layer1.2.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.2.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.2.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 2.7623e-02, -2.4443e-02,  4.5454e-02],\n            [ 8.7865e-02,  2.6252e-02,  6.0390e-03],\n            [ 6.4354e-02,  1.5069e-02,  2.8763e-02]],\n  \n           [[ 1.0857e-01,  9.5209e-03, -3.1717e-02],\n            [-8.3909e-02,  3.4287e-02, -1.4324e-02],\n            [-5.9549e-03, -1.5819e-02, -3.5980e-02]],\n  \n           [[-8.5880e-02,  1.6646e-02,  1.2425e-01],\n            [-2.6203e-02, -5.9565e-02, -3.9389e-02],\n            [-2.6639e-02, -4.4188e-02, -1.3339e-03]],\n  \n           ...,\n  \n           [[-2.4837e-02,  5.7556e-02, -3.5952e-02],\n            [ 1.8752e-02,  3.6821e-02, -5.4847e-02],\n            [-2.1440e-02,  3.2884e-02,  3.4099e-02]],\n  \n           [[-3.2155e-02, -8.0906e-02,  1.5429e-02],\n            [ 1.9014e-02,  3.3896e-03,  6.8020e-02],\n            [ 9.0992e-02,  1.3429e-01,  3.1759e-02]],\n  \n           [[ 2.1567e-02,  3.0925e-02, -7.6576e-02],\n            [-1.1861e-02,  8.9780e-02, -5.2691e-03],\n            [-7.9270e-02, -2.1960e-02, -2.5949e-02]]],\n  \n  \n          [[[-9.3808e-02, -3.4036e-02,  7.0871e-02],\n            [-3.6460e-02,  2.6389e-02,  1.2293e-02],\n            [-3.4808e-02, -8.4648e-02, -2.3852e-02]],\n  \n           [[-9.1580e-02, -1.3380e-01,  1.0249e-01],\n            [-3.5538e-02, -8.9153e-02,  7.2105e-02],\n            [-9.4974e-02,  1.1773e-01,  1.0579e-02]],\n  \n           [[ 9.7100e-03, -1.3482e-02,  1.0436e-01],\n            [-4.5951e-02,  1.1003e-02, -9.9243e-05],\n            [-5.9685e-02, -1.0033e-01, -4.7110e-02]],\n  \n           ...,\n  \n           [[ 1.0462e-02,  1.0273e-02,  5.1620e-02],\n            [-2.6795e-02,  2.0875e-02, -5.0219e-02],\n            [-1.6426e-01, -7.4874e-02, -1.2192e-01]],\n  \n           [[-5.0368e-03,  3.4347e-02, -8.3174e-02],\n            [ 9.7084e-02,  8.0580e-02, -8.3466e-02],\n            [-5.2946e-03, -8.7937e-02,  6.9336e-02]],\n  \n           [[ 7.6833e-02, -3.7339e-02,  3.1383e-02],\n            [-4.4461e-02, -1.7069e-02,  4.0680e-02],\n            [ 5.5677e-02,  8.6088e-02, -9.6315e-02]]],\n  \n  \n          [[[ 7.4762e-02, -7.1960e-02, -2.5068e-02],\n            [ 3.5040e-02, -2.2360e-02, -4.9041e-02],\n            [-7.8669e-03,  2.9328e-02,  6.2925e-02]],\n  \n           [[ 3.2424e-02, -5.5091e-02,  4.0217e-03],\n            [ 2.4502e-02,  1.2622e-02, -1.3791e-02],\n            [ 2.5224e-02,  2.3484e-02,  2.0312e-02]],\n  \n           [[-2.2768e-02,  8.3269e-02, -3.7646e-02],\n            [-5.0028e-02,  5.5880e-02,  5.2385e-02],\n            [-1.2832e-02, -2.7209e-02,  3.0309e-02]],\n  \n           ...,\n  \n           [[ 8.0386e-02, -2.6481e-02, -3.0677e-02],\n            [-5.6881e-02,  9.4150e-03, -4.5432e-02],\n            [-6.4330e-02,  6.6453e-02, -2.4158e-03]],\n  \n           [[ 1.8041e-02, -2.0965e-02,  6.2920e-02],\n            [ 5.2443e-02, -1.3662e-01,  2.3951e-02],\n            [ 2.3993e-02, -4.7842e-02,  1.8909e-02]],\n  \n           [[-2.2260e-02, -2.1502e-02, -1.3355e-04],\n            [ 1.4345e-01, -1.4556e-03,  9.0243e-02],\n            [ 2.6895e-02, -1.3526e-02, -9.9742e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[-4.0446e-02,  4.8274e-02, -1.0063e-01],\n            [-5.6964e-02,  1.8800e-02,  6.5169e-02],\n            [ 1.3205e-01,  4.2361e-02,  4.9500e-02]],\n  \n           [[-6.9711e-02, -9.0528e-02,  5.0771e-02],\n            [-3.9869e-02,  6.1646e-03,  1.4484e-02],\n            [ 2.3159e-02, -8.5628e-03, -1.9791e-02]],\n  \n           [[-6.9742e-02, -8.4354e-02,  2.0633e-02],\n            [ 4.0481e-02, -4.6717e-02, -3.5373e-02],\n            [ 6.4515e-02,  1.0619e-01, -4.2886e-02]],\n  \n           ...,\n  \n           [[ 2.9073e-04, -9.5342e-02,  1.1611e-01],\n            [-3.4193e-02, -5.3242e-02, -6.3283e-02],\n            [-2.5843e-02,  9.4612e-03, -5.5869e-02]],\n  \n           [[ 6.6120e-02, -5.6313e-02,  1.4887e-01],\n            [-1.7104e-04, -1.5355e-02, -2.9736e-02],\n            [ 3.9859e-02,  7.0039e-02, -8.8858e-02]],\n  \n           [[-7.3081e-03,  9.9355e-03,  1.4254e-02],\n            [ 2.2108e-03, -6.6447e-02, -1.1148e-02],\n            [ 6.7862e-02, -3.3462e-02, -4.2591e-02]]],\n  \n  \n          [[[-1.3626e-02, -1.2138e-01,  5.2448e-02],\n            [-7.2336e-03,  1.5065e-02,  7.5403e-02],\n            [-1.0493e-01, -2.1835e-02, -3.9315e-03]],\n  \n           [[ 1.2141e-02, -7.1064e-02, -6.8463e-02],\n            [-6.7753e-02,  2.4702e-02, -1.7162e-01],\n            [ 8.9272e-02,  3.0368e-02, -4.8349e-02]],\n  \n           [[ 9.4632e-02, -1.1466e-02,  2.5121e-03],\n            [ 1.7472e-02,  1.3335e-02,  2.6825e-02],\n            [ 1.3707e-02, -6.1328e-02, -7.7781e-02]],\n  \n           ...,\n  \n           [[ 2.6461e-02,  5.7461e-02, -3.1987e-03],\n            [ 1.1933e-02,  3.9273e-02,  5.4511e-02],\n            [-9.3806e-02,  5.2417e-03, -1.4411e-02]],\n  \n           [[-2.6175e-02,  4.1200e-02,  5.7196e-02],\n            [-7.8570e-04, -1.5683e-02, -2.3434e-02],\n            [ 2.1435e-02,  2.2791e-02,  4.6291e-02]],\n  \n           [[-8.0804e-02,  3.7061e-02, -3.3381e-02],\n            [ 3.4563e-02, -4.9236e-02,  5.5186e-02],\n            [ 6.3069e-02, -1.0868e-01,  5.3660e-02]]],\n  \n  \n          [[[ 1.2605e-01,  6.6433e-02,  8.8640e-02],\n            [ 8.5893e-03, -3.3182e-02,  6.5961e-02],\n            [ 7.2643e-03, -1.8267e-02, -1.8358e-02]],\n  \n           [[ 2.4428e-02,  8.6418e-03, -5.2183e-04],\n            [ 6.5911e-02, -7.1729e-02, -1.8189e-02],\n            [-2.8079e-02,  2.0210e-02, -4.4632e-02]],\n  \n           [[-6.8029e-02, -8.9508e-02,  6.0479e-02],\n            [-4.0031e-02,  3.7867e-02, -8.2941e-02],\n            [-1.1101e-01,  2.2200e-02,  3.4795e-03]],\n  \n           ...,\n  \n           [[-8.1502e-04, -1.7430e-02, -1.3901e-02],\n            [-6.0020e-02, -3.3643e-02, -1.5537e-02],\n            [ 5.1050e-03,  9.4597e-02, -2.7701e-02]],\n  \n           [[-7.1083e-03,  6.4714e-02, -1.9855e-02],\n            [ 6.6565e-02,  1.0231e-01,  3.2664e-02],\n            [-9.1783e-02,  6.9543e-02, -2.8385e-02]],\n  \n           [[ 1.5205e-02,  9.6691e-02,  4.7726e-02],\n            [-2.0648e-02, -8.0649e-02, -1.5861e-01],\n            [-3.9811e-02,  7.8259e-02,  2.6619e-02]]]], requires_grad=True)),\n ('layer1.2.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer1.2.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.2.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0306]],\n  \n           [[ 0.0725]],\n  \n           [[ 0.0381]],\n  \n           ...,\n  \n           [[ 0.0420]],\n  \n           [[ 0.0278]],\n  \n           [[ 0.0542]]],\n  \n  \n          [[[ 0.0608]],\n  \n           [[ 0.0121]],\n  \n           [[ 0.0613]],\n  \n           ...,\n  \n           [[ 0.0566]],\n  \n           [[-0.0026]],\n  \n           [[-0.1931]]],\n  \n  \n          [[[-0.0136]],\n  \n           [[-0.1026]],\n  \n           [[ 0.0474]],\n  \n           ...,\n  \n           [[ 0.1794]],\n  \n           [[-0.0550]],\n  \n           [[ 0.0323]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0182]],\n  \n           [[-0.0238]],\n  \n           [[ 0.0016]],\n  \n           ...,\n  \n           [[ 0.0263]],\n  \n           [[ 0.0003]],\n  \n           [[ 0.0154]]],\n  \n  \n          [[[ 0.0377]],\n  \n           [[ 0.1148]],\n  \n           [[ 0.1470]],\n  \n           ...,\n  \n           [[ 0.1437]],\n  \n           [[-0.0267]],\n  \n           [[-0.3001]]],\n  \n  \n          [[[-0.1186]],\n  \n           [[ 0.1915]],\n  \n           [[-0.1796]],\n  \n           ...,\n  \n           [[-0.1408]],\n  \n           [[ 0.1165]],\n  \n           [[ 0.0756]]]], requires_grad=True)),\n ('layer1.2.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer1.2.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer2.0.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0222]],\n  \n           [[ 0.2770]],\n  \n           [[ 0.1094]],\n  \n           ...,\n  \n           [[ 0.1907]],\n  \n           [[-0.0701]],\n  \n           [[-0.1194]]],\n  \n  \n          [[[-0.0121]],\n  \n           [[ 0.0138]],\n  \n           [[ 0.2060]],\n  \n           ...,\n  \n           [[-0.2114]],\n  \n           [[ 0.0572]],\n  \n           [[-0.0050]]],\n  \n  \n          [[[ 0.1011]],\n  \n           [[-0.1271]],\n  \n           [[-0.1459]],\n  \n           ...,\n  \n           [[-0.1627]],\n  \n           [[-0.1899]],\n  \n           [[ 0.1883]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0880]],\n  \n           [[ 0.1103]],\n  \n           [[-0.0390]],\n  \n           ...,\n  \n           [[-0.1149]],\n  \n           [[-0.0555]],\n  \n           [[-0.1955]]],\n  \n  \n          [[[ 0.1186]],\n  \n           [[ 0.1267]],\n  \n           [[ 0.0955]],\n  \n           ...,\n  \n           [[ 0.0880]],\n  \n           [[ 0.0887]],\n  \n           [[-0.2007]]],\n  \n  \n          [[[ 0.0411]],\n  \n           [[ 0.0024]],\n  \n           [[ 0.1000]],\n  \n           ...,\n  \n           [[-0.0377]],\n  \n           [[-0.0060]],\n  \n           [[-0.0530]]]], requires_grad=True)),\n ('layer2.0.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.0.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.0.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 0.0459, -0.0034, -0.0008],\n            [-0.0396, -0.0395,  0.0005],\n            [-0.0316, -0.0243, -0.0672]],\n  \n           [[ 0.0192, -0.0147,  0.0301],\n            [ 0.1093,  0.0164,  0.0399],\n            [ 0.0598,  0.0002,  0.0135]],\n  \n           [[ 0.0201,  0.0344,  0.0135],\n            [ 0.0144, -0.0456,  0.0735],\n            [-0.0339,  0.0573,  0.0477]],\n  \n           ...,\n  \n           [[ 0.0435, -0.0236, -0.0284],\n            [ 0.0211,  0.0043,  0.0005],\n            [-0.0228, -0.0126,  0.0513]],\n  \n           [[ 0.0647, -0.0524, -0.0100],\n            [ 0.0410,  0.0557,  0.0147],\n            [-0.0017,  0.0921,  0.0840]],\n  \n           [[ 0.0164,  0.1197, -0.0890],\n            [-0.0572, -0.0042, -0.0885],\n            [-0.0037,  0.0158, -0.0699]]],\n  \n  \n          [[[ 0.0265,  0.0215, -0.0373],\n            [ 0.0767,  0.0298,  0.0485],\n            [ 0.0372, -0.0689, -0.0186]],\n  \n           [[-0.0938,  0.0625,  0.0155],\n            [ 0.0498,  0.0062,  0.0048],\n            [-0.0567,  0.0217, -0.0220]],\n  \n           [[ 0.0081, -0.0235,  0.0215],\n            [-0.0356, -0.0169, -0.0391],\n            [ 0.0068,  0.0768,  0.0498]],\n  \n           ...,\n  \n           [[-0.0472,  0.0282,  0.0278],\n            [-0.0012, -0.0464,  0.0440],\n            [ 0.0007, -0.0512,  0.0297]],\n  \n           [[-0.0236,  0.0265,  0.0195],\n            [-0.0392, -0.0330,  0.0327],\n            [-0.0023,  0.0147,  0.0240]],\n  \n           [[ 0.0101,  0.0304, -0.0005],\n            [ 0.0485, -0.0303, -0.0300],\n            [-0.0166, -0.0461,  0.0785]]],\n  \n  \n          [[[-0.0284,  0.0963,  0.0404],\n            [-0.0235, -0.0824, -0.0377],\n            [-0.0293, -0.0681, -0.0122]],\n  \n           [[ 0.0284, -0.0063,  0.0279],\n            [ 0.0388, -0.0102, -0.0715],\n            [-0.0182, -0.0489, -0.0375]],\n  \n           [[-0.0382, -0.0039,  0.0391],\n            [ 0.0471, -0.0328, -0.0249],\n            [ 0.0348,  0.0374,  0.0814]],\n  \n           ...,\n  \n           [[-0.0059,  0.0133,  0.0117],\n            [ 0.0089,  0.0103, -0.0292],\n            [-0.0197, -0.0197, -0.0087]],\n  \n           [[ 0.0375, -0.0097, -0.0687],\n            [-0.0213,  0.0612,  0.0328],\n            [-0.0070, -0.0330, -0.0250]],\n  \n           [[-0.0470, -0.0106, -0.0020],\n            [-0.0389,  0.0292,  0.0454],\n            [ 0.0285,  0.0224,  0.0723]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0314, -0.0212, -0.0029],\n            [ 0.0197,  0.0302, -0.0148],\n            [ 0.0212, -0.0400,  0.0698]],\n  \n           [[ 0.0419,  0.0249,  0.0140],\n            [ 0.0248,  0.0332, -0.0442],\n            [ 0.0208,  0.0679, -0.0792]],\n  \n           [[ 0.0793, -0.0401, -0.0305],\n            [ 0.0447,  0.0551,  0.0005],\n            [-0.0061,  0.0462, -0.0102]],\n  \n           ...,\n  \n           [[-0.0075,  0.0076, -0.0007],\n            [-0.0213, -0.0259, -0.0432],\n            [ 0.0091, -0.0829, -0.0728]],\n  \n           [[ 0.0095, -0.0104,  0.0188],\n            [-0.0384,  0.0506, -0.0284],\n            [-0.0421,  0.0226, -0.0147]],\n  \n           [[-0.0179,  0.0427,  0.0326],\n            [-0.0329, -0.1014,  0.0071],\n            [-0.0402,  0.0005,  0.0096]]],\n  \n  \n          [[[-0.0064,  0.0191, -0.0647],\n            [-0.0410, -0.0393,  0.0005],\n            [-0.0262,  0.0384,  0.0445]],\n  \n           [[ 0.0269, -0.0841,  0.0206],\n            [ 0.0238, -0.0238, -0.0691],\n            [ 0.0919,  0.0441, -0.0491]],\n  \n           [[ 0.0330, -0.0181,  0.0003],\n            [-0.0159, -0.0187, -0.0862],\n            [ 0.0613,  0.0316,  0.0280]],\n  \n           ...,\n  \n           [[-0.0695,  0.0080,  0.0633],\n            [-0.0551, -0.0281, -0.0252],\n            [ 0.0252,  0.1216,  0.0565]],\n  \n           [[-0.0836, -0.0271, -0.0065],\n            [-0.0389,  0.0459, -0.0051],\n            [-0.0039,  0.0881, -0.0274]],\n  \n           [[-0.0313,  0.0383,  0.0551],\n            [-0.0350, -0.0206,  0.0670],\n            [-0.0388, -0.0122, -0.0261]]],\n  \n  \n          [[[ 0.0081, -0.0048,  0.0090],\n            [ 0.0304,  0.0288, -0.0414],\n            [ 0.1180,  0.0236, -0.0033]],\n  \n           [[-0.0795,  0.0286,  0.0035],\n            [-0.0153, -0.0263,  0.0210],\n            [ 0.0239,  0.0126, -0.0494]],\n  \n           [[ 0.0545,  0.0846, -0.0489],\n            [-0.0914,  0.0092,  0.0175],\n            [ 0.0086, -0.0188, -0.0282]],\n  \n           ...,\n  \n           [[-0.0406, -0.0584,  0.0323],\n            [ 0.0215,  0.0307,  0.0278],\n            [-0.0338, -0.0218, -0.0216]],\n  \n           [[-0.0008,  0.0049,  0.0406],\n            [-0.0054, -0.0384, -0.0151],\n            [ 0.0143,  0.0061,  0.0194]],\n  \n           [[-0.0364,  0.0218, -0.0532],\n            [ 0.0114, -0.0278,  0.0892],\n            [ 0.0109,  0.0297, -0.0421]]]], requires_grad=True)),\n ('layer2.0.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.0.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.0.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0322]],\n  \n           [[-0.0207]],\n  \n           [[ 0.0017]],\n  \n           ...,\n  \n           [[-0.0589]],\n  \n           [[-0.0791]],\n  \n           [[ 0.0407]]],\n  \n  \n          [[[-0.0468]],\n  \n           [[-0.1143]],\n  \n           [[-0.0532]],\n  \n           ...,\n  \n           [[ 0.0797]],\n  \n           [[ 0.0507]],\n  \n           [[ 0.0112]]],\n  \n  \n          [[[-0.0296]],\n  \n           [[ 0.1012]],\n  \n           [[-0.0236]],\n  \n           ...,\n  \n           [[ 0.0637]],\n  \n           [[ 0.0361]],\n  \n           [[-0.0102]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0948]],\n  \n           [[ 0.0369]],\n  \n           [[ 0.0102]],\n  \n           ...,\n  \n           [[ 0.0161]],\n  \n           [[-0.0379]],\n  \n           [[-0.0404]]],\n  \n  \n          [[[-0.0224]],\n  \n           [[-0.0473]],\n  \n           [[ 0.0513]],\n  \n           ...,\n  \n           [[-0.0477]],\n  \n           [[ 0.1113]],\n  \n           [[-0.0506]]],\n  \n  \n          [[[ 0.0291]],\n  \n           [[-0.0379]],\n  \n           [[-0.0768]],\n  \n           ...,\n  \n           [[ 0.0835]],\n  \n           [[ 0.0320]],\n  \n           [[ 0.0158]]]], requires_grad=True)),\n ('layer2.0.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.0.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.0.downsample.0.weight',\n  Parameter containing:\n  tensor([[[[ 0.0449]],\n  \n           [[-0.0063]],\n  \n           [[ 0.0182]],\n  \n           ...,\n  \n           [[-0.1253]],\n  \n           [[ 0.1364]],\n  \n           [[-0.0247]]],\n  \n  \n          [[[-0.0724]],\n  \n           [[ 0.0317]],\n  \n           [[ 0.0669]],\n  \n           ...,\n  \n           [[ 0.0403]],\n  \n           [[-0.0421]],\n  \n           [[-0.0267]]],\n  \n  \n          [[[-0.0560]],\n  \n           [[ 0.0098]],\n  \n           [[-0.0215]],\n  \n           ...,\n  \n           [[-0.1559]],\n  \n           [[-0.0150]],\n  \n           [[ 0.0436]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.1543]],\n  \n           [[ 0.0630]],\n  \n           [[ 0.0007]],\n  \n           ...,\n  \n           [[ 0.0226]],\n  \n           [[ 0.0238]],\n  \n           [[ 0.0149]]],\n  \n  \n          [[[ 0.0068]],\n  \n           [[-0.0364]],\n  \n           [[ 0.1170]],\n  \n           ...,\n  \n           [[-0.1112]],\n  \n           [[-0.0013]],\n  \n           [[-0.0032]]],\n  \n  \n          [[[-0.1066]],\n  \n           [[-0.0325]],\n  \n           [[-0.0539]],\n  \n           ...,\n  \n           [[ 0.0266]],\n  \n           [[ 0.0531]],\n  \n           [[-0.0026]]]], requires_grad=True)),\n ('layer2.0.downsample.1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer2.0.downsample.1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.1.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.1880]],\n  \n           [[-0.0538]],\n  \n           [[-0.2180]],\n  \n           ...,\n  \n           [[-0.1800]],\n  \n           [[-0.0178]],\n  \n           [[-0.1162]]],\n  \n  \n          [[[-0.1225]],\n  \n           [[ 0.2978]],\n  \n           [[ 0.1373]],\n  \n           ...,\n  \n           [[ 0.2007]],\n  \n           [[-0.0082]],\n  \n           [[-0.0192]]],\n  \n  \n          [[[-0.0777]],\n  \n           [[-0.0042]],\n  \n           [[-0.0100]],\n  \n           ...,\n  \n           [[-0.0537]],\n  \n           [[-0.2876]],\n  \n           [[-0.1438]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0339]],\n  \n           [[-0.1204]],\n  \n           [[ 0.0436]],\n  \n           ...,\n  \n           [[ 0.0552]],\n  \n           [[ 0.0879]],\n  \n           [[-0.0777]]],\n  \n  \n          [[[ 0.0013]],\n  \n           [[ 0.0958]],\n  \n           [[-0.0824]],\n  \n           ...,\n  \n           [[ 0.0171]],\n  \n           [[-0.2543]],\n  \n           [[-0.2877]]],\n  \n  \n          [[[ 0.0900]],\n  \n           [[-0.0857]],\n  \n           [[-0.0475]],\n  \n           ...,\n  \n           [[-0.0014]],\n  \n           [[ 0.0152]],\n  \n           [[-0.1122]]]], requires_grad=True)),\n ('layer2.1.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.1.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.1.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 0.0697, -0.0207,  0.0424],\n            [-0.0059,  0.0507, -0.0814],\n            [-0.0417, -0.0154,  0.0132]],\n  \n           [[-0.0258, -0.0465, -0.0457],\n            [ 0.0372, -0.0680, -0.0374],\n            [-0.0301, -0.0081, -0.0351]],\n  \n           [[-0.0193, -0.0110, -0.0002],\n            [-0.0390,  0.0357,  0.0522],\n            [-0.0389,  0.0299,  0.0367]],\n  \n           ...,\n  \n           [[-0.1265, -0.0454, -0.0114],\n            [ 0.0473,  0.0496, -0.0003],\n            [-0.0332,  0.0307, -0.0427]],\n  \n           [[-0.0225, -0.0058, -0.0834],\n            [ 0.0620,  0.0053, -0.0505],\n            [ 0.0710, -0.0108,  0.0254]],\n  \n           [[-0.0273, -0.0076, -0.0290],\n            [ 0.0241,  0.0014,  0.0442],\n            [-0.0790, -0.0174, -0.0151]]],\n  \n  \n          [[[-0.0019,  0.0191, -0.0472],\n            [ 0.0267,  0.0205,  0.0074],\n            [ 0.0248,  0.0130, -0.0469]],\n  \n           [[-0.0381, -0.0643,  0.0027],\n            [ 0.0258,  0.0631, -0.0204],\n            [-0.0046,  0.0454,  0.0085]],\n  \n           [[ 0.0311,  0.0633,  0.0191],\n            [-0.0072,  0.0212, -0.0019],\n            [-0.0466,  0.0196,  0.0286]],\n  \n           ...,\n  \n           [[-0.0078,  0.0295, -0.0582],\n            [ 0.0045,  0.0275, -0.0264],\n            [-0.0286,  0.0302, -0.0584]],\n  \n           [[ 0.0498,  0.0007, -0.0533],\n            [ 0.0945,  0.0666, -0.0047],\n            [ 0.1063,  0.0066,  0.0272]],\n  \n           [[ 0.0832, -0.0737,  0.0477],\n            [ 0.0309,  0.0125,  0.0192],\n            [ 0.0421, -0.0530,  0.0883]]],\n  \n  \n          [[[ 0.0365, -0.0164, -0.0016],\n            [ 0.0158, -0.0202,  0.0894],\n            [ 0.1136, -0.0163,  0.0893]],\n  \n           [[-0.0863, -0.0738, -0.0006],\n            [-0.0699,  0.0486,  0.0100],\n            [ 0.0218,  0.0386, -0.0201]],\n  \n           [[-0.0002, -0.0538, -0.0078],\n            [-0.0222,  0.0270,  0.0419],\n            [ 0.0388,  0.0020,  0.0384]],\n  \n           ...,\n  \n           [[ 0.0267, -0.0315, -0.0036],\n            [-0.0022, -0.0926, -0.0231],\n            [ 0.0106, -0.0011, -0.0009]],\n  \n           [[-0.0474, -0.0170,  0.0376],\n            [-0.0174,  0.0227, -0.0525],\n            [-0.0545,  0.0113,  0.0588]],\n  \n           [[ 0.0293, -0.0805,  0.0377],\n            [-0.0455, -0.0063,  0.0448],\n            [ 0.0345,  0.0225,  0.0062]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0295, -0.0362, -0.0464],\n            [ 0.0396, -0.0192,  0.0273],\n            [ 0.0292, -0.0852, -0.0028]],\n  \n           [[-0.0506, -0.0345, -0.0019],\n            [-0.0079, -0.1070,  0.0582],\n            [ 0.0787,  0.0382, -0.0125]],\n  \n           [[-0.0539,  0.0216, -0.0077],\n            [ 0.0373, -0.0785,  0.0263],\n            [ 0.0144, -0.0461, -0.0421]],\n  \n           ...,\n  \n           [[-0.0006, -0.0576, -0.0467],\n            [ 0.1064,  0.0119,  0.0112],\n            [ 0.0612,  0.0200,  0.0106]],\n  \n           [[-0.0252,  0.0513, -0.0062],\n            [ 0.0400, -0.0129, -0.0335],\n            [-0.0027, -0.0090, -0.0146]],\n  \n           [[-0.0305, -0.0492, -0.0475],\n            [ 0.0320,  0.0528, -0.0613],\n            [-0.0368, -0.0261,  0.0014]]],\n  \n  \n          [[[-0.0793, -0.0052,  0.0399],\n            [-0.0179, -0.0864, -0.0072],\n            [-0.0391,  0.0013, -0.0240]],\n  \n           [[-0.0257,  0.0225,  0.0207],\n            [-0.0646, -0.0004,  0.0172],\n            [-0.0188,  0.0042, -0.0151]],\n  \n           [[-0.0744,  0.0360, -0.0780],\n            [ 0.0219, -0.0330, -0.0226],\n            [ 0.0457, -0.0446,  0.0450]],\n  \n           ...,\n  \n           [[-0.0271,  0.0807, -0.0412],\n            [ 0.0576,  0.0096,  0.0036],\n            [ 0.0467,  0.0229, -0.0051]],\n  \n           [[ 0.0264, -0.0025,  0.0217],\n            [-0.0352,  0.0220,  0.0567],\n            [-0.0093, -0.0367,  0.0265]],\n  \n           [[ 0.0039,  0.0721,  0.0782],\n            [-0.0299, -0.0014, -0.0043],\n            [-0.0312,  0.0334,  0.0384]]],\n  \n  \n          [[[ 0.0109, -0.0010,  0.0662],\n            [ 0.0110, -0.0225,  0.0210],\n            [-0.0561,  0.0550,  0.0840]],\n  \n           [[-0.0490,  0.0154, -0.0172],\n            [-0.0187,  0.0792, -0.0032],\n            [-0.0927,  0.0010, -0.0085]],\n  \n           [[ 0.0193, -0.0105,  0.0865],\n            [ 0.0297,  0.0200,  0.0195],\n            [ 0.0324, -0.0830,  0.0709]],\n  \n           ...,\n  \n           [[ 0.1229, -0.0067,  0.0117],\n            [-0.0083, -0.0332,  0.0481],\n            [ 0.0130, -0.0207,  0.0043]],\n  \n           [[-0.0346, -0.0098, -0.0292],\n            [ 0.0550, -0.0351,  0.0193],\n            [-0.0082, -0.0281,  0.0923]],\n  \n           [[ 0.0032,  0.0028, -0.0271],\n            [-0.0214,  0.0660, -0.0070],\n            [-0.0941,  0.0405, -0.0653]]]], requires_grad=True)),\n ('layer2.1.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.1.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.1.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0560]],\n  \n           [[-0.1670]],\n  \n           [[-0.0752]],\n  \n           ...,\n  \n           [[ 0.1228]],\n  \n           [[ 0.0277]],\n  \n           [[-0.0409]]],\n  \n  \n          [[[ 0.1189]],\n  \n           [[-0.0691]],\n  \n           [[ 0.1002]],\n  \n           ...,\n  \n           [[-0.0274]],\n  \n           [[ 0.0465]],\n  \n           [[ 0.0040]]],\n  \n  \n          [[[-0.0044]],\n  \n           [[ 0.1422]],\n  \n           [[ 0.1064]],\n  \n           ...,\n  \n           [[-0.0558]],\n  \n           [[ 0.0187]],\n  \n           [[-0.0482]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0750]],\n  \n           [[-0.0004]],\n  \n           [[ 0.0955]],\n  \n           ...,\n  \n           [[-0.0196]],\n  \n           [[ 0.1160]],\n  \n           [[ 0.0207]]],\n  \n  \n          [[[-0.0193]],\n  \n           [[ 0.0702]],\n  \n           [[ 0.0392]],\n  \n           ...,\n  \n           [[ 0.0019]],\n  \n           [[ 0.0543]],\n  \n           [[ 0.0146]]],\n  \n  \n          [[[ 0.0219]],\n  \n           [[ 0.1291]],\n  \n           [[ 0.0310]],\n  \n           ...,\n  \n           [[-0.0031]],\n  \n           [[-0.0277]],\n  \n           [[-0.0419]]]], requires_grad=True)),\n ('layer2.1.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.1.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.2.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0384]],\n  \n           [[ 0.1299]],\n  \n           [[ 0.0837]],\n  \n           ...,\n  \n           [[ 0.0894]],\n  \n           [[-0.0530]],\n  \n           [[ 0.0014]]],\n  \n  \n          [[[ 0.0026]],\n  \n           [[-0.1249]],\n  \n           [[-0.1714]],\n  \n           ...,\n  \n           [[-0.0187]],\n  \n           [[ 0.0268]],\n  \n           [[ 0.0785]]],\n  \n  \n          [[[ 0.0553]],\n  \n           [[-0.0484]],\n  \n           [[-0.0217]],\n  \n           ...,\n  \n           [[-0.0288]],\n  \n           [[ 0.0248]],\n  \n           [[-0.0360]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0118]],\n  \n           [[ 0.0336]],\n  \n           [[-0.0985]],\n  \n           ...,\n  \n           [[ 0.1601]],\n  \n           [[-0.0942]],\n  \n           [[-0.1221]]],\n  \n  \n          [[[-0.2731]],\n  \n           [[-0.0064]],\n  \n           [[ 0.1716]],\n  \n           ...,\n  \n           [[ 0.0496]],\n  \n           [[-0.0848]],\n  \n           [[-0.2240]]],\n  \n  \n          [[[ 0.0347]],\n  \n           [[-0.0766]],\n  \n           [[-0.1705]],\n  \n           ...,\n  \n           [[-0.1784]],\n  \n           [[ 0.2293]],\n  \n           [[ 0.0554]]]], requires_grad=True)),\n ('layer2.2.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.2.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.2.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 0.0283, -0.0086, -0.0251],\n            [ 0.0379,  0.0064, -0.0373],\n            [ 0.0057,  0.0254,  0.0114]],\n  \n           [[-0.0042,  0.0328,  0.0400],\n            [-0.0651, -0.0091, -0.0554],\n            [ 0.0600,  0.0040, -0.0140]],\n  \n           [[-0.0101,  0.0116, -0.0645],\n            [ 0.0504, -0.0051,  0.0361],\n            [-0.0397,  0.0335,  0.0076]],\n  \n           ...,\n  \n           [[-0.0962, -0.0075,  0.0111],\n            [ 0.0313, -0.1087,  0.0211],\n            [-0.0724,  0.0631, -0.0254]],\n  \n           [[-0.0311,  0.0312, -0.0380],\n            [-0.0102,  0.0101,  0.0551],\n            [ 0.0347,  0.0022,  0.0444]],\n  \n           [[ 0.0020,  0.0667,  0.0252],\n            [-0.0106, -0.0077, -0.0387],\n            [-0.0065,  0.0677, -0.0109]]],\n  \n  \n          [[[-0.0504,  0.0417, -0.0186],\n            [-0.0630,  0.0230,  0.0427],\n            [-0.0606,  0.0079, -0.0260]],\n  \n           [[ 0.1051, -0.0155,  0.0787],\n            [ 0.0057, -0.0031,  0.0214],\n            [-0.0173,  0.0480, -0.0346]],\n  \n           [[ 0.0376, -0.0142, -0.0480],\n            [ 0.0172, -0.0145, -0.0020],\n            [-0.0701, -0.0420, -0.0118]],\n  \n           ...,\n  \n           [[-0.0969, -0.0152, -0.0184],\n            [ 0.0343, -0.0159,  0.0073],\n            [ 0.0414,  0.0106,  0.0629]],\n  \n           [[-0.0123, -0.0211, -0.0688],\n            [ 0.0630, -0.0037, -0.0073],\n            [ 0.0103, -0.0098, -0.0576]],\n  \n           [[ 0.0090, -0.1192,  0.0524],\n            [-0.0284, -0.0032,  0.0520],\n            [-0.0287, -0.0519, -0.0449]]],\n  \n  \n          [[[ 0.0029, -0.0154, -0.0670],\n            [-0.0440,  0.0343, -0.0365],\n            [ 0.0011, -0.0143,  0.0193]],\n  \n           [[-0.0285, -0.0358, -0.0228],\n            [ 0.0019,  0.0353,  0.0193],\n            [ 0.0438, -0.0138, -0.0229]],\n  \n           [[-0.0375,  0.0184,  0.0193],\n            [ 0.0020,  0.0197, -0.0362],\n            [-0.0333,  0.0209, -0.0349]],\n  \n           ...,\n  \n           [[-0.0027, -0.0524, -0.0370],\n            [-0.0046,  0.0526, -0.0067],\n            [ 0.0699, -0.0392,  0.0017]],\n  \n           [[ 0.0294,  0.0721,  0.0472],\n            [ 0.1187,  0.0225,  0.0294],\n            [ 0.0083, -0.0029,  0.0037]],\n  \n           [[ 0.0320, -0.0643,  0.0195],\n            [ 0.0228, -0.0562,  0.0468],\n            [ 0.0328,  0.0985,  0.0232]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0738, -0.0710,  0.0809],\n            [-0.0434, -0.0367,  0.0057],\n            [-0.0123, -0.0829, -0.0476]],\n  \n           [[ 0.0291,  0.0154,  0.0456],\n            [ 0.0028,  0.0174, -0.0142],\n            [-0.0321, -0.0878, -0.0010]],\n  \n           [[-0.0370,  0.0556, -0.1078],\n            [ 0.0193, -0.0553, -0.0638],\n            [ 0.0655,  0.0499, -0.0274]],\n  \n           ...,\n  \n           [[ 0.0242,  0.0300,  0.0074],\n            [ 0.0274,  0.1339, -0.0017],\n            [-0.0769,  0.0013, -0.0217]],\n  \n           [[-0.0350, -0.0242, -0.0117],\n            [ 0.0550,  0.0094, -0.0628],\n            [-0.0487, -0.0520,  0.0693]],\n  \n           [[-0.0263, -0.0601,  0.0016],\n            [ 0.0156,  0.0512, -0.0267],\n            [-0.0325,  0.0731,  0.0257]]],\n  \n  \n          [[[ 0.0271,  0.0446,  0.1001],\n            [-0.0054, -0.0047, -0.0456],\n            [ 0.0371, -0.0517,  0.1276]],\n  \n           [[-0.0575,  0.0331, -0.0117],\n            [-0.0017, -0.0364, -0.0445],\n            [ 0.0034,  0.0205, -0.0380]],\n  \n           [[-0.0173,  0.0739, -0.0237],\n            [-0.0091,  0.0360, -0.0104],\n            [-0.0084,  0.0452,  0.0560]],\n  \n           ...,\n  \n           [[ 0.0254,  0.0016, -0.0377],\n            [ 0.0135,  0.0478, -0.0337],\n            [-0.0415,  0.0179,  0.0147]],\n  \n           [[ 0.0534,  0.0890,  0.0614],\n            [ 0.0066, -0.0319,  0.0080],\n            [ 0.0287, -0.1043,  0.0457]],\n  \n           [[-0.0073,  0.0077, -0.0046],\n            [-0.0071, -0.0004, -0.0222],\n            [ 0.0181,  0.0302, -0.0201]]],\n  \n  \n          [[[-0.0232,  0.0041, -0.0263],\n            [-0.0091, -0.0048, -0.0287],\n            [ 0.0334,  0.0379,  0.0182]],\n  \n           [[-0.0761, -0.0387,  0.0591],\n            [-0.0179, -0.0439,  0.0401],\n            [ 0.0172, -0.0011,  0.0724]],\n  \n           [[-0.0144, -0.0295, -0.0064],\n            [ 0.0074,  0.0074, -0.0048],\n            [ 0.0519, -0.0245, -0.0054]],\n  \n           ...,\n  \n           [[ 0.0578, -0.0086, -0.0474],\n            [ 0.1343,  0.0067,  0.0305],\n            [ 0.0289, -0.0083,  0.0291]],\n  \n           [[ 0.0026,  0.0274,  0.0551],\n            [-0.0163, -0.0592,  0.0110],\n            [-0.0158,  0.0292, -0.0385]],\n  \n           [[-0.0391, -0.0098,  0.0770],\n            [-0.0342, -0.0147,  0.0069],\n            [-0.0116,  0.0462,  0.0754]]]], requires_grad=True)),\n ('layer2.2.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.2.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.2.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0363]],\n  \n           [[ 0.0423]],\n  \n           [[ 0.0530]],\n  \n           ...,\n  \n           [[-0.1036]],\n  \n           [[ 0.0047]],\n  \n           [[-0.0443]]],\n  \n  \n          [[[ 0.1291]],\n  \n           [[-0.0241]],\n  \n           [[-0.0485]],\n  \n           ...,\n  \n           [[-0.0795]],\n  \n           [[ 0.0691]],\n  \n           [[ 0.0883]]],\n  \n  \n          [[[-0.0461]],\n  \n           [[ 0.0429]],\n  \n           [[-0.0257]],\n  \n           ...,\n  \n           [[-0.1092]],\n  \n           [[-0.0334]],\n  \n           [[ 0.0070]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0474]],\n  \n           [[-0.0008]],\n  \n           [[-0.0384]],\n  \n           ...,\n  \n           [[-0.0271]],\n  \n           [[ 0.0627]],\n  \n           [[-0.0937]]],\n  \n  \n          [[[-0.0280]],\n  \n           [[-0.0236]],\n  \n           [[ 0.0240]],\n  \n           ...,\n  \n           [[-0.0514]],\n  \n           [[-0.1152]],\n  \n           [[ 0.0925]]],\n  \n  \n          [[[-0.0773]],\n  \n           [[-0.0597]],\n  \n           [[-0.0563]],\n  \n           ...,\n  \n           [[-0.0086]],\n  \n           [[ 0.0817]],\n  \n           [[-0.0288]]]], requires_grad=True)),\n ('layer2.2.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.2.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.3.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.1351]],\n  \n           [[-0.0165]],\n  \n           [[ 0.0364]],\n  \n           ...,\n  \n           [[ 0.1438]],\n  \n           [[ 0.1376]],\n  \n           [[ 0.0278]]],\n  \n  \n          [[[-0.0258]],\n  \n           [[-0.1271]],\n  \n           [[-0.0459]],\n  \n           ...,\n  \n           [[-0.0265]],\n  \n           [[-0.0015]],\n  \n           [[ 0.0292]]],\n  \n  \n          [[[ 0.0698]],\n  \n           [[ 0.0084]],\n  \n           [[ 0.0487]],\n  \n           ...,\n  \n           [[ 0.1092]],\n  \n           [[-0.0199]],\n  \n           [[-0.0309]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0391]],\n  \n           [[-0.0047]],\n  \n           [[ 0.0156]],\n  \n           ...,\n  \n           [[-0.1524]],\n  \n           [[-0.0501]],\n  \n           [[ 0.0380]]],\n  \n  \n          [[[ 0.0221]],\n  \n           [[ 0.1337]],\n  \n           [[ 0.0129]],\n  \n           ...,\n  \n           [[ 0.0332]],\n  \n           [[-0.0457]],\n  \n           [[ 0.0148]]],\n  \n  \n          [[[ 0.2395]],\n  \n           [[-0.0683]],\n  \n           [[-0.1396]],\n  \n           ...,\n  \n           [[-0.1805]],\n  \n           [[-0.1780]],\n  \n           [[ 0.1194]]]], requires_grad=True)),\n ('layer2.3.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.3.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.3.conv2.weight',\n  Parameter containing:\n  tensor([[[[-0.0073,  0.0520,  0.0548],\n            [ 0.0040,  0.0403,  0.0211],\n            [-0.0578,  0.0497,  0.0180]],\n  \n           [[ 0.0189,  0.0223,  0.0626],\n            [ 0.0312,  0.0362,  0.0353],\n            [-0.0422, -0.0257, -0.0790]],\n  \n           [[-0.0327, -0.0641, -0.0637],\n            [-0.0511, -0.0103,  0.0735],\n            [ 0.0605,  0.0090, -0.0300]],\n  \n           ...,\n  \n           [[-0.0444,  0.0627,  0.0221],\n            [-0.0393,  0.0187,  0.0006],\n            [-0.0093,  0.0199, -0.0565]],\n  \n           [[-0.0045,  0.0320,  0.0038],\n            [ 0.0013, -0.0049, -0.0257],\n            [-0.0081,  0.0301,  0.0079]],\n  \n           [[ 0.0277, -0.0151,  0.0886],\n            [-0.0095,  0.0878,  0.0358],\n            [ 0.0305, -0.0608, -0.0559]]],\n  \n  \n          [[[ 0.0010,  0.0141, -0.0225],\n            [-0.0602,  0.0477, -0.0099],\n            [ 0.0131,  0.0205, -0.0037]],\n  \n           [[-0.0206, -0.0359, -0.0222],\n            [-0.0702, -0.0584,  0.0468],\n            [ 0.0012, -0.0727,  0.0528]],\n  \n           [[-0.0695,  0.0403, -0.0044],\n            [ 0.0875,  0.0189, -0.0036],\n            [ 0.0501,  0.0033, -0.0536]],\n  \n           ...,\n  \n           [[ 0.0326,  0.0822, -0.0254],\n            [ 0.0017,  0.0460, -0.0290],\n            [-0.0508,  0.0129, -0.0162]],\n  \n           [[-0.0657, -0.0051, -0.0715],\n            [-0.0045, -0.0377, -0.0350],\n            [-0.0570, -0.0265, -0.0569]],\n  \n           [[ 0.0020, -0.0142, -0.0388],\n            [ 0.0353, -0.0005, -0.0785],\n            [ 0.0823,  0.0712,  0.0533]]],\n  \n  \n          [[[ 0.0128, -0.0433,  0.0540],\n            [-0.0595,  0.0259, -0.0504],\n            [-0.0454, -0.0084, -0.0523]],\n  \n           [[-0.0467, -0.0532, -0.0509],\n            [-0.0811,  0.0432, -0.0183],\n            [ 0.0647,  0.0472, -0.0170]],\n  \n           [[ 0.0592, -0.0101,  0.0119],\n            [-0.0629,  0.0740, -0.0644],\n            [-0.0277, -0.0129,  0.0175]],\n  \n           ...,\n  \n           [[-0.0039,  0.0180,  0.0230],\n            [ 0.0606, -0.0631, -0.0547],\n            [ 0.0126,  0.0264, -0.0034]],\n  \n           [[ 0.0862, -0.0133,  0.0045],\n            [-0.0723, -0.0645,  0.0223],\n            [-0.0339,  0.0375,  0.0730]],\n  \n           [[ 0.0141,  0.0063,  0.0485],\n            [ 0.0263,  0.0067, -0.0128],\n            [-0.0127, -0.0401,  0.0715]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0315, -0.0157, -0.0132],\n            [ 0.0126, -0.0006, -0.0056],\n            [ 0.0032, -0.0068,  0.0433]],\n  \n           [[ 0.0019,  0.0576,  0.0565],\n            [ 0.0407, -0.0128,  0.0261],\n            [-0.0354,  0.0435, -0.0025]],\n  \n           [[ 0.0320, -0.0250, -0.0632],\n            [-0.0817, -0.0318, -0.0892],\n            [ 0.0732,  0.0240, -0.0044]],\n  \n           ...,\n  \n           [[ 0.0030, -0.0015,  0.0322],\n            [-0.0061,  0.0394, -0.0152],\n            [ 0.0132,  0.0190,  0.0827]],\n  \n           [[-0.0328,  0.0581, -0.1011],\n            [-0.0410,  0.0429,  0.0073],\n            [ 0.0265, -0.0546, -0.0213]],\n  \n           [[-0.0333,  0.0039, -0.0616],\n            [-0.0069, -0.0302,  0.1083],\n            [ 0.0170,  0.0722,  0.0251]]],\n  \n  \n          [[[-0.0253,  0.0277,  0.0622],\n            [-0.0139,  0.0313,  0.0236],\n            [ 0.0577, -0.0536, -0.0909]],\n  \n           [[-0.0404,  0.0462,  0.0667],\n            [-0.0343, -0.0044, -0.0513],\n            [ 0.0028, -0.0044,  0.0319]],\n  \n           [[-0.0820, -0.0195,  0.0255],\n            [ 0.0844,  0.0114, -0.0194],\n            [-0.0471, -0.0683, -0.0249]],\n  \n           ...,\n  \n           [[-0.0422,  0.0309,  0.0158],\n            [ 0.0096,  0.0806, -0.0519],\n            [-0.0339, -0.0548, -0.0273]],\n  \n           [[ 0.0053, -0.0002, -0.0454],\n            [ 0.0202,  0.0161, -0.0682],\n            [ 0.0171, -0.0238,  0.0222]],\n  \n           [[-0.0357, -0.0057,  0.0194],\n            [-0.0502,  0.0502, -0.0157],\n            [-0.0215,  0.0491, -0.0350]]],\n  \n  \n          [[[ 0.0306,  0.0423, -0.0321],\n            [ 0.0886,  0.0168,  0.0512],\n            [-0.0074,  0.0351,  0.0989]],\n  \n           [[-0.0089, -0.0338,  0.0168],\n            [-0.0595, -0.0074,  0.0128],\n            [-0.0228,  0.0381, -0.0301]],\n  \n           [[ 0.0143, -0.0234,  0.0008],\n            [-0.0219,  0.0162,  0.0315],\n            [ 0.0114, -0.0047,  0.0579]],\n  \n           ...,\n  \n           [[-0.0654, -0.0516, -0.0372],\n            [ 0.0358,  0.0456,  0.0205],\n            [-0.0522,  0.0409,  0.0256]],\n  \n           [[ 0.0075, -0.0188, -0.0007],\n            [-0.0089,  0.0377, -0.0398],\n            [-0.0165, -0.0047,  0.0945]],\n  \n           [[ 0.0698,  0.0023,  0.0263],\n            [-0.0633,  0.0509,  0.0175],\n            [ 0.0969, -0.0350, -0.0396]]]], requires_grad=True)),\n ('layer2.3.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1.], requires_grad=True)),\n ('layer2.3.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.3.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0659]],\n  \n           [[-0.0745]],\n  \n           [[-0.0380]],\n  \n           ...,\n  \n           [[-0.0046]],\n  \n           [[-0.0849]],\n  \n           [[-0.0789]]],\n  \n  \n          [[[ 0.0376]],\n  \n           [[-0.0662]],\n  \n           [[ 0.0721]],\n  \n           ...,\n  \n           [[-0.0350]],\n  \n           [[-0.0621]],\n  \n           [[-0.0565]]],\n  \n  \n          [[[-0.0551]],\n  \n           [[ 0.0231]],\n  \n           [[ 0.0595]],\n  \n           ...,\n  \n           [[ 0.0934]],\n  \n           [[ 0.0222]],\n  \n           [[ 0.0139]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0666]],\n  \n           [[-0.0092]],\n  \n           [[-0.0635]],\n  \n           ...,\n  \n           [[-0.0297]],\n  \n           [[ 0.0985]],\n  \n           [[-0.0780]]],\n  \n  \n          [[[ 0.0325]],\n  \n           [[ 0.1274]],\n  \n           [[ 0.0181]],\n  \n           ...,\n  \n           [[ 0.0114]],\n  \n           [[ 0.0021]],\n  \n           [[-0.0567]]],\n  \n  \n          [[[-0.0292]],\n  \n           [[ 0.0744]],\n  \n           [[-0.0323]],\n  \n           ...,\n  \n           [[-0.1086]],\n  \n           [[ 0.0314]],\n  \n           [[ 0.0771]]]], requires_grad=True)),\n ('layer2.3.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer2.3.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer3.0.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.0845]],\n  \n           [[ 0.0102]],\n  \n           [[ 0.0012]],\n  \n           ...,\n  \n           [[-0.1678]],\n  \n           [[-0.0670]],\n  \n           [[ 0.0408]]],\n  \n  \n          [[[-0.0171]],\n  \n           [[ 0.0401]],\n  \n           [[-0.0633]],\n  \n           ...,\n  \n           [[ 0.0030]],\n  \n           [[-0.0883]],\n  \n           [[-0.0824]]],\n  \n  \n          [[[-0.0342]],\n  \n           [[ 0.0686]],\n  \n           [[-0.0105]],\n  \n           ...,\n  \n           [[ 0.1833]],\n  \n           [[-0.0033]],\n  \n           [[ 0.1529]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0085]],\n  \n           [[ 0.0042]],\n  \n           [[ 0.0311]],\n  \n           ...,\n  \n           [[ 0.1536]],\n  \n           [[-0.0888]],\n  \n           [[-0.0247]]],\n  \n  \n          [[[-0.0876]],\n  \n           [[-0.1136]],\n  \n           [[ 0.1498]],\n  \n           ...,\n  \n           [[ 0.1551]],\n  \n           [[ 0.0631]],\n  \n           [[ 0.0742]]],\n  \n  \n          [[[ 0.1216]],\n  \n           [[-0.0451]],\n  \n           [[-0.1252]],\n  \n           ...,\n  \n           [[ 0.2079]],\n  \n           [[ 0.0335]],\n  \n           [[-0.0232]]]], requires_grad=True)),\n ('layer3.0.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.0.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.0.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 0.0054, -0.0260, -0.0133],\n            [-0.0465, -0.0140, -0.0472],\n            [-0.0405,  0.0130,  0.0056]],\n  \n           [[ 0.0220,  0.0407, -0.0025],\n            [ 0.0508,  0.0268, -0.0190],\n            [ 0.0133,  0.0175,  0.0226]],\n  \n           [[ 0.0222, -0.0246,  0.0335],\n            [-0.0154, -0.0267, -0.0054],\n            [ 0.0276,  0.0136, -0.0168]],\n  \n           ...,\n  \n           [[-0.0054, -0.0477, -0.0600],\n            [-0.0005, -0.0187,  0.0213],\n            [ 0.0345,  0.0113, -0.0234]],\n  \n           [[ 0.0102,  0.0144, -0.0012],\n            [-0.0023,  0.0300, -0.0282],\n            [-0.0173, -0.0372,  0.0399]],\n  \n           [[ 0.0396, -0.0156,  0.0292],\n            [-0.0092, -0.0046,  0.0060],\n            [-0.0300, -0.0011, -0.0062]]],\n  \n  \n          [[[ 0.0107,  0.0487, -0.0230],\n            [ 0.0641,  0.0255,  0.0138],\n            [-0.0256, -0.0052, -0.0233]],\n  \n           [[ 0.0314, -0.0036, -0.0070],\n            [-0.0024, -0.0479,  0.0019],\n            [ 0.0074,  0.0068, -0.0608]],\n  \n           [[-0.0187, -0.0072,  0.0091],\n            [-0.0052,  0.0140, -0.0011],\n            [ 0.0081,  0.0171, -0.0402]],\n  \n           ...,\n  \n           [[ 0.0009, -0.0404,  0.0238],\n            [ 0.0034, -0.0412,  0.0418],\n            [ 0.0213,  0.0003,  0.0007]],\n  \n           [[-0.0129,  0.0403,  0.0498],\n            [-0.0462,  0.0423,  0.0315],\n            [-0.0382,  0.0109, -0.0138]],\n  \n           [[ 0.0412,  0.0036,  0.0171],\n            [ 0.0204, -0.0161,  0.0444],\n            [ 0.0504,  0.0005, -0.0174]]],\n  \n  \n          [[[-0.0145, -0.0327, -0.0086],\n            [-0.0458,  0.0330, -0.0358],\n            [-0.0094, -0.0360,  0.0425]],\n  \n           [[-0.0657,  0.0022,  0.0333],\n            [ 0.0245, -0.0385,  0.0436],\n            [ 0.0133, -0.0165, -0.0262]],\n  \n           [[ 0.0351, -0.0199,  0.0338],\n            [-0.0155, -0.0337,  0.0400],\n            [-0.0282, -0.0275, -0.0318]],\n  \n           ...,\n  \n           [[ 0.0278, -0.0112,  0.0329],\n            [ 0.0502, -0.0210,  0.0336],\n            [ 0.0124,  0.0124,  0.0531]],\n  \n           [[-0.0016,  0.0408,  0.0217],\n            [ 0.0054,  0.0088,  0.0254],\n            [ 0.0151, -0.0240,  0.0151]],\n  \n           [[ 0.0216, -0.0051,  0.0314],\n            [ 0.0353,  0.0032,  0.0223],\n            [-0.0267, -0.0099, -0.0234]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0210, -0.0026, -0.0172],\n            [-0.0343,  0.0718,  0.0502],\n            [-0.0075, -0.0264,  0.0600]],\n  \n           [[ 0.0394,  0.0233, -0.0046],\n            [ 0.0189,  0.0276, -0.0078],\n            [ 0.0299,  0.0374, -0.0133]],\n  \n           [[-0.0130,  0.0592, -0.0115],\n            [-0.0140,  0.0114, -0.0427],\n            [ 0.0023,  0.0143, -0.0040]],\n  \n           ...,\n  \n           [[ 0.0712, -0.0429,  0.0040],\n            [-0.0558, -0.0347,  0.0403],\n            [ 0.0137, -0.0193,  0.0369]],\n  \n           [[ 0.0283,  0.0017,  0.0157],\n            [ 0.0405,  0.0147,  0.0313],\n            [ 0.0185,  0.0040, -0.0031]],\n  \n           [[ 0.0103, -0.0265,  0.0189],\n            [-0.0207,  0.0019, -0.0503],\n            [ 0.0391,  0.0102, -0.0204]]],\n  \n  \n          [[[-0.0681,  0.0341,  0.0467],\n            [-0.0279, -0.0049,  0.0164],\n            [ 0.0105,  0.0570, -0.0042]],\n  \n           [[-0.0522, -0.0258, -0.0114],\n            [-0.0650,  0.0012, -0.0082],\n            [-0.0170,  0.0125,  0.0222]],\n  \n           [[-0.0010, -0.0199,  0.0739],\n            [ 0.0021, -0.0230,  0.0196],\n            [ 0.0085,  0.0183,  0.0127]],\n  \n           ...,\n  \n           [[-0.0054,  0.0165,  0.0731],\n            [ 0.0181, -0.0219,  0.0036],\n            [ 0.0333, -0.0221,  0.0187]],\n  \n           [[ 0.0410, -0.0073, -0.0103],\n            [-0.0206, -0.0148, -0.0488],\n            [-0.0231, -0.0477, -0.0302]],\n  \n           [[ 0.0091, -0.0188,  0.0103],\n            [-0.0295,  0.0108, -0.0184],\n            [-0.0366,  0.0315, -0.0020]]],\n  \n  \n          [[[-0.0297,  0.0054,  0.0063],\n            [-0.0064, -0.0519,  0.0216],\n            [-0.0371,  0.0482,  0.0331]],\n  \n           [[-0.0189, -0.0559, -0.0614],\n            [ 0.0205, -0.0413, -0.0164],\n            [-0.0263,  0.0695, -0.0307]],\n  \n           [[-0.0307, -0.0036,  0.0779],\n            [ 0.0348, -0.0336, -0.0329],\n            [ 0.0415,  0.0250, -0.0442]],\n  \n           ...,\n  \n           [[ 0.0043, -0.0138, -0.0417],\n            [-0.0288, -0.0027,  0.0415],\n            [ 0.0207,  0.0294, -0.0172]],\n  \n           [[ 0.0451,  0.0013, -0.0203],\n            [-0.0031, -0.0159,  0.0105],\n            [-0.0259,  0.0246, -0.0105]],\n  \n           [[-0.0049,  0.0738,  0.0085],\n            [ 0.0742, -0.0125,  0.0289],\n            [-0.0108,  0.0175,  0.0288]]]], requires_grad=True)),\n ('layer3.0.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.0.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.0.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0686]],\n  \n           [[-0.0283]],\n  \n           [[ 0.0097]],\n  \n           ...,\n  \n           [[ 0.0343]],\n  \n           [[-0.0661]],\n  \n           [[-0.0526]]],\n  \n  \n          [[[-0.0218]],\n  \n           [[-0.0132]],\n  \n           [[-0.0259]],\n  \n           ...,\n  \n           [[ 0.0197]],\n  \n           [[ 0.0984]],\n  \n           [[-0.0743]]],\n  \n  \n          [[[-0.0377]],\n  \n           [[-0.0789]],\n  \n           [[ 0.0198]],\n  \n           ...,\n  \n           [[ 0.0414]],\n  \n           [[-0.0558]],\n  \n           [[-0.0468]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0251]],\n  \n           [[-0.0536]],\n  \n           [[ 0.0254]],\n  \n           ...,\n  \n           [[ 0.0134]],\n  \n           [[-0.0759]],\n  \n           [[-0.0472]]],\n  \n  \n          [[[ 0.1082]],\n  \n           [[-0.0331]],\n  \n           [[ 0.0160]],\n  \n           ...,\n  \n           [[ 0.0087]],\n  \n           [[-0.0622]],\n  \n           [[-0.0590]]],\n  \n  \n          [[[ 0.0456]],\n  \n           [[ 0.0003]],\n  \n           [[ 0.0144]],\n  \n           ...,\n  \n           [[-0.0242]],\n  \n           [[-0.0136]],\n  \n           [[ 0.0080]]]], requires_grad=True)),\n ('layer3.0.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.0.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.0.downsample.0.weight',\n  Parameter containing:\n  tensor([[[[-0.0418]],\n  \n           [[-0.0208]],\n  \n           [[-0.0206]],\n  \n           ...,\n  \n           [[ 0.0169]],\n  \n           [[ 0.0099]],\n  \n           [[-0.0694]]],\n  \n  \n          [[[ 0.0275]],\n  \n           [[-0.0150]],\n  \n           [[ 0.0252]],\n  \n           ...,\n  \n           [[-0.0361]],\n  \n           [[ 0.0399]],\n  \n           [[ 0.0184]]],\n  \n  \n          [[[-0.0298]],\n  \n           [[-0.0082]],\n  \n           [[-0.0231]],\n  \n           ...,\n  \n           [[-0.0983]],\n  \n           [[-0.0073]],\n  \n           [[-0.0450]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0242]],\n  \n           [[-0.0659]],\n  \n           [[ 0.0390]],\n  \n           ...,\n  \n           [[-0.0169]],\n  \n           [[ 0.0065]],\n  \n           [[-0.0043]]],\n  \n  \n          [[[-0.0112]],\n  \n           [[ 0.0470]],\n  \n           [[-0.1091]],\n  \n           ...,\n  \n           [[-0.0556]],\n  \n           [[ 0.0504]],\n  \n           [[ 0.0536]]],\n  \n  \n          [[[ 0.0255]],\n  \n           [[-0.0391]],\n  \n           [[-0.0058]],\n  \n           ...,\n  \n           [[ 0.0461]],\n  \n           [[ 0.0224]],\n  \n           [[-0.0092]]]], requires_grad=True)),\n ('layer3.0.downsample.1.weight',\n  Parameter containing:\n  tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)),\n ('layer3.0.downsample.1.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.1.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0826]],\n  \n           [[ 0.0453]],\n  \n           [[-0.0682]],\n  \n           ...,\n  \n           [[-0.0298]],\n  \n           [[-0.1112]],\n  \n           [[ 0.0268]]],\n  \n  \n          [[[-0.1231]],\n  \n           [[ 0.0271]],\n  \n           [[ 0.0273]],\n  \n           ...,\n  \n           [[-0.0921]],\n  \n           [[-0.0240]],\n  \n           [[-0.1141]]],\n  \n  \n          [[[ 0.0228]],\n  \n           [[-0.0395]],\n  \n           [[-0.0694]],\n  \n           ...,\n  \n           [[ 0.0231]],\n  \n           [[ 0.0933]],\n  \n           [[-0.1104]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.1635]],\n  \n           [[-0.0216]],\n  \n           [[ 0.0367]],\n  \n           ...,\n  \n           [[-0.0508]],\n  \n           [[-0.0599]],\n  \n           [[-0.1261]]],\n  \n  \n          [[[-0.0671]],\n  \n           [[-0.0695]],\n  \n           [[ 0.0251]],\n  \n           ...,\n  \n           [[ 0.0852]],\n  \n           [[-0.0611]],\n  \n           [[ 0.1764]]],\n  \n  \n          [[[ 0.0020]],\n  \n           [[ 0.0262]],\n  \n           [[-0.0006]],\n  \n           ...,\n  \n           [[ 0.1464]],\n  \n           [[ 0.1554]],\n  \n           [[-0.0512]]]], requires_grad=True)),\n ('layer3.1.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.1.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.1.conv2.weight',\n  Parameter containing:\n  tensor([[[[-1.5791e-02, -3.6361e-02,  2.9642e-02],\n            [ 4.9116e-02, -2.8563e-03,  1.4321e-02],\n            [-3.7315e-02, -6.8900e-03, -2.3771e-02]],\n  \n           [[ 1.1476e-02,  7.3049e-02, -7.8586e-03],\n            [-6.6519e-03,  2.4986e-03,  1.2868e-02],\n            [-1.7880e-02,  3.4451e-02,  4.1237e-04]],\n  \n           [[-4.0590e-02,  4.2409e-03, -4.9967e-02],\n            [-3.6613e-02,  3.5440e-02, -3.6613e-03],\n            [ 9.1528e-03, -2.2696e-02, -3.6998e-02]],\n  \n           ...,\n  \n           [[ 3.0958e-02, -3.3448e-02, -4.8575e-02],\n            [ 7.4950e-03, -3.9495e-02,  1.4678e-02],\n            [ 2.3532e-02, -2.0511e-02, -8.3222e-05]],\n  \n           [[-3.5708e-02,  2.7490e-02, -2.7328e-03],\n            [ 2.3998e-02, -4.3742e-02, -6.2410e-02],\n            [-4.2915e-02,  2.9370e-02, -1.4159e-02]],\n  \n           [[-4.6807e-02, -1.4428e-02,  6.3704e-04],\n            [ 3.2704e-03, -4.0851e-02,  5.5261e-03],\n            [ 1.1192e-03, -5.5855e-02,  2.0870e-02]]],\n  \n  \n          [[[-2.5382e-02,  1.8127e-02, -1.8301e-02],\n            [ 1.4928e-02, -4.1463e-02, -5.0125e-02],\n            [-3.9927e-02, -2.2737e-02,  3.5403e-02]],\n  \n           [[ 3.9119e-02,  3.0162e-02,  9.6497e-03],\n            [ 5.0243e-03, -1.9404e-02, -4.6817e-02],\n            [-1.9546e-02,  1.5879e-02,  4.2258e-02]],\n  \n           [[ 1.5648e-02, -2.4402e-02,  2.8837e-02],\n            [ 6.7391e-02, -1.7979e-03,  4.9645e-02],\n            [-2.4509e-02,  2.5692e-02, -1.3416e-02]],\n  \n           ...,\n  \n           [[-4.5968e-02, -3.2238e-02,  2.5851e-02],\n            [-2.7755e-02, -2.5351e-03,  1.6848e-02],\n            [-1.1841e-02, -2.2025e-02, -1.0079e-02]],\n  \n           [[ 2.9096e-02, -5.6588e-03, -3.7430e-02],\n            [ 2.3139e-02, -6.1421e-03,  5.3547e-03],\n            [-3.5642e-02, -1.6272e-02,  1.2680e-03]],\n  \n           [[-4.5059e-02,  3.0672e-02,  4.1950e-02],\n            [-3.3552e-03, -2.1627e-02, -1.8304e-02],\n            [ 9.7815e-03, -4.3939e-02, -2.8075e-02]]],\n  \n  \n          [[[-1.4995e-02, -2.7266e-03, -7.6974e-04],\n            [ 1.1558e-02,  3.4109e-02,  3.4308e-02],\n            [-2.4849e-03,  3.8366e-02,  2.5413e-02]],\n  \n           [[ 2.0227e-02,  2.9320e-02, -4.8138e-02],\n            [-3.1481e-02, -2.1374e-03,  6.6066e-03],\n            [ 6.3341e-03, -2.5838e-02, -4.0143e-02]],\n  \n           [[ 3.6880e-02, -1.2170e-02, -2.0159e-02],\n            [-1.0906e-02, -4.5360e-02,  2.1248e-02],\n            [-2.9780e-02,  4.0236e-02, -2.9158e-02]],\n  \n           ...,\n  \n           [[ 2.1072e-02,  6.1683e-02, -3.5969e-02],\n            [ 2.0307e-02, -5.4780e-05, -3.4308e-02],\n            [ 5.5149e-03,  4.9749e-02, -3.7749e-02]],\n  \n           [[-2.1034e-02,  3.4420e-02,  7.1253e-03],\n            [ 2.7329e-02,  1.1216e-02, -2.1896e-03],\n            [ 3.3569e-02,  2.1730e-02, -3.6669e-03]],\n  \n           [[ 1.6961e-03,  3.6973e-02, -7.8023e-03],\n            [-5.6584e-02,  3.8111e-02, -2.6280e-02],\n            [ 6.2532e-02,  3.7533e-02,  3.0196e-03]]],\n  \n  \n          ...,\n  \n  \n          [[[ 3.9798e-02, -2.5715e-02, -6.7929e-03],\n            [-2.5687e-02, -2.9894e-02, -2.9725e-02],\n            [-3.3797e-02,  1.5095e-02, -8.6130e-05]],\n  \n           [[-2.6542e-02,  7.6514e-02, -1.1748e-02],\n            [ 1.8552e-02, -2.5801e-02, -3.7192e-02],\n            [ 5.4452e-03, -2.2453e-02, -7.8372e-02]],\n  \n           [[ 6.4529e-02, -2.0579e-02,  4.7808e-02],\n            [ 6.1085e-02,  1.8428e-02, -1.3527e-02],\n            [-7.4832e-03, -2.5188e-02, -2.2736e-02]],\n  \n           ...,\n  \n           [[ 2.4293e-02, -1.3172e-02,  1.1246e-02],\n            [-4.3928e-02, -7.9775e-04,  1.1975e-02],\n            [-2.3470e-03,  1.9584e-02,  3.1799e-02]],\n  \n           [[-2.1593e-02,  3.2263e-02,  4.5072e-02],\n            [ 3.0098e-02, -4.5587e-02, -2.7600e-02],\n            [-1.0876e-02, -5.4578e-02,  2.8274e-02]],\n  \n           [[-3.1220e-02, -1.4101e-03,  5.1790e-03],\n            [-5.8895e-02,  1.5052e-02,  6.7957e-04],\n            [-4.6669e-02,  4.0789e-03,  8.4386e-03]]],\n  \n  \n          [[[ 2.6818e-02, -3.3355e-02,  7.3886e-04],\n            [ 6.5702e-02, -2.5676e-02,  1.6238e-02],\n            [-5.5273e-02, -6.3716e-03, -1.3914e-02]],\n  \n           [[ 4.4987e-02, -2.3497e-03, -2.8143e-02],\n            [ 2.5779e-02,  1.8882e-02, -6.3830e-04],\n            [-1.8685e-03,  3.3612e-02,  9.3307e-04]],\n  \n           [[-2.6406e-02,  3.5219e-03,  3.4773e-02],\n            [ 6.8522e-02,  8.3221e-03,  9.4333e-03],\n            [-4.6144e-02, -2.4965e-02, -4.1377e-03]],\n  \n           ...,\n  \n           [[-7.3474e-02, -5.5011e-02,  1.3724e-02],\n            [ 1.0802e-01,  2.9984e-02,  1.5933e-02],\n            [ 3.7104e-02, -1.3888e-02, -4.6466e-02]],\n  \n           [[ 6.0294e-03,  2.2019e-02, -4.4663e-04],\n            [ 1.8679e-02,  4.0528e-02, -1.1986e-02],\n            [ 6.0598e-02, -1.6437e-02, -3.0676e-03]],\n  \n           [[-5.7882e-02, -3.4872e-02, -2.6283e-02],\n            [-7.6126e-03,  2.7011e-03, -8.8197e-02],\n            [-4.4718e-02, -1.0295e-02, -2.9779e-02]]],\n  \n  \n          [[[-5.5724e-03,  2.0327e-02, -1.6305e-02],\n            [ 4.9112e-02,  2.2103e-02,  1.1756e-02],\n            [-1.9243e-03,  1.9718e-02,  2.5022e-02]],\n  \n           [[-4.6871e-03, -4.9651e-03, -4.6574e-02],\n            [-1.7458e-03, -2.3545e-02,  2.3278e-02],\n            [-1.1229e-02,  1.1368e-02,  4.2316e-02]],\n  \n           [[-2.7840e-02,  2.2139e-02, -1.5531e-02],\n            [-1.1877e-02,  3.0877e-02, -1.0118e-02],\n            [-1.2845e-02, -3.0826e-02,  1.8834e-02]],\n  \n           ...,\n  \n           [[ 1.8303e-02,  9.5048e-03, -3.5328e-03],\n            [-1.1956e-03,  1.1421e-03, -3.7856e-02],\n            [-1.9882e-02,  3.0404e-02, -3.0646e-02]],\n  \n           [[ 1.1251e-02,  4.9189e-02, -2.7675e-02],\n            [ 1.1346e-02,  3.6158e-02, -3.9763e-02],\n            [ 5.1055e-03,  3.1012e-03, -2.1895e-03]],\n  \n           [[ 1.7851e-03, -3.0441e-03, -4.1181e-02],\n            [-2.7162e-02,  1.8100e-02, -3.1112e-02],\n            [ 3.1842e-02,  3.9658e-02,  5.6591e-03]]]], requires_grad=True)),\n ('layer3.1.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.1.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.1.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0280]],\n  \n           [[-0.0096]],\n  \n           [[-0.0810]],\n  \n           ...,\n  \n           [[-0.0509]],\n  \n           [[-0.0823]],\n  \n           [[-0.0097]]],\n  \n  \n          [[[-0.0252]],\n  \n           [[ 0.0282]],\n  \n           [[ 0.0197]],\n  \n           ...,\n  \n           [[ 0.0006]],\n  \n           [[-0.0064]],\n  \n           [[-0.0242]]],\n  \n  \n          [[[ 0.0306]],\n  \n           [[-0.0208]],\n  \n           [[ 0.0482]],\n  \n           ...,\n  \n           [[-0.0822]],\n  \n           [[ 0.0428]],\n  \n           [[-0.1039]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0301]],\n  \n           [[-0.0662]],\n  \n           [[ 0.0129]],\n  \n           ...,\n  \n           [[-0.0420]],\n  \n           [[-0.0155]],\n  \n           [[-0.0484]]],\n  \n  \n          [[[ 0.0248]],\n  \n           [[-0.0137]],\n  \n           [[ 0.0189]],\n  \n           ...,\n  \n           [[ 0.0184]],\n  \n           [[-0.0066]],\n  \n           [[ 0.0409]]],\n  \n  \n          [[[ 0.0030]],\n  \n           [[ 0.0016]],\n  \n           [[ 0.0436]],\n  \n           ...,\n  \n           [[-0.0076]],\n  \n           [[ 0.0018]],\n  \n           [[ 0.0217]]]], requires_grad=True)),\n ('layer3.1.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.1.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.2.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.0200]],\n  \n           [[-0.0951]],\n  \n           [[ 0.0186]],\n  \n           ...,\n  \n           [[ 0.0646]],\n  \n           [[-0.0765]],\n  \n           [[ 0.0731]]],\n  \n  \n          [[[ 0.0588]],\n  \n           [[ 0.0336]],\n  \n           [[ 0.0448]],\n  \n           ...,\n  \n           [[ 0.0682]],\n  \n           [[ 0.0963]],\n  \n           [[-0.0980]]],\n  \n  \n          [[[ 0.0687]],\n  \n           [[-0.0813]],\n  \n           [[ 0.0295]],\n  \n           ...,\n  \n           [[ 0.0353]],\n  \n           [[-0.0588]],\n  \n           [[ 0.0658]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0363]],\n  \n           [[-0.1020]],\n  \n           [[-0.0139]],\n  \n           ...,\n  \n           [[-0.0637]],\n  \n           [[ 0.0578]],\n  \n           [[ 0.0608]]],\n  \n  \n          [[[-0.0602]],\n  \n           [[-0.0510]],\n  \n           [[ 0.0497]],\n  \n           ...,\n  \n           [[-0.0003]],\n  \n           [[ 0.1302]],\n  \n           [[-0.0945]]],\n  \n  \n          [[[-0.1196]],\n  \n           [[-0.0980]],\n  \n           [[ 0.0038]],\n  \n           ...,\n  \n           [[-0.0067]],\n  \n           [[-0.0103]],\n  \n           [[-0.1775]]]], requires_grad=True)),\n ('layer3.2.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.2.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.2.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 8.2847e-03,  1.6677e-02,  1.4527e-02],\n            [ 8.5915e-03,  3.2973e-02,  3.9604e-02],\n            [-2.2169e-02,  2.9133e-02, -1.6774e-02]],\n  \n           [[ 6.0294e-02, -7.1674e-04,  5.5939e-02],\n            [-1.6964e-02,  3.9841e-02,  3.5852e-02],\n            [-5.3230e-02,  1.4253e-03, -1.3850e-02]],\n  \n           [[ 1.2236e-02,  2.6060e-02,  1.7525e-02],\n            [-1.4547e-02,  3.9906e-02,  4.2274e-02],\n            [ 6.9792e-03,  1.1519e-02,  2.4149e-02]],\n  \n           ...,\n  \n           [[-3.5614e-02,  3.8915e-02,  4.9838e-02],\n            [-2.1771e-03,  1.3593e-03,  1.4572e-02],\n            [ 7.1951e-03, -2.3047e-03, -3.0261e-02]],\n  \n           [[-9.3531e-02,  1.9502e-02,  2.6046e-03],\n            [-2.3474e-02, -1.7514e-02,  5.2145e-02],\n            [-9.6907e-03,  8.5393e-03,  3.5762e-03]],\n  \n           [[-5.7824e-02,  2.0054e-02,  7.4115e-03],\n            [ 2.0059e-02, -9.7816e-03,  2.3132e-02],\n            [ 8.6665e-03, -3.3068e-02,  3.7214e-02]]],\n  \n  \n          [[[-3.9028e-03, -3.0342e-02, -1.8745e-02],\n            [-4.9580e-02,  2.6396e-02, -4.0269e-02],\n            [ 6.8253e-03,  1.0314e-02,  1.0629e-02]],\n  \n           [[ 4.6180e-03,  8.9664e-03,  4.6218e-02],\n            [-1.8667e-02, -2.8731e-03, -2.9544e-02],\n            [ 2.3982e-03,  1.7261e-02,  2.0615e-02]],\n  \n           [[ 1.8091e-02, -5.8626e-02,  4.2836e-02],\n            [ 2.5931e-02, -2.0920e-02, -1.0538e-02],\n            [ 6.1750e-02,  1.1744e-02,  1.6510e-02]],\n  \n           ...,\n  \n           [[ 5.6912e-02, -3.3634e-02,  1.4816e-02],\n            [-1.0799e-02,  2.3500e-02, -6.9046e-03],\n            [ 1.4270e-02,  1.3251e-02, -3.0396e-02]],\n  \n           [[-1.5597e-02, -3.4988e-02, -9.9426e-03],\n            [ 1.0084e-02,  8.3798e-03,  3.8586e-02],\n            [-1.0141e-02,  3.6370e-02, -2.6960e-02]],\n  \n           [[ 3.6252e-02, -6.7878e-03, -9.2819e-03],\n            [-1.2435e-02, -1.6956e-02, -2.3464e-02],\n            [-2.8971e-02, -1.4484e-05,  3.7100e-02]]],\n  \n  \n          [[[-2.5472e-02, -2.5646e-02, -2.1588e-02],\n            [-1.3794e-02,  1.1192e-02,  6.3307e-02],\n            [-5.5175e-02,  2.9825e-02,  2.8346e-02]],\n  \n           [[ 4.7922e-03,  3.2381e-02, -1.5673e-03],\n            [ 4.4095e-02,  3.4130e-02, -1.7086e-02],\n            [-2.2049e-02, -5.9746e-02,  3.4687e-03]],\n  \n           [[ 6.0871e-02, -6.0833e-04, -2.8201e-02],\n            [ 4.7908e-03, -5.3538e-03,  1.3398e-02],\n            [ 3.1056e-02,  2.8855e-02, -3.5163e-02]],\n  \n           ...,\n  \n           [[ 1.0334e-02, -3.4671e-03, -1.7009e-03],\n            [-2.0201e-02, -1.5973e-02,  2.5389e-02],\n            [-1.7292e-02,  2.6464e-02, -2.5394e-02]],\n  \n           [[ 2.3953e-02,  6.2547e-03, -1.8064e-02],\n            [-3.7268e-02, -5.1822e-03, -2.7933e-02],\n            [ 1.8027e-02, -7.2723e-02,  4.3008e-02]],\n  \n           [[-4.5355e-02, -2.9464e-02, -8.1841e-02],\n            [ 6.5791e-02, -2.8992e-04,  3.5616e-03],\n            [ 9.5372e-03, -1.0692e-02,  1.9527e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 7.9685e-02,  2.1810e-02, -1.2611e-02],\n            [ 1.5779e-02, -1.1464e-02,  1.2943e-02],\n            [-1.7995e-02,  6.5461e-04,  1.9755e-02]],\n  \n           [[-9.7413e-03, -3.7014e-02, -2.2684e-02],\n            [-8.1871e-04,  2.7409e-02, -5.0674e-02],\n            [-4.7077e-02,  2.6810e-02,  3.0313e-02]],\n  \n           [[ 7.2511e-04,  5.1719e-02,  1.1566e-02],\n            [ 1.9188e-02,  1.9353e-02,  2.7462e-02],\n            [-3.1201e-02, -5.0842e-02, -1.8247e-02]],\n  \n           ...,\n  \n           [[-1.1175e-02, -9.0107e-03, -5.1530e-03],\n            [-2.3717e-03,  1.6803e-02, -6.9798e-03],\n            [-6.2794e-02, -2.5733e-03,  8.0564e-03]],\n  \n           [[ 1.8738e-02, -1.4322e-02, -3.4469e-03],\n            [-1.6180e-02, -2.6044e-02, -1.2323e-03],\n            [-2.8622e-02, -7.4329e-03,  3.1876e-02]],\n  \n           [[ 5.2834e-03, -5.2158e-02, -3.3926e-02],\n            [-4.6468e-02, -1.6522e-02, -3.6937e-02],\n            [ 2.2631e-02,  1.9870e-02,  4.0593e-02]]],\n  \n  \n          [[[ 1.1668e-02, -2.8983e-02,  2.4513e-02],\n            [ 2.0327e-02, -7.9667e-03, -8.2108e-04],\n            [-3.1045e-02, -5.6449e-02,  3.2075e-02]],\n  \n           [[ 1.0411e-02,  3.6846e-02,  7.3951e-03],\n            [ 2.1491e-02,  6.4708e-02, -2.9158e-02],\n            [-6.7655e-02, -2.1640e-02,  5.0303e-02]],\n  \n           [[ 4.8983e-02, -1.9326e-02,  1.9924e-02],\n            [-6.5550e-03, -1.5009e-03, -4.5588e-02],\n            [ 2.6072e-02,  6.3135e-03, -5.3702e-02]],\n  \n           ...,\n  \n           [[-3.1809e-02,  1.3491e-02, -3.8330e-03],\n            [-1.1270e-02, -1.9763e-03, -2.2435e-02],\n            [-2.6880e-02,  2.4187e-03,  5.1126e-02]],\n  \n           [[ 9.4548e-03, -3.6026e-02,  1.1095e-02],\n            [-1.4757e-02, -4.6296e-02,  2.3856e-02],\n            [ 4.1071e-02,  1.4884e-03, -1.1488e-02]],\n  \n           [[ 9.8374e-03,  3.3745e-02,  1.5055e-02],\n            [ 1.5424e-03,  2.4750e-02, -2.0943e-03],\n            [-2.7401e-02,  2.8452e-02, -6.6456e-03]]],\n  \n  \n          [[[-2.9554e-02,  3.1573e-02, -2.3323e-02],\n            [ 3.2860e-02, -1.2010e-02,  1.3053e-02],\n            [-1.4563e-02,  9.4927e-02,  8.4784e-03]],\n  \n           [[-3.6402e-02, -3.7391e-03, -3.7304e-03],\n            [ 2.9706e-02, -2.2957e-02, -4.3798e-02],\n            [-2.5277e-02, -1.9728e-02, -2.7168e-02]],\n  \n           [[-4.5600e-02, -2.5123e-02, -8.5362e-03],\n            [-1.6403e-02,  3.8167e-02, -2.2246e-02],\n            [-3.2903e-02,  1.8067e-02, -1.4901e-02]],\n  \n           ...,\n  \n           [[ 2.8575e-02, -4.0251e-02,  5.1598e-02],\n            [ 1.3479e-02, -4.8410e-03, -2.1953e-02],\n            [-2.7338e-03,  2.0802e-02, -5.1434e-03]],\n  \n           [[ 5.2211e-02,  4.5468e-03, -9.3347e-03],\n            [-2.8731e-02,  2.1231e-02, -8.6606e-03],\n            [-1.4195e-03, -6.0878e-03, -6.8584e-03]],\n  \n           [[-3.1122e-02, -2.3617e-03,  8.3305e-03],\n            [ 3.9178e-02,  9.4839e-03,  4.7496e-02],\n            [ 1.4776e-02, -5.1577e-02,  1.2084e-02]]]], requires_grad=True)),\n ('layer3.2.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.2.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.2.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0144]],\n  \n           [[-0.0766]],\n  \n           [[-0.0167]],\n  \n           ...,\n  \n           [[ 0.0017]],\n  \n           [[ 0.0279]],\n  \n           [[-0.0447]]],\n  \n  \n          [[[ 0.0170]],\n  \n           [[ 0.0075]],\n  \n           [[-0.0095]],\n  \n           ...,\n  \n           [[-0.0002]],\n  \n           [[ 0.0174]],\n  \n           [[ 0.0018]]],\n  \n  \n          [[[-0.0367]],\n  \n           [[-0.0542]],\n  \n           [[ 0.0189]],\n  \n           ...,\n  \n           [[ 0.0402]],\n  \n           [[ 0.0316]],\n  \n           [[ 0.0284]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0132]],\n  \n           [[ 0.0141]],\n  \n           [[ 0.0675]],\n  \n           ...,\n  \n           [[-0.0287]],\n  \n           [[ 0.0613]],\n  \n           [[ 0.0924]]],\n  \n  \n          [[[-0.1017]],\n  \n           [[ 0.0018]],\n  \n           [[-0.0132]],\n  \n           ...,\n  \n           [[ 0.0532]],\n  \n           [[-0.1004]],\n  \n           [[ 0.0086]]],\n  \n  \n          [[[ 0.0274]],\n  \n           [[ 0.0686]],\n  \n           [[ 0.0411]],\n  \n           ...,\n  \n           [[-0.0363]],\n  \n           [[-0.0396]],\n  \n           [[-0.0070]]]], requires_grad=True)),\n ('layer3.2.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.2.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.3.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0488]],\n  \n           [[-0.0243]],\n  \n           [[-0.0953]],\n  \n           ...,\n  \n           [[-0.0322]],\n  \n           [[-0.0006]],\n  \n           [[-0.0957]]],\n  \n  \n          [[[-0.0568]],\n  \n           [[ 0.0433]],\n  \n           [[-0.0657]],\n  \n           ...,\n  \n           [[-0.0415]],\n  \n           [[-0.0010]],\n  \n           [[ 0.0810]]],\n  \n  \n          [[[ 0.1400]],\n  \n           [[ 0.0629]],\n  \n           [[ 0.1938]],\n  \n           ...,\n  \n           [[ 0.1159]],\n  \n           [[ 0.0375]],\n  \n           [[ 0.0372]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.1325]],\n  \n           [[ 0.0417]],\n  \n           [[-0.0262]],\n  \n           ...,\n  \n           [[-0.0167]],\n  \n           [[ 0.0747]],\n  \n           [[ 0.1331]]],\n  \n  \n          [[[-0.0194]],\n  \n           [[-0.0361]],\n  \n           [[-0.0088]],\n  \n           ...,\n  \n           [[ 0.0381]],\n  \n           [[ 0.0449]],\n  \n           [[ 0.0604]]],\n  \n  \n          [[[-0.0150]],\n  \n           [[-0.1971]],\n  \n           [[-0.0012]],\n  \n           ...,\n  \n           [[-0.1198]],\n  \n           [[-0.1358]],\n  \n           [[-0.0544]]]], requires_grad=True)),\n ('layer3.3.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.3.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.3.conv2.weight',\n  Parameter containing:\n  tensor([[[[-1.7035e-02,  7.1942e-03, -2.3327e-02],\n            [ 3.0909e-02, -1.5759e-02, -2.3324e-02],\n            [-4.2068e-02,  2.5518e-02,  1.0073e-03]],\n  \n           [[-3.2041e-02, -3.4009e-02,  2.2773e-03],\n            [-1.1814e-03,  2.7857e-02, -2.1206e-03],\n            [ 1.4320e-02, -1.8606e-02,  1.5336e-02]],\n  \n           [[-3.9873e-02, -9.1911e-02,  1.8274e-02],\n            [ 1.7043e-02, -1.7755e-02,  1.6855e-02],\n            [-2.9968e-02,  2.0778e-03, -1.6478e-02]],\n  \n           ...,\n  \n           [[ 6.2308e-03,  4.4974e-03,  1.6540e-03],\n            [-3.1207e-04, -2.8205e-02, -1.2350e-02],\n            [-4.7715e-02,  4.8100e-02,  2.9551e-02]],\n  \n           [[ 4.1786e-02,  2.6159e-02,  3.3757e-05],\n            [-1.9367e-03, -5.1768e-02, -2.2192e-02],\n            [-4.4027e-02,  4.4060e-03,  5.0508e-03]],\n  \n           [[ 8.0665e-03,  8.1101e-03, -2.4044e-02],\n            [ 9.0603e-02,  2.6511e-02,  1.3938e-02],\n            [ 6.0320e-02,  3.4512e-02,  1.7849e-02]]],\n  \n  \n          [[[-4.5262e-03, -2.4455e-02, -4.6461e-03],\n            [ 8.6930e-03, -3.7523e-02, -5.4648e-02],\n            [-1.1002e-02,  1.0499e-02,  5.3224e-03]],\n  \n           [[ 2.7643e-02,  6.7480e-02,  2.0328e-02],\n            [-2.5531e-02,  5.3490e-03, -1.1315e-03],\n            [ 3.4711e-02,  5.3466e-03,  4.2625e-02]],\n  \n           [[-5.5408e-02,  3.7122e-02,  3.8803e-03],\n            [-7.6885e-03,  1.8007e-02,  6.5030e-02],\n            [ 2.5908e-02,  1.4660e-02,  1.3991e-02]],\n  \n           ...,\n  \n           [[ 4.5448e-02, -3.2369e-02,  1.1668e-02],\n            [ 3.6233e-02,  1.4623e-02,  7.5676e-03],\n            [-2.7893e-02, -1.9312e-02,  3.4560e-02]],\n  \n           [[ 1.9561e-02,  8.9970e-03,  3.8577e-02],\n            [ 1.3902e-02,  8.7593e-03,  2.5725e-02],\n            [-5.0444e-02, -1.2465e-02, -1.6791e-02]],\n  \n           [[-3.4285e-02, -3.7859e-02, -7.1149e-03],\n            [-2.8030e-02, -6.5988e-03,  1.1789e-02],\n            [ 1.9973e-02,  1.3128e-02,  3.1544e-03]]],\n  \n  \n          [[[ 2.5615e-02,  1.0154e-02, -2.3357e-02],\n            [ 1.2082e-02, -1.0405e-02,  9.1418e-02],\n            [ 4.5012e-02,  3.9455e-03,  4.8355e-03]],\n  \n           [[ 6.4426e-03,  3.4305e-02, -5.1241e-02],\n            [-1.9072e-02,  5.6626e-02, -9.7465e-03],\n            [-1.6924e-02, -1.7575e-03, -5.0027e-02]],\n  \n           [[ 3.5558e-02, -9.8706e-02, -2.6702e-03],\n            [-3.5161e-02,  4.7312e-02,  6.4126e-04],\n            [-1.0879e-02, -2.1216e-03, -4.9678e-02]],\n  \n           ...,\n  \n           [[-8.8431e-03,  2.0539e-02,  4.1600e-02],\n            [-3.6894e-02,  1.4730e-02,  7.6153e-02],\n            [-1.3843e-02, -3.8007e-02, -5.1604e-03]],\n  \n           [[ 5.7732e-02,  1.3151e-02,  1.9315e-02],\n            [ 4.6730e-02, -4.4377e-04, -1.0353e-03],\n            [-2.1472e-02,  1.0628e-02, -9.6998e-03]],\n  \n           [[-3.5218e-02, -1.4437e-02, -3.3259e-03],\n            [-3.1088e-02,  3.3845e-02,  3.7010e-02],\n            [ 1.1174e-02,  2.2558e-02,  2.0674e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 2.5338e-02, -2.6722e-02, -8.1347e-03],\n            [ 1.2231e-03,  2.1782e-02, -4.9276e-02],\n            [ 1.1718e-02, -3.4569e-02, -2.3134e-02]],\n  \n           [[ 6.3636e-03, -4.6785e-02, -1.6028e-03],\n            [-2.7843e-02, -6.6190e-02, -3.0660e-02],\n            [ 5.2333e-02,  4.4412e-02,  5.4673e-02]],\n  \n           [[ 4.3816e-02,  1.5387e-02, -1.3446e-02],\n            [-2.1582e-04, -6.0563e-03,  2.0600e-02],\n            [ 2.2070e-02,  1.6775e-02, -6.0009e-03]],\n  \n           ...,\n  \n           [[-7.2384e-03,  1.2649e-03, -6.6799e-04],\n            [-4.5331e-02, -1.3192e-03, -2.7107e-02],\n            [ 3.7801e-02, -3.7307e-02, -3.4440e-02]],\n  \n           [[-6.8024e-03,  5.5347e-03, -1.6108e-02],\n            [-1.6065e-02,  1.2956e-02,  3.1415e-02],\n            [-3.7788e-02, -3.1853e-03,  8.8218e-03]],\n  \n           [[ 3.5222e-02, -1.8286e-02, -5.8837e-02],\n            [ 3.2023e-03,  4.7753e-02, -1.7863e-02],\n            [-2.6978e-03, -2.7018e-02,  1.1348e-02]]],\n  \n  \n          [[[ 9.4646e-03, -4.9642e-02, -1.4083e-02],\n            [-1.0439e-02,  3.7155e-03, -1.7208e-02],\n            [ 4.4904e-02,  1.2062e-02, -1.2025e-03]],\n  \n           [[-2.1972e-04, -1.9514e-02,  1.8675e-03],\n            [ 3.9539e-02, -1.5473e-02, -2.4104e-02],\n            [ 3.5305e-02, -2.2602e-02, -6.8348e-02]],\n  \n           [[ 1.4678e-02, -3.6212e-02, -4.3677e-02],\n            [ 2.9750e-02,  1.2638e-02,  2.7216e-02],\n            [ 5.3793e-03,  1.8831e-02, -3.7095e-02]],\n  \n           ...,\n  \n           [[ 5.4385e-02,  3.5083e-02, -1.3416e-02],\n            [-3.0418e-02, -2.1716e-02, -2.4747e-02],\n            [-7.4251e-03,  5.8676e-03,  9.7599e-03]],\n  \n           [[-3.6018e-02,  2.9550e-02, -4.3119e-02],\n            [ 8.5634e-03, -9.1419e-03, -7.5138e-03],\n            [ 1.6382e-02,  1.7247e-02, -3.1261e-02]],\n  \n           [[ 3.4712e-02, -3.8684e-03, -9.7017e-03],\n            [ 5.6648e-03,  1.0028e-02,  5.2526e-03],\n            [-5.8685e-02, -8.2147e-03,  1.2674e-02]]],\n  \n  \n          [[[-5.3166e-02, -4.8768e-02, -1.3591e-02],\n            [-2.5855e-02,  8.6810e-04, -2.0275e-02],\n            [ 1.8711e-02,  1.5382e-02, -5.1489e-02]],\n  \n           [[-1.1853e-02,  3.2730e-03, -1.4702e-02],\n            [-7.4826e-03, -7.2251e-03, -1.0603e-02],\n            [ 3.5157e-02, -4.1526e-02,  1.2648e-02]],\n  \n           [[-2.7885e-03, -4.7841e-04,  1.1337e-02],\n            [-1.6938e-03,  1.7197e-02,  5.8655e-03],\n            [-5.3049e-02,  4.3308e-02, -1.4599e-02]],\n  \n           ...,\n  \n           [[ 5.3726e-02, -4.4607e-02,  2.9851e-03],\n            [-4.1750e-03,  2.4736e-02, -4.1434e-02],\n            [-1.0675e-02, -3.2776e-02,  1.7287e-02]],\n  \n           [[-1.0569e-02,  1.8271e-02, -4.7659e-02],\n            [ 2.5124e-02, -7.7333e-03,  1.0467e-02],\n            [ 3.2057e-02,  1.7390e-02, -4.6390e-02]],\n  \n           [[-1.0176e-02, -2.4395e-03,  1.9234e-02],\n            [ 3.9036e-02, -3.5639e-02, -7.3514e-02],\n            [-1.5681e-03, -6.2660e-02, -1.1289e-02]]]], requires_grad=True)),\n ('layer3.3.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.3.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.3.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0740]],\n  \n           [[ 0.0006]],\n  \n           [[-0.0194]],\n  \n           ...,\n  \n           [[-0.0347]],\n  \n           [[ 0.0174]],\n  \n           [[-0.0092]]],\n  \n  \n          [[[-0.0247]],\n  \n           [[-0.0448]],\n  \n           [[ 0.0328]],\n  \n           ...,\n  \n           [[-0.0049]],\n  \n           [[ 0.0437]],\n  \n           [[-0.0303]]],\n  \n  \n          [[[ 0.0682]],\n  \n           [[ 0.0395]],\n  \n           [[ 0.0420]],\n  \n           ...,\n  \n           [[-0.1273]],\n  \n           [[-0.0295]],\n  \n           [[-0.0332]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0200]],\n  \n           [[ 0.0546]],\n  \n           [[-0.0362]],\n  \n           ...,\n  \n           [[ 0.0198]],\n  \n           [[-0.0488]],\n  \n           [[-0.0178]]],\n  \n  \n          [[[-0.0435]],\n  \n           [[ 0.0261]],\n  \n           [[ 0.0481]],\n  \n           ...,\n  \n           [[-0.0055]],\n  \n           [[-0.0137]],\n  \n           [[ 0.0312]]],\n  \n  \n          [[[ 0.0020]],\n  \n           [[ 0.0494]],\n  \n           [[ 0.0359]],\n  \n           ...,\n  \n           [[ 0.0071]],\n  \n           [[ 0.0292]],\n  \n           [[-0.0646]]]], requires_grad=True)),\n ('layer3.3.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.3.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.4.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0251]],\n  \n           [[-0.0959]],\n  \n           [[-0.0428]],\n  \n           ...,\n  \n           [[ 0.0545]],\n  \n           [[ 0.0474]],\n  \n           [[-0.0231]]],\n  \n  \n          [[[ 0.0412]],\n  \n           [[-0.1001]],\n  \n           [[ 0.0165]],\n  \n           ...,\n  \n           [[ 0.1040]],\n  \n           [[-0.0598]],\n  \n           [[-0.0018]]],\n  \n  \n          [[[-0.0410]],\n  \n           [[ 0.0863]],\n  \n           [[-0.0144]],\n  \n           ...,\n  \n           [[ 0.0507]],\n  \n           [[-0.0472]],\n  \n           [[ 0.0432]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0558]],\n  \n           [[-0.0153]],\n  \n           [[ 0.0689]],\n  \n           ...,\n  \n           [[-0.0202]],\n  \n           [[ 0.0411]],\n  \n           [[-0.0481]]],\n  \n  \n          [[[-0.1581]],\n  \n           [[-0.0546]],\n  \n           [[ 0.0222]],\n  \n           ...,\n  \n           [[ 0.1405]],\n  \n           [[ 0.0790]],\n  \n           [[ 0.1383]]],\n  \n  \n          [[[ 0.0294]],\n  \n           [[-0.0496]],\n  \n           [[-0.0059]],\n  \n           ...,\n  \n           [[ 0.0113]],\n  \n           [[-0.1224]],\n  \n           [[ 0.0432]]]], requires_grad=True)),\n ('layer3.4.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.4.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.4.conv2.weight',\n  Parameter containing:\n  tensor([[[[-1.6009e-03,  1.0269e-02, -5.2161e-02],\n            [ 4.0043e-02,  5.0708e-02,  3.5235e-02],\n            [-4.4591e-03,  5.7668e-02,  1.2324e-02]],\n  \n           [[ 1.7627e-02, -5.0328e-03,  3.8007e-02],\n            [ 5.7972e-03,  2.1237e-02,  1.4645e-02],\n            [-4.7255e-03, -3.0667e-02, -2.1673e-02]],\n  \n           [[ 4.2580e-02, -3.6451e-02, -2.9569e-02],\n            [ 3.6061e-02, -2.0741e-02, -1.8165e-02],\n            [ 1.2687e-02,  4.9119e-02,  1.5015e-02]],\n  \n           ...,\n  \n           [[-2.4219e-02, -9.8479e-03, -7.3977e-04],\n            [-5.5825e-03,  3.7482e-02,  9.6175e-02],\n            [-2.9165e-03, -1.0624e-02,  1.8222e-03]],\n  \n           [[-2.1274e-02,  2.4935e-02,  2.8950e-02],\n            [ 1.9929e-02, -1.7737e-03, -1.8487e-02],\n            [-4.3933e-02,  2.1108e-02, -4.5799e-02]],\n  \n           [[ 1.1021e-02,  1.3842e-02, -1.2138e-02],\n            [-1.2067e-02, -3.7539e-02,  1.2205e-02],\n            [-3.8640e-03,  1.6865e-02, -1.5869e-02]]],\n  \n  \n          [[[-1.8228e-02,  8.5102e-03, -4.2277e-02],\n            [ 2.7811e-02, -9.1877e-03, -9.5644e-03],\n            [ 4.9165e-02, -2.2988e-02, -2.8005e-02]],\n  \n           [[-2.4615e-02,  1.2243e-02, -1.7397e-02],\n            [-9.8779e-03, -1.8880e-02, -3.1017e-02],\n            [-5.1766e-03,  9.8683e-04, -2.7243e-02]],\n  \n           [[-2.0895e-02,  1.9797e-02, -2.2411e-02],\n            [ 4.9098e-02,  2.3675e-02,  3.6758e-02],\n            [ 1.2734e-02,  3.8140e-02,  1.9758e-02]],\n  \n           ...,\n  \n           [[ 1.6472e-02,  3.2317e-02,  2.5021e-02],\n            [-2.8711e-03, -4.5026e-03,  1.7441e-02],\n            [-1.1909e-02,  3.7979e-02,  1.5970e-02]],\n  \n           [[-6.0905e-02,  5.1312e-03, -9.7965e-03],\n            [ 8.7254e-03, -3.2012e-03, -2.3571e-02],\n            [ 7.9624e-03, -2.2770e-02, -6.2757e-02]],\n  \n           [[ 4.7039e-02, -2.2488e-02, -6.6792e-03],\n            [ 6.7790e-03,  4.0642e-02, -1.3390e-02],\n            [-3.8539e-02,  1.9785e-02, -2.8096e-02]]],\n  \n  \n          [[[ 5.2986e-03, -2.1664e-03,  3.4332e-03],\n            [-2.6189e-03,  1.5890e-02,  1.0145e-03],\n            [ 5.5392e-02,  2.1408e-02, -1.4123e-02]],\n  \n           [[-7.2157e-02, -3.6886e-02, -2.3648e-02],\n            [ 8.3747e-03,  2.3851e-02,  5.2880e-02],\n            [-6.5505e-03,  4.4400e-02, -1.0688e-02]],\n  \n           [[ 1.8727e-03, -1.2892e-02, -3.4563e-02],\n            [ 2.2497e-02,  3.0416e-02,  7.0525e-02],\n            [ 4.2641e-02, -3.7020e-02, -3.0178e-02]],\n  \n           ...,\n  \n           [[ 5.7191e-02,  3.1901e-02,  4.9941e-03],\n            [-2.8775e-02,  2.8710e-02,  4.5303e-03],\n            [-1.4885e-02, -1.9145e-02, -2.7643e-02]],\n  \n           [[ 4.5434e-02,  7.0119e-02,  2.6029e-02],\n            [-1.6961e-02, -7.6769e-03,  9.0082e-03],\n            [ 2.6719e-02,  2.9827e-02, -2.4014e-02]],\n  \n           [[ 3.0025e-02, -3.5443e-02, -1.6958e-02],\n            [ 3.8376e-02,  8.3631e-04,  9.9465e-06],\n            [-2.8835e-02, -2.2292e-02, -2.1455e-03]]],\n  \n  \n          ...,\n  \n  \n          [[[-2.4478e-03,  5.2327e-02, -1.5298e-02],\n            [ 3.0101e-02, -2.9548e-03, -1.0679e-02],\n            [-7.3549e-03, -7.6644e-03, -1.7683e-02]],\n  \n           [[-1.2216e-02,  1.4038e-02, -2.3639e-02],\n            [ 3.0317e-02, -4.1579e-02,  1.3884e-02],\n            [-6.9711e-03,  1.9289e-02,  8.7853e-03]],\n  \n           [[-2.6694e-02, -1.8092e-02, -4.2012e-02],\n            [-5.6319e-02, -1.3250e-03, -2.4169e-02],\n            [-2.7920e-03, -4.9812e-02,  6.0940e-03]],\n  \n           ...,\n  \n           [[-5.1009e-02,  1.3664e-03,  1.2903e-02],\n            [ 6.9633e-02, -2.9692e-02, -3.7569e-02],\n            [ 3.9885e-02,  9.6930e-03,  6.6237e-02]],\n  \n           [[ 2.0155e-02,  1.4155e-02, -7.7627e-03],\n            [-1.8187e-02, -4.0251e-02, -5.8297e-03],\n            [ 1.9117e-02, -3.6646e-02, -3.6978e-02]],\n  \n           [[ 2.1382e-03, -1.4589e-02, -4.1422e-03],\n            [ 1.9308e-02,  3.1649e-02, -8.0743e-02],\n            [ 4.4503e-03,  2.0663e-02, -7.0815e-03]]],\n  \n  \n          [[[-2.5216e-02, -2.2953e-02, -1.3140e-02],\n            [-1.6166e-02, -1.2077e-02, -1.1348e-02],\n            [ 1.8164e-02, -1.7068e-02, -5.5312e-03]],\n  \n           [[ 3.0465e-02,  9.5054e-03,  3.3812e-02],\n            [ 5.7187e-03, -6.4852e-02,  3.7219e-02],\n            [-6.3665e-02,  1.0682e-03,  7.9524e-03]],\n  \n           [[-1.7826e-02,  1.2793e-02, -4.0524e-02],\n            [-2.8849e-02, -3.3858e-02, -1.7214e-02],\n            [-9.2936e-03, -9.0694e-02, -3.7321e-02]],\n  \n           ...,\n  \n           [[ 9.3909e-03,  1.5924e-02,  1.3192e-02],\n            [ 1.8454e-02, -2.0455e-03, -5.9107e-03],\n            [ 4.5423e-03, -1.0603e-02, -4.8922e-02]],\n  \n           [[-3.7442e-02,  5.2821e-03,  4.7385e-02],\n            [ 4.8794e-02, -4.3371e-02, -1.0199e-02],\n            [ 2.6104e-02, -1.3963e-03, -8.6061e-03]],\n  \n           [[ 3.2018e-03, -5.4097e-02,  1.0782e-02],\n            [-3.4256e-02, -1.1275e-02,  4.7361e-02],\n            [ 1.7762e-02,  2.0964e-02,  1.8498e-02]]],\n  \n  \n          [[[-3.8928e-03, -2.7141e-03,  8.0282e-02],\n            [ 1.6840e-02,  2.1849e-02, -4.4947e-03],\n            [-2.5872e-03,  1.0124e-02,  2.5470e-02]],\n  \n           [[-4.5082e-02,  1.4184e-02,  6.2454e-02],\n            [ 1.8772e-02, -2.7898e-02,  3.7316e-02],\n            [ 1.5929e-02,  4.5841e-02,  1.2856e-03]],\n  \n           [[ 4.1949e-05, -4.5213e-03, -4.3752e-02],\n            [ 2.5881e-02,  3.6509e-02, -3.6787e-02],\n            [-7.6144e-04,  2.6140e-02, -7.2909e-03]],\n  \n           ...,\n  \n           [[ 2.7576e-02,  2.2081e-04,  4.4722e-02],\n            [ 1.4542e-02, -1.9347e-02, -8.7500e-03],\n            [-3.3666e-02, -8.7216e-03,  6.1050e-02]],\n  \n           [[ 4.8506e-02,  8.1524e-03, -3.0751e-02],\n            [-9.4473e-03,  4.5495e-02, -2.2727e-02],\n            [-1.4064e-02,  3.7462e-02, -3.3589e-02]],\n  \n           [[ 3.8455e-02,  2.5547e-02, -7.7607e-02],\n            [-2.1535e-02,  3.7851e-02, -1.8051e-02],\n            [-1.2138e-02, -1.1708e-02,  7.7128e-02]]]], requires_grad=True)),\n ('layer3.4.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.4.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.4.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0045]],\n  \n           [[ 0.0044]],\n  \n           [[-0.0911]],\n  \n           ...,\n  \n           [[-0.0347]],\n  \n           [[-0.0436]],\n  \n           [[ 0.0638]]],\n  \n  \n          [[[-0.0112]],\n  \n           [[ 0.0490]],\n  \n           [[ 0.0046]],\n  \n           ...,\n  \n           [[ 0.0429]],\n  \n           [[ 0.0371]],\n  \n           [[-0.0258]]],\n  \n  \n          [[[-0.0271]],\n  \n           [[-0.0352]],\n  \n           [[-0.0645]],\n  \n           ...,\n  \n           [[ 0.0979]],\n  \n           [[-0.0059]],\n  \n           [[-0.0179]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0250]],\n  \n           [[-0.0537]],\n  \n           [[-0.0432]],\n  \n           ...,\n  \n           [[-0.0911]],\n  \n           [[-0.0098]],\n  \n           [[-0.0308]]],\n  \n  \n          [[[-0.0220]],\n  \n           [[-0.0425]],\n  \n           [[ 0.0297]],\n  \n           ...,\n  \n           [[ 0.0403]],\n  \n           [[ 0.0201]],\n  \n           [[ 0.0108]]],\n  \n  \n          [[[ 0.0364]],\n  \n           [[-0.0380]],\n  \n           [[-0.0156]],\n  \n           ...,\n  \n           [[-0.0154]],\n  \n           [[-0.0092]],\n  \n           [[ 0.0012]]]], requires_grad=True)),\n ('layer3.4.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.4.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.5.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.0043]],\n  \n           [[ 0.0350]],\n  \n           [[ 0.0014]],\n  \n           ...,\n  \n           [[ 0.0885]],\n  \n           [[ 0.0438]],\n  \n           [[ 0.0069]]],\n  \n  \n          [[[ 0.0312]],\n  \n           [[ 0.0504]],\n  \n           [[-0.0351]],\n  \n           ...,\n  \n           [[-0.0128]],\n  \n           [[ 0.1635]],\n  \n           [[ 0.0118]]],\n  \n  \n          [[[-0.2543]],\n  \n           [[ 0.1250]],\n  \n           [[ 0.1887]],\n  \n           ...,\n  \n           [[ 0.0169]],\n  \n           [[ 0.0846]],\n  \n           [[-0.0082]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0547]],\n  \n           [[ 0.0112]],\n  \n           [[-0.0782]],\n  \n           ...,\n  \n           [[ 0.1330]],\n  \n           [[ 0.0309]],\n  \n           [[ 0.0876]]],\n  \n  \n          [[[-0.0116]],\n  \n           [[ 0.0339]],\n  \n           [[-0.1773]],\n  \n           ...,\n  \n           [[ 0.0444]],\n  \n           [[ 0.0096]],\n  \n           [[ 0.1220]]],\n  \n  \n          [[[ 0.1451]],\n  \n           [[-0.0023]],\n  \n           [[ 0.2502]],\n  \n           ...,\n  \n           [[ 0.0243]],\n  \n           [[ 0.0253]],\n  \n           [[-0.0036]]]], requires_grad=True)),\n ('layer3.5.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.5.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.5.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 2.6434e-02, -2.1836e-02, -1.1234e-02],\n            [-9.2392e-03, -2.2462e-02, -2.0102e-02],\n            [ 2.2414e-02,  5.0330e-03,  6.6964e-03]],\n  \n           [[ 1.4137e-02, -1.0181e-02, -1.3095e-02],\n            [ 5.3328e-02,  6.4189e-03,  5.4357e-02],\n            [-5.3178e-03, -1.9453e-04,  1.8373e-02]],\n  \n           [[ 4.0453e-02,  3.8967e-02, -1.7597e-02],\n            [ 3.0030e-03,  2.7744e-02,  3.4714e-02],\n            [ 2.8372e-02,  2.6899e-02, -4.4800e-03]],\n  \n           ...,\n  \n           [[-4.0310e-03,  2.1234e-02, -3.4657e-02],\n            [ 5.2988e-03,  1.5898e-02,  4.7074e-02],\n            [-1.9815e-02,  2.8434e-03,  2.2006e-02]],\n  \n           [[ 1.0875e-02, -1.6967e-02, -1.9532e-02],\n            [-4.0627e-02,  5.3548e-02, -4.6134e-02],\n            [-4.3328e-02, -3.8583e-03, -5.8635e-03]],\n  \n           [[ 1.4780e-02, -3.6662e-02, -3.4554e-02],\n            [ 6.2814e-02, -4.1860e-03,  6.5860e-02],\n            [ 4.0634e-02,  2.6404e-02,  1.5064e-02]]],\n  \n  \n          [[[-2.0236e-02,  9.2149e-03, -4.0874e-02],\n            [-3.3153e-02, -8.2559e-03,  4.0984e-02],\n            [-9.6066e-03,  1.7085e-02,  2.8705e-03]],\n  \n           [[ 1.9451e-02,  3.7758e-02, -1.4316e-02],\n            [-4.3537e-02, -2.0956e-02,  3.6915e-02],\n            [-2.2385e-02,  3.3081e-02, -4.8114e-02]],\n  \n           [[ 8.5790e-03, -1.5657e-02,  6.7200e-04],\n            [-4.1046e-02, -6.8384e-02, -7.5918e-02],\n            [-6.0541e-03,  7.8350e-02, -2.0818e-02]],\n  \n           ...,\n  \n           [[ 3.8658e-02,  5.2896e-03,  4.3779e-03],\n            [-2.7270e-04,  1.8343e-02, -3.5445e-02],\n            [ 2.0636e-02,  2.6610e-02,  2.4861e-02]],\n  \n           [[-5.4595e-02,  9.0047e-03, -3.9797e-02],\n            [ 1.2457e-02,  3.4872e-02, -6.6128e-05],\n            [-3.3244e-03, -2.1983e-02,  1.8678e-02]],\n  \n           [[-1.7539e-02,  1.9651e-02,  1.3256e-02],\n            [-1.0192e-02,  1.4562e-02, -1.1938e-02],\n            [-9.4854e-03,  3.0962e-02,  3.0916e-02]]],\n  \n  \n          [[[-1.0523e-02, -1.3421e-02, -1.8469e-02],\n            [ 1.8604e-02, -1.6417e-02, -7.9428e-03],\n            [ 2.4185e-02, -1.2071e-02, -1.8940e-02]],\n  \n           [[-1.4024e-02,  9.8398e-04,  2.4521e-02],\n            [ 1.6701e-02,  4.2594e-03,  2.7685e-03],\n            [ 1.5224e-02,  7.2711e-02,  7.4280e-03]],\n  \n           [[ 2.2856e-02,  1.0961e-02,  2.5747e-02],\n            [-5.4889e-02, -3.6458e-02, -3.4843e-02],\n            [-1.7421e-02, -4.4129e-04, -1.1286e-02]],\n  \n           ...,\n  \n           [[ 1.6951e-02,  3.0037e-02,  6.9573e-03],\n            [ 2.0069e-02, -4.4338e-02,  7.7577e-02],\n            [ 4.6790e-02, -2.1949e-02, -3.5002e-03]],\n  \n           [[-1.6753e-02,  2.6515e-02,  1.1000e-02],\n            [ 9.3577e-05,  4.5227e-02,  2.1505e-03],\n            [ 2.4821e-02,  3.4910e-02,  4.2795e-02]],\n  \n           [[ 2.3439e-02,  7.7976e-04, -7.4422e-03],\n            [ 1.3590e-02, -5.2847e-03, -7.2529e-02],\n            [-7.6659e-03, -2.2971e-03, -3.8417e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[-1.2381e-02, -8.4840e-03,  4.2581e-02],\n            [ 2.9181e-02,  1.8611e-02, -4.6999e-02],\n            [-1.2886e-02,  8.5311e-03,  8.8962e-03]],\n  \n           [[-4.0055e-03,  1.9318e-03, -2.8455e-03],\n            [ 7.4364e-03,  1.3394e-02,  3.2150e-02],\n            [-6.1572e-03,  6.0423e-03,  3.2564e-02]],\n  \n           [[-2.4173e-02,  2.2617e-02, -5.6635e-03],\n            [-7.6475e-02, -7.8061e-03, -3.7392e-02],\n            [ 6.2541e-04, -1.5019e-02,  4.4601e-02]],\n  \n           ...,\n  \n           [[ 1.8854e-02,  4.6594e-03,  4.2575e-02],\n            [-3.2127e-02,  3.9457e-02,  8.4578e-03],\n            [ 1.3317e-02,  1.1770e-03,  1.5734e-02]],\n  \n           [[-1.2903e-02, -2.4881e-02,  2.8543e-02],\n            [ 9.3455e-03,  2.5847e-02,  7.2611e-03],\n            [ 1.4907e-02, -3.8168e-02, -1.2744e-02]],\n  \n           [[-1.4446e-02,  2.7135e-02,  2.6066e-03],\n            [ 1.4309e-02, -1.3428e-02,  1.0472e-02],\n            [-3.1630e-02,  2.6150e-02,  1.5644e-02]]],\n  \n  \n          [[[ 1.9963e-03, -9.8211e-03,  5.2271e-02],\n            [ 9.1818e-03,  3.4334e-02,  1.0121e-02],\n            [ 2.7377e-02,  1.0128e-02, -3.7383e-02]],\n  \n           [[-4.0218e-03, -1.2025e-02, -2.3390e-02],\n            [ 9.1903e-03,  1.9955e-02, -1.5659e-02],\n            [ 1.2404e-02, -1.3599e-03,  2.1699e-02]],\n  \n           [[ 2.7179e-02,  7.3579e-03,  1.6134e-02],\n            [ 4.0107e-02,  4.0452e-02,  1.3144e-02],\n            [-4.6361e-02, -1.8972e-02, -1.0145e-02]],\n  \n           ...,\n  \n           [[ 1.9948e-02,  2.5877e-02, -2.9555e-02],\n            [-2.8426e-02, -3.3010e-02,  3.1103e-03],\n            [ 6.9286e-03,  5.1598e-02,  4.4639e-02]],\n  \n           [[ 2.7256e-02,  2.2442e-02,  6.6776e-02],\n            [ 2.8108e-02,  3.2509e-02, -3.1326e-02],\n            [ 5.3454e-02,  7.9991e-04,  3.6430e-02]],\n  \n           [[ 1.9641e-02, -5.8673e-03,  2.1618e-02],\n            [ 1.3525e-03,  2.2246e-02,  2.6140e-02],\n            [ 3.5949e-02,  3.2162e-02,  1.0413e-02]]],\n  \n  \n          [[[ 2.9142e-02, -6.8248e-03,  3.1984e-02],\n            [ 2.3306e-02, -1.9535e-02, -2.3457e-02],\n            [ 9.2808e-03, -2.5361e-02, -1.4000e-03]],\n  \n           [[ 2.4940e-02,  4.6259e-03, -1.6168e-02],\n            [ 3.3114e-02,  5.0440e-02, -3.0993e-02],\n            [ 5.6596e-02,  7.1922e-02,  8.3012e-04]],\n  \n           [[ 3.7307e-02,  5.3811e-02,  1.0921e-02],\n            [-4.1824e-03, -2.0072e-04, -4.2779e-02],\n            [-9.4249e-03, -2.5234e-03, -8.4463e-02]],\n  \n           ...,\n  \n           [[ 3.8850e-02, -2.5920e-02, -8.6630e-03],\n            [-2.9257e-02, -1.6580e-02, -1.1036e-02],\n            [-3.2739e-03,  4.8092e-02, -2.6990e-03]],\n  \n           [[-2.1638e-02, -2.6557e-02, -6.0524e-02],\n            [-5.2343e-02,  5.4182e-03, -2.1419e-02],\n            [-3.0394e-02, -3.8983e-02, -1.6648e-02]],\n  \n           [[-4.8174e-03, -1.9662e-02, -4.5180e-02],\n            [-4.0188e-02,  1.3924e-02, -2.0476e-02],\n            [ 3.9147e-02,  7.4245e-03,  4.7037e-02]]]], requires_grad=True)),\n ('layer3.5.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1.], requires_grad=True)),\n ('layer3.5.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n         requires_grad=True)),\n ('layer3.5.conv3.weight',\n  Parameter containing:\n  tensor([[[[-0.0615]],\n  \n           [[ 0.0263]],\n  \n           [[ 0.0758]],\n  \n           ...,\n  \n           [[-0.0147]],\n  \n           [[ 0.0666]],\n  \n           [[ 0.0276]]],\n  \n  \n          [[[ 0.0117]],\n  \n           [[-0.0110]],\n  \n           [[-0.0161]],\n  \n           ...,\n  \n           [[ 0.0337]],\n  \n           [[-0.0308]],\n  \n           [[-0.0739]]],\n  \n  \n          [[[-0.0050]],\n  \n           [[ 0.0043]],\n  \n           [[-0.0038]],\n  \n           ...,\n  \n           [[-0.0171]],\n  \n           [[-0.0593]],\n  \n           [[-0.0623]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0822]],\n  \n           [[ 0.0019]],\n  \n           [[-0.0674]],\n  \n           ...,\n  \n           [[-0.0398]],\n  \n           [[-0.0516]],\n  \n           [[-0.0331]]],\n  \n  \n          [[[-0.0094]],\n  \n           [[-0.0401]],\n  \n           [[ 0.0197]],\n  \n           ...,\n  \n           [[-0.0362]],\n  \n           [[ 0.0016]],\n  \n           [[-0.0070]]],\n  \n  \n          [[[ 0.0430]],\n  \n           [[ 0.0288]],\n  \n           [[ 0.0055]],\n  \n           ...,\n  \n           [[-0.0367]],\n  \n           [[-0.0204]],\n  \n           [[-0.0331]]]], requires_grad=True)),\n ('layer3.5.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer3.5.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.0.conv1.weight',\n  Parameter containing:\n  tensor([[[[-5.9745e-02]],\n  \n           [[-7.4324e-02]],\n  \n           [[-4.4100e-02]],\n  \n           ...,\n  \n           [[ 1.5265e-03]],\n  \n           [[ 6.9681e-02]],\n  \n           [[ 6.4814e-02]]],\n  \n  \n          [[[ 9.4036e-02]],\n  \n           [[-5.6925e-02]],\n  \n           [[ 4.6335e-02]],\n  \n           ...,\n  \n           [[ 5.5958e-02]],\n  \n           [[-7.8256e-02]],\n  \n           [[-5.1269e-02]]],\n  \n  \n          [[[-2.4896e-02]],\n  \n           [[ 7.1292e-02]],\n  \n           [[ 8.5281e-02]],\n  \n           ...,\n  \n           [[ 9.0233e-02]],\n  \n           [[-5.7452e-02]],\n  \n           [[ 6.2677e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 9.4506e-02]],\n  \n           [[ 1.0230e-01]],\n  \n           [[ 1.0362e-01]],\n  \n           ...,\n  \n           [[-1.6433e-02]],\n  \n           [[ 1.5824e-02]],\n  \n           [[ 2.1363e-02]]],\n  \n  \n          [[[ 4.4766e-02]],\n  \n           [[ 8.4423e-06]],\n  \n           [[ 2.3952e-02]],\n  \n           ...,\n  \n           [[-8.0248e-02]],\n  \n           [[ 2.3833e-03]],\n  \n           [[-1.2434e-01]]],\n  \n  \n          [[[ 1.0772e-01]],\n  \n           [[-9.4413e-02]],\n  \n           [[ 4.4412e-02]],\n  \n           ...,\n  \n           [[-2.1047e-02]],\n  \n           [[ 4.6554e-03]],\n  \n           [[-4.9911e-02]]]], requires_grad=True)),\n ('layer4.0.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.0.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.0.conv2.weight',\n  Parameter containing:\n  tensor([[[[-3.8304e-03,  2.0046e-03, -2.7439e-02],\n            [ 2.7892e-02, -2.0464e-02, -4.3362e-03],\n            [-2.5856e-02, -5.1440e-03,  8.1045e-03]],\n  \n           [[-2.8010e-02, -9.9120e-03,  6.1674e-03],\n            [-1.8060e-02,  2.3548e-02, -1.8937e-03],\n            [ 3.3644e-03,  4.2877e-03,  1.9253e-03]],\n  \n           [[-1.0331e-02, -3.2050e-02, -1.2061e-02],\n            [-6.5353e-03,  2.3804e-03, -2.7365e-03],\n            [ 2.2381e-02, -1.9510e-02,  2.5892e-02]],\n  \n           ...,\n  \n           [[-1.1943e-02,  2.3960e-02,  5.1885e-02],\n            [-5.3831e-03, -1.0590e-03, -1.4592e-02],\n            [ 2.0945e-03,  4.8015e-02, -1.5303e-02]],\n  \n           [[-1.7354e-03,  1.1883e-02,  1.1044e-02],\n            [ 1.5336e-03, -2.9820e-03,  2.1448e-02],\n            [ 1.9597e-02, -1.4044e-02, -1.7430e-02]],\n  \n           [[ 1.1387e-02,  9.9918e-03, -4.7555e-03],\n            [-1.8673e-02, -1.7513e-02, -1.8200e-03],\n            [ 8.1278e-03, -3.9202e-03,  2.1658e-02]]],\n  \n  \n          [[[ 2.8501e-02,  3.0649e-03, -1.6597e-02],\n            [ 4.4866e-02, -4.0526e-03, -4.5529e-04],\n            [-2.2344e-02,  3.5199e-02, -5.6911e-03]],\n  \n           [[ 2.5598e-03, -2.3868e-02, -2.4421e-03],\n            [-2.8201e-02, -3.8168e-02, -1.9877e-02],\n            [ 8.1070e-03,  2.6183e-02,  1.4152e-02]],\n  \n           [[ 3.0290e-02, -5.1524e-02,  3.9259e-02],\n            [-2.3437e-02, -2.1343e-02,  5.6372e-03],\n            [-6.6533e-03, -4.1233e-02, -1.4518e-02]],\n  \n           ...,\n  \n           [[-2.4665e-02, -3.3341e-02, -1.4408e-02],\n            [ 1.8418e-03, -1.1030e-03, -2.3373e-02],\n            [ 4.1626e-02,  2.6753e-02,  1.1980e-02]],\n  \n           [[ 2.3877e-02, -1.9031e-02, -2.6479e-02],\n            [-1.0980e-03,  1.3448e-02, -6.7551e-03],\n            [-9.5208e-03, -1.1656e-02,  1.0237e-02]],\n  \n           [[-1.0321e-02,  1.7482e-02,  4.3014e-02],\n            [-4.0213e-03, -3.8233e-02, -1.4208e-02],\n            [-4.1915e-03, -6.1718e-03, -6.7788e-03]]],\n  \n  \n          [[[-1.9105e-02,  3.1632e-02,  7.9245e-03],\n            [ 3.2457e-03, -5.9955e-03, -2.9531e-02],\n            [ 3.0654e-03, -3.3552e-02, -1.2069e-02]],\n  \n           [[-7.8934e-03, -3.6186e-03, -1.0570e-02],\n            [-1.8258e-02,  6.7459e-03,  1.1433e-02],\n            [-2.4231e-02,  4.5846e-03,  2.6002e-02]],\n  \n           [[ 7.8882e-03,  5.1516e-03,  2.4427e-02],\n            [ 1.9511e-02,  4.8677e-03,  2.5931e-02],\n            [ 7.1875e-03,  1.0486e-02, -8.4402e-03]],\n  \n           ...,\n  \n           [[-2.1804e-03, -2.2392e-02, -1.4152e-02],\n            [ 1.7224e-02, -3.8805e-02, -4.0450e-02],\n            [-3.3390e-02, -3.5384e-04, -2.2877e-02]],\n  \n           [[ 2.3938e-02,  4.4311e-05, -4.7773e-02],\n            [ 2.8038e-02,  1.3672e-02,  1.8736e-02],\n            [-1.4882e-02,  1.4046e-02, -1.2547e-02]],\n  \n           [[-4.0174e-02, -1.7367e-02, -2.2264e-02],\n            [-2.5122e-03, -2.5608e-02, -9.6666e-03],\n            [-2.7492e-02, -2.4944e-02, -1.7466e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 1.5336e-03,  1.0210e-02,  2.9918e-02],\n            [ 3.6739e-02, -1.6524e-02, -1.1422e-02],\n            [ 2.4231e-02,  1.1863e-04,  2.0878e-02]],\n  \n           [[-2.1000e-02,  5.3396e-03,  2.7090e-02],\n            [-1.4960e-02,  2.7985e-02,  2.7828e-03],\n            [ 3.9340e-03, -4.5147e-03, -4.6418e-02]],\n  \n           [[-1.6133e-03, -2.2086e-02, -2.9943e-02],\n            [ 2.8666e-02,  4.4507e-02, -7.9303e-03],\n            [-1.2702e-02,  2.7493e-03,  5.3313e-02]],\n  \n           ...,\n  \n           [[ 4.7325e-03, -3.9084e-03, -5.6850e-03],\n            [ 1.5464e-02, -5.0315e-02, -1.5982e-02],\n            [ 2.8746e-02, -4.8295e-02,  1.4566e-03]],\n  \n           [[ 1.0323e-02, -3.1141e-02, -2.1491e-02],\n            [-6.4892e-03, -6.0506e-03,  3.8508e-02],\n            [-2.7322e-02,  1.5664e-02,  3.0606e-02]],\n  \n           [[ 1.7488e-02,  1.1108e-02, -8.0003e-03],\n            [-2.5927e-02,  4.9017e-02, -4.0043e-02],\n            [ 2.6868e-02, -3.2086e-02, -2.8714e-03]]],\n  \n  \n          [[[ 3.6620e-03, -2.9163e-02, -1.8104e-02],\n            [ 8.2524e-03,  1.1828e-02,  3.4014e-02],\n            [ 2.2276e-02,  1.8918e-02,  2.0629e-02]],\n  \n           [[ 8.2328e-03,  1.8445e-02,  2.2128e-02],\n            [-2.3662e-02, -4.4555e-03, -2.7564e-02],\n            [-1.8956e-03, -2.8180e-02, -1.0048e-02]],\n  \n           [[ 1.6084e-02, -2.4208e-02,  2.2892e-02],\n            [ 5.5978e-03, -5.1475e-02, -1.7993e-02],\n            [-5.7298e-03, -9.5657e-03, -6.6069e-03]],\n  \n           ...,\n  \n           [[-1.8728e-02, -3.3384e-02,  3.2787e-02],\n            [ 7.3618e-03,  7.6472e-03,  6.7767e-03],\n            [-3.5113e-03,  3.9306e-03,  1.6094e-03]],\n  \n           [[ 5.9951e-03,  5.4963e-03, -2.2865e-02],\n            [-6.9230e-03, -6.2176e-03, -1.6691e-02],\n            [ 1.5921e-02, -7.2493e-03,  3.4725e-02]],\n  \n           [[-1.9864e-02,  7.7958e-03,  1.8141e-02],\n            [ 2.3738e-02,  9.3161e-03,  3.5635e-03],\n            [-3.9675e-03,  4.7543e-03,  7.5388e-03]]],\n  \n  \n          [[[ 1.0158e-02, -8.2707e-03, -1.8857e-02],\n            [-4.6163e-03,  6.1191e-03,  2.7733e-03],\n            [ 3.3697e-02,  3.5186e-02,  8.1448e-03]],\n  \n           [[ 1.4247e-03,  1.9141e-03,  1.6456e-02],\n            [ 2.4840e-02, -3.0980e-02,  1.6093e-02],\n            [-1.1054e-02,  6.7501e-03,  3.0667e-02]],\n  \n           [[ 7.5286e-03,  6.5059e-03,  6.3152e-04],\n            [ 1.4788e-02, -6.2009e-03, -4.0890e-02],\n            [-1.0598e-02,  5.4706e-04, -1.0918e-02]],\n  \n           ...,\n  \n           [[ 2.1269e-02, -1.7388e-02, -4.3288e-02],\n            [-3.0102e-03, -6.4838e-03,  1.1306e-02],\n            [ 2.9644e-02,  1.6322e-02,  1.9997e-02]],\n  \n           [[-3.4962e-02,  1.4516e-02,  1.0152e-03],\n            [-4.5765e-02, -1.6689e-02,  3.4970e-02],\n            [ 2.0386e-02,  2.8021e-03, -3.2868e-02]],\n  \n           [[ 3.2117e-03, -3.6542e-02, -3.9330e-03],\n            [-1.0898e-02,  5.8171e-03,  9.4409e-03],\n            [ 1.2874e-02, -8.5553e-04, -2.1420e-02]]]], requires_grad=True)),\n ('layer4.0.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.0.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.0.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0046]],\n  \n           [[-0.0008]],\n  \n           [[-0.0233]],\n  \n           ...,\n  \n           [[-0.0107]],\n  \n           [[-0.0437]],\n  \n           [[-0.0185]]],\n  \n  \n          [[[ 0.0070]],\n  \n           [[ 0.0212]],\n  \n           [[ 0.0024]],\n  \n           ...,\n  \n           [[ 0.0335]],\n  \n           [[-0.0535]],\n  \n           [[-0.0604]]],\n  \n  \n          [[[-0.0353]],\n  \n           [[-0.0117]],\n  \n           [[-0.0006]],\n  \n           ...,\n  \n           [[ 0.0195]],\n  \n           [[ 0.0140]],\n  \n           [[-0.0113]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0137]],\n  \n           [[ 0.0049]],\n  \n           [[-0.0327]],\n  \n           ...,\n  \n           [[-0.0119]],\n  \n           [[ 0.0281]],\n  \n           [[ 0.0484]]],\n  \n  \n          [[[-0.0099]],\n  \n           [[-0.0086]],\n  \n           [[-0.0018]],\n  \n           ...,\n  \n           [[-0.0190]],\n  \n           [[-0.0030]],\n  \n           [[-0.0048]]],\n  \n  \n          [[[-0.0155]],\n  \n           [[ 0.0632]],\n  \n           [[-0.0235]],\n  \n           ...,\n  \n           [[-0.0011]],\n  \n           [[-0.0269]],\n  \n           [[ 0.0105]]]], requires_grad=True)),\n ('layer4.0.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.0.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.0.downsample.0.weight',\n  Parameter containing:\n  tensor([[[[ 0.0083]],\n  \n           [[-0.0228]],\n  \n           [[-0.0358]],\n  \n           ...,\n  \n           [[ 0.0407]],\n  \n           [[ 0.0470]],\n  \n           [[ 0.0972]]],\n  \n  \n          [[[-0.0314]],\n  \n           [[-0.0021]],\n  \n           [[-0.0051]],\n  \n           ...,\n  \n           [[ 0.0472]],\n  \n           [[-0.0119]],\n  \n           [[ 0.0029]]],\n  \n  \n          [[[-0.0372]],\n  \n           [[-0.0418]],\n  \n           [[-0.0275]],\n  \n           ...,\n  \n           [[-0.0457]],\n  \n           [[ 0.0187]],\n  \n           [[ 0.0087]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0391]],\n  \n           [[ 0.0145]],\n  \n           [[ 0.0012]],\n  \n           ...,\n  \n           [[ 0.0104]],\n  \n           [[-0.0364]],\n  \n           [[ 0.0500]]],\n  \n  \n          [[[ 0.0189]],\n  \n           [[ 0.0402]],\n  \n           [[-0.0187]],\n  \n           ...,\n  \n           [[-0.0638]],\n  \n           [[ 0.0278]],\n  \n           [[-0.0170]]],\n  \n  \n          [[[-0.0285]],\n  \n           [[-0.0459]],\n  \n           [[ 0.0076]],\n  \n           ...,\n  \n           [[-0.0510]],\n  \n           [[-0.0109]],\n  \n           [[-0.0272]]]], requires_grad=True)),\n ('layer4.0.downsample.1.weight',\n  Parameter containing:\n  tensor([1., 1., 1.,  ..., 1., 1., 1.], requires_grad=True)),\n ('layer4.0.downsample.1.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.1.conv1.weight',\n  Parameter containing:\n  tensor([[[[-0.1204]],\n  \n           [[ 0.0467]],\n  \n           [[ 0.0948]],\n  \n           ...,\n  \n           [[-0.0150]],\n  \n           [[ 0.0605]],\n  \n           [[-0.0105]]],\n  \n  \n          [[[-0.0534]],\n  \n           [[-0.0625]],\n  \n           [[-0.1042]],\n  \n           ...,\n  \n           [[ 0.1123]],\n  \n           [[-0.0423]],\n  \n           [[ 0.0004]]],\n  \n  \n          [[[ 0.0787]],\n  \n           [[ 0.0911]],\n  \n           [[-0.0282]],\n  \n           ...,\n  \n           [[ 0.0347]],\n  \n           [[ 0.0323]],\n  \n           [[-0.0826]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0602]],\n  \n           [[ 0.0721]],\n  \n           [[ 0.0858]],\n  \n           ...,\n  \n           [[-0.0578]],\n  \n           [[-0.0190]],\n  \n           [[ 0.0481]]],\n  \n  \n          [[[ 0.1233]],\n  \n           [[ 0.0088]],\n  \n           [[ 0.0011]],\n  \n           ...,\n  \n           [[-0.0653]],\n  \n           [[ 0.0105]],\n  \n           [[-0.0348]]],\n  \n  \n          [[[-0.0663]],\n  \n           [[ 0.0027]],\n  \n           [[ 0.1578]],\n  \n           ...,\n  \n           [[ 0.0338]],\n  \n           [[-0.0268]],\n  \n           [[ 0.0397]]]], requires_grad=True)),\n ('layer4.1.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.1.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.1.conv2.weight',\n  Parameter containing:\n  tensor([[[[-1.4875e-02,  3.2817e-02,  2.0309e-03],\n            [ 2.7361e-02,  1.7980e-02,  4.7771e-03],\n            [ 8.3609e-03,  1.9908e-03, -2.1515e-02]],\n  \n           [[ 1.5472e-02, -1.8721e-02, -1.5944e-02],\n            [ 1.0105e-02, -1.6259e-02,  4.2593e-03],\n            [-1.4311e-02, -2.1756e-02, -3.5767e-02]],\n  \n           [[-2.0048e-03,  2.5163e-02,  2.1553e-03],\n            [ 7.1713e-03, -1.5705e-02,  6.5028e-03],\n            [-2.8759e-04,  1.9339e-02,  1.1133e-02]],\n  \n           ...,\n  \n           [[ 1.9712e-02, -1.4370e-02,  1.4445e-02],\n            [ 1.0048e-03,  7.7705e-03,  3.4548e-03],\n            [ 4.1120e-02, -2.0746e-02,  1.8221e-02]],\n  \n           [[-3.8585e-02,  1.9015e-05,  2.3851e-02],\n            [ 2.2705e-02, -1.2875e-02, -4.3378e-02],\n            [-1.0224e-03, -1.1943e-02, -5.5919e-02]],\n  \n           [[ 2.7346e-03,  5.4173e-03,  1.4899e-02],\n            [-2.9461e-02, -6.3389e-03, -2.5316e-02],\n            [-8.9263e-04, -2.2314e-02, -1.3692e-03]]],\n  \n  \n          [[[-2.3572e-02,  1.3061e-02,  8.1310e-03],\n            [-3.3054e-02,  3.7524e-03, -8.4084e-03],\n            [ 2.0152e-02,  9.5777e-03, -3.0059e-02]],\n  \n           [[ 2.0882e-02, -3.3932e-04, -2.1867e-02],\n            [-5.7642e-03, -2.5067e-02, -3.2238e-02],\n            [-3.9565e-03,  9.7498e-03, -7.4497e-03]],\n  \n           [[-4.2966e-03,  1.1454e-02,  9.1774e-03],\n            [-4.3429e-03, -9.5762e-04, -2.8221e-04],\n            [-2.4145e-03,  5.8480e-03, -6.3342e-03]],\n  \n           ...,\n  \n           [[ 1.5185e-02,  1.7225e-02, -1.3493e-02],\n            [ 1.8122e-02, -2.5433e-02, -8.0547e-03],\n            [-3.2391e-03,  3.1090e-03,  2.7796e-02]],\n  \n           [[ 2.5820e-02, -2.0805e-03,  3.1768e-02],\n            [-4.5366e-03,  2.5713e-03, -5.1541e-02],\n            [ 2.7077e-02,  2.4704e-02,  2.3425e-02]],\n  \n           [[ 1.0992e-02, -4.3989e-03, -2.9784e-02],\n            [-3.8059e-02, -3.4452e-03,  1.6183e-02],\n            [-2.3624e-02,  3.6482e-03, -3.8072e-03]]],\n  \n  \n          [[[-2.5082e-02, -2.1973e-02,  2.4752e-02],\n            [ 8.6584e-03, -4.8067e-03,  3.2572e-02],\n            [ 3.1512e-02, -1.4320e-02,  4.2325e-03]],\n  \n           [[-2.4489e-03,  7.2891e-03, -4.3926e-02],\n            [-3.4502e-03, -3.2062e-03,  2.8278e-02],\n            [ 2.1744e-03, -1.1845e-04,  3.5486e-02]],\n  \n           [[-1.5193e-02,  3.4429e-02,  1.2551e-02],\n            [-1.3719e-02,  1.1010e-02, -1.6960e-02],\n            [-4.3950e-04, -7.7311e-03,  1.3521e-02]],\n  \n           ...,\n  \n           [[ 4.4235e-04, -1.6710e-02,  2.8953e-02],\n            [ 2.0065e-02,  9.1982e-03, -3.5463e-02],\n            [ 1.7301e-02, -1.9391e-02, -2.4868e-02]],\n  \n           [[ 1.7814e-02, -5.5200e-03, -2.2634e-02],\n            [-3.7579e-03,  1.1860e-02, -5.0001e-04],\n            [-5.1746e-03, -1.8023e-02, -5.7977e-03]],\n  \n           [[ 2.3632e-02,  2.4088e-02, -1.4406e-02],\n            [ 4.4347e-03, -1.2388e-02, -3.5370e-02],\n            [ 3.0446e-02,  5.7332e-03,  2.2244e-04]]],\n  \n  \n          ...,\n  \n  \n          [[[-2.5161e-03, -1.5265e-02, -2.7160e-02],\n            [ 1.5742e-02,  1.2813e-02, -4.9171e-03],\n            [ 3.2447e-02,  3.7092e-02,  2.4212e-03]],\n  \n           [[ 1.2892e-02, -5.6578e-03,  4.0294e-03],\n            [-1.8055e-02, -2.5514e-02,  4.1187e-03],\n            [-4.0521e-02, -1.6409e-02,  2.2845e-02]],\n  \n           [[-1.1588e-02, -6.1483e-03,  2.0049e-02],\n            [-3.7533e-03,  2.4134e-02,  5.8985e-03],\n            [ 1.6091e-02,  4.1375e-02, -1.1914e-03]],\n  \n           ...,\n  \n           [[-1.8447e-02,  2.1346e-02, -2.0074e-02],\n            [ 4.4945e-02,  8.4388e-03, -4.4124e-03],\n            [-3.5401e-02,  1.3727e-02, -3.0955e-02]],\n  \n           [[-8.4029e-03, -6.6551e-03, -1.2266e-02],\n            [ 2.0679e-02,  4.7484e-02, -3.3798e-04],\n            [ 1.6623e-02, -2.4894e-02, -3.1041e-02]],\n  \n           [[-9.0618e-03, -2.8014e-03, -2.0485e-03],\n            [ 1.0627e-02, -5.7895e-03, -1.2222e-02],\n            [-3.6892e-03,  1.8226e-02,  3.0287e-03]]],\n  \n  \n          [[[-1.4413e-02, -2.5413e-02,  1.1292e-02],\n            [-1.8975e-02,  4.7378e-04,  2.7890e-02],\n            [-5.3665e-03,  6.1852e-03,  1.8250e-02]],\n  \n           [[-2.0131e-02, -4.0751e-02, -7.6659e-03],\n            [-2.9683e-02, -1.3461e-02,  4.4304e-03],\n            [-4.3538e-02, -2.5943e-02,  3.9320e-02]],\n  \n           [[ 1.4356e-02, -3.6358e-04,  1.3382e-03],\n            [-1.8499e-02,  4.6870e-04,  1.2708e-06],\n            [-1.0194e-02,  2.3945e-02, -2.1767e-02]],\n  \n           ...,\n  \n           [[-1.2497e-02, -2.6169e-03, -2.8204e-02],\n            [-1.1539e-02,  9.4762e-03,  2.0115e-02],\n            [ 3.3677e-02, -1.7105e-02,  1.4507e-02]],\n  \n           [[-1.3053e-02, -2.8408e-02, -4.0868e-02],\n            [-2.8236e-02,  6.2103e-03, -4.6452e-03],\n            [ 4.4288e-03,  1.4584e-02, -3.8451e-03]],\n  \n           [[ 2.6254e-02,  1.8147e-02,  3.6901e-02],\n            [ 1.7411e-02, -3.1215e-02,  5.8578e-03],\n            [-4.6043e-02,  7.0331e-02, -2.2305e-02]]],\n  \n  \n          [[[ 6.3843e-03, -2.6831e-02, -1.0774e-02],\n            [ 1.4541e-02,  9.5206e-03, -6.6421e-03],\n            [ 2.6314e-02,  1.0686e-02,  1.6661e-03]],\n  \n           [[ 1.4916e-02, -1.0201e-02,  1.5558e-02],\n            [ 1.7815e-03,  1.8692e-02, -2.5806e-02],\n            [ 1.0424e-02,  3.0308e-02,  1.9223e-02]],\n  \n           [[ 3.0190e-02,  1.5153e-02, -7.5506e-03],\n            [ 1.0196e-02,  9.0764e-03,  1.5230e-02],\n            [ 2.2625e-02,  1.7294e-02,  1.0638e-02]],\n  \n           ...,\n  \n           [[ 1.1707e-02,  1.8566e-02, -1.4157e-02],\n            [-8.9678e-03,  2.0868e-02,  1.1559e-02],\n            [ 7.8745e-04,  3.0270e-02,  1.4833e-02]],\n  \n           [[-5.7109e-03, -1.2130e-02, -2.7492e-02],\n            [-4.6356e-03,  3.6730e-02,  1.3568e-02],\n            [ 4.1427e-02, -7.8176e-03, -7.0532e-03]],\n  \n           [[ 4.5137e-03,  1.3893e-02, -2.5502e-02],\n            [ 3.4937e-02, -9.3189e-03,  1.8159e-02],\n            [-1.0250e-02,  4.7569e-04, -1.2051e-02]]]], requires_grad=True)),\n ('layer4.1.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.1.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.1.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 0.0697]],\n  \n           [[ 0.0180]],\n  \n           [[-0.0302]],\n  \n           ...,\n  \n           [[ 0.0276]],\n  \n           [[ 0.0211]],\n  \n           [[-0.0052]]],\n  \n  \n          [[[ 0.0008]],\n  \n           [[-0.0202]],\n  \n           [[ 0.0040]],\n  \n           ...,\n  \n           [[-0.0055]],\n  \n           [[-0.0018]],\n  \n           [[ 0.0169]]],\n  \n  \n          [[[ 0.0036]],\n  \n           [[-0.0117]],\n  \n           [[-0.0001]],\n  \n           ...,\n  \n           [[-0.0088]],\n  \n           [[ 0.0150]],\n  \n           [[-0.0107]]],\n  \n  \n          ...,\n  \n  \n          [[[-0.0468]],\n  \n           [[ 0.0299]],\n  \n           [[-0.0465]],\n  \n           ...,\n  \n           [[ 0.0008]],\n  \n           [[ 0.0666]],\n  \n           [[-0.0275]]],\n  \n  \n          [[[-0.0167]],\n  \n           [[-0.0299]],\n  \n           [[-0.0457]],\n  \n           ...,\n  \n           [[ 0.0287]],\n  \n           [[-0.1034]],\n  \n           [[ 0.0131]]],\n  \n  \n          [[[ 0.0016]],\n  \n           [[-0.0029]],\n  \n           [[ 0.0188]],\n  \n           ...,\n  \n           [[ 0.0329]],\n  \n           [[-0.0163]],\n  \n           [[-0.0215]]]], requires_grad=True)),\n ('layer4.1.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.1.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.2.conv1.weight',\n  Parameter containing:\n  tensor([[[[ 0.0869]],\n  \n           [[ 0.0008]],\n  \n           [[-0.0862]],\n  \n           ...,\n  \n           [[-0.0899]],\n  \n           [[ 0.0431]],\n  \n           [[ 0.0210]]],\n  \n  \n          [[[-0.0638]],\n  \n           [[ 0.0383]],\n  \n           [[-0.0071]],\n  \n           ...,\n  \n           [[ 0.0776]],\n  \n           [[ 0.0079]],\n  \n           [[-0.0025]]],\n  \n  \n          [[[-0.0752]],\n  \n           [[ 0.0471]],\n  \n           [[ 0.0177]],\n  \n           ...,\n  \n           [[-0.0676]],\n  \n           [[ 0.0094]],\n  \n           [[-0.0518]]],\n  \n  \n          ...,\n  \n  \n          [[[ 0.0063]],\n  \n           [[-0.0471]],\n  \n           [[-0.0583]],\n  \n           ...,\n  \n           [[ 0.0199]],\n  \n           [[-0.0632]],\n  \n           [[-0.0098]]],\n  \n  \n          [[[ 0.0009]],\n  \n           [[-0.0451]],\n  \n           [[-0.0351]],\n  \n           ...,\n  \n           [[ 0.0193]],\n  \n           [[ 0.0237]],\n  \n           [[-0.0408]]],\n  \n  \n          [[[ 0.1019]],\n  \n           [[ 0.0358]],\n  \n           [[-0.0502]],\n  \n           ...,\n  \n           [[-0.0375]],\n  \n           [[ 0.0198]],\n  \n           [[ 0.0104]]]], requires_grad=True)),\n ('layer4.2.bn1.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.2.bn1.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.2.conv2.weight',\n  Parameter containing:\n  tensor([[[[ 4.0372e-03,  9.6009e-03,  5.7336e-03],\n            [ 3.6475e-03,  1.3929e-03, -4.3581e-02],\n            [ 1.8282e-02,  2.6522e-02, -4.4680e-03]],\n  \n           [[ 1.8466e-03, -2.1687e-02,  3.2666e-02],\n            [-1.1404e-03,  4.9626e-03,  2.6408e-02],\n            [ 7.1162e-03,  1.9486e-02, -2.4696e-02]],\n  \n           [[-1.1102e-02, -3.2891e-03,  1.2114e-02],\n            [-3.5552e-02,  1.5232e-02,  3.2585e-02],\n            [-2.1484e-02,  3.1279e-02,  1.4156e-02]],\n  \n           ...,\n  \n           [[-2.5637e-03,  2.4398e-03, -3.0658e-03],\n            [-1.1979e-02,  1.6302e-02,  2.3396e-03],\n            [ 8.2219e-03,  6.6287e-02, -7.6532e-03]],\n  \n           [[-2.9873e-03,  3.1535e-03, -3.0700e-03],\n            [ 3.1522e-02, -3.0844e-02, -2.4698e-02],\n            [ 2.0255e-02, -5.4907e-03,  7.8847e-03]],\n  \n           [[-4.5566e-02, -3.2117e-04, -2.9282e-02],\n            [ 2.1581e-02,  3.1376e-02, -6.7348e-03],\n            [ 3.3176e-02, -1.7408e-02, -1.2875e-03]]],\n  \n  \n          [[[ 9.0611e-03, -7.6816e-04, -1.9904e-02],\n            [-7.1802e-03,  1.6015e-02, -1.7035e-02],\n            [ 8.4524e-03,  2.4376e-02, -1.3405e-02]],\n  \n           [[ 1.3314e-03, -3.2731e-02, -2.7464e-02],\n            [ 3.4712e-02, -1.2054e-02, -1.3446e-02],\n            [ 1.7766e-03,  6.2005e-02, -3.8113e-02]],\n  \n           [[ 4.3504e-02,  8.5865e-04,  7.6798e-04],\n            [-1.7990e-02,  1.2751e-02, -7.5429e-03],\n            [ 1.0408e-02,  3.8950e-02, -1.0803e-02]],\n  \n           ...,\n  \n           [[-4.2192e-02,  3.7597e-02,  1.2419e-03],\n            [-1.1473e-02, -2.0376e-02,  1.3651e-02],\n            [ 1.8838e-02, -1.9380e-02, -1.4051e-02]],\n  \n           [[-3.3401e-03, -1.8234e-03,  1.1112e-02],\n            [ 2.3838e-02, -7.7340e-03,  1.4265e-03],\n            [-3.9946e-03, -4.3768e-02, -1.4484e-03]],\n  \n           [[-1.8119e-02,  2.5660e-02,  3.8637e-03],\n            [ 5.3056e-04, -1.4192e-02, -1.6952e-02],\n            [ 1.3493e-02, -1.7834e-02,  2.4105e-02]]],\n  \n  \n          [[[ 1.4504e-02,  1.2735e-02,  2.6928e-03],\n            [ 4.2135e-03,  4.0163e-03,  3.3633e-02],\n            [ 1.4109e-02,  2.5378e-02,  3.2268e-03]],\n  \n           [[-4.0881e-02,  2.9987e-02, -6.7412e-03],\n            [-1.3335e-03,  9.1620e-03, -3.5123e-04],\n            [-2.5886e-02,  1.2616e-02,  1.3708e-02]],\n  \n           [[-2.6507e-03, -2.2557e-02,  3.2115e-02],\n            [-2.4336e-02, -3.8428e-03, -2.8200e-02],\n            [-1.9067e-02,  2.4719e-02, -5.3098e-02]],\n  \n           ...,\n  \n           [[ 1.3047e-02, -4.6418e-02,  1.8212e-02],\n            [ 1.8339e-02,  2.4303e-03,  1.7478e-02],\n            [ 1.5208e-02, -8.4832e-03,  3.6281e-02]],\n  \n           [[-1.3485e-02,  6.7969e-03,  2.2060e-02],\n            [ 3.4260e-02,  3.5324e-03, -2.3624e-02],\n            [-1.1581e-02, -1.8611e-02, -1.7838e-02]],\n  \n           [[-2.5433e-03,  2.6012e-02,  1.2603e-02],\n            [ 2.5943e-02,  1.4686e-02, -2.8406e-03],\n            [-1.1629e-02,  1.8200e-02,  2.5403e-03]]],\n  \n  \n          ...,\n  \n  \n          [[[ 2.7300e-02,  1.0148e-02,  3.8089e-02],\n            [-3.7646e-02, -2.8380e-02,  6.6293e-03],\n            [-1.4086e-02, -2.3508e-02,  3.8443e-02]],\n  \n           [[-3.1648e-02,  2.7956e-04, -4.5027e-03],\n            [-3.5491e-02,  4.1126e-02, -3.2401e-02],\n            [ 2.2612e-02, -1.0945e-02, -4.6242e-03]],\n  \n           [[-2.6057e-02,  5.9616e-03, -2.8074e-02],\n            [ 1.2896e-02,  1.8758e-02, -1.3279e-02],\n            [ 9.2041e-03, -5.8497e-03, -1.0998e-02]],\n  \n           ...,\n  \n           [[-9.1234e-03,  6.9578e-03, -2.1609e-02],\n            [ 1.9468e-03,  1.8515e-02, -1.8667e-04],\n            [ 3.8241e-02, -1.6975e-02,  2.9781e-02]],\n  \n           [[ 3.0355e-02, -8.8759e-04, -2.8915e-02],\n            [ 1.3347e-02,  3.3460e-03,  7.2086e-03],\n            [-2.0003e-02,  1.0483e-02,  1.0230e-02]],\n  \n           [[ 1.1430e-03, -2.5290e-02, -7.6073e-03],\n            [ 1.6937e-02,  8.2370e-03,  2.9507e-02],\n            [ 1.3583e-02, -1.5253e-02, -2.7242e-02]]],\n  \n  \n          [[[-7.6098e-04,  3.9051e-03,  1.8709e-02],\n            [-1.1853e-02, -3.9333e-03, -2.3217e-02],\n            [ 1.3281e-02,  6.7374e-03, -1.1190e-02]],\n  \n           [[-1.4907e-02, -2.2079e-02, -5.1073e-03],\n            [ 8.6738e-03,  2.5048e-02,  3.1550e-02],\n            [ 1.2738e-02,  1.1874e-02,  7.4871e-03]],\n  \n           [[-1.3418e-02, -1.6440e-02,  2.0048e-03],\n            [ 3.3758e-02,  1.7985e-02, -7.6593e-03],\n            [ 1.0501e-02, -1.1576e-02,  1.1482e-02]],\n  \n           ...,\n  \n           [[-3.9476e-02,  4.3286e-02, -1.4864e-02],\n            [ 1.0187e-02,  3.5476e-03, -2.0036e-03],\n            [ 2.8613e-02,  5.0859e-03,  1.9285e-02]],\n  \n           [[ 2.6005e-02, -9.6460e-03,  1.4698e-02],\n            [ 1.5942e-02, -6.0562e-03,  5.4321e-03],\n            [ 1.8563e-02,  2.8981e-02, -4.2562e-02]],\n  \n           [[ 6.3422e-03, -8.8243e-03,  1.2056e-02],\n            [-8.7140e-03, -7.0939e-03,  4.0304e-02],\n            [-1.3844e-02, -1.5328e-02,  1.6865e-02]]],\n  \n  \n          [[[ 9.2547e-03, -2.0169e-02, -2.6993e-02],\n            [ 2.2630e-02, -9.1510e-03,  2.9532e-03],\n            [ 1.5936e-02, -1.2428e-02, -1.1674e-02]],\n  \n           [[-6.4904e-03, -2.4222e-02,  3.2656e-04],\n            [-7.8919e-03, -2.1352e-02,  1.6693e-02],\n            [ 1.6575e-02,  3.7735e-03, -3.0243e-02]],\n  \n           [[ 7.2092e-03,  3.3445e-02,  3.1266e-02],\n            [ 3.0373e-03, -4.3604e-02,  1.2334e-02],\n            [ 1.8124e-02, -1.6813e-02, -3.5622e-02]],\n  \n           ...,\n  \n           [[-5.3451e-04, -7.1725e-04,  3.3224e-02],\n            [ 3.2404e-02,  2.0535e-02,  3.7013e-02],\n            [ 1.8017e-02, -4.6330e-03, -7.2671e-05]],\n  \n           [[-2.1402e-02, -1.5603e-02, -2.9944e-02],\n            [ 2.2587e-02, -2.3721e-02,  1.6249e-02],\n            [ 2.3000e-02,  1.2225e-02, -2.4762e-02]],\n  \n           [[-7.1571e-03,  5.2951e-03, -6.9071e-03],\n            [ 1.3710e-02, -1.1639e-02, -2.1029e-02],\n            [-2.8345e-02, -9.9142e-03,  1.6903e-02]]]], requires_grad=True)),\n ('layer4.2.bn2.weight',\n  Parameter containing:\n  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n          1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)),\n ('layer4.2.bn2.bias',\n  Parameter containing:\n  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n          0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)),\n ('layer4.2.conv3.weight',\n  Parameter containing:\n  tensor([[[[ 1.2131e-02]],\n  \n           [[ 5.8428e-02]],\n  \n           [[ 2.0046e-02]],\n  \n           ...,\n  \n           [[ 1.2015e-03]],\n  \n           [[-5.0296e-04]],\n  \n           [[ 2.0999e-03]]],\n  \n  \n          [[[-3.1696e-03]],\n  \n           [[ 1.6836e-02]],\n  \n           [[-4.9158e-02]],\n  \n           ...,\n  \n           [[ 2.1881e-02]],\n  \n           [[ 1.6721e-02]],\n  \n           [[-1.4479e-02]]],\n  \n  \n          [[[ 1.4656e-02]],\n  \n           [[-1.9131e-02]],\n  \n           [[-1.2144e-02]],\n  \n           ...,\n  \n           [[ 2.0264e-02]],\n  \n           [[-6.3847e-02]],\n  \n           [[-1.8942e-02]]],\n  \n  \n          ...,\n  \n  \n          [[[ 5.3712e-05]],\n  \n           [[ 3.9394e-02]],\n  \n           [[ 4.2408e-03]],\n  \n           ...,\n  \n           [[ 1.0187e-02]],\n  \n           [[-3.4083e-02]],\n  \n           [[ 3.9114e-02]]],\n  \n  \n          [[[ 1.5032e-02]],\n  \n           [[-9.2758e-03]],\n  \n           [[-1.4523e-02]],\n  \n           ...,\n  \n           [[-6.3346e-04]],\n  \n           [[ 8.7917e-03]],\n  \n           [[-3.3098e-02]]],\n  \n  \n          [[[-5.7945e-03]],\n  \n           [[ 2.6874e-02]],\n  \n           [[-3.3141e-02]],\n  \n           ...,\n  \n           [[ 1.7235e-02]],\n  \n           [[-9.5212e-03]],\n  \n           [[-2.5897e-02]]]], requires_grad=True)),\n ('layer4.2.bn3.weight',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('layer4.2.bn3.bias',\n  Parameter containing:\n  tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)),\n ('fc.weight',\n  Parameter containing:\n  tensor([[ 0.0066,  0.0131, -0.0071,  ..., -0.0081, -0.0121, -0.0037],\n          [ 0.0060,  0.0119,  0.0071,  ..., -0.0145,  0.0127, -0.0213],\n          [-0.0149, -0.0186, -0.0024,  ..., -0.0134, -0.0213,  0.0144],\n          ...,\n          [ 0.0178,  0.0139,  0.0033,  ..., -0.0196, -0.0128, -0.0092],\n          [ 0.0086, -0.0037, -0.0164,  ...,  0.0169,  0.0027, -0.0115],\n          [ 0.0034,  0.0171,  0.0171,  ...,  0.0028,  0.0152,  0.0161]],\n         requires_grad=True)),\n ('fc.bias',\n  Parameter containing:\n  tensor([-4.9517e-03, -2.5835e-03,  2.0803e-02,  9.4650e-03,  3.3053e-03,\n          -5.6519e-03,  1.9817e-02,  2.0498e-02, -1.6693e-02,  2.1255e-02,\n          -9.7826e-04, -9.4811e-03,  1.1158e-02,  5.8161e-04,  1.3158e-02,\n           2.0398e-02, -1.5821e-02,  1.4266e-02,  7.0510e-03, -3.6685e-03,\n          -1.7214e-02, -1.4209e-02, -3.0199e-03,  1.0627e-02,  6.5157e-03,\n           9.4924e-04,  1.0380e-02,  3.8509e-03, -5.7467e-03,  1.5026e-02,\n          -5.9394e-03, -8.6701e-03,  1.6169e-02,  4.5708e-03, -2.0653e-02,\n          -1.5963e-03,  6.8233e-03,  1.7060e-02, -1.3947e-02, -3.4503e-03,\n          -1.1365e-02, -1.2223e-02,  1.2113e-02, -2.4736e-04,  1.3549e-02,\n          -2.0833e-02, -1.6784e-02, -1.9889e-02, -4.5695e-03,  7.6254e-03,\n          -4.5849e-03,  1.6212e-02, -1.9736e-03,  1.7916e-02, -1.5456e-03,\n          -1.7383e-02, -6.6034e-03,  4.0540e-03, -1.6151e-02,  2.4600e-03,\n          -7.5390e-03, -1.7564e-02,  8.3464e-03, -5.7819e-03,  9.3517e-03,\n          -1.0946e-02, -1.9944e-02, -9.4418e-03,  2.0330e-02, -8.0082e-03,\n          -2.0544e-02,  1.6829e-02,  1.4149e-02, -1.4097e-03,  1.5277e-02,\n           2.0283e-02, -6.3989e-03, -5.1823e-03, -3.7406e-05,  1.3873e-02,\n          -1.6744e-02, -2.1233e-02, -3.0119e-03,  1.9213e-02,  1.0302e-02,\n          -5.7545e-03, -5.6215e-03,  6.3183e-03, -1.5332e-02, -1.8230e-02,\n           5.7956e-03, -2.2010e-02, -2.3797e-03,  1.1589e-02, -2.0739e-02,\n          -4.9881e-03,  6.2564e-03, -2.0244e-02,  8.1927e-03,  2.0681e-02,\n          -7.8505e-03, -1.7218e-02,  1.0768e-02, -1.2801e-02, -1.3541e-02,\n          -1.2043e-02, -2.1172e-02, -1.4716e-02, -5.4089e-03,  2.0620e-02,\n           2.0371e-02, -2.1446e-02, -2.1623e-02,  4.9458e-03, -2.0032e-02,\n           1.3742e-02,  2.7540e-03,  1.0424e-02, -9.8711e-04,  2.9598e-03,\n          -1.5282e-02, -2.5758e-03, -1.8975e-02, -1.8392e-02, -2.3569e-03,\n          -1.9854e-02, -1.6204e-02,  1.5703e-02,  1.4556e-02, -5.1735e-03,\n           1.5252e-02,  1.8951e-02, -8.9992e-03,  1.9383e-02, -3.2948e-03,\n          -1.0476e-02, -7.5083e-03,  3.5340e-03,  9.8979e-03, -1.5054e-02,\n          -2.0320e-02, -6.3631e-03,  2.0043e-02,  1.9830e-02,  1.3094e-02,\n          -1.5390e-02, -7.6599e-03,  1.3593e-02,  1.0336e-02,  1.0929e-02,\n           2.0372e-04,  1.1107e-04,  1.0213e-02,  3.6813e-03, -1.6412e-02,\n           1.1802e-03,  8.4597e-03, -9.2707e-03, -5.4170e-03,  1.9675e-02,\n          -8.5243e-03, -1.1558e-02,  1.6129e-02, -1.3405e-02,  4.6223e-04,\n          -1.8774e-02, -2.9299e-03,  7.3921e-03,  2.8056e-03, -1.2501e-03,\n           7.3736e-03, -1.4411e-03, -1.7926e-02,  1.0428e-03,  2.0704e-02,\n           1.0374e-02, -1.8622e-02, -1.9445e-04,  2.8512e-03, -9.0790e-03,\n          -2.2082e-02,  4.1009e-03,  1.2553e-02, -2.1904e-02,  1.1606e-02,\n          -5.5057e-03,  1.7030e-02, -1.4541e-02, -1.8824e-03,  3.1945e-03,\n          -2.0524e-02, -8.5445e-03,  1.2024e-02,  1.8271e-02, -1.3442e-02,\n           9.6984e-03, -1.7566e-02, -1.5033e-02,  8.0769e-03, -1.9867e-02,\n          -2.1866e-03,  5.9113e-03,  9.7809e-03, -2.0488e-02, -1.3959e-03,\n          -9.7055e-03, -9.8444e-03,  7.6046e-03, -1.1191e-02,  9.0376e-03,\n          -5.9319e-03,  1.2340e-03, -1.5603e-02, -1.1446e-02, -1.2420e-02,\n          -1.6465e-02, -2.1580e-02,  1.1416e-02, -1.8703e-02, -5.5200e-03,\n           1.4327e-02, -9.4115e-03, -6.8531e-03, -7.7144e-03, -1.8033e-02,\n           1.2368e-02,  1.2903e-02,  2.1552e-02,  1.7600e-02, -2.2058e-02,\n          -1.4971e-02,  9.7099e-03, -1.6501e-02,  3.2777e-03, -1.6091e-02,\n          -5.1584e-03, -1.9415e-02,  7.5102e-03, -1.9682e-04,  2.1740e-02,\n           1.1847e-02, -7.9145e-03, -1.2820e-02,  4.5116e-03, -1.3666e-02,\n          -6.1617e-03,  6.9369e-03, -1.5905e-02, -2.1222e-02, -2.0794e-02,\n           6.3799e-03, -8.7952e-03,  3.8081e-03,  4.8792e-03, -1.3953e-02,\n           1.5906e-02, -1.2821e-02, -1.5098e-02,  1.1480e-02, -1.5811e-02,\n          -9.0970e-03,  1.3753e-02, -1.7108e-02, -8.2053e-03,  8.0987e-03,\n          -2.1263e-02, -1.6520e-03,  5.0387e-03, -1.2997e-02,  1.8601e-02,\n          -1.2021e-02,  3.5198e-03,  1.0363e-02, -1.8617e-02,  1.9091e-02,\n           4.8841e-03, -3.8488e-03,  1.0711e-02,  1.1413e-02,  1.8473e-02,\n           1.3143e-02, -1.2351e-02,  1.7619e-02,  2.1178e-02, -7.2509e-03,\n           1.7539e-03,  8.9103e-03,  6.8085e-03, -1.8319e-02, -6.9452e-03,\n          -9.7860e-03,  1.2727e-02,  6.6076e-03,  1.7720e-02,  1.4674e-02,\n          -1.2926e-02, -1.6900e-02, -1.1140e-02,  1.4983e-02, -1.1368e-02,\n           9.4286e-03,  1.4835e-02, -1.5095e-02,  1.0321e-02,  1.3902e-02,\n          -1.7476e-02, -1.6859e-02, -1.0545e-02, -1.1084e-02, -1.1835e-02,\n          -1.1957e-02, -8.5929e-03, -1.3127e-02, -1.3736e-02,  1.3488e-02,\n          -2.0739e-02,  2.0337e-02,  5.7911e-03, -6.8449e-03,  1.3518e-02,\n          -8.1384e-04, -1.8692e-02,  9.2392e-03,  1.1783e-02, -1.8160e-02,\n          -1.9098e-02, -1.1255e-02, -1.0805e-02,  8.0050e-03, -1.8007e-02,\n          -1.5128e-02, -2.1591e-02, -2.1274e-02, -1.1624e-02,  1.9031e-02,\n          -4.1611e-03,  1.0402e-02, -6.3048e-03, -2.2016e-03,  1.0273e-02,\n          -9.4744e-03, -1.1790e-03,  1.9104e-02,  2.1342e-02, -3.6236e-03,\n          -1.0277e-03,  1.5656e-02, -1.3345e-02, -1.1322e-03, -1.7586e-02,\n           4.8012e-03,  1.5300e-02,  4.5882e-03,  2.1683e-02, -2.1033e-02,\n          -1.5027e-02, -6.3138e-03,  2.1747e-02, -2.1445e-02,  1.0298e-02,\n          -2.2789e-03, -6.4715e-03,  1.9718e-02, -4.3231e-03, -1.1430e-02,\n          -1.5865e-04, -1.4925e-02,  1.5791e-02,  1.3199e-02, -1.4581e-05,\n          -1.4061e-02,  5.8062e-03, -3.1722e-03, -1.6711e-02, -4.6809e-04,\n          -4.7077e-03,  1.9770e-03,  2.1560e-02,  5.8819e-03,  8.6811e-03,\n          -1.3900e-02,  1.2796e-02,  1.1072e-02, -1.9871e-02, -2.1805e-02,\n          -6.9476e-03,  4.2047e-03,  1.1786e-02, -1.2602e-02,  2.0011e-02,\n          -2.0960e-02, -2.0632e-02,  1.9798e-02, -1.8500e-02,  1.4066e-02,\n           9.7893e-03, -1.4190e-02, -1.2838e-02, -8.0358e-03,  9.5744e-03,\n          -2.1932e-02,  1.7855e-02,  8.4145e-03,  1.7016e-02,  1.1687e-02,\n          -3.4172e-03,  1.6287e-02,  5.0397e-03,  1.7872e-02,  1.1479e-02,\n           2.1969e-02,  1.0821e-02, -7.9417e-03,  7.1654e-03,  2.1060e-02,\n          -8.3020e-03, -1.8638e-02, -9.3095e-04, -7.7715e-03, -8.2957e-03,\n          -1.3282e-02, -1.9109e-02, -1.2374e-02,  9.7353e-04, -8.1837e-03,\n          -1.4622e-02,  1.1454e-02,  1.0515e-02, -1.9166e-02, -6.8525e-03,\n          -1.8575e-02,  5.7142e-03,  1.4394e-03,  8.9292e-03,  5.1929e-03,\n          -1.2240e-02, -2.2635e-03,  1.3791e-02, -2.4685e-03, -7.2995e-03,\n          -1.4123e-02,  1.6297e-02, -3.3858e-03, -4.4183e-03,  1.8000e-02,\n          -1.4335e-02,  4.5018e-03,  1.5483e-02,  2.5999e-04, -1.1335e-03,\n           8.6351e-03,  7.0153e-03,  1.8897e-02, -1.5894e-02,  4.6480e-03,\n          -1.9323e-02,  1.5131e-02,  1.7955e-02,  4.6175e-03, -1.0162e-02,\n          -2.1903e-02, -1.3536e-02,  2.1272e-02,  1.2172e-02,  1.5229e-02,\n           1.5017e-02, -6.5936e-04,  9.1162e-03,  1.1969e-02,  3.7553e-03,\n           2.5052e-03, -7.1500e-03, -1.2421e-02, -7.1459e-03, -4.2322e-03,\n           1.3768e-02,  1.4648e-02,  1.5209e-02,  1.9892e-02,  7.9093e-03,\n           4.3179e-03, -1.3151e-02, -2.3440e-04,  3.3739e-03,  1.0237e-04,\n           1.8864e-02,  1.2870e-02, -9.9585e-04, -2.1991e-02, -1.4360e-02,\n           3.7434e-03, -7.6701e-03, -1.1384e-02,  1.6661e-02,  1.9187e-02,\n          -2.0348e-02, -1.4835e-02, -1.5876e-02, -1.6566e-02, -1.7361e-02,\n          -8.1709e-03, -1.3951e-02, -7.7663e-03,  1.7139e-02, -1.2510e-03,\n           2.1167e-02,  1.2276e-02,  1.5110e-02,  1.6990e-02, -1.9665e-02,\n           1.3673e-02, -9.1360e-03,  8.1295e-03,  1.7129e-02,  1.0140e-02,\n          -5.9856e-03, -7.5962e-03,  1.6340e-02, -1.9074e-02,  1.3153e-02,\n           7.5182e-03, -5.6618e-03,  1.2192e-02,  2.4147e-03,  2.1047e-02,\n          -1.1521e-02, -1.0900e-02, -2.1034e-02,  1.3398e-02, -1.0785e-02,\n           1.8369e-03,  1.5977e-02,  1.2432e-02, -7.9101e-05,  1.1572e-02,\n           1.2245e-02, -6.3671e-03, -1.4696e-02, -1.6340e-02,  1.5202e-02,\n          -1.2289e-02, -2.7069e-03, -7.0397e-03,  2.1084e-02, -8.9272e-03,\n          -1.2174e-02, -3.4679e-03,  1.3586e-02,  1.8469e-02,  1.1128e-02,\n          -1.4652e-02, -1.4174e-03, -2.5736e-03, -1.5123e-02,  8.1012e-03,\n          -2.0349e-02,  1.0656e-02, -2.0199e-02, -1.1416e-02, -9.7104e-03,\n           2.0190e-02,  1.2100e-02, -3.8040e-03,  1.1001e-02,  5.2912e-03,\n          -4.6104e-03,  1.0243e-02,  1.3352e-02,  2.1053e-02, -6.2129e-03,\n          -2.0363e-02,  1.6866e-02,  1.1901e-02,  8.1996e-03,  1.5963e-03,\n          -1.7059e-02,  1.5045e-02, -1.8559e-02,  1.3757e-02, -1.8632e-02,\n          -2.2015e-02,  2.0504e-02,  1.5887e-02, -1.2357e-02, -1.8150e-02,\n           1.1014e-02, -1.2420e-02,  1.7391e-02,  1.2971e-02,  1.7690e-02,\n           2.1935e-02,  3.9169e-03,  1.3033e-02, -1.6934e-02,  1.5721e-02,\n           1.1105e-02, -1.5463e-02,  1.5717e-02,  1.6165e-02,  1.9766e-02,\n           8.9036e-03,  5.6378e-03, -8.1526e-03, -8.4512e-03, -2.0250e-02,\n           1.2077e-02,  7.5124e-03, -2.1096e-02,  1.3698e-03, -1.3093e-02,\n           1.3279e-02,  6.6738e-03,  1.8701e-02, -6.9794e-03,  1.0992e-02,\n           1.5188e-03, -4.6861e-03,  7.2525e-03, -1.2847e-02,  1.9655e-02,\n          -1.5097e-02, -2.0911e-03, -9.8533e-03, -7.6127e-03, -9.8279e-03,\n           8.1965e-03,  8.5138e-03, -1.6099e-02, -1.5560e-02, -6.0219e-03,\n          -2.1577e-02, -1.4375e-02,  9.0273e-03, -4.5386e-03,  2.0099e-02,\n           1.0280e-02,  4.0028e-04, -1.7355e-02, -3.2309e-03,  5.0577e-03,\n          -1.9788e-02, -1.6672e-02,  9.0755e-04,  3.9617e-03, -1.6378e-02,\n           1.4650e-02,  1.9184e-02,  2.2063e-02,  3.0684e-03,  3.6840e-03,\n           1.5183e-02,  6.2177e-03, -8.0125e-03,  2.0416e-02,  6.6802e-03,\n           1.9526e-02, -7.2869e-03, -1.6115e-02,  1.6575e-02, -2.1773e-02,\n           1.4647e-02, -1.1335e-03,  1.1754e-02,  7.4279e-03,  2.1790e-02,\n           9.7781e-03, -1.1670e-02,  1.8610e-02, -9.9980e-03,  2.0379e-02,\n           2.0725e-02,  3.3085e-03,  1.8963e-02,  6.0999e-03,  9.5618e-03,\n          -1.7002e-04,  6.4194e-03, -1.9245e-02, -1.2431e-02, -2.1172e-02,\n          -1.8921e-03, -1.3325e-02, -3.3971e-03, -1.1584e-02, -1.7310e-02,\n          -6.4643e-03,  3.3318e-03, -1.2277e-02,  1.5242e-02,  1.1760e-02,\n          -1.6007e-02,  2.0333e-03, -7.5641e-03,  8.6426e-03, -1.3459e-02,\n           7.0664e-03,  1.2533e-02, -1.9227e-02, -1.3475e-02, -1.4893e-02,\n           5.8377e-03, -1.1470e-02, -3.8911e-03,  2.1943e-02, -5.3640e-03,\n          -1.2865e-02,  3.3044e-03,  2.0893e-02, -1.3921e-05,  1.5204e-02,\n           3.6257e-03,  1.7901e-02,  1.0070e-02,  6.9632e-03, -1.9174e-03,\n           1.6392e-02, -9.9775e-03,  1.8044e-02, -1.5411e-02, -1.3273e-02,\n          -1.7880e-02, -7.8289e-03,  2.2550e-03,  6.3893e-03,  3.5462e-03,\n           6.9925e-03, -2.5911e-03, -1.0612e-02,  1.4826e-02,  1.3884e-02,\n          -1.4000e-03,  1.5987e-03, -4.6452e-03, -1.1618e-02, -2.0149e-02,\n          -1.3772e-02, -1.7160e-02, -8.4254e-03, -7.1950e-03, -4.1100e-03,\n          -1.2062e-02, -1.7413e-02,  1.5985e-02, -8.4590e-03, -1.4495e-02,\n          -5.3490e-03,  8.3093e-03, -4.2371e-03,  1.6793e-02, -1.3310e-02,\n           3.6993e-03,  1.3885e-02, -1.0712e-02,  2.4818e-03,  1.4337e-02,\n           2.0618e-02, -8.4925e-03, -1.8957e-02, -1.8900e-03,  1.9504e-02,\n           1.3275e-02,  1.1105e-02, -1.4725e-02,  3.2079e-03, -1.6973e-02,\n           3.6681e-03,  7.1125e-04,  6.5027e-03, -1.7414e-02,  8.2018e-03,\n          -1.3817e-02,  1.2712e-02, -1.5307e-02, -6.0227e-03,  1.5489e-02,\n           7.1236e-03,  2.3681e-03,  6.0732e-03, -4.2783e-03,  1.2268e-02,\n          -8.3375e-03,  2.0609e-02, -8.2188e-03,  1.4331e-02,  1.7850e-02,\n           1.5566e-02,  1.8160e-03, -5.8200e-03,  1.7657e-02,  1.9558e-02,\n          -1.7277e-02,  2.1292e-02, -1.2465e-02, -1.7991e-02, -2.0505e-02,\n          -1.3503e-02, -4.1113e-03, -1.1449e-02,  2.4823e-03, -1.1202e-02,\n          -6.9809e-04, -1.8982e-02, -5.3955e-04,  9.1083e-04, -1.5664e-02,\n          -1.8429e-02,  1.0945e-02, -1.2788e-02,  4.6081e-03, -5.5316e-03,\n          -1.2816e-02,  3.8990e-03,  1.6105e-02, -5.4946e-03,  5.6768e-03,\n           1.5971e-02,  2.6038e-03, -8.8425e-03, -1.7558e-03,  9.6863e-03,\n          -1.2111e-02, -5.9780e-03,  7.3771e-03,  1.1320e-02,  2.1157e-02,\n          -9.7849e-03, -1.3291e-02,  1.4207e-02,  3.2374e-03,  2.0961e-02,\n           7.2693e-03,  5.8949e-04, -9.8841e-03,  3.5098e-03,  1.6390e-02,\n          -1.0017e-02, -3.1970e-04, -5.9094e-03, -6.4119e-03,  5.3413e-03,\n           7.1157e-03,  6.4619e-03,  1.1393e-02, -7.1464e-03,  5.1133e-03,\n           9.0641e-03,  9.6438e-03,  9.0189e-05,  1.0883e-02, -3.7932e-03,\n           2.5017e-03, -1.7825e-02, -1.4203e-02, -1.7710e-03, -7.1340e-04,\n          -4.0021e-03, -9.6363e-03, -5.5243e-03, -7.0829e-03,  1.0999e-02,\n           1.1586e-02,  2.4833e-03,  1.5734e-02,  1.1409e-02,  8.6240e-04,\n          -1.7745e-02,  1.2150e-02,  1.3793e-02,  1.9770e-02, -3.3163e-03,\n           1.5077e-02,  1.6411e-02, -4.1076e-03,  8.8523e-03, -1.1404e-02,\n          -9.1464e-03,  4.6428e-03,  3.9873e-03, -3.1982e-03,  2.0111e-02,\n          -1.5999e-02, -1.7787e-03,  3.6124e-03,  4.0629e-03, -4.5407e-03,\n           8.6281e-03, -1.3185e-02,  1.2544e-03,  5.6449e-03,  2.0068e-03,\n          -6.1967e-03,  3.6230e-03, -1.5569e-02, -9.3001e-03,  2.0333e-03,\n          -1.3977e-02, -1.3309e-02, -1.3870e-02, -4.3964e-03, -7.7488e-03,\n          -1.3162e-02,  8.4607e-03, -1.7212e-02,  2.7149e-03,  1.3080e-02,\n          -1.4455e-02, -1.9062e-02,  1.3224e-02, -4.5129e-03,  3.6081e-03,\n           2.7577e-03,  4.0550e-03, -1.6445e-02, -1.1008e-02,  1.6174e-02,\n          -7.7051e-03,  6.3677e-03, -1.3266e-02, -7.3469e-03,  1.4390e-02,\n          -3.2118e-03, -8.6737e-03,  1.5162e-02,  1.0866e-02,  6.9447e-03,\n           1.0797e-02, -1.7845e-02,  6.7007e-03, -1.9287e-02, -2.1862e-02,\n           1.9741e-02, -1.9081e-02, -1.4026e-02,  1.1471e-02,  1.7169e-02,\n          -1.9041e-02,  7.0727e-03,  2.2238e-03, -9.9619e-03,  1.3220e-02,\n          -3.2950e-04,  1.2184e-02,  1.7468e-02,  2.2058e-02, -1.5459e-03,\n           6.7954e-03, -1.2202e-02, -2.0387e-03, -1.5792e-03,  6.3441e-03,\n          -1.1300e-02, -6.2397e-03, -1.8822e-03,  1.4816e-02,  6.6225e-03,\n           9.9826e-03, -8.7119e-03,  3.0391e-03, -2.8649e-03, -1.3948e-02,\n           2.0792e-02,  1.0017e-02, -3.1149e-03, -1.7141e-02,  1.1803e-02,\n          -4.2656e-03,  1.6982e-02,  5.9842e-04, -2.0265e-02,  4.7678e-03,\n           5.1757e-03,  1.6460e-02, -1.7625e-02,  9.2040e-03,  1.4852e-02,\n          -3.9193e-03,  1.7594e-02, -9.7115e-03,  5.8997e-03, -5.5003e-03,\n          -1.6391e-02,  2.0805e-02, -1.4473e-02, -1.5498e-02, -2.1715e-02,\n          -1.8653e-02, -1.0868e-02,  3.8331e-04,  1.8159e-02, -1.8092e-02,\n          -1.1388e-02,  5.8366e-03,  1.1091e-02, -2.1615e-02, -4.4408e-03,\n          -1.0165e-02, -8.3646e-03,  1.6342e-02, -1.0834e-02,  8.9725e-03],\n         requires_grad=True))]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet50.named_parameters())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:19:28.072850900Z",
     "start_time": "2023-12-28T15:19:27.593846300Z"
    }
   },
   "id": "8559cbb60513de6f"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn = nn.BatchNorm2d(123)\n",
    "list(bn.named_children())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:25:54.756517500Z",
     "start_time": "2023-12-28T15:25:54.287998400Z"
    }
   },
   "id": "f86c8c6a79ff7280"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "[[4], [4], [4]]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [[]] * 3\n",
    "l[0].append(4)\n",
    "l"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:28:43.916532100Z",
     "start_time": "2023-12-28T15:28:43.500455600Z"
    }
   },
   "id": "c11963e7398038cc"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def bn_filter(module_name, module, param_name, param):\n",
    "    return isinstance(module, (nn.InstanceNorm1d, nn.InstanceNorm2d, nn.InstanceNorm3d, nn.LazyInstanceNorm1d, nn.LazyInstanceNorm2d, nn.LazyInstanceNorm3d, nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d, nn.LazyBatchNorm1d, nn.LazyBatchNorm2d, nn.LazyBatchNorm3d))\n",
    "\n",
    "def bias_filter(module_name, module, param_name, param):\n",
    "    return param_name == \"bias\"\n",
    "\n",
    "def bn_or_bias_filter(module_name, module, param_name, param):\n",
    "    return bn_filter(module_name, module, param_name, param) or bias_filter(module_name, module, param_name, param)\n",
    "\n",
    "def pass_all_filter(module_name, module, param_name, param):\n",
    "    return True\n",
    "\n",
    "def split_params(model: nn.Module, filters, prefix=\"\"):\n",
    "    results = []\n",
    "    for i in range(len(filters)):\n",
    "        results.append([])\n",
    "    for module_name, module in model.named_children():\n",
    "        full_module_name = prefix + module_name\n",
    "        for param_name, param in module.named_parameters(recurse=False):\n",
    "            for i, f in enumerate(filters):\n",
    "                if f(full_module_name, module, param_name, param):\n",
    "                    results[i].append(param)\n",
    "                    break\n",
    "        module_results = split_params(module, filters, full_module_name + \".\")\n",
    "        for i in range(len(filters)):\n",
    "            results[i] += module_results[i]\n",
    "    return results\n",
    "\n",
    "def add_weight_decay(\n",
    "        model, \n",
    "        weight_decay=1e-5):\n",
    "    params = split_params(model, [bn_or_bias_filter, pass_all_filter])\n",
    "    return [\n",
    "        {'params': params[0], 'weight_decay': 0.},\n",
    "        {'params': params[1], 'weight_decay': weight_decay}]\n",
    "\n",
    "# result = split_params(resnet50, [bn_or_bias_filter, pass_all_filter])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:41:44.195483800Z",
     "start_time": "2023-12-28T15:41:43.867304400Z"
    }
   },
   "id": "ec23306805f75690"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "AdamW (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 0.0\n\nParameter Group 1\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.001\n    maximize: False\n    weight_decay: 1e-05\n)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "AdamW(add_weight_decay(resnet50), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:47:09.046264400Z",
     "start_time": "2023-12-28T15:47:08.624713300Z"
    }
   },
   "id": "82548b81b1582efd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "21d97eda78138f48"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "['conv1.weight',\n 'layer1.0.conv1.weight',\n 'layer1.0.conv2.weight',\n 'layer1.0.conv3.weight',\n 'layer1.0.downsample.0.weight',\n 'layer1.1.conv1.weight',\n 'layer1.1.conv2.weight',\n 'layer1.1.conv3.weight',\n 'layer1.2.conv1.weight',\n 'layer1.2.conv2.weight',\n 'layer1.2.conv3.weight',\n 'layer2.0.conv1.weight',\n 'layer2.0.conv2.weight',\n 'layer2.0.conv3.weight',\n 'layer2.0.downsample.0.weight',\n 'layer2.1.conv1.weight',\n 'layer2.1.conv2.weight',\n 'layer2.1.conv3.weight',\n 'layer2.2.conv1.weight',\n 'layer2.2.conv2.weight',\n 'layer2.2.conv3.weight',\n 'layer2.3.conv1.weight',\n 'layer2.3.conv2.weight',\n 'layer2.3.conv3.weight',\n 'layer3.0.conv1.weight',\n 'layer3.0.conv2.weight',\n 'layer3.0.conv3.weight',\n 'layer3.0.downsample.0.weight',\n 'layer3.1.conv1.weight',\n 'layer3.1.conv2.weight',\n 'layer3.1.conv3.weight',\n 'layer3.2.conv1.weight',\n 'layer3.2.conv2.weight',\n 'layer3.2.conv3.weight',\n 'layer3.3.conv1.weight',\n 'layer3.3.conv2.weight',\n 'layer3.3.conv3.weight',\n 'layer3.4.conv1.weight',\n 'layer3.4.conv2.weight',\n 'layer3.4.conv3.weight',\n 'layer3.5.conv1.weight',\n 'layer3.5.conv2.weight',\n 'layer3.5.conv3.weight',\n 'layer4.0.conv1.weight',\n 'layer4.0.conv2.weight',\n 'layer4.0.conv3.weight',\n 'layer4.0.downsample.0.weight',\n 'layer4.1.conv1.weight',\n 'layer4.1.conv2.weight',\n 'layer4.1.conv3.weight',\n 'layer4.2.conv1.weight',\n 'layer4.2.conv2.weight',\n 'layer4.2.conv3.weight',\n 'fc.weight']"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m[0] for m in result[1]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:39:12.810111100Z",
     "start_time": "2023-12-28T15:39:12.276111400Z"
    }
   },
   "id": "35ade6e993f711cc"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(resnet50.named_parameters(recurse=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:30:12.117268200Z",
     "start_time": "2023-12-28T15:30:11.397982700Z"
    }
   },
   "id": "1b44c44915a148e9"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "['.conv1.weight',\n '.bn1.weight',\n '.bn1.bias',\n '.layer1.0.conv1.weight',\n '.layer1.0.bn1.weight',\n '.layer1.0.bn1.bias',\n '.layer1.0.conv2.weight',\n '.layer1.0.bn2.weight',\n '.layer1.0.bn2.bias',\n '.layer1.0.conv3.weight',\n '.layer1.0.bn3.weight',\n '.layer1.0.bn3.bias',\n '.layer1.0.downsample.0.weight',\n '.layer1.0.downsample.1.weight',\n '.layer1.0.downsample.1.bias',\n '.layer1.1.conv1.weight',\n '.layer1.1.bn1.weight',\n '.layer1.1.bn1.bias',\n '.layer1.1.conv2.weight',\n '.layer1.1.bn2.weight',\n '.layer1.1.bn2.bias',\n '.layer1.1.conv3.weight',\n '.layer1.1.bn3.weight',\n '.layer1.1.bn3.bias',\n '.layer1.2.conv1.weight',\n '.layer1.2.bn1.weight',\n '.layer1.2.bn1.bias',\n '.layer1.2.conv2.weight',\n '.layer1.2.bn2.weight',\n '.layer1.2.bn2.bias',\n '.layer1.2.conv3.weight',\n '.layer1.2.bn3.weight',\n '.layer1.2.bn3.bias',\n '.layer2.0.conv1.weight',\n '.layer2.0.bn1.weight',\n '.layer2.0.bn1.bias',\n '.layer2.0.conv2.weight',\n '.layer2.0.bn2.weight',\n '.layer2.0.bn2.bias',\n '.layer2.0.conv3.weight',\n '.layer2.0.bn3.weight',\n '.layer2.0.bn3.bias',\n '.layer2.0.downsample.0.weight',\n '.layer2.0.downsample.1.weight',\n '.layer2.0.downsample.1.bias',\n '.layer2.1.conv1.weight',\n '.layer2.1.bn1.weight',\n '.layer2.1.bn1.bias',\n '.layer2.1.conv2.weight',\n '.layer2.1.bn2.weight',\n '.layer2.1.bn2.bias',\n '.layer2.1.conv3.weight',\n '.layer2.1.bn3.weight',\n '.layer2.1.bn3.bias',\n '.layer2.2.conv1.weight',\n '.layer2.2.bn1.weight',\n '.layer2.2.bn1.bias',\n '.layer2.2.conv2.weight',\n '.layer2.2.bn2.weight',\n '.layer2.2.bn2.bias',\n '.layer2.2.conv3.weight',\n '.layer2.2.bn3.weight',\n '.layer2.2.bn3.bias',\n '.layer2.3.conv1.weight',\n '.layer2.3.bn1.weight',\n '.layer2.3.bn1.bias',\n '.layer2.3.conv2.weight',\n '.layer2.3.bn2.weight',\n '.layer2.3.bn2.bias',\n '.layer2.3.conv3.weight',\n '.layer2.3.bn3.weight',\n '.layer2.3.bn3.bias',\n '.layer3.0.conv1.weight',\n '.layer3.0.bn1.weight',\n '.layer3.0.bn1.bias',\n '.layer3.0.conv2.weight',\n '.layer3.0.bn2.weight',\n '.layer3.0.bn2.bias',\n '.layer3.0.conv3.weight',\n '.layer3.0.bn3.weight',\n '.layer3.0.bn3.bias',\n '.layer3.0.downsample.0.weight',\n '.layer3.0.downsample.1.weight',\n '.layer3.0.downsample.1.bias',\n '.layer3.1.conv1.weight',\n '.layer3.1.bn1.weight',\n '.layer3.1.bn1.bias',\n '.layer3.1.conv2.weight',\n '.layer3.1.bn2.weight',\n '.layer3.1.bn2.bias',\n '.layer3.1.conv3.weight',\n '.layer3.1.bn3.weight',\n '.layer3.1.bn3.bias',\n '.layer3.2.conv1.weight',\n '.layer3.2.bn1.weight',\n '.layer3.2.bn1.bias',\n '.layer3.2.conv2.weight',\n '.layer3.2.bn2.weight',\n '.layer3.2.bn2.bias',\n '.layer3.2.conv3.weight',\n '.layer3.2.bn3.weight',\n '.layer3.2.bn3.bias',\n '.layer3.3.conv1.weight',\n '.layer3.3.bn1.weight',\n '.layer3.3.bn1.bias',\n '.layer3.3.conv2.weight',\n '.layer3.3.bn2.weight',\n '.layer3.3.bn2.bias',\n '.layer3.3.conv3.weight',\n '.layer3.3.bn3.weight',\n '.layer3.3.bn3.bias',\n '.layer3.4.conv1.weight',\n '.layer3.4.bn1.weight',\n '.layer3.4.bn1.bias',\n '.layer3.4.conv2.weight',\n '.layer3.4.bn2.weight',\n '.layer3.4.bn2.bias',\n '.layer3.4.conv3.weight',\n '.layer3.4.bn3.weight',\n '.layer3.4.bn3.bias',\n '.layer3.5.conv1.weight',\n '.layer3.5.bn1.weight',\n '.layer3.5.bn1.bias',\n '.layer3.5.conv2.weight',\n '.layer3.5.bn2.weight',\n '.layer3.5.bn2.bias',\n '.layer3.5.conv3.weight',\n '.layer3.5.bn3.weight',\n '.layer3.5.bn3.bias',\n '.layer4.0.conv1.weight',\n '.layer4.0.bn1.weight',\n '.layer4.0.bn1.bias',\n '.layer4.0.conv2.weight',\n '.layer4.0.bn2.weight',\n '.layer4.0.bn2.bias',\n '.layer4.0.conv3.weight',\n '.layer4.0.bn3.weight',\n '.layer4.0.bn3.bias',\n '.layer4.0.downsample.0.weight',\n '.layer4.0.downsample.1.weight',\n '.layer4.0.downsample.1.bias',\n '.layer4.1.conv1.weight',\n '.layer4.1.bn1.weight',\n '.layer4.1.bn1.bias',\n '.layer4.1.conv2.weight',\n '.layer4.1.bn2.weight',\n '.layer4.1.bn2.bias',\n '.layer4.1.conv3.weight',\n '.layer4.1.bn3.weight',\n '.layer4.1.bn3.bias',\n '.layer4.2.conv1.weight',\n '.layer4.2.bn1.weight',\n '.layer4.2.bn1.bias',\n '.layer4.2.conv2.weight',\n '.layer4.2.bn2.weight',\n '.layer4.2.bn2.bias',\n '.layer4.2.conv3.weight',\n '.layer4.2.bn3.weight',\n '.layer4.2.bn3.bias',\n '.fc.weight',\n '.fc.bias',\n 'conv1.weight',\n 'layer1.0.conv1.weight',\n 'layer1.0.bn1.weight',\n 'layer1.0.bn1.bias',\n 'layer1.0.conv2.weight',\n 'layer1.0.bn2.weight',\n 'layer1.0.bn2.bias',\n 'layer1.0.conv3.weight',\n 'layer1.0.bn3.weight',\n 'layer1.0.bn3.bias',\n 'layer1.0.downsample.0.weight',\n 'layer1.0.downsample.1.weight',\n 'layer1.0.downsample.1.bias',\n 'layer1.1.conv1.weight',\n 'layer1.1.bn1.weight',\n 'layer1.1.bn1.bias',\n 'layer1.1.conv2.weight',\n 'layer1.1.bn2.weight',\n 'layer1.1.bn2.bias',\n 'layer1.1.conv3.weight',\n 'layer1.1.bn3.weight',\n 'layer1.1.bn3.bias',\n 'layer1.2.conv1.weight',\n 'layer1.2.bn1.weight',\n 'layer1.2.bn1.bias',\n 'layer1.2.conv2.weight',\n 'layer1.2.bn2.weight',\n 'layer1.2.bn2.bias',\n 'layer1.2.conv3.weight',\n 'layer1.2.bn3.weight',\n 'layer1.2.bn3.bias',\n 'layer1.0.conv1.weight',\n 'layer1.0.bn1.weight',\n 'layer1.0.bn1.bias',\n 'layer1.0.conv2.weight',\n 'layer1.0.bn2.weight',\n 'layer1.0.bn2.bias',\n 'layer1.0.conv3.weight',\n 'layer1.0.bn3.weight',\n 'layer1.0.bn3.bias',\n 'layer1.0.downsample.0.weight',\n 'layer1.0.downsample.1.weight',\n 'layer1.0.downsample.1.bias',\n 'layer1.0.conv1.weight',\n 'layer1.0.conv2.weight',\n 'layer1.0.conv3.weight',\n 'layer1.0.downsample.0.weight',\n 'layer1.0.downsample.1.weight',\n 'layer1.0.downsample.1.bias',\n 'layer1.0.downsample.0.weight',\n 'layer1.1.conv1.weight',\n 'layer1.1.bn1.weight',\n 'layer1.1.bn1.bias',\n 'layer1.1.conv2.weight',\n 'layer1.1.bn2.weight',\n 'layer1.1.bn2.bias',\n 'layer1.1.conv3.weight',\n 'layer1.1.bn3.weight',\n 'layer1.1.bn3.bias',\n 'layer1.1.conv1.weight',\n 'layer1.1.conv2.weight',\n 'layer1.1.conv3.weight',\n 'layer1.2.conv1.weight',\n 'layer1.2.bn1.weight',\n 'layer1.2.bn1.bias',\n 'layer1.2.conv2.weight',\n 'layer1.2.bn2.weight',\n 'layer1.2.bn2.bias',\n 'layer1.2.conv3.weight',\n 'layer1.2.bn3.weight',\n 'layer1.2.bn3.bias',\n 'layer1.2.conv1.weight',\n 'layer1.2.conv2.weight',\n 'layer1.2.conv3.weight',\n 'layer2.0.conv1.weight',\n 'layer2.0.bn1.weight',\n 'layer2.0.bn1.bias',\n 'layer2.0.conv2.weight',\n 'layer2.0.bn2.weight',\n 'layer2.0.bn2.bias',\n 'layer2.0.conv3.weight',\n 'layer2.0.bn3.weight',\n 'layer2.0.bn3.bias',\n 'layer2.0.downsample.0.weight',\n 'layer2.0.downsample.1.weight',\n 'layer2.0.downsample.1.bias',\n 'layer2.1.conv1.weight',\n 'layer2.1.bn1.weight',\n 'layer2.1.bn1.bias',\n 'layer2.1.conv2.weight',\n 'layer2.1.bn2.weight',\n 'layer2.1.bn2.bias',\n 'layer2.1.conv3.weight',\n 'layer2.1.bn3.weight',\n 'layer2.1.bn3.bias',\n 'layer2.2.conv1.weight',\n 'layer2.2.bn1.weight',\n 'layer2.2.bn1.bias',\n 'layer2.2.conv2.weight',\n 'layer2.2.bn2.weight',\n 'layer2.2.bn2.bias',\n 'layer2.2.conv3.weight',\n 'layer2.2.bn3.weight',\n 'layer2.2.bn3.bias',\n 'layer2.3.conv1.weight',\n 'layer2.3.bn1.weight',\n 'layer2.3.bn1.bias',\n 'layer2.3.conv2.weight',\n 'layer2.3.bn2.weight',\n 'layer2.3.bn2.bias',\n 'layer2.3.conv3.weight',\n 'layer2.3.bn3.weight',\n 'layer2.3.bn3.bias',\n 'layer2.0.conv1.weight',\n 'layer2.0.bn1.weight',\n 'layer2.0.bn1.bias',\n 'layer2.0.conv2.weight',\n 'layer2.0.bn2.weight',\n 'layer2.0.bn2.bias',\n 'layer2.0.conv3.weight',\n 'layer2.0.bn3.weight',\n 'layer2.0.bn3.bias',\n 'layer2.0.downsample.0.weight',\n 'layer2.0.downsample.1.weight',\n 'layer2.0.downsample.1.bias',\n 'layer2.0.conv1.weight',\n 'layer2.0.conv2.weight',\n 'layer2.0.conv3.weight',\n 'layer2.0.downsample.0.weight',\n 'layer2.0.downsample.1.weight',\n 'layer2.0.downsample.1.bias',\n 'layer2.0.downsample.0.weight',\n 'layer2.1.conv1.weight',\n 'layer2.1.bn1.weight',\n 'layer2.1.bn1.bias',\n 'layer2.1.conv2.weight',\n 'layer2.1.bn2.weight',\n 'layer2.1.bn2.bias',\n 'layer2.1.conv3.weight',\n 'layer2.1.bn3.weight',\n 'layer2.1.bn3.bias',\n 'layer2.1.conv1.weight',\n 'layer2.1.conv2.weight',\n 'layer2.1.conv3.weight',\n 'layer2.2.conv1.weight',\n 'layer2.2.bn1.weight',\n 'layer2.2.bn1.bias',\n 'layer2.2.conv2.weight',\n 'layer2.2.bn2.weight',\n 'layer2.2.bn2.bias',\n 'layer2.2.conv3.weight',\n 'layer2.2.bn3.weight',\n 'layer2.2.bn3.bias',\n 'layer2.2.conv1.weight',\n 'layer2.2.conv2.weight',\n 'layer2.2.conv3.weight',\n 'layer2.3.conv1.weight',\n 'layer2.3.bn1.weight',\n 'layer2.3.bn1.bias',\n 'layer2.3.conv2.weight',\n 'layer2.3.bn2.weight',\n 'layer2.3.bn2.bias',\n 'layer2.3.conv3.weight',\n 'layer2.3.bn3.weight',\n 'layer2.3.bn3.bias',\n 'layer2.3.conv1.weight',\n 'layer2.3.conv2.weight',\n 'layer2.3.conv3.weight',\n 'layer3.0.conv1.weight',\n 'layer3.0.bn1.weight',\n 'layer3.0.bn1.bias',\n 'layer3.0.conv2.weight',\n 'layer3.0.bn2.weight',\n 'layer3.0.bn2.bias',\n 'layer3.0.conv3.weight',\n 'layer3.0.bn3.weight',\n 'layer3.0.bn3.bias',\n 'layer3.0.downsample.0.weight',\n 'layer3.0.downsample.1.weight',\n 'layer3.0.downsample.1.bias',\n 'layer3.1.conv1.weight',\n 'layer3.1.bn1.weight',\n 'layer3.1.bn1.bias',\n 'layer3.1.conv2.weight',\n 'layer3.1.bn2.weight',\n 'layer3.1.bn2.bias',\n 'layer3.1.conv3.weight',\n 'layer3.1.bn3.weight',\n 'layer3.1.bn3.bias',\n 'layer3.2.conv1.weight',\n 'layer3.2.bn1.weight',\n 'layer3.2.bn1.bias',\n 'layer3.2.conv2.weight',\n 'layer3.2.bn2.weight',\n 'layer3.2.bn2.bias',\n 'layer3.2.conv3.weight',\n 'layer3.2.bn3.weight',\n 'layer3.2.bn3.bias',\n 'layer3.3.conv1.weight',\n 'layer3.3.bn1.weight',\n 'layer3.3.bn1.bias',\n 'layer3.3.conv2.weight',\n 'layer3.3.bn2.weight',\n 'layer3.3.bn2.bias',\n 'layer3.3.conv3.weight',\n 'layer3.3.bn3.weight',\n 'layer3.3.bn3.bias',\n 'layer3.4.conv1.weight',\n 'layer3.4.bn1.weight',\n 'layer3.4.bn1.bias',\n 'layer3.4.conv2.weight',\n 'layer3.4.bn2.weight',\n 'layer3.4.bn2.bias',\n 'layer3.4.conv3.weight',\n 'layer3.4.bn3.weight',\n 'layer3.4.bn3.bias',\n 'layer3.5.conv1.weight',\n 'layer3.5.bn1.weight',\n 'layer3.5.bn1.bias',\n 'layer3.5.conv2.weight',\n 'layer3.5.bn2.weight',\n 'layer3.5.bn2.bias',\n 'layer3.5.conv3.weight',\n 'layer3.5.bn3.weight',\n 'layer3.5.bn3.bias',\n 'layer3.0.conv1.weight',\n 'layer3.0.bn1.weight',\n 'layer3.0.bn1.bias',\n 'layer3.0.conv2.weight',\n 'layer3.0.bn2.weight',\n 'layer3.0.bn2.bias',\n 'layer3.0.conv3.weight',\n 'layer3.0.bn3.weight',\n 'layer3.0.bn3.bias',\n 'layer3.0.downsample.0.weight',\n 'layer3.0.downsample.1.weight',\n 'layer3.0.downsample.1.bias',\n 'layer3.0.conv1.weight',\n 'layer3.0.conv2.weight',\n 'layer3.0.conv3.weight',\n 'layer3.0.downsample.0.weight',\n 'layer3.0.downsample.1.weight',\n 'layer3.0.downsample.1.bias',\n 'layer3.0.downsample.0.weight',\n 'layer3.1.conv1.weight',\n 'layer3.1.bn1.weight',\n 'layer3.1.bn1.bias',\n 'layer3.1.conv2.weight',\n 'layer3.1.bn2.weight',\n 'layer3.1.bn2.bias',\n 'layer3.1.conv3.weight',\n 'layer3.1.bn3.weight',\n 'layer3.1.bn3.bias',\n 'layer3.1.conv1.weight',\n 'layer3.1.conv2.weight',\n 'layer3.1.conv3.weight',\n 'layer3.2.conv1.weight',\n 'layer3.2.bn1.weight',\n 'layer3.2.bn1.bias',\n 'layer3.2.conv2.weight',\n 'layer3.2.bn2.weight',\n 'layer3.2.bn2.bias',\n 'layer3.2.conv3.weight',\n 'layer3.2.bn3.weight',\n 'layer3.2.bn3.bias',\n 'layer3.2.conv1.weight',\n 'layer3.2.conv2.weight',\n 'layer3.2.conv3.weight',\n 'layer3.3.conv1.weight',\n 'layer3.3.bn1.weight',\n 'layer3.3.bn1.bias',\n 'layer3.3.conv2.weight',\n 'layer3.3.bn2.weight',\n 'layer3.3.bn2.bias',\n 'layer3.3.conv3.weight',\n 'layer3.3.bn3.weight',\n 'layer3.3.bn3.bias',\n 'layer3.3.conv1.weight',\n 'layer3.3.conv2.weight',\n 'layer3.3.conv3.weight',\n 'layer3.4.conv1.weight',\n 'layer3.4.bn1.weight',\n 'layer3.4.bn1.bias',\n 'layer3.4.conv2.weight',\n 'layer3.4.bn2.weight',\n 'layer3.4.bn2.bias',\n 'layer3.4.conv3.weight',\n 'layer3.4.bn3.weight',\n 'layer3.4.bn3.bias',\n 'layer3.4.conv1.weight',\n 'layer3.4.conv2.weight',\n 'layer3.4.conv3.weight',\n 'layer3.5.conv1.weight',\n 'layer3.5.bn1.weight',\n 'layer3.5.bn1.bias',\n 'layer3.5.conv2.weight',\n 'layer3.5.bn2.weight',\n 'layer3.5.bn2.bias',\n 'layer3.5.conv3.weight',\n 'layer3.5.bn3.weight',\n 'layer3.5.bn3.bias',\n 'layer3.5.conv1.weight',\n 'layer3.5.conv2.weight',\n 'layer3.5.conv3.weight',\n 'layer4.0.conv1.weight',\n 'layer4.0.bn1.weight',\n 'layer4.0.bn1.bias',\n 'layer4.0.conv2.weight',\n 'layer4.0.bn2.weight',\n 'layer4.0.bn2.bias',\n 'layer4.0.conv3.weight',\n 'layer4.0.bn3.weight',\n 'layer4.0.bn3.bias',\n 'layer4.0.downsample.0.weight',\n 'layer4.0.downsample.1.weight',\n 'layer4.0.downsample.1.bias',\n 'layer4.1.conv1.weight',\n 'layer4.1.bn1.weight',\n 'layer4.1.bn1.bias',\n 'layer4.1.conv2.weight',\n 'layer4.1.bn2.weight',\n 'layer4.1.bn2.bias',\n 'layer4.1.conv3.weight',\n 'layer4.1.bn3.weight',\n 'layer4.1.bn3.bias',\n 'layer4.2.conv1.weight',\n 'layer4.2.bn1.weight',\n 'layer4.2.bn1.bias',\n 'layer4.2.conv2.weight',\n 'layer4.2.bn2.weight',\n 'layer4.2.bn2.bias',\n 'layer4.2.conv3.weight',\n 'layer4.2.bn3.weight',\n 'layer4.2.bn3.bias',\n 'layer4.0.conv1.weight',\n 'layer4.0.bn1.weight',\n 'layer4.0.bn1.bias',\n 'layer4.0.conv2.weight',\n 'layer4.0.bn2.weight',\n 'layer4.0.bn2.bias',\n 'layer4.0.conv3.weight',\n 'layer4.0.bn3.weight',\n 'layer4.0.bn3.bias',\n 'layer4.0.downsample.0.weight',\n 'layer4.0.downsample.1.weight',\n 'layer4.0.downsample.1.bias',\n 'layer4.0.conv1.weight',\n 'layer4.0.conv2.weight',\n 'layer4.0.conv3.weight',\n 'layer4.0.downsample.0.weight',\n 'layer4.0.downsample.1.weight',\n 'layer4.0.downsample.1.bias',\n 'layer4.0.downsample.0.weight',\n 'layer4.1.conv1.weight',\n 'layer4.1.bn1.weight',\n 'layer4.1.bn1.bias',\n 'layer4.1.conv2.weight',\n 'layer4.1.bn2.weight',\n 'layer4.1.bn2.bias',\n 'layer4.1.conv3.weight',\n 'layer4.1.bn3.weight',\n 'layer4.1.bn3.bias',\n 'layer4.1.conv1.weight',\n 'layer4.1.conv2.weight',\n 'layer4.1.conv3.weight',\n 'layer4.2.conv1.weight',\n 'layer4.2.bn1.weight',\n 'layer4.2.bn1.bias',\n 'layer4.2.conv2.weight',\n 'layer4.2.bn2.weight',\n 'layer4.2.bn2.bias',\n 'layer4.2.conv3.weight',\n 'layer4.2.bn3.weight',\n 'layer4.2.bn3.bias',\n 'layer4.2.conv1.weight',\n 'layer4.2.conv2.weight',\n 'layer4.2.conv3.weight',\n 'fc.weight',\n 'fc.bias']"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1][\"param_names\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T15:25:01.278893700Z",
     "start_time": "2023-12-28T15:25:01.237707400Z"
    }
   },
   "id": "fe9f389eac666f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-2.)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(12, 100)\n",
    "y = x * 10\n",
    "x_norm = torch.linalg.norm(x, ord=2, dim=1)\n",
    "y_norm = torch.linalg.norm(y, ord=2, dim=1)\n",
    "-2 * torch.mean(torch.sum(x * y, dim=1) / (x_norm * y_norm))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T19:03:58.838708200Z",
     "start_time": "2023-12-28T19:03:57.001062300Z"
    }
   },
   "id": "15dd58c60e3c864d"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train step 0142/2356 - loss 4.558164:   0%|          | 0/10 [00:25<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[31], line 150\u001B[0m\n\u001B[0;32m    147\u001B[0m resnet50 \u001B[38;5;241m=\u001B[39m timm\u001B[38;5;241m.\u001B[39mcreate_model(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresnet50\u001B[39m\u001B[38;5;124m\"\u001B[39m, pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    148\u001B[0m backbone \u001B[38;5;241m=\u001B[39m _Backbone(resnet50)\n\u001B[1;32m--> 150\u001B[0m \u001B[43mcallback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbackbone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2048\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[31], line 66\u001B[0m, in \u001B[0;36mClassificationCallback.eval_model\u001B[1;34m(self, backbone, backbone_output_size)\u001B[0m\n\u001B[0;32m     64\u001B[0m opt\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 66\u001B[0m     features \u001B[38;5;241m=\u001B[39m \u001B[43mbackbone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimage\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m logits \u001B[38;5;241m=\u001B[39m fc(features)\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtclip:\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[31], line 143\u001B[0m, in \u001B[0;36m_Backbone.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m--> 143\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackbone\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    144\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbackbone\u001B[38;5;241m.\u001B[39mglobal_pool(x)\n\u001B[0;32m    145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\timm\\models\\resnet.py:568\u001B[0m, in \u001B[0;36mResNet.forward_features\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    566\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer2(x)\n\u001B[0;32m    567\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer3(x)\n\u001B[1;32m--> 568\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer4\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    569\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 215\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\timm\\models\\resnet.py:227\u001B[0m, in \u001B[0;36mBottleneck.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    224\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact2(x)\n\u001B[0;32m    225\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maa(x)\n\u001B[1;32m--> 227\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv3\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    228\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn3(x)\n\u001B[0;32m    230\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mse \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    457\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import models\n",
    "import utils\n",
    "from datamodules import Task1Datamodule\n",
    "\n",
    "\n",
    "class ClassificationCallback(pl.Callback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        datamodule: Task1Datamodule,\n",
    "        num_epochs: int = 80,\n",
    "        lr: List[float] = None,\n",
    "        tclip: bool = True,\n",
    "        tclip_alpha: float = 10.0,\n",
    "        weight_decay: float = 1e-2,\n",
    "        early_stopping: int = 10,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if lr is None:\n",
    "            lr = [1e-3]\n",
    "\n",
    "        self.datamodule = datamodule\n",
    "        self.num_epochs = num_epochs\n",
    "        self.lr = lr\n",
    "        self.tclip = tclip\n",
    "        self.tclip_alpha = tclip_alpha\n",
    "        self.weight_decay = weight_decay\n",
    "        self.early_stopping = early_stopping\n",
    "\n",
    "    def eval_model(self, backbone: nn.Module, backbone_output_size: int):\n",
    "        acc = torchmetrics.Accuracy(\"multiclass\", num_classes=models.NUM_CLASSES)\n",
    "        ap = torchmetrics.AveragePrecision(\"multiclass\", num_classes=models.NUM_CLASSES)\n",
    "        best_loss = -1000000\n",
    "        best_lr = None\n",
    "        best_epoch = None\n",
    "        best_acc = None\n",
    "        best_ap = None\n",
    "        for lr in self.lr:\n",
    "            fc = nn.Linear(backbone_output_size, models.NUM_CLASSES)\n",
    "            opt = torch.optim.AdamW(\n",
    "                utils.add_weight_decay(fc, self.weight_decay), lr=lr\n",
    "            )\n",
    "            best_lr_loss = -1000000\n",
    "            best_lr_epoch = -1\n",
    "\n",
    "            train_dataloader = self.datamodule.train_dataloader()\n",
    "            val_dataloader = self.datamodule.val_dataloader()\n",
    "            if isinstance(val_dataloader, list):\n",
    "                assert len(val_dataloader) == 1\n",
    "                val_dataloader = val_dataloader[0]\n",
    "            tq = tqdm(range(self.num_epochs))\n",
    "            for epoch in tq:\n",
    "                num_batches = 0\n",
    "                for data, labels in train_dataloader:\n",
    "                    num_batches += 1\n",
    "                    opt.zero_grad()\n",
    "                    with torch.no_grad():\n",
    "                        features = backbone(data[\"image\"])\n",
    "                    logits = fc(features)\n",
    "                    if self.tclip:\n",
    "                        logits = self.tclip_alpha * torch.tanh(\n",
    "                            logits / self.tclip_alpha\n",
    "                        )\n",
    "                    loss = F.cross_entropy(logits, labels)\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "                    tq.set_description(\n",
    "                        f\"Train step {num_batches:04d}/{len(train_dataloader):04d} - loss {loss:.6f}\"\n",
    "                    )\n",
    "\n",
    "                loss = 0\n",
    "                num_batches = 0\n",
    "                for data, labels in val_dataloader:\n",
    "                    num_batches += 1\n",
    "                    with torch.no_grad():\n",
    "                        features = backbone(data[\"image\"])\n",
    "                        logits = fc(features)\n",
    "                        if self.tclip:\n",
    "                            logits = self.tclip_alpha * torch.tanh(\n",
    "                                logits / self.tclip_alpha\n",
    "                            )\n",
    "                        loss += F.cross_entropy(logits, labels)\n",
    "                        acc.update(logits, labels)\n",
    "                        ap.update(logits, labels)\n",
    "                    tq.set_description(\n",
    "                        f\"Eval step {num_batches:04d}/{len(val_dataloader):04d} - loss {loss:.6f}\"\n",
    "                    )\n",
    "                val_loss = loss / num_batches\n",
    "                val_acc = acc.compute()\n",
    "                val_ap = ap.compute()\n",
    "                acc.reset()\n",
    "                ap.reset()\n",
    "                if val_loss < best_loss:\n",
    "                    best_loss = val_loss\n",
    "                    best_lr = lr\n",
    "                    best_epoch = epoch\n",
    "                    best_acc = val_acc\n",
    "                    best_ap = val_ap\n",
    "                if val_loss < best_lr_loss:\n",
    "                    best_lr_loss = val_loss\n",
    "                    best_lr_epoch = epoch\n",
    "                elif epoch - best_lr_epoch > self.early_stopping:\n",
    "                    break\n",
    "        return {\n",
    "            \"loss\": best_loss,\n",
    "            \"lr\": best_lr,\n",
    "            \"epoch\": best_epoch,\n",
    "            \"acc\": best_acc,\n",
    "            \"ap\": best_ap,\n",
    "        }\n",
    "\n",
    "    def on_validation_epoch_end(\n",
    "        self, trainer: pl.Trainer, pl_module: pl.LightningModule\n",
    "    ):\n",
    "        backbone = nn.Sequential(pl_module.online_backbone, pl_module.global_pool)\n",
    "\n",
    "        logs = self.eval_model(backbone, pl_module.hparams.mlp_out_size)\n",
    "\n",
    "        pl_module.log_dict({f\"classification/{k}\": v for k, v in logs.items()})\n",
    "        print(f\"Classification {logs}\")\n",
    "\n",
    "import datamodules\n",
    "\n",
    "datamodule = datamodules.Task1Datamodule(\"C:/Data/AAIT/task1\", num_train_workers=0, num_val_workers=0, num_test_workers=0, batch_size=64, labeled=True, unlabeled=False, val_size=0.2, train_dataset_replicas=2)\n",
    "datamodule.setup(\"fit\")\n",
    "\n",
    "callback = ClassificationCallback(datamodule, num_epochs=10, lr=[0.001], tclip=True, tclip_alpha=10., weight_decay=1e-2, early_stopping=10)\n",
    "\n",
    "class _Backbone(nn.Module):\n",
    "    def __init__(self, model: nn.Module):\n",
    "        super().__init__()\n",
    "        self.backbone = model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.forward_features(x)\n",
    "        x = self.backbone.global_pool(x)\n",
    "        return x\n",
    "\n",
    "resnet50 = timm.create_model(\"resnet50\", pretrained=True)\n",
    "backbone = _Backbone(resnet50)\n",
    "\n",
    "callback.eval_model(backbone, 2048)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T20:07:48.573508100Z",
     "start_time": "2023-12-28T20:07:19.413410700Z"
    }
   },
   "id": "61652c228373ab5e"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x1000 and 2048x100)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 20\u001B[0m\n\u001B[0;32m     16\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[0;32m     18\u001B[0m backbone \u001B[38;5;241m=\u001B[39m _Backbone(resnet50)\n\u001B[1;32m---> 20\u001B[0m \u001B[43mcallback\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meval_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresnet50\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2048\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[24], line 67\u001B[0m, in \u001B[0;36mClassificationCallback.eval_model\u001B[1;34m(self, backbone, backbone_output_size)\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m     66\u001B[0m     features \u001B[38;5;241m=\u001B[39m backbone(data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m---> 67\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mfc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtclip:\n\u001B[0;32m     69\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtclip_alpha \u001B[38;5;241m*\u001B[39m torch\u001B[38;5;241m.\u001B[39mtanh(\n\u001B[0;32m     70\u001B[0m         features \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtclip_alpha\n\u001B[0;32m     71\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (16x1000 and 2048x100)"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-28T20:01:46.273059Z",
     "start_time": "2023-12-28T20:01:43.201449700Z"
    }
   },
   "id": "4ba638c352ebdf67"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n = 23555\n",
    "m = 2048\n",
    "X = np.random.randn(n, m) * 10 + np.random.randn(n, m) * 5 + 8\n",
    "y = np.random.randint(0, 100, (n,)).astype(int)\n",
    "# y_sampled = y\n",
    "# y_binarized = np.zeros((y.size, 100))\n",
    "# y_binarized[np.arange(y.size), y] = 1\n",
    "# y = y_binarized\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:37:20.354795400Z",
     "start_time": "2024-01-03T20:37:17.279227500Z"
    }
   },
   "id": "99ed0691fab4f91c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "labels = np.arange(100)\n",
    "def train_test(algo, pca_n_comp=2048, knn_n_neighbors=20):\n",
    "    global X_train, X_test, y_train, y_test, labels\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_transformed = scaler.fit_transform(X_train)\n",
    "    X_test_transformed = scaler.transform(X_test)\n",
    "    \n",
    "    if pca_n_comp != X_train.shape[1]:\n",
    "        pca = PCA(n_components=pca_n_comp)\n",
    "        X_train_transformed = pca.fit_transform(X_train_transformed)\n",
    "        X_test_transformed = pca.transform(X_test_transformed)\n",
    "    \n",
    "    if algo == \"knn\":\n",
    "        knn = KNeighborsClassifier(n_neighbors=knn_n_neighbors)\n",
    "        knn.fit(X_train_transformed, y_train)\n",
    "        y_proba = knn.predict_proba(X_test_transformed)\n",
    "    elif algo == \"randomforest\":\n",
    "        model = RandomForestClassifier(class_weight=\"balanced_subsample\")\n",
    "        model.fit(X_train_transformed, y_train)\n",
    "        y_proba = model.predict_proba(X_test_transformed)\n",
    "    elif algo == \"xgb\":\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(\"unknown algo\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T18:10:04.526256500Z",
     "start_time": "2024-01-03T18:10:04.523278200Z"
    }
   },
   "id": "558c25ea3947cb25"
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2 s ± 609 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit train_test(algo=\"knn\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:49:15.420583700Z",
     "start_time": "2024-01-03T17:48:42.059890600Z"
    }
   },
   "id": "a7e39bb57430e422"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%timeit train_test(algo=\"randomforest\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-03T17:49:55.511538400Z"
    }
   },
   "id": "3c5b0fd5692135c2"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(class_weight=\"balanced_subsample\", n_jobs=12)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T18:10:11.248599900Z",
     "start_time": "2024-01-03T18:10:11.231520800Z"
    }
   },
   "id": "7cc4dfa0b18e9bdb"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(class_weight='balanced_subsample', n_jobs=12)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_jobs=12)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced_subsample&#x27;, n_jobs=12)</pre></div></div></div></div></div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_transformed, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T18:13:27.909838700Z",
     "start_time": "2024-01-03T18:10:12.548518300Z"
    }
   },
   "id": "bf21f4a76010466b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "y_proba = model.predict_proba(X_test_transformed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T18:13:28.195837300Z",
     "start_time": "2024-01-03T18:13:27.913838100Z"
    }
   },
   "id": "f6c00d7d1d06d5e8"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=256)\n",
    "X_train_transformed = pca.fit_transform(X_train_transformed)\n",
    "X_test_transformed = pca.transform(X_test_transformed)\n",
    "\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "xgb = XGBClassifier(early_stopping_rounds=10, tree_method=\"hist\", max_depth=4, n_estimators=100, device=\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:37:37.301640900Z",
     "start_time": "2024-01-03T20:37:30.170418100Z"
    }
   },
   "id": "657de4bff7b623b3"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:4.61183\n",
      "[1]\tvalidation_0-mlogloss:4.61640\n",
      "[2]\tvalidation_0-mlogloss:4.62094\n",
      "[3]\tvalidation_0-mlogloss:4.62685\n",
      "[4]\tvalidation_0-mlogloss:4.63390\n",
      "[5]\tvalidation_0-mlogloss:4.63917\n",
      "[6]\tvalidation_0-mlogloss:4.64556\n",
      "[7]\tvalidation_0-mlogloss:4.65126\n",
      "[8]\tvalidation_0-mlogloss:4.65507\n",
      "[9]\tvalidation_0-mlogloss:4.66272\n"
     ]
    },
    {
     "data": {
      "text/plain": "XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device='cuda', early_stopping_rounds=10,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, objective='multi:softprob', ...)",
      "text/html": "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=10,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=&#x27;cuda&#x27;, early_stopping_rounds=10,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=4, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=100, n_jobs=None,\n              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div></div></div></div></div>"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train_transformed, y_train, eval_set=[(X_test_transformed, y_test)], verbose=True, sample_weight=sample_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:37:48.219437200Z",
     "start_time": "2024-01-03T20:37:37.304644400Z"
    }
   },
   "id": "24a50c88d1f55549"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "(4711, 100)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = xgb.predict_proba(X_test_transformed)\n",
    "y_proba.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:44:17.644611Z",
     "start_time": "2024-01-03T20:44:16.762541200Z"
    }
   },
   "id": "1c0d02caf4a7417e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from xgboost import DMatrix\n",
    "\n",
    "DMatrix()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48a3f4574bbefe42"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "['T_destination',\n '__annotations__',\n '__call__',\n '__class__',\n '__delattr__',\n '__dict__',\n '__dir__',\n '__doc__',\n '__eq__',\n '__format__',\n '__ge__',\n '__getattr__',\n '__getattribute__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__init__',\n '__init_subclass__',\n '__le__',\n '__lt__',\n '__module__',\n '__ne__',\n '__new__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__setattr__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__subclasshook__',\n '__weakref__',\n '_apply',\n '_backward_hooks',\n '_backward_pre_hooks',\n '_buffers',\n '_call_impl',\n '_compiled_call_impl',\n '_forward_hooks',\n '_forward_hooks_always_called',\n '_forward_hooks_with_kwargs',\n '_forward_pre_hooks',\n '_forward_pre_hooks_with_kwargs',\n '_get_backward_hooks',\n '_get_backward_pre_hooks',\n '_get_name',\n '_is_full_backward_hook',\n '_load_from_state_dict',\n '_load_state_dict_post_hooks',\n '_load_state_dict_pre_hooks',\n '_maybe_warn_non_full_backward_hook',\n '_modules',\n '_named_members',\n '_non_persistent_buffers_set',\n '_parameters',\n '_register_load_state_dict_pre_hook',\n '_register_state_dict_hook',\n '_replicate_for_data_parallel',\n '_save_to_state_dict',\n '_slow_forward',\n '_state_dict_hooks',\n '_state_dict_pre_hooks',\n '_version',\n '_wrapped_call_impl',\n 'act1',\n 'add_module',\n 'apply',\n 'bfloat16',\n 'bn1',\n 'buffers',\n 'call_super_init',\n 'children',\n 'compile',\n 'conv1',\n 'cpu',\n 'cuda',\n 'default_cfg',\n 'double',\n 'drop_rate',\n 'dump_patches',\n 'eval',\n 'extra_repr',\n 'fc',\n 'feature_info',\n 'float',\n 'forward',\n 'forward_features',\n 'forward_head',\n 'get_buffer',\n 'get_classifier',\n 'get_extra_state',\n 'get_parameter',\n 'get_submodule',\n 'global_pool',\n 'grad_checkpointing',\n 'group_matcher',\n 'half',\n 'init_weights',\n 'ipu',\n 'layer1',\n 'layer2',\n 'layer3',\n 'layer4',\n 'load_state_dict',\n 'maxpool',\n 'modules',\n 'named_buffers',\n 'named_children',\n 'named_modules',\n 'named_parameters',\n 'num_classes',\n 'num_features',\n 'parameters',\n 'pretrained_cfg',\n 'register_backward_hook',\n 'register_buffer',\n 'register_forward_hook',\n 'register_forward_pre_hook',\n 'register_full_backward_hook',\n 'register_full_backward_pre_hook',\n 'register_load_state_dict_post_hook',\n 'register_module',\n 'register_parameter',\n 'register_state_dict_pre_hook',\n 'requires_grad_',\n 'reset_classifier',\n 'set_extra_state',\n 'set_grad_checkpointing',\n 'share_memory',\n 'state_dict',\n 'to',\n 'to_empty',\n 'train',\n 'training',\n 'type',\n 'xpu',\n 'zero_grad']"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "m = timm.create_model(\"resnet34\", pretrained=False)\n",
    "dir(m)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:09:39.184103200Z",
     "start_time": "2024-01-03T20:09:37.840851400Z"
    }
   },
   "id": "3c323215df105d95"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet' object has no attribute 'device'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[70], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1694\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1695\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'ResNet' object has no attribute 'device'"
     ]
    }
   ],
   "source": [
    "m.device"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T20:09:47.493697Z",
     "start_time": "2024-01-03T20:09:46.350697200Z"
    }
   },
   "id": "6225b924eace6e9c"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.01011109, 0.00971837, 0.00985839, ..., 0.00944635, 0.01012211,\n        0.00957291],\n       [0.00997305, 0.00958568, 0.00972379, ..., 0.00931739, 0.00964165,\n        0.0103318 ],\n       [0.01025263, 0.0098544 , 0.00999638, ..., 0.00957858, 0.00991193,\n        0.00970691],\n       ...,\n       [0.01017627, 0.00978102, 0.00992194, ..., 0.00950725, 0.00903583,\n        0.00963462],\n       [0.01016838, 0.00977342, 0.00991424, ..., 0.00949987, 0.00983048,\n        0.00962714],\n       [0.01022303, 0.00982595, 0.00996752, ..., 0.01263243, 0.00988332,\n        0.00967888]], dtype=float32)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.predict_proba(X_test_transformed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T18:24:45.446062700Z",
     "start_time": "2024-01-03T18:24:44.654997Z"
    }
   },
   "id": "6ebee0aa37f62d76"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.],\n       [0., 0., 0., ..., 0., 0., 0.]])"
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_proba = knn.predict(X_test)\n",
    "y_proba"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:44:44.195782500Z",
     "start_time": "2024-01-03T17:44:40.631226300Z"
    }
   },
   "id": "1a617590c70fb537"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0., 1.])"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_proba)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:44:54.787316800Z",
     "start_time": "2024-01-03T17:44:54.280781600Z"
    }
   },
   "id": "5a89acb0f78d43bd"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "(4711, 199)"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate(y_proba, axis=1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:41:36.195819300Z",
     "start_time": "2024-01-03T17:41:36.140716800Z"
    }
   },
   "id": "9ccee69ff745720b"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "[(4711, 1),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2),\n (4711, 2)]"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[a.shape for a in y_proba]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:41:36.219745800Z",
     "start_time": "2024-01-03T17:41:36.153715700Z"
    }
   },
   "id": "9bed6461b363d42c"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.],\n       [1.],\n       [1.],\n       ...,\n       [1.],\n       [1.],\n       [1.]])"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:41:49.197773900Z",
     "start_time": "2024-01-03T17:41:48.244710200Z"
    }
   },
   "id": "34b441a0fcfc2674"
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1. , 0. ],\n       [0.8, 0.2],\n       [1. , 0. ],\n       ...,\n       [1. , 0. ],\n       [1. , 0. ],\n       [1. , 0. ]])"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba[16]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:42:36.318791Z",
     "start_time": "2024-01-03T17:42:35.765660800Z"
    }
   },
   "id": "46314b91cc007fae"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[113], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtimeit\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain_test(algo=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mknn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2417\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[1;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[0;32m   2415\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[0;32m   2416\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m-> 2417\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2419\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[0;32m   2420\u001B[0m \u001B[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001B[39;00m\n\u001B[0;32m   2421\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[0;32m   2422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1170\u001B[0m, in \u001B[0;36mExecutionMagics.timeit\u001B[1;34m(self, line, cell, local_ns)\u001B[0m\n\u001B[0;32m   1168\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m   1169\u001B[0m     number \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m index\n\u001B[1;32m-> 1170\u001B[0m     time_number \u001B[38;5;241m=\u001B[39m \u001B[43mtimer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1171\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m time_number \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m:\n\u001B[0;32m   1172\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\magics\\execution.py:158\u001B[0m, in \u001B[0;36mTimer.timeit\u001B[1;34m(self, number)\u001B[0m\n\u001B[0;32m    156\u001B[0m gc\u001B[38;5;241m.\u001B[39mdisable()\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 158\u001B[0m     timing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "File \u001B[1;32m<magic-timeit>:1\u001B[0m, in \u001B[0;36minner\u001B[1;34m(_it, _timer)\u001B[0m\n",
      "Cell \u001B[1;32mIn[112], line 35\u001B[0m, in \u001B[0;36mtrain_test\u001B[1;34m(algo, pca_n_comp, knn_n_neighbors)\u001B[0m\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munknown algo\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m# missing_labels = np.sort(np.array(list(set(range(100)).difference(set(np.unique(y_train))))))\u001B[39;00m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;66;03m# if len(missing_labels) > 0:\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m#     missing_labels = missing_labels - np.arange(len(missing_labels))\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m#     print(y_proba.shape)\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m#     y_proba = np.insert(y_proba, missing_labels, 0, axis=1)\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m#     print(y_proba.shape)\u001B[39;00m\n\u001B[1;32m---> 35\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43my_proba\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m)\n\u001B[0;32m     36\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(y_proba, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     37\u001B[0m \u001B[38;5;66;03m# print(y_hat.shape)\u001B[39;00m\n\u001B[0;32m     38\u001B[0m \u001B[38;5;66;03m# print(y_proba.shape)\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "%timeit train_test(algo=\"knn\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:38:32.094021500Z",
     "start_time": "2024-01-03T17:38:28.017232400Z"
    }
   },
   "id": "464056757809dac8"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:20:35.902801100Z",
     "start_time": "2024-01-03T17:20:35.456959400Z"
    }
   },
   "id": "33d47e6313a42e0f"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51,\n       52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68,\n       69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85,\n       86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:20:05.948611700Z",
     "start_time": "2024-01-03T17:20:05.485614100Z"
    }
   },
   "id": "c76d7bf87d20cb65"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "array({1, 2, 3}, dtype=object)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array({1, 2, 3})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:17:43.978246200Z",
     "start_time": "2024-01-03T17:17:43.678948400Z"
    }
   },
   "id": "a7c1501efdea2fa2"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n       68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n       85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:05:55.247974200Z",
     "start_time": "2024-01-03T17:05:55.201971400Z"
    }
   },
   "id": "8fddaf4756a457e5"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "2048"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:05:56.339010600Z",
     "start_time": "2024-01-03T17:05:56.319010900Z"
    }
   },
   "id": "b38db0e9551ea060"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1757: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of given labels, 100, not equal to the number of columns in 'y_score', 101",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[66], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mget_ipython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_line_magic\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtimeit\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtrain_test(algo=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mknn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m)\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2417\u001B[0m, in \u001B[0;36mInteractiveShell.run_line_magic\u001B[1;34m(self, magic_name, line, _stack_depth)\u001B[0m\n\u001B[0;32m   2415\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlocal_ns\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_local_scope(stack_depth)\n\u001B[0;32m   2416\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuiltin_trap:\n\u001B[1;32m-> 2417\u001B[0m     result \u001B[38;5;241m=\u001B[39m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   2419\u001B[0m \u001B[38;5;66;03m# The code below prevents the output from being displayed\u001B[39;00m\n\u001B[0;32m   2420\u001B[0m \u001B[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001B[39;00m\n\u001B[0;32m   2421\u001B[0m \u001B[38;5;66;03m# when the last Python token in the expression is a ';'.\u001B[39;00m\n\u001B[0;32m   2422\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(fn, magic\u001B[38;5;241m.\u001B[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001B[38;5;28;01mFalse\u001B[39;00m):\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\magics\\execution.py:1170\u001B[0m, in \u001B[0;36mExecutionMagics.timeit\u001B[1;34m(self, line, cell, local_ns)\u001B[0m\n\u001B[0;32m   1168\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m   1169\u001B[0m     number \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m index\n\u001B[1;32m-> 1170\u001B[0m     time_number \u001B[38;5;241m=\u001B[39m \u001B[43mtimer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimeit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1171\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m time_number \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.2\u001B[39m:\n\u001B[0;32m   1172\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\IPython\\core\\magics\\execution.py:158\u001B[0m, in \u001B[0;36mTimer.timeit\u001B[1;34m(self, number)\u001B[0m\n\u001B[0;32m    156\u001B[0m gc\u001B[38;5;241m.\u001B[39mdisable()\n\u001B[0;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 158\u001B[0m     timing \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minner\u001B[49m\u001B[43m(\u001B[49m\u001B[43mit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtimer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m gcold:\n",
      "File \u001B[1;32m<magic-timeit>:1\u001B[0m, in \u001B[0;36minner\u001B[1;34m(_it, _timer)\u001B[0m\n",
      "Cell \u001B[1;32mIn[65], line 38\u001B[0m, in \u001B[0;36mtrain_test\u001B[1;34m(algo, pca_n_comp, knn_n_neighbors)\u001B[0m\n\u001B[0;32m     32\u001B[0m     y_proba \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39minsert(y_proba, missing_labels, \u001B[38;5;241m0\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     33\u001B[0m y_hat \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(y_proba, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124macc\u001B[39m\u001B[38;5;124m\"\u001B[39m: accuracy_score(y_test, y_hat),\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m\"\u001B[39m: f1_score(y_test, y_hat, average\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmacro\u001B[39m\u001B[38;5;124m\"\u001B[39m, labels\u001B[38;5;241m=\u001B[39mlabels),\n\u001B[1;32m---> 38\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauc\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[43mroc_auc_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_proba\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43movr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m     39\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124map\u001B[39m\u001B[38;5;124m\"\u001B[39m: average_precision_score(y_test, y_proba, labels\u001B[38;5;241m=\u001B[39mlabels),\n\u001B[0;32m     40\u001B[0m }\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:620\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    618\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m multi_class \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    619\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulti_class must be in (\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movo\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124movr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 620\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_multiclass_roc_auc_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    621\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maverage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\n\u001B[0;32m    622\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    623\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    624\u001B[0m     labels \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y_true)\n",
      "File \u001B[1;32m~\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:728\u001B[0m, in \u001B[0;36m_multiclass_roc_auc_score\u001B[1;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001B[0m\n\u001B[0;32m    726\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mParameter \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m must be ordered\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    727\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(classes) \u001B[38;5;241m!=\u001B[39m y_score\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m--> 728\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    729\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of given labels, \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m, not equal to the number \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    730\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof columns in \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_score\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mlen\u001B[39m(classes), y_score\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m])\n\u001B[0;32m    731\u001B[0m     )\n\u001B[0;32m    732\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(np\u001B[38;5;241m.\u001B[39msetdiff1d(y_true, classes)):\n\u001B[0;32m    733\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m contains labels not in parameter \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Number of given labels, 100, not equal to the number of columns in 'y_score', 101"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:19:14.858474600Z",
     "start_time": "2024-01-03T17:19:11.282647800Z"
    }
   },
   "id": "7171d6adad6cbead"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "970091408e9e9275"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0,  0,  1,  2,  3,  0,  0,  4],\n       [ 5,  0,  6,  7,  8,  0,  0,  9],\n       [10,  0, 11, 12, 13,  0,  0, 14],\n       [15,  0, 16, 17, 18,  0,  0, 19],\n       [20,  0, 21, 22, 23,  0,  0, 24]])"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.insert(np.arange(25).reshape(5, 5), np.array([1, 4, 4]), 0, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:18:51.532769800Z",
     "start_time": "2024-01-03T17:18:51.057560600Z"
    }
   },
   "id": "2de84d93066ae42"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 2, 3])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T17:16:47.920496400Z",
     "start_time": "2024-01-03T17:16:47.460981600Z"
    }
   },
   "id": "cbe96b5df31c37e7"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.min()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:56:10.808615100Z",
     "start_time": "2024-01-03T16:56:10.183544700Z"
    }
   },
   "id": "15dcdf32fade08f4"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.min()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:56:16.323847500Z",
     "start_time": "2024-01-03T16:56:16.285668900Z"
    }
   },
   "id": "99d7e0effddd7ace"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(4711,)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:56:19.019295300Z",
     "start_time": "2024-01-03T16:56:18.978811600Z"
    }
   },
   "id": "e84cdbf534844736"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(4711,)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T16:56:27.082894900Z",
     "start_time": "2024-01-03T16:56:26.554536600Z"
    }
   },
   "id": "41f41e5ed46aae9e"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"C:/Data/AAIT/task1/train_data/annotations.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:49:37.339054300Z",
     "start_time": "2024-01-03T19:49:36.119313800Z"
    }
   },
   "id": "b28a790d830389a5"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "                                           sample  label\n0          task1/train_data/images/labeled/0.jpeg      0\n1          task1/train_data/images/labeled/1.jpeg      1\n2          task1/train_data/images/labeled/2.jpeg      2\n3          task1/train_data/images/labeled/3.jpeg      3\n4          task1/train_data/images/labeled/4.jpeg      4\n...                                           ...    ...\n23550  task1/train_data/images/labeled/23550.jpeg     97\n23551  task1/train_data/images/labeled/23551.jpeg     28\n23552  task1/train_data/images/labeled/23552.jpeg     53\n23553  task1/train_data/images/labeled/23553.jpeg      9\n23554  task1/train_data/images/labeled/23554.jpeg     90\n\n[23555 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>task1/train_data/images/labeled/0.jpeg</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>task1/train_data/images/labeled/1.jpeg</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>task1/train_data/images/labeled/2.jpeg</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>task1/train_data/images/labeled/3.jpeg</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>task1/train_data/images/labeled/4.jpeg</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>23550</th>\n      <td>task1/train_data/images/labeled/23550.jpeg</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>23551</th>\n      <td>task1/train_data/images/labeled/23551.jpeg</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>23552</th>\n      <td>task1/train_data/images/labeled/23552.jpeg</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>23553</th>\n      <td>task1/train_data/images/labeled/23553.jpeg</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>23554</th>\n      <td>task1/train_data/images/labeled/23554.jpeg</td>\n      <td>90</td>\n    </tr>\n  </tbody>\n</table>\n<p>23555 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:49:38.187524Z",
     "start_time": "2024-01-03T19:49:38.129490700Z"
    }
   },
   "id": "2b0f973c9c3b7402"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "       sample\nlabel        \n96         75\n89        149\n92        156\n75        167\n83        170\n...       ...\n82        280\n8         280\n3         286\n5         289\n52        289\n\n[100 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>96</th>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>156</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>286</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>289</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>289</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count().sort_values(\"sample\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:50:27.351143500Z",
     "start_time": "2024-01-03T19:50:26.101787300Z"
    }
   },
   "id": "8159e098eec5476d"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "       sample\nlabel        \n52        289\n5         289\n3         286\n8         280\n82        280\n...       ...\n83        170\n75        167\n92        156\n89        149\n96         75\n\n[100 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample</th>\n    </tr>\n    <tr>\n      <th>label</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>52</th>\n      <td>289</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>289</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>286</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>280</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>83</th>\n      <td>170</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>167</td>\n    </tr>\n    <tr>\n      <th>92</th>\n      <td>156</td>\n    </tr>\n    <tr>\n      <th>89</th>\n      <td>149</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>75</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count().sort_values(\"sample\", ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:50:41.145325100Z",
     "start_time": "2024-01-03T19:50:41.067230Z"
    }
   },
   "id": "ad55987ec36a428a"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1\n",
      "1/1\n",
      "2/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\.conda\\envs\\ml\\lib\\site-packages\\sklearn\\model_selection\\_split.py:725: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[67], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m train_zeros \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39msum(y[train_index] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_zeros\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtest_zeros\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m test_zeros \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m train_zeros \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "X = np.arange(400).reshape((80, 5))\n",
    "y = np.sqrt(np.random.randint(0, 16, size=(80,))).astype(int)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    test_zeros = np.sum(y[test_index] == 0)\n",
    "    train_zeros = np.sum(y[train_index] == 0)\n",
    "    print(f\"{train_zeros}/{test_zeros}\")\n",
    "    assert test_zeros > 0 and train_zeros > 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:58:59.294775Z",
     "start_time": "2024-01-03T19:58:58.787604300Z"
    }
   },
   "id": "a2288065cd958e89"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T19:58:17.085019600Z",
     "start_time": "2024-01-03T19:58:16.590833400Z"
    }
   },
   "id": "87c0738554e1a90e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "imagenet_classes = {\n",
    "0: \"tench, Tinca tinca\",\n",
    "1: \"goldfish, Carassius auratus\",\n",
    "2: \"great white shark, white shark, man-eater, man-eating shark, Carcharodon caharias',\",\n",
    "3: \"tiger shark, Galeocerdo cuvieri\",\n",
    "4: \"hammerhead, hammerhead shark\",\n",
    "5: \"electric ray, crampfish, numbfish, torpedo\",\n",
    "6: \"stingray\",\n",
    "7: \"cock\",\n",
    "8: \"hen\",\n",
    "9: \"ostrich, Struthio camelus\",\n",
    "10: \"brambling, Fringilla montifringilla\",\n",
    "11: \"goldfinch, Carduelis carduelis\",\n",
    "12: \"house finch, linnet, Carpodacus mexicanus\",\n",
    "13: \"junco, snowbird\",\n",
    "14: \"indigo bunting, indigo finch, indigo bird, Passerina cyanea\",\n",
    "15: \"robin, American robin, Turdus migratorius\",\n",
    "16: \"bulbul\",\n",
    "17: \"jay\",\n",
    "18: \"magpie\",\n",
    "19: \"chickadee\",\n",
    "20: \"water ouzel, dipper\",\n",
    "21: \"kite\",\n",
    "22: \"bald eagle, American eagle, Haliaeetus leucocephalus\",\n",
    "23: \"vulture\",\n",
    "24: \"great grey owl, great gray owl, Strix nebulosa\",\n",
    "25: \"European fire salamander, Salamandra salamandra\",\n",
    "26: \"common newt, Triturus vulgaris\",\n",
    "27: \"eft\",\n",
    "28: \"spotted salamander, Ambystoma maculatum\",\n",
    "29: \"axolotl, mud puppy, Ambystoma mexicanum\",\n",
    "30: \"bullfrog, Rana catesbeiana\",\n",
    "31: \"tree frog, tree-frog\",\n",
    "32: \"tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\",\n",
    "33: \"loggerhead, loggerhead turtle, Caretta caretta\",\n",
    "34: \"leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea\",\n",
    "35: \"mud turtle\",\n",
    "36: \"terrapin\",\n",
    "37: \"box turtle, box tortoise\",\n",
    "38: \"banded gecko\",\n",
    "39: \"common iguana, iguana, Iguana iguana\",\n",
    "40: \"American chameleon, anole, Anolis carolinensis\",\n",
    "41: \"whiptail, whiptail lizard\",\n",
    "42: \"agama\",\n",
    "43: \"frilled lizard, Chlamydosaurus kingi\",\n",
    "44: \"alligator lizard\",\n",
    "45: \"Gila monster, Heloderma suspectum\",\n",
    "46: \"green lizard, Lacerta viridis\",\n",
    "47: \"African chameleon, Chamaeleo chamaeleon\",\n",
    "48: \"Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoeis',\",\n",
    "49: \"African crocodile, Nile crocodile, Crocodylus niloticus\",\n",
    "50: \"American alligator, Alligator mississipiensis\",\n",
    "51: \"triceratops\",\n",
    "52: \"thunder snake, worm snake, Carphophis amoenus\",\n",
    "53: \"ringneck snake, ring-necked snake, ring snake\",\n",
    "54: \"hognose snake, puff adder, sand viper\",\n",
    "55: \"green snake, grass snake\",\n",
    "56: \"king snake, kingsnake\",\n",
    "57: \"garter snake, grass snake\",\n",
    "58: \"water snake\",\n",
    "59: \"vine snake\",\n",
    "60: \"night snake, Hypsiglena torquata\",\n",
    "61: \"boa constrictor, Constrictor constrictor\",\n",
    "62: \"rock python, rock snake, Python sebae\",\n",
    "63: \"Indian cobra, Naja naja\",\n",
    "64: \"green mamba\",\n",
    "65: \"sea snake\",\n",
    "66: \"horned viper, cerastes, sand viper, horned asp, Cerastes cornutus\",\n",
    "67: \"diamondback, diamondback rattlesnake, Crotalus adamanteus\",\n",
    "68: \"sidewinder, horned rattlesnake, Crotalus cerastes\",\n",
    "69: \"trilobite\",\n",
    "70: \"harvestman, daddy longlegs, Phalangium opilio\",\n",
    "71: \"scorpion\",\n",
    "72: \"black and gold garden spider, Argiope aurantia\",\n",
    "73: \"barn spider, Araneus cavaticus\",\n",
    "74: \"garden spider, Aranea diademata\",\n",
    "75: \"black widow, Latrodectus mactans\",\n",
    "76: \"tarantula\",\n",
    "77: \"wolf spider, hunting spider\",\n",
    "78: \"tick\",\n",
    "79: \"centipede\",\n",
    "80: \"black grouse\",\n",
    "81: \"ptarmigan\",\n",
    "82: \"ruffed grouse, partridge, Bonasa umbellus\",\n",
    "83: \"prairie chicken, prairie grouse, prairie fowl\",\n",
    "84: \"peacock\",\n",
    "85: \"quail\",\n",
    "86: \"partridge\",\n",
    "87: \"African grey, African gray, Psittacus erithacus\",\n",
    "88: \"macaw\",\n",
    "89: \"sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita\",\n",
    "90: \"lorikeet\",\n",
    "91: \"coucal\",\n",
    "92: \"bee eater\",\n",
    "93: \"hornbill\",\n",
    "94: \"hummingbird\",\n",
    "95: \"jacamar\",\n",
    "96: \"toucan\",\n",
    "97: \"drake\",\n",
    "98: \"red-breasted merganser, Mergus serrator\",\n",
    "99: \"goose\",\n",
    "100: \"black swan, Cygnus atratus\",\n",
    "101: \"tusker\",\n",
    "102: \"echidna, spiny anteater, anteater\",\n",
    "103: \"platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhyhus anatinus',\",\n",
    "104: \"wallaby, brush kangaroo\",\n",
    "105: \"koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\",\n",
    "106: \"wombat\",\n",
    "107: \"jellyfish\",\n",
    "108: \"sea anemone, anemone\",\n",
    "109: \"brain coral\",\n",
    "110: \"flatworm, platyhelminth\",\n",
    "111: \"nematode, nematode worm, roundworm\",\n",
    "112: \"conch\",\n",
    "113: \"snail\",\n",
    "114: \"slug\",\n",
    "115: \"sea slug, nudibranch\",\n",
    "116: \"chiton, coat-of-mail shell, sea cradle, polyplacophore\",\n",
    "117: \"chambered nautilus, pearly nautilus, nautilus\",\n",
    "118: \"Dungeness crab, Cancer magister\",\n",
    "119: \"rock crab, Cancer irroratus\",\n",
    "120: \"fiddler crab\",\n",
    "121: \"king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodesamtschatica',\",\n",
    "122: \"American lobster, Northern lobster, Maine lobster, Homarus americanus\",\n",
    "123: \"spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\",\n",
    "124: \"crayfish, crawfish, crawdad, crawdaddy\",\n",
    "125: \"hermit crab\",\n",
    "126: \"isopod\",\n",
    "127: \"white stork, Ciconia ciconia\",\n",
    "128: \"black stork, Ciconia nigra\",\n",
    "129: \"spoonbill\",\n",
    "130: \"flamingo\",\n",
    "131: \"little blue heron, Egretta caerulea\",\n",
    "132: \"American egret, great white heron, Egretta albus\",\n",
    "133: \"bittern\",\n",
    "134: \"crane, bird\",\n",
    "135: \"limpkin, Aramus pictus\",\n",
    "136: \"European gallinule, Porphyrio porphyrio\",\n",
    "137: \"American coot, marsh hen, mud hen, water hen, Fulica americana\",\n",
    "138: \"bustard\",\n",
    "139: \"ruddy turnstone, Arenaria interpres\",\n",
    "140: \"red-backed sandpiper, dunlin, Erolia alpina\",\n",
    "141: \"redshank, Tringa totanus\",\n",
    "142: \"dowitcher\",\n",
    "143: \"oystercatcher, oyster catcher\",\n",
    "144: \"pelican\",\n",
    "145: \"king penguin, Aptenodytes patagonica\",\n",
    "146: \"albatross, mollymawk\",\n",
    "147: \"grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius rostus',\",\n",
    "148: \"killer whale, killer, orca, grampus, sea wolf, Orcinus orca\",\n",
    "149: \"dugong, Dugong dugon\",\n",
    "150: \"sea lion\",\n",
    "151: \"Chihuahua\",\n",
    "152: \"Japanese spaniel\",\n",
    "153: \"Maltese dog, Maltese terrier, Maltese\",\n",
    "154: \"Pekinese, Pekingese, Peke\",\n",
    "155: \"Shih-Tzu\",\n",
    "156: \"Blenheim spaniel\",\n",
    "157: \"papillon\",\n",
    "158: \"toy terrier\",\n",
    "159: \"Rhodesian ridgeback\",\n",
    "160: \"Afghan hound, Afghan\",\n",
    "161: \"basset, basset hound\",\n",
    "162: \"beagle\",\n",
    "163: \"bloodhound, sleuthhound\",\n",
    "164: \"bluetick\",\n",
    "165: \"black-and-tan coonhound\",\n",
    "166: \"Walker hound, Walker foxhound\",\n",
    "167: \"English foxhound\",\n",
    "168: \"redbone\",\n",
    "169: \"borzoi, Russian wolfhound\",\n",
    "170: \"Irish wolfhound\",\n",
    "171: \"Italian greyhound\",\n",
    "172: \"whippet\",\n",
    "173: \"Ibizan hound, Ibizan Podenco\",\n",
    "174: \"Norwegian elkhound, elkhound\",\n",
    "175: \"otterhound, otter hound\",\n",
    "176: \"Saluki, gazelle hound\",\n",
    "177: \"Scottish deerhound, deerhound\",\n",
    "178: \"Weimaraner\",\n",
    "179: \"Staffordshire bullterrier, Staffordshire bull terrier\",\n",
    "180: \"American Staffordshire terrier, Staffordshire terrier, American pit bull rrier, pit bull terrier',\",\n",
    "181: \"Bedlington terrier\",\n",
    "182: \"Border terrier\",\n",
    "183: \"Kerry blue terrier\",\n",
    "184: \"Irish terrier\",\n",
    "185: \"Norfolk terrier\",\n",
    "186: \"Norwich terrier\",\n",
    "187: \"Yorkshire terrier\",\n",
    "188: \"wire-haired fox terrier\",\n",
    "189: \"Lakeland terrier\",\n",
    "190: \"Sealyham terrier, Sealyham\",\n",
    "191: \"Airedale, Airedale terrier\",\n",
    "192: \"cairn, cairn terrier\",\n",
    "193: \"Australian terrier\",\n",
    "194: \"Dandie Dinmont, Dandie Dinmont terrier\",\n",
    "195: \"Boston bull, Boston terrier\",\n",
    "196: \"miniature schnauzer\",\n",
    "197: \"giant schnauzer\",\n",
    "198: \"standard schnauzer\",\n",
    "199: \"Scotch terrier, Scottish terrier, Scottie\",\n",
    "200: \"Tibetan terrier, chrysanthemum dog\",\n",
    "201: \"silky terrier, Sydney silky\",\n",
    "202: \"soft-coated wheaten terrier\",\n",
    "203: \"West Highland white terrier\",\n",
    "204: \"Lhasa, Lhasa apso\",\n",
    "205: \"flat-coated retriever\",\n",
    "206: \"curly-coated retriever\",\n",
    "207: \"golden retriever\",\n",
    "208: \"Labrador retriever\",\n",
    "209: \"Chesapeake Bay retriever\",\n",
    "210: \"German short-haired pointer\",\n",
    "211: \"vizsla, Hungarian pointer\",\n",
    "212: \"English setter\",\n",
    "213: \"Irish setter, red setter\",\n",
    "214: \"Gordon setter\",\n",
    "215: \"Brittany spaniel\",\n",
    "216: \"clumber, clumber spaniel\",\n",
    "217: \"English springer, English springer spaniel\",\n",
    "218: \"Welsh springer spaniel\",\n",
    "219: \"cocker spaniel, English cocker spaniel, cocker\",\n",
    "220: \"Sussex spaniel\",\n",
    "221: \"Irish water spaniel\",\n",
    "222: \"kuvasz\",\n",
    "223: \"schipperke\",\n",
    "224: \"groenendael\",\n",
    "225: \"malinois\",\n",
    "226: \"briard\",\n",
    "227: \"kelpie\",\n",
    "228: \"komondor\",\n",
    "229: \"Old English sheepdog, bobtail\",\n",
    "230: \"Shetland sheepdog, Shetland sheep dog, Shetland\",\n",
    "231: \"collie\",\n",
    "232: \"Border collie\",\n",
    "233: \"Bouvier des Flandres, Bouviers des Flandres\",\n",
    "234: \"Rottweiler\",\n",
    "235: \"German shepherd, German shepherd dog, German police dog, alsatian\",\n",
    "236: \"Doberman, Doberman pinscher\",\n",
    "237: \"miniature pinscher\",\n",
    "238: \"Greater Swiss Mountain dog\",\n",
    "239: \"Bernese mountain dog\",\n",
    "240: \"Appenzeller\",\n",
    "241: \"EntleBucher\",\n",
    "242: \"boxer\",\n",
    "243: \"bull mastiff\",\n",
    "244: \"Tibetan mastiff\",\n",
    "245: \"French bulldog\",\n",
    "246: \"Great Dane\",\n",
    "247: \"Saint Bernard, St Bernard\",\n",
    "248: \"Eskimo dog, husky\",\n",
    "249: \"malamute, malemute, Alaskan malamute\",\n",
    "250: \"Siberian husky\",\n",
    "251: \"dalmatian, coach dog, carriage dog\",\n",
    "252: \"affenpinscher, monkey pinscher, monkey dog\",\n",
    "253: \"basenji\",\n",
    "254: \"pug, pug-dog\",\n",
    "255: \"Leonberg\",\n",
    "256: \"Newfoundland, Newfoundland dog\",\n",
    "257: \"Great Pyrenees\",\n",
    "258: \"Samoyed, Samoyede\",\n",
    "259: \"Pomeranian\",\n",
    "260: \"chow, chow chow\",\n",
    "261: \"keeshond\",\n",
    "262: \"Brabancon griffon\",\n",
    "263: \"Pembroke, Pembroke Welsh corgi\",\n",
    "264: \"Cardigan, Cardigan Welsh corgi\",\n",
    "265: \"toy poodle\",\n",
    "266: \"miniature poodle\",\n",
    "267: \"standard poodle\",\n",
    "268: \"Mexican hairless\",\n",
    "269: \"timber wolf, grey wolf, gray wolf, Canis lupus\",\n",
    "270: \"white wolf, Arctic wolf, Canis lupus tundrarum\",\n",
    "271: \"red wolf, maned wolf, Canis rufus, Canis niger\",\n",
    "272: \"coyote, prairie wolf, brush wolf, Canis latrans\",\n",
    "273: \"dingo, warrigal, warragal, Canis dingo\",\n",
    "274: \"dhole, Cuon alpinus\",\n",
    "275: \"African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus\",\n",
    "276: \"hyena, hyaena\",\n",
    "277: \"red fox, Vulpes vulpes\",\n",
    "278: \"kit fox, Vulpes macrotis\",\n",
    "279: \"Arctic fox, white fox, Alopex lagopus\",\n",
    "280: \"grey fox, gray fox, Urocyon cinereoargenteus\",\n",
    "281: \"tabby, tabby cat\",\n",
    "282: \"tiger cat\",\n",
    "283: \"Persian cat\",\n",
    "284: \"Siamese cat, Siamese\",\n",
    "285: \"Egyptian cat\",\n",
    "286: \"cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\",\n",
    "287: \"lynx, catamount\",\n",
    "288: \"leopard, Panthera pardus\",\n",
    "289: \"snow leopard, ounce, Panthera uncia\",\n",
    "290: \"jaguar, panther, Panthera onca, Felis onca\",\n",
    "291: \"lion, king of beasts, Panthera leo\",\n",
    "292: \"tiger, Panthera tigris\",\n",
    "293: \"cheetah, chetah, Acinonyx jubatus\",\n",
    "294: \"brown bear, bruin, Ursus arctos\",\n",
    "295: \"American black bear, black bear, Ursus americanus, Euarctos americanus\",\n",
    "296: \"ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus\",\n",
    "297: \"sloth bear, Melursus ursinus, Ursus ursinus\",\n",
    "298: \"mongoose\",\n",
    "299: \"meerkat, mierkat\",\n",
    "300: \"tiger beetle\",\n",
    "301: \"ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\",\n",
    "302: \"ground beetle, carabid beetle\",\n",
    "303: \"long-horned beetle, longicorn, longicorn beetle\",\n",
    "304: \"leaf beetle, chrysomelid\",\n",
    "305: \"dung beetle\",\n",
    "306: \"rhinoceros beetle\",\n",
    "307: \"weevil\",\n",
    "308: \"fly\",\n",
    "309: \"bee\",\n",
    "310: \"ant, emmet, pismire\",\n",
    "311: \"grasshopper, hopper\",\n",
    "312: \"cricket\",\n",
    "313: \"walking stick, walkingstick, stick insect\",\n",
    "314: \"cockroach, roach\",\n",
    "315: \"mantis, mantid\",\n",
    "316: \"cicada, cicala\",\n",
    "317: \"leafhopper\",\n",
    "318: \"lacewing, lacewing fly\",\n",
    "319: \"dragonfly, darning needle, devil's darning needle, sewing needle, snake fder, snake doctor, mosquito hawk, skeeter hawk\",\n",
    "320: \"damselfly\",\n",
    "321: \"admiral\",\n",
    "322: \"ringlet, ringlet butterfly\",\n",
    "323: \"monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\",\n",
    "324: \"cabbage butterfly\",\n",
    "325: \"sulphur butterfly, sulfur butterfly\",\n",
    "326: \"lycaenid, lycaenid butterfly\",\n",
    "327: \"starfish, sea star\",\n",
    "328: \"sea urchin\",\n",
    "329: \"sea cucumber, holothurian\",\n",
    "330: \"wood rabbit, cottontail, cottontail rabbit\",\n",
    "331: \"hare\",\n",
    "332: \"Angora, Angora rabbit\",\n",
    "333: \"hamster\",\n",
    "334: \"porcupine, hedgehog\",\n",
    "335: \"fox squirrel, eastern fox squirrel, Sciurus niger\",\n",
    "336: \"marmot\",\n",
    "337: \"beaver\",\n",
    "338: \"guinea pig, Cavia cobaya\",\n",
    "339: \"sorrel\",\n",
    "340: \"zebra\",\n",
    "341: \"hog, pig, grunter, squealer, Sus scrofa\",\n",
    "342: \"wild boar, boar, Sus scrofa\",\n",
    "343: \"warthog\",\n",
    "344: \"hippopotamus, hippo, river horse, Hippopotamus amphibius\",\n",
    "345: \"ox\",\n",
    "346: \"water buffalo, water ox, Asiatic buffalo, Bubalus bubalis\",\n",
    "347: \"bison\",\n",
    "348: \"ram, tup\",\n",
    "349: \"bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain eep, Ovis canadensis',\",\n",
    "350: \"ibex, Capra ibex\",\n",
    "351: \"hartebeest\",\n",
    "352: \"impala, Aepyceros melampus\",\n",
    "353: \"gazelle\",\n",
    "354: \"Arabian camel, dromedary, Camelus dromedarius\",\n",
    "355: \"llama\",\n",
    "356: \"weasel\",\n",
    "357: \"mink\",\n",
    "358: \"polecat, fitch, foulmart, foumart, Mustela putorius\",\n",
    "359: \"black-footed ferret, ferret, Mustela nigripes\",\n",
    "360: \"otter\",\n",
    "361: \"skunk, polecat, wood pussy\",\n",
    "362: \"badger\",\n",
    "363: \"armadillo\",\n",
    "364: \"three-toed sloth, ai, Bradypus tridactylus\",\n",
    "365: \"orangutan, orang, orangutang, Pongo pygmaeus\",\n",
    "366: \"gorilla, Gorilla gorilla\",\n",
    "367: \"chimpanzee, chimp, Pan troglodytes\",\n",
    "368: \"gibbon, Hylobates lar\",\n",
    "369: \"siamang, Hylobates syndactylus, Symphalangus syndactylus\",\n",
    "370: \"guenon, guenon monkey\",\n",
    "371: \"patas, hussar monkey, Erythrocebus patas\",\n",
    "372: \"baboon\",\n",
    "373: \"macaque\",\n",
    "374: \"langur\",\n",
    "375: \"colobus, colobus monkey\",\n",
    "376: \"proboscis monkey, Nasalis larvatus\",\n",
    "377: \"marmoset\",\n",
    "378: \"capuchin, ringtail, Cebus capucinus\",\n",
    "379: \"howler monkey, howler\",\n",
    "380: \"titi, titi monkey\",\n",
    "381: \"spider monkey, Ateles geoffroyi\",\n",
    "382: \"squirrel monkey, Saimiri sciureus\",\n",
    "383: \"Madagascar cat, ring-tailed lemur, Lemur catta\",\n",
    "384: \"indri, indris, Indri indri, Indri brevicaudatus\",\n",
    "385: \"Indian elephant, Elephas maximus\",\n",
    "386: \"African elephant, Loxodonta africana\",\n",
    "387: \"lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\",\n",
    "388: \"giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca\",\n",
    "389: \"barracouta, snoek\",\n",
    "390: \"eel\",\n",
    "391: \"coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch\",\n",
    "392: \"rock beauty, Holocanthus tricolor\",\n",
    "393: \"anemone fish\",\n",
    "394: \"sturgeon\",\n",
    "395: \"gar, garfish, garpike, billfish, Lepisosteus osseus\",\n",
    "396: \"lionfish\",\n",
    "397: \"puffer, pufferfish, blowfish, globefish\",\n",
    "398: \"abacus\",\n",
    "399: \"abaya\",\n",
    "400: \"academic gown, academic robe, judge's robe\",\n",
    "401: \"accordion, piano accordion, squeeze box\",\n",
    "402: \"acoustic guitar\",\n",
    "403: \"aircraft carrier, carrier, flattop, attack aircraft carrier\",\n",
    "404: \"airliner\",\n",
    "405: \"airship, dirigible\",\n",
    "406: \"altar\",\n",
    "407: \"ambulance\",\n",
    "408: \"amphibian, amphibious vehicle\",\n",
    "409: \"analog clock\",\n",
    "410: \"apiary, bee house\",\n",
    "411: \"apron\",\n",
    "412: \"ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustb, trash barrel, trash bin',\",\n",
    "413: \"assault rifle, assault gun\",\n",
    "414: \"backpack, back pack, knapsack, packsack, rucksack, haversack\",\n",
    "415: \"bakery, bakeshop, bakehouse\",\n",
    "416: \"balance beam, beam\",\n",
    "417: \"balloon\",\n",
    "418: \"ballpoint, ballpoint pen, ballpen, Biro\",\n",
    "419: \"Band Aid\",\n",
    "420: \"banjo\",\n",
    "421: \"bannister, banister, balustrade, balusters, handrail\",\n",
    "422: \"barbell\",\n",
    "423: \"barber chair\",\n",
    "424: \"barbershop\",\n",
    "425: \"barn\",\n",
    "426: \"barometer\",\n",
    "427: \"barrel, cask\",\n",
    "428: \"barrow, garden cart, lawn cart, wheelbarrow\",\n",
    "429: \"baseball\",\n",
    "430: \"basketball\",\n",
    "431: \"bassinet\",\n",
    "432: \"bassoon\",\n",
    "433: \"bathing cap, swimming cap\",\n",
    "434: \"bath towel\",\n",
    "435: \"bathtub, bathing tub, bath, tub\",\n",
    "436: \"beach wagon, station wagon, wagon, estate car, beach waggon, station wagg, waggon',\",\n",
    "437: \"beacon, lighthouse, beacon light, pharos\",\n",
    "438: \"beaker\",\n",
    "439: \"bearskin, busby, shako\",\n",
    "440: \"beer bottle\",\n",
    "441: \"beer glass\",\n",
    "442: \"bell cote, bell cot\",\n",
    "443: \"bib\",\n",
    "444: \"bicycle-built-for-two, tandem bicycle, tandem\",\n",
    "445: \"bikini, two-piece\",\n",
    "446: \"binder, ring-binder\",\n",
    "447: \"binoculars, field glasses, opera glasses\",\n",
    "448: \"birdhouse\",\n",
    "449: \"boathouse\",\n",
    "450: \"bobsled, bobsleigh, bob\",\n",
    "451: \"bolo tie, bolo, bola tie, bola\",\n",
    "452: \"bonnet, poke bonnet\",\n",
    "453: \"bookcase\",\n",
    "454: \"bookshop, bookstore, bookstall\",\n",
    "455: \"bottlecap\",\n",
    "456: \"bow\",\n",
    "457: \"bow tie, bow-tie, bowtie\",\n",
    "458: \"brass, memorial tablet, plaque\",\n",
    "459: \"brassiere, bra, bandeau\",\n",
    "460: \"breakwater, groin, groyne, mole, bulwark, seawall, jetty\",\n",
    "461: \"breastplate, aegis, egis\",\n",
    "462: \"broom\",\n",
    "463: \"bucket, pail\",\n",
    "464: \"buckle\",\n",
    "465: \"bulletproof vest\",\n",
    "466: \"bullet train, bullet\",\n",
    "467: \"butcher shop, meat market\",\n",
    "468: \"cab, hack, taxi, taxicab\",\n",
    "469: \"caldron, cauldron\",\n",
    "470: \"candle, taper, wax light\",\n",
    "471: \"cannon\",\n",
    "472: \"canoe\",\n",
    "473: \"can opener, tin opener\",\n",
    "474: \"cardigan\",\n",
    "475: \"car mirror\",\n",
    "476: \"carousel, carrousel, merry-go-round, roundabout, whirligig\",\n",
    "477: \"carpenter's kit, tool kit\",\n",
    "478: \"carton\",\n",
    "479: \"car wheel\",\n",
    "480: \"cash machine, cash dispenser, automated teller machine, automatic teller chine, automated teller, automatic teller, ATM',\",\n",
    "481: \"cassette\",\n",
    "482: \"cassette player\",\n",
    "483: \"castle\",\n",
    "484: \"catamaran\",\n",
    "485: \"CD player\",\n",
    "486: \"cello, violoncello\",\n",
    "487: \"cellular telephone, cellular phone, cellphone, cell, mobile phone\",\n",
    "488: \"chain\",\n",
    "489: \"chainlink fence\",\n",
    "490: \"chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring mour',\",\n",
    "491: \"chain saw, chainsaw\",\n",
    "492: \"chest\",\n",
    "493: \"chiffonier, commode\",\n",
    "494: \"chime, bell, gong\",\n",
    "495: \"china cabinet, china closet\",\n",
    "496: \"Christmas stocking\",\n",
    "497: \"church, church building\",\n",
    "498: \"cinema, movie theater, movie theatre, movie house, picture palace\",\n",
    "499: \"cleaver, meat cleaver, chopper\",\n",
    "500: \"cliff dwelling\",\n",
    "501: \"cloak\",\n",
    "502: \"clog, geta, patten, sabot\",\n",
    "503: \"cocktail shaker\",\n",
    "504: \"coffee mug\",\n",
    "505: \"coffeepot\",\n",
    "506: \"coil, spiral, volute, whorl, helix\",\n",
    "507: \"combination lock\",\n",
    "508: \"computer keyboard, keypad\",\n",
    "509: \"confectionery, confectionary, candy store\",\n",
    "510: \"container ship, containership, container vessel\",\n",
    "511: \"convertible\",\n",
    "512: \"corkscrew, bottle screw\",\n",
    "513: \"cornet, horn, trumpet, trump\",\n",
    "514: \"cowboy boot\",\n",
    "515: \"cowboy hat, ten-gallon hat\",\n",
    "516: \"cradle\",\n",
    "517: \"crane\",\n",
    "518: \"crash helmet\",\n",
    "519: \"crate\",\n",
    "520: \"crib, cot\",\n",
    "521: \"Crock Pot\",\n",
    "522: \"croquet ball\",\n",
    "523: \"crutch\",\n",
    "524: \"cuirass\",\n",
    "525: \"dam, dike, dyke\",\n",
    "526: \"desk\",\n",
    "527: \"desktop computer\",\n",
    "528: \"dial telephone, dial phone\",\n",
    "529: \"diaper, nappy, napkin\",\n",
    "530: \"digital clock\",\n",
    "531: \"digital watch\",\n",
    "532: \"dining table, board\",\n",
    "533: \"dishrag, dishcloth\",\n",
    "534: \"dishwasher, dish washer, dishwashing machine\",\n",
    "535: \"disk brake, disc brake\",\n",
    "536: \"dock, dockage, docking facility\",\n",
    "537: \"dogsled, dog sled, dog sleigh\",\n",
    "538: \"dome\",\n",
    "539: \"doormat, welcome mat\",\n",
    "540: \"drilling platform, offshore rig\",\n",
    "541: \"drum, membranophone, tympan\",\n",
    "542: \"drumstick\",\n",
    "543: \"dumbbell\",\n",
    "544: \"Dutch oven\",\n",
    "545: \"electric fan, blower\",\n",
    "546: \"electric guitar\",\n",
    "547: \"electric locomotive\",\n",
    "548: \"entertainment center\",\n",
    "549: \"envelope\",\n",
    "550: \"espresso maker\",\n",
    "551: \"face powder\",\n",
    "552: \"feather boa, boa\",\n",
    "553: \"file, file cabinet, filing cabinet\",\n",
    "554: \"fireboat\",\n",
    "555: \"fire engine, fire truck\",\n",
    "556: \"fire screen, fireguard\",\n",
    "557: \"flagpole, flagstaff\",\n",
    "558: \"flute, transverse flute\",\n",
    "559: \"folding chair\",\n",
    "560: \"football helmet\",\n",
    "561: \"forklift\",\n",
    "562: \"fountain\",\n",
    "563: \"fountain pen\",\n",
    "564: \"four-poster\",\n",
    "565: \"freight car\",\n",
    "566: \"French horn, horn\",\n",
    "567: \"frying pan, frypan, skillet\",\n",
    "568: \"fur coat\",\n",
    "569: \"garbage truck, dustcart\",\n",
    "570: \"gasmask, respirator, gas helmet\",\n",
    "571: \"gas pump, gasoline pump, petrol pump, island dispenser\",\n",
    "572: \"goblet\",\n",
    "573: \"go-kart\",\n",
    "574: \"golf ball\",\n",
    "575: \"golfcart, golf cart\",\n",
    "576: \"gondola\",\n",
    "577: \"gong, tam-tam\",\n",
    "578: \"gown\",\n",
    "579: \"grand piano, grand\",\n",
    "580: \"greenhouse, nursery, glasshouse\",\n",
    "581: \"grille, radiator grille\",\n",
    "582: \"grocery store, grocery, food market, market\",\n",
    "583: \"guillotine\",\n",
    "584: \"hair slide\",\n",
    "585: \"hair spray\",\n",
    "586: \"half track\",\n",
    "587: \"hammer\",\n",
    "588: \"hamper\",\n",
    "589: \"hand blower, blow dryer, blow drier, hair dryer, hair drier\",\n",
    "590: \"hand-held computer, hand-held microcomputer\",\n",
    "591: \"handkerchief, hankie, hanky, hankey\",\n",
    "592: \"hard disc, hard disk, fixed disk\",\n",
    "593: \"harmonica, mouth organ, harp, mouth harp\",\n",
    "594: \"harp\",\n",
    "595: \"harvester, reaper\",\n",
    "596: \"hatchet\",\n",
    "597: \"holster\",\n",
    "598: \"home theater, home theatre\",\n",
    "599: \"honeycomb\",\n",
    "600: \"hook, claw\",\n",
    "601: \"hoopskirt, crinoline\",\n",
    "602: \"horizontal bar, high bar\",\n",
    "603: \"horse cart, horse-cart\",\n",
    "604: \"hourglass\",\n",
    "605: \"iPod\",\n",
    "606: \"iron, smoothing iron\",\n",
    "607: \"jack-o'-lantern\",\n",
    "608: \"jean, blue jean, denim\",\n",
    "609: \"jeep, landrover\",\n",
    "610: \"jersey, T-shirt, tee shirt\",\n",
    "611: \"jigsaw puzzle\",\n",
    "612: \"jinrikisha, ricksha, rickshaw\",\n",
    "613: \"joystick\",\n",
    "614: \"kimono\",\n",
    "615: \"knee pad\",\n",
    "616: \"knot\",\n",
    "617: \"lab coat, laboratory coat\",\n",
    "618: \"ladle\",\n",
    "619: \"lampshade, lamp shade\",\n",
    "620: \"laptop, laptop computer\",\n",
    "621: \"lawn mower, mower\",\n",
    "622: \"lens cap, lens cover\",\n",
    "623: \"letter opener, paper knife, paperknife\",\n",
    "624: \"library\",\n",
    "625: \"lifeboat\",\n",
    "626: \"lighter, light, igniter, ignitor\",\n",
    "627: \"limousine, limo\",\n",
    "628: \"liner, ocean liner\",\n",
    "629: \"lipstick, lip rouge\",\n",
    "630: \"Loafer\",\n",
    "631: \"lotion\",\n",
    "632: \"loudspeaker, speaker, speaker unit, loudspeaker system, speaker system\",\n",
    "633: \"loupe, jeweler's loupe\",\n",
    "634: \"lumbermill, sawmill\",\n",
    "635: \"magnetic compass\",\n",
    "636: \"mailbag, postbag\",\n",
    "637: \"mailbox, letter box\",\n",
    "638: \"maillot\",\n",
    "639: \"maillot, tank suit\",\n",
    "640: \"manhole cover\",\n",
    "641: \"maraca\",\n",
    "642: \"marimba, xylophone\",\n",
    "643: \"mask\",\n",
    "644: \"matchstick\",\n",
    "645: \"maypole\",\n",
    "646: \"maze, labyrinth\",\n",
    "647: \"measuring cup\",\n",
    "648: \"medicine chest, medicine cabinet\",\n",
    "649: \"megalith, megalithic structure\",\n",
    "650: \"microphone, mike\",\n",
    "651: \"microwave, microwave oven\",\n",
    "652: \"military uniform\",\n",
    "653: \"milk can\",\n",
    "654: \"minibus\",\n",
    "655: \"miniskirt, mini\",\n",
    "656: \"minivan\",\n",
    "657: \"missile\",\n",
    "658: \"mitten\",\n",
    "659: \"mixing bowl\",\n",
    "660: \"mobile home, manufactured home\",\n",
    "661: \"Model T\",\n",
    "662: \"modem\",\n",
    "663: \"monastery\",\n",
    "664: \"monitor\",\n",
    "665: \"moped\",\n",
    "666: \"mortar\",\n",
    "667: \"mortarboard\",\n",
    "668: \"mosque\",\n",
    "669: \"mosquito net\",\n",
    "670: \"motor scooter, scooter\",\n",
    "671: \"mountain bike, all-terrain bike, off-roader\",\n",
    "672: \"mountain tent\",\n",
    "673: \"mouse, computer mouse\",\n",
    "674: \"mousetrap\",\n",
    "675: \"moving van\",\n",
    "676: \"muzzle\",\n",
    "677: \"nail\",\n",
    "678: \"neck brace\",\n",
    "679: \"necklace\",\n",
    "680: \"nipple\",\n",
    "681: \"notebook, notebook computer\",\n",
    "682: \"obelisk\",\n",
    "683: \"oboe, hautboy, hautbois\",\n",
    "684: \"ocarina, sweet potato\",\n",
    "685: \"odometer, hodometer, mileometer, milometer\",\n",
    "686: \"oil filter\",\n",
    "687: \"organ, pipe organ\",\n",
    "688: \"oscilloscope, scope, cathode-ray oscilloscope, CRO\",\n",
    "689: \"overskirt\",\n",
    "690: \"oxcart\",\n",
    "691: \"oxygen mask\",\n",
    "692: \"packet\",\n",
    "693: \"paddle, boat paddle\",\n",
    "694: \"paddlewheel, paddle wheel\",\n",
    "695: \"padlock\",\n",
    "696: \"paintbrush\",\n",
    "697: \"pajama, pyjama, pj's, jammies\",\n",
    "698: \"palace\",\n",
    "699: \"panpipe, pandean pipe, syrinx\",\n",
    "700: \"paper towel\",\n",
    "701: \"parachute, chute\",\n",
    "702: \"parallel bars, bars\",\n",
    "703: \"park bench\",\n",
    "704: \"parking meter\",\n",
    "705: \"passenger car, coach, carriage\",\n",
    "706: \"patio, terrace\",\n",
    "707: \"pay-phone, pay-station\",\n",
    "708: \"pedestal, plinth, footstall\",\n",
    "709: \"pencil box, pencil case\",\n",
    "710: \"pencil sharpener\",\n",
    "711: \"perfume, essence\",\n",
    "712: \"Petri dish\",\n",
    "713: \"photocopier\",\n",
    "714: \"pick, plectrum, plectron\",\n",
    "715: \"pickelhaube\",\n",
    "716: \"picket fence, paling\",\n",
    "717: \"pickup, pickup truck\",\n",
    "718: \"pier\",\n",
    "719: \"piggy bank, penny bank\",\n",
    "720: \"pill bottle\",\n",
    "721: \"pillow\",\n",
    "722: \"ping-pong ball\",\n",
    "723: \"pinwheel\",\n",
    "724: \"pirate, pirate ship\",\n",
    "725: \"pitcher, ewer\",\n",
    "726: \"plane, carpenter's plane, woodworking plane\",\n",
    "727: \"planetarium\",\n",
    "728: \"plastic bag\",\n",
    "729: \"plate rack\",\n",
    "730: \"plow, plough\",\n",
    "731: \"plunger, plumber's helper\",\n",
    "732: \"Polaroid camera, Polaroid Land camera\",\n",
    "733: \"pole\",\n",
    "734: \"police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\",\n",
    "735: \"poncho\",\n",
    "736: \"pool table, billiard table, snooker table\",\n",
    "737: \"pop bottle, soda bottle\",\n",
    "738: \"pot, flowerpot\",\n",
    "739: \"potter's wheel\",\n",
    "740: \"power drill\",\n",
    "741: \"prayer rug, prayer mat\",\n",
    "742: \"printer\",\n",
    "743: \"prison, prison house\",\n",
    "744: \"projectile, missile\",\n",
    "745: \"projector\",\n",
    "746: \"puck, hockey puck\",\n",
    "747: \"punching bag, punch bag, punching ball, punchball\",\n",
    "748: \"purse\",\n",
    "749: \"quill, quill pen\",\n",
    "750: \"quilt, comforter, comfort, puff\",\n",
    "751: \"racer, race car, racing car\",\n",
    "752: \"racket, racquet\",\n",
    "753: \"radiator\",\n",
    "754: \"radio, wireless\",\n",
    "755: \"radio telescope, radio reflector\",\n",
    "756: \"rain barrel\",\n",
    "757: \"recreational vehicle, RV, R.V.\",\n",
    "758: \"reel\",\n",
    "759: \"reflex camera\",\n",
    "760: \"refrigerator, icebox\",\n",
    "761: \"remote control, remote\",\n",
    "762: \"restaurant, eating house, eating place, eatery\",\n",
    "763: \"revolver, six-gun, six-shooter\",\n",
    "764: \"rifle\",\n",
    "765: \"rocking chair, rocker\",\n",
    "766: \"rotisserie\",\n",
    "767: \"rubber eraser, rubber, pencil eraser\",\n",
    "768: \"rugby ball\",\n",
    "769: \"rule, ruler\",\n",
    "770: \"running shoe\",\n",
    "771: \"safe\",\n",
    "772: \"safety pin\",\n",
    "773: \"saltshaker, salt shaker\",\n",
    "774: \"sandal\",\n",
    "775: \"sarong\",\n",
    "776: \"sax, saxophone\",\n",
    "777: \"scabbard\",\n",
    "778: \"scale, weighing machine\",\n",
    "779: \"school bus\",\n",
    "780: \"schooner\",\n",
    "781: \"scoreboard\",\n",
    "782: \"screen, CRT screen\",\n",
    "783: \"screw\",\n",
    "784: \"screwdriver\",\n",
    "785: \"seat belt, seatbelt\",\n",
    "786: \"sewing machine\",\n",
    "787: \"shield, buckler\",\n",
    "788: \"shoe shop, shoe-shop, shoe store\",\n",
    "789: \"shoji\",\n",
    "790: \"shopping basket\",\n",
    "791: \"shopping cart\",\n",
    "792: \"shovel\",\n",
    "793: \"shower cap\",\n",
    "794: \"shower curtain\",\n",
    "795: \"ski\",\n",
    "796: \"ski mask\",\n",
    "797: \"sleeping bag\",\n",
    "798: \"slide rule, slipstick\",\n",
    "799: \"sliding door\",\n",
    "800: \"slot, one-armed bandit\",\n",
    "801: \"snorkel\",\n",
    "802: \"snowmobile\",\n",
    "803: \"snowplow, snowplough\",\n",
    "804: \"soap dispenser\",\n",
    "805: \"soccer ball\",\n",
    "806: \"sock\",\n",
    "807: \"solar dish, solar collector, solar furnace\",\n",
    "808: \"sombrero\",\n",
    "809: \"soup bowl\",\n",
    "810: \"space bar\",\n",
    "811: \"space heater\",\n",
    "812: \"space shuttle\",\n",
    "813: \"spatula\",\n",
    "814: \"speedboat\",\n",
    "815: \"spider web, spider's web\",\n",
    "816: \"spindle\",\n",
    "817: \"sports car, sport car\",\n",
    "818: \"spotlight, spot\",\n",
    "819: \"stage\",\n",
    "820: \"steam locomotive\",\n",
    "821: \"steel arch bridge\",\n",
    "822: \"steel drum\",\n",
    "823: \"stethoscope\",\n",
    "824: \"stole\",\n",
    "825: \"stone wall\",\n",
    "826: \"stopwatch, stop watch\",\n",
    "827: \"stove\",\n",
    "828: \"strainer\",\n",
    "829: \"streetcar, tram, tramcar, trolley, trolley car\",\n",
    "830: \"stretcher\",\n",
    "831: \"studio couch, day bed\",\n",
    "832: \"stupa, tope\",\n",
    "833: \"submarine, pigboat, sub, U-boat\",\n",
    "834: \"suit, suit of clothes\",\n",
    "835: \"sundial\",\n",
    "836: \"sunglass\",\n",
    "837: \"sunglasses, dark glasses, shades\",\n",
    "838: \"sunscreen, sunblock, sun blocker\",\n",
    "839: \"suspension bridge\",\n",
    "840: \"swab, swob, mop\",\n",
    "841: \"sweatshirt\",\n",
    "842: \"swimming trunks, bathing trunks\",\n",
    "843: \"swing\",\n",
    "844: \"switch, electric switch, electrical switch\",\n",
    "845: \"syringe\",\n",
    "846: \"table lamp\",\n",
    "847: \"tank, army tank, armored combat vehicle, armoured combat vehicle\",\n",
    "848: \"tape player\",\n",
    "849: \"teapot\",\n",
    "850: \"teddy, teddy bear\",\n",
    "851: \"television, television system\",\n",
    "852: \"tennis ball\",\n",
    "853: \"thatch, thatched roof\",\n",
    "854: \"theater curtain, theatre curtain\",\n",
    "855: \"thimble\",\n",
    "856: \"thresher, thrasher, threshing machine\",\n",
    "857: \"throne\",\n",
    "858: \"tile roof\",\n",
    "859: \"toaster\",\n",
    "860: \"tobacco shop, tobacconist shop, tobacconist\",\n",
    "861: \"toilet seat\",\n",
    "862: \"torch\",\n",
    "863: \"totem pole\",\n",
    "864: \"tow truck, tow car, wrecker\",\n",
    "865: \"toyshop\",\n",
    "866: \"tractor\",\n",
    "867: \"trailer truck, tractor trailer, trucking rig, rig, articulated lorry, sem,\",\n",
    "868: \"tray\",\n",
    "869: \"trench coat\",\n",
    "870: \"tricycle, trike, velocipede\",\n",
    "871: \"trimaran\",\n",
    "872: \"tripod\",\n",
    "873: \"triumphal arch\",\n",
    "874: \"trolleybus, trolley coach, trackless trolley\",\n",
    "875: \"trombone\",\n",
    "876: \"tub, vat\",\n",
    "877: \"turnstile\",\n",
    "878: \"typewriter keyboard\",\n",
    "879: \"umbrella\",\n",
    "880: \"unicycle, monocycle\",\n",
    "881: \"upright, upright piano\",\n",
    "882: \"vacuum, vacuum cleaner\",\n",
    "883: \"vase\",\n",
    "884: \"vault\",\n",
    "885: \"velvet\",\n",
    "886: \"vending machine\",\n",
    "887: \"vestment\",\n",
    "888: \"viaduct\",\n",
    "889: \"violin, fiddle\",\n",
    "890: \"volleyball\",\n",
    "891: \"waffle iron\",\n",
    "892: \"wall clock\",\n",
    "893: \"wallet, billfold, notecase, pocketbook\",\n",
    "894: \"wardrobe, closet, press\",\n",
    "895: \"warplane, military plane\",\n",
    "896: \"washbasin, handbasin, washbowl, lavabo, wash-hand basin\",\n",
    "897: \"washer, automatic washer, washing machine\",\n",
    "898: \"water bottle\",\n",
    "899: \"water jug\",\n",
    "900: \"water tower\",\n",
    "901: \"whiskey jug\",\n",
    "902: \"whistle\",\n",
    "903: \"wig\",\n",
    "904: \"window screen\",\n",
    "905: \"window shade\",\n",
    "906: \"Windsor tie\",\n",
    "907: \"wine bottle\",\n",
    "908: \"wing\",\n",
    "909: \"wok\",\n",
    "910: \"wooden spoon\",\n",
    "911: \"wool, woolen, woollen\",\n",
    "912: \"worm fence, snake fence, snake-rail fence, Virginia fence\",\n",
    "913: \"wreck\",\n",
    "914: \"yawl\",\n",
    "915: \"yurt\",\n",
    "916: \"web site, website, internet site, site\",\n",
    "917: \"comic book\",\n",
    "918: \"crossword puzzle, crossword\",\n",
    "919: \"street sign\",\n",
    "920: \"traffic light, traffic signal, stoplight\",\n",
    "921: \"book jacket, dust cover, dust jacket, dust wrapper\",\n",
    "922: \"menu\",\n",
    "923: \"plate\",\n",
    "924: \"guacamole\",\n",
    "925: \"consomme\",\n",
    "926: \"hot pot, hotpot\",\n",
    "927: \"trifle\",\n",
    "928: \"ice cream, icecream\",\n",
    "929: \"ice lolly, lolly, lollipop, popsicle\",\n",
    "930: \"French loaf\",\n",
    "931: \"bagel, beigel\",\n",
    "932: \"pretzel\",\n",
    "933: \"cheeseburger\",\n",
    "934: \"hotdog, hot dog, red hot\",\n",
    "935: \"mashed potato\",\n",
    "936: \"head cabbage\",\n",
    "937: \"broccoli\",\n",
    "938: \"cauliflower\",\n",
    "939: \"zucchini, courgette\",\n",
    "940: \"spaghetti squash\",\n",
    "941: \"acorn squash\",\n",
    "942: \"butternut squash\",\n",
    "943: \"cucumber, cuke\",\n",
    "944: \"artichoke, globe artichoke\",\n",
    "945: \"bell pepper\",\n",
    "946: \"cardoon\",\n",
    "947: \"mushroom\",\n",
    "948: \"Granny Smith\",\n",
    "949: \"strawberry\",\n",
    "950: \"orange\",\n",
    "951: \"lemon\",\n",
    "952: \"fig\",\n",
    "953: \"pineapple, ananas\",\n",
    "954: \"banana\",\n",
    "955: \"jackfruit, jak, jack\",\n",
    "956: \"custard apple\",\n",
    "957: \"pomegranate\",\n",
    "958: \"hay\",\n",
    "959: \"carbonara\",\n",
    "960: \"chocolate sauce, chocolate syrup\",\n",
    "961: \"dough\",\n",
    "962: \"meat loaf, meatloaf\",\n",
    "963: \"pizza, pizza pie\",\n",
    "964: \"potpie\",\n",
    "965: \"burrito\",\n",
    "966: \"red wine\",\n",
    "967: \"espresso\",\n",
    "968: \"cup\",\n",
    "969: \"eggnog\",\n",
    "970: \"alp\",\n",
    "971: \"bubble\",\n",
    "972: \"cliff, drop, drop-off\",\n",
    "973: \"coral reef\",\n",
    "974: \"geyser\",\n",
    "975: \"lakeside, lakeshore\",\n",
    "976: \"promontory, headland, head, foreland\",\n",
    "977: \"sandbar, sand bar\",\n",
    "978: \"seashore, coast, seacoast, sea-coast\",\n",
    "979: \"valley, vale\",\n",
    "980: \"volcano\",\n",
    "981: \"ballplayer, baseball player\",\n",
    "982: \"groom, bridegroom\",\n",
    "983: \"scuba diver\",\n",
    "984: \"rapeseed\",\n",
    "985: \"daisy\",\n",
    "986: \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripium parviflorum\",\n",
    "987: \"corn\",\n",
    "988: \"acorn\",\n",
    "989: \"hip, rose hip, rosehip\",\n",
    "990: \"buckeye, horse chestnut, conker\",\n",
    "991: \"coral fungus\",\n",
    "992: \"agaric\",\n",
    "993: \"gyromitra\",\n",
    "994: \"stinkhorn, carrion fungus\",\n",
    "995: \"earthstar\",\n",
    "996: \"hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa\",\n",
    "997: \"bolete\",\n",
    "998: \"ear, spike, capitulum\",\n",
    "999: \"toilet tissue, toilet paper, bathroom tissue\",\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:07:14.694037466Z",
     "start_time": "2024-01-07T19:07:14.515520746Z"
    }
   },
   "id": "2cfe9bebbd6e55bd",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "imagenet64_classes = {\n",
    "1: \"kit_fox\",\n",
    "2: \"English_setter\",\n",
    "3: \"Siberian_husky\",\n",
    "4: \"Australian_terrier\",\n",
    "5: \"English_springer\",\n",
    "6: \"grey_whale\",\n",
    "7: \"lesser_panda\",\n",
    "8: \"Egyptian_cat\",\n",
    "9: \"ibex\",\n",
    "10: \"Persian_cat\",\n",
    "11: \"cougar\",\n",
    "12: \"gazelle\",\n",
    "13: \"porcupine\",\n",
    "14: \"sea_lion\",\n",
    "15: \"malamute\",\n",
    "16: \"badger\",\n",
    "17: \"Great_Dane\",\n",
    "18: \"Walker_hound\",\n",
    "19: \"Welsh_springer_spaniel\",\n",
    "20: \"whippet\",\n",
    "21: \"Scottish_deerhound\",\n",
    "22: \"killer_whale\",\n",
    "23: \"mink\",\n",
    "24: \"African_elephant\",\n",
    "25: \"Weimaraner\",\n",
    "26: \"soft-coated_wheaten_terrier\",\n",
    "27: \"Dandie_Dinmont\",\n",
    "28: \"red_wolf\",\n",
    "29: \"Old_English_sheepdog\",\n",
    "30: \"jaguar\",\n",
    "31: \"otterhound\",\n",
    "32: \"bloodhound\",\n",
    "33: \"Airedale\",\n",
    "34: \"hyena\",\n",
    "35: \"meerkat\",\n",
    "36: \"giant_schnauzer\",\n",
    "37: \"titi\",\n",
    "38: \"three-toed_sloth\",\n",
    "39: \"sorrel\",\n",
    "40: \"black-footed_ferret\",\n",
    "41: \"dalmatian\",\n",
    "42: \"black-and-tan_coonhound\",\n",
    "43: \"papillon\",\n",
    "44: \"skunk\",\n",
    "45: \"Staffordshire_bullterrier\",\n",
    "46: \"Mexican_hairless\",\n",
    "47: \"Bouvier_des_Flandres\",\n",
    "48: \"weasel\",\n",
    "49: \"miniature_poodle\",\n",
    "50: \"Cardigan\",\n",
    "51: \"malinois\",\n",
    "52: \"bighorn\",\n",
    "53: \"fox_squirrel\",\n",
    "54: \"colobus\",\n",
    "55: \"tiger_cat\",\n",
    "56: \"Lhasa\",\n",
    "57: \"impala\",\n",
    "58: \"coyote\",\n",
    "59: \"Yorkshire_terrier\",\n",
    "60: \"Newfoundland\",\n",
    "61: \"brown_bear\",\n",
    "62: \"red_fox\",\n",
    "63: \"Norwegian_elkhound\",\n",
    "64: \"Rottweiler\",\n",
    "65: \"hartebeest\",\n",
    "66: \"Saluki\",\n",
    "67: \"grey_fox\",\n",
    "68: \"schipperke\",\n",
    "69: \"Pekinese\",\n",
    "70: \"Brabancon_griffon\",\n",
    "71: \"West_Highland_white_terrier\",\n",
    "72: \"Sealyham_terrier\",\n",
    "73: \"guenon\",\n",
    "74: \"mongoose\",\n",
    "75: \"indri\",\n",
    "76: \"tiger\",\n",
    "77: \"Irish_wolfhound\",\n",
    "78: \"wild_boar\",\n",
    "79: \"EntleBucher\",\n",
    "80: \"zebra\",\n",
    "81: \"ram\",\n",
    "82: \"French_bulldog\",\n",
    "83: \"orangutan\",\n",
    "84: \"basenji\",\n",
    "85: \"leopard\",\n",
    "86: \"Bernese_mountain_dog\",\n",
    "87: \"Maltese_dog\",\n",
    "88: \"Norfolk_terrier\",\n",
    "89: \"toy_terrier\",\n",
    "90: \"vizsla\",\n",
    "91: \"cairn\",\n",
    "92: \"squirrel_monkey\",\n",
    "93: \"groenendael\",\n",
    "94: \"clumber\",\n",
    "95: \"Siamese_cat\",\n",
    "96: \"chimpanzee\",\n",
    "97: \"komondor\",\n",
    "98: \"Afghan_hound\",\n",
    "99: \"Japanese_spaniel\",\n",
    "100: \"proboscis_monkey\",\n",
    "101: \"guinea_pig\",\n",
    "102: \"white_wolf\",\n",
    "103: \"ice_bear\",\n",
    "104: \"gorilla\",\n",
    "105: \"borzoi\",\n",
    "106: \"toy_poodle\",\n",
    "107: \"Kerry_blue_terrier\",\n",
    "108: \"ox\",\n",
    "109: \"Scotch_terrier\",\n",
    "110: \"Tibetan_mastiff\",\n",
    "111: \"spider_monkey\",\n",
    "112: \"Doberman\",\n",
    "113: \"Boston_bull\",\n",
    "114: \"Greater_Swiss_Mountain_dog\",\n",
    "115: \"Appenzeller\",\n",
    "116: \"Shih-Tzu\",\n",
    "117: \"Irish_water_spaniel\",\n",
    "118: \"Pomeranian\",\n",
    "119: \"Bedlington_terrier\",\n",
    "120: \"warthog\",\n",
    "121: \"Arabian_camel\",\n",
    "122: \"siamang\",\n",
    "123: \"miniature_schnauzer\",\n",
    "124: \"collie\",\n",
    "125: \"golden_retriever\",\n",
    "126: \"Irish_terrier\",\n",
    "127: \"affenpinscher\",\n",
    "128: \"Border_collie\",\n",
    "129: \"hare\",\n",
    "130: \"boxer\",\n",
    "131: \"silky_terrier\",\n",
    "132: \"beagle\",\n",
    "133: \"Leonberg\",\n",
    "134: \"German_short-haired_pointer\",\n",
    "135: \"patas\",\n",
    "136: \"dhole\",\n",
    "137: \"baboon\",\n",
    "138: \"macaque\",\n",
    "139: \"Chesapeake_Bay_retriever\",\n",
    "140: \"bull_mastiff\",\n",
    "141: \"kuvasz\",\n",
    "142: \"capuchin\",\n",
    "143: \"pug\",\n",
    "144: \"curly-coated_retriever\",\n",
    "145: \"Norwich_terrier\",\n",
    "146: \"flat-coated_retriever\",\n",
    "147: \"hog\",\n",
    "148: \"keeshond\",\n",
    "149: \"Eskimo_dog\",\n",
    "150: \"Brittany_spaniel\",\n",
    "151: \"standard_poodle\",\n",
    "152: \"Lakeland_terrier\",\n",
    "153: \"snow_leopard\",\n",
    "154: \"Gordon_setter\",\n",
    "155: \"dingo\",\n",
    "156: \"standard_schnauzer\",\n",
    "157: \"hamster\",\n",
    "158: \"Tibetan_terrier\",\n",
    "159: \"Arctic_fox\",\n",
    "160: \"wire-haired_fox_terrier\",\n",
    "161: \"basset\",\n",
    "162: \"water_buffalo\",\n",
    "163: \"American_black_bear\",\n",
    "164: \"Angora\",\n",
    "165: \"bison\",\n",
    "166: \"howler_monkey\",\n",
    "167: \"hippopotamus\",\n",
    "168: \"chow\",\n",
    "169: \"giant_panda\",\n",
    "170: \"American_Staffordshire_terrier\",\n",
    "171: \"Shetland_sheepdog\",\n",
    "172: \"Great_Pyrenees\",\n",
    "173: \"Chihuahua\",\n",
    "174: \"tabby\",\n",
    "175: \"marmoset\",\n",
    "176: \"Labrador_retriever\",\n",
    "177: \"Saint_Bernard\",\n",
    "178: \"armadillo\",\n",
    "179: \"Samoyed\",\n",
    "180: \"bluetick\",\n",
    "181: \"redbone\",\n",
    "182: \"polecat\",\n",
    "183: \"marmot\",\n",
    "184: \"kelpie\",\n",
    "185: \"gibbon\",\n",
    "186: \"llama\",\n",
    "187: \"miniature_pinscher\",\n",
    "188: \"wood_rabbit\",\n",
    "189: \"Italian_greyhound\",\n",
    "190: \"lion\",\n",
    "191: \"cocker_spaniel\",\n",
    "192: \"Irish_setter\",\n",
    "193: \"dugong\",\n",
    "194: \"Indian_elephant\",\n",
    "195: \"beaver\",\n",
    "196: \"Sussex_spaniel\",\n",
    "197: \"Pembroke\",\n",
    "198: \"Blenheim_spaniel\",\n",
    "199: \"Madagascar_cat\",\n",
    "200: \"Rhodesian_ridgeback\",\n",
    "201: \"lynx\",\n",
    "202: \"African_hunting_dog\",\n",
    "203: \"langur\",\n",
    "204: \"Ibizan_hound\",\n",
    "205: \"timber_wolf\",\n",
    "206: \"cheetah\",\n",
    "207: \"English_foxhound\",\n",
    "208: \"briard\",\n",
    "209: \"sloth_bear\",\n",
    "210: \"Border_terrier\",\n",
    "211: \"German_shepherd\",\n",
    "212: \"otter\",\n",
    "213: \"koala\",\n",
    "214: \"tusker\",\n",
    "215: \"echidna\",\n",
    "216: \"wallaby\",\n",
    "217: \"platypus\",\n",
    "218: \"wombat\",\n",
    "219: \"revolver\",\n",
    "220: \"umbrella\",\n",
    "221: \"schooner\",\n",
    "222: \"soccer_ball\",\n",
    "223: \"accordion\",\n",
    "224: \"ant\",\n",
    "225: \"starfish\",\n",
    "226: \"chambered_nautilus\",\n",
    "227: \"grand_piano\",\n",
    "228: \"laptop\",\n",
    "229: \"strawberry\",\n",
    "230: \"airliner\",\n",
    "231: \"warplane\",\n",
    "232: \"airship\",\n",
    "233: \"balloon\",\n",
    "234: \"space_shuttle\",\n",
    "235: \"fireboat\",\n",
    "236: \"gondola\",\n",
    "237: \"speedboat\",\n",
    "238: \"lifeboat\",\n",
    "239: \"canoe\",\n",
    "240: \"yawl\",\n",
    "241: \"catamaran\",\n",
    "242: \"trimaran\",\n",
    "243: \"container_ship\",\n",
    "244: \"liner\",\n",
    "245: \"pirate\",\n",
    "246: \"aircraft_carrier\",\n",
    "247: \"submarine\",\n",
    "248: \"wreck\",\n",
    "249: \"half_track\",\n",
    "250: \"tank\",\n",
    "251: \"missile\",\n",
    "252: \"bobsled\",\n",
    "253: \"dogsled\",\n",
    "254: \"bicycle-built-for-two\",\n",
    "255: \"mountain_bike\",\n",
    "256: \"freight_car\",\n",
    "257: \"passenger_car\",\n",
    "258: \"barrow\",\n",
    "259: \"shopping_cart\",\n",
    "260: \"motor_scooter\",\n",
    "261: \"forklift\",\n",
    "262: \"electric_locomotive\",\n",
    "263: \"steam_locomotive\",\n",
    "264: \"amphibian\",\n",
    "265: \"ambulance\",\n",
    "266: \"beach_wagon\",\n",
    "267: \"cab\",\n",
    "268: \"convertible\",\n",
    "269: \"jeep\",\n",
    "270: \"limousine\",\n",
    "271: \"minivan\",\n",
    "272: \"Model_T\",\n",
    "273: \"racer\",\n",
    "274: \"sports_car\",\n",
    "275: \"go-kart\",\n",
    "276: \"golfcart\",\n",
    "277: \"moped\",\n",
    "278: \"snowplow\",\n",
    "279: \"fire_engine\",\n",
    "280: \"garbage_truck\",\n",
    "281: \"pickup\",\n",
    "282: \"tow_truck\",\n",
    "283: \"trailer_truck\",\n",
    "284: \"moving_van\",\n",
    "285: \"police_van\",\n",
    "286: \"recreational_vehicle\",\n",
    "287: \"streetcar\",\n",
    "288: \"snowmobile\",\n",
    "289: \"tractor\",\n",
    "290: \"mobile_home\",\n",
    "291: \"tricycle\",\n",
    "292: \"unicycle\",\n",
    "293: \"horse_cart\",\n",
    "294: \"jinrikisha\",\n",
    "295: \"oxcart\",\n",
    "296: \"bassinet\",\n",
    "297: \"cradle\",\n",
    "298: \"crib\",\n",
    "299: \"four-poster\",\n",
    "300: \"bookcase\",\n",
    "301: \"china_cabinet\",\n",
    "302: \"medicine_chest\",\n",
    "303: \"chiffonier\",\n",
    "304: \"table_lamp\",\n",
    "305: \"file\",\n",
    "306: \"park_bench\",\n",
    "307: \"barber_chair\",\n",
    "308: \"throne\",\n",
    "309: \"folding_chair\",\n",
    "310: \"rocking_chair\",\n",
    "311: \"studio_couch\",\n",
    "312: \"toilet_seat\",\n",
    "313: \"desk\",\n",
    "314: \"pool_table\",\n",
    "315: \"dining_table\",\n",
    "316: \"entertainment_center\",\n",
    "317: \"wardrobe\",\n",
    "318: \"Granny_Smith\",\n",
    "319: \"orange\",\n",
    "320: \"lemon\",\n",
    "321: \"fig\",\n",
    "322: \"pineapple\",\n",
    "323: \"banana\",\n",
    "324: \"jackfruit\",\n",
    "325: \"custard_apple\",\n",
    "326: \"pomegranate\",\n",
    "327: \"acorn\",\n",
    "328: \"hip\",\n",
    "329: \"ear\",\n",
    "330: \"rapeseed\",\n",
    "331: \"corn\",\n",
    "332: \"buckeye\",\n",
    "333: \"organ\",\n",
    "334: \"upright\",\n",
    "335: \"chime\",\n",
    "336: \"drum\",\n",
    "337: \"gong\",\n",
    "338: \"maraca\",\n",
    "339: \"marimba\",\n",
    "340: \"steel_drum\",\n",
    "341: \"banjo\",\n",
    "342: \"cello\",\n",
    "343: \"violin\",\n",
    "344: \"harp\",\n",
    "345: \"acoustic_guitar\",\n",
    "346: \"electric_guitar\",\n",
    "347: \"cornet\",\n",
    "348: \"French_horn\",\n",
    "349: \"trombone\",\n",
    "350: \"harmonica\",\n",
    "351: \"ocarina\",\n",
    "352: \"panpipe\",\n",
    "353: \"bassoon\",\n",
    "354: \"oboe\",\n",
    "355: \"sax\",\n",
    "356: \"flute\",\n",
    "357: \"daisy\",\n",
    "358: \"yellow_lady's_slipper\",\n",
    "359: \"cliff\",\n",
    "360: \"valley\",\n",
    "361: \"alp\",\n",
    "362: \"volcano\",\n",
    "363: \"promontory\",\n",
    "364: \"sandbar\",\n",
    "365: \"coral_reef\",\n",
    "366: \"lakeside\",\n",
    "367: \"seashore\",\n",
    "368: \"geyser\",\n",
    "369: \"hatchet\",\n",
    "370: \"cleaver\",\n",
    "371: \"letter_opener\",\n",
    "372: \"plane\",\n",
    "373: \"power_drill\",\n",
    "374: \"lawn_mower\",\n",
    "375: \"hammer\",\n",
    "376: \"corkscrew\",\n",
    "377: \"can_opener\",\n",
    "378: \"plunger\",\n",
    "379: \"screwdriver\",\n",
    "380: \"shovel\",\n",
    "381: \"plow\",\n",
    "382: \"chain_saw\",\n",
    "383: \"cock\",\n",
    "384: \"hen\",\n",
    "385: \"ostrich\",\n",
    "386: \"brambling\",\n",
    "387: \"goldfinch\",\n",
    "388: \"house_finch\",\n",
    "389: \"junco\",\n",
    "390: \"indigo_bunting\",\n",
    "391: \"robin\",\n",
    "392: \"bulbul\",\n",
    "393: \"jay\",\n",
    "394: \"magpie\",\n",
    "395: \"chickadee\",\n",
    "396: \"water_ouzel\",\n",
    "397: \"kite\",\n",
    "398: \"bald_eagle\",\n",
    "399: \"vulture\",\n",
    "400: \"great_grey_owl\",\n",
    "401: \"black_grouse\",\n",
    "402: \"ptarmigan\",\n",
    "403: \"ruffed_grouse\",\n",
    "404: \"prairie_chicken\",\n",
    "405: \"peacock\",\n",
    "406: \"quail\",\n",
    "407: \"partridge\",\n",
    "408: \"African_grey\",\n",
    "409: \"macaw\",\n",
    "410: \"sulphur-crested_cockatoo\",\n",
    "411: \"lorikeet\",\n",
    "412: \"coucal\",\n",
    "413: \"bee_eater\",\n",
    "414: \"hornbill\",\n",
    "415: \"hummingbird\",\n",
    "416: \"jacamar\",\n",
    "417: \"toucan\",\n",
    "418: \"drake\",\n",
    "419: \"red-breasted_merganser\",\n",
    "420: \"goose\",\n",
    "421: \"black_swan\",\n",
    "422: \"white_stork\",\n",
    "423: \"black_stork\",\n",
    "424: \"spoonbill\",\n",
    "425: \"flamingo\",\n",
    "426: \"American_egret\",\n",
    "427: \"little_blue_heron\",\n",
    "428: \"bittern\",\n",
    "429: \"crane\",\n",
    "430: \"limpkin\",\n",
    "431: \"American_coot\",\n",
    "432: \"bustard\",\n",
    "433: \"ruddy_turnstone\",\n",
    "434: \"red-backed_sandpiper\",\n",
    "435: \"redshank\",\n",
    "436: \"dowitcher\",\n",
    "437: \"oystercatcher\",\n",
    "438: \"European_gallinule\",\n",
    "439: \"pelican\",\n",
    "440: \"king_penguin\",\n",
    "441: \"albatross\",\n",
    "442: \"great_white_shark\",\n",
    "443: \"tiger_shark\",\n",
    "444: \"hammerhead\",\n",
    "445: \"electric_ray\",\n",
    "446: \"stingray\",\n",
    "447: \"barracouta\",\n",
    "448: \"coho\",\n",
    "449: \"tench\",\n",
    "450: \"goldfish\",\n",
    "451: \"eel\",\n",
    "452: \"rock_beauty\",\n",
    "453: \"anemone_fish\",\n",
    "454: \"lionfish\",\n",
    "455: \"puffer\",\n",
    "456: \"sturgeon\",\n",
    "457: \"gar\",\n",
    "458: \"loggerhead\",\n",
    "459: \"leatherback_turtle\",\n",
    "460: \"mud_turtle\",\n",
    "461: \"terrapin\",\n",
    "462: \"box_turtle\",\n",
    "463: \"banded_gecko\",\n",
    "464: \"common_iguana\",\n",
    "465: \"American_chameleon\",\n",
    "466: \"whiptail\",\n",
    "467: \"agama\",\n",
    "468: \"frilled_lizard\",\n",
    "469: \"alligator_lizard\",\n",
    "470: \"Gila_monster\",\n",
    "471: \"green_lizard\",\n",
    "472: \"African_chameleon\",\n",
    "473: \"Komodo_dragon\",\n",
    "474: \"triceratops\",\n",
    "475: \"African_crocodile\",\n",
    "476: \"American_alligator\",\n",
    "477: \"thunder_snake\",\n",
    "478: \"ringneck_snake\",\n",
    "479: \"hognose_snake\",\n",
    "480: \"green_snake\",\n",
    "481: \"king_snake\",\n",
    "482: \"garter_snake\",\n",
    "483: \"water_snake\",\n",
    "484: \"vine_snake\",\n",
    "485: \"night_snake\",\n",
    "486: \"boa_constrictor\",\n",
    "487: \"rock_python\",\n",
    "488: \"Indian_cobra\",\n",
    "489: \"green_mamba\",\n",
    "490: \"sea_snake\",\n",
    "491: \"horned_viper\",\n",
    "492: \"diamondback\",\n",
    "493: \"sidewinder\",\n",
    "494: \"European_fire_salamander\",\n",
    "495: \"common_newt\",\n",
    "496: \"eft\",\n",
    "497: \"spotted_salamander\",\n",
    "498: \"axolotl\",\n",
    "499: \"bullfrog\",\n",
    "500: \"tree_frog\",\n",
    "501: \"tailed_frog\",\n",
    "502: \"whistle\",\n",
    "503: \"wing\",\n",
    "504: \"paintbrush\",\n",
    "505: \"hand_blower\",\n",
    "506: \"oxygen_mask\",\n",
    "507: \"snorkel\",\n",
    "508: \"loudspeaker\",\n",
    "509: \"microphone\",\n",
    "510: \"screen\",\n",
    "511: \"mouse\",\n",
    "512: \"electric_fan\",\n",
    "513: \"oil_filter\",\n",
    "514: \"strainer\",\n",
    "515: \"space_heater\",\n",
    "516: \"stove\",\n",
    "517: \"guillotine\",\n",
    "518: \"barometer\",\n",
    "519: \"rule\",\n",
    "520: \"odometer\",\n",
    "521: \"scale\",\n",
    "522: \"analog_clock\",\n",
    "523: \"digital_clock\",\n",
    "524: \"wall_clock\",\n",
    "525: \"hourglass\",\n",
    "526: \"sundial\",\n",
    "527: \"parking_meter\",\n",
    "528: \"stopwatch\",\n",
    "529: \"digital_watch\",\n",
    "530: \"stethoscope\",\n",
    "531: \"syringe\",\n",
    "532: \"magnetic_compass\",\n",
    "533: \"binoculars\",\n",
    "534: \"projector\",\n",
    "535: \"sunglasses\",\n",
    "536: \"loupe\",\n",
    "537: \"radio_telescope\",\n",
    "538: \"bow\",\n",
    "539: \"cannon\",\n",
    "540: \"assault_rifle\",\n",
    "541: \"rifle\",\n",
    "542: \"projectile\",\n",
    "543: \"computer_keyboard\",\n",
    "544: \"typewriter_keyboard\",\n",
    "545: \"crane\",\n",
    "546: \"lighter\",\n",
    "547: \"abacus\",\n",
    "548: \"cash_machine\",\n",
    "549: \"slide_rule\",\n",
    "550: \"desktop_computer\",\n",
    "551: \"hand-held_computer\",\n",
    "552: \"notebook\",\n",
    "553: \"web_site\",\n",
    "554: \"harvester\",\n",
    "555: \"thresher\",\n",
    "556: \"printer\",\n",
    "557: \"slot\",\n",
    "558: \"vending_machine\",\n",
    "559: \"sewing_machine\",\n",
    "560: \"joystick\",\n",
    "561: \"switch\",\n",
    "562: \"hook\",\n",
    "563: \"car_wheel\",\n",
    "564: \"paddlewheel\",\n",
    "565: \"pinwheel\",\n",
    "566: \"potter's_wheel\",\n",
    "567: \"gas_pump\",\n",
    "568: \"carousel\",\n",
    "569: \"swing\",\n",
    "570: \"reel\",\n",
    "571: \"radiator\",\n",
    "572: \"puck\",\n",
    "573: \"hard_disc\",\n",
    "574: \"sunglass\",\n",
    "575: \"pick\",\n",
    "576: \"car_mirror\",\n",
    "577: \"solar_dish\",\n",
    "578: \"remote_control\",\n",
    "579: \"disk_brake\",\n",
    "580: \"buckle\",\n",
    "581: \"hair_slide\",\n",
    "582: \"knot\",\n",
    "583: \"combination_lock\",\n",
    "584: \"padlock\",\n",
    "585: \"nail\",\n",
    "586: \"safety_pin\",\n",
    "587: \"screw\",\n",
    "588: \"muzzle\",\n",
    "589: \"seat_belt\",\n",
    "590: \"ski\",\n",
    "591: \"candle\",\n",
    "592: \"jack-o'-lantern\",\n",
    "593: \"spotlight\",\n",
    "594: \"torch\",\n",
    "595: \"neck_brace\",\n",
    "596: \"pier\",\n",
    "597: \"tripod\",\n",
    "598: \"maypole\",\n",
    "599: \"mousetrap\",\n",
    "600: \"spider_web\",\n",
    "601: \"trilobite\",\n",
    "602: \"harvestman\",\n",
    "603: \"scorpion\",\n",
    "604: \"black_and_gold_garden_spider\",\n",
    "605: \"barn_spider\",\n",
    "606: \"garden_spider\",\n",
    "607: \"black_widow\",\n",
    "608: \"tarantula\",\n",
    "609: \"wolf_spider\",\n",
    "610: \"tick\",\n",
    "611: \"centipede\",\n",
    "612: \"isopod\",\n",
    "613: \"Dungeness_crab\",\n",
    "614: \"rock_crab\",\n",
    "615: \"fiddler_crab\",\n",
    "616: \"king_crab\",\n",
    "617: \"American_lobster\",\n",
    "618: \"spiny_lobster\",\n",
    "619: \"crayfish\",\n",
    "620: \"hermit_crab\",\n",
    "621: \"tiger_beetle\",\n",
    "622: \"ladybug\",\n",
    "623: \"ground_beetle\",\n",
    "624: \"long-horned_beetle\",\n",
    "625: \"leaf_beetle\",\n",
    "626: \"dung_beetle\",\n",
    "627: \"rhinoceros_beetle\",\n",
    "628: \"weevil\",\n",
    "629: \"fly\",\n",
    "630: \"bee\",\n",
    "631: \"grasshopper\",\n",
    "632: \"cricket\",\n",
    "633: \"walking_stick\",\n",
    "634: \"cockroach\",\n",
    "635: \"mantis\",\n",
    "636: \"cicada\",\n",
    "637: \"leafhopper\",\n",
    "638: \"lacewing\",\n",
    "639: \"dragonfly\",\n",
    "640: \"damselfly\",\n",
    "641: \"admiral\",\n",
    "642: \"ringlet\",\n",
    "643: \"monarch\",\n",
    "644: \"cabbage_butterfly\",\n",
    "645: \"sulphur_butterfly\",\n",
    "646: \"lycaenid\",\n",
    "647: \"jellyfish\",\n",
    "648: \"sea_anemone\",\n",
    "649: \"brain_coral\",\n",
    "650: \"flatworm\",\n",
    "651: \"nematode\",\n",
    "652: \"conch\",\n",
    "653: \"snail\",\n",
    "654: \"slug\",\n",
    "655: \"sea_slug\",\n",
    "656: \"chiton\",\n",
    "657: \"sea_urchin\",\n",
    "658: \"sea_cucumber\",\n",
    "659: \"iron\",\n",
    "660: \"espresso_maker\",\n",
    "661: \"microwave\",\n",
    "662: \"Dutch_oven\",\n",
    "663: \"rotisserie\",\n",
    "664: \"toaster\",\n",
    "665: \"waffle_iron\",\n",
    "666: \"vacuum\",\n",
    "667: \"dishwasher\",\n",
    "668: \"refrigerator\",\n",
    "669: \"washer\",\n",
    "670: \"Crock_Pot\",\n",
    "671: \"frying_pan\",\n",
    "672: \"wok\",\n",
    "673: \"caldron\",\n",
    "674: \"coffeepot\",\n",
    "675: \"teapot\",\n",
    "676: \"spatula\",\n",
    "677: \"altar\",\n",
    "678: \"triumphal_arch\",\n",
    "679: \"patio\",\n",
    "680: \"steel_arch_bridge\",\n",
    "681: \"suspension_bridge\",\n",
    "682: \"viaduct\",\n",
    "683: \"barn\",\n",
    "684: \"greenhouse\",\n",
    "685: \"palace\",\n",
    "686: \"monastery\",\n",
    "687: \"library\",\n",
    "688: \"apiary\",\n",
    "689: \"boathouse\",\n",
    "690: \"church\",\n",
    "691: \"mosque\",\n",
    "692: \"stupa\",\n",
    "693: \"planetarium\",\n",
    "694: \"restaurant\",\n",
    "695: \"cinema\",\n",
    "696: \"home_theater\",\n",
    "697: \"lumbermill\",\n",
    "698: \"coil\",\n",
    "699: \"obelisk\",\n",
    "700: \"totem_pole\",\n",
    "701: \"castle\",\n",
    "702: \"prison\",\n",
    "703: \"grocery_store\",\n",
    "704: \"bakery\",\n",
    "705: \"barbershop\",\n",
    "706: \"bookshop\",\n",
    "707: \"butcher_shop\",\n",
    "708: \"confectionery\",\n",
    "709: \"shoe_shop\",\n",
    "710: \"tobacco_shop\",\n",
    "711: \"toyshop\",\n",
    "712: \"fountain\",\n",
    "713: \"cliff_dwelling\",\n",
    "714: \"yurt\",\n",
    "715: \"dock\",\n",
    "716: \"brass\",\n",
    "717: \"megalith\",\n",
    "718: \"bannister\",\n",
    "719: \"breakwater\",\n",
    "720: \"dam\",\n",
    "721: \"chainlink_fence\",\n",
    "722: \"picket_fence\",\n",
    "723: \"worm_fence\",\n",
    "724: \"stone_wall\",\n",
    "725: \"grille\",\n",
    "726: \"sliding_door\",\n",
    "727: \"turnstile\",\n",
    "728: \"mountain_tent\",\n",
    "729: \"scoreboard\",\n",
    "730: \"honeycomb\",\n",
    "731: \"plate_rack\",\n",
    "732: \"pedestal\",\n",
    "733: \"beacon\",\n",
    "734: \"mashed_potato\",\n",
    "735: \"bell_pepper\",\n",
    "736: \"head_cabbage\",\n",
    "737: \"broccoli\",\n",
    "738: \"cauliflower\",\n",
    "739: \"zucchini\",\n",
    "740: \"spaghetti_squash\",\n",
    "741: \"acorn_squash\",\n",
    "742: \"butternut_squash\",\n",
    "743: \"cucumber\",\n",
    "744: \"artichoke\",\n",
    "745: \"cardoon\",\n",
    "746: \"mushroom\",\n",
    "747: \"shower_curtain\",\n",
    "748: \"jean\",\n",
    "749: \"carton\",\n",
    "750: \"handkerchief\",\n",
    "751: \"sandal\",\n",
    "752: \"ashcan\",\n",
    "753: \"safe\",\n",
    "754: \"plate\",\n",
    "755: \"necklace\",\n",
    "756: \"croquet_ball\",\n",
    "757: \"fur_coat\",\n",
    "758: \"thimble\",\n",
    "759: \"pajama\",\n",
    "760: \"running_shoe\",\n",
    "761: \"cocktail_shaker\",\n",
    "762: \"chest\",\n",
    "763: \"manhole_cover\",\n",
    "764: \"modem\",\n",
    "765: \"tub\",\n",
    "766: \"tray\",\n",
    "767: \"balance_beam\",\n",
    "768: \"bagel\",\n",
    "769: \"prayer_rug\",\n",
    "770: \"kimono\",\n",
    "771: \"hot_pot\",\n",
    "772: \"whiskey_jug\",\n",
    "773: \"knee_pad\",\n",
    "774: \"book_jacket\",\n",
    "775: \"spindle\",\n",
    "776: \"ski_mask\",\n",
    "777: \"beer_bottle\",\n",
    "778: \"crash_helmet\",\n",
    "779: \"bottlecap\",\n",
    "780: \"tile_roof\",\n",
    "781: \"mask\",\n",
    "782: \"maillot\",\n",
    "783: \"Petri_dish\",\n",
    "784: \"football_helmet\",\n",
    "785: \"bathing_cap\",\n",
    "786: \"teddy\",\n",
    "787: \"holster\",\n",
    "788: \"pop_bottle\",\n",
    "789: \"photocopier\",\n",
    "790: \"vestment\",\n",
    "791: \"crossword_puzzle\",\n",
    "792: \"golf_ball\",\n",
    "793: \"trifle\",\n",
    "794: \"suit\",\n",
    "795: \"water_tower\",\n",
    "796: \"feather_boa\",\n",
    "797: \"cloak\",\n",
    "798: \"red_wine\",\n",
    "799: \"drumstick\",\n",
    "800: \"shield\",\n",
    "801: \"Christmas_stocking\",\n",
    "802: \"hoopskirt\",\n",
    "803: \"menu\",\n",
    "804: \"stage\",\n",
    "805: \"bonnet\",\n",
    "806: \"meat_loaf\",\n",
    "807: \"baseball\",\n",
    "808: \"face_powder\",\n",
    "809: \"scabbard\",\n",
    "810: \"sunscreen\",\n",
    "811: \"beer_glass\",\n",
    "812: \"hen-of-the-woods\",\n",
    "813: \"guacamole\",\n",
    "814: \"lampshade\",\n",
    "815: \"wool\",\n",
    "816: \"hay\",\n",
    "817: \"bow_tie\",\n",
    "818: \"mailbag\",\n",
    "819: \"water_jug\",\n",
    "820: \"bucket\",\n",
    "821: \"dishrag\",\n",
    "822: \"soup_bowl\",\n",
    "823: \"eggnog\",\n",
    "824: \"mortar\",\n",
    "825: \"trench_coat\",\n",
    "826: \"paddle\",\n",
    "827: \"chain\",\n",
    "828: \"swab\",\n",
    "829: \"mixing_bowl\",\n",
    "830: \"potpie\",\n",
    "831: \"wine_bottle\",\n",
    "832: \"shoji\",\n",
    "833: \"bulletproof_vest\",\n",
    "834: \"drilling_platform\",\n",
    "835: \"binder\",\n",
    "836: \"cardigan\",\n",
    "837: \"sweatshirt\",\n",
    "838: \"pot\",\n",
    "839: \"birdhouse\",\n",
    "840: \"hamper\",\n",
    "841: \"ping-pong_ball\",\n",
    "842: \"pencil_box\",\n",
    "843: \"pay-phone\",\n",
    "844: \"consomme\",\n",
    "845: \"apron\",\n",
    "846: \"punching_bag\",\n",
    "847: \"backpack\",\n",
    "848: \"groom\",\n",
    "849: \"bearskin\",\n",
    "850: \"pencil_sharpener\",\n",
    "851: \"broom\",\n",
    "852: \"mosquito_net\",\n",
    "853: \"abaya\",\n",
    "854: \"mortarboard\",\n",
    "855: \"poncho\",\n",
    "856: \"crutch\",\n",
    "857: \"Polaroid_camera\",\n",
    "858: \"space_bar\",\n",
    "859: \"cup\",\n",
    "860: \"racket\",\n",
    "861: \"traffic_light\",\n",
    "862: \"quill\",\n",
    "863: \"radio\",\n",
    "864: \"dough\",\n",
    "865: \"cuirass\",\n",
    "866: \"military_uniform\",\n",
    "867: \"lipstick\",\n",
    "868: \"shower_cap\",\n",
    "869: \"monitor\",\n",
    "870: \"oscilloscope\",\n",
    "871: \"mitten\",\n",
    "872: \"brassiere\",\n",
    "873: \"French_loaf\",\n",
    "874: \"vase\",\n",
    "875: \"milk_can\",\n",
    "876: \"rugby_ball\",\n",
    "877: \"paper_towel\",\n",
    "878: \"earthstar\",\n",
    "879: \"envelope\",\n",
    "880: \"miniskirt\",\n",
    "881: \"cowboy_hat\",\n",
    "882: \"trolleybus\",\n",
    "883: \"perfume\",\n",
    "884: \"bathtub\",\n",
    "885: \"hotdog\",\n",
    "886: \"coral_fungus\",\n",
    "887: \"bullet_train\",\n",
    "888: \"pillow\",\n",
    "889: \"toilet_tissue\",\n",
    "890: \"cassette\",\n",
    "891: \"carpenter's_kit\",\n",
    "892: \"ladle\",\n",
    "893: \"stinkhorn\",\n",
    "894: \"lotion\",\n",
    "895: \"hair_spray\",\n",
    "896: \"academic_gown\",\n",
    "897: \"dome\",\n",
    "898: \"crate\",\n",
    "899: \"wig\",\n",
    "900: \"burrito\",\n",
    "901: \"pill_bottle\",\n",
    "902: \"chain_mail\",\n",
    "903: \"theater_curtain\",\n",
    "904: \"window_shade\",\n",
    "905: \"barrel\",\n",
    "906: \"washbasin\",\n",
    "907: \"ballpoint\",\n",
    "908: \"basketball\",\n",
    "909: \"bath_towel\",\n",
    "910: \"cowboy_boot\",\n",
    "911: \"gown\",\n",
    "912: \"window_screen\",\n",
    "913: \"agaric\",\n",
    "914: \"cellular_telephone\",\n",
    "915: \"nipple\",\n",
    "916: \"barbell\",\n",
    "917: \"mailbox\",\n",
    "918: \"lab_coat\",\n",
    "919: \"fire_screen\",\n",
    "920: \"minibus\",\n",
    "921: \"packet\",\n",
    "922: \"maze\",\n",
    "923: \"pole\",\n",
    "924: \"horizontal_bar\",\n",
    "925: \"sombrero\",\n",
    "926: \"pickelhaube\",\n",
    "927: \"rain_barrel\",\n",
    "928: \"wallet\",\n",
    "929: \"cassette_player\",\n",
    "930: \"comic_book\",\n",
    "931: \"piggy_bank\",\n",
    "932: \"street_sign\",\n",
    "933: \"bell_cote\",\n",
    "934: \"fountain_pen\",\n",
    "935: \"Windsor_tie\",\n",
    "936: \"volleyball\",\n",
    "937: \"overskirt\",\n",
    "938: \"sarong\",\n",
    "939: \"purse\",\n",
    "940: \"bolo_tie\",\n",
    "941: \"bib\",\n",
    "942: \"parachute\",\n",
    "943: \"sleeping_bag\",\n",
    "944: \"television\",\n",
    "945: \"swimming_trunks\",\n",
    "946: \"measuring_cup\",\n",
    "947: \"espresso\",\n",
    "948: \"pizza\",\n",
    "949: \"breastplate\",\n",
    "950: \"shopping_basket\",\n",
    "951: \"wooden_spoon\",\n",
    "952: \"saltshaker\",\n",
    "953: \"chocolate_sauce\",\n",
    "954: \"ballplayer\",\n",
    "955: \"goblet\",\n",
    "956: \"gyromitra\",\n",
    "957: \"stretcher\",\n",
    "958: \"water_bottle\",\n",
    "959: \"dial_telephone\",\n",
    "960: \"soap_dispenser\",\n",
    "961: \"jersey\",\n",
    "962: \"school_bus\",\n",
    "963: \"jigsaw_puzzle\",\n",
    "964: \"plastic_bag\",\n",
    "965: \"reflex_camera\",\n",
    "966: \"diaper\",\n",
    "967: \"Band_Aid\",\n",
    "968: \"ice_lolly\",\n",
    "969: \"velvet\",\n",
    "970: \"tennis_ball\",\n",
    "971: \"gasmask\",\n",
    "972: \"doormat\",\n",
    "973: \"Loafer\",\n",
    "974: \"ice_cream\",\n",
    "975: \"pretzel\",\n",
    "976: \"quilt\",\n",
    "977: \"maillot\",\n",
    "978: \"tape_player\",\n",
    "979: \"clog\",\n",
    "980: \"iPod\",\n",
    "981: \"bolete\",\n",
    "982: \"scuba_diver\",\n",
    "983: \"pitcher\",\n",
    "984: \"matchstick\",\n",
    "985: \"bikini\",\n",
    "986: \"sock\",\n",
    "987: \"CD_player\",\n",
    "988: \"lens_cap\",\n",
    "989: \"thatch\",\n",
    "990: \"vault\",\n",
    "991: \"beaker\",\n",
    "992: \"bubble\",\n",
    "993: \"cheeseburger\",\n",
    "994: \"parallel_bars\",\n",
    "995: \"flagpole\",\n",
    "996: \"coffee_mug\",\n",
    "997: \"rubber_eraser\",\n",
    "998: \"stole\",\n",
    "999: \"carbonara\",\n",
    "1000: \"dumbbell\",\n",
    "}\n",
    "imagenet64_classes = {k-1:v for k, v in imagenet64_classes.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:07:14.816624736Z",
     "start_time": "2024-01-07T19:07:14.628584229Z"
    }
   },
   "id": "e219054dbdc021f6",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "imagenet_assoc = [314,\n",
    " 932,\n",
    " 810,\n",
    " 414,\n",
    " 341,\n",
    " 917,\n",
    " 627,\n",
    " 877,\n",
    " 705,\n",
    " 625,\n",
    " 683,\n",
    " 448,\n",
    " 781,\n",
    " 372,\n",
    " 704,\n",
    " 158,\n",
    " 105,\n",
    " 689,\n",
    " 354,\n",
    " 325,\n",
    " 400,\n",
    " 739,\n",
    " 308,\n",
    " 862,\n",
    " 207,\n",
    " 614,\n",
    " 114,\n",
    " 954,\n",
    " 187,\n",
    " 474,\n",
    " 457,\n",
    " 286,\n",
    " 69,\n",
    " 806,\n",
    " 912,\n",
    " 652,\n",
    " 733,\n",
    " 938,\n",
    " 570,\n",
    " 910,\n",
    " 496,\n",
    " 73,\n",
    " 839,\n",
    " 511,\n",
    " 747,\n",
    " 849,\n",
    " 970,\n",
    " 978,\n",
    " 540,\n",
    " 367,\n",
    " 480,\n",
    " 32,\n",
    " 25,\n",
    " 424,\n",
    " 842,\n",
    " 425,\n",
    " 525,\n",
    " 109,\n",
    " 50,\n",
    " 675,\n",
    " 283,\n",
    " 349,\n",
    " 1,\n",
    " 281,\n",
    " 526,\n",
    " 765,\n",
    " 440,\n",
    " 737,\n",
    " 438,\n",
    " 821,\n",
    " 612,\n",
    " 311,\n",
    " 964,\n",
    " 744,\n",
    " 500,\n",
    " 975,\n",
    " 430,\n",
    " 458,\n",
    " 761,\n",
    " 945,\n",
    " 678,\n",
    " 957,\n",
    " 79,\n",
    " 619,\n",
    " 734,\n",
    " 774,\n",
    " 470,\n",
    " 482,\n",
    " 447,\n",
    " 542,\n",
    " 532,\n",
    " 760,\n",
    " 75,\n",
    " 315,\n",
    " 887,\n",
    " 411,\n",
    " 71,\n",
    " 567,\n",
    " 123,\n",
    " 758]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:07:17.709619001Z",
     "start_time": "2024-01-07T19:07:17.480914152Z"
    }
   },
   "id": "e3d73e265eb06676",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act1): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (drop_block): Identity()\n      (act2): ReLU(inplace=True)\n      (aa): Identity()\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act3): ReLU(inplace=True)\n    )\n  )\n  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "from datamodules import Task1Datamodule\n",
    "import torch\n",
    "\n",
    "dm = Task1Datamodule(\n",
    "    path=\"/home/doved/Data/AAIT/task2\",\n",
    "    hq_path=None,\n",
    "    batch_size=64,\n",
    "    num_train_workers=0,\n",
    "    num_val_workers=0,\n",
    "    labeled=True,\n",
    "    unlabeled=False,\n",
    "    no_train_augmentations=True,\n",
    "    val_size=0,\n",
    ")\n",
    "dm.setup(\"fit\")\n",
    "resnet50 = timm.create_model(\"resnet50\", pretrained=True)\n",
    "resnet50.eval()\n",
    "resnet50.load_state_dict(torch.load(\"resnet50.lr01.pth.tar\")[\"state_dict\"])\n",
    "resnet50.to(\"cuda\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:06.707661120Z",
     "start_time": "2024-01-07T19:08:01.412934243Z"
    }
   },
   "id": "a4b5ead502a524cb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [00:42<00:00, 18.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "outputs = []\n",
    "labels = []\n",
    "for batch, l in tqdm(dm.train_dataloader()):\n",
    "    with torch.no_grad():\n",
    "        out = resnet50(batch[\"image\"].to(\"cuda\")).to(\"cpu\")\n",
    "    outputs.append(out)\n",
    "    labels.append(l)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:49.505901612Z",
     "start_time": "2024-01-07T19:08:06.554859748Z"
    }
   },
   "id": "c263eee837a6476a",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y_pred = [torch.argmax(o, dim=1) for o in outputs]\n",
    "y_pred = torch.cat(y_pred)\n",
    "y_true = torch.cat(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:49.590080715Z",
     "start_time": "2024-01-07T19:08:49.420667496Z"
    }
   },
   "id": "aa13e52766a44f52",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.9830, 3.8007, 3.9100,  ..., 4.1896, 4.4467, 3.4942])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "y_score = torch.cat(outputs, dim=0)\n",
    "y_score = F.softmax(y_score, dim=1)\n",
    "entropy = -torch.sum(y_score * torch.log(y_score), dim=1)\n",
    "entropy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:49.825729419Z",
     "start_time": "2024-01-07T19:08:49.464299011Z"
    }
   },
   "id": "c7b8e9fa4de69db",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "per_label = {}\n",
    "for i in range(len(y_true)):\n",
    "    true_label = y_true[i].item()\n",
    "    pred_label = y_pred[i].item()\n",
    "    if true_label not in per_label:\n",
    "        per_label[true_label] = []\n",
    "    per_label[true_label].append(pred_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:49.987785353Z",
     "start_time": "2024-01-07T19:08:49.716629363Z"
    }
   },
   "id": "4f1f2a12351c6eee",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "per_label_entropy = {}\n",
    "for i in range(len(y_true)):\n",
    "    true_label = y_true[i].item()\n",
    "    item_entropy = entropy[i]\n",
    "    if true_label not in per_label_entropy:\n",
    "        per_label_entropy[true_label] = []\n",
    "    per_label_entropy[true_label].append(item_entropy)\n",
    "per_label_entropy = {k:torch.mean(torch.tensor(v)).item() for k,v in per_label_entropy.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:50.561727512Z",
     "start_time": "2024-01-07T19:08:49.912698955Z"
    }
   },
   "id": "64f10e52384b9213",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "3.0747556686401367"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_label_entropy[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:50.593516102Z",
     "start_time": "2024-01-07T19:08:50.554356599Z"
    }
   },
   "id": "58328e155691d12",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{36: 1.6281516551971436,\n 86: 1.9547804594039917,\n 11: 2.1009693145751953,\n 58: 2.1751296520233154,\n 65: 2.367432117462158,\n 92: 2.4463260173797607,\n 40: 2.4592394828796387,\n 87: 2.5581116676330566,\n 59: 2.5781123638153076,\n 72: 2.5926170349121094,\n 33: 2.7311947345733643,\n 71: 2.7430431842803955,\n 18: 2.7498161792755127,\n 35: 2.7590317726135254,\n 77: 2.759401559829712,\n 62: 2.7597756385803223,\n 39: 2.801635265350342,\n 32: 2.8274872303009033,\n 27: 2.8408284187316895,\n 67: 2.844877243041992,\n 99: 2.9089839458465576,\n 43: 2.9867351055145264,\n 0: 3.0192549228668213,\n 2: 3.029355049133301,\n 1: 3.0747556686401367,\n 89: 3.094172954559326,\n 41: 3.1061506271362305,\n 30: 3.13783597946167,\n 79: 3.1408355236053467,\n 83: 3.1774415969848633,\n 23: 3.187620162963867,\n 52: 3.2298531532287598,\n 6: 3.234541177749634,\n 21: 3.2465596199035645,\n 47: 3.3309314250946045,\n 90: 3.3966944217681885,\n 28: 3.451287031173706,\n 73: 3.4555883407592773,\n 50: 3.469701051712036,\n 5: 3.506221055984497,\n 64: 3.522979974746704,\n 94: 3.5235471725463867,\n 17: 3.5261240005493164,\n 70: 3.5262913703918457,\n 48: 3.5344948768615723,\n 97: 3.5361804962158203,\n 69: 3.5466418266296387,\n 42: 3.574763536453247,\n 54: 3.581070899963379,\n 29: 3.581683397293091,\n 88: 3.5823256969451904,\n 75: 3.5903146266937256,\n 85: 3.594209671020508,\n 78: 3.6132473945617676,\n 53: 3.6192994117736816,\n 93: 3.632246732711792,\n 46: 3.648385763168335,\n 26: 3.6501760482788086,\n 38: 3.6640067100524902,\n 3: 3.669996976852417,\n 56: 3.678724527359009,\n 24: 3.6872994899749756,\n 16: 3.691693067550659,\n 49: 3.69636607170105,\n 20: 3.69880747795105,\n 12: 3.709904432296753,\n 51: 3.729212522506714,\n 45: 3.739285945892334,\n 10: 3.7398457527160645,\n 37: 3.7447726726531982,\n 34: 3.7526049613952637,\n 60: 3.766993284225464,\n 81: 3.7737538814544678,\n 15: 3.779420852661133,\n 22: 3.7898921966552734,\n 14: 3.789928913116455,\n 66: 3.799777030944824,\n 76: 3.815551280975342,\n 80: 3.8208861351013184,\n 74: 3.8317182064056396,\n 57: 3.836042881011963,\n 68: 3.8517708778381348,\n 95: 3.85178542137146,\n 19: 3.8526382446289062,\n 63: 3.8583855628967285,\n 84: 3.861159324645996,\n 8: 3.8612449169158936,\n 25: 3.8644936084747314,\n 9: 3.8698155879974365,\n 4: 3.8757176399230957,\n 61: 3.8862905502319336,\n 96: 3.8924179077148438,\n 98: 3.909842014312744,\n 31: 3.918715715408325,\n 44: 3.922569751739502,\n 91: 3.9250612258911133,\n 82: 3.932076930999756,\n 7: 3.9883310794830322,\n 13: 4.281946659088135,\n 55: 4.425940990447998}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in sorted(per_label_entropy.items(), key=lambda item: item[1])}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:50.600751213Z",
     "start_time": "2024-01-07T19:08:50.559675933Z"
    }
   },
   "id": "995b7502e3a3ae62",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "per_label = {k:Counter(v) for k, v in per_label.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:50.640167429Z",
     "start_time": "2024-01-07T19:08:50.568069524Z"
    }
   },
   "id": "91a2715619473e4",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(822, 91), (739, 90), (336, 40), (805, 29), (84, 25)]"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_label[3].most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:50.728709855Z",
     "start_time": "2024-01-07T19:08:50.573921220Z"
    }
   },
   "id": "c6d573148f375f55",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# imagenet64_assoc = assoc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:50.842922528Z",
     "start_time": "2024-01-07T19:08:50.616102501Z"
    }
   },
   "id": "fdc96324a4186a71",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{5: 900,\n 68: 364,\n 97: 901,\n 15: 604,\n 45: 805,\n 53: 604,\n 86: 422,\n 77: 11,\n 19: 883,\n 34: 739,\n 94: 82,\n 11: 524,\n 73: 492,\n 21: 524,\n 41: 886,\n 24: 717,\n 13: 935,\n 88: 332,\n 20: 739,\n 40: 440,\n 9: 6,\n 99: 255,\n 62: 60,\n 25: 219,\n 91: 901,\n 4: 621,\n 17: 850,\n 1: 419,\n 78: 826,\n 66: 632,\n 64: 210,\n 7: 785,\n 84: 573,\n 79: 646,\n 85: 711,\n 8: 444,\n 38: 976,\n 18: 642,\n 3: 822,\n 12: 554,\n 39: 681,\n 96: 709,\n 59: 213,\n 76: 351,\n 51: 744,\n 0: 164,\n 89: 554,\n 63: 745,\n 48: 302,\n 74: 558,\n 33: 677,\n 16: 307,\n 60: 597,\n 50: 994,\n 82: 326,\n 81: 192,\n 22: 852,\n 61: 652,\n 35: 904,\n 31: 444,\n 2: 961,\n 36: 192,\n 27: 189,\n 55: 875,\n 57: 822,\n 23: 235,\n 56: 336,\n 72: 283,\n 70: 988,\n 28: 318,\n 47: 116,\n 26: 550,\n 42: 492,\n 49: 143,\n 29: 584,\n 87: 531,\n 37: 377,\n 80: 616,\n 95: 999,\n 43: 514,\n 93: 739,\n 71: 527,\n 65: 794,\n 10: 842,\n 69: 709,\n 30: 739,\n 54: 819,\n 83: 273,\n 6: 843,\n 90: 924,\n 46: 546,\n 44: 538,\n 14: 370,\n 75: 107,\n 67: 439,\n 32: 7,\n 98: 274,\n 52: 698,\n 92: 732,\n 58: 6}"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assoc = {k:pl.most_common(1)[0][0] for k, pl in per_label.items()}\n",
    "assoc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:08:50.864468017Z",
     "start_time": "2024-01-07T19:08:50.616332376Z"
    }
   },
   "id": "35d9fcf5d2e7e13a",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[32,\n 61,\n 73,\n 99,\n 107,\n 113,\n 115,\n 122,\n 128,\n 145,\n 146,\n 149,\n 208,\n 235,\n 267,\n 285,\n 291,\n 294,\n 301,\n 309,\n 313,\n 319,\n 323,\n 329,\n 338,\n 345,\n 347,\n 353,\n 365,\n 386,\n 387,\n 398,\n 406,\n 421,\n 427,\n 435,\n 437,\n 445,\n 462,\n 463,\n 466,\n 467,\n 488,\n 492,\n 543,\n 557,\n 562,\n 565,\n 568,\n 573,\n 576,\n 604,\n 604,\n 605,\n 621,\n 635,\n 645,\n 645,\n 677,\n 682,\n 687,\n 707,\n 720,\n 731,\n 735,\n 751,\n 779,\n 786,\n 801,\n 808,\n 811,\n 826,\n 836,\n 845,\n 847,\n 850,\n 853,\n 865,\n 866,\n 873,\n 874,\n 879,\n 888,\n 890,\n 900,\n 909,\n 923,\n 923,\n 923,\n 923,\n 923,\n 929,\n 947,\n 950,\n 951,\n 963,\n 967,\n 972,\n 973,\n 988]"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(assoc.values())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T17:32:25.449725314Z",
     "start_time": "2024-01-07T17:32:25.147208636Z"
    }
   },
   "id": "5b8028342b8a05ba",
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assoc = [\n",
    "    164,\n",
    "    419,\n",
    "    961,\n",
    "    733,\n",
    "    621,\n",
    "    900,\n",
    "    946,\n",
    "    785,\n",
    "    657,\n",
    "    100,\n",
    "    842,\n",
    "    524,\n",
    "    373,\n",
    "    935,\n",
    "    530,\n",
    "    638,\n",
    "    676,\n",
    "    850,\n",
    "    642,\n",
    "    883,\n",
    "    812,\n",
    "    818,\n",
    "    756,\n",
    "    235,\n",
    "    717,\n",
    "    219,\n",
    "    979,\n",
    "    189,\n",
    "    318,\n",
    "    584,\n",
    "    319,\n",
    "    654,\n",
    "    173,\n",
    "    677,\n",
    "    947,\n",
    "    904,\n",
    "    192,\n",
    "    377,\n",
    "    984,\n",
    "    681,\n",
    "    440,\n",
    "    886,\n",
    "    485,\n",
    "    514,\n",
    "    538,\n",
    "    805,\n",
    "    546,\n",
    "    116,\n",
    "    761,\n",
    "    175,\n",
    "    994,\n",
    "    629,\n",
    "    698,\n",
    "    604,\n",
    "    819,\n",
    "    875,\n",
    "    671,\n",
    "    792,\n",
    "    6,\n",
    "    213,\n",
    "    597,\n",
    "    652,\n",
    "    60,\n",
    "    745,\n",
    "    210,\n",
    "    794,\n",
    "    632,\n",
    "    439,\n",
    "    364,\n",
    "    707,\n",
    "    988,\n",
    "    527,\n",
    "    881,\n",
    "    500,\n",
    "    558,\n",
    "    107,\n",
    "    967,\n",
    "    11,\n",
    "    826,\n",
    "    646,\n",
    "    616,\n",
    "    506,\n",
    "    326,\n",
    "    273,\n",
    "    573,\n",
    "    711,\n",
    "    422,\n",
    "    531,\n",
    "    332,\n",
    "    288,\n",
    "    924,\n",
    "    358,\n",
    "    732,\n",
    "    753,\n",
    "    82,\n",
    "    999,\n",
    "    706,\n",
    "    854,\n",
    "    274,\n",
    "    255,\n",
    "]\n",
    "assoc = {i:v for i, v in enumerate(assoc)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:09:35.798744333Z",
     "start_time": "2024-01-07T19:09:35.560343945Z"
    }
   },
   "id": "cafb3c74e5d8c105",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "print([item for item, count in collections.Counter(assoc.values()).items() if count > 1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:09:37.484043768Z",
     "start_time": "2024-01-07T19:09:37.345899168Z"
    }
   },
   "id": "f75d94c054b8db43",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[21, 11]"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k, v in assoc.items() if v == 524]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T17:28:45.677031841Z",
     "start_time": "2024-01-07T17:28:45.367448823Z"
    }
   },
   "id": "b4d3656e9c5f0eb3",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 45 = kettle\n",
    "# 66 = beer bottle\n",
    "# 67 = also bottle?"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.336639595Z",
     "start_time": "2024-01-06T16:42:00.110926778Z"
    }
   },
   "id": "2f392ec9bff11aa6",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(923, 90), (962, 28), (927, 18), (415, 12), (766, 11)]"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_label[45].most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T17:32:44.390396460Z",
     "start_time": "2024-01-07T17:32:44.254554296Z"
    }
   },
   "id": "fc554cf31efd5fd7",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(776, 22), (771, 19), (757, 12), (830, 8), (787, 8)]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_label[66].most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.375482923Z",
     "start_time": "2024-01-06T16:42:00.111640297Z"
    }
   },
   "id": "438fefc50bb81e07",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[(787, 21), (771, 10), (776, 9), (29, 7), (893, 5)]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_label[67].most_common(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:42:00.381037409Z",
     "start_time": "2024-01-06T16:42:00.112036864Z"
    }
   },
   "id": "558c71169c752ff1",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 82 = miriapod\n",
    "# 86 = scorpion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T09:36:18.420667038Z",
     "start_time": "2024-01-05T09:36:18.254596755Z"
    }
   },
   "id": "31d456fccb5fc81c",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T16:44:28.271832714Z",
     "start_time": "2024-01-06T16:44:27.974028640Z"
    }
   },
   "id": "b91b5c667a1a49bf",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDg4U+WpRHjDGqUOprnbHZSuf8AbIWnvqN2i/LBbR4/vMTj8q8pt3OxQ0uWZFIyWGPpzUmmQxzajF5y5iQl3GM7gO349KxjfajdSbA2WPCrFGOv412OiQro+nSedcLLezRgzjePkU5IUHoOME+pB6gU23FeZrCnzPyMy/lkmuHAXl5AVCplEHbp6YP6/SuavUMBVnRWLcgkHnj3rq727hZF6q+/bEWXA4J5J75z9KxLuNfMDbyAwLRbeQABjjPOODj6H3qoysayguhzLx7yzcDdyMdKjeEiM+4NbpsC4OxgxU4KDgj8+v4HtVGWELG3TOPrit4VLnJOFjet9P1BoUaYhVzjLEgVs2+mWsQy+yeTHQA4/XrW/M0UwB2qI8ZxtGT+NQT2YeXyIvLjn3bNsqNgHv0HXg8ZzwemK8R1KlV2joetThTiveIoYMKzQwRJGg52Ltx1P58H8qZe3ENnGkkm4Kyl1DL8uQCRjBBG7jByQBzyKuXzWulrFBJcRQrdFQwVFzHIu3Cjdkj75YknAwO4FQXeixXSi7tZlEblV2PL5w8sZI5JIODzj7p2jrwK6aVNU+pMpxltsYMTo9uuoPE6wRsQ/krh0J5XqPuk8cHIHTqKy9SuFklZUEQUv8gjBwRyQMHOD+J61oS+G71J2ns3aaHe6qFU72X0YfL0yR689BXPXLsjk70bLfNt+7064P0z/njqjBN3TOepOSjawkcrGX7RuIfI4zgmrM9uzpyuS+GBHfP/ANf69DVUqWlMmflyc5OQT355rStpvMSOAhgVkBHsD1/kP1q3pqjC/NozuL1Zra1U8RLOHAZyFXAB/wDHeDk88AjnpUttYWusWsNxNdmJTyIpOHK7gAy7SBnAPrj34FckmqTarrcUElwq2zMiNDgeW4B6uOh+8xyeRn8a27wSsZzayi3CcIoiGCR2GOme3GK8yX7mKitztk59C5NFYTTwK+0SZwI2QqR09iGzzgZyScDPAqa3thbvJvUyQkZRof8AlnxnHTOON2T6H0JqtaWt6LOGSYefJIRIZpCFLDBIwAeOi+v8XPQVbTUrSayWWGcsACcxFvmHQ8dQcKATyecjoMaJKej3XY09rFK8fmQ6PEY7qYLesLaVWcIgCCIY2ndkc/L3JGSPWsrXfCsZ/fafEYZE4MBYfOc84I4HJOPywOg01WCKVzNEzyybS8jA9cYCEMTghV6cHGPqbxWS503ysLHYCBYpFZWLdCFICjJBA9jnjoebhOSk4tilCM488VY8tZRDceRLuSdCyFHGCDkZznp3z7/mIUmFs8kh5BXCqRnjI/pmu51yys2eYypGf3SsshRg7sd6g/MNxBzyT3BrkbWNo7yQtF8zYCDr1PUfzrr51yu5wzpOLXmPvNRNrORbEDO7zXRcbjnHHfGMHPHXoMV0Nt4hWW2igmt5Vfam/wApl7kkA885/oOKksF+23R+36NBaW4Q7jIoSR29cnk//q/G+NK0y7ALQKm0kBB84x0zyBWbpQatJalfW2pX6FEa1JPsgsJpmJB/dkZ+QDJIHUjAB6cDPHWoxcy5ZIyswwQzJGW5Y53D/wDVwee9blvotjD5osomtzKArtGwUsB2P3uD3AwOB6Crtt4fsoZBKIU3HOc5fqcn7xI7Dt2qFQ7Kw/r8Y7pM5qELuKSmcsY/3IHKgMd2evGSOgBySa6G11SSERK8E22JQHhmOxXG4kE7uv0/x50TawpGQucf3c4H5Diq00wy3zFT04NUqCWvUyqY6c9ErIxNSkW4v/tk+kma08xZChlCBiMYG/GQBjgDpk+tVdb1TR9QETWPhdNOuUbLSR3hkD8ehAAq7eR27BiOprnZ5ApK1vTimuU5p1pt3bP/2Q==",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import Image, display\n",
    "\n",
    "df = pd.read_csv(\"/home/doved/Data/AAIT/task2/train_data/annotations.csv\")\n",
    "\n",
    "def show_images_with_label(label):\n",
    "    ldf = df[df[\"label\"] == label]\n",
    "    ldf = ldf.sample(12)\n",
    "    paths = ldf[\"sample\"].tolist()\n",
    "    for imageName in paths:\n",
    "        display(Image(filename=f\"/home/doved/Data/AAIT/{imageName}\"))\n",
    "\n",
    "show_images_with_label(45)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T19:09:43.641271933Z",
     "start_time": "2024-01-07T19:09:43.406972655Z"
    }
   },
   "id": "1c8b65901cfd9555",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "cassoc = deepcopy(assoc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T16:40:32.569381203Z",
     "start_time": "2024-01-07T16:40:32.336369150Z"
    }
   },
   "id": "a41521dd2ec286d1",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 7\n",
      "Guesses:\n",
      "    785: teddy\n",
      "    968: velvet\n",
      "    52: fox_squirrel\n",
      "    350: ocarina\n",
      "    116: Irish_water_spaniel\n",
      "    901: chain_mail\n",
      "    336: gong\n",
      "    351: panpipe\n",
      "    664: waffle_iron\n",
      "    84: leopard\n",
      "Predicted: 785: teddy\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDxlV74p2OKOn0pwGRUEDetIV9q6zwnp1vPby3k0SSv5vlIrqGC4AYnB78/oavX3hO1lmaWMNb+qqQFz7Ajjr0FZOtFSszojh5SjzI4NhUeDmu0tPClrHcbb6SVwTlAuFB+p69/asLxHpC6PqnkRuzRyIJE3dQCSMH8qqFWMnZEyozhG7MjtmhhinYpWGVrUyuSnilXjrSfyrU0DRbnxBrEGnWvDyZLORkIo6sf89SB3qQSbdkXvDD3NteI/lyCynfypH2Ervx8oz0zkj869DEMc6AuqybSGAIHUHI/Wur0Twnpnh/Tzb2kILuB5szn55fr7ew4rG8VeG5p9NnOmt5U8mNqK4T58g/KSQADj19cdhXJU96Vz1qdGUKemrOb1WSOxs5rwI7sOdoY846Y64/+vmvNtX1GXVr5rmUKvG1EX+FeSB79TzXu2geGZdPsIftlxLNdbcNKW3YJOTyc5+tefeOfAU+nzzanpaCSzZ/nhjXmI4HI9QTngAY44x0ujaL1McTSm4Jr7jzwg+uKMdxSnke1N/pXSecSg816X8LymmLLqM0W4TNsDZ5CjqR+JII9q8xVhXe+EtSnvdLOnW8caPar/rGOd2Sccfn+XvWVZtR0OjDW9oe0Q3sN6xFs3mfKAWzwB9fxq6V/dyeXnIIxjHA4rjbHXbW1tYoZFninAAcmMEZ7n1I61rXWqR2mhXU5ZXt7hGSN0OPmYY6HoeuR14NYKSZ7D0VzTuJdkZUHDdeoHpWDc+KNF2TxG7tmnXcoi3bm3jrkdRgj/wCvTrnVIbrSft6SIxcbfLTnDkH5T6d/wrjbrS7W5vr3U760t5JZwp2mMbUAUAYB6dOaHJLciUmkuU848R21tb6iTaMm1+WjX+A/TsD/AI1kde+Ks36xJqFzHCuIllYICc4GeKqetdcVaKPGm7ybAHHStXQdXfStTSXcRE3yyAenY/hWSOaXHPSm0mrMSfK7o9nuLmG500XYK42b1YEc/jXnGueI5r2SOO1nlWGPPRiAScZwO3SsVZZBD5PmP5ROSgY4z9KQKAKxhRUXc2niJSVlodBo/i2406EQzxtKo58wN834+tb9z4z0+XSpCkji4K5WLYc59DxjFcCRxxTWXjiqlSi3cmNeaVhjuzuXY5Ykkn1NNpxXFJgntxWpkf/Z",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1XxXNPDb3rquI00+VvM9H3rtH8/ypfCcLRSJ5ibJjpFl5o7hiZif1Jqp4tuYjZ61A8xXMEEUgPRQxfBH4/wAq19AhQ3d3diTdKYbeCVf7rLHu/lIK65K1Gz/rb/Mwj8ZW+IB/4oq/XqWMaj/vta8q0nTLa61i21W4uFjtbS1MKlkYkzM8oXbxwV2k54wQPqPVPHs6weF5C5wGlQZyBjnPf6V4xN4ltrUTSEFVZGdI0AxI6uw5brjJYj/e78VKdqDsbU1F1lzbHRXMUZib99ulCg7mwe47H/Jrk9dtYUVTEC5RidwwQT0GfetTW/GFvbaZp00awbrlRu2YJVSvz429wxxj6jA5rlNc1WVriGOPcEjX96gQHn5jlcnJGVILDIHHfiuWHMnc6q0+de8+pft/h9fapvmnlt7VY1SSeIsPO8s5xjAOzIzgNjOD1xXFRK9uk8luSPJxwV5bnnNWrfxJeRaYmlrd3drbSHbdtE5fzUwVHyEjkIxXAYKwVAQCu45UF48ayKBlXQq3PXIx/wDXredRS2OOx9PeM4I7zTtViK7Jrq+t7PfnqoVSD+BkNdbpCKt9rRXob1f0ghH9K4XxFNLEiM6ki710xxHPb5FB/BlI/Cu70WLYdRlDblmvZGU/QBCPwKGtqytBa/1oRT3ZhfE5d3gubPQTRk+3NeB+KbT7CLOPaU/dS8Ef9NTz+PFfTmt2YvtOMO51+YMChIYEdCMV8+/E9yZ45WZSxxyoA4Yg9vrWSd6TG/4h51dQk+UwyS4A2jrnitvxHpV7Jqs6/Z5hOMzyRG2aN13KHwUG4JgBmIJ+UK3JxWcXKtZsuchgQR9RXqfjqGUfFVpRBAnmWpMsc95FbloyGiJV2YDLKd2OevzKRkVzxSVmy57nkkNndzQNImnyywxx7WnjhLCMBlLNkYBI3AHdn74H93FK5iSKV1jLMm47GddrMvYkZOD7ZP1NegW3ikW8WkQzwCXSLPcxscxTbpUVyw2uMqrmTknd1JX7gVeAmQ+YcMJFHAbnGP51bt0Kj3PpGKddSn8KCZcI2oz3DAnOW82Qj8mVa77QAP7Ncjo13csPoZ3P9a82ih/4qXwFa2xOwWpnl59UMhJ/E/8Aj1dd4fuLiGwhKyZSWRmVWPG1nZlP4gr+dddWPMtP63OaEuV6nQ6pcRW1i8s0iIgHJc4HSvm7x7eW+qyhILhWIdATtPCqqAnGM4BVug7V3/iu2vJ7iKK/W5ntLqSQEJMqeUiouCflJLFpMcHGIwe/HiOtW9xBqN5DLvdYGOyXG0OCQAcZI5GeB/SuinSw8KXvttvsUnzSuIqLK1t5UiTBTlyuQF5HqBXqXjPW7W48falcwwLOVsTbRSTW6SJDItwsbMwcEAZR1Bx1YdM5Hjtu5KLGHKYJbIPc4z/IVbub3ULqRWuNSuZ2UKAZZWfAUYA59O3pXnV1FT9zb/gGrTaNLWWZ7mUfaFvZfMd5ZnIBMhPzHn5mHHfPc+tYM0MysrPuVWGQcYFX7aCcBXiikIY7WliLfJ0zuyQB6nJx6YxUqWd3Neoq2N1OZhlIxCxMvc7cdeM8jtk8Vkl5Ep8qsev6V4m02w8YaVIbkzwQ6abUSIhYsyRrltoyQCIySegHU13Gk6vpEOg2BfUrVJordI2RpVVsqu3BB56jrXgI0S+juEnSO7wjhjusnUYz3J4A9+1W4tcsGv4orm5KwFlEkijnaSMleuSMnrjpXpU6NSrqkYOK6HpHjO2h3XGoiS7jARCn2SIETEjDsSFyfljQFieAvGK8d1XTYlke4uUnHmMpV3GwBSPkGOSBjHU5711nj/xsNRmXStCuVez80MWUkB24+XJPIBGc8CuK8R6/d6tK4klBQvuYKCAzDuMnOPTNaulL2KlJa9TRKz93Yq3VtbQBEj3LL1YHOQMd8/WoAMEYOah8ySZQCxIXCj6dqbscHOV/OvMqfFqao0ItUv7KOIQXEqICN0IJCNgkgMB97r+ten6HfFdS0ScQoJpUgJY5IUyfK2BnuGOPTAry5Irm/kKW1szsXHyxqz7cn0GT3r0V4L64NrJoNncoYtq2/wBqVYyPLHBOW46dyDkfn0wsl7pjPzP/2Q==",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABAAEADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD1VI8CuD+KN1La6Zaqg3BmZmT1AGOfbmvQsVxfxB0qW9sI7qAbmtwcr2KnqKzlsVHc8hsIrW9VZkdvMjBxAzffIwMfTvWrqF1La2f+jjC7SPlG3AH8uMfl+VDT9MsJp2uEaVFQMDz909ec+mPftVvWpni01Vt1EbYA+Y/KM46j05P19e1Ys2RW0y6murkNI5BQqsm4YAIHODyP1NdPqHhuLW9K85GxcwDKgAZkGDwR0+h/xzXLiDTINLe4vTvaMDcISIxyQvGe/PT2J7V0HgydW1SKG2l+0WM6sELqoeN0xlSR1wGU7uM7vY1HMr6FOLtqdp8LortPDI+0KqxiQ+WACOPxr0SBc4rJ0uJYbKKNVChRjAHFbEJFdMNEc8tyiap6gglsZUPQqRTbm9jt0ZncDA9a4jVvGrTowsWiCDqxfn8RilKSRUVc85nJ0vWLqxmZo4pJNyMOBnNS6xPv0aVlj/eRAnco9uc+uSevpitjUL64ubaUoEuItuZIz0HXOM/hVDTL6wk05Tc25uQzFSyn7hBx6HPfjHpXJXrci5rXOilT55ctzLsDa3kUcn2+O0IRcO6FznHQLkZ+ue/5dboEtu+p2UFsYzFpomd3jQKmWKgDCnrxkj3A+kNnoyrKq6XqN1Dabt7pE7xKP72Nrjqfb8B0N3WLaO106R4ZJEfqXjYq2eBnIIPp36D8K5KeKpyqqN9/wOqtRcad0tT1HS7hJrYbAw28fN1+ta8TdK8v8I+L91zbW2oyBZNjRMyqVDtkYdl6DhW9ucjAOK9Ljb0r2bxv7p5VpfaPH9Z1qe8Z4Vysb5XeTj8q87vryOzkkhiXCOR8hzgg4JyT1PPTPvW7Npr64TPPN5O07Ywq8jae/Xj2rn720On3Hk3EC+aMsrqx2k5PJUcA478d/rXL7SMpWOj2coxuWIdR8i0kjaZ45FULEoHDZA6fnnFXkie2s1gWOMgRhNzOAxbH3TxzjHXp39xT/sm0ud0kU6qUT5o3525HUfnnHtW5HGGiSFpF8mQCPJ9TwBz3J7H8aqysK7uZVxNqMVgzxXLjaxK4k2gHkYxngd+/HfrWvZ3Vwlm1teGSfaAPLaNt4boAecHoPT+tRfZoIbdPIQLFI2/arHk8fh/+uj92nzWVwQ7gBflOMc846Z4yPTP5S4R7Fc77lO7iWwvra2tpZdjP8iiRlQDnjGccY7Y/rXs/g3VWvtFVZC3mwMUfcckfWvKbmwtbe4N1qCK4LDBXA/iz8579B+v0rsPCmv6XbBoYlaITHfzg859RVRlaREldHBWd5PZalcafdIQC7SW0hOfMUknGe5HX3/Creswre26feAXdu29W+XA+uMmp/EWkG82T27FZ4xxg/wAqwpZ75VVTJJuQYaEx4bd0yG6Y/ofyylSandGsaqcLMzLYyxy+ZCzqX58s/MVAO3DZHHQn0ANatizyWw3lki3Dy5CcY6YUk8+n1yO+al0z7PEkyNIpUSOVjhGZOTxx3x1B/wAK018Oaxd2CHT9NZF5I+0OFIJ7hR268fStrMxuZs17KLGPzJTcBiVLLheDkADoNx4HbB+gpsOrRQxokZkUkAPJg56ZA55x2z79ORVK80/ULPV4LbU7YQLy6Ij5yc9v5f8A6qmvbCG4urUecvDAkK20nnk8fX8c0pabjTubGg6S2osL3U/3sKudiB8hyCeSPQGr+vwQW9o1zbr5bxkY2tgcnpjv1z+FTxXENpZJGjKsca4xnjisuxeXxTr0cMR22cEikccO3IOfb2rjgpTqXOubjCFj/9k=",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "for i in range(100):\n",
    "    clear_output(wait=True)\n",
    "    print(f\"Index {i}\")\n",
    "    top_guesses = [p[0] for p in per_label[i].most_common(10)]\n",
    "    print(\"Guesses:\")\n",
    "    for j in top_guesses:\n",
    "        print(f\"    {j}: {imagenet64_classes[j]}\")\n",
    "    print(f\"Predicted: {assoc[i]}: {imagenet64_classes[assoc[i]]}\")\n",
    "    # print(f\"Was: {imagenet64_classes[imagenet64_assoc[i]]}\", flush=True)\n",
    "    show_images_with_label(i)\n",
    "    time.sleep(0.5)\n",
    "    # new_class = input(f\"{imagenet_classes[assoc[i]]}\\nCorrect: {imagenet64_classes[imagenet64_assoc[i]]}\") \n",
    "    new_class = input(f\"{imagenet64_classes[assoc[i]]}\") \n",
    "    if len(new_class) > 0:\n",
    "        ok = True\n",
    "        try:\n",
    "            new_class = int(new_class)\n",
    "        except Exception:\n",
    "            ok = False\n",
    "        if not ok:\n",
    "            break\n",
    "        assoc[i] = new_class"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6049562dd4d59314",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[901, 585, 969, 440, 737]"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [p[0] for p in per_label[67].most_common(5)]\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T09:48:29.789196039Z",
     "start_time": "2024-01-05T09:48:29.531413491Z"
    }
   },
   "id": "696f096105d99de5",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 89\n",
      "Guesses:\n",
      "    866: tractor\n",
      "    856: thresher, thrasher, threshing machine\n",
      "    595: harvester, reaper\n",
      "    730: plow, plough\n",
      "    621: lawn mower, mower\n",
      "    820: steam locomotive\n",
      "    803: snowplow, snowplough\n",
      "    864: tow truck, tow car, wrecker\n",
      "    847: tank, army tank, armored combat vehicle, armoured combat vehicle\n",
      "    586: half track\n",
      "Predicted: 866: tractor\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": "<IPython.core.display.Image object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 89\n",
    "print(f\"Index {i}\")\n",
    "top_guesses = [p[0] for p in per_label[i].most_common(10)]\n",
    "print(\"Guesses:\")\n",
    "for j in top_guesses:\n",
    "    print(f\"    {j}: {imagenet_classes[j]}\")\n",
    "print(f\"Predicted: {assoc[i]}: {imagenet_classes[assoc[i]]}\", flush=True)\n",
    "show_images_with_label(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T17:43:19.227063404Z",
     "start_time": "2024-01-07T17:43:18.947822968Z"
    }
   },
   "id": "95269b3289d764f2",
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "assoc[21] = 818"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T17:29:59.547186385Z",
     "start_time": "2024-01-07T17:29:59.325764952Z"
    }
   },
   "id": "a1e911a85a9bf7a8",
   "execution_count": 107
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "imagenet64_assoc[31] = 654\n",
    "imagenet64_assoc[42] = 485\n",
    "imagenet64_assoc[48] = 761\n",
    "imagenet64_assoc[56] = 671\n",
    "imagenet64_assoc[57] = 792\n",
    "imagenet64_assoc[89] = 288"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T17:44:52.432073571Z",
     "start_time": "2024-01-07T17:44:52.209758684Z"
    }
   },
   "id": "50f3ae3680cf30ed",
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'steel arch bridge'"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet_classes[821]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:12:02.206001042Z",
     "start_time": "2024-01-05T10:12:01.909248723Z"
    }
   },
   "id": "7ccbcfef34b3245f",
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{61: 349, 66: 440, 28: 187, 13: 372, 16: 105, 56: 525, 81: 957, 89: 542, 12: 781, 34: 912, 53: 424, 98: 123, 82: 79, 72: 964, 85: 774, 41: 73, 86: 470, 46: 970, 5: 917, 95: 411, 32: 69, 3: 414, 21: 739, 99: 758, 27: 954, 7: 877, 93: 315, 47: 978, 60: 283, 20: 400, 59: 675, 8: 705, 45: 849, 23: 862, 90: 532, 74: 500, 71: 311, 2: 810, 73: 744, 76: 430, 38: 570, 43: 511, 33: 806, 10: 683, 1: 932, 18: 354, 54: 842, 22: 308, 40: 496, 58: 50, 31: 286, 39: 910, 94: 887, 77: 458, 69: 821, 30: 457, 52: 25, 19: 325, 83: 619, 0: 314, 15: 158, 64: 526, 11: 448, 42: 839, 68: 438, 75: 975, 51: 32, 24: 207, 25: 614, 29: 474, 78: 761, 92: 75, 6: 627, 17: 689, 9: 625, 97: 567, 48: 540, 57: 109, 50: 480, 37: 938, 14: 704, 44: 747, 67: 737, 70: 612, 84: 734, 80: 678, 36: 733, 63: 281, 49: 367, 26: 114, 4: 341, 35: 652, 62: 1, 79: 945, 91: 760, 96: 71, 55: 425, 87: 482, 65: 765, 88: 447}\n"
     ]
    }
   ],
   "source": [
    "print(assoc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:14:13.386283588Z",
     "start_time": "2024-01-05T10:14:13.149189382Z"
    }
   },
   "id": "184a992f0703ef49",
   "execution_count": 96
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[164,\n 419,\n 961,\n 733,\n 621,\n 900,\n 946,\n 785,\n 657,\n 100,\n 842,\n 524,\n 373,\n 935,\n 530,\n 638,\n 676,\n 850,\n 642,\n 883,\n 812,\n 818,\n 756,\n 235,\n 717,\n 219,\n 979,\n 189,\n 318,\n 584,\n 319,\n 654,\n 173,\n 677,\n 947,\n 904,\n 192,\n 377,\n 984,\n 681,\n 440,\n 886,\n 485,\n 514,\n 538,\n 805,\n 546,\n 116,\n 761,\n 175,\n 994,\n 629,\n 698,\n 604,\n 819,\n 875,\n 671,\n 792,\n 6,\n 213,\n 597,\n 652,\n 60,\n 745,\n 210,\n 794,\n 632,\n 439,\n 364,\n 707,\n 988,\n 527,\n 881,\n 500,\n 558,\n 107,\n 967,\n 11,\n 826,\n 646,\n 616,\n 506,\n 326,\n 273,\n 573,\n 711,\n 422,\n 531,\n 332,\n 288,\n 924,\n 358,\n 732,\n 753,\n 82,\n 999,\n 706,\n 854,\n 274,\n 255]"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assoc_vec = [imagenet64_assoc[i] for i in range(100)]\n",
    "assoc_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-07T17:45:24.241644115Z",
     "start_time": "2024-01-07T17:45:23.897840664Z"
    }
   },
   "id": "496b2ab9df5261fd",
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'goldfish, Carassius auratus'"
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenet_classes[1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-05T10:29:46.887839133Z",
     "start_time": "2024-01-05T10:29:46.643668533Z"
    }
   },
   "id": "3d9be506027cd330",
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "[633,\n 974,\n 542,\n 846,\n 146,\n 929,\n 269,\n 726,\n 265,\n 237,\n 353,\n 838,\n 728,\n 136,\n 526,\n 88,\n 212,\n 879,\n 120,\n 644,\n 895,\n 565,\n 628,\n 593,\n 124,\n 769,\n 653,\n 322,\n 58,\n 835,\n 816,\n 10,\n 600,\n 985,\n 721,\n 865,\n 922,\n 737,\n 970,\n 950,\n 800,\n 599,\n 680,\n 267,\n 845,\n 674,\n 360,\n 366,\n 544,\n 95,\n 547,\n 498,\n 493,\n 704,\n 944,\n 682,\n 719,\n 648,\n 475,\n 283,\n 9,\n 51,\n 449,\n 173,\n 312,\n 309,\n 776,\n 787,\n 990,\n 679,\n 293,\n 631,\n 829,\n 541,\n 712,\n 365,\n 907,\n 715,\n 577,\n 734,\n 594,\n 325,\n 610,\n 813,\n 284,\n 750,\n 590,\n 928,\n 532,\n 798,\n 314,\n 667,\n 606,\n 634,\n 789,\n 844,\n 602,\n 670,\n 617,\n 569]"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assoc_vec = [assoc[i] for i in range(100)]\n",
    "assoc_vec"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:04:29.523438539Z",
     "start_time": "2024-01-06T17:04:29.180292934Z"
    }
   },
   "id": "22fed6d50dfc586b",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['H',\n 'T',\n '__abs__',\n '__add__',\n '__and__',\n '__array__',\n '__array_priority__',\n '__array_wrap__',\n '__bool__',\n '__class__',\n '__complex__',\n '__contains__',\n '__deepcopy__',\n '__delattr__',\n '__delitem__',\n '__dict__',\n '__dir__',\n '__div__',\n '__dlpack__',\n '__dlpack_device__',\n '__doc__',\n '__eq__',\n '__float__',\n '__floordiv__',\n '__format__',\n '__ge__',\n '__getattribute__',\n '__getitem__',\n '__getstate__',\n '__gt__',\n '__hash__',\n '__iadd__',\n '__iand__',\n '__idiv__',\n '__ifloordiv__',\n '__ilshift__',\n '__imod__',\n '__imul__',\n '__index__',\n '__init__',\n '__init_subclass__',\n '__int__',\n '__invert__',\n '__ior__',\n '__ipow__',\n '__irshift__',\n '__isub__',\n '__iter__',\n '__itruediv__',\n '__ixor__',\n '__le__',\n '__len__',\n '__long__',\n '__lshift__',\n '__lt__',\n '__matmul__',\n '__mod__',\n '__module__',\n '__mul__',\n '__ne__',\n '__neg__',\n '__new__',\n '__nonzero__',\n '__or__',\n '__pos__',\n '__pow__',\n '__radd__',\n '__rand__',\n '__rdiv__',\n '__reduce__',\n '__reduce_ex__',\n '__repr__',\n '__reversed__',\n '__rfloordiv__',\n '__rlshift__',\n '__rmatmul__',\n '__rmod__',\n '__rmul__',\n '__ror__',\n '__rpow__',\n '__rrshift__',\n '__rshift__',\n '__rsub__',\n '__rtruediv__',\n '__rxor__',\n '__setattr__',\n '__setitem__',\n '__setstate__',\n '__sizeof__',\n '__str__',\n '__sub__',\n '__subclasshook__',\n '__torch_dispatch__',\n '__torch_function__',\n '__truediv__',\n '__weakref__',\n '__xor__',\n '_addmm_activation',\n '_autocast_to_full_precision',\n '_autocast_to_reduced_precision',\n '_backward_hooks',\n '_base',\n '_cdata',\n '_coalesced_',\n '_conj',\n '_conj_physical',\n '_dimI',\n '_dimV',\n '_fix_weakref',\n '_grad',\n '_grad_fn',\n '_has_symbolic_sizes_strides',\n '_indices',\n '_is_all_true',\n '_is_any_true',\n '_is_view',\n '_is_zerotensor',\n '_make_subclass',\n '_make_wrapper_subclass',\n '_neg_view',\n '_nested_tensor_size',\n '_nested_tensor_storage_offsets',\n '_nested_tensor_strides',\n '_nnz',\n '_post_accumulate_grad_hooks',\n '_python_dispatch',\n '_reduce_ex_internal',\n '_sparse_mask_projection',\n '_to_dense',\n '_to_sparse',\n '_to_sparse_bsc',\n '_to_sparse_bsr',\n '_to_sparse_csc',\n '_to_sparse_csr',\n '_typed_storage',\n '_update_names',\n '_values',\n '_version',\n '_view_func',\n 'abs',\n 'abs_',\n 'absolute',\n 'absolute_',\n 'acos',\n 'acos_',\n 'acosh',\n 'acosh_',\n 'add',\n 'add_',\n 'addbmm',\n 'addbmm_',\n 'addcdiv',\n 'addcdiv_',\n 'addcmul',\n 'addcmul_',\n 'addmm',\n 'addmm_',\n 'addmv',\n 'addmv_',\n 'addr',\n 'addr_',\n 'adjoint',\n 'align_as',\n 'align_to',\n 'all',\n 'allclose',\n 'amax',\n 'amin',\n 'aminmax',\n 'angle',\n 'any',\n 'apply_',\n 'arccos',\n 'arccos_',\n 'arccosh',\n 'arccosh_',\n 'arcsin',\n 'arcsin_',\n 'arcsinh',\n 'arcsinh_',\n 'arctan',\n 'arctan2',\n 'arctan2_',\n 'arctan_',\n 'arctanh',\n 'arctanh_',\n 'argmax',\n 'argmin',\n 'argsort',\n 'argwhere',\n 'as_strided',\n 'as_strided_',\n 'as_strided_scatter',\n 'as_subclass',\n 'asin',\n 'asin_',\n 'asinh',\n 'asinh_',\n 'atan',\n 'atan2',\n 'atan2_',\n 'atan_',\n 'atanh',\n 'atanh_',\n 'backward',\n 'baddbmm',\n 'baddbmm_',\n 'bernoulli',\n 'bernoulli_',\n 'bfloat16',\n 'bincount',\n 'bitwise_and',\n 'bitwise_and_',\n 'bitwise_left_shift',\n 'bitwise_left_shift_',\n 'bitwise_not',\n 'bitwise_not_',\n 'bitwise_or',\n 'bitwise_or_',\n 'bitwise_right_shift',\n 'bitwise_right_shift_',\n 'bitwise_xor',\n 'bitwise_xor_',\n 'bmm',\n 'bool',\n 'broadcast_to',\n 'byte',\n 'cauchy_',\n 'ccol_indices',\n 'cdouble',\n 'ceil',\n 'ceil_',\n 'cfloat',\n 'chalf',\n 'char',\n 'cholesky',\n 'cholesky_inverse',\n 'cholesky_solve',\n 'chunk',\n 'clamp',\n 'clamp_',\n 'clamp_max',\n 'clamp_max_',\n 'clamp_min',\n 'clamp_min_',\n 'clip',\n 'clip_',\n 'clone',\n 'coalesce',\n 'col_indices',\n 'conj',\n 'conj_physical',\n 'conj_physical_',\n 'contiguous',\n 'copy_',\n 'copysign',\n 'copysign_',\n 'corrcoef',\n 'cos',\n 'cos_',\n 'cosh',\n 'cosh_',\n 'count_nonzero',\n 'cov',\n 'cpu',\n 'cross',\n 'crow_indices',\n 'cuda',\n 'cummax',\n 'cummin',\n 'cumprod',\n 'cumprod_',\n 'cumsum',\n 'cumsum_',\n 'data',\n 'data_ptr',\n 'deg2rad',\n 'deg2rad_',\n 'dense_dim',\n 'dequantize',\n 'det',\n 'detach',\n 'detach_',\n 'device',\n 'diag',\n 'diag_embed',\n 'diagflat',\n 'diagonal',\n 'diagonal_scatter',\n 'diff',\n 'digamma',\n 'digamma_',\n 'dim',\n 'dim_order',\n 'dist',\n 'div',\n 'div_',\n 'divide',\n 'divide_',\n 'dot',\n 'double',\n 'dsplit',\n 'dtype',\n 'eig',\n 'element_size',\n 'eq',\n 'eq_',\n 'equal',\n 'erf',\n 'erf_',\n 'erfc',\n 'erfc_',\n 'erfinv',\n 'erfinv_',\n 'exp',\n 'exp2',\n 'exp2_',\n 'exp_',\n 'expand',\n 'expand_as',\n 'expm1',\n 'expm1_',\n 'exponential_',\n 'fill_',\n 'fill_diagonal_',\n 'fix',\n 'fix_',\n 'flatten',\n 'flip',\n 'fliplr',\n 'flipud',\n 'float',\n 'float_power',\n 'float_power_',\n 'floor',\n 'floor_',\n 'floor_divide',\n 'floor_divide_',\n 'fmax',\n 'fmin',\n 'fmod',\n 'fmod_',\n 'frac',\n 'frac_',\n 'frexp',\n 'gather',\n 'gcd',\n 'gcd_',\n 'ge',\n 'ge_',\n 'geometric_',\n 'geqrf',\n 'ger',\n 'get_device',\n 'grad',\n 'grad_fn',\n 'greater',\n 'greater_',\n 'greater_equal',\n 'greater_equal_',\n 'gt',\n 'gt_',\n 'half',\n 'hardshrink',\n 'has_names',\n 'heaviside',\n 'heaviside_',\n 'histc',\n 'histogram',\n 'hsplit',\n 'hypot',\n 'hypot_',\n 'i0',\n 'i0_',\n 'igamma',\n 'igamma_',\n 'igammac',\n 'igammac_',\n 'imag',\n 'index_add',\n 'index_add_',\n 'index_copy',\n 'index_copy_',\n 'index_fill',\n 'index_fill_',\n 'index_put',\n 'index_put_',\n 'index_reduce',\n 'index_reduce_',\n 'index_select',\n 'indices',\n 'inner',\n 'int',\n 'int_repr',\n 'inverse',\n 'ipu',\n 'is_coalesced',\n 'is_complex',\n 'is_conj',\n 'is_contiguous',\n 'is_cpu',\n 'is_cuda',\n 'is_distributed',\n 'is_floating_point',\n 'is_inference',\n 'is_ipu',\n 'is_leaf',\n 'is_meta',\n 'is_mkldnn',\n 'is_mps',\n 'is_neg',\n 'is_nested',\n 'is_nonzero',\n 'is_ort',\n 'is_pinned',\n 'is_quantized',\n 'is_same_size',\n 'is_set_to',\n 'is_shared',\n 'is_signed',\n 'is_sparse',\n 'is_sparse_csr',\n 'is_vulkan',\n 'is_xla',\n 'is_xpu',\n 'isclose',\n 'isfinite',\n 'isinf',\n 'isnan',\n 'isneginf',\n 'isposinf',\n 'isreal',\n 'istft',\n 'item',\n 'itemsize',\n 'kron',\n 'kthvalue',\n 'layout',\n 'lcm',\n 'lcm_',\n 'ldexp',\n 'ldexp_',\n 'le',\n 'le_',\n 'lerp',\n 'lerp_',\n 'less',\n 'less_',\n 'less_equal',\n 'less_equal_',\n 'lgamma',\n 'lgamma_',\n 'log',\n 'log10',\n 'log10_',\n 'log1p',\n 'log1p_',\n 'log2',\n 'log2_',\n 'log_',\n 'log_normal_',\n 'log_softmax',\n 'logaddexp',\n 'logaddexp2',\n 'logcumsumexp',\n 'logdet',\n 'logical_and',\n 'logical_and_',\n 'logical_not',\n 'logical_not_',\n 'logical_or',\n 'logical_or_',\n 'logical_xor',\n 'logical_xor_',\n 'logit',\n 'logit_',\n 'logsumexp',\n 'long',\n 'lstsq',\n 'lt',\n 'lt_',\n 'lu',\n 'lu_solve',\n 'mH',\n 'mT',\n 'map2_',\n 'map_',\n 'masked_fill',\n 'masked_fill_',\n 'masked_scatter',\n 'masked_scatter_',\n 'masked_select',\n 'matmul',\n 'matrix_exp',\n 'matrix_power',\n 'max',\n 'maximum',\n 'mean',\n 'median',\n 'min',\n 'minimum',\n 'mm',\n 'mode',\n 'moveaxis',\n 'movedim',\n 'msort',\n 'mul',\n 'mul_',\n 'multinomial',\n 'multiply',\n 'multiply_',\n 'mv',\n 'mvlgamma',\n 'mvlgamma_',\n 'name',\n 'names',\n 'nan_to_num',\n 'nan_to_num_',\n 'nanmean',\n 'nanmedian',\n 'nanquantile',\n 'nansum',\n 'narrow',\n 'narrow_copy',\n 'nbytes',\n 'ndim',\n 'ndimension',\n 'ne',\n 'ne_',\n 'neg',\n 'neg_',\n 'negative',\n 'negative_',\n 'nelement',\n 'new',\n 'new_empty',\n 'new_empty_strided',\n 'new_full',\n 'new_ones',\n 'new_tensor',\n 'new_zeros',\n 'nextafter',\n 'nextafter_',\n 'nonzero',\n 'nonzero_static',\n 'norm',\n 'normal_',\n 'not_equal',\n 'not_equal_',\n 'numel',\n 'numpy',\n 'orgqr',\n 'ormqr',\n 'outer',\n 'output_nr',\n 'permute',\n 'pin_memory',\n 'pinverse',\n 'polygamma',\n 'polygamma_',\n 'positive',\n 'pow',\n 'pow_',\n 'prelu',\n 'prod',\n 'put',\n 'put_',\n 'q_per_channel_axis',\n 'q_per_channel_scales',\n 'q_per_channel_zero_points',\n 'q_scale',\n 'q_zero_point',\n 'qr',\n 'qscheme',\n 'quantile',\n 'rad2deg',\n 'rad2deg_',\n 'random_',\n 'ravel',\n 'real',\n 'reciprocal',\n 'reciprocal_',\n 'record_stream',\n 'refine_names',\n 'register_hook',\n 'register_post_accumulate_grad_hook',\n 'reinforce',\n 'relu',\n 'relu_',\n 'remainder',\n 'remainder_',\n 'rename',\n 'rename_',\n 'renorm',\n 'renorm_',\n 'repeat',\n 'repeat_interleave',\n 'requires_grad',\n 'requires_grad_',\n 'reshape',\n 'reshape_as',\n 'resize',\n 'resize_',\n 'resize_as',\n 'resize_as_',\n 'resize_as_sparse_',\n 'resolve_conj',\n 'resolve_neg',\n 'retain_grad',\n 'retains_grad',\n 'roll',\n 'rot90',\n 'round',\n 'round_',\n 'row_indices',\n 'rsqrt',\n 'rsqrt_',\n 'scatter',\n 'scatter_',\n 'scatter_add',\n 'scatter_add_',\n 'scatter_reduce',\n 'scatter_reduce_',\n 'select',\n 'select_scatter',\n 'set_',\n 'sgn',\n 'sgn_',\n 'shape',\n 'share_memory_',\n 'short',\n 'sigmoid',\n 'sigmoid_',\n 'sign',\n 'sign_',\n 'signbit',\n 'sin',\n 'sin_',\n 'sinc',\n 'sinc_',\n 'sinh',\n 'sinh_',\n 'size',\n 'slice_scatter',\n 'slogdet',\n 'smm',\n 'softmax',\n 'solve',\n 'sort',\n 'sparse_dim',\n 'sparse_mask',\n 'sparse_resize_',\n 'sparse_resize_and_clear_',\n 'split',\n 'split_with_sizes',\n 'sqrt',\n 'sqrt_',\n 'square',\n 'square_',\n 'squeeze',\n 'squeeze_',\n 'sspaddmm',\n 'std',\n 'stft',\n 'storage',\n 'storage_offset',\n 'storage_type',\n 'stride',\n 'sub',\n 'sub_',\n 'subtract',\n 'subtract_',\n 'sum',\n 'sum_to_size',\n 'svd',\n 'swapaxes',\n 'swapaxes_',\n 'swapdims',\n 'swapdims_',\n 'symeig',\n 't',\n 't_',\n 'take',\n 'take_along_dim',\n 'tan',\n 'tan_',\n 'tanh',\n 'tanh_',\n 'tensor_split',\n 'tile',\n 'to',\n 'to_dense',\n 'to_mkldnn',\n 'to_padded_tensor',\n 'to_sparse',\n 'to_sparse_bsc',\n 'to_sparse_bsr',\n 'to_sparse_coo',\n 'to_sparse_csc',\n 'to_sparse_csr',\n 'tolist',\n 'topk',\n 'trace',\n 'transpose',\n 'transpose_',\n 'triangular_solve',\n 'tril',\n 'tril_',\n 'triu',\n 'triu_',\n 'true_divide',\n 'true_divide_',\n 'trunc',\n 'trunc_',\n 'type',\n 'type_as',\n 'unbind',\n 'unflatten',\n 'unfold',\n 'uniform_',\n 'unique',\n 'unique_consecutive',\n 'unsafe_chunk',\n 'unsafe_split',\n 'unsafe_split_with_sizes',\n 'unsqueeze',\n 'unsqueeze_',\n 'untyped_storage',\n 'values',\n 'var',\n 'vdot',\n 'view',\n 'view_as',\n 'vsplit',\n 'where',\n 'xlogy',\n 'xlogy_',\n 'xpu',\n 'zero_']"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(resnet50.fc.weight)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:11:05.882316321Z",
     "start_time": "2024-01-06T17:11:05.647452147Z"
    }
   },
   "id": "81056bd713d345b1",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "resnet50.fc.weight.set_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40539e7e6912c1c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "odict_keys(['conv1.weight', 'bn1.weight', 'bn1.bias', 'bn1.running_mean', 'bn1.running_var', 'bn1.num_batches_tracked', 'layer1.0.conv1.weight', 'layer1.0.bn1.weight', 'layer1.0.bn1.bias', 'layer1.0.bn1.running_mean', 'layer1.0.bn1.running_var', 'layer1.0.bn1.num_batches_tracked', 'layer1.0.conv2.weight', 'layer1.0.bn2.weight', 'layer1.0.bn2.bias', 'layer1.0.bn2.running_mean', 'layer1.0.bn2.running_var', 'layer1.0.bn2.num_batches_tracked', 'layer1.0.conv3.weight', 'layer1.0.bn3.weight', 'layer1.0.bn3.bias', 'layer1.0.bn3.running_mean', 'layer1.0.bn3.running_var', 'layer1.0.bn3.num_batches_tracked', 'layer1.0.downsample.0.weight', 'layer1.0.downsample.1.weight', 'layer1.0.downsample.1.bias', 'layer1.0.downsample.1.running_mean', 'layer1.0.downsample.1.running_var', 'layer1.0.downsample.1.num_batches_tracked', 'layer1.1.conv1.weight', 'layer1.1.bn1.weight', 'layer1.1.bn1.bias', 'layer1.1.bn1.running_mean', 'layer1.1.bn1.running_var', 'layer1.1.bn1.num_batches_tracked', 'layer1.1.conv2.weight', 'layer1.1.bn2.weight', 'layer1.1.bn2.bias', 'layer1.1.bn2.running_mean', 'layer1.1.bn2.running_var', 'layer1.1.bn2.num_batches_tracked', 'layer1.1.conv3.weight', 'layer1.1.bn3.weight', 'layer1.1.bn3.bias', 'layer1.1.bn3.running_mean', 'layer1.1.bn3.running_var', 'layer1.1.bn3.num_batches_tracked', 'layer1.2.conv1.weight', 'layer1.2.bn1.weight', 'layer1.2.bn1.bias', 'layer1.2.bn1.running_mean', 'layer1.2.bn1.running_var', 'layer1.2.bn1.num_batches_tracked', 'layer1.2.conv2.weight', 'layer1.2.bn2.weight', 'layer1.2.bn2.bias', 'layer1.2.bn2.running_mean', 'layer1.2.bn2.running_var', 'layer1.2.bn2.num_batches_tracked', 'layer1.2.conv3.weight', 'layer1.2.bn3.weight', 'layer1.2.bn3.bias', 'layer1.2.bn3.running_mean', 'layer1.2.bn3.running_var', 'layer1.2.bn3.num_batches_tracked', 'layer2.0.conv1.weight', 'layer2.0.bn1.weight', 'layer2.0.bn1.bias', 'layer2.0.bn1.running_mean', 'layer2.0.bn1.running_var', 'layer2.0.bn1.num_batches_tracked', 'layer2.0.conv2.weight', 'layer2.0.bn2.weight', 'layer2.0.bn2.bias', 'layer2.0.bn2.running_mean', 'layer2.0.bn2.running_var', 'layer2.0.bn2.num_batches_tracked', 'layer2.0.conv3.weight', 'layer2.0.bn3.weight', 'layer2.0.bn3.bias', 'layer2.0.bn3.running_mean', 'layer2.0.bn3.running_var', 'layer2.0.bn3.num_batches_tracked', 'layer2.0.downsample.0.weight', 'layer2.0.downsample.1.weight', 'layer2.0.downsample.1.bias', 'layer2.0.downsample.1.running_mean', 'layer2.0.downsample.1.running_var', 'layer2.0.downsample.1.num_batches_tracked', 'layer2.1.conv1.weight', 'layer2.1.bn1.weight', 'layer2.1.bn1.bias', 'layer2.1.bn1.running_mean', 'layer2.1.bn1.running_var', 'layer2.1.bn1.num_batches_tracked', 'layer2.1.conv2.weight', 'layer2.1.bn2.weight', 'layer2.1.bn2.bias', 'layer2.1.bn2.running_mean', 'layer2.1.bn2.running_var', 'layer2.1.bn2.num_batches_tracked', 'layer2.1.conv3.weight', 'layer2.1.bn3.weight', 'layer2.1.bn3.bias', 'layer2.1.bn3.running_mean', 'layer2.1.bn3.running_var', 'layer2.1.bn3.num_batches_tracked', 'layer2.2.conv1.weight', 'layer2.2.bn1.weight', 'layer2.2.bn1.bias', 'layer2.2.bn1.running_mean', 'layer2.2.bn1.running_var', 'layer2.2.bn1.num_batches_tracked', 'layer2.2.conv2.weight', 'layer2.2.bn2.weight', 'layer2.2.bn2.bias', 'layer2.2.bn2.running_mean', 'layer2.2.bn2.running_var', 'layer2.2.bn2.num_batches_tracked', 'layer2.2.conv3.weight', 'layer2.2.bn3.weight', 'layer2.2.bn3.bias', 'layer2.2.bn3.running_mean', 'layer2.2.bn3.running_var', 'layer2.2.bn3.num_batches_tracked', 'layer2.3.conv1.weight', 'layer2.3.bn1.weight', 'layer2.3.bn1.bias', 'layer2.3.bn1.running_mean', 'layer2.3.bn1.running_var', 'layer2.3.bn1.num_batches_tracked', 'layer2.3.conv2.weight', 'layer2.3.bn2.weight', 'layer2.3.bn2.bias', 'layer2.3.bn2.running_mean', 'layer2.3.bn2.running_var', 'layer2.3.bn2.num_batches_tracked', 'layer2.3.conv3.weight', 'layer2.3.bn3.weight', 'layer2.3.bn3.bias', 'layer2.3.bn3.running_mean', 'layer2.3.bn3.running_var', 'layer2.3.bn3.num_batches_tracked', 'layer3.0.conv1.weight', 'layer3.0.bn1.weight', 'layer3.0.bn1.bias', 'layer3.0.bn1.running_mean', 'layer3.0.bn1.running_var', 'layer3.0.bn1.num_batches_tracked', 'layer3.0.conv2.weight', 'layer3.0.bn2.weight', 'layer3.0.bn2.bias', 'layer3.0.bn2.running_mean', 'layer3.0.bn2.running_var', 'layer3.0.bn2.num_batches_tracked', 'layer3.0.conv3.weight', 'layer3.0.bn3.weight', 'layer3.0.bn3.bias', 'layer3.0.bn3.running_mean', 'layer3.0.bn3.running_var', 'layer3.0.bn3.num_batches_tracked', 'layer3.0.downsample.0.weight', 'layer3.0.downsample.1.weight', 'layer3.0.downsample.1.bias', 'layer3.0.downsample.1.running_mean', 'layer3.0.downsample.1.running_var', 'layer3.0.downsample.1.num_batches_tracked', 'layer3.1.conv1.weight', 'layer3.1.bn1.weight', 'layer3.1.bn1.bias', 'layer3.1.bn1.running_mean', 'layer3.1.bn1.running_var', 'layer3.1.bn1.num_batches_tracked', 'layer3.1.conv2.weight', 'layer3.1.bn2.weight', 'layer3.1.bn2.bias', 'layer3.1.bn2.running_mean', 'layer3.1.bn2.running_var', 'layer3.1.bn2.num_batches_tracked', 'layer3.1.conv3.weight', 'layer3.1.bn3.weight', 'layer3.1.bn3.bias', 'layer3.1.bn3.running_mean', 'layer3.1.bn3.running_var', 'layer3.1.bn3.num_batches_tracked', 'layer3.2.conv1.weight', 'layer3.2.bn1.weight', 'layer3.2.bn1.bias', 'layer3.2.bn1.running_mean', 'layer3.2.bn1.running_var', 'layer3.2.bn1.num_batches_tracked', 'layer3.2.conv2.weight', 'layer3.2.bn2.weight', 'layer3.2.bn2.bias', 'layer3.2.bn2.running_mean', 'layer3.2.bn2.running_var', 'layer3.2.bn2.num_batches_tracked', 'layer3.2.conv3.weight', 'layer3.2.bn3.weight', 'layer3.2.bn3.bias', 'layer3.2.bn3.running_mean', 'layer3.2.bn3.running_var', 'layer3.2.bn3.num_batches_tracked', 'layer3.3.conv1.weight', 'layer3.3.bn1.weight', 'layer3.3.bn1.bias', 'layer3.3.bn1.running_mean', 'layer3.3.bn1.running_var', 'layer3.3.bn1.num_batches_tracked', 'layer3.3.conv2.weight', 'layer3.3.bn2.weight', 'layer3.3.bn2.bias', 'layer3.3.bn2.running_mean', 'layer3.3.bn2.running_var', 'layer3.3.bn2.num_batches_tracked', 'layer3.3.conv3.weight', 'layer3.3.bn3.weight', 'layer3.3.bn3.bias', 'layer3.3.bn3.running_mean', 'layer3.3.bn3.running_var', 'layer3.3.bn3.num_batches_tracked', 'layer3.4.conv1.weight', 'layer3.4.bn1.weight', 'layer3.4.bn1.bias', 'layer3.4.bn1.running_mean', 'layer3.4.bn1.running_var', 'layer3.4.bn1.num_batches_tracked', 'layer3.4.conv2.weight', 'layer3.4.bn2.weight', 'layer3.4.bn2.bias', 'layer3.4.bn2.running_mean', 'layer3.4.bn2.running_var', 'layer3.4.bn2.num_batches_tracked', 'layer3.4.conv3.weight', 'layer3.4.bn3.weight', 'layer3.4.bn3.bias', 'layer3.4.bn3.running_mean', 'layer3.4.bn3.running_var', 'layer3.4.bn3.num_batches_tracked', 'layer3.5.conv1.weight', 'layer3.5.bn1.weight', 'layer3.5.bn1.bias', 'layer3.5.bn1.running_mean', 'layer3.5.bn1.running_var', 'layer3.5.bn1.num_batches_tracked', 'layer3.5.conv2.weight', 'layer3.5.bn2.weight', 'layer3.5.bn2.bias', 'layer3.5.bn2.running_mean', 'layer3.5.bn2.running_var', 'layer3.5.bn2.num_batches_tracked', 'layer3.5.conv3.weight', 'layer3.5.bn3.weight', 'layer3.5.bn3.bias', 'layer3.5.bn3.running_mean', 'layer3.5.bn3.running_var', 'layer3.5.bn3.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.conv3.weight', 'layer4.0.bn3.weight', 'layer4.0.bn3.bias', 'layer4.0.bn3.running_mean', 'layer4.0.bn3.running_var', 'layer4.0.bn3.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'layer4.1.conv3.weight', 'layer4.1.bn3.weight', 'layer4.1.bn3.bias', 'layer4.1.bn3.running_mean', 'layer4.1.bn3.running_var', 'layer4.1.bn3.num_batches_tracked', 'layer4.2.conv1.weight', 'layer4.2.bn1.weight', 'layer4.2.bn1.bias', 'layer4.2.bn1.running_mean', 'layer4.2.bn1.running_var', 'layer4.2.bn1.num_batches_tracked', 'layer4.2.conv2.weight', 'layer4.2.bn2.weight', 'layer4.2.bn2.bias', 'layer4.2.bn2.running_mean', 'layer4.2.bn2.running_var', 'layer4.2.bn2.num_batches_tracked', 'layer4.2.conv3.weight', 'layer4.2.bn3.weight', 'layer4.2.bn3.bias', 'layer4.2.bn3.running_mean', 'layer4.2.bn3.running_var', 'layer4.2.bn3.num_batches_tracked', 'fc.weight', 'fc.bias'])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(\"/home/doved/Downloads/checkpoint-86.pth.tar\")[\"state_dict\"]\n",
    "ckpt.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:12:05.045145922Z",
     "start_time": "2024-01-06T17:12:03.273744218Z"
    }
   },
   "id": "4e4e2bc6b00643a3",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 2048])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"fc.weight\"].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:12:29.764133031Z",
     "start_time": "2024-01-06T17:12:29.389839445Z"
    }
   },
   "id": "1302af4ecbd2ec7",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100, 2048])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"fc.weight\"][assoc_vec, :].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:13:11.454019355Z",
     "start_time": "2024-01-06T17:13:11.078309061Z"
    }
   },
   "id": "5168dbf810649ccb",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([100])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt[\"fc.bias\"][assoc_vec].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T17:13:28.773431200Z",
     "start_time": "2024-01-06T17:13:28.024116659Z"
    }
   },
   "id": "877c926ec6e8c4fd",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.0081, -0.0097,  0.0011,  ..., -0.0133, -0.0127,  0.0085],\n        [-0.0019,  0.0140, -0.0250,  ..., -0.0080, -0.0202, -0.0104],\n        [ 0.0090, -0.0086, -0.0173,  ...,  0.0043, -0.0041,  0.0032],\n        ...,\n        [-0.0156,  0.0012,  0.0091,  ..., -0.0050, -0.0256, -0.0050],\n        [-0.0131,  0.0065, -0.0048,  ..., -0.0041,  0.0036,  0.0081],\n        [ 0.0165,  0.0112, -0.0049,  ...,  0.0074,  0.0196, -0.0051]],\n       requires_grad=True)"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T19:00:50.533719347Z",
     "start_time": "2024-01-06T19:00:50.207178604Z"
    }
   },
   "id": "7d41f2ff0109e259",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0067, -0.0298, -0.0128,  ..., -0.0086, -0.0073, -0.0129],\n        [-0.0191, -0.0153, -0.0138,  ...,  0.0082, -0.0227,  0.0018],\n        [ 0.0037,  0.0036, -0.0062,  ..., -0.0047,  0.0087,  0.0090],\n        ...,\n        [-0.0155, -0.0111, -0.0111,  ...,  0.0053, -0.0109,  0.0098],\n        [-0.0113, -0.0032, -0.0249,  ..., -0.0084, -0.0237, -0.0171],\n        [-0.0189,  0.0148, -0.0050,  ..., -0.0014, -0.0113, -0.0154]])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc.weight.data.set_(resnet50.fc.weight.data[assoc_vec, :])\n",
    "# resnet50.fc.bias.data.set_(resnet50.fc.bias.data[assoc_vec])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T19:01:32.984376509Z",
     "start_time": "2024-01-06T19:01:32.551020071Z"
    }
   },
   "id": "6796eba359a254ec",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[-0.0081, -0.0097,  0.0011,  ..., -0.0133, -0.0127,  0.0085],\n        [-0.0019,  0.0140, -0.0250,  ..., -0.0080, -0.0202, -0.0104],\n        [ 0.0090, -0.0086, -0.0173,  ...,  0.0043, -0.0041,  0.0032],\n        ...,\n        [-0.0156,  0.0012,  0.0091,  ..., -0.0050, -0.0256, -0.0050],\n        [-0.0131,  0.0065, -0.0048,  ..., -0.0041,  0.0036,  0.0081],\n        [ 0.0165,  0.0112, -0.0049,  ...,  0.0074,  0.0196, -0.0051]],\n       requires_grad=True)"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc.weight"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T19:01:36.383121767Z",
     "start_time": "2024-01-06T19:01:36.204558169Z"
    }
   },
   "id": "799f69b75dcda320",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1000, 2048])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet50.fc.weight.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T19:01:37.821604996Z",
     "start_time": "2024-01-06T19:01:37.808060495Z"
    }
   },
   "id": "839bcd8931c40211",
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(assoc_vec)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T19:01:22.806854157Z",
     "start_time": "2024-01-06T19:01:22.604069368Z"
    }
   },
   "id": "d1ac60109ad2f880",
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn.init\n",
    "\n",
    "torch.nn.init.uniform_()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9905fe74ca325290"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
